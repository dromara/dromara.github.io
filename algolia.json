[{"author":null,"categories":["SOFAStack"],"content":"\nSOFAStack™ (Scalable Open Financial Architecture Stack) is a collection of cloud native middleware components, which are designed to build distributed systems with high performance and reliability, and have been fully validated by mission-critical financial business scenarios.\nLinks Home Page: https://www.sofastack.tech\nSource Code: https://github.com/sofastack\nProjects  SOFABoot is a development framework open sourced by Ant Financial which is based on Spring Boot, provides capabilities such as Readiness Check, class isolation, log space isolation and asynchronous initialization of bean. SOFARPC is a high-performance, high-extensibility, production-level Java RPC framework. SOFAMesh SOFAMesh is a large-scale implementation solution for Service Mesh which is improved and extended based on Istio. SOFAMosn SOFAMosn(Modular Observable Smart Network) is a powerful proxy acting as Service Mesh\u0026amp;rsquo;s data plane written in Go. SOFATracer SOFATracer is a distributed link tracing system based onOpenTracing specification. SOFALookout SOFALookout is a lightweight and open source middleware service that solves the metrics and monitoring issues of the system. SOFABolt SOFABolt is a network communication framework implemented based on Netty. SOFAArk SOFAArk is a light-weight, java based classloader isolation framework. SOFAJarslink Is a dynamic modules and merged deployments solution based on SOFAArk. SOFAActs ACTS (AntCoreTest) is a white-box testing framework that is based on the accumulation of testing practices for financial-grade distributed architectures. SOFAJraft SOFAJRaft is a production-grade, high-performance Java implementation based on the RAFT consensus algorithm. SOFARegistry SOFARegistry is a production ready, high efficient, highly available service registry. SOFADashboard Is a one-stop console of SOFAStack.  More projects in: github/sofastack\nCommunity   Github\n  WeChat\n  Official Account：Antfin_SOFA is a technology exchange platform dedicated to building first-class distributed technologies in financial scenario applications, focusing on the most cutting-edge, reference-oriented technical solutions and implementation routes in the financial technology industry.\n  WeChat Groups：We have ten groups and more than four thousand developers, Add ant-techfin02 as your friend, and reply SOFA will invite to joining into the group.\n    DingTalk\n  DingTalk Group:\n 「SOFAStack 1」 No: 23127468 Group is Full 「SOFAStack 2」 No: 23195297 Group is Full 「SOFAStack 3」 No: 23390449 Group is Full 「SOFAStack 4」 No: 23372465 Group is Full 「SOFAStack 5」 No: 30315793    DingTalk Group:「SOFAStack Online service」, If you have used any SOFAStack related components in a production environment, please let us know, and we will invite you to join this group for faster communication and more efficient use of problem support online.\n    Weibo\n  SegmentFault\n  juejin.im\n  ","date":1524135415,"description":"Say hello to SOFAStack!","dir":"blog/hello-sofastack/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"26e249e6b2d0e482eb4404b76dabaec4","permalink":"/en/blog/hello-sofastack/","publishdate":"2018-04-19T11:56:55+01:00","readingtime":2,"relpermalink":"/en/blog/hello-sofastack/","summary":"SOFAStack™ (Scalable Open Financial Architecture Stack) is a collection of cloud native middleware components, which are designed to build distributed systems with high performance and reliability, and have been fully validated by mission-critical financial business scenarios.\nLinks Home Page: https://www.sofastack.tech\nSource Code: https://github.com/sofastack\nProjects  SOFABoot is a development framework open sourced by Ant Financial which is based on Spring Boot, provides capabilities such as Readiness Check, class isolation, log space isolation and asynchronous initialization of bean.","tags":["SOFAStack"],"title":"Hello SOFAStack!","type":"blog","url":"/en/blog/hello-sofastack/","wordcount":383},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级云原生架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\nSOFAStack 官网: https://www.sofastack.tech\nSOFAStack: https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题 通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n@吴小彬 提问：\n 请教下，如果分支事务中使用了分库分表中间件（shardingsphere-proxy、mycat 等），Seata-AT 模式是不是不能用的？是只可以用 TCC 模式吗？现在的 shardingsphereProxy 中间件（不是 shardingsphereJdbc ）用 AT 模式，它对微服务来说就是一个 MySQL 连接，它是怎么知道微服务调用链中的 xid 的？\n A：可以用，shardingsphere 4.1 支持 Seata AT， proxy 我估摸着有点悬，因为他属于一个代理层。Jdbc 是直接在应用的 Jdbc 层提供服务的，所以 AT 可以很好的支持。\n@谭玖朋 提问：\n 在关于 AT 模式，第一阶段执行完后生成行锁然后注册分支事务，其中的行锁具体是指什么锁呢？因为发现第一阶段执行完后，其实再查数据的话是已经改变了。所以关于这个行锁这么解释？\n A：Select for update 的时候，首先 Seata 会代理这个语句，去查询 TC 这个行有没有锁住，如果没锁住，客户端业务用了 for update 那么就拿到了本地锁，此时因为本地锁排他，这个时候没有全局锁的 for update 就是分布式下的读已提交。 不是允许脏读，是读已提交。读未提交是默认的，所以只有在你 update 的时候（update 是当前读），但是如果你的 update 是基于快照度的 select 结果，可能会出现事与愿违的结果，如果你要基于某个数据来 update，要么 for update 来读分布式下的已提交，要么就用 update x=x-1 之类的写法，因为提交时会抢占全局锁，没抢到会 rollback，释放当前锁进行重试，这样就能保证抢到锁的时候，update 的数据当前读是分布式下的读已提交并修改 目前好像没人写关于 AT 行锁及全局锁部分源码有分析讲解的资料，如果感兴趣可以去阅读一下，写出来投稿给我们。\nSeata：https://github.com/seata/seata\n本周推荐阅读  Mecha：将 Mesh 进行到底 记一次在 MOSN 对 Dubbo、Dubbo-go-hessian2 的性能优化 Service Mesh 和 API Gateway 关系深度探讨 Service Mesh 通用数据平面 API（UDPA）最新进展深度介绍  Occlum 项目进展 Occlum 发布 v0.19.1 版本，主要变更如下：\ni.同时兼容 Glibc 和 musl libc的应用\nii. 支持基于 DCAP (Intel SGX Data Center Attestation Primitives) 的远程验证\niii. 修复了内存泄漏问题\n详细发布报告： https://github.com/occlum/occlum/releases/tag/0.19.1\n","date":1610694000,"description":"SOFA WEEKLY | Occlum 发布新版本，Seata QA 整理","dir":"blog/sofa-weekly-20210115/","fuzzywordcount":1200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"48d18f44f20f4b6d5f8b219e383bfa51","permalink":"/blog/sofa-weekly-20210115/","publishdate":"2021-01-15T15:00:00+08:00","readingtime":3,"relpermalink":"/blog/sofa-weekly-20210115/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级云","tags":["SOFA Weekly"],"title":"SOFA Weekly | Occlum 发布新版本，Seata QA 整理","type":"blog","url":"/blog/sofa-weekly-20210115/","wordcount":1106},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级云原生架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\nSOFAStack 官网: https://www.sofastack.tech\nSOFAStack: https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题 通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@梁俊 提问：\n 有一台物理服务器，没有安装 OS，是不是可以把 Occlum LibOS 像通用操作系统一样当做 host OS 用，运行 Occlum LibOS，需不需要在物理服务器上安装 host OS?\n A：Occlum 对硬件也是有要求的。这个机器需要支持 Intel SGX 技术。简单得说，就是必须可以安装 SGX 驱动。 Guest OS 是虚拟机的概念，从 guest OS 的角度看，OS 依然运行在 kernel 态。简单来说，如果想使用 Occlum，那么建议方案： 1 . 找一台 SGX 机器 （比如 W55）； 2. 安装一个OS，并且装上 SGX 驱动； 3. 安装 Occlum；\n Occlum 相对于 Docker 有哪些优势，比 Docker 快吗?\n A：Occlum 的优势是安全。外界无法探测运行在 Occlum 中的程序和这个程序使用的内存以及寄存器。也就是说，可以把机密信息（比如密钥）放在 Occlum 中而不用担心信息泄露。\nOcclum：https://github.com/occlum/occlum\n2、@李天宇 提问：\n 可不可以定义一个这样的准则每个 RPC 后面，必须得有一个 TM，每个 TM 维护一个 TM 块，RPC +1，就应该等于 TM 块？ A：这样一个完整的链路有多少个参与者，发起者可以获得，校验规则就是 spanid 是否与参与者数量 +1，是否相等？认为 RPC 向下的服务资源都是一个完整的事务，不管它是否与 db 交互，即可以无 RM ，我的想法就是让 TM 发起者，可以随着链路信息感知所有的 TM。 Tm 可以在每个微服务上都标注下 注解，默认是加入到之前的事务中。TraceId 可以塞到 Seata 的协议中传递到 RPC 下游。\n3、@李天宇 提问：\n 支持不同 branch 不同的 type 吗？\n A：AT 和 TCC 可以共存，Saga 不行。比如 a 数据在 AT 下被改，又被 Saga 或者 xa 分支改动，因为它们不是 AT 无法通过全局锁保证隔离性，除非所有的模式只要内部含有 AT 分支，都去获取全局锁，这样带来了一个问题，如何提前知晓某个 TM 的调用链路中有 AT 分支，靠用户注解上写，那入侵性就有点大了。\nSeata：https://github.com/seata/seata\n本周推荐阅读  SOFAEnclave：蚂蚁机密计算如何解决现实挑战？ 蚂蚁集团宣布开源 KubeTEE：让机密计算支持大规模 K8s 集群 开源项目是如何让这个世界更安全的？ 网商银行是如何建设金融级云原生分布式架构的？  MOSN 项目进展 本周发布详情如下：\n1、MOSN 发布 v0.20.0 版本，主要变更如下：\n 路由模块进行了优化与重构，支持变量机制与可配置的扩展模式 使用的 Go 版本升级到了 1.14.13 支持 XDS 非持久化模式下配置的热升级 完善支持了 Netpoll 模式 其他一些新功能、优化与 Bug Fix  详细参考：https://github.com/mosn/mosn/releases/tag/v0.20.0\n","date":1610089200,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20210108/","fuzzywordcount":1300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"86ee4a89adc2c475c6f406d2774743c8","permalink":"/blog/sofa-weekly-20210108/","publishdate":"2021-01-08T15:00:00+08:00","readingtime":3,"relpermalink":"/blog/sofa-weekly-20210108/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级云","tags":["SOFA Weekly"],"title":"SOFA Weekly | MOSN 发布新版本，QA 整理","type":"blog","url":"/blog/sofa-weekly-20210108/","wordcount":1294},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级云原生架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\nSOFAStack 官网: https://www.sofastack.tech\nSOFAStack: https://github.com/sofastack\n社区 Big News  SOFA 社群元旦快乐！新的一年我们也要在一起哦！\n同时，也有一个好消息要和大家共享： MOSN 荣获 「2020 年中国优秀开源项目」，感谢所有开发者们的支持和喜爱，MOSN 团队会继续努力，提供更好的开源产品和服务，也期待大家的持续共建。\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题 通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@苏榴结 提问：\n 对于某个全局事务来说，向 tc 注册说你是 tm 也是 rm，但因为这个全局事务已经有了 tm，所以它就会被认定为rm 是吗？\n A :服务起来的时候就跟 TC 说了你可以做 TM ，也可以做 RM (分别建立一个长连接与 TC 通信)，然后在需要进行某个全局事务的时候，如果他是发起全局事务的那个，那么他就发挥了他 TM 那部分职能，如果他是负责操作数据库，那他就发挥了 RM 那部分的职能。\n2、@刘亚飞 提问：\n 为什么图 1 中描述用协程池来处理可读 conn，图 2 中，又说每一个 conn 有一个读协程呢？是因为图 1 描述的是 rawpoll 模型下的代码方式，而图 2 是 goroutine-per-connection 模式下的一个 write goroutine 池化吗？\n 图1\n图2\nA：图 1 图 2 属于两种模型。Rawpoll 模型的话就是自己做 epoll_wait，有可读事件从协程池拿一个协程来读取数据；协程模型的话就是一个连接一个协程，标准的 go 编码模式，runtime 来处理 epoll_wait，可配置选择不同模式。\n本周推荐阅读  云原生网络代理 MOSN 的进化之路 基于 MOSN 和 Istio Service Mesh 的服务治理实践 记一次在 MOSN 对 Dubbo、Dubbo-go-hessian2 的性能优化 云原生网络代理 MOSN 透明劫持技术解读 | 开源  SOFA项目进展 本周发布详情如下：\n1、SOFA-Common-Tools 发布 1.3.1 版本：\n 修复多 classloader 场景下 commons-logging 的兼容性 修复 SOFAThreadPoolExecutor 被删除的方法，提高向下兼容性  详细参考: https://github.com/sofastack/sofa-common-tools/releases/tag/v1.3.1\n2、SOFA-Ark 发布 1.1.6 版本：\n 支持插件扩展，通过宿主动态扩展指定 plugin 依赖和导出关系 SOFA-Ark-manve-plugin 支持打包按规则排除依赖（from file）  详细参考： https://github.com/sofastack/sofa-ark/releases/tag/v1.1.6\n","date":1609398000,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20201231/","fuzzywordcount":1000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"ca60ed7c9ac011477c8861c0f5650629","permalink":"/blog/sofa-weekly-20201231/","publishdate":"2020-12-31T15:00:00+08:00","readingtime":2,"relpermalink":"/blog/sofa-weekly-20201231/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级云","tags":["SOFA Weekly"],"title":"SOFA Weekly | SOFA 社区元旦快乐，MOSN 荣获 2020 中国优秀开源项目","type":"blog","url":"/blog/sofa-weekly-20201231/","wordcount":994},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级云原生架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\nSOFAStack 官网: https://www.sofastack.tech\nSOFAStack: https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题 通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@薛帅领 提问：\n 多数据源切换后，增加事务但不起作用（切数据源是执行方法后才切换的），本地事务及 Seate 分布式事务也不行，这个有什么好的解决方案吗？\n A：Spring 本地事务注解本身就不支持多数据源事务，且如果你开启了本地事务，之后并不会进入你的切换数据源的切面。 在多数据源下，去掉本地事务注解就好了。用 globaltransactional 注解在多数据源的入口加上，多个数据源都被 Seata 代理的话，就会保证多数据源的事务。\n2、@李天宇 提问\n 如果在分布式事务中，另一个线程做批处理 update 之类的，是否会锁住呢?\n A：不会，另一个线程也要记得加上 globaltransactional 注解就行了。在 a 线程要提交之前要去尝试拿到它修改数据的全局锁的，如果 a 拿到了，但是还没到二阶段提交，b 也是要去尝试拿，拿不到就会不执行 SQL，等待全局锁释放了，也就是 a 发起的事务结束了，b 才能执行 SQL 提交。这样就保证了利用全局锁（粒度行级），来达到隔离性。\nSeata：https://github.com/seata/seata\n相关推荐阅读   Kubernetes: 微内核的分布式操作系统\n  走出微服务误区：避免从单体到分布式单体\n  网商银行是如何建设金融级云原生分布式架构的？\n  支付宝资深技术专家尹博学：新一代金融核心突破之全分布式单元化技术架构\n  SOFA 项目进展 本周发布详情如下：\nSOFA-Common-Tools 发布1.3.0 版本，主要变更如下：\n SOFA 线程池支持 ScheduledThreadPoolExecutor 与 ThreadPoolTaskScheduler 新增 SofaConfigs 支持统一的配置获取 新增 LogCode2Description 支持统一的错误码获取 重构线程池实现，支持更丰富的监控数据 所有组件统一 spce 属性获取逻辑 修复配置日志输出到控制台时不生效的问题  详细参考：https://github.com/sofastack/sofa-common-tools/releases/tag/v1.3.0\n祝大家圣诞节快乐！\n","date":1608879600,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20201225/","fuzzywordcount":1000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"59bc2ae2a6b06f7ca356aeb61a6c78fd","permalink":"/blog/sofa-weekly-20201225/","publishdate":"2020-12-25T15:00:00+08:00","readingtime":2,"relpermalink":"/blog/sofa-weekly-20201225/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级云","tags":["SOFA Weekly"],"title":"SOFA Weekly | SOFA-Common-Tools 发布新版本， QA 整理","type":"blog","url":"/blog/sofa-weekly-20201225/","wordcount":963},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级云原生架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\nSOFAStack 官网: https://www.sofastack.tech\nSOFAStack: https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题 通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@缪文 提问:\n SOFA-Boot 框架，模块隔离时，子 module 中引入 mybatis 框架，@MapperScan 注解是在RootContext 中扫描，还是在子 module 中扫描？\n A: 非 auto 的 configuration 都是在对应模块进行解析的。\nSOFABoot：https://github.com/sofastack/sofa-boot\n2、@李扬 提问：\n 分支事务被回滚是同步还是异步的,如果是异步的,能加监听方法吗?\n A：可以实现 transactionhook 这个类，然后在 tm 发起者里加入到 Transaction HookManager#registerHook 。这样在二阶段决议后，可以做一些小动作，比如二阶段提交的时候，再执行 redis ，mongo 的数据插入。\n3、@吴国柱 提问：\n 本地事务与全局事务一起开启会有问题吗？\n A：全局事务要在本地事务的外层,就是包裹本地事务，不能由本地事务包裹全局事务。本地事务出异常都不会进行注册，也就代表本地事务如果出问题本地事务自行会回滚(基础知识)，如果本地事务提交了，其它服务的本地事务出现异常，或者业务代码出现异常，将有 Seata来负责把已提交的事务回滚。\nSeata：https://github.com/seata/seata\nSOFAChannel 部分合辑  人人都可以“机密计算”：Occlum 使用入门和技术揭秘 | 开源 蚂蚁集团网络通信框架 SOFABolt 功能介绍及协议框架解析 | 开源 不得不说的云原生隔离性 | SOFAChannel#16 直播回顾 蚂蚁集团分布式链路组件 SOFATracer 埋点机制解析 | SOFAChannel#15 直播整理 云原生网络代理 MOSN 扩展机制解析 | SOFAChannel#14 直播整理 云原生网络代理 MOSN 多协议机制解析 | SOFAChannel#13 直播整理 蚂蚁集团分布式事务实践解析 | SOFAChannel#12 直播整理 从一个例子开始体验轻量级类隔离容器 SOFAArk | SOFAChannel#11 直播整理  相关推荐阅读  剖析 | 详谈 SOFABoot 模块化原理 蚂蚁集团研发框架日志隔离解析 | SOFABoot 框架剖析 蚂蚁集团研发框架总览 | SOFABoot 框架剖析  ","date":1608274800,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20201218/","fuzzywordcount":1000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"712d560758c60f16cc7d2651bb781e65","permalink":"/blog/sofa-weekly-20201218/","publishdate":"2020-12-18T15:00:00+08:00","readingtime":2,"relpermalink":"/blog/sofa-weekly-20201218/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级云","tags":["SOFA Weekly"],"title":"SOFA Weekly | 线上直播合辑整理，QA 整理","type":"blog","url":"/blog/sofa-weekly-20201218/","wordcount":949},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 【12/07 - 12/11】每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级云原生架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\nSOFAStack 官网: https://www.sofastack.tech\nSOFAStack: https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题 通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@bruce 提问：\n SOFAJRaft 可以实现在三个节点中选出一个 leader , 其他逻辑由自己实现吗?\n A：可以，可以不用状态机，也不用加载和持久化快照, 只需要选个 leader。\n 各个节点如何知道自己是主还是从?\n A：示例 2、@李明 提问:\n 全局事务执行过程中，有其他线程操作数据库，这时全局事务执行失败，在回滚的时校验数据发现数据被修改过，导致回滚失败，这种情况怎么避免?\n A：其他线程也加上 global transactional 注解。分布式事务下，没有单个分支是独立的个体存在，需要拿到全局事务中，让其他事务知晓他的存在，从而避免在分布式调用链路中，恰好遇到同一个数据进行修改时，发生的脏写脏读 globallock 是在更新前去 tc 看下这个时候这个数据有没有被其他事务锁定，没有的话就说明这个数据没有被其他事务使用，是提交的数据，所以这叫读分布式事务下的已提交。 但是他并没有去注册分支，也就是他没有去占有这个全局锁，来达到分布式事务下的排他性。他在得到 tc 响应的时候，去执行 update 是有时间的，此时有个分布式事务下的分支 update 后，拿到了全局锁，然后他的链路二阶段是回滚 ，但是数据就被你这个认为没有全局锁的本地线程给改了，这就导致被干扰无法回滚。 所以 globallock 需要配合 sql 语句，在 update 前，先做 for update 这个数据，拿到这个数据的本地锁，拿到本地锁之后，再去 tc 判断有没有全局锁，如果 tc 没有锁，因为本地已经拿到本地锁了，具有本地事务的排他性，其他分支事务拿不到该数据的本地锁，是无法去注册分支去拿到全局锁，也就是禁止了其他分支事务的干扰，所以不会脏写。 目前 tcc 下一般就是 globallock+select for update 来防止被其他 at 事务改动后，进行了脏写。\n3、@ 尚攀 提问:\n Raft 是为了解决目前的什么问题？\n A: 依赖外部存储。AT 有 before 镜像、after 镜像，after 镜像是在 undo_log 表里存储，那么 before 在哪里存着了？未来的 Raft 模式，集群支持动态扩缩容，事务信息存储在内存中（测试下来比 redis 快），现在的全局事务信息，分支事务信息，全局锁都是持久化到 db，或者 redis 去的。如果这个时候持久化用的 db 宕机了，Seata-Server会不可用，而集成了 Raft ，leader 宕机后自动选举新 leader，继续运转。所以，利用 raft 一致性算法，可以让多个Seata集群内存中的数据保持一致。\n相关推荐阅读   基于 RAFT 的生产级高性能 Java 实现 - SOFAJRaft 系列内容合辑\n  蚂蚁集团生产级 Raft 算法库 SOFAJRaft 存储模块剖析 | SOFAJRaft 实现原理\n  蚂蚁集团 SOFAJRaft 优先级选举剖析 | 特性解析\n  剖析 | 蚂蚁集团生产级 Raft 算法 SOFAJRaft 合辑\n  Seata 项目进展 本周发布详情如下： 发布 Seata 1.4.0 版本，主要变更如下：\n 支持 yml 配置文件 支持 Oracle nclob 类型 支持客户端最少的活动负载均衡 支持客户端一致性哈希的负载均衡 支持 Spring Boot 使用自定义配置中心和注册中心 支持配置默认全局事务超时时间 多处 BUG 修复和功能优化  详细参考：https://github.com/seata/seata/releases/tag/v1.4.0\n","date":1607670000,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20201211/","fuzzywordcount":1500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"dc10639aea7c443d918ac8f8355ed64c","permalink":"/blog/sofa-weekly-20201211/","publishdate":"2020-12-11T15:00:00+08:00","readingtime":3,"relpermalink":"/blog/sofa-weekly-20201211/","summary":"SOFA WEEKLY | 【12/07 - 12/11】每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是","tags":["SOFA Weekly"],"title":"SOFA Weekly | Seata 发布新版本， QA 整理","type":"blog","url":"/blog/sofa-weekly-20201211/","wordcount":1417},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动\n  SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级云原生架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\nSOFAStack 官网: https://www.sofastack.tech\nSOFAStack: https://github.com/sofastack\n  每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题 通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@刘江涛 提问：\n 已知在同一个分布式事务中，各个 RM 的模式都应该与对应 TM 模式相同。那同一个微服务可以多种模式并存吗？比如 AT , XA , Saga 并存，然后 A 业务使用 AT 模式，B 业务使用其他模式之类的。\n A：不可以，隔离性无法得到保证。如果要一起用，就要保证一条调用链路中所有数据的隔离性，也就是跟 AT 一样都得去竞争锁，而且 Saga，TCC 之类的对 SQL 没要求，可能在跟 AT 一起使用的时候就有要求了，得不偿失。\n 如果公司要引入多种模式的话，微服务之间的关系是这样的吗？\n A ：是的，当然 AT 集群是可以调 Saga 集群的，但是他们不能属于同一个全局事务,也就是 AT 那个事务提交了，Saga 的如果回滚了，是 Saga 集群的问题，等于有 2 个全局事务的诞生。 Seata：https://github.com/seata/seata\n相关推荐阅读   记一次在 MOSN 对 Dubbo、Dubbo-go-hessian2 的性能优化\n  云原生网络代理 MOSN 透明劫持技术解读 | 开源\n  基于 MOSN 和 Istio Service Mesh 的服务治理实践\n  云原生网络代理 MOSN 的进化之路\n  MOSN 项目进展 本周发布详情如下： 1、MOSN 发布了 v0.19.0 版本：\n 重构了 StreamFilter 框架，提供更强的可复用的能力 支持 MaxProcs 可基于 CPU 使用限制自动识别的能力 支持指定 Istio cluster 的网络 针对高并发场景的内存使用进行了优化 多处BUG修复  详细参考：https://github.com/mosn/mosn/releases/tag/v0.19.0\n","date":1607065200,"description":"SOFA WEEKLY | 【11/30 - 12/04】每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20201204/","fuzzywordcount":900,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"4123f0805fdf3799cbafcc143f8d6bac","permalink":"/blog/sofa-weekly-20201204/","publishdate":"2020-12-04T15:00:00+08:00","readingtime":2,"relpermalink":"/blog/sofa-weekly-20201204/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级云","tags":["SOFA Weekly"],"title":"SOFA Weekly | MOSN 发布新版本、 Seata QA 整理","type":"blog","url":"/blog/sofa-weekly-20201204/","wordcount":837},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n  SOFAStack 官网：https://www.sofastack.tech\n  SOFAStack：https://github.com/sofastack\n  社区 Big News  SOFAStack 获得 2020 年度 OSC 中国开源项目评选**「优秀 Gitee 组织」**，感谢所有开发者们的支持和喜爱，SOFA 团队会继续努力，提供更好的开源产品和服务，也期待大家的持续共建。 2020 年度 OSC 中国开源项目评选结果公布\n 每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题 通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@张松 提问：\n SOFARPC 支持提供者注册的时候配置一个标识，然后消费者根据这个标识来获取到对应的服务提供者吗？类似于对服务提供者做一个分组。\n A：你是指 SOFARPC 的 unique-id 吧，支持的。\n 不是，类似于分组的配置，因为我这边现在需要多环境，要来区分同一个注册中心下的同一个接口的不同分组。\n A：SOFARPC 就是用 uniqueId 来区分同一个接口，不同实现的。SOFARPC 没有 group 的概念，只有一个 uniqueId，需要服务方和调用方配置一样，强隔离的。 SOFARPC：https://github.com/sofastack/sofa-rpc\n2、@徐泽唯 提问：\n 自动降级以后如果调用的服务抛错了 数据是不是就不对了？\n A：自动降级只是发起者那边发现 SeataServer 不可用后，不去走 begin 。你业务数据就完全没全局事务的允许运行，是会出现数据不一致。比如seata-server宕机了，后续的服务因为 Seata-Server 宕机，不走分布式事务，此时全局事务有部分数据是需要回滚的，但是由于Seata-Server宕机了，导致没法回滚，这个时候不经过全局事务的事务执行就会导致数据不一致。所以说，tc 最好集群搭建，以免宕机后，降级代表了你允许 at 模式下数据不一致。 Seata：https://github.com/seata/seata\n相关推荐阅读  蚂蚁金服微服务实践 | 开源中国年终盛典分享实录 火了 2 年的服务网格究竟给微服务带来了什么？ 走出微服务误区：避免从单体到分布式单体  SOFA 项目进展 本周发布详情如下： 1、SOFAJRaft 发布了 1.3.5 版本：\n 增加对IPv6的支持＃526 ＃527 升级\u0026amp;rsquo;rocksdb\u0026amp;rsquo;到5.18.4以支持AArch64 优化：心跳响应不经过管道直接发送，避免管道影响心跳响应的及时性   详细参考：https://github.com/sofastack/sofa-jraft/releases/tag/1.3.5 2、SOFABoot 发布 3.4.6 版本:\n 支持手动 readiness 回调（健康检查二阶段） 扩展点失败反馈健康检查，默认为否 提供上下文隔离场景下获取所有 Spring 上下文的标准方法 Bean 加载时间和层级树形分层显示  详细参考：https://github.com/sofastack/sofa-boot/releases/tag/v3.4.6\n","date":1606460400,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20201127/","fuzzywordcount":1400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"f379c4483cff2807f5cfe8c6bbab5d8c","permalink":"/blog/sofa-weekly-20201127/","publishdate":"2020-11-27T15:00:00+08:00","readingtime":3,"relpermalink":"/blog/sofa-weekly-20201127/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | 每周精选【11/23 - 11/27】SOFA Weekly | SOFAJRaft 、SOFABoot发布新版本，SOFAStack 获优秀 Gitee 组织奖","type":"blog","url":"/blog/sofa-weekly-20201127/","wordcount":1346},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n  SOFAStack 官网：https://www.sofastack.tech\n  SOFAStack：https://github.com/sofastack\n  每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@小刘 提问：\n 刚开始用 Seata ，方法上用了 @GlobalTrasactional  + mybatis 插入一条数据的时候返回的自增id不正确,取消@GlobalTrasactional用普通的事务@Trasactiona  插入数据的时候返回的自增 id 正常了。\n A: 这个基础是有问题的。全局锁的作用是锁定并发修改时的数据的，不是针对接口。接口并发肯定是多线程走的，不可能阻塞等待排队。 Seata：https://github.com/seata/seata\n2、@初识 提问：\n 防悬挂是怎么理解的？能简单说说吗？\n A: 保证一致性，幂等用的。比如a-\u0026amp;gt;b，因为特殊原因，比如全局事务超时，b注册上了分支事务，本地事务的 commit 还没执行的时候，全局事务回滚下发到了，如果这个时候本地事务 commit 了，那么数据就不一致了，所以全局事务回滚下发到了，会插入一个 undolog ，让本地事务 commit 的时候因为 undolog 唯一索引冲突使本地事务提交失败，触发回滚，保证了当全局事务状态是回滚时，分支事务都是回滚的。 当然，如果是 commit 了，再收到下发回滚，因为 commit 了已经有 undolog了，那么会通过 undolog 回滚，这个针对的是没有 undolog 时的情况。\n**3、@StevenCheney **提问：\n Nmosn 的版本 和 Istio 有对应关系吗？\n A：目前的 Master 支持 1.5._，但是上次看1.5.的时候有一些注入的问题，你可以看一下 feature-istio_adapter 这个分支，最近应该会合并一些pr进来，到时候可以直接适配1.7.，理论上1.6._也是可以支持的，需要测试一下。\n Docker image 会同步更新吗？\n A：主要是看你的需求，如果你是只要 MOSN ，不要 Envoy，就直接使用https://github.com/istio/istio/issues/23753 这个来打包，如果你都需要的话或者说不介意多一个 Envoy，就直接使用 proxyv2 打一个就好了。 MOSN：https://github.com/mosn/mosn\n本周推荐阅读  蚂蚁智能运维：单指标异常检测算法初探 蚂蚁宣布开源 KubeTEE：让机密计算支持大规模 K8s 集群 企业数字化转型指南，《SOFAStack 解决方案白皮书》正式发布  SOFA 项目进展** 本周发布详情如下： 1、SOFA-Common-Tools 发布1.2.1版本：\n 重构了本地控制台输出日志逻辑； 移除了 log-sofa-boot-starter 相关代码；  详细参考： https://github.com/sofastack/sofa-common-tools/releases/tag/v1.2.1\n","date":1605855600,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20201120/","fuzzywordcount":1300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"a81d6649eb11649a90e54eef8a5a57e2","permalink":"/blog/sofa-weekly-20201120/","publishdate":"2020-11-20T15:00:00+08:00","readingtime":3,"relpermalink":"/blog/sofa-weekly-20201120/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | 每周精选【11/16 - 11/20】SOFA-Common-Tools 项目发布新版本、Seata、MOSN 相关 QA 整理","type":"blog","url":"/blog/sofa-weekly-20201120/","wordcount":1228},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n SOFAStack 官网：https://www.sofastack.tech SOFAStack：https://github.com/sofastack  每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@杨文鹏 提问：\n 感觉 SOFAArk 在静态合并部署情况下,和 SOFABoot 的类隔离起到的作用是一样的？不知道我理解对不对。\n A：SOFABoot 没类隔离，它的类隔离就是继续 SOFAArk。\n 比如新建一个 SOFABoot 应用，需要再手动集成 SOFAArk 吗？\n A：需要的。\n SOFABoot：https://github.com/sofastack/sofa-boot SOFAArk：https://github.com/sofastack/sofa-ark  2、@倪绍东 提问：\n 如果是提交阶段有数据库失败了，其他成功的怎么办呢，没办法了吧？\n A：一阶段提交,二阶段不可能提交的情况下还失败，XA 本地事务一阶段持久化在数据库层面不可能丢失，本地事务undolog跟redolog了解一下。对 Seata-server 来说保存了事务状态，如果二阶段有节点执行失败，就重试，直到成功。也就是你节点二阶段执行失败，自己了解下为什么你数据库出问题了，而不是分布式事务有什么问题。\n 会不会出现重试过程中，其他事务修改了现有数据，而最终又被重试成功的情况?\n  A：二阶段提交代表了什么？代表了整个调用链是成功的，一个成功的分布式事务，一阶段已经持久化了，你再去改，这个数据又不是脏的有什么问题？XA 来说，本地事务的本地锁先了解一下，一阶段不提了，锁被本地持有，如何修改？本地排它锁都没释放，何来脏写。\n3、@李艺渊 提问：\n Seata TCC 模式下，订单微服务和库存微服务。订单微服务try阶段添加订单信息，现阶段可以支持在库存微服务try阶段获取订单信息吗？或者说能把创建好的订单信息存储到 Seata-server ，然后在其他微服务可以获取到吗？\n  A：我理解 Server只负责全局事务的流转，try 出错就 cancel ，成功就 commit。Try 里面对两个库操作，正常是可以拿到数据吧。  这2个微服务是分开部署的，数据库也是分开的。像订单微服务的 try 阶段，把订单信息存储到 order 数据库了。那库存微服务是不会去访问 order 数据库的。现在就是看库存微服务如何获取到新增的订单信息，看有没有什么 好的方式。\n  Seata：https://github.com/seata/seata  Service Mesh 相关推荐阅读  Service Mesh 中的可观察性实践 陌陌的 Service Mesh 探索与实践 - 直播回顾 Service Mesh Webinar#1：多点生活在 Service Mesh 上的实践 Service Mesh 高可用在企业级生产中的实践 | 线上直播回顾 Apache SkyWalking 在 Service Mesh 中的可观察性应用  ","date":1605254400,"description":"【11/9-11/13】| 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20201113/","fuzzywordcount":1300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"59cb50e2977d5e0b3ad675ca234c2b0f","permalink":"/blog/sofa-weekly-20201113/","publishdate":"2020-11-13T16:00:00+08:00","readingtime":3,"relpermalink":"/blog/sofa-weekly-20201113/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | Service Mesh 相关阅读合集、SOFABoot 以及 Seata QA 整理","type":"blog","url":"/blog/sofa-weekly-20201113/","wordcount":1267},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n SOFAStack 官网：https://www.sofastack.tech SOFAStack：https://github.com/sofastack  每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、《Service Mesh Webinar#4:阿里云 CDN 微服务架构演进之路》直播回顾以及 QA 整理 视频回顾地址：https://www.bilibili.com/video/BV13D4y1R7do/\n@道酉 提问：\n 请问阿里云 MOSN 两个容器的热更新怎么实现的，就是怎么在pod内添加一个容器再去掉一个\n A：我们其实也没用跨容器热升级的方式，两个 Pod 挂载相同目录的方式是支持的。\n@陈鹏 提问：\n 请问一下同一个容器的热升级是怎么做的呢？\n A：我们是通过 RPM 升级的方式，容器内 systemd 管理的进程。\n@梁昌泰 提问：\n 重启不叫热升级吧？\n A：没有重启哈，直接起来一个新的进程。\n2、@谢子华 提问：\n Seata Saga 中，TC 的作用是什么？在 Saga 执行过程中 TM、TC、RM 和状态机的交互过程是怎样的？\n A：1）发起重试。2）根据分支响应状态，判断是否切换重试方向。目前，Sage 的分支默认情况下不会注册到 TC 了的，因为 Saga 本地库里有各 RM 的数据。 只有全局事务注册和全局事务提交或回滚时，与 TC 交互。\n 现在二阶段重试失败不断发起重试在 1.4.0 版本解决了吗？判断是否切换重试方向是只有可能 TC 会决定向后或者向前重试？\n A：是由 RM 端返回的状态为依据，由 TC 端切换重试方向，决定权在 RM 端。\n 我的理解是 RM 告诉 TC 回滚失败，然后有可回滚和不可回滚两个状态，TC 根据这个决定是否继续重试？那如何在 RM 进行配置？\n A：我刚才的截图是 TC 端发起全局提交时，RM 返回“回滚”失败重试回滚，这种情况，默认情况下不存在了，因为 Saga 不会注册分支到 TC。 实际上，应该是在 SagaCore 的全局回滚时，RM 端如果返回“提交”失败，重试提交状态时，会切换到向前重试。\n看了下源码，只有全局事务是因超时而进入全局回滚时，才会切换重试方向。\n 切换重试方向是指本来流程图配置是向后重试，然后超时了，TC 会切换为向前重试？\n A：意思是全局事务正在运行时，因超时60秒，TC 端自动将全局事务标记为超时回滚状态，然后会异步发起全局回滚请求。 这种情况下，碰到回滚失败时，会切换为向前重试。\n 哦哦，原来是这个样子。默认情况下，本地只会把全局的 RM，状态发送给 TC?\n A：默认情况下，RM 的数据只会存在本地。TC 端可以说是不管 Saga 分支的情况的。TC 只管接收 1）TM 的开始全局事务、完成全局事务；2）超时进入全局回滚；3）根据状态判断是否继续重试，还是切换重试方向。\n 1)是 TM 监测到所有 RM 都已完成然后告诉 TC 全局事务结束？3)TC 根据状态判断是否重试，现在 RM 不把状态发送给 TC，那这个状态是从哪里来?\n A：1）是的。 3）这个请求是从 TC 向 RM 端发起的。RM 只是返回一个状态而已。\n 我在实践中的问题就是在二阶段执行出现异常会不断地重试，如之前跟你聊过的补偿触发后补偿服务执行异常会不断重试。上述 TC 发起的全局回滚如果回滚过程中出现异常是不是也会不断地重试？不断地重试感觉比较占用资源？是否有应对策略让他能够只是有限次重试？\n A：重试策略的 PR 已经有了，但是因为 PR 依赖关系较多，暂时还没有合并，后续我会精简 PR 代码，单单引入重试策略的功能及其配置的功能。到时候会能够配置重试策略。目前，基本上是1秒钟就会发起一次重试。\n 现在没有重试策略的情况下，是否有其他的应对方法？\n A：将重试时间间隔配置稍微大一些，默认1秒。\n本周推荐阅读  云原生网络代理 MOSN 的进化之路 基于 MOSN 和 Istio Service Mesh 的服务治理实践 记一次在 MOSN 对 Dubbo、Dubbo-go-hessian2 的性能优化 云原生网络代理 MOSN 透明劫持技术解读 | 开源 云原生网络代理 MOSN 扩展机制解析 | SOFAChannel#14 直播整理 云原生网络代理 MOSN 多协议机制解析 | SOFAChannel#13 直播整理 云原生网络代理 MOSN 平滑升级原理解析 | 开源  SOFA 项目进展 本周发布详情如下：\n1、发布 MOSN v0.18.0 版本，主要变更如下：\n 新增 MOSN 配置文件扩展机制； 新增 MOSN 配置工具，提升用户配置体验； 优化 HTTP 协议处理对内存的占用； TLS 模块优化，增加了客户端降级配置逻辑、降低了 TLS 内存占用； 支持大于 4M 的 XDS 消息； 部分 API 接口进行了重构；  详细发布报告： https://github.com/mosn/mosn/releases/tag/v0.18.0\n2、发布 Seata v1.4.0 版本，主要变更如下：\n 支持 yml 配置文件； 支持 Oracle nclob 类型； 支持客户端最少的活动负载均衡； 支持客户端一致性哈希的负载均衡； 支持 Spring Boot 使用自定义配置中心和注册中心； 支持 Apollo 密钥 key 配置； 修复禁止执行更新主键值的 SQL； 重构 Redis 存储模式下 session 的存储结构；  详细发布报告： https://github.com/seata/seata/releases/tag/v1.4.0\n","date":1604646000,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20201106/","fuzzywordcount":2100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"dc199415476133ea6f6ee6adf2bf91fa","permalink":"/blog/sofa-weekly-20201106/","publishdate":"2020-11-06T15:00:00+08:00","readingtime":5,"relpermalink":"/blog/sofa-weekly-20201106/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | MOSN、Seata 发布新版本、MOSN 相关阅读整理","type":"blog","url":"/blog/sofa-weekly-20201106/","wordcount":2031},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n SOFAStack 官网：https://www.sofastack.tech SOFAStack：https://github.com/sofastack  每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@王钢 提问：\n https://github.com/sofastack-guides/kc-sofastack-dynamic-demo/issues/11 基于 SOFAArk 和 SOFADashboard 实现动态模块管控时遇到宿主应用能够下载biz安装成功，但是不能在zookeeper下生成对应的/apps/biz节点，导致管理端不能更新状态，不知道应该怎么排查解决。使用的 ZK 版本是 3.4.10。\n A：可以 debug 下写 /apps/biz 的逻辑，这里是不是宿主客户端没有连接上来，具体可以看一下：https://github.com/sofastack/sofa-dashboard-client SOFADashboard 之前只做了一个简单的模型，后面陆续其他同学也在上面做了一些开发，如果有兴趣可以一起参与共建哈。\nSOFADashboard：https://github.com/sofastack/sofa-dashboard\n2、@钟文豪 提问：\n SOFAJRaft 是如何计算 commitIndex 的呢？\n A：可以看看这个文档：https://www.sofastack.tech/projects/sofa-jraft/raft-introduction/\nSOFAJRaft：https://github.com/sofastack/sofa-jraft\n3、@张潇 提问：\n 各位好 问个概念的问题。我三个服务 A,B,C，在 A 服务方法加了 @GlobalTransactional，调用 B ，C。启动三个服务的时候看 Seata 日志 ,A,B,C 服务每一个都是 RM 也是 TM。是这样的吗？不是 A 服务才是 TM 吗？\n A：在你这个事务当中，A 是对应着 TM，B、C 对应着 RM。 但是在注册的时候，他们都同时向 seata-server 注册了 TM 和 RM，意味着他们可以作为 TM，也可以作为 RM。 比如你有一个全局事务从 B 发起的，那这个时候他就是 TM。如果你认为你的业务场景中 B、C 这两个服务不会作为 TM 存在，你也可以把 TM 相关的配置删了，然后他就不会去注册 TM 了。可以从定义上去看 TM 和 RM，会发起全局事务的就是 TM，对应着数据库资源的就是 RM。一个服务可能只是 TM，也可能只是 RM，也可能都是。\nSeata：https://github.com/seata/seata\n本周推荐阅读  网商银行是如何建设金融级云原生分布式架构的？ 开源项目是如何让这个世界更安全的？  SOFA 项目进展 本周发布详情如下：\n开源 MOSN Golang 系统诊断工具 holmes beta 版：\n 支持基于 goroutine 波动的自动 goroutine profile dump； 支持基于 RSS 统计的 heap profile dump； 支持基于 CPU 使用率的自动 cpu profile dump；  详细参考： https://github.com/mosn/holmes/blob/master/readme.md\nSOFA 直播预告 传统 CDN 节点内组件间通信通过 IP 分组渲染的方式实现，当更多参差不齐的异构节点资源出现的时候则不再能很好地满足我们的需求。\n本期主要分享阿里云将传统的 CDN 节点改造成微服务架构的落地过程，主要使用了蚂蚁 SOFAStack–Service Mesh 的数据面 MOSN，主要分为两个阶段，第一个阶段是由传统 CDN 节点到数据面先行的微服务架构，通过数据面 MOSN+coredns 实现服务发现；第二个阶段是由数据面先行到数据面+控制面的标准 Service Mesh 架构。根据我们的落地和改造经验，介绍基于 MOSN+coredns/Istio 的 Service Mesh 架构改造的实际案例。上期分享了《Service Mesh 在 CDN 边缘场景的落地实践》，大家也可以温故一下～ 视频回顾地址：https://tech.antfin.com/community/live/1289\n分享主题：《Service Mesh Webinar#4:阿里云 CDN 节点微服务架构演进之路》\n**分享嘉宾：**邓茜（花名沐沂），阿里云高级开发工程师\n听众收获：\n 了解边缘场景下，使用 Service Mesh 架构的好处； 了解如何利用 MOSN + coredns 实现简单的服务发现； 了解如何利用 MOSN+ Istio 配置 http/tcp/udp 的转发规则以及如何动态配置持久化；  **线上直播时间：**2020 年 11 月 4 日（周三）20:00-21:00\n欢迎报名：点击“这里”，即可报名。\n","date":1604041200,"description":"【10/26-10/30】 | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20201030/","fuzzywordcount":1800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"a67a4e194b658ba2f0427011c0b56dba","permalink":"/blog/sofa-weekly-20201030/","publishdate":"2020-10-30T15:00:00+08:00","readingtime":4,"relpermalink":"/blog/sofa-weekly-20201030/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | MOSN 项目更新及直播预告","type":"blog","url":"/blog/sofa-weekly-20201030/","wordcount":1777},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n SOFAStack 官网：https://www.sofastack.tech SOFAStack：https://github.com/sofastack  每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@廖虹剑 提问：\n 我们想扩展一下 Dubbo 的 thrift 协议，遇到一个问题，consumer -\u0026amp;gt; mosn-client -\u0026amp;gt; provider，现在请求可以正常 decode -\u0026amp;gt; encode 到达 provider，并且 provider 可以正常调用，在返回的时候，数据包已经发回 MOSN，并且成功 decode，但是会阻塞在 read 处直到超时，没办法 write 回 consumer。 请问有什么排查思路吗？MOSN 里面这个网络模型看得有点晕。\n A：先 read 再 decode 的呀，你说的阻塞在 read 是阻塞在哪？\n read 方法已经正常调用，并且 decode了，但是没有触发写事件，consumer端 会一直在等待。 然后又会到这里卡住直到超时  A：数据 read 了没有新数据，这里就是会超时啊。你要看 decode 之后做了什么。\n 我打断点看到的 remote ip 和端口是 provider 端的。或者我换一个问法，MOSN 在获取到 upstream 的响应数据并且 decode 之后，是如何怎么触发 encodeResponse 并写回 writebuffer 的。我调试发现它 read 完数据之后无法进入到 endStream 方法。 也没看到什么异常日志。 我对 go 还不是特别了解，如果有什么问题还请多指正，辛苦了。\n A：你从 Decode 的逻辑往下跟一下就可以了，Dubbo 目前是 xprotocol 协议的实现 Decode 以后会经过 proxy 的流程最后再 encode，然后 write。read 是异步的，这个有点简单的介绍： https://mosn.io/blog/code/mosn-eventloop/\n 找到问题了，是 encode 的时候 replace requestId 的时候出了点问题，导致找不到对应的 stream，感谢~\n MOSN：https://github.com/mosn/mosn\n2、@Bernie G 提问：\n 我这边项目是 Spring Boot，没有用 Dubbo， 这种情况可以用 Seata 做 Saga 事务吗？\n A：你的服务调用是通过 feign，resttemplate？Saga 跟 RPC 框架不是强绑定的，你的远程服务可用在被调用方作为类似 reference bean 的形式调用就可以。\n 我们这边主要用的是 RestfulApi 还有 gRPC 来作为微服务之间的调用， Seata 能支持吗？ 如果能给个代码 Sample 最好。\n A：Test 中有 gRPC 的实例，看下是否满足需求。 https://github.com/seata/seata/tree/develop/integration/grpc\nSeata：https://github.com/seata/seata\n本周推荐阅读  开源项目是如何让这个世界更安全的？ Hey，邀请你加入我们一起玩耍  SOFA 项目进展 本周发布详情如下：\n1、发布 SOFABoot v3.4.5 版本，主要变更如下：\n 支持 triple 线程监控； 升级 sofa-ark 版本至 1.1.5； 升级 junit 版本至 4.13.1； 修复 jvm filter npe 问题； 修复http server 线程池配置问题；  详细发布报告： https://github.com/sofastack/sofa-boot/releases/tag/v3.4.5\n2、发布 SOFAArk v1.1.5 版本，主要变更如下：\n 修复 web 模块并发安装问题； 修复支持 web 环境测试 webContext 默认为 null 导致的 NPE 问题；  详细发布报告： https://github.com/sofastack/sofa-ark/releases/tag/v1.1.5\nSOFA 直播预告 在边缘计算和 5G 商业化风起云涌的当下，阿里云 CDN 开展了节点全面云原生化的改造，在此背景下，我们尝试利用 CDN 资源池为底座，在大规模复杂边缘场景下建设 Service Mesh 的基础能力，打造边缘 PaaS 平台。落地实践过程中我们使用了蚂蚁 SOFAStack–Service Mesh 体系中的 MOSN 作为数据面，Istio 作为控制面。本次分享将从 Service Mesh 技术以及 CDN 边缘场景介绍入手，重点分析 Istio 和 MOSN 结合的落地实战过程。\n分享主题：《Service Mesh Webinar#3：Service Mesh 在 CDN 边缘场景的落地实践》\n**分享嘉宾：**肖源（花名萧源），阿里云技术专家\n听众收获：\n 了解 Service Mesh 技术； 了解 Service Mesh 在阿里云 CDN 边缘场景的落地实践； 给到想要落地 Service Mesh 的同学一些案例与建议；  **线上直播时间：**2020 年 10 月 28 日（周三）20:00-21:00\n欢迎报名：点击“这里”，即可报名。\n","date":1603436400,"description":"【10/19-10/23】 | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20201023/","fuzzywordcount":1700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"cf0c4a06a60155202353fe19c3185072","permalink":"/blog/sofa-weekly-20201023/","publishdate":"2020-10-23T15:00:00+08:00","readingtime":4,"relpermalink":"/blog/sofa-weekly-20201023/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | SOFAArk、SOFABoot 发版、10月28日线上直播预告","type":"blog","url":"/blog/sofa-weekly-20201023/","wordcount":1648},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n SOFAStack 官网：https://www.sofastack.tech SOFAStack：https://github.com/sofastack  每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@谢子华 提问：\n  SOFARPC 客户端A调用服务端 B，B在方法中想异步调用C（不同步等结果），在callback里面才响应结果返回给A。这种有 Demo 吗？\n  A：链路异步吗？ 可直接看测试用例 https://github.com/sofastack/sofa-rpc/blob/master/test/test-integration/src/test/java/com/alipay/sofa/rpc/test/async/AsyncChainTest.java\n 谢谢，看了下用例。我理解是 服务端接口执行时在 RpcInvokeContext 设置了 SendableResponseCallback 类型的 callback。SOFA 就会忽略接口的返回值。然后在 callback 中主动调用 sendAppResponse 返回结果。对吗？\n A：对的。\nSOFARPC：https://github.com/sofastack/sofa-rpc\n2、@明丽 提问：\n 有没有存在经常锁表的童鞋？lock_table 里存在锁表数据和 undo_log 里面有历史几天的数据没有被删除掉？\n A：locktable 如果没删除，说明可能遇到脏数据导致分支事务无法回滚，此时就会有锁无法释放，这时候要根据 locktable 的信息去找对应的分支事务是那个应用，去看下日志提示，如果是脏数据会说镜像校验不通过\n 这里的脏数据具体是指什么样的数据？\n A：全局事务是回滚时，需要回滚的数据被改动。\n 通常报错的就是并发情况下扣减库存，操作同一条 update 库存数量语句。\n A：比如 a=1，update 后时 a=2。此时其他的分支事务异常，导致全局事务决议时回滚，这个时候 a 被改为了3，这个 a 的数据脏了，隔离性没被保证。此时回滚的时候会校验 a 还是不是当前事务修改的值，如果不是，说明这个数据脏了，已经不正确了，不能盲目的直接回滚成1，说明隔离性没保证，有数据被 Seata 全局事务外的地方修改了，如果想保证隔离性，就需要保证任何一个写场景，都被全局事务注解覆盖。\n 我们这边的更新场景都有加全局事务的注解，好像没有起作用，还有别的不起作用的情况吗？\n A：那就检查是否都覆盖了，比如定时任务，或者会不会有认为的去数据库层面直接修改。\n 另外一个问题，我在订单服务下单的时候发起扣库存请求，这个时候只需要在订单服务的方法加上全局注解就可以了，对吗？不需要在库存服务被调用的方法加注解？\n A：只要保证 xid 传递跟数据源代理即可，但是如果有订单服务之外，没有被全局事务注解覆盖的地方操作了库存，一样会脏。这个文章我借鉴了清铭、屹远、煊意的博客，总结了一下 XA 跟 AT 的关系，也谈到了隔离性方面的问题，希望你看过后可以理解 AT 的隔离性是如何保证的。 https://blog.csdn.net/qq_35721287/article/details/108982806\nSeata：https://github.com/seata/seata\n剖析 SOFAJRaft 实现原理合集  SOFAJRaft 实现原理 - 生产级 Raft 算法库存储模块剖析原理 SOFAJRaft 实现原理 - SOFAJRaft-RheaKV 是如何使用 Raft 的 SOFAJRaft 线性一致读实现剖析 | SOFAJRaft 实现原理 SOFAJRaft 选举机制剖析 | SOFAJRaft 实现原理 SOFAJRaft-RheaKV MULTI-RAFT-GROUP 实现分析 | SOFAJRaft 实现原理 SOFAJRaft 日志复制 - pipeline 实现剖析 | SOFAJRaft 实现原理 SOFAJRaft-RheaKV 分布式锁实现剖析 | SOFAJRaft 实现原理 SOFAJRaft Snapshot 原理剖析 | SOFAJRaft 实现原理  SOFA 项目进展 本周发布详情如下：\n发布 SOFAJRaft v1.3.5.Alpha1 版本，主要变更如下：\n 升级 \u0026amp;lsquo;rocksdb\u0026amp;rsquo; 到 5.18.4 以支持 AArch64； 优化：心跳响应不经过 pipeline 直接发送，避免 pipeline 影响心跳响应的及时性； 修复使用 grpc 时，在一定情况下无法自动重连的问题； 修复使用 grpc 时，在 error response 处理的错误； 致谢（排名不分先后）：@cmonkey @odidev  详细发布报告：https://github.com/sofastack/sofa-jraft/releases/tag/1.3.5.Alpha1\nSOFA 团队欢迎你加入 蚂蚁集团招聘技术运营专家啦～欢迎加入我们一起为可信技术带来更多的想象。\n岗位名称：可信原生技术运营专家\n岗位描述：\n 挖掘技术内容和业务价值，并形成体系，构建传播矩阵，形成并提高产品和技术的行业美誉度； 完整策划并执行线上、线下的技术活动、大赛，构建围绕可信原生技术的开发者活跃群体，并有更多创造性的技术玩法，使技术可感知； 维护重点 KOL，并吸纳行业专业意见，加大行业贡献，并深化行业影响力。  岗位要求：\n 具备用户细分、市场定位、产品规划、产品包装的能力中的一项或多项； 具备良好的创新思维、有技术前瞻性； 良好的沟通协作能力，及横向驱动能力； 有线上市场推广经验，或线下活动策划经验者优先考虑； 对于云计算领域有较深入的了解，有相关工作背景者优先考虑。  欢迎简历投递至：khotyn.huangt@antgroup.com\n","date":1602831600,"description":"【10/12-10/16】 | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20201016/","fuzzywordcount":2000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"a7a2f16f7c62d777b8aff0f90a85ba7b","permalink":"/blog/sofa-weekly-20201016/","publishdate":"2020-10-16T15:00:00+08:00","readingtime":4,"relpermalink":"/blog/sofa-weekly-20201016/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | SOFAJRaft 发布、SOFAJRaft 源码解析文章合集","type":"blog","url":"/blog/sofa-weekly-20201016/","wordcount":1951},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n SOFAStack 官网：https://www.sofastack.tech SOFAStack：https://github.com/sofastack  每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@叶翔宇 提问：\n 想请教一个问题，使用 MOSN 的过程中，我们想通过 request 的 header 中带的 version 信息来实现灰度的机制。比如：目标 service 有 3 个 host，其中一台版本1.0，其他两个版本2.0。\n A：你这个加一个 route 的判断就可以路由到不同的 cluster 了。\n 我们的是同一个 cluster 里面的不同 hosts\u0026amp;hellip;\n A：你就把不同版本的 hosts 归为不同的 cluster 就可以啦。\n2、@李样兵 提问：\n 我们现在生产环境中没有使用 K8s, 只使用 MOSN+自定义配置和注册中心，可行吗？\n A：你们是 Dubbo 么？\n 对，dubbo+http， 生产环境是 docker 还没有 K8s。\n A：你可以用这个方案，MOSN 直接连接注册中心。 https://github.com/mosn/mosn/issues/1087 MOSN：https://github.com/mosn/mosn\n线上直播 SOFAChannel 合集  人人都可以“机密计算”：Occlum 使用入门和技术揭秘 | 开源 蚂蚁集团网络通信框架 SOFABolt 功能介绍及协议框架解析 | 开源 不得不说的云原生隔离性 | SOFAChannel#16 直播回顾 蚂蚁金服分布式链路组件 SOFATracer 埋点机制解析 | SOFAChannel#15 直播整理 云原生网络代理 MOSN 扩展机制解析 | SOFAChannel#14 直播整理 云原生网络代理 MOSN 多协议机制解析 | SOFAChannel#13 直播整理 蚂蚁金服分布式事务实践解析 | SOFAChannel#12 直播整理 从一个例子开始体验轻量级类隔离容器 SOFAArk | SOFAChannel#11 直播整理 Seata 长事务解决方案 Saga 模式 | SOFAChannel#10 回顾 从一个例子开始体验 SOFAJRaft | SOFAChannel#8 直播整理 蚂蚁金服轻量级监控分析系统解析 | SOFAChannel#6 直播整理 给研发工程师的代码质量利器 | SOFAChannel#5 直播整理 分布式事务 Seata TCC 模式深度解析 | SOFAChannel#4 直播整理 SOFARPC 性能优化实践（下）| SOFAChannel#3 直播整理 SOFARPC 性能优化实践（上）| SOFAChannel#2 直播整理 从蚂蚁金服微服务实践谈起 | SOFAChannel#1 直播整理  ","date":1602226800,"description":"【10/05-10/09】 | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20201009/","fuzzywordcount":1000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"a83b0d192a605f994a1379ab41578403","permalink":"/blog/sofa-weekly-20201009/","publishdate":"2020-10-09T15:00:00+08:00","readingtime":2,"relpermalink":"/blog/sofa-weekly-20201009/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | MOSN QA 整理、SOFAChannel 线上直播合集","type":"blog","url":"/blog/sofa-weekly-20201009/","wordcount":936},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n SOFAStack 官网：https://www.sofastack.tech SOFAStack：https://github.com/sofastack  每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n@周爽 提问：\n 我现在基于springcloud 集成 nacos,sentinel,zipkin,jpa,shardingjdbc，昨天说的做了防止重复代理，如果我是多数据源呢？后续1.3.1是配置也需要开启，代码也需要写代理吗？\n A：多数据源就关掉自动代理，自己手动\n 就在我多数据源里面加上右边的 DataSourceProxy 就可以了吗？ @Primary 这个只需DataSource1Config加上，DataSource2Config是否需要加呢？\n A：代理这个 reresult；\n AT 和 XA 1.3版本可以理解为代码“使用”上就一个 new poxy 不同吗？\n A：一个是 new DataSourceProxy，一个是 new DataSourceXAProxy\n Seata “实现”一个是二阶，一个是基于 XA 事务规范？\n A：都是二阶段，一个模式是自研，一个是基于数据库底层实现。 Seata：https://github.com/seata/seata\n本周推荐阅读  蚂蚁宣布开源 KubeTEE：让机密计算支持大规模 K8s 集群 人人都可以“机密计算”：Occlum 使用入门和技术揭秘 | 开源 SOFAEnclave：蚂蚁金服新一代可信编程环境，让机密计算为金融业务保驾护航102年  SOFA 项目进展 本周发布详情如下：\n1、发布 SOFARPC v5.7.6 版本，主要变更如下：\n 支持精细化配置 Jackson 序列化； Triple 协议支持用户自定义元数据； Triple 协议支持 SPI 编程模式； 升级 hibernate-validator 版本到 5.3.6.Final； TripleServer 启动时发送启动事件；  详细发布报告： https://github.com/sofastack/sofa-rpc/releases/tag/v5.7.6\n2、发布 MOSN v0.17.0 版本，主要变更如下：\n 重构 XProtocol 连接池，支持 pingpong 模式、多路复用模式与连接绑定模式； 优化 XProtocol 多路复用模式，支持单机 Host 连接数可配置； Listener 配置新增对 UDS 的支持； 新增在 Dubbo 协议下通过 xDS HTTP 配置进行转换的过滤器； 部分框架实现优化与 Bug 修复；  详细发布报告： https://github.com/mosn/mosn/releases/tag/v0.17.0\n","date":1601622000,"description":"【09/28-10/02】 | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20201002/","fuzzywordcount":1100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"bc9b38b8088d82138a46a8318e944840","permalink":"/blog/sofa-weekly-20201002/","publishdate":"2020-10-02T15:00:00+08:00","readingtime":3,"relpermalink":"/blog/sofa-weekly-20201002/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分","tags":["SOFA Weekly"],"title":" SOFA Weekly | MOSN、SOFARPC 发版、Seata QA 整理","type":"blog","url":"/blog/sofa-weekly-20201002/","wordcount":1017},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n SOFAStack 官网：https://www.sofastack.tech SOFAStack：https://github.com/sofastack  每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n@刘源远 提问：\n 请教一下大家，这个本地事务提交，是指这个本地事务在分布式事务中提交，还是指在自己的事务中提交啊？ 如果是指分布式事务中提交，那不就应该在分支事务提交之前，才存在回滚嘛？如果是指自己的事务中提交，那我断点下来，本地业务事务已经提交了，为什么还产生这条记录呢？  A：只要二阶段回滚的时候，发现你的 undolog 没插入就会做一条防御性的 undolog，你可以认为你没产生资源悬挂，但是二阶段确实没读到你的 undolog。所以才会插入一个防御性，你完全不需要理会 status=1 的记录。\n 奇怪的是，我断点下来，在一阶段会产生 undolog 记录（两条），然后抛异常回滚之后，一阶段的 undolog 记录（两条）被删除了，产生一条 status=1 的记录。会不会是因为某些原因，一阶段会产生 undolog 记录被删除了，所有二阶段没有查询到？\n A： 多数据源？\n 对的，多数据源。\n A：确认下是不是重复代理了？把自动代理关了，一般多数据源都是已经手动代理了，因为二阶段的时候，下发找 datasource，找到的不是你当时操作数据库的 datasource，导致没发现 undolog，就插了一条 status=1。\n 我现在手动配置代理，有两个数据源，一个用了 DataSourceProxy，一个没有。现在处于分布式事务中是使用了 DataSourceProxy 的数据源，但是回滚后还是会产生一条 status=1 的 undolog。\n A： 自动代理关了吗，看下怎么代理的。\n 你指的自动代理是 springboot-start 吗？还是其他的？\n A：Seata 的数据源自动代理，设置 Seata: enable-auto-data-source-proxy: false\n OK，好啦\n Seata：https://github.com/seata/seata\n本周推荐阅读  蚂蚁金服通信框架 SOFABolt 解析 | 超时控制机制及心跳机制 蚂蚁金服通信框架 SOFABolt 解析 | 连接管理剖析 蚂蚁金服通信框架 SOFABolt 解析 | 协议框架解析 蚂蚁金服通信框架 SOFABolt 解析 | 序列化机制(Serializer) 蚂蚁金服通信框架 SOFABolt 解析 | 编解码机制  社区活动预告 CSDI summit 中国软件研发管理行业技术峰会（Software development management industry technology summit）由国内专业咨询机构百林哲匠心打造的软件行业技术领域顶级盛会，将于2020年9月24-27日举办。 话题涵盖：组织数字化转型、研发效能、产品创新、用户增长、云原生、架构创新、微服务、AI 大数据、数据安全和云安全、AIOT 实践等方面。蚂蚁集团也应邀参与本次大会分享。\n分享主题：金融级云原生 PaaS 实践之路\n**分享嘉宾：**成旻 蚂蚁金服高级技术专家\n**分享时间：**2020-09-26 16:40 - 18:00\n分享亮点：\n 蚂蚁 PaaS 产品的缘起； 经典应用服务的能力和特色； 容器应用服务的进阶能力； 面向未来\u0026amp;ndash;混合云发展发向；  **活动形式：**线上峰会\n**活动详情：**点击“这里”，了解日程详情\n","date":1601017200,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20200925/","fuzzywordcount":1500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"c7562a535d9b34b23d0b559dd756ef6a","permalink":"/blog/sofa-weekly-20200925/","publishdate":"2020-09-25T15:00:00+08:00","readingtime":3,"relpermalink":"/blog/sofa-weekly-20200925/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | SOFABolt 源码解析合辑、CSDI summit 活动预告","type":"blog","url":"/blog/sofa-weekly-20200925/","wordcount":1401},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n SOFAStack 官网：https://www.sofastack.tech SOFAStack：https://github.com/sofastack  社区大事件 MOSN 支持 Istio 啦～详见链接：\n 英文版：《Using MOSN with Istio: an alternative data plane》 中文版：《在 Istio 中使用 MOSN：另一个数据平面》  每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@梓郁 提问：\n 我最近刚刚接触分布式链路监控，看了 SOFATracer 的 slf4j 的 demo。现在有一个问题。就是我想在日志里面打印出 span 的 parentid，但是我不想在我自己的代码里面显性地用 MDC 添加，有什么其他方法吗？（我现在是打算在 MDCSpanExtension 里面用 mdc.put 添加;再重新打包添加依赖这样可行吗？）\n A：自己扩展下这个接口 SpanExtension。\nSOFATracer：https://github.com/sofastack/sofa-tracer\n2、@石评 提问：\n 我有个关于 Seata 的疑问：A -\u0026amp;gt; B-\u0026amp;gt;C 的时候，不管 B 有没有本地事务，如果 C 失败了 B 的都会回滚，那么 B 的本地事务的作用是什么呢？\n A：分布式事务认为由若干个分支事务（本地事务）构成的，如果加了 autocommit=false，那么 B 服务的几条 sql构成一个本地事务，如果不加那么每条 DML 语句都是一个本地事务。本地事务越少那么与 TC 的交互次数越少。\n3、@徐成阳 提问：\n Seata 的 TCC 强一致的嘛？\n A：AT、XA、TCC 应该都属于强一致性。 SAGA 无法保证事务隔离性，在部分情况下可能会存在无法回滚，而选择向前继续重试来保证事务最终一致性。 四种模式都是属于最终一致性。SAGA 性能更高，因为没有二阶段提交，而且分支数据都是保存在本地的。\nSeata：https://github.com/seata/seata\n本周推荐阅读  来了！2020 云栖大会 蚂蚁金融科技产品能力再升级 企业数字化转型指南，《SOFAStack 解决方案白皮书》正式发布  SOFA 项目进展 本周发布详情如下：\n发布 SOFAJRaft v1.3.4.bugfix_2 版本，主要变更如下：\n 修复使用 grpc 时，在一定情况下无法自动重连的问题；  详细发布报告： https://github.com/sofastack/sofa-jraft/releases/tag/1.3.4.bugfix_2\n社区活动预告 这里有一个您的专属日程提醒，请查收：\n日程主题：OceanBaseDev Meetup#1 上海站「深入分布式数据库：事务·高可用·云原生」\n出品人：\n 杨传辉（花名：日照）蚂蚁集团研究员、OceanBase 总架构师 韩富晟（花名：颜然）蚂蚁集团资深技术专家、OceanBase 事务研发负责人  日程时间：2020-09-20 本周日 13:00-17:30\n**日程地点：**上海市杨浦区政学路77号 InnoSpace+\n**日程详情：**点击“这里”，了解日程详情\n","date":1600412400,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20200918/","fuzzywordcount":1300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"d3e2feb22ec7504b5fc6648eeba4769f","permalink":"/blog/sofa-weekly-20200918/","publishdate":"2020-09-18T15:00:00+08:00","readingtime":3,"relpermalink":"/blog/sofa-weekly-20200918/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFAWeekly｜MOSN 支持 Istio、SOFAJRaft 发布、本周日您有一条待办日程","type":"blog","url":"/blog/sofa-weekly-20200918/","wordcount":1257},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n SOFAStack 官网：https://www.sofastack.tech SOFAStack：https://github.com/sofastack  每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@陈健斌 提问：\n Seata 使用注册中心只存储个地址列表，引入 SOFAJRaft 后感觉注册中心没必要了？用户用起来就跟 zk 集群、kafka 集群一样，ip:port,ip:port 这样。\n A：这个 看需求了，都可以啊。我感觉还是可以继续使用注册中心，然后 SOFAJRaft 的地址从注册中心回去，动态构建 SOFAJRaft 集群。\n 可以噢，这样 client 端不需要设置 server 的集群了，通过注册中心来就可以了，自动组装了。 我目前是这么设计的，有空的话还望指点一二。\n A：Sesta server 经常会经常替换吗？\n 这个得看用户了，要不咱假设2个情况吧，如果不经常替换，此方案适用不。经常替换下要做哪些改进？\n A：经常替换的话要考虑 raft 集群的替换，要处理 addpeer removepeer 这是要走 raft 协议的（用 cliservice 这个接口），就是换一台 server 不是换个地址就完事了，需要调用 addpeer把新机器加入 raftgroup 然后 SOFAJRaft 会自动同步数据，移除一个节点需要调用 removepeer。\n 也就是，如果我现在扩容，比如我原来的节点是127.0.0.1:7091，127.0.0.1:7092，127.0.0.1:7093 然后我现在要加一个127.0.0.1:7094，我能不能直接跟 zk 那边扩容一样，我新加入进来的节点设置的地址是127.0.0.1:7091，127.0.0.1:7092，127.0.0.1:7093，127.0.0.1:7094，先让他加入进去，然后手动挨个重启其余3台。目前这样的扩缩容，我的设计方案能满足吗？\n A：不需要重启，需要 addpeer，参考第11小结，最有效的排查 SOFAJRaft 问题工具 https://www.sofastack.tech/projects/sofa-jraft/jraft-user-guide/ SOFAJRaft：https://github.com/sofastack/sofa-jraft\n2、@koutatu 提问：\n 想咨询下，Seata Saga 模式下，TC 的作用是什么呢，回滚操作还是 TC 触发吗？感觉 Saga 状态机模式下，状态机可以控制回滚，TC 是不是只是记录下状态，不做什么实际处理了呢？\n A：你说的应该是对的，Saga 脱离 TC 理论上都是可行的。\n 目前的回滚操作是不是也是状态机自身控制的，也就是链路里面的每一步都需要有一个状态机。TC 只负责接收消息，而不是像 TCC 或者拦截器式的 Saga 一样，回滚由 TC 统一控制。\n A：TC 在 Saga 模式的作用就是记录全局事务分支事务状态。 Seata：https://github.com/seata/seata\n本周推荐阅读  蚂蚁金服研发框架总览 | SOFABoot 框架剖析 蚂蚁金服研发框架日志隔离解析 | SOFABoot 框架剖析 SOFABoot 扩展点初体验 | SOFALab 实践系列 剖析 | 详谈 SOFABoot 模块化原理 实操 | 基于 SOFABoot 进行模块化开发 开源 | SOFABoot 类隔离原理剖析  SOFA 项目进展 1、发布 SOFAArk v1.1.4 版本，主要变更如下：\n 支持动态替换 biz name； TestClassLoader 导出 mockito 包以支持 mockito 测试框架； 修复 AfterBizStopEvent 事件处理时机问题导致的 NPE； 修复 web 模块卸载问题； 支持 ark telnet 使用安全模式启动；  详细发布报告：https://github.com/sofastack/sofa-ark/releases/tag/v1.1.4\n2、发布 SOFABoot v3.4.4 版本，主要变更如下：\n 提供 jvm 调用拦截扩展； 修复若干测试用例； 修复在 ark 环境使用 sofa:reference 引用 jvm 服务出现 NPE bug； 修复健康检查通过但 ExtensionComponent activate 失败 bug；  详细发布报告：https://github.com/sofastack/sofa-boot/releases/tag/v3.4.4\n社区活动预告 近几年，越来越多的传统企业面临互联网化，IOT、区块链、AI、5G 等技术也在高速发展，任何一个技术的推广到成熟都会带来数据量的指数级增长，都会对存储带来巨大的冲击。相信随着这些技术的突破，未来越来越多的核心场景会走向分布式的领域。国内很多团队也在进行分布式数据库的探索与实践。\nOceanBaseDev Meetup 是以城市站展开的数据库技术交流活动，旨在为关注分布式数据库技术的同学提供技术交流、分享、探讨的空间与平台。\nOceanBaseDev Meetup#1 上海站，将邀请蚂蚁集团 OceanBase 团队的三位核心研发专家以及网易杭研资深研发工程师，针对分布式数据库的分布式事务以及落地实践展开分享。现场更有外滩大会门票等你来拿～\n活动主题：**OceanBaseDev Meetup#1 上海站「深入分布式数据库：事务·高可用·云原生」\n出品人：\n 杨传辉（花名：日照）蚂蚁集团研究员、OceanBase 总架构师 韩富晟（花名：颜然）蚂蚁集团资深技术专家、OceanBase 事务研发负责人  **活动时间：**2020-09-20 13:00-17:30\n**活动地点：**上海市杨浦区政学路77号 InnoSpace+\n**活动报名：点击“阅读原文”，了解活动详细议题并锁定席位\n","date":1599807600,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20200911/","fuzzywordcount":2100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"25ab3501e7db2cd836d05f86bb6c17ef","permalink":"/blog/sofa-weekly-20200911/","publishdate":"2020-09-11T15:00:00+08:00","readingtime":5,"relpermalink":"/blog/sofa-weekly-20200911/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | SOFABoot、SOFAArk 发布、9/20 上海线下活动推荐","type":"blog","url":"/blog/sofa-weekly-20200911/","wordcount":2099},{"author":"王发康（毅松）","categories":"MOSN","content":"本文根据 2020 年 8 月 15 号在深圳 GIAC（GLOBAL INTERNET ARCHITECTURE CONFERENCE）全球互联网架构大会云原生专场现场实录整理。\n分享嘉宾：王发康（毅松）蚂蚁集团可信原生技术部 技术专家，专注于高性能网络服务器研发，是 MOSN、Tengine 开源项目核心成员，目前关注云原生 Service Mesh、Nginx、Istio 等相关领域，喜欢开源，乐于分享。\nGItHub：https://github.com/wangfakang\n以下是分享全文。\n前言 MOSN 在蚂蚁集团的 Service Mesh 大规模落地后，通过对接 UDPA 打造为 Istio 的数据面之一，本文就其在演进过程中遇到的问题及思考进行展开。对接 UDPA，实现 Istio 融合，并增强 MOSN 服务治理及流量控制能力对接云原生周边组件，实现 MOSN 开箱即用。\n大家下午好，我叫王发康，来自蚂蚁集团可信云原生应用网络团队，之前几年一直从事南北向网关（接入层）的开发和维护，说来也是和流量有着别样的渊缘，现在主要做东西向的流量网关（Service Mesh）开发和设计。今天演讲的主题是《云原生网络代理 MOSN 的进化之路》，主要从如下几点介绍：\n MOSN 介绍； 云原生演进； 总结与展望；  MOSN 介绍 接下来，就 MOSN 的诞生背景、发展历程、MOSN 具备的功能和架构以及内部的落地情况这几个维度介绍下 MOSN。\nMOSN 诞生背景 随着云计算、物联网等技术迅速发展，也促使着微服务的架构一直在进化，其演进过程通常经历了如下四个阶段：\n单体：一般起始阶段业务很简单，流量也不大，所有的处理都可以在一个服务中完成；\n分布式：随着业务操作的多样化以及流量的日益增长，不得不按照服务维度进行拆分，这样相同的服务资源消耗可对等，方便容量评估及管理；\n微服务：随着服务的拆分粒度越来越细，其服务的数量一直在增加，由此出现各种微服务治理的需求（限流、鉴权、路由等），于是便出现各种治理组件并以 SDK 插件的方式集成到不同应用中；\nService Mesh：伴随着服务治理的 SDK 种类、版本、重复等一系列问题，于是把 SDK 的能力剥离到 Sidecar，和业务进行解耦，从而实现业务和中间件能力的并行迭代；\n业务痛点\n 多语言，中间件组件开发适配成本高； SDK 升级困难； 服务治理能力弱； 技术不通用，无法复用；  业界解决方案\n Envoy (C++)； Linkerd (活跃度较低)； NginxMesh (活跃度低)；  综合以上业务痛点以及业界现有方案的评估，于是 MOSN 就诞生了。MOSN（Modular Open Smart Network）是用 GoLang 编写的网络代理服务器。作为 Sidecar、API Gateway、云原生 Ingress、Layer 4 或 Layer 7 负载均衡器等场景构建的。随着时间的推移，我们添加了额外的功能，例如多协议框架，多进程插件机制，DSL 以及对 xDS API 等的支持，支持 xDS 意味着我们现在可以将 MOSN 用作 Istio 的数据平面。\nMOSN 发展历程 从 2017 年底开始 Service Mesh 技术调研，2018 年 3 月份 MOSN 雏形问世并进行了小规模试点，秉着让更多的用户能够享受这一技术红利的思路，于是 2018 年 6 月正式开源 MOSN。2019 年 618 进行了规模化落地，并在同年的双 11 大促达到了核心支付链路的全覆盖。在通过大规模验证后，MOSN 社区开始在其标准化以及生态方面进行发展和演进。\nMOSN 功能视图 MOSN 作为一个通用的数据转发平面，提供多协议卸载、动态服务发现、服务治理（Trace、限流、重试、重写、超时控制等）、丰富的负载均衡算法等功能，可用于 Sidecar、API Gateway、云原生 Ingress、Layer 4 或 Layer 7 负载均衡器等场景。\nMOSN 架构解析 MOSN 采用的是分层的体系结构，其系统分为 NET/IO、Protocol、Stream、Proxy 四层：\n NET/IO 作为网络层，监测连接和数据包的到来，同时作为 listener filter 和 network filter 的挂载点; Protocol 作为多协议引擎层，对数据包进行检测，并使用对应协议做 decode/encode 处理; Stream 对 decode 的数据包做二次封装为 stream，作为 stream filter 的挂载点; Proxy 作为 MOSN 的转发框架，对封装的 stream 做 proxy 处理;  其中，每一层通过工厂设计模式向外暴露其接口，方便用户灵活地注册自身的需求。通过协程池的方式使得用户以同步的编码风格实现异步功能特性。通过区分协程类型，MOSN 实现了 read 和 proxy worker 两大类协程，read 协程主要是处理网络的读取及协议解析，proxy worker 协程用来完成读取后数据的加工、路由、转发等。其架构如下图所示：\nMOSN 为了降低 Runtime GC 带来的卡顿，自身做了内存池的封装方便多种对象高效地复用，另外为了提升服务网格之间的建连性能还设计了多种协议的连接池从而方便地实现连接复用及管理。\n在连接管理方面，MOSN 设计了多协议连接池， 当 Proxy 模块在 Downstream 收到 Request 的时候，在经过路由、负载均衡等模块处理获取到 Upstream Host 以及对应的转发协议时，通过 Cluster Manager 获取对应协议的连接池 ，如果连接池不存在则创建并加入缓存中，之后在长连接上创建 Stream，并发送数据，如下图所示：\n在内存管理方面，MOSN 在 sync.Pool 之上封装了一层资源对的注册管理模块，可以方便的扩展各种类型的对象进行复用和管理。其中 bpool 是用来存储各类对象的构建方法，vpool 用来存放 bpool 中各个实例对象具体的值。运行时通过 bpool 里保存的构建方法来创建对应的对象通过 index 关联记录到 vpool 中，使用完后通过 sync.Pool 进行空闲对象的管理达到复用，如下图所示：\nMOSN 落地情况 服务在做了 Mesh 化后，有人可能会质疑，增加一跳 Sidecar 转发是否会导致性能下降，其实不然，在蚂蚁的部分业务场景中，部分业务上了 Mesh 后，其 CPU 消耗还比之前低了，原因是之前的一些通用 SDK 能力都下沉到 Sidecar 中，并统一做了一定的优化。另一个好处是，由于 MOSN 使用 GoLang 开发，天然具备其高开发效率，所以也大大的提升了中间件相关能力的研发速度。\nMOSN 云原生演进 在 MOSN 大规模落地并通过双 11 大考后，MOSN 也开始在实践的道路上进行标准化演进。并通过和 Istio 社区的合作，MOSN 实现了 xDS 的适配，可方便的实现 Istio 作为 MOSN 的控制面进行服务配置的管理。另一方面，我们也在积极参加 Istio …","date":1599022800,"description":"MOSN 在蚂蚁集团的 Service Mesh 大规模落地后，通过对接 UDPA 打造为 Istio 的数据面之一，本文就其在演进过程中遇到的问题及思考进行展开。","dir":"blog/cloud-native-network proxy-mosn-evolutionary-path/","fuzzywordcount":5100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"080e78e9d0103daed414ee3a8b5b7996","permalink":"/blog/cloud-native-network-proxy-mosn-evolutionary-path/","publishdate":"2020-09-02T13:00:00+08:00","readingtime":11,"relpermalink":"/blog/cloud-native-network-proxy-mosn-evolutionary-path/","summary":"本文根据 2020 年 8 月 15 号在深圳 GIAC（GLOBAL INTERNET ARCHITECTURE CONFERENCE）全球互联网架构大会云原生专场现场实录整理。 分享嘉宾：王发康（毅松）","tags":["MOSN","Service Mesh"],"title":"云原生网络代理 MOSN 的进化之路","type":"blog","url":"/blog/cloud-native-network-proxy-mosn-evolutionary-path/","wordcount":5065},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n SOFAStack 官网：https://www.sofastack.tech SOFAStack：https://github.com/sofastack  每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1**、@晏伦** 提问：\n 请问 Seata 的全局锁粒度是数据库级别还是表级别？全局锁会带来并发的问题吧？如何权衡的呢？\n A：全局锁是行级别的；如果2个事务在同时更新同一行，会出现锁竞争问题，所以 AT 模式的适用场景是并发请求较低，不会产生行锁竞争的业务场景。\nSeata：https://github.com/seata/seata\n本周推荐阅读  少年五年升阿里 P8，他如何从低谷登上“光明顶”？ 支付宝资深技术专家尹博学：新一代金融核心突破之全分布式单元化技术架构 Forrester中国首席分析师戴鲲：云原生技术趋向成熟，金融企业选择云原生平台需满足三大要求  组件解析部分合辑  基于 RAFT 的生产级高性能 Java 实现 - SOFAJRaft 系列内容合辑 生产级高性能 Java RPC 框架 - SOFARPC 系列内容合辑  SOFA 项目进展 发布 sofa-common-tools v1.2.0 版本，主要变更如下：\n 修复多线程日期打印问题； SOFAThreadPool 支持一个 Runnable 在多个 thread 运行； 停止 JDK6 支持；  详细发布报告：https://github.com/sofastack/sofa-common-tools/releases/tag/v1.2.0\n社区活动预告 CSDI summit 中国软件研发管理行业技术峰会（Software development management industry technology summit）是软件行业技术领域顶级盛会，协同国内外知名软件、互联网等企业研发一线技术专家从 AI 和大数据、产业变革、技术创新、生态发展、业务创新、商业模式等方面重点研讨软件研发趋势。蚂蚁集团也受邀参与本次峰会分享“云原生”相关主题。\n分享主题：金融级云原生 PaaS 实践之路\n**分享嘉宾：**成旻 蚂蚁集团高级技术专家\n**分享时间：**2020-09-26 16:40-18:00\n听众收获：\n 蚂蚁 PaaS 产品的缘起； 经典应用服务的能力和特色； 容器应用服务的进阶能力； 面向未来\u0026amp;ndash;混合云发展发向；  活动地点： 线上活动\n活动报名： 点击“这里\n","date":1598598000,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20200828/","fuzzywordcount":1100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"474484cd88c8a1971016217eb9c1438d","permalink":"/blog/sofa-weekly-20200828/","publishdate":"2020-08-28T15:00:00+08:00","readingtime":3,"relpermalink":"/blog/sofa-weekly-20200828/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | sofa-common-tools 发布、组件解析合辑、云原生活动推荐","type":"blog","url":"/blog/sofa-weekly-20200828/","wordcount":1050},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n SOFAStack 官网：https://www.sofastack.tech SOFAStack：https://github.com/sofastack  每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动\n我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@谢小东 提问：\n 请教一个问题，在使用 AT 模式的时候，新增的一条数据，回滚之前我在 db 改了我刚新增的数据，这个时候如果我抛出异常，但是就不发回滚，该怎么处理？\n A：不要在全局事务包裹之外进行对数据的并发操作，如果你这样做，就跳过了 AT 的全局锁，隔离性无法保证，如果你有这方面需求的，可以用 XA 模式，并且使用数据库自身带有排它锁的操作，数据库的自身支持了 XA 模式，就可以帮你保证隔离性。\n 你的意思就是我在这种情况下 XA 模式适合？XA 模式是行锁么？\n A：XA 是数据库自身实现的隔离机制，AT 是统一到 TC 去竞争行锁，而没用到 AT 的地方修改数据库当然就不会去 TC 竞争行锁，隔离性只能保证再全局事务注解下的操作生效。\n2、@彭兴家 提问：\n 请问 Seata 里说的全局锁和本地锁对应 MySQL 的什么锁呀？\n A：全局锁就是从 TC 竞争的锁，本地锁就是参与方自己本地的 MySQL 连接，比如 update 不就有排他锁的作用吗，因为一阶段提交，连接释放了，这个本地数据库的锁就解开了。而全局锁是从 TC 拿的，这个锁保证了你的入口只要是分布式事务注解下，就会去竞争这个全局锁。保证了再分布式事务注解下的全局事务间的隔离性\n 谢谢，明白了。但这样的话，Seata 通过前置镜像回滚。在全局事物执行的过程中，要是其他项目(没在全局事物下的项目)对该条数据进行了修改，那么按照 Seata 的机制，前置镜像对比不同了就不能回滚，需要手动处理？\n A：是的，需要人工介入，因为只有人为分析才能校准数据了。对 Seata 来说他只知道要把数据回滚到发生前，但是数据被干扰了，就无法回滚了。\n 理论上来说这种情况出现的几率很大呀，多个不同项目操作同一条数据。\n A：全局事务，字面意思要理解一下。你让他不全局了，让它不覆盖到，如何保证隔离性？要么涉及到的库对应的应用全局使用 Seata AT，要么就换 XA，修改的数据，用 select for update，这个本地锁在二阶段下发通知前不会释放，保证了隔离性。\n3、@苏龙飞 提问：\n 请问，现在我们的 cloud 项目中用了 Seata，数据库只有一个，然后发现性能不够，所以想换成多主从数据库，并且能和 Seata 兼容，有没有好的方案呀？\n A：主从方案本就应该是允许暂时的不一致，只要你保证读写都需要的时候，一定是主库，并把主库的 datasource 代理掉就好了，保证需要读后马上写的，一定要是主库操作。 Seata：https://github.com/seata/seata\nSOFAChannel 部分合辑  人人都可以“机密计算”：Occlum 使用入门和技术揭秘 | 开源 蚂蚁集团网络通信框架 SOFABolt 功能介绍及协议框架解析 | 开源 不得不说的云原生隔离性 | SOFAChannel#16 直播回顾 链接蚂蚁金服分布式链路组件 SOFATracer 埋点机制解析 | SOFAChannel#15 直播整理 云原生网络代理 MOSN 扩展机制解析 | SOFAChannel#14 直播整理 云原生网络代理 MOSN 多协议机制解析 | SOFAChannel#13 直播整理 蚂蚁金服分布式事务实践解析 | SOFAChannel#12 直播整理 从一个例子开始体验轻量级类隔离容器 SOFAArk | SOFAChannel#11 直播整理  本周推荐阅读  蚂蚁集团如何在大规模 Kubernetes 集群上实现高 SLO？ 蚂蚁是如何改进 K8s 集群敏感信息的安全防护的？  ","date":1597993200,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20200821/","fuzzywordcount":1600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"34ac475f8a4ec2435b62a9bf4d520e2a","permalink":"/blog/sofa-weekly-20200821/","publishdate":"2020-08-21T15:00:00+08:00","readingtime":4,"relpermalink":"/blog/sofa-weekly-20200821/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | 线上直播合辑整理、Seata QA 整理","type":"blog","url":"/blog/sofa-weekly-20200821/","wordcount":1511},{"author":"樱桃","categories":"Occlum","content":" \u0026amp;lt; SOFA:Channel/ \u0026amp;gt;，有趣实用的分布式架构频道。 回顾视频以及 PPT 查看地址见文末。欢迎加入直播互动钉钉群 : 30315793，不错过每场直播。\n 本文根据 SOFAChannel#18 直播分享整理，主题：零门槛的机密计算：Occlum LibOS 使用入门和技术揭秘。\n大家好，我是今天的讲师田洪亮（花名：樱桃），蚂蚁集团技术专家，也是 Occlum 开源负责人。今天我和大家分享一下如何使用 Occlum 的轻松开发机密计算应用以及 Occlum 技术架构和特色。\n前言 云计算、大数据、人工智能，我们正处在一个数据爆炸的时代。如何能够在享受和利用海量数据所产生的价值的同时，保证数据的安全和用户的隐私呢？这无异是一个用户、企业和监管部门共同关注的问题。\n近年来兴起的机密计算（Confidential Computing），正是为了解决这个问题而来。利用可信执行环境（Trusted Execution Environments，简称 TEE）技术，机密计算使得数据始终保持加密和强隔离状态，从而确保了用户数据的安全和隐私。机密计算可以解决诸多应用场景中“信任”难题，比如多个不互信组织之间的数据融合与联合分析、区块链上的智能合约的机密性保护、公有云平台对外部或内部攻击的防御、高敏感信息（比如密码学材料、医疗档案等）的安全保护等等。\n但是，机密计算底层依赖的 TEE 技术——比如目前最成熟的云端 TEE 技术 Intel SGX——也带来了额外的功能限制和兼容问题。这使得机密计算的开发者面领一个巨大的阻碍：应用开发难。\n在本文中，我们会首先分析当前 SGX 应用开发者会遇到的各种挑战和痛点，然后介绍蚂蚁集团自研的开源 TEE OS 系统 Occlum 如何大幅降低 SGX 应用开发的门槛，真正做到人人都可以玩转机密计算。\n为什么 SGX 应用开发难？ SGX 应用程序是一种基于划分的模型：在用户态的（不可信）应用程序（上图红色部分）可以嵌入 SGX TEE 保护的区域（上图绿色部分），被称为 Enclave。支持 SGX 的 Intel CPU 保证 Enclave 中的受保护内容是在内存中加密的，并且与外界强隔离。外界的代码如果想进入 Enclave 中执行其中的可信代码必须通过指定的入口点，后者可以实施访问控制和安全检查以保证 Enclave 无法被外界滥用。\n由于 SGX 应用程序是基于这种划分的架构，应用开发者通常需要使用某种 SGX SDK，比如 Intel SGX SDK、Open Enclave SDK、Google Asylo 或 Apache Rust SGX SDK。但无论使用上述哪种 SDK，开发者会遭遇下面的开发困境：\n 必须将目标应用做二分：开发者需要决定哪些组件应该置于 Enclave 内部，哪些置于 Enclave 外部，以及双方如何通信。对于复杂的应用，确定高效、合理且安全的划分方案本身就是一件颇具挑战的工作，更不要说实施划分所需的工程量。 被限定在某个编程语言：无论使用上述哪种 SDK 开发，一个开发者都将被限定在该 SDK 所支持的语言，这通常意味着 C/C++（当使用 Intel SGX SDK、Open Enclave SDK 或 Google Asylo 时），而无法使用 Java、Python、Go 等更加友好的编程语言。 只能获得很有限的功能：处于硬件限制和安全考虑，Enclave 中是无法直接访问 Enclave 外的（不可信）OS 的。由于 Enclave 中缺乏 OS 的支持，各种 SDK 只能提供普通不可信环境下的一个很小的功能子集，这使得很多现有的软件库或工具都无法在 Enclave 中运行。  上述困境使得为 SGX 开发应用成为一件十分痛苦的事，制约了 SGX 和机密计算的普及度和接受度。\n学会 Occlum 的“三板斧” Occlum 是一款蚂蚁集团开源的 TEE OS，可以大幅降低 SGX 应用的开发门槛。那到底多低呢？只需要学会 Occlum的三条命令：new、build和run。本节我们以利用 Occlum 在 SGX 中运行一个 Hello World 程序为例进行说明。\n这里有一个非常简单的 Hello World 程序。\n$ cat hello_world.c #include \u0026amp;lt;stdio.h\u0026amp;gt; int main() { printf(\u0026amp;quot;Hello World!\\n\u0026amp;quot;); return 0; } 首先，我们用 Occlum 提供的 GCC 工具链（occlum-gcc）编译这个程序，并验证它在 Linux 上能正常工作。\n$ occlum-gcc hello_world.c -o hello_world $ ./hello_world Hello World! 然后，我们为这个程序创建一个 Occlum 的实例目录（使用 occlum new 命令）。\n$ occlum new occlum_hello $ cd occlum_hello 该命令会创建一个名为 occlum_hello 的目录，并在该目录中准备一些必要的文件（如 Occlum.json 配置文件）子目录（如 image/）。\n接下来，我们基于刚刚编译好的 hello_world 制作一个 Occlum 的 Enclave 文件和可信镜像（使用 occlum build 命令）。\n$ cp ../hello_world image/bin $ occlum build 最后，我们在 SGX 中运行 hello_world（使用 occlum run 命令）。\n$ occlum run /bin/hello_world Hello World! 更复杂的程序也可以用类似上面的流程通过 Occlum 移植进 SGX 中。用户无需理解 SGX 的二分编程模型，无需或只需少量修改应用代码，还可以自由选择编程语言（比如 Java、Python、Go 等）。使用 Occlum，应用开发者可以将宝贵的精力集中在编写应用上，而非为 SGX 做应用移植。\n用起来像 Docker 的 TEE OS 在了解了 Occlum 的基本用法和体验之后，很自然地会好奇 Occlum 的技术原理：Occlum 的用户接口为什么这样设计？而简单接口背后的技术架构又是怎样的？本节就试图回答这些问题。\nOcclum 的一个设计理念是 Enclave-as-a-Container。在云原生时代，容器至关重要，容器无处不在。容器最常见的实现方式是基于 Linux 的 cgroup 和 namespace（比如 Docker），但也有基于虚拟化的实现（比如 Kata）。我们观察到，TEE 或者 Enclave 也可以作为一种容器的实现手段。因此，为了传达这种理念，同时给用户提供一种熟悉的体验，我们特意将 Occlum 的用户接口设计成与 Docker 和 OCI 标准接近。除了前面提到的 new、build和run 三个命令，Occlum 还提供 start、exec、stop、kill 等命令，其语意与 Docker 同名命令类似。 …","date":1597906800,"description":"本文分享如何使用 Occlum 的轻松开发机密计算应用以及 Occlum 技术架构和特色。","dir":"blog/sofa-channel-18-retrospect/","fuzzywordcount":3000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"a1d55e5deb00aa8cde8d14f250569013","permalink":"/blog/sofa-channel-18-retrospect/","publishdate":"2020-08-20T15:00:00+08:00","readingtime":6,"relpermalink":"/blog/sofa-channel-18-retrospect/","summary":"\u0026lt; SOFA:Channel/ \u0026gt;，有趣实用的分布式架构频道。 回顾视频以及 PPT 查看地址见文末。欢迎加入直播互动钉钉群 : 30315793，不错过每场直播。 本文根据 SOFAChannel#18 直","tags":["Occlum","SOFAchannel"],"title":"人人都可以“机密计算”：Occlum 使用入门和技术揭秘 | SOFAChannel#18 直播回顾","type":"blog","url":"/blog/sofa-channel-18-retrospect/","wordcount":2939},{"author":"田晓旭","categories":"Kubernetes","content":" 随着 Kubernetes 逐渐成为云计算的标准，企业中的 Kubernetes 应用正成为主流。\n 根据 CNCF 2019 Kubernetes 使用调查报告的显示：目前 84% 的用户已经在生产环境中使用 Kubernetes，生产环境中容器部署规模超过 1000 的比例是 34%，其中超过 5000 的大规模应用比例是 19%。当集群越来越大、越来越复杂，集群可用性就会面临挑战。\n 整体指标：集群是否健康，所有组件是否正常工作，集群中 Pod 创建的失败数量有多少等等； 追踪能力：集群中发生了什么，是否有异常，用户做了什么事情等等； 原因定位：出现异常之后，找到是哪个组件出了问题；  想要解决这些问题，比较好的一个方法就是 SLO，通过定义 SLO 来描述集群的可用性，追踪集群中 Pod 的生命周期，一旦出现失败 Pod，快速定位异常组件。本文采访了蚂蚁集团技术专家范康和姚菁华来分享蚂蚁集团的 SLO 体系是如何建立的。\n大家常会听到 SLA，其实 SLA 是 SLO 衍生出来的协议，SLA 协议会形成具有法律效力的合同，通常是服务供应商和外部客户之间签订的，而 SLO 是用于内部服务之间，定义服务所提供功能的一种期望状态。\n1 SLO 指标定义 如果我们要通过定义来描述集群的可用性，那么具体的描述指标就成为了需要解决的关键问题。在蚂蚁 集团 内部，集群可用性的关键指标包含五个：集群健康度、Pod 创建成功率、残留 Terminating Pod 的数量、服务在线率和故障机数量。\n 集群健康度：通常使用 Healthy，Warning，Fatal 三个值来描述，其中 Warning 和 Fatal 对应告警体系，例如 P2 告警发生，那集群就是 Warning，而 P0 告警发生，那集群就是 Fatal，必须进行处理； Pod 创建成功率：这是一个非常重要的指标，蚂蚁集团一周的 Pod 创建量在百万级别，如果成功率波动会造成大量 Pod 失败，同时 Pod 成功率下跌也是集群异常的最直观反映； 残留 Terminating Pod 的数量：有人可能会好奇为什么使用残留 Terminating Pod 的数量，而不用删除成功率？这是因为当 Pod 数量达到百万级别后，即使删除成功率达到了 99.9%，Terminating Pod 的数量也有数千，残留这么多 Pod 占用应用容量，在生产环境中是不可接受的； 服务在线率：这个指标是通过探针来衡量的，探针失败则意味着集群不可用； 故障机数量：这是一个节点维度的指标，故障机通常是指无法正确交付 Pod 的物理机，集群故障机需要做到“快速发现，快速隔离，及时修复”，否则会对集群容量造成影响；  以上指标的阈值和 SLO 性能目标都是根据业务方的增长来定义的，随着业务的不断增长，这些指标的定义也可能需要跟着做调整。\n以 Pod 创建成功率为例，蚂蚁集团将 Pod 分为了普通 Pod 和 Job 类 Pob，普通 Pod 的 RestartPolicy 为 Never，Job 类 Pod 的 RestartPlicy 为 Never 或 OnFailure，两者都设定有交付时间，普通 Pod 的交付标准是 1min 内 Pod 已经 Ready；Job 类 Pod 的交付标准是 1min 内 Pod 的状态已达 Running、Succeeded 或 Failed。最开始 Pod 创建成功率的定义是成功创建的 Pod 和总 Pod 的比值，但是很快就发现在排查原因时，系统很难分辨，所以又将 Pod 失败原因调整成用户和系统两部分，创建成功率的定义就变成了创建成功的 Pod 和总的 Pod 减去用户失败 Pod 的比值。\n2 蚂蚁集团的 SLO 体系 确定好 SLO 各项关键指标的定义之后，接下来就是构建 SLO 体系。\n据范康介绍，蚂蚁集团 SLO 系统主要包括两个方面，一个方面用于向终端用户 / 运维人员展示当前集群各项指标状，另一方面是各个组件相互协作，分析当前集群状态，获取影响 SLO 的各项因素，为提升集群 pod 交付成功率提供数据支持。\n蚂蚁集团 SLO 体系架构图\n自顶向下而看，蚂蚁集团 SLO 的分层架构包括 SLO、Trace system、Increase of SLO、Target 和 The unhealthy node。\n其中，顶层组件主要面向各种指标数据，如集群健康状态、pod 创建、删除、升级成功率、残留 pods 数量、不健康节点数量等指标。其中 Display Board 是指监控大盘，可能不会实时查看，为避免错过处理紧急事件的最佳时机，同时构建了 Alert 告警子系统，支持配置多种告警方式；Analysis System 通过分析指标历史数据以及采集到的节点 metrics 和 master 组件指标，给出更详细的集群运营报告；Weekly Report 子系统给出当前集群本周 pod 创建 / 删除 / 升级的数据统计，以及失败案例原因汇总；Terminating Pods Number 给出一段时间内集群内新增的无法通过 Kubernetes 机制删除的 Pods 列表和 Pods 残留原因；Unhealthy Nodes 则给出一个周期内集群所有节点的总可用时间占比，每个节点的可用时间、运维记录、以及不能自动恢复，需要人工介入恢复的节点列表。\n为了支撑上述这些功能，蚂蚁集团还开发了 Trace System，用来分析展示单个 pod 创建 / 删除 / 升级失败的具体原因。其中包含日志和事件采集、数据分析、pod 生命周期展示三个模块。日志和事件采集模块采集各 master 组件以及节点组件的运行日志和 pod、node 事件，分别以 pod/node 为索引存储日志和事件；数据分析模块分析还原出 pod 生命周期中各阶段用时，判断 pod 失败原因，节点不可用原因。最后，由 Report 模块向终端用户暴露接口和 UI，向终端用户展示 pod 生命周期以及出错原因。\n3 经验总结 目前蚂蚁集团的 SLO 实践不仅提高了集群 pod 的交付成功率，同时通过构建 tracing 系统，分析到集群内 pod 交付关键链路的耗时，整理失败原因，实现了数据分析 / 诊断平台。对于如何实现高 SLO，范康也给出了自己的五点经验。\n 在提升成功率的进程中，SLO 治理团队面临最大的问题是镜像下载。Pod 必须在规定时间内交付，而镜像下载通常需要非常多的时间。所以，团队通过计算镜像下载时间，专门设置了一个 ImagePullCostTime 的错误，即镜像下载时间太长，导致 Pod 无法按时交付。另外，阿里镜像分发平台蜻蜓支持了 Image lazyload 技术，在 Kubelet 创建容器时，不用再下载镜像，大大加速了 Pod 的交付速度； 提升单个 Pod 成功率：随着成功率的提升，再提升的难度会越来越大，这是可以引入 workload 进行重试。蚂蚁集团内部的 PaaS 平台会不断重试，直到 Pod 成功交付或者超时。需要注意的是，重试时要先排除之前的失败节点； 检查关键 Daemonset： …","date":1597820400,"description":"随着 Kubernetes 逐渐成为云计算的标准，企业中的 Kubernetes 应用正成为主流。本文分享蚂蚁集团的 SLO 体系是如何建立的。","dir":"blog/antgroup-kubernetes-high-slo/","fuzzywordcount":2600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"f15367978d8b820ec3fcddf3ab6d7779","permalink":"/blog/antgroup-kubernetes-high-slo/","publishdate":"2020-08-19T15:00:00+08:00","readingtime":6,"relpermalink":"/blog/antgroup-kubernetes-high-slo/","summary":"随着 Kubernetes 逐渐成为云计算的标准，企业中的 Kubernetes 应用正成为主流。 根据 CNCF 2019 Kubernetes 使用调查报告的显示：目前 84% 的用户已经在生产环境中使用 Kubernetes，生","tags":["Kubernetes"],"title":"蚂蚁集团如何在大规模 Kubernetes 集群上实现高 SLO？","type":"blog","url":"/blog/antgroup-kubernetes-high-slo/","wordcount":2530},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n SOFAStack 官网：https://www.sofastack.tech SOFAStack：https://github.com/sofastack  每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动\n我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@陈亚兵 提问：\n 我想单独使用注册中心 SOFARegistry，可能的服务有 Java 和 Python，SOFARegistry 支持 Python 服务接口的注册吗？\n A：SOFARegistry 注册中心是支持各个语言的服务发现和订阅的，目前开源版中只有 Java client。实现其他语言的服务发现和订阅，需要自己实现相关语言的 Registry client。\n sofa-bolt-python 也有服务发现和发布，它和 sofa-registry 的发现有什么不同吗？\n A：sofa-bolt-python 只做了使用 MOSN 的服务接口的客户端。sofa-registry 是服务端。 SOFARegistry：https://github.com/sofastack/sofa-registry\n2、@刘明 提问：\n Seata 的 XA 模式做了一个压测，tps=1000，开始报错，ORA-24756：事务处理不存在。 看了下数据库global_table，状态是 3。 3 是 CommitRetrying ， 这说明 phase 1 阶段过了，2 阶段提交报事务不存在。 目前 global_table 里有700多条记录，95%是状态3，还有状态1的。\n A：应该是一个原因，很可能就是2阶段提交失败了。begin 的你查看下他的分支事务状态是什么。\n begin 的分支表里没有数据，可能注册就失败了。\n A：是的，有可能，TC 收到了，然后 TM 超时了，我建议你 1000tps 的测试，搞个 TC 集群，就一台可能撑不住。\n 我想在出错的时候，有个日志轨迹，可以知道数据目前是不是脏的？\n A：select for update 或者 update x=x+n 这样写法一般没事。\n 会不会锁住记录呢？\n A：不锁住怎么保证隔离性。这个 for update xa 没提交前会锁住的，这个锁由数据库方自己已经实现了。\n 是的，那1阶段已经过了，记录会一直锁在那里了吗？\n A：二阶段没提交，锁在数据库肯定没释放。不过看起来你应该提交了吧，因为已经提示你事务不存在了。\n 是的，事务提示不存在，但是数据没有提交。 我研究下。\n A：可以的，seata-xa 现在还不是特别完善，可以多研究下，发现问题可以提交 PR 来贡献，一起让 XA 更稳定更好。\n 并发情况下，事务已经提交，TCC 发起 global commit 请求超时导致了 commitRetry，因此事务不再存在，只是 TCC 会一直去重试。 这导致了性能下降很快，不断重复已经不存在事务的 commit 动作，使用 Oralce 测试下来耗时很大，MySQL 可能也不会更好。考虑在 RM 端做 xaCommit 的时候，引入一个 Redis 检查 xid 是否已经提交，已经提交返回提交成功。\n Seata：https://github.com/seata/seata\n本周推荐阅读  基于 RAFT 的生产级高性能 Java 实现 - SOFAJRaft 系列内容合辑 生产级高性能 Java RPC 框架 - SOFARPC 系列内容合辑 蚂蚁是如何改进 K8s 集群敏感信息的安全防护的？  SOFA 项目进展 本周发布详情如下：\n发布 SOFABoot v3.4.3 版本，主要变更如下：\n 新增 endpoint，支持展示启动耗时信息； 升级 Tomcat 版本，修复安全隐患 CVE-2020-11996；  详细发布报告：https://github.com/sofastack/sofa-boot/releases/tag/v3.4.3\n社区活动报名 A2M 峰会旨在发现全球互联网领域在人工智能、大数据、互联网架构等领域的创新工程和杰出团队，整合国际最佳技术实践，构建行业案例研究智库，帮助中国企业在人工智能时代成功转型、升级。蚂蚁集团受邀进行云原生构建之路的专题分享。\n**分享主题：**Dubbo 基于 MOSN 在 Service Mesh 场景下的落地实践\n**分享嘉宾：**曹春晖 蚂蚁集团 可信原生技术部技术专家\n蚂蚁集团技术专家，对 Go 语言有深入的研究，《Go 语言高级编程》作者。在后端业务开发、数据平台等领域有多年的实践经验。目前正在领导 MOSN 社区进行 Dubbo 生态在 Service Mesh 场景下的落地工作。\n**背景介绍：**过去一段时间，云原生和 Service Mesh 大火。很多公司希望借着东风推动公司的微服务架构演进到下一阶段。然而在实践过程中不会事事如意，问题接踵而至。\n在使用 Dubbo 来做微服务框架的公司中，因为每个公司发展阶段不同，上云的进度不同，社区方案却要求必须要在完全上云之后才能沐浴 Service Mesh 的春风，这着实令人失望。\n**解决思路：**借助前人的落地经验，在 MOSN 与 Dubbo 结合的探索中，我们思考出一些可供处于不同上云阶段的公司参考的落地方案。经过对数据面的简单改造，在控制风险的前提下，能够渐进地将 Service Mesh 落地到公司内。\n**成果：**基于 MOSN 和 Dubbo-go，实现 Service Mesh 在 Dubbo 场景下的落地。\n听众收益：\n 了解落地 Service Mesh 对于整体架构的收益； 了解 MOSN 社区的发展现状和规划； 了解 Dubbo 在各种业务场景和上云发展阶段中如何优雅落地 Service Mesh；  分享时间：2020-09-05 16:50-17:50\n活动地点：上海\n**活动报名：**点击“这里”锁定席位\n","date":1597388400,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20200814/","fuzzywordcount":2200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"68d4b22d401ef51b62f39c8680895b36","permalink":"/blog/sofa-weekly-20200814/","publishdate":"2020-08-14T15:00:00+08:00","readingtime":5,"relpermalink":"/blog/sofa-weekly-20200814/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | SOFABoot 发布、SOFAJRaft 以及 SOFARPC 内容合辑、MOSN 活动报名","type":"blog","url":"/blog/sofa-weekly-20200814/","wordcount":2137},{"author":"万佳","categories":"Kubernetes","content":"在 Kubernetes 中，Secret 显得尤其重要。因为它是 K8s 中存储所有敏感信息的对象。据悉，这些敏感信息包含密码、集群的证书、OAuth token、ssh key 以及其他用户自定义的敏感文件等。因此，一旦 K8s 中 Secret 出现安全问题，后果将非常严重。此外，虽然社区提供了一定的安全防护方案，但是依然存在诸多问题。\nK8s Secret 面临着哪些安全问题？这些安全问题会带来什么影响？社区提供的解决方案存在哪些不足？\u0026amp;hellip;\u0026amp;hellip;针对这些问题，InfoQ 记者采访了蚂蚁集团高级工程师秦凯伦，他专注于可信计算、系统安全和虚拟化等领域，对 K8s Secret 有着深入的研究和探索。\nK8s Secret 的安全问题 根据 Kubernetes 文档，Secret 是 K8s 中存储所有敏感信息的对象。事实上，如果敏感信息直接存放于 K8s 的 Pod spec 或镜像中，不仅管控困难，而且存在较大的安全隐患。因此，K8s 通过创建、管理、应用 Secret 对象，可以更好地控制敏感信息的用途，并降低其意外暴露的风险。\n秦凯伦称，虽然引入 K8s Secret 对象，这在一定程度上降低了意外泄露的风险（更多地是通过集中式的管理），但是 K8s Secret 对象自身的安全性，“社区默认方案中仍存在许多安全问题”。\n一般来说，K8s 中，Secret 数据以纯文本的方式存储在 etcd 中，默认只有 base64 编码，未经加密。同时，共享该文件或将其检入代码库，密码容易泄露。\n社区解决方案的不足 针对此问题，K8s 社区提供了基于 KMS 的 K8s Secret 加密方案，谷歌云、AWS 和 Azure 均支持该方案。他说，“这虽然解决了 etcd 中 Secret 明文存储问题，但依然有一些问题。”\n Secret、加密 Secret 的密钥在内存中明文存放、易被攻破； 攻击者可以假冒合法用户，调用解密接口，窃取密钥；  密钥一旦泄露，将导致所有数据的泄露，从而引起用户对整个系统的信任崩溃。“为此，社区和一些公司尝试为该方案中的 Plugin 加上基于硬件的安全保护，从而提升攻击难度。但对某些特定用户来说，保护的覆盖面和程度依然不够”。\n实际上，我们可以从 K8s Secret 的整个生命周期来看：\n Secret 的生成及访问 Secret 的身份证书明文存放在用户侧内存中，用户侧环境复杂，容易被攻击者攻破； 加密 Secret 的密钥的生成、cache 等在 K8s API server 中明文存放在内存中，安全根易被窃取或破坏； 与 KMS 交互的 Plugin 的加解密接口无法防止攻击者假冒，存在泄漏风险； Secret 在 Node 中消费，依然明文内存存放，暴露出一定攻击面；  在秦凯伦看来，理想中，对 K8s 中 Secret 的保护程度应该考虑其整个生命周期的安全、可信，做到端到端的安全防护。\n蚂蚁集团的探索 为此，他们基于 TEE 技术，将 K8s Secret 整个生命周期和端到端使用过程中的关键组件、步骤保护起来。整体方案大致如下：\n 将 API Server 端与 KMS 交互的 KMS Plugin 用 TEE 保护，在保障了 Plugin 中根密钥（安全根）、数据加密密钥无泄漏风险的前提下，降低了性能开销； 将 API Server 端的 KMS provider 用 TEE 保护，避免数据密钥及 Secret 在任何时候明文直接暴露在内存中；同时，通过 TEE 的本地证明机制能够认证解密数据密钥接口的调用者，防止攻击者假冒，确保密钥的安全； 将用户端的 kubectl、kubeconfig 等使用 TEE 保护，一方面 kubeconfig 不落盘同时被硬件保护，提升了安全水位；另一方面，用户的 Secret 通过安全信道直通到 TEE 中进行处理，避免了直接暴露在内存中，规避了被恶意窃取的风险，且用户对 API Server 进行 TEE 远程证明，可以帮助用户确信他正在把自己的 Secret 托付给可信的软件实体（没有含有故意泄露用户秘密的恶意逻辑），建立对 API Server 的信任； 将 Node 端的 kubelet 中 Secret 的消费过程用 TEE 保护，进一步避免了 Secret直接暴露在内存中，规避了被恶意窃取的风险；  秦凯伦向 InfoQ 记者指出，“这种方案是基于 TEE 的端到端 K8s Secret 保护，还引入 LibOS 技术，实现 TEE 保护对用户、开发者和运维团队完全透明。”\n据悉，KMS Plugin 和 TEE-based KMS Plugin 没有标准和开源的社区实现，因此他们设计并开发了自己的 KMS Plugin，并在灰度发布、应急处理、监控管理等方面进行了生产增强。“在与 TEE 结合的过程中，我们为了应对 SGX 机型存在的性能问题，提供了 standalone 和服务化 KMS Plugin 两套方案”。\n同样，TEE-based kubectl 也没有标准和开源的社区实现，他说：“我们基于 kubeproxy 开发了自己的安全 kubectl，实现了 kubeconfig 对用户透明、与用户身份绑定、不落盘并采用TEE保护内存安全等设计目标。”\n此外，考虑到 TEE 保护的易用性、可靠性、可扩展性和可维护性等，他们在评估多套方案后，引入了由蚂蚁开源的 Occlum LibOS，屏蔽了 TEE 对用户、开发者和运维团队的影响，大大降低了 TEE 开发的门槛和成本。\n在秦凯伦看来，K8s 作为蚂蚁大规模容器集群的管控根基，应用基于 TEE 的端到端 K8s Secret 保护防护方案，增强了其自身安全和可信，提升了蚂蚁核心管控平面的安全水位，“这对于金融场景下高标准的数据安全和隐私保护来说不可或缺”。\nK8s 相关阅读  备战双 11！蚂蚁金服万级规模 K8s 集群管理系统如何设计？ Kubernetes: 微内核的分布式操作系统 开箱即用的 Java Kubernetes Operator 运行时 深入Kubernetes 的“无人区” — 蚂蚁金服双十一的调度系统 深度 | 蚂蚁金服自动化运维大规模 Kubernetes 集群的实践之路  ","date":1597215600,"description":"K8s Secret 面临着哪些安全问题？这些安全问题会带来什么影响？社区提供的解决方案存在哪些不足？","dir":"blog/antgroup-k8s-security-protection-of-cluster-sensitive-information/","fuzzywordcount":2000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"39e435e749635a88bce9e36771e5b2e2","permalink":"/blog/antgroup-k8s-security-protection-of-cluster-sensitive-information/","publishdate":"2020-08-12T15:00:00+08:00","readingtime":4,"relpermalink":"/blog/antgroup-k8s-security-protection-of-cluster-sensitive-information/","summary":"在 Kubernetes 中，Secret 显得尤其重要。因为它是 K8s 中存储所有敏感信息的对象。据悉，这些敏感信息包含密码、集群的证书、OAuth token、ssh key","tags":["Kubernetes"],"title":"蚂蚁是如何改进 K8s 集群敏感信息的安全防护的？","type":"blog","url":"/blog/antgroup-k8s-security-protection-of-cluster-sensitive-information/","wordcount":1958},{"author":"SOFA 团队","categories":"SOFAStack","content":" PS：阅读本文大约需要 15 分钟，或者您可以选择直接拉至文末投递简历，加入云上江湖。\n 有人说，历史是由懒汉推动的。\n科技的演进史，其实就是人类不断偷懒的过程。我们懒得浪费体力，于是有了蒸汽机；我们懒得动笔演算，于是有了电子计算机；我们懒得随身携带现钞，于是有了线上交易和无接触支付……程序和信息成为这个时代的基底，服务和应用围绕着我们的指尖打转。\n我们从网络上索取一切，海量的数据和代码在赛博空间里奔流不息。\n突然有一天，构筑代码世界的工人们也犯懒了。为首的“懒汉”开始思考，能不能把一些通用的代码模块打包起来，供给上层随时取用，这样就省下了重复“造轮子”的力气，让敲代码也成为一种模块化的工作？\n这一“偷懒”，就偷出了一个新概念：中间件。\n无人探索的道路 对普通人来说，“中间件”是一个很遥远的词汇。\n从技术层面来讲，中间件是介于基础设施和业务系统之间的特殊软件。程序员们别出心裁地构思了各种比喻：有人说它是建筑工地上的“预制件”，让工人不必从头开始搅拌水泥；有人说它是整合货源的“中间商”，让商家免于一次次询价比价的操劳……\n“基础设施和业务系统之间，有很多通信和集成方面的要求，让每个业务系统都去做一遍是很浪费人力的。”蚂蚁集团高级产品专家马振雄这么说，“大家都有这样的诉求。”\n时势造英雄，SOFAStack 在蚂蚁集团应运而生。\n它诞生得悄无声息，初衷只是为了“解救”支付宝。那还是青涩年代的支付宝，没有琳琅满目的蚂蚁森林、花呗和健康码，用4个“一”就能概括它的全部：一个简单的应用，装在一台应用服务器上，使用一个数据库，服务一个大客户——淘宝。\n简单、轻快、便捷，这个系统支撑了支付宝从2004年到2006年早期的发展。但是随着交易量的攀升、业务的复杂化，支付宝很快遭遇了成长中的阵痛。\n“从刚开始几十个人，后来几百人，到现在几千人的技术团队，在不同规模下的研发方式和组织方式都是不一样的。”蚂蚁集团高级技术专家黄挺说，“人一多，你发现不同的人写的代码会不一样，冲突也越来越多。”\n概而言之，研发效率出现了问题。\n如果说从前的支付宝是一间平房，如今则要发展成一座城市。而每搭建一座建筑，工人都必须从头开始烧制砖块、搅拌水泥——没有挖掘机，没有液压锤，一切从手无寸铁开始，对以“建设城市”为己任的团队来说，这是完全不可接受的。\n举个例子，当时支付宝的一个电子钱包系统 iWallet，每次启动需要五六分钟，足够开发人员下楼抽一支烟。如果发现错误，就得修改后重新启动，开发人员每天深陷在代码编译和重启的“死循环”之中。\n究其原因，就是因为 iWallet 系统包含了几十个工程，有十多个团队并行开发。支付宝原本的系统无法支撑这么复杂的业务逻辑，也难以让那么多工程师在一起并行工作，大家把它称为 monolithic——庞大的单体系统。\n支付宝的诉求显而易见：第一，希望成百上千个项目并行进行，每个工程师可以不受干扰地工作；第二，当业务逻辑增加的时候，系统的复杂度不要成指数级上升。 它需要一套能够力挽狂澜的“中间件”。\n2006年，契机来临。技术团队在这一年开了一连串的会，会议的核心议题只有一个：决定支付宝未来的技术架构。团队内部分成两派：第一派提议向银行老大哥学习，走集中式架构的老路；第二派则认为分布式架构才能支撑未来的交易支付系统，而且不是客户端/服务器时代那种小规模架构，是互联网时代的超大规模分布式架构。\n毫无疑问，这是一条无人探索过的道路。\n当然，你知道阿里人的秉性，退缩和守成从来不是他们的标签。经过长达一年左右的思考和论证，技术团队果断驶入第二条赛道。2007年起，支付宝率先启动了对交易系统、商户系统、会员系统、支付清算系统的改造，一个全新的架构正在孕育之中。\n这套分布式架构就叫“SOFA”。\n为什么叫这个名字？其一是源于当时正火的“SOA”概念，即 Service-Oriented Architecture，“面向服务的架构”，在此基础上加入金融业务，就构成了 SOFA 的全称：Service-Oriented Fabric Architecture。\n其二则是开发者的私心，“希望能够像沙发（Sofa）一样，让工程师可以非常爽地工作。” 从“连接器”到“工具库” 什么是 SOA？用偏技术的语言表述，就是把企业的 IT 系统以“服务”的方式重新组织，再通过“服务总线”连接起来，形成可插拔式的企业 IT 架构，这个架构就是 SOA。\n你或许觉得这个释义很难懂，没关系，因为在那个年代，SOA 纯粹只是一套面向传统企业 IT 架构的思想，换句话说，一套理论框架罢了。\n你问业界具体的成功实践？抱歉，没有。\n初次试水，蚂蚁的“探路者”们走得非常谨慎：第一代 SOFA 只解决两个问题，一是充当一个类似于“胶水”、“连接器”的机制，把分布式系统连接成整体；二是做到每一个服务组件化，让每个工程师专注做好各自的组件，最后把组件拼装在一起成为“服务”，再把“服务”拼装在一起组成整个系统。\n用黄挺的话来说，“SOFA 能够隔离出一些不同的模块，由不同的人去做开发，每个人有了更加细致的分工，不会跟别人出现太多的交叉。”\n第一代 SOFA 清晰地定义了团队之间的边界，何时分工协作，何时紧密联合，安排得明明白白。黄挺举了个例子：简单的一次转账业务，系统需要调用用户的通讯录，调用账务相关的子系统——可能还得去问银行，账户余额到底够不够？整个流程涉及到非常复杂的系统交互，这些由不同团队开发和运维的系统，怎样才能高效交互、稳定完成每一笔业务呢？这就仰赖 SOFA 从中协调和沟通了。\n燃眉之急解决了，但初生的分布式中间件 SOFA 并不能处理所有问题。它还需要打怪升级，积累经验，向下一代、再下一代演化。\n无人探索的道路上没有先驱者，只有野蛮生长的技术难题在横冲直撞。\n在 SOFA 的加持下，支付宝一边拆分金融业务系统（后来的业务中台）一边拆分底层 IT 系统（后来的数据中台和计算中台），在拆分过程中还要应对历年双十一的海量数据冲刷，以及不断涌现、千奇百怪的技术问题。甚至在解决分布式服务一致性问题时，由于业界提出的两个 SOA 事务标准都无法支撑支付宝核心系统的交易量，团队干脆一狠心一咬牙：现有的标准都不可行，要不我们自己提一个吧！\n逢山开路，遇水搭桥。很难说清 SOFA 这些年来的演进中，他们遭遇过多少类似的阻碍，又有多少奇思妙想和技术实践沉淀下来，最后凝练成 SOFA 内部的几行代码。\n他们在无人区设下哨塔，漫漫长夜被灯火点亮。\n第一代 SOFA，做到了模块化。\n第二代 SOFA，完成了服务化。\n第三代 SOFA 的亮点，则是被誉为“蚂蚁黑科技”的单元化，“异地多活”架构让服务器资源水平扩容的难度大大下降，保障了用户的每一笔订单平稳顺滑。团队坦诚，面向超大规模互联网金融交易的分布化改造，单元化这一技术构想完全是被业务倒逼的，业界没有先例可循。\n“我们找到过一些论文、一些概念，但以支付宝这么大的体量，没有人确定这事儿真的能做成。”团队成员感慨。\n就这样，随着支付宝架构的逐次优化，SOFA 也在不断迭代和成长。从最初仅是一个简单的框架，到后来强化通讯性能、提升容灾效率、建设异地容灾架构、单元化改造、添加 LDC 逻辑数据中心项目……SOFA 羽翼 …","date":1597042800,"description":"从初试锋芒到大展拳脚，从无人区的前哨到数字化转型的领航员，云上自有江湖，欢迎加入云上江湖","dir":"blog/antgroup-sofastack-rivers-and-lakes-on-the-cloud/","fuzzywordcount":8900,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"dc1065f8e3a2e016a6fc8750bbfab2c2","permalink":"/blog/antgroup-sofastack-rivers-and-lakes-on-the-cloud/","publishdate":"2020-08-10T15:00:00+08:00","readingtime":18,"relpermalink":"/blog/antgroup-sofastack-rivers-and-lakes-on-the-cloud/","summary":"PS：阅读本文大约需要 15 分钟，或者您可以选择直接拉至文末投递简历，加入云上江湖。 有人说，历史是由懒汉推动的。 科技的演进史，其实就是人类不断偷","tags":["SOFAStack"],"title":"蚂蚁 SOFAStack：云上自有江湖","type":"blog","url":"/blog/antgroup-sofastack-rivers-and-lakes-on-the-cloud/","wordcount":8849},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n SOFAStack 官网：https://www.sofastack.tech SOFAStack：https://github.com/sofastack  每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动\n我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@丁浪 提问：\n 这个跟 TCP 长链接的心跳没根本区别啊！也只能保证链路上的通畅，应用僵死或者苟延残喘了可能发现不了，可以补充从注册中心去主动探测 URL，反正现在 SpringBoot 和 SOFABoot 应用都可以开启 healthcheck 的 endpoint，为啥不从注册中心发探测请求，反正都有 healthcheck 的 endpoint。链路上的保活那只是基本生存需求，稍微高级一点就不行了，应用僵死或者苟延残喘那种可能还有心跳的。我看你们把这个问题交给 RPC 框架去做了，让 RPC 框架去做故障剔除和容错。  A：SOFARegistry 目前设计是比较依赖网络连接的，网络连接只要出发了断链事件（这个目前监听是靠 Netty 的事件通知过来的）就会进行数据清理，这个敏感性也决定了服务发现比较快，但是对于抖动和其他大面积不稳定情况处理确实显得不足。我们说的 RPC 框架剔除是对于经常性的链接不通地址采取自动降级不进行调用处理，至于 Spring 那种心跳检测机制，我们开始实现也考虑过，因为这个健康检查机制和网络断连触发的敏感性差别较大，健康检是定期轮训的可能确定服务下线没有这么快速发现，所以没有采用，后续也想过兼容两种模式解决这个断链处理，引入类似 ZK 那种 Session 过期等机制可以在快速发现和稳定性做一个取舍。\n 那种应用进程僵死、较长时间 fullgc 之类的，长链接心跳还在注册中心发现不了流量过来就有问题的，RPC 框架的剔除机制我个人认为只能是种兜底降级。我目前是结合 K8s 探针去请求应用的 healthcheck 路径的，K8s 健康检查不通过就会杀进程重启 Pod，这样注册中心也会感知到 RPC 流量也就剔了。\n SOFARegistry：https://github.com/sofastack/sofa-registry\n2、@倪美俭 提问：\n 这是 AT 模式，store:db，rollback 的交互图，麻烦帮忙瞅瞅有问题吗？  A：是的，一阶段都是提交的，二阶段如果是回滚就会把之前的本地 commit 回滚掉。\n 这种场景是否要优化下，直接发起二阶段回滚，就不再进行这个本地事务一阶段的提交呢？这里为什么会进入到本地事务的 commit 方法里，而不是 rollback 方法里呢？\n A：这种你把本地的事务注解加到全局事务注解下面就好了，这样发起方所在的本地事务是直接走 rollback，其余参与方才是二阶段决议通知下来。\n 强一致性需求的场景，Seata 里只能用 XA，但 XA 是依赖数据库本身对 XA 协议的支持来实现的，那是不是这种模式下性能上会比 LCN 要逊色一些呢？\n A：首先 LCN 的原理是通过 connection 的代理，使之做空提交，二阶段决议后，把 hold 住的 connection 进行真正的 commit 或者 rollback，然而这个方式的隔离性交由本地事务来实现，因为 connection 未提交，所以事务还未提交，强依赖了本地事务。其次除非你的服务不会宕机，否则不建议你使用 LCN 模式，因为如果在二阶段决议后，宕机了一个参与者，那么 LCN 是无法恢复之前的数据，导致数据丢失。\n而 XA 你可以认为他跟 LCN 也很像，但是 LCN 面对的是数据源连接，而 XA 你会发现这个才是由数据库真正意义上去支持的一个协议，即使宕机了，Seata XA 也是做了 XA 的预提交，持久化提交数据在数据库层面，但未真正提交，从而可达到宕机后重启也可以提交事务。\n这是我做在 Seata 中 LCN 原理实现的 PR：https://github.com/seata/seata/pull/2772 ，你可以阅读下，很容易发现他的缺陷，LCN 的性能高是基于啥也基本没干，就多了个几个 RPC 通信的消耗，无需解析 SQL，做镜像校验，全局锁解锁等操作，他仅仅只是把本地事务的提交延迟到其余的参与者都完成了业务并且没发生异常的情况下。看过这个 PR 或者 LCN 的源码后，你就会真正的理解为什么 LCN 说自己不产生事务，而是事务的协调者而已。\n 去年看过 LCN 的源码，它也是代理了数据库连接，在一阶段会 hold 住所有的数据库连接，并不真正提交，二阶段会全部一起提交或回滚，那么有参与者宕机的话不应该会全部回滚吗？\n A：因为是基于本地连接的回滚，连接断开会自动回滚，所以即使二阶段决议形成提交时，若应用或网络出问题，连接断开就自动回滚了，不能保证极端一致性。 Seata：https://github.com/seata/seata\n本周推荐阅读  少年五年升阿里 P8，他如何从低谷登上“光明顶”？ 生产级高性能 Java RPC 框架 - SOFARPC 系列内容合辑  SOFA 项目进展 本周发布详情如下：\n1、发布 MOSN v0.15.0 版本，主要变更如下：\n 新增 UDP Listener 的支持； 新增配置扩展能力，Dubbo 服务发现可通过扩展配置扩展，支持 Yaml 格式的配置解析； 新增流量镜像功能的扩展实现； 支持了更多路由配置； Skywalking 升级到 0.5.0 版本； 针对 Upstream 与 XProtocol 进行了优化与 Bug 修复；  详细发布报告： https://github.com/mosn/mosn/releases/tag/v0.15.0\n同时，恭喜**邓茜（@dengqian）**成为 MOSN Committer，感谢她为 MOSN 社区所做的贡献。\n2、发布 SOFARPC v5.7.5 版本，主要变更如下：\n 修复日志打印的问题；  详细发布报告： https://github.com/sofastack/sofa-rpc/releases/tag/v5.7.5\n社区活动报名 GIAC（GLOBAL INTERNET ARCHITECTURE CONFERENCE）是面向架构师、技术负责人及高端技术从业人员的年度技术架构大会，是中国地区规模最大的技术会议之一。蚂蚁集团也受邀进行 CloudNative(云原生) 的主题分享。\n 分享主题： …","date":1596783600,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20200807/","fuzzywordcount":2700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"3ae77ff6536d0104b38d51679b7f078b","permalink":"/blog/sofa-weekly-20200807/","publishdate":"2020-08-07T15:00:00+08:00","readingtime":6,"relpermalink":"/blog/sofa-weekly-20200807/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | MOSN \u0026 SOFARPC 发布、MOSN 社区活动报名","type":"blog","url":"/blog/sofa-weekly-20200807/","wordcount":2600},{"author":"陈伟荣","categories":"智能监控","content":" 电影《太空旅客》里，无人驾驶的阿瓦隆号飞船去往家园2号要经历120年，飞船的顺利抵达必须依赖一套高端智能运维系统。在蚂蚁，技术风险部的智能监控就好比那个智能运维系统，而智能监控团队便是背后那群看不见的守护飞船的人。\n 2019年双十一的凌晨三四点，阿里西溪园区附近的某家网咖里门客冷清，只有几个神色淡定的青年小伙聚在一排座位上愉快地进行 DOTA 游戏， 他们时不时看一眼手机上发来的消息，像是在守着什么不敢掉以轻心，但脸上又流露出胜券在握的信心。\n就在几个小时前，这群看似“不务正业”的网咖少年还坐在阿里双十一最核心的作战室“光明顶”，与阿里众大佬高管一起值班，助力双十一决胜千里。\n他们正是蚂蚁集团技术风险部智能监控团队。\n对于阿里人来说，“光明顶之战”为每年大促中的巅峰一战，能够登上“光明顶”的非泰山北斗即拥有超强武功的高手。作为该团队主力之一的陈伟荣说，光明顶上各路阿里大神、大佬汇聚一堂，每年的双十一就是智能监控团队的“高光时刻”。\n从象牙塔走向“光明顶” 在蚂蚁技术大事记上，智能监控团队于2012年就曾被留名：首次实现秒级交易监控。之后，他们每隔一段时间就会有技术突破。2014年至2016年期间，蚂蚁监控就用一套 xflush 系列产品成功走出蚂蚁实现与阿里集团监控团队的合作，为当时的淘系赋能。之后的 sunfire 监控、新一代阿里集团网络监控与 IDC 监控均是在此基础上迭代而来，并且沿用至今。\n这期间，一位青涩少年正从象牙塔走向阿里。他就是陈伟荣，2015年以应届毕业生身份加入阿里监控团队成为一名工程师。\n和很多刚毕业的同学一样，陈伟荣对互联网公司的技术体系并不熟悉，彼时他眼中的监控团队更像是一个运维工具组，日常工作就是服务器上看看日志，看看 CPU、内存指标，再做下数据展现就完事了。相较于消息中间件、数据中间件、虚拟化、块存储等各种基础技术团队相比，初入职场的陈伟荣偶尔也会觉得智能监控好像并没有那么高端大气上档次。因此才刚工作几个月，他就判定自己在监控团队肯定呆不了多久就会转岗。\n但是随着进一步深入工作领域，他发现大家工作对标的是各类流式计算，加之团队重视底层引擎研发，在对计算框架和时序存储研究一番后，陈伟荣意识到团队在做的事一点都不比其他基础技术团队简单：这是一个非常典型的垂直领域大数据应用，技术和业务上都非常具有相当挑战性。\n在技术层面上，实时、稳定、低成本、高精度都是对监控的要求，这些约束条件做到一点两点不难，但是要同时做到，极难。但陈伟荣所在的团队就是落地了这样一个高度稳定，秒级延迟，PB 级吞吐的监控平台，他透露后面团队还将重点发力算法和智能化能力。\n2016年发生了很多让陈伟荣迄今难忘的事，有一些事情的影响至今存留。\n那年支付宝新春红包登上了央视春晚，春晚直播屏幕前是全国人民一双双充满期待的眼睛。对于春节红包项目组的技术同学来说自然是严阵以待、不允许有丝毫差池。入职仅半年的陈伟荣有幸和团队其他精兵强将一起加入项目组，承担实时数据计算部分的任务，他主动提出要做项目内相对复杂的内存缓存部分研发。\n但代码写出来后陈伟荣被师兄狠狠痛批了。本来对于自己的技术和工作态度都很有信心的陈伟荣看到师兄一边改 bug 一边骂、一副恨铁不成钢的架势，心中的底气彻底被击碎。\n此后，少年卸下傲气，行路时步步夯实。\n2016年的双十一如约而至，这是陈伟荣在监控团队的第二年，面孔依旧很新，但是双十一活动却已经迎来了第八年。恰逢又一年的光明顶之战，团队却正好缺位，陈伟荣主动挺身而出，承担起阿里16年双十一监控系统稳定性负责人的角色。\n那次双十一，陈伟荣首次挑大梁，最终拼尽全力不负众望完成任务。双十一交易巅峰来临的那十几分钟也成为陈伟荣至今回忆起来最难忘的一段时间。据后来公布的数据了解到，2016年的双十一支付宝支付峰值已达到12万笔/秒，全天交易量达十亿，但是没有一笔交易异常。\n“平时研发中只要我认定这个事情从长期，或者更高视角看能帮助到团队和用户，我就愿意去做一些非常危险的，甚至短期都看不到收益的研发工作，”陈伟荣说。\n2017年，陈伟荣从阿里集团转到了蚂蚁集团，随后逐步切入工作，带领着蚂蚁技术风险部监控技术中台，负责数据的采集链路和实时计算的架构，并在此基础上构筑监控的数据服务体系。猛将加持，蚂蚁监控团队持续发力，2018年后，他们便结合自身的定位和业务目标，重新审视监控这个领域，又推出了 Antmonitor 系列的监控产品，现已发展到了2.0版本。 五年升P8，回首依然是少年 十年前，高考在陈伟荣生命里落下帷幕。只不过这场尽力准备了三年的考试，结果并不如意。\n高考成绩出来后陈伟荣大失所望，比正常发挥时几乎掉了一个层次，最后被南开大学德语专业录取，几乎等同于被调剂。高考后的暑假，难以接受打击的陈伟荣一度靠游戏度日。在复读和将就之间纠结了很久后，最终他决定向前看，并开始着手调研和规划大学的学习计划，为转专业作准备。\n高考失意，大学时奋起直追，陈伟荣通过各种努力走出了一条独特的发展道路：从文科的德语专业到软件工程专业，期间还修了金融学学位。\n毕业前的校招季，不少互联网公司开始招实习生，陈伟荣把简历投递给了阿里。但那时他心里更想走的是继续出国深造的路，所以当年投的简历更多是无心插柳之举。\n经过几轮紧张的现场面试后，没想到第二天阿里面试官就电话通知陈伟荣面试通过了。人生就是这样不可预料，同期报名的同学中仅他一个临时起意投递简历的被录取了。来了阿里后，陈伟荣一下子被阿里技术体系的先进性吸引了，实习转正后，他便决定不再继续读书直接工作了。\n他不知道自己本科拼命几年扭转的人生方向是否正确，只携一身热血前往，不回头。\n从2015年加入阿里开始，陈伟荣一直在监控领域做事，但是工作范围逐渐放大，从最初采集 agent 研发到逐步深入理解整个数链路、开始掌握数据技术架构，到现在能带领团队推进技术架构演进，他不断挑战自己的极限。\n五年时间弹指一挥间，说起过去，陈伟荣的回忆里酸甜苦辣翻涌。但要说最开心的时刻，他觉得是今年年初完成 pontus2.0 项目研发并最终上线支撑业务监控场景这个事。这次的技术升级突破了先前的监控技术框架，真正统一了监控数据层模型为未来数据建设铺平了道路，大家一起攻克艰难让项目按时落地，过程中的不易最后都变成了开心的回忆。\n团队里同事们年龄相仿，组队打篮球或者去网吧开黑打 DOTA 成为大家最放松的时刻，或嬉笑怒骂，或相互扶持，抛去工作上的对接合作与依赖关系，他们可以聊天南地北，聊海阔天空……\n最近，有一件事让 92 年的陈伟荣比较开心，那就是他专门定制的电吉他终于到货了。\n原来，这位少年还是一位重金属音乐爱好者。说着，他给我发来一个 Arch Enemy 在 2016 年 wacken 音乐节现场的视频链接，还提醒我要关小声音听。\n“我去过两次这个乐队在上海的 live，还跟主唱的那个妹子击过掌。”\n我眼前浮现这样一幅画面：“光明顶”少年与 Arch Enemy 歌曲中那些真实直白歌词达成了共识——人生也要“不断突破，向死而生”。\n","date":1596438000,"description":"坐在光明顶的少年。","dir":"blog/five-years-to-ali-p8/","fuzzywordcount":2800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"80f2d7c63c3dfb1ee561e79745630a68","permalink":"/blog/five-years-to-ali-p8/","publishdate":"2020-08-03T15:00:00+08:00","readingtime":6,"relpermalink":"/blog/five-years-to-ali-p8/","summary":"电影《太空旅客》里，无人驾驶的阿瓦隆号飞船去往家园2号要经历120年，飞船的顺利抵达必须依赖一套高端智能运维系统。在蚂蚁，技术风险部的智能监","tags":["智能监控"],"title":"少年五年升阿里 P8，他如何从低谷登上“光明顶”？","type":"blog","url":"/blog/five-years-to-ali-p8/","wordcount":2786},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n **SOFAStack 官网: **https://www.sofastack.tech **SOFAStack: **https://github.com/sofastack  每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n@刘明 提问\n 请问，分支事务在回滚过程中，服务器宕机了，重新启动后，TC 如果发送过来的回滚请求，是否还能继续回滚？\n A：可以。\n 是使用 XA 模式的 Oracle 数据库，分支服务器即使宕机了，回滚日志还在 Oracle 上是么？\n A：是的，xa_prepare 在 DB 实现 XA 层面做了持久化，MySQL 要求 5.7.7+。\n 刚测试了下 Oracle 的，xid 就像一个字符串 key 一样，任何时候只要告诉 Oracled 对 xid 做 rollback 都可以成功。我以为需要在 start/end 同一个连接里才行，是我理解错了。\n A：lcn 才需要这样，xa 不需要一个连接，所以 lcn 那种宕机了数据就没了。\n LCN 没有了解，他难道不是基于数据库自带的 XA 实现的？\n A：lcn 是 lcn 框架的一个原理，就是通过 connection 来统一提交和回滚。\n 我是用 jdbc 直接操作 Oracle 测试的，用 Oracle 的 XAResource。 这个特性是数据库自带的？\n A：XA 协议本来就是由数据库方进行的支持。\n 使用 DatabaseSessionManager 去存储 globalsession，这个 lockAndExecute 方法没有 lock 的逻辑，多个进程在获取 global 会话做超时、重试提交等时，会有资源冲突吗？\n A：多个 TC 会出现资源争抢冲突，倒是不影响一致性。\n 多个 TC 会对同一个 XID 做 retryCommitingg 操作吧，2个 TC 会做2次，3个 TC 会做3次？\n A：是的，没有分布式任务调度。\n 2个事务分支，TC 在发起提交请求后，分支一正常提交，分支二网络波动没有收到提交请求。 这个时候 TC 会尝试重试提交。 如果一直重试失败，会因为全局事务 timeout 发起回滚请求吗？\n A：提交一阶段就是持久化了，不会影响。\n 但是全局事务会有个超时检查，超时的事务处理方式就是回滚，会不会这样？分支二的提交重试一直不能成功，最后global 会话超时的吧？这时候分支一已经 commit，再做 rollback 肯定不行了。\n A：二阶段结果已经出现了，已经决议好了的，二阶段的提交只不过是空提交而已，异步的。\n 二阶段 TC 成功发送 commit，RM 接收到了后，执行 XA 提交动作，这时候数据才真正可以看到，如果 RM 接收不到 commit 请求，他本地数据时没有提交的吧？\n A：XA 模式确实是这样的。\n 那参与者中有人收到 commit 请求了，有人没收到，最后 global 超时，是不是也没法回滚了？\n A：XA 一阶段只是做了预备数据的持久化，保持操作，并没有真正入库，等到 commit 的时候才会入库，每个模式2阶段都不一样。 Seata：https://github.com/seata/seata\n本周推荐阅读  Kata Containers 2.0 的进击之路 Kata Containers 创始人：安全容器导论 Kata创始人王旭：远程工作可以从开源中借鉴哪些经验？  SOFA 项目进展 本周发布详情如下：\n1、发布 SOFABoot v3.4.2 版本，主要变更如下：\n 修复 ServiceComponent 和 ReferenceComponent 的健康检查结果不包含抛出的内部异常； 修复默认情况下 SOFA runtime 忽略组件抛出的内部异常； 增加引流操作的阻断性，fail fast；  详细发布报告：https://github.com/sofastack/sofa-boot/releases/tag/v3.4.2\n2、发布 SOFAJRaft v1.3.4 版本，主要变更如下：\n 升级 SOFABolt 到 1.6.2（支持异步非阻塞建连机制）； 移除对 log4j 的直接依赖； RouteTable、RegionEngine、StoreEngine 实现 Describer 以提供更详细的调试信息； 修复 snapshot 文件创建漏洞，禁止跳出 snapshot 目录之外创建文件；  详细发布报告：https://github.com/sofastack/sofa-jraft/releases/tag/1.3.4\n社区活动报名 GIAC（GLOBAL INTERNET ARCHITECTURE CONFERENCE）是面向架构师、技术负责人及高端技术从业人员的年度技术架构大会，是中国地区规模最大的技术会议之一。蚂蚁集团也受邀进行 CloudNative(云原生) 的主题分享。\n 分享主题：云原生网络代理 MOSN 的进化之路 **分享嘉宾：**王发康（毅松）蚂蚁集团 可信原生技术部 技术专家 **背景介绍：**网络通信代理 MOSN 在蚂蚁集团的 Service Mesh 大规模落地后，通过对接 UDPA 打造为 Istio 的数据面之一，增强 MOSN 服务治理及流量控制能力，对接云原生周边组件，实现 MOSN 开箱即用，MOSN 成为云原生 Service Mesh 的标准 Sidecar 之一，从而借力开源，反哺开源。 **听众收益：**可快速基于 MOSN 和 Istio 进行 Service Mesh 实践，了解微服务的发展历程、遇到的痛点以及解决方案，获取 MOSN 的功能特性，解决微服务常见的问题。 分享时间：2020-08-15 13:30-14:30 **活动地点：**深圳 **活动报名：**点击“这里”  ","date":1596178800,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20200731/","fuzzywordcount":2000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"ba067c1a03b386adff832962bb27dd52","permalink":"/blog/sofa-weekly-20200731/","publishdate":"2020-07-31T15:00:00+08:00","readingtime":4,"relpermalink":"/blog/sofa-weekly-20200731/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | SOFAJRaft 以及 SOFABoot 发布、MOSN 社区活动预告","type":"blog","url":"/blog/sofa-weekly-20200731/","wordcount":1961},{"author":"李昊阳","categories":"Kata Containers","content":"Kata Containers 开源项目于2017年底正式启动，其目标是将虚拟机（VM）的安全优势与容器的高速及可管理性相结合，为用户带来出色的容器解决方案。该项目在过去两年取得了哪些进展？下一版本的路线图包含什么特性？首先让我们快速回顾一下 Kata Containers 项目的奋进之路… 缘起：Kata Containers 2013 年，Docker 问世，容器成为热门新事物，全球的开发者为之着迷。也难怪，容器以标准格式封装，将运行于标准操作系统环境上的应用打包，使应用程序可从一个计算环境快速可靠的切换至另一个计算环境，这对于那些想要快速构建、测试和部署软件的开发者而言至关重要。容器具有轻量化、低开销的特性，几乎可以立即被调度和启动，可在任何环境中运行，为微服务提供便利，扩展资源等（以上仅列举了一些流行的优势）。 尽管有许多技术优势，但容器有一个缺点 - 容器与宿主机共享内核，这可能会引发严重的安全漏洞问题。理论上，如果您在单个主机上部署了多个容器，一旦其中某个容器被恶意代码利用，由于共享namespace，该主机上的其他所有容器也容易受到攻击，在这种情况下，可能会对云基础设施整体构成严重的安全威胁。如果您是云供应商，安全威胁可能会扩展到云端客户的数据和业务，这是绝对要避免的。\n图1. 传统容器：主要通过共享内核的 Cgroup 和 Namespace 来达到容器隔离和资源限制的目的\n因此，许多负责大规模容器运行的运维人员将容器“嵌套”在虚拟机中，从逻辑上将其与运行在同一主机上的其他进程隔离开，但在虚拟机中运行容器会丧失容器的速度和敏捷性优势。Intel 和 Hyper.sh（已加入蚂蚁集团）的开发人员意识到了这个问题，同时开始独立研发解决方案，两家公司都希望容器可以摆脱传统虚机的所有包袱，换言之，就是开发“面向云原生的虚拟化”技术：\n 来自 Intel 开源技术中心的工程师在 Intel Clear Containers 项目中运用 Intel Virtualization Technology（Intel VT）技术来强化性能和安全隔离； 与此同时，Hyper.sh 的工程师采用相似的策略启动了开源项目 runV，将容器放在一个安全“沙箱”中，通过支持多种 CPU 架构和管理程序，侧重于开发技术中立的解决方案；  2017年，两家公司将项目合并，互为补充，创建了开源项目 Kata Containers。Intel 和 Hyper.sh 联合开发者社区，希望在各方的共同努力下，兼顾性能和兼容性，在为终端用户提供出色应用体验的同时，加速开发新的功能特性以满足未来新兴用例的需求。Kata Containers 成为 OpenStack 基金会（OSF）除 OpenStack 之外的首个托管项目，该项目于2017年12月在北美 KubeCon 上正式公开亮相，社区座右铭是“快如容器，稳似虚机”。 其实质是，通过 Kata Containers 让每个容器/pod 采用其单独的内核，运行在一个轻量级的虚拟机中。由于每个容器/pod 现在都运行在专属虚拟机中，恶意代码无法再利用共享内核来访问邻近的容器，因此，容器即服务(CaaS)供应商能够更安全的提供在裸金属上运行容器的服务。由于容器之间的硬件隔离，Kata Containers 允许互不信任的租户，甚至生产应用及未经认证的生产应用程序都能在同一集群内安全运行。\n图2. Kata Containers: 每个容器/pod 被隔离在各自的轻量级虚拟机中\n因此，Kata Containers 与容器一样轻便快捷，并且可与容器生态系统无缝集成（包括流行的编排工具，如 Docker 和 Kubernetes），同时还具有虚拟机的安全优势。\n社区进展 Kata Containers 项目成立的第一年，社区主要致力于合并 Intel 及 Hyper.sh 的代码，并在全球的行业活动中介绍该项目独特的硬件隔离方案，这是其他容器运行时所缺乏的功能，同时也邀请了大量的社区开发者共同推进该项目。 Kata Containers 社区如今已经拥有众多的贡献者和支持者，包括来自九州云、阿里巴巴、AMD、AWS、百度、Canonical、中国移动、CityNetwork、戴尔易安信、易捷行云、烽火通信、谷歌、华为、IBM、微软、红帽、SUSE、腾讯、同方有云、中兴、英伟达、Mirantis、NetApp、PackageCloud、Packet、Vexxhost 等许多有影响力公司的开发者。随着社区的不断壮大，该项目正在稳步发展中。 社区成就包括：\n 加入开放容器倡议（OCI）规范，Kata Containers 社区持续与 OCI 和 Kubernetes 社区紧密合作，并在 AWS、Azure、GCP 和 OpenStack 公有云环境以及所有主要 Linux 发行版中对 Kata Containers 进行定期测试； 添加了对主要架构的支持，除 x86_64 外，还包括 AMD64，ARM，IBM p- 系列和 IBM z- 系列等架构； 无缝集成上游 Kubernetes 生态系统，Kata Containers 现在可以立即连接到大多数开箱即用的 Kubernetes 网络； 删除不必要的间接层，社区已经去掉了 kata-proxy 组件，并在 KubernetesSIG-Node 开发者和 containerd 社区的帮助下引入了 shim-v2，从而减少了 Kata Containers 辅助进程的数量； 降低开销，提升速度，社区正努力提升启动速度，减少内存消耗，并朝着创建（几乎）“零开销”沙箱技术的目标迈进。为此引入多个虚拟机管理程序，包括 QEMU，QEMU-lite，NEMU和AWSFirecracker。还与 containerd 项目整合，推动建立了 rust-vmm 项目，2019年，社区用 Rust 重写了一个沙箱内的 agent，显著减少了匿名页。总之，社区正通过一系列的改进工作来最大限度地减少开销，通过引入 FirecrackerVMM 将内存开销减少到 10MB，而通过 rust-agent 的合并将 agent 的匿名页从10MB减少到1.1MB； “面向云原生的虚拟化”，与面向虚拟机领域不同，容器领域是以应用为中心的，为了解决这种差异，社区引入了 virtio-vsock 和 virtio-fs，后续将引入更灵活的内存弹性技术virtio-mem；  如需详细了解项目进展，可查看王旭的系列博客：KataContainers: 两年而立 百度智能云的 Kata Containers 应用实践 百度，中国领先的搜索引擎运营商，全球最大的中文网站托管商，全球领先的 AI 公司-正在其百度智能云中大规模（超过 43k CPU 内核！）应用 Kata Containers，包括百度智能云函数计算（CFC）、百度智能云容器实例（BCI）、百度边缘计算等多种实践场景。 百度智能云是百度面向企业和开发人员的智能云计算平台，致力于为各行各业的企业提供一体化的人工智能、大数据和云计算服务。根据 Synergy Research Group 发布 …","date":1595919600,"description":"Kata Containers 项目的奋进之路","dir":"blog/kata-container-2.0-road-to-attack/","fuzzywordcount":4100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"2eaaa668460266fb66b2b44f5611c472","permalink":"/blog/kata-container-2.0-road-to-attack/","publishdate":"2020-07-28T15:00:00+08:00","readingtime":9,"relpermalink":"/blog/kata-container-2.0-road-to-attack/","summary":"Kata Containers 开源项目于2017年底正式启动，其目标是将虚拟机（VM）的安全优势与容器的高速及可管理性相结合，为用户带来出色的容器解决方案。该项目在过","tags":["Kata Containers"],"title":"Kata Containers 2.0 的进击之路","type":"blog","url":"/blog/kata-container-2.0-road-to-attack/","wordcount":4042},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n SOFAStack 官网https://www.sofastack.tech SOFAStack:https://github.com/sofastack  每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动\n我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n@Zhengguang 提问：\n 想问下，默认的 RMClient.init(applicationId, txServiceGroup); 这个方式启动 RM 的时候有个问题，它传递的 resourceId 为 null 也就是说 RM 初始化的时候虽然在 TC 注册了，但是注册的信并非之前断开始后那个 resourceId，所以 RM 重启后并不会立即收到来自 TC 的 retry。 以下是日志，可以看到默认 RM 初始化的时候 resourceIds 是空的： [timeoutChecker_2] INFO io.seata.core.rpc.netty.NettyPoolableFactory - NettyPool create channel to transactionRole:RMROLE,address:127.0.0.1:8091,msg:\u0026amp;lt; RegisterRMRequest{resourceIds=\u0026amp;lsquo;null\u0026amp;rsquo;, applicationId=\u0026amp;lsquo;api\u0026amp;rsquo;, transactionServiceGroup=\u0026amp;lsquo;my_test_tx_group\u0026amp;rsquo;} \u0026amp;gt;\n使用 API 方式，跑的是 seata-sample-api 这个 demo，AT 模式。\n A：1.其实 RMClient.init 的时候，并不会进行注册，真正进行注册的是初始化 DataSourceProxy的 时候。 2.如果注册的时候 resourceIds=\u0026amp;lsquo;null\u0026amp;rsquo;，很有可能你的 DataSourceProxy 没有初始化，也即是数据源没代理成功。\n 是的我观察到的就是这个现象，我这边项目更希望在 API 模式下使用 Seata，所以并没有通过 spring 启动，可能 DataSourceProxy 没有自动初始化，所以这里是不是应该有什么方式可以手动触发 DataSourceProxy 初始化的过程。\n A：手动配置一样就可以了，像这样子：\n\u0026amp;lt;bean id=\u0026amp;quot;dataSourceProxy\u0026amp;quot; class=\u0026amp;quot;io.seata.rm.datasource.DataSourceProxy\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;constructor-arg ref=\u0026amp;quot;dataSource\u0026amp;quot; /\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt;  哦哦，所以我要在 RMClient.init 启动后，马上手动获取一次 DataSourceProxy。Demo 中的这个 DataSourceUtil 要在第一次 getDataSource 的时候才会初始化 proxy，所以我要在 RMClient.init 启动后马上 get 一次数据源就好了， 测试通过。\n Seata：https://github.com/seata/seata\n本周推荐阅读  基于 MOSN 和 Istio Service Mesh 的服务治理实践 再启程，Service Mesh 前路虽长，尤可期许 记一次在 MOSN 对 Dubbo、Dubbo-go-hessian2 的性能优化 云原生网络代理 MOSN 透明劫持技术解读 | 开源  SOFA 项目进展 本周发布详情如下：\n发布 SOFABolt v1.6.2 版本，主要变更如下：\n 支持检查连接并异步创建连接； 支持用户设置 UserProcessor 的 ClassLoader； 修复 URL 对象默认连接数为0导致不创建连接的问题； 修复无可用连接的 ConnectionPool 无法被回收的问题；  详细发布报告：https://github.com/sofastack/sofa-bolt/releases/tag/v1.6.2\n社区活动报名 机密计算（Confidential Computig）是近年来发展迅速的一种安全技术，它利用可信执行环境（TEE）——如 Intel SGX——来保证内存数据始终处于加密状态，因而将安全性提高到前所未有的程度，并赋能了诸多新型应用场景，比如多方联合数据分析、隐私保护的机器学习、保证机密性的区块链合约等等。虽然技术本身令人兴奋，但机密计算对应用开发者有比较高的门槛，令人望而却步。\n针对上面的问题，蚂蚁集团开源了 Occlum 项目，一款使用 Rust 语言开发的、面向机密计算的 TEE OS，可使得任何语言的任何应用程序轻松地移植进 TEE 环境。本次分享既会从用户角度介绍如何使用 Occlum 的轻松开发机密计算应用，也会从技术角度分享 Occlum 技术架构和特色。\nOcclum 网站：https://occlum.io\nOcclum Github：https://github.com/occlum/occlum\n本期主题：《SOFAChannel#18：零门槛的机密计算：Occlum LibOS 使用入门和技术揭秘》\n分享嘉宾：田洪亮（花名：樱桃） 蚂蚁集团技术专家 Occlum 开源负责人\n你将收获：\n 了解机密计算领域的最新进展； 了解 Occlum 的技术架构； 了解使用 Rust 语言开发安全软件的一手经验； 了解如何将创新工作转化为实用系统；  **直播时间：**2020-07-30 19:00-20:00\n**报名方式：**点击“这里”，即可报名\n","date":1595574000,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20200724/","fuzzywordcount":1700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"6efe8af3dfb578bdfd495367e78b60e4","permalink":"/blog/sofa-weekly-20200724/","publishdate":"2020-07-24T15:00:00+08:00","readingtime":4,"relpermalink":"/blog/sofa-weekly-20200724/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | SOFABolt 发布新版本、MOSN 相关文章整理","type":"blog","url":"/blog/sofa-weekly-20200724/","wordcount":1611},{"author":"姚昌宇","categories":"Service Mesh","content":" Service Mesh Webinar 是由 ServiceMesher 社区和 CNCF 联合发起的线上直播活动，活动将不定期举行，为大家带来 Service Mesh 领域的知识和实践分享。\n 本文根据7月22日晚 Service Mesh Webinar#2 有米科技高级后端工程师、MOSN Committer 姚昌宇，线上主题分享《基于 MOSN 和 Istio Service Mesh 的服务治理实践》整理，文末包含本次分享的视频回顾链接以及 PPT 下载地址。\n前言 大家好, 欢迎大家参加第二期 Service Mesh Webinar。本期的分享主题是《基于 MOSN 和 Istio Service Mesh 的服务治理实践》。我是今天的分享嘉宾姚昌宇，来自有米科技，目前在公司也是负责服务治理相关的工作，我本身也是一名云原生爱好者，在空余时间关注和参与 Service Mesh 社区，最近参与了 MOSN 新版本的开发，也是有了很多收获。这次受社区邀请来给大家做这次分享，希望能给大家带来收获。\n今天的分享将从以下几个方面进行：\n 第一部分会简单介绍一下什么是 Service Mesh、Service Mesh 可以给我们带来什么红利以及我参与社区的过程和一些收获； 第二部分是这次分享的重点，我会从一个开发者的角度，说说如何基于 MOSN 和 Istio 去做服务治理，中间会包括 MOSN 源码的分析和 Istio 功能的实操，也是比较多 Service Mesh 爱好者关注的如何落地的问题，比如流量的控制啊、服务监控等等的功能； 第三部分会总结一下今天的分享以及 MOSN 一些近况和未来愿景的介绍；  Service Mesh 简介以及社区共建实践分享 Service Mesh 简介 首先，什么是 Service Mesh 呢？相信这是众多爱好者刚接触 Service Mesh 时的最初疑问。Service Mesh 发展了这么多年，网上介绍和分析的文章也是很多，在这里我也再啰嗦一句。如果用一句话来概括 Service Mesh，我会说，它是一种微服务的通信方案，是不断演进而成的。\n大家都知道，服务端架构经历了一系列的演进，从最开始的单体服务到 SOA，再到微服务，服务间通信也从最开始的无需通信、到集成在代码里、再到胖客户端库，再演进为 Service Mesh 的 network stub 模式，又或者称为 sidecar 模式。\nService Mesh 主要解决了之前的服务间通信方案的几个问题：\n 语言绑定； 升级困难； 重复开发、标准不一；  语言绑定：在将服务治理逻辑抽离到 Sidecar 之前，这些治理逻辑需要集成在代码里面。这就容易导致业务要么要绑死在同一种开发语言上，要么就要相同的逻辑不同语言维护多份。这样既不灵活，维护起来成本也比较大。\n升级困难：企业里的基础设施团队，在升级服务治理逻辑之后，需要推动各个业务去重启他们的服务，这样一个周期通常会拖的非常长，重启过程也会有各种问题，导致线上各个版本的治理功能不一致，落地起来相当费劲。\n重复开发、标准不一：每个公司都会根据他们的实际情况落地微服务，有的会使用各个语言比较成熟的微服务框架，比如 Java 的 Spring Cloud、Dubbo；或者 Golang 的 go-micro 之类的框架。有的团队或者会使用集成组件的方式，在各个语言的基础上，加上一些成熟的服务治理组件，比如 Consul、Zookeeper、Hytrix、Vault 等。通常，通过对接这些组件来抽象出一个类似于微服务控制平面需要一定的开发成本，而且这些框架和组件标准也是不一致的，维护起来也会有不少成本。\n那么，Service Mesh 是如何解决这些问题的呢？\n首先，Service Mesh 架构将服务治理的逻辑抽离到一个单独的 Sidecar 进程中，而 Sidecar 进程是与语言无关的。Sidecar 通过代理的形式劫持业务进程的流量，从而做到与具体的业务开发语言解耦。\n其次，Sidecar 通过边车模式和业务进程部署在一起，但是又与业务进程分离。Sidecar 进程可以随时重启更新，业务进程无需感知这个过程。这样可以加速治理逻辑更新换代的过程，解决了传统服务治理，升级困难的问题。\n最后，Service Mesh 定义了控制面和数据面的概念。控制面提供 UI 给操作者去控制整个集群的流量，数据面，顾名思义就是数据流动的平面，负责接收这些配置信息，表现出对应的代理行为。控制面和数据面通过统一的协议进行通信，也就是 Service Mesh 里的 xDS 协议来交换配置信息。通过这样的方式，理论上实现了 xDS 协议的控制面/数据面可以互相插拔替换，这就统一了标准，解决了第三点重复开发和标准不一的问题。\n社区共建经历分享 那了这么多，那我是如何从关注 Service Mesh 社区，到参与到 MOSN 开源共建的呢？觉得整个过程可以概括成3点：\n 找到组织； 知识积累； 参与贡献；  其实一开始我也是一个初学者，刚接触到 Service Mesh 也会被一大堆不知名的名词砸得晕头转向的，像是 xDS、控制面、metrics tracing 之类的名词。所幸的是，ServiceMesher 的中文社区相当完善和活跃。我相信有了解过 Service mesh 的同学，肯定有加过2个微信 \u0026amp;ndash; 一个就是宋净超宋大的微信，一个就是 ServiceMesher 社区的微信群。也是得益于众多的前辈将 ServiceMesher 中文社区维护的这么好，将各种内部实践分享出去，以及外部一手资讯搬运甚至翻译过来，乃至是这样子的不定期的线上线下分享。这些都是非常好的资源。只要你想去学，就肯定有方法的。而对于新人的疑问，社区里的大神们也是非常乐意解答。\n既然有了目标和资源，那就差去做了。接下来我通过不断的去理解这些新领域的概念，理解它们的含义和背后的设计目的以及应用场景，再加上源码分析和动手实践，慢慢也就搭建起了整个关于 Service Mesh 的知识体系。\n在摸清门道之后，其实参与开发也不是什么难事了。那为什么我会选择 MOSN 呢？其实蚂蚁集团有整个 SOFAStack，也就是金融级云原生架构的开源共建计划，其中有服务注册、流量跟踪、rpc 协议、分布式事务等等的项目。我选择 MOSN 主要是有两点考虑：\n 第一是 MOSN 是使用 Golang 实现的，这一点和个人的技术栈比较吻合； 那第二点，我认为 Sidecar 在 Mesh 的位置是比较关键的。在大型的集群里，上百万的 Sidecar 在集群里互相通信，为业务进程转发处理数据包，其稳定性、性能要求和灵活性都是比较高的；  近期我也参与到了 MOSN 的 Istio Roadmap 开发中，主要目标是将 MOSN无 缝地接入到 Istio 里，成为在里面可以工作的 Sidecar。我主要做的几个功能是pilot-agent 的适配以及一致性哈希负载均衡功能的开发。其实和做业务需求是类似的，首先要知道功能要达到什么目的，然后预演改动的地方，最后实践：fork 一份 MOSN、开发代 …","date":1595498400,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/mosn-istio-service-mesh/","fuzzywordcount":4600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"03b066886bc7e069eca5654ee35e4782","permalink":"/blog/mosn-istio-service-mesh/","publishdate":"2020-07-23T18:00:00+08:00","readingtime":10,"relpermalink":"/blog/mosn-istio-service-mesh/","summary":"Service Mesh Webinar 是由 ServiceMesher 社区和 CNCF 联合发起的线上直播活动，活动将不定期举行，为大家带来 Service Mesh 领域的知识和实践分享。 本文根据7月22日晚 Service Mesh Webinar#2 有米科技高级后端","tags":["Service Mesh","MOSN"],"title":"基于 MOSN 和 Istio Service Mesh 的服务治理实践","type":"blog","url":"/blog/mosn-istio-service-mesh/","wordcount":4565},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n SOFAStack 官网: https://www.sofastack.tech SOFAStack: https://github.com/sofastack  每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@古月 提问：\n 请问 SOFARPC 可以在 Spring MVC 环境 XML 配置使用?老项目 ssm，非 Spring Boot 环境。\n A：可以的。和直接用 SOFARPC 没区别。 SOFARPC 相关 Demo：https://www.sofastack.tech/projects/sofa-rpc/getting-started-with-rpc/\nSOFARPC：https://github.com/sofastack/sofa-rpc\n2、@伍月 提问：\n 工程使用 OperatingSystemMXBean（osBean）类对系统 CPU 情况进行监控。 osBean.getSystemCpuLoad() = -1 ？？？ osBean.getProcessCpuLoad() = -1 ？？？ 有没有人知道是怎么回事。 注：正常情况下 CPU 返回值在 0 到 1 之间。\n A：抛出异常的时候会返回 -1，之前记得 arthas 也会返回 -1。\n 感谢回答。 工程在 Linux 服务器上运行时获取 CPU 数据正常。只是在本地 Windows 上运行时获取 CPU 数据返回 -1。后来百度得知可能由于本地 Windows 用户没有获取系统 CPU 数据的权限。\n Seata：https://github.com/seata/seata\n本周推荐阅读  我们需要什么样的端到端 AI 系统？蚂蚁 SQLFlow 的思考与答案 火了 2 年的服务网格究竟给微服务带来了什么？ Kubernetes: 微内核的分布式操作系统  SOFA 项目进展 本周发布详情如下：\n1、发布 SOFARPC v5.7.4版本，主要变更如下：\n 允许用户设置 Triple 服务的版本； protobuf 编译器升级到 0.0.2； hibernate-validator 升级到 5.3.5.Final； jackson-databind 升级到 2.9.10.5； 修复了 Hessian over triple 不支持基本类型的问题；  详细发布报告：https://github.com/sofastack/sofa-rpc/releases/tag/v5.7.4\n2、发布 Seata v1.3.0 版本，主要变更如下：\n AT 模式支持了像多主键，自动升降级，redis 存储等大量 feature； TCC 模式支持了模式支持 Dubbo 和 SOFARPC 注解调用； Saga 模式支持 Groovy 脚本任务、支持 jackson 序列化、代码重构将内部扩展点 SPI 化； 整体性能得到大幅度提升，修复了旧版本的存量 bug； 本次 release 变动文件数：442，代码变动：+17062 −8419，参与代码 commit 人数：31，合并 PR 数：90，其中：feature：20，bugfix：29，代码优化重构：41；  详细发布报告：https://github.com/seata/seata/releases/tag/v1.3.0\n社区活动报名 Service Mesh Webinar 是由 ServiceMesher 社区和 CNCF 联合发起的线上直播活动，活动将不定期举行，邀请社区成员为大家带来 Service Mesh 领域的知识和实践分享。\nService Mesh Webinar#2，邀请有米科技高级后端工程师姚昌宇，带来分享《基于 MOSN 和 Istio Service Mesh 的服务治理实践》。本期分享可以收获对 Service Mesh 技术以及如何落地有更多的认识。\n**分享主题：**基于 MOSN 和 Istio Service Mesh 的服务治理实践\n**分享嘉宾：**姚昌宇 有米科技高级后端工程师、MOSN committer\n你将收获：\n 了解如何参与到 MOSN 开源社区共建中； 了解如何使用 MOSN 在 Istio 场景下的服务治理实践 ; 了解 MOSN 新版本的功能以及未来远景； 结合 Istio 各个场景的 Demo，分享 MSON 的多协议/私有协议实现；  **直播时间：**2020-07-22 20:00-21:00\n**直播间地址：**关注直播间，7月22日不见不散\n","date":1594969200,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20200717/","fuzzywordcount":1500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"54ea1b69911fe82c9674739a421a0ce5","permalink":"/blog/sofa-weekly-20200717/","publishdate":"2020-07-17T15:00:00+08:00","readingtime":3,"relpermalink":"/blog/sofa-weekly-20200717/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | SOFARPC、Seata 组件发布以及社区 QA 整理、社区直播预告","type":"blog","url":"/blog/sofa-weekly-20200717/","wordcount":1491},{"author":"沈凋墨","categories":"Kubernetes","content":"如今，Kubernetes 已经成为分布式集群管理系统和公有云/私有云的事实标准。实际上，Kubernetes 是一个分布式操作系统，它是 Google 在分布式操作系统领域十余年工程经验和智慧的结晶，而 Google 一直以来都管理着世界上最大的分布式集群，在分布式操作系统领域的研究和认识领先于全世界。因此，2014年发布的 Kubernetes 能在短短几年时间内就超越了诸多前辈，大获成功。\n作为分布式操作系统，Kubernetes（包括其前代产品 Google Borg）的出现远远晚于 UNIX、Linux、Windows 等著名的单机操作系统，Kubernetes 架构设计自然地继承了很多单机操作系统的珍贵遗产，微内核架构就是这些遗产中最重要的一份。在本文接下来的部分，我们将专注于微内核（microkernel）这个概念及其对 Kubernetes 架构的影响。\n什么是微内核？ 在介绍微内核的时候，我们有必要同时回顾一下单机操作系统的历史，以理解其价值所在。本章中以「操作系统」指代「单机操作系统」。\nUNIX 的兴起 电子计算机诞生之后，在上个世纪70年代以前，出现过许许多多的操作系统，DOS、OS/360、Multics 是其中的知名代表，这是操作系统领域的拓荒时代。20年来的拓荒孕育出了伟大的成果：随着 CPU 技术的发展，UNIX 于1969年诞生了，这是一个真正意义上的分时操作系统。\n图片来源：维基百科\n借助新的 CPU 技术的支持，UNIX 将软件系统划分为**内核（kernel）和用户态程序（userland programs）**两部分。内核是一组中断处理程序的集合，把硬件的能力封装为操作系统功能调用（system calls），用户态程序通过系统调用使用硬件功能，用户态程序运行于各自的进程中，所有用户态进程都共享同一个内核，每当系统调用或中断发生，UNIX 便陷入（trap）内核，内核执行系统调用，与此同时，内核中的分时调度算法将决定把 CPU 交给哪个进程，并管理进程的上下文切换。另外，UNIX 把（几乎）所有硬件都封装为文件。UNIX 还提供了一个特殊的用户态程序 shell，供用户直接使用系统，通过内核提供的进程间通信能力，shell让 用户可以把一系列应用程序组合起来，处理复杂的需求，作者称这个设计思想为「KISS」（Keep It Simple and Stupld）。UNIX 的所有设计思想在当时是都是非常了不起的创举。\nUNIX 不但自身对业界产生了巨大的直接贡献，还成为所有现代操作系统的蓝本，两位作者 Ken Tompson 和 Dennis Ritchie 因此荣获1983年度的图灵奖。\nUNIX 诞生于贝尔实验室，该实验室属于美国国家电信电报公司（AT\u0026amp;amp;T），见识到 UNIX 的强大威力之后，AT\u0026amp;amp;T 做出了一个看似无私的决定：将 UNIX 开源（初期只对大学开源），这使得所有现代操作系统得以诞生。虽然 AT\u0026amp;amp;T 最终被分拆，辉煌不再，但这个决定对人们的贡献绵延至今。在21世纪20年代的今天，无论是 MacOS、Windows、Linux，都直接受到 UNIX 的影响，而 iOS 来自 MacOS，Android 来自 Linux，因此 UNIX 的灵魂仍然活在每个人的手机中、活在每个手机 App 后台的服务中。\n此外，UNIX 诞生之时，还附送了一项比操作系统本身价值更大的副产品：Dennis Ritchie 为开发 UNIX 设计了C语言，C语言成为了所有流行的现代编程语言的主要设计来源，不仅如此，C语言在其诞生近40年后的今天，仍然是最重要的编程语言之一。\n值得一提的是，当时 UNIX 的主要开放对象是伯克利、卡内基梅隆等研究型大学，文理学院规模较小，没有研究生项目，不属于 AT\u0026amp;amp;T 的主要开放目标，因此 Olivet College 毕业的一位小哥未受到 UNIX 思潮的影响。这位名叫 David Cutler 的软件天才于1975年在 DEC 设计了 VMS 操作系统，VMS 和最初的 UNIX 一样，运行在 PDP-11 上，但并不是基于 UNIX，而是独立设计的。VMS 在业界没有掀起大浪，以兼容 UNIX 告终。后来 David Cutler 离开 DEC，加入微软，在那里谱写了属于他自己的传奇。有趣的是，乔布斯也曾在文理学院就读，看来美国文理学院的学生是不走寻常路的。\n微内核的兴起 UNIX「一切皆文件」的设计带来了用户程序设计的很多便利，但它要求所有对硬件的封装都要在内核态，因此内核中模块的 bug 会让整个系统受到影响，比如说，如果某个设备驱动有内存泄漏，所有使用该设备的用户态进程都会有内存泄漏，如果某个内核模块有安全漏洞，整个系统的安全性将不再可控。\n为了解决这类问题，上个世纪70年代，操作系统研究者们开始发展「微内核」的概念，微内核的本质是让操作系统的内核态只保留内存地址管理、线程管理和进程间通讯（IPC）这些基本功能，而把其它功能如文件系统、设备驱动、网络协议栈、GUI 系统等都作为单独的服务，这类服务一般是单独的用户态 daemon 进程。\n用户态应用程序通过 IPC 访问这些服务，从而访问操作系统的全部功能，如此一来，需要陷入内核的系统调用数量将大大减少，系统的模块化更加清晰。同时系统更加健壮，只有内核中的少量系统调用才有权限访问硬件的全部能力，如设备驱动的问题只会影响对应服务，而不是影响整个系统。和 micro kernel 相对，UNIX 的设计被称为 monolithic kernel。\nUNIX 开放后，AT\u0026amp;amp;T 继续着版本迭代，而各大学基于 AT\u0026amp;amp;T 的 UNIX 开发了很多新的操作系统内核，其中较为知名的有：\n BSD，monolithic，由伯克利的传奇人物 Bill Joy 于1974年发布（据说 Bill Joy 花三天便完成了 BSD 内核的第一个版本开发，Bill Joy 的作品还包含第一个 TCP/IP 协议栈、vi、Solaris、SPARK 芯片等等）。该内核对业界影响非常之大，后来发展为 FreeBSD、OpenBSD、NetBSD 等分支。现代操作系统如 Solaris、MacOS X、Windows NT 对其多有借鉴。 Mach，微内核，由卡内基梅隆大学于1984年发布，主要作者是 CMU 的两位研究生 Avie Tevanian 和 Rick Rashid。该内核对业界影响也很大，GNU Hurd、MacOS X 对其多有借鉴，但该项目本身以失败告终。 MINIX，微内核，由阿姆斯特丹自由大学（Vrije Universiteit Amsterdam）的 Andrew Tanenbaum 教授于1987年发布。无数计算机系学生通过 MINIX 及其配套教材掌握了操作系统的设计原理，Linux 的初始版本就是基于 MINIX 复刻的。MINIX 虽然著名，但主要用于教学，从未在工业界获得一席之地。  微内核的沉寂 从上世纪90年代至本世纪10年代，UNIX 和 VMS 的后裔们展开了一场混战，从结果来看，微内核的概念虽然美好，但现 …","date":1594882800,"description":"本文将专注于微内核（microkernel）这个概念及其对 Kubernetes 架构的影响分享。","dir":"blog/microkernel-distributed-operating-system-kubernetes/","fuzzywordcount":7200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"9fc5956b0fc0551dfdcf50df35ee8a84","permalink":"/blog/microkernel-distributed-operating-system-kubernetes/","publishdate":"2020-07-16T15:00:00+08:00","readingtime":15,"relpermalink":"/blog/microkernel-distributed-operating-system-kubernetes/","summary":"如今，Kubernetes 已经成为分布式集群管理系统和公有云/私有云的事实标准。实际上，Kubernetes 是一个分布式操作系统，它是 Google 在分","tags":["Kubernetes"],"title":"Kubernetes: 微内核的分布式操作系统","type":"blog","url":"/blog/microkernel-distributed-operating-system-kubernetes/","wordcount":7104},{"author":"潘潘","categories":"SOFAChannel","content":"概要   活动主题：Service Mesh Webinar#2：基于 MOSN 和 Istio Service Mesh 的服务治理实践\n  活动时间：7 月 22 日周四晚 8 点\n  活动形式：线上直播\n  报名方式：戳这里\n  介绍 Service Mesh Webinar Service Mesh Webinar 是由 ServiceMesher 社区和 CNCF 联合发起的线上直播活动，活动将不定期举行，邀请社区成员为大家带来 Service Mesh 领域的知识和实践分享。\nService Mesh Webinar#2 Service Mesh Webinar#2，邀请有米科技高级后端工程师姚昌宇，带来分享《基于 MOSN 和 Istio Service Mesh 的服务治理实践》。\n本期嘉宾将为大家分享从关注 ServiceMesher 社区，到参与 MOSN 开源共建的心路历程，包括 Service Mesh 技术的相关介绍、如何参与社区共建以及如何将 MOSN 结合 Istio 根据实际场景落地的示范。本期分享可以使你对 Service Mesh 技术，以及如何落地有更多的认识。\n分享主题：\n《基于 MOSN 和 Istio Service Mesh 的服务治理实践》\n分享嘉宾：\n姚昌宇 有米科技高级后端工程师、MOSN committer。多年后端开发经验、云原生爱好者。目前负责公司内部数据和算法能力接口的服务治理相关的开发工作，2018年起关注并参与 ServiceMesher 社区发起的各种活动，近期参与 MOSN v0.14.0 版本功能的开发。\n**直播时间：**2020年5月28日（周四）20:00-21:00\n大纲：\n Service Mesh 带来的红利 参与 MOSN 开源共建给我带来的收获 如何参与 MOSN 开源共建  找到组织：进入 MOSN 开发者群 熟悉 MOSN \u0026amp;amp; 搭建本地调试环境：现场演示（http、grpc 服务流量控制演示，指标收集，请求跟踪演示） 发现优化点/参与 Roadmap   感悟总结，以及 MOSN 近况\u0026amp;amp;未来远景介绍  用户收获：\n 了解如何参与到 MOSN 开源社区共建中； 了解如何使用 MOSN 在 Istio 场景下的服务治理实践 ; 了解 MOSN 新版本的功能以及未来远景； 结合 Istio 各个场景的 Demo，分享 MSON 的多协议/私有协议实现；  ","date":1594710000,"description":"7 月 22 日周四晚 8 点，Service Mesh Webinar#2 线上直播。","dir":"activities/service-mesh-webinar-2/","fuzzywordcount":700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"856529bdb9666c8bad4c59a80444662f","permalink":"/activities/service-mesh-webinar-2/","publishdate":"2020-07-14T15:00:00+08:00","readingtime":2,"relpermalink":"/activities/service-mesh-webinar-2/","summary":"概要 活动主题：Service Mesh Webinar#2：基于 MOSN 和 Istio Service Mesh 的服务治理实践 活动时间：7 月 22 日周四晚 8 点 活动形式：线上直播 报名方式：戳这里","tags":["MOSN","Service Mesh Webinar"],"title":"Service Mesh Webinar#2：基于 MOSN 和 Istio Service Mesh 的服务治理实践","type":"activities","url":"/activities/service-mesh-webinar-2/","wordcount":661},{"author":"罗广明","categories":"Service Mesh","content":" 本文节选自 ServiceMesher 社区出品的开源电子书《Istio Handbook——Istio 服务网格进阶实战》，作者罗广明，来自百度。\n 在过去几年中，微服务成为了业界技术热点，大量的互联网公司都在使用微服务架构，也有很多传统企业开始实践互联网技术转型，基本上也是以微服务和容器为核心。本文将主要介绍微服务架构的概述以及云原生环境下的 Service Mesh 和传统微服务应用的区别。\n微服务架构概述 微服务架构可谓是当前软件开发领域的技术热点，在各种博客、社交媒体和会议演讲上的出镜率非常之高，无论是做基础架构还是做业务系统的工程师，对微服务都相当关注，而这个现象与热度到目前为止，已经持续了近 5 年之久。\n尤其是近些年来，微服务架构逐渐发展成熟，从最初的星星之火到现在的大规模落地与实践，几乎已经成为分布式环境下的首选架构。微服务成为时下技术热点，大量互联网公司都在做微服务架构的落地和推广。同时，也有很多传统企业基于微服务和容器，在做互联网技术转型。\n而在这个技术转型中，国内有一个趋势，以 Spring Cloud 与 Dubbo 为代表的微服务开发框架非常普及和受欢迎。然而软件开发没有银弹，基于这些传统微服务框架构建的应用系统在享受其优势的同时，痛点也越加明显。这些痛点包括但不限于以下几点：\n 侵入性强。想要集成 SDK 的能力，除了需要添加相关依赖，往往还需要在业务代码中增加一部分的代码、或注解、或配置；业务代码与治理层代码界限不清晰。 升级成本高。每次升级都需要业务应用修改 SDK 版本，重新进行功能回归测试，并且对每一台机器进行部署上线，而这对于业务方来说，与业务的快速迭代开发是有冲突的，大多不愿意停下来做这些与业务目标不太相关的事情。 版本碎片化严重。由于升级成本高，而中间件却不会停止向前发展的步伐，久而久之，就会导致线上不同服务引用的 SDK 版本不统一、能力参差不齐，造成很难统一治理。 中间件演变困难。由于版本碎片化严重，导致中间件向前演进的过程中就需要在代码中兼容各种各样的老版本逻辑，带着 “枷锁” 前行，无法实现快速迭代。 内容多、门槛高。Spring Cloud 被称为微服务治理的全家桶，包含大大小小几十个组件，内容相当之多，往往需要几年时间去熟悉其中的关键组件。而要想使用 Spring Cloud 作为完整的治理框架，则需要深入了解其中原理与实现，否则遇到问题还是很难定位。 治理功能不全。不同于 RPC 框架，Spring Cloud 作为治理全家桶的典型，也不是万能的，诸如协议转换支持、多重授权机制、动态请求路由、故障注入、灰度发布等高级功能并没有覆盖到。而这些功能往往是企业大规模落地不可获缺的功能，因此公司往往还需要投入其它人力进行相关功能的自研或者调研其它组件作为补充。  以上列出了传统微服务框架的局限性，但这并不意味着它们就一无是处了。在中小企业，采用 Spring Cloud 这样的传统微服务框架已经可以满足绝大部分服务治理的需求，并且借此快速推进微服务化改造。这些痛点往往是技术发展到一定的程度必然要经历的阶段，这些痛点促使技术不断发展、不断前进。\n在众多热门技术趋势中，云原生的关注度居高不下，很多开发者都对由此兴起的一众技术十分追捧，众多企业又开始探索云原生架构的转型与落地。这一年，中国的开发者们经历了从关注“云原生概念”到关注“云原生落地实践”的转变。而 Service Mesh 技术也因此越来越火热，受到越来越多开发者的关注，并拥有了大批拥趸。那么 Service Mesh 是什么呢？它为什么会受到开发者的关注？它和传统微服务应用有什么区别？\nService Mesh 定义 Service Mesh 一词最早由开发 Linkerd 的 Buoyant 公司提出，并于 2016 年 9 月29 日第一次公开使用了这一术语。William Morgan，Buoyant CEO，对 Service Mesh 这一概念定义如下：\n A service mesh is a dedicated infrastructure layer for handling service-to-service communication. It’s responsible for the reliable delivery of requests through the complex topology of services that comprise a modern, cloud native application. In practice, the service mesh is typically implemented as an array of lightweight network proxies that are deployed alongside application code, without the application needing to be aware.\n 翻译成中文如下：\nService Mesh 是一个专门处理服务通讯的基础设施层。它的职责是在由云原生应用组成服务的复杂拓扑结构下进行可靠的请求传送。在实践中，它是一组和应用服务部署在一起的轻量级的网络代理，并且对应用服务透明。\n以上这段话有四个关键点：\n 本质：基础设施层； 功能：请求分发； 部署形式：网络代理； 特点：透明；  2017 年，随着 Linkerd 的传入，Service Mesh 进入国内社区的视野，并且由国内的技术布道师们翻译成“服务网格”。\n服务网格概述 服务网格从总体架构上来讲比较简单，不过是一堆紧挨着各项服务的用户代理，外加一组任务管理流程组成。代理在服务网格中被称为数据层或数据平面（data plane），管理流程被称为控制层或控制平面（control plane）。数据层截获不同服务之间的调用并对其进行“处理”；控制层协调代理的行为，并为运维人员提供 API，用来操控和测量整个网络。\n更进一步地说，服务网格是一个专用的基础设施层，旨在“在微服务架构中实现可靠、快速和安全的服务间调用”。它不是一个“服务”的网格，而是一个“代理”的网格，服务可以插入这个代理，从而使网络抽象化。在典型的服务网格中，这些代理作为一个 sidecar（边车）被注入到每个服务部署中。服务不直接通过网络调用服务，而是调用它们本地的 sidecar 代理，而 sidecar 代理又代表服务管理请求，从而封装了服务间通信的复杂性。相互连接的 sidecar 代理集实现了所谓的数据平面，这与用于配置代理和收集指标的服务网格组件（控制平面）形成对比。\n总而言之，Service Mesh 的基础设施层主要分为两部分：控制平面与数据平面。当前流行的两款开源服务网格 Istio 和 Linkerd 实际上都是这种构造。\n控制平面的特点：\n 不直接解析数据包。 与控制平面中的代理通信，下发策略和配置。 负责网络行为的可视化。 通常提供 API 或者命令行工具可用于配置版本化管理，便于持续集成和部署。  数据平面的特点：\n 通常是按照无状态目标设计的，但实际上为了提高流量转发性能，需 …","date":1594710000,"description":"本文将主要介绍微服务架构的概述以及云原生环境下的 Service Mesh 和传统微服务应用的区别。","dir":"blog/microservices-service-mesh/","fuzzywordcount":5300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"f6d713862b049df801c82f5c52ec6ed1","permalink":"/blog/microservices-service-mesh/","publishdate":"2020-07-14T15:00:00+08:00","readingtime":11,"relpermalink":"/blog/microservices-service-mesh/","summary":"本文节选自 ServiceMesher 社区出品的开源电子书《Istio Handbook——Istio 服务网格进阶实战》，作者罗广明，来自百度。 在过去几年中，微服务成为","tags":["Service Mesh"],"title":"火了 2 年的服务网格究竟给微服务带来了什么？","type":"blog","url":"/blog/microservices-service-mesh/","wordcount":5223},{"author":"SOFA 团队","categories":"SQLFlow","content":" 端到端机器学习是一种由输入端的数据直接得到输出端结果的AI系统，它可以对业务人员屏蔽复杂技术细节，同时给模型以更多自动调节空间，增加模型整体契合度。近两年来，端到端机器学习成为 AI 领域研发热点，蚂蚁集团于2019年5月发布端到端 AI 系统 SQLFlow 开源项目，受到业界广泛关注。今天，就让我们来看看它对端到端 AI 的思考与解答。\n **SQLFlow **是蚂蚁集团开源的使用 SQL 完成 AI 工作流构建的编译系统。SQLFlow 将多种数据库系统（MySQL, Hive, MaxCompute）和多种机器学习引擎（Tensorflow, Keras, XGBoost）连接起来，将 SQL 程序编译成可以分布式执行的工作流，完成从数据的抽取，预处理，模型训练，评估，预测，模型解释，运筹规划等工作流的构建。\n接下来我们会根据以下内容逐步介绍 SQLFlow：\n 为什么要使用 SQL 语言描述端到端 AI 任务； 使用 SQLFlow SQL 语句构建 AI 任务； 使用 SQL 程序构建端到端 AI 工作流； 使用 SQLFlow Model Zoo 沉淀模型； 应用 SQLFlow 的场景案例；  为什么要使用 SQL 语言描述端到端 AI 任务 首先，思考一个问题，人工智能和金融有哪些耳熟能详的结合呢？  在智能征信风控方向，可以运用大数据进行机器学习，刻画用户画像，抽取个性化典型特征，推进反欺诈评估、用户征信评估。  用到的技术：聚类（将有相似特征的群体聚类，确定人群标签）、分类（学习已有分类标签的用户特征，识别新用户所属的类型、标签）、模型解释\n 在智能投资顾问方向，我们以人工智能算法为基础，为客户提供自动化投资管理解决方案，包括提供投资资讯、构建投资组合、直接投资管理等服务。  用到的技术：时序模型、回归、运筹规划\n 智能营销方向，上世纪90年代沃尔玛超市将「啤酒」与「尿布」摆在同一区域的做法，大大增加了商品销售收入，成为借助数据分析实现智能营销的经典案例。而今天，在人工智能等新技术的加持下，数据分析技术正在不断进化，千人千面的智能营销已有广泛的应用。  用到的技术：推荐算法、Ranking、CTR、运筹规划\n然而，构建传统的机器学习工作流程，需要经历非常多的步骤并使用复杂的技术栈： 构建完整的 AI 应用，首先需要获取用于构建模型的数据，这些数据通常可以从日志、订单数据、交易记录等获得。之后通过数据抽取，将其中我们需要用到的部分信息，从多个存储位置抽取出来。抽取数据之后需要进行数据预处理，比如去掉错误的数据，填充缺失的数据，整理，排序等。预处理完成之后，我们需要从这部分数据中得到用于训练模型的特征，比如提取时间序列的周期性特征，获取交叉特征等，最后将构建的特征转换成训练框架可以接收的数据格式，才能开始训练。 另外，在开始训练之前，我们还需要确定使用哪个模型，XGBoost 模型还是深度学习模型，哪个模型更适合当前的场景？模型可以从现有模型库中获取并根据需要修改，或者从头编写新的模型使用。另外在构建机器学习模型时，我们需要不断的评估模型的表现如何，以获得最优的模型，这时就要使用各种评价指标描述训练好的模型。当模型评估结果验证达标之后，就需要将模型代码发布一个新的版本，部署到线上环境。发布之前还要通过线下测试，小流量 ABTest，然后推全部署。如果是离线任务则需要更新定时任务使用新的模型代码。\n当模型的时效性比较强的时候，我们还需要不断的使用新的数据更新模型，就是“增量训练“，这样每次增量训练就不得不再次从头走一次完整的流程。\n要完成这一整套流程，需要用到复杂的技术栈。\n我们需要的数据可能存储在磁盘，或者像 HDFS 这样的分布式文件系统，或者可以从结构化的数据库系统中获得，或者是 NoSQL 引擎（比如 mongodb）存储的数据；在预处理阶段，有可能需要编写 MapReduce Job 来处理 HDFS 上的大量的数据，或者使用 Hive 编写 SQL 语句完成处理，亦或直接编写 Python 代码处理数据；在特征工程阶段，又需要使用类似 statsmodels, tsfresh 或者编写 Python 程序使用诸如 Pandas 之类的库完成预处理；在模型训练阶段，算法工程师首先需要掌握各种建模的能力，算法原理和基础知识，也需要熟练使用各种机器学习引擎如 sklearn, XGBoost, Tensorflow, Pytorch 等；最后在上线部署阶段，还需要了解模型如何接入 Serving 系统，怎么样做 ABTest，怎么编写 CI/CD 任务保证模型上线不影响线上业务。\n构建 AI 应用，不仅需要冗长的链路和复杂的技术，从业务需求到 AI 系统上线也需要特别长的沟通链路。\n比如业务同学和产品同学在构建产品思路的时候，在他的脑海中的 AI 系统需要完成的任务，传达给开发同学之后，有可能传达不到位，需要反复的沟通。有时甚至做了一半还需要重做。\n另外从需求到上线，为了保证线上服务和数据产出的稳定，也需要通过许多的步骤。比如业务同学说：「活动要上线了，时间点很关键，明天必须发布！」开发同学接到需求，加班加点，开发验证完成之后，模型准确率提升10个点，准备发布模型。SRE 同学则会把控上线之前的各项准备，包括预发测试是否通过，压力测试是否通过，CPU 负载是否有提升，硬件资源是否能承载新的模型，模型预测延迟是否提升了等……完成流程也需要很长时间。然而如果没有 SRE 的把关，线上的服务很难保证稳定性。\n使用 SQL 作为描述和构建 AI 任务的语言，可以降低构建 AI 应用的门槛，提升效率。\n首先需要区分编程语言主要的两种描述方法：描述意图和描述过程。简而言之，描述意图是在描述「做什么」，描述过程是描述「怎么做」。比如，夏天大家有空喜欢吃点烧烤喝点啤酒，描述意图的方式，说「我想去撸串」这一句就够了。而描述过程，就需要说「我今天晚上下班后，叫上老王小李，去公司楼下的烧烤店，点100个串和10个啤酒，最后用支付宝扫码付款」。可以看到描述意图可以非常简洁，而具体的执行方案，可以根据意图中构建得出。这点也是 SQL 不同于其他语言的关键点。\n在描述模型训练任务时，使用 SQLFlow SQL 只需要编写 SELECT * FROM iris.train TO TRAIN DNNClassifier LABEL class INTO my_dnn_model; 即可，如果使用 Python 完成相同的任务则需要编写如下图这样的较长的代码。\nSQL 语言除了有非常简洁的优势之外，在数据科学领域，SQL 语言的已有用户量大，并且在不断的增加。这里也有两个统计图，统计了数据科学类任务所使用的工具的流行程度和增长趋势。SQL 语言流行程度排名第三，增量排在第四名。数据科学领域正在更多的使用 SQL 是我们希望使用 SQL 语言描述 AI 任务的原因。除了在表达能力上 SQL 语言有非常简洁的优势之外，在蚂蚁内 MaxCompute 被广泛使用也是我们选择 SQL 的一个原因。\n如何使用 SQLFlow SQL 语句构建 AI 任务 SQLFlow 是一个开源项目，您可以在任意环境 …","date":1594623600,"description":"近两年来，端到端机器学习成为 AI 领域研发热点，蚂蚁集团于2019年5月发布端到端 AI 系统 SQLFlow 开源项目，受到业界广泛关注。今天，就让我们来看看它对端到端 AI 的思考与解答。","dir":"blog/end-to-end-ai-system-sqlflow/","fuzzywordcount":6700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"667a8ff160a9c7f54a5ceba7c20b7437","permalink":"/blog/end-to-end-ai-system-sqlflow/","publishdate":"2020-07-13T15:00:00+08:00","readingtime":14,"relpermalink":"/blog/end-to-end-ai-system-sqlflow/","summary":"端到端机器学习是一种由输入端的数据直接得到输出端结果的AI系统，它可以对业务人员屏蔽复杂技术细节，同时给模型以更多自动调节空间，增加模型整体","tags":["SQLFlow"],"title":"我们需要什么样的端到端 AI 系统？蚂蚁 SQLFlow 的思考与答案","type":"blog","url":"/blog/end-to-end-ai-system-sqlflow/","wordcount":6623},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n SOFAStack 官网:https://www.sofastack.tech SOFAStack:https://github.com/sofastack  每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n@郝连帅 提问：\n 如果回滚失败有没有告警机制实现？比如钉钉告警。\n A：可以的，实现 FailureHandler 接口。\n本周推荐阅读  支付宝资深技术专家尹博学：新一代金融核心突破之全分布式单元化技术架构 走出微服务误区：避免从单体到分布式单体  SOFA 项目进展 本周发布详情如下：\n发布 SOFAJRaft v1.3.3，主要变更如下：\n RheaKV 允许不同分片各自配置不同的 learner 节点； 在只有一个成员变更的情况下，仍然使用 raft 联合一致性算法； 替换基于 GPL-2.0 licence 的 Bits.java； 升级 jackson.databind 版本到 2.10.4 已修复安全漏洞； 修复在 node panic 后可能因为未及时刷盘导致快照元数据丢失的 bug；  致谢（排名不分先后）：@zongtanghu\n此版本强烈建议升级 详细发布报告：https://github.com/sofastack/sofa-jraft/releases/tag/1.3.3\n社区活动报名 CNCF 的旗舰会议聚集了全球领先开源社区和云原生社区的使用者和技术大咖参加线上峰会。相约 2020 年 7 月 30 日 - 8 月 1 日三天的线上峰会，共同探讨云原生计算的未来和方向。蚂蚁集团也受邀进行两个云原生主题分享。\n分享主题：在大规模 Kubernetes 集群上实现高 SLO 的方法\n **分享嘉宾：**霜林 蚂蚁集团技术专家、散樗 蚂蚁集团高级开发工程师 **议题介绍：**随着 Kubernetes 集群的规模和复杂性的增加，集群越来越难以提供高成功率和低延迟的合格 pod。在本次演讲中，蚂蚁集团的工程师将分享他们在设计 SLO架构和实现高服务水平目标的方法的经验。他们将引入适当的指标，首先衡量 Kubernetes 集群是否健康。然后，他们将解释如何设计和实现跟踪和分析平台，以收集有效的度量和计算这些指标。有了跟踪分析平台，pod 提供过程中出现的问题可以很容易的被诊断出来。最后，他们将展示如何沉淀人工体验到自我修复系统，以自动修复已知的问题。 **分享时间：**2020-07-30 20:10-20:40 报名方式：点击“这里”，即可报名  分享主题：为 Kubernetes 的秘密披上无形的盾牌\n 分享嘉宾：柯粟 蚂蚁集团高级开发工程师 议题介绍：K8s 的秘密广泛应用于生产中，用于对敏感信息进行存储管理。与 KMS 的集成，甚至与基于硬件的插件，确实增强了保护，但还远远不够，特别是对于财务级的安全需求。由于缺乏端到端的秘密加固解决方案，攻击面在很大程度上在 K8s 集群中其他关键元素/流的威胁中仍然不受保护。通过聚合可信执行环境（TEE）和增强的身份验证，本讲座探索在使用、静止和传输中保护 K8s 秘密的答案。对 kubectl、K8S主节点和节点进行了更改，以保证可用性和机密性。TEE 对开发人员和用户的透明性将通过一个演示进行阐述和演示。最后，将分享在蚂蚁集团的实践经验和 KEP 给社区。 分享时间：2020-07-31 20:10-20:40 报名方式：点击“这里”，即可报名  ","date":1594364400,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20200710/","fuzzywordcount":1400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"304a9dc50d507f12e1b562491d6b5546","permalink":"/blog/sofa-weekly-20200710/","publishdate":"2020-07-10T15:00:00+08:00","readingtime":3,"relpermalink":"/blog/sofa-weekly-20200710/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | SOFAJRaft 发布、CNCF 旗舰会议活动预告","type":"blog","url":"/blog/sofa-weekly-20200710/","wordcount":1373},{"author":"尹博学","categories":"分布式架构","content":" 过去几年是云原生理念高速普及的黄金时期。微服务、容器、无服务器架构、服务网格等新技术的出现，在技术社区中激起了一浪又一浪的创新热潮。然而由于金融行业对性能和安全的严苛要求，云原生技术在企业实际场景中的实施落地，特别是在金融场景的实施落地，仍然面临诸多挑战。\n本文整理自2020阿里云线上峰会蚂蚁集团资深技术专家尹博学的主题演讲，为大家分享蚂蚁关于金融级 IT 架构及分布式架构的思考和应用实践。关注本网站，蚂蚁 SOFAStack 白皮书即将发布，不要错过哦～\n 以下为演讲整理全文：\n大家好，我是蚂蚁集团的尹博学，今天和大家分享一下蚂蚁关于金融级 IT 架构及分布式架构的一些思考和应用案例，主要包含三个部分，分别是行业常见的分布式架构介绍、蚂蚁单元化架构的介绍以及单元化架构的应用案例。\n行业常见分布式架构 行业常见的分布式架构主要包含，单活架构、双活架构和冷备架构。从容灾能力角度来看，双活架构和冷备架构均能做到应用级跨机房容灾，但是数据库因为使用了异步复制的技术，无法做到机房级 RPU=0 的容灾。再看灰度发布的能力，冷备架构和双活架构都只能做到机房级灰度发布，无法做到更细粒度的灰度发布。\n蚂蚁集团单元化架构介绍 在介绍完行业常见的分布式架构后，我们来看一下蚂蚁的分布式架构发展历程，和单元化架构的详细介绍。\n这是蚂蚁分布式架构发展历程。蚂蚁也经历了单活、同城双活、两地三中心三个阶段。其中两地三中心是同城双活加一个冷备。随着蚂蚁业务和业务量复杂度的越来越高，业务对于基础架构的要求也越来越高，即扩展能力、容灾能力、灰度能力要求越来越高。最终蚂蚁发展到了单元化架构，将主要业务拆分单元即分片，装入不同的逻辑单元内，每个分片的数据库实现三地五中心部署即三地五中心的单元化架构。\n首先我们来看一下蚂蚁单元化架构的整体架构设计，整体架构包含 RZone、GZone 和 CZone。其中 GZone 部署的是无法拆分的数据和业务，GZone 的数据和业务被 RZone 依赖，GZone 全局只部署一份，而 RZone 部署的是可拆分的业务和对应的数据。每个 RZone 内的数据分片如图所示有五副本，实现三地五中心部署，每个分片内只有一个可写入的主副本，其余副本按照 Paxos 协议做数据强一致。每个 RZone 内实现业务单元封闭，独立完成自己的所有业务。而 CZone 的出现是因为 GZone 全局只有一份，不同城市的 RZone 可能依赖 GZone 服务和数据的时候需要远距离调用，延迟比较大，所以在每个城市部署一个 CZone 作为 GZone 的只读副本，为本城市的 RZone 提供服务。\n介绍完单元化架构的整体设计之后，我们从容灾、灰度发布、弹性三个方面详细看一下该架构的能力。\n首先看容灾能力，容灾能力分为同城容灾和异地容灾，以图中所示为例，RZone1 出现故障先看同城容灾能力，我们目标将 RZone1 切换至同城容灾 RZone2。先做数据库分片切换，RZone1 对应的分片为分片1，把分片1在 RZone2 的副本提升为主副本，数据库副本提升完毕后将 RZone1 的流量切换至 RZone2，实现同城容灾 RPO=0、RTO\u0026amp;lt;1min。\n再看异地容灾，同样以 RZone1 故障为例。目标切换至 RZone3，先做数据库切换，分片1在 RZone3 的副本切换成主副本，完成后将 RZone1 的流量切换至 RZone3，实现异地容灾，该过程 RPO=0、RTO\u0026amp;lt;1min。\n接下来我们看弹性。弹性的背景是业务在大促、节假日等流量出现大幅上涨的过程，我们可以短期租借新的城市和新的 IDC。如图所示，我们租借城市 X 的 IDCX 作为 RZoneX，将 RZone5 的部分流量弹出至 RZoneX，对应流量的数据也弹出至 RZoneX 内。在节假日大促结束之后，将 RZoneX 内的流量和数据弹回至 RZone5，然后回收 RZoneX，这样大幅节约了机房成本。\n介绍完弹性之后，我们来看灰度能力。如图所示，我们将四个 RZone（RZone1、RZone2、RZone3、RZone4）的业务和应用分为 A、B 组，日常 A 组和 B 组各承担50%的应用流量。在应用新版本发布时，我们将 A 组的流量全部切换至 B 组，此时在 A 组上部署新版本，部署完毕后将 B 组的流量按粒度切换至 A 组上，切换粒度等于数据分片的粒度。在切换的过程中可以做 A 组和 B 组的服务对比，如果发现 A 组的服务异常，可以快速将流量切换回 B 组。在 A 组服务一段时间后无异常发生，最终可以将 B 组的流量全部切换至 A 组，把 B 组的版本更新为新的版本，在整个切换的过程中实现了可灰度、可回滚、可监控。\n我们再深入到架构内部，来阐释一下架构内关键模块是如何支撑该架构的。\n首先我们看流量路由模块。流量路由模块的核心是将用户的 uid 信息和对应的 Zone 信息植入到 cookie 中，供流量路由模块做精准路由。我们以用户 uid=68、RZone=RZ03 为例来看流量路由模块是如何工作的，首次用户接入时 cookie 内无 Zone 信息，流量接入模块会随即将该请求发到一个 RZone 内，如发到 RZone1 内，RZone1 通过 zoneClinet 会准确计算该请求应发至 RZone3，即通过 RouteClinet 将该请求发送。发送过程中将计算出的 uid 信息和对应的 Zone 信息植入 cookie 内转发至 RZone3，RZone3 完成本次业务请求后将结果返回给用户，其后用户同意 session 内的其它请求，因为在 cookie 内已经有了准确的路由信息，会被流量路由模块准确的发至 RZone3 完成业务请求。\n接着我们再看一下服务路由，服务路由分为本机房服务路由和跨机房服务路由调用。先看本机房服务路由，服务调用端向本机房服务注册中心订阅服务，发现服务地址后做本机房服务路由调用。再看跨机房服务路由调用，服务调用端向其他 IDC 的注册中心订阅服务地址，发现服务地址后做跨机房服务调用。\n最后我们看数据是如何实现高可靠的。蚂蚁使用自研的分布式关系数据库 OceanBase，每个分片的数据库做5副本部署，部署地域实现三地五中心部署，5副本中有3副本实现强一致，如图所示可以实现同城、IDC 容灾和异地容灾。\n单元化架构实践场景 介绍完蚂蚁单元化架构的主要概念即关键模块信息之后，我们看一下单元化架构在外部客户实施的一些案例。\n第一个案例是一家城商行，它的业务系统、IT系统历史比较长，无法一步跨越到单元化架构，我们为其推荐了大 GZone 的模式，即把城商行的所有服务和数据不做拆分，直接装入一个 GZone 内，在 GZone 的基础上实现同城双活即应用同城双中心部署，数据库同城三中心部署，从而实现同城容灾能力，RPO=0、RTO\u0026amp;lt;1min，但无法实现异地容灾能力，其可灰度能力和弹性能力都无法做到更细力度。\n再看第二个区域银行的案例。我们为这家区域银行实现了同城单元化，即将这家区域银行的主要业务拆分成两个逻辑业务单元两个分片，将其装入一个城市的两个 IDC 内，在另外一个城市建设冷 …","date":1594278000,"description":"本文整理自2020阿里云线上峰会蚂蚁集团资深技术专家尹博学的主题演讲，为大家分享蚂蚁关于金融级 IT 架构及分布式架构的思考和应用实践。","dir":"blog/antgroup-yinboxue-fully-distributed-unitized-technology-architecture/","fuzzywordcount":3700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"dec27e85a58fcb573b33b9de6125bbc5","permalink":"/blog/antgroup-yinboxue-fully-distributed-unitized-technology-architecture/","publishdate":"2020-07-09T15:00:00+08:00","readingtime":8,"relpermalink":"/blog/antgroup-yinboxue-fully-distributed-unitized-technology-architecture/","summary":"过去几年是云原生理念高速普及的黄金时期。微服务、容器、无服务器架构、服务网格等新技术的出现，在技术社区中激起了一浪又一浪的创新热潮。然而由于","tags":["分布式架构"],"title":"支付宝资深技术专家尹博学：新一代金融核心突破之全分布式单元化技术架构","type":"blog","url":"/blog/antgroup-yinboxue-fully-distributed-unitized-technology-architecture/","wordcount":3642},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n SOFAStack 官网: https://www.sofastack.tech SOFAStack: https://github.com/sofastack  每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动\n我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@guotaisu 提问：\n 根据 jraft-example, 使用“fake PD”, 怎样手动 rebalance。使用 PD 自管理体现在哪？\n A：手动 API： https://github.com/sofastack/sofa-jraft/blob/master/jraft-core/src/main/java/com/alipay/sofa/jraft/CliService.java#L190\nPD 目前只实现了 leader 平衡和自动分裂，支持很容易基于 SPI 扩展增加自己的逻辑(增加并实现自己的 com.alipay.sofa.jraft.rhea.util.pipeline.Handler 即可)，文档见：https://www.sofastack.tech/projects/sofa-jraft/jraft-rheakv-user-guide/\n regionEngineOptionsList 配置：实例中的 regionId 的 startKey：01000000-endKey：23000000 根据什么来定义的，假设我一个 store 节点只部署 1-3 个 region，可以自定义上下界是吗，依据什么来定义？\n A：rheakv multi group 按照 range 分片，左闭右开，可以自定义，怎么定义取决于你对自己场景 key 分布的评估。\n yaml 配置中 regionEngineOptionsList.RegionEngineOptions 中的 serverAddress、initialServerList 等配置和外部与 regionEngineOptionsList 平级的 serverAddress 配置以及与 storeEngineOptions 平级的 initialServerList 是什么关系，谁覆盖谁？\n A：store 和 region 为1：n， region 包含在 store 中，store 的参数会 copy 传递到 region。\n jraft-example 展示，Rhea-kv 是客户端+服务端模式，其中 benchmark 使用分片集群部署模式，需要先同时使用 BenchmarkClient、BenchmarkServer 拉启后台服务，而后面的 rheakv 使用分节点配置和启动，如何区分二者的场景和使用姿势。\n A：rheakv 可以作为 client+server 部署，也可以单独作为 client 部署，通常你不想在每个节点提供服务但是还需要调用服务，那么就只 client 部署即可（配置的区别就在于是否配置了 StoreEngineOptions）。\n 本人项目使用 SOFAJRaft 场景是分布式单体服务快速便捷存储业务元数据，实现一致性访问。请问后台需要拉取这么多服务如何还能保证我的应用轻量快捷？另外，这些后台 jraft-kv 选举和存储服务启动后，是独立进程吗，整合到自己到项目中后，可否一个进程并且其服务生命周期随同我的母体应用的生命周期。\n A：SOFAJRaft 是一个 jar 包，是不是独立进程完全取决于你自己的意愿，都可以。\n 参考 jraft-example 实例，基于 rheakv 部署 multi group，加减 learnner 节点等，应该是以分组为单位操作，目前只看到 NodeOptions 中有 groupId 属性，多组时怎么配置和分别操作。\n A：这应该是两个问题。 问题1（groupId 多组如何配置）：在 rheakv 里，groupId 是 clusterName + ‘-’ regionId。 问题2（多组如何配置 learner）：目前没有很灵活，我们内部使用还是单独指定几台机器，上面的节点全部是 learner 节点，只要配置 initialServerList: 127.0.0.1:8181,127.0.0.1:8182,127.0.0.1:8183/learner 即所有 group 的 learner 都在 127.0.0.1:8183/learner 一个节点上，你的需求收到了，下个版本会增加每个 region 单独指定 learner，需要修改 RegionEngineOptions.initialServerList 在不为空的时候不被 StoreEngineOptions 的值覆盖即可。\nSOFAJRaft：https://github.com/sofastack/sofa-jraft\n本周推荐阅读  网络通信框架 SOFABolt 功能介绍及协议框架解析 | SOFAChannel#17 直播回顾 走出微服务误区：避免从单体到分布式单体  SOFA 项目进展 本周发布详情如下：\n发布 MOSN v0.14.0，主要变更如下：\n 支持 Istio 1.5.x 版本； 升级了一些依赖库，如 FastHTTP、Dubbo-go、Tars； 支持 Maglev 负载均衡、支持 HostRewrite Header； 新增了一些 Metrics 输出与查询接口； 部分实现优化与 Bug 修复；  详细发布报告：https://mosn.io/zh/blog/releases/v0.14.0/\n同时，恭喜**姚昌宇（@trainyao）**成为 MOSN Committer，感谢他为 MOSN 社区所做的贡献。\n社区活动报名 GIAC（GLOBAL INTERNET ARCHITECTURE CONFERENCE）是面向架构师、技术负责人及高端技术从业人员的年度技术架构大会，是中国地区规模最大的技术会议之一。蚂蚁集团也受邀进行 CloudNative(云原生) 的主题分享。\n 分享主题：云原生网络代理 MOSN 的进化之路 **分享嘉宾：**王发康（毅松）蚂蚁集团 可信原生技术部 技术专家 **背景介绍：**网络通信代理 MOSN 在蚂蚁集团的 Service Mesh 大规模落地后，通过对接 UDPA 打造为 Istio 的数据面之一，增强 MOSN 服务治理及流量控制能力，对接云原生周边组件，实现 MOSN 开箱即用，MOSN  …","date":1593759600,"description":"【06/29-07/03】 | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20200703/","fuzzywordcount":2100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"6f65c94a70fdd3d222fb510cbec05abf","permalink":"/blog/sofa-weekly-20200703/","publishdate":"2020-07-03T15:00:00+08:00","readingtime":5,"relpermalink":"/blog/sofa-weekly-20200703/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | MOSN 版本发布以及社区活动预告、SOFABolt 直播回顾整理","type":"blog","url":"/blog/sofa-weekly-20200703/","wordcount":2013},{"author":"丞一","categories":"SOFAChannel","content":" SOFA:Channel/，有趣实用的分布式架构频道。 回顾视频以及 PPT 查看地址见文末。欢迎加入直播互动钉钉群 : 30315793，不错过每场直播。\n 大家好，我是本期 SOFAChannel 的分享讲师丞一，来自蚂蚁集团，是 SOFABolt 的开源负责人。今天我们来聊一下蚂蚁集团开源的网络通信框架 SOFABolt 的框架解析以及功能介绍。本期分享将从以下四个方面展开：\n SOFABolt 简介； 基础通信能力解析； 协议框架解析； 私有协议实现解析；  SOFABolt 是什么 SOFABolt 产生背景 相信大家都知道 SOFAStack，SOFAStack(Scalable Open Financial Architecture Stack)是一套用于快速构建金融级云原生架构的中间件，也是在金融场景里锤炼出来的最佳实践。\nSOFABolt 则是 SOFAStack 中的网络通信框架，是一个基于 Netty 最佳实践的轻量、易用、高性能、易扩展的通信框架，他的名字 Bolt 取自迪士尼动画《闪电狗》。他一开始是怎么在蚂蚁集团内部产生的，我们可以类比一下 Netty 的产生原因：\n 为了让 Java 程序员能将更多的精力放在基于网络通信的业务逻辑实现上，而不是过多的纠结于网络底层 NIO 的实现以及处理难以调试的网络问题，Netty 应运而生； 为了让中间件开发者能将更多的精力放在产品功能特性实现上，而不是重复地一遍遍制造通信框架的轮子，SOFABolt 应运而生；  这些年，在微服务与消息中间件在网络通信上，蚂蚁集团解决过很多问题、积累了很多经验并持续进行着优化和完善，我们把总结的解决方案沉淀到 SOFABolt 这个基础组件里并反馈到开源社区，希望能够让更多使用网络通信的场景受益。目前该组件已经运用在了蚂蚁集团中间件的微服务 (SOFARPC)、消息中心、分布式事务、分布式开关、以及配置中心等众多产品上。\n同时，已有数家企业在生产环境中使用了 SOFABolt，感谢大家的肯定，也希望 SOFABolt 可以给更多的企业带来实践价值。\n以上企业信息根据企业用户 Github 上反馈统计 — 截止 2020.06。\nSOFABolt：https://github.com/sofastack/sofa-bolt\nSOFABolt 框架组成 SOFABolt 整体可以分为三个部分：\n 基础通信能力（基于 Netty 高效的网络 IO 与线程模型、连接管理、超时控制）； 协议框架（命令与命令处理器、编解码处理器）； 私有协议实现（私有 RPC 通信协议的实现）；  下面，我们分别介绍一下 SOFABolt 每个部分的具体能力。\n基础通信能力 基础通信模型 如上图所示，SOFABolt 有多种通信模型，分别为：oneway、sync、future、callback。下面，我们介绍一下每个通信模型以及他们的使用场景。\n oneway：不关注结果，即客户端发起调用后不关注服务端返回的结果，适用于发起调用的一方不需要拿到请求的处理结果，或者说请求或处理结果可以丢失的场景； sync：同步调用，调用线程会被阻塞，直到拿到响应结果或者超时，是最常用的方式，适用于发起调用方需要同步等待响应的场景； future：异步调用，调用线程不会被阻塞，通过 future 获取调用结果时才会被阻塞，适用于需要并发调用的场景，比如调用多个服务端并等待所有结果返回后执行特定逻辑的场景； callback：异步调用，调用线程不会被阻塞，调用结果在 callback 线程中被处理，适用于高并发要求的场景；  oneway 调用的场景非常明确，当调用方不需要拿到调用结果的时候就可以使用这种模式，但是当需要处理调用结果的时候，选择使用同步的 sync 还是使用异步的 future 和 callback？都是异步调用，又如何在 future、callback 两种模式中选择？\n显然同步能做的事情异步也能做，但是异步调用会涉及到线程上下文的切换、异步线程池的设置等等，较为复杂。如果你的场景比较简单，比如整个流程就一个调用并处理结果，那么建议使用同步的方式处理；如果整个过程需要分几个步骤执行，可以拆分不同的步骤异步执行，给耗时的操作分配更多的资源来提升系统整体的吞吐。\n在 future 和 callback 的选择中，callback 是更彻底的异步调用，future 适用于需要协调多个异步调用的场景。比如需要调用多个服务，并且根据多个服务端响应结果执行逻辑时，可以采用 future 的模式给多个服务发送请求，在统一对所有的 future 进行处理完成协同操作。\n超时控制机制 在上一部分的通信模型中，除了 oneway 之后，其他三种（sync、future、callback）都需要进行超时控制，因为用户需要在预期的时间内拿到结果。超时控制简单来说就是在用户发起调用后，在预期的时间内如果没有拿到服务端响应的结果，那么这次调用就超时了，需要让用户感知到超时，避免一直阻塞调用线程或者 callback 永远得不到执行。\n在通信框架中，超时控制必须要满足高效、准确的要求，因为通信框架是分布式系统的基础组件，一旦通信框架出现性能问题，那么上层系统的性能显然是无法提升的。超时控制的准确性也非常重要，比如用户预期一次调用最多只能执行3秒，因为超时控制不准确导致用户调用时线程被阻塞了4秒，这显然是不能接受的。\nSOFABolt 的超时控制采用了 Netty 中的 HashedWheelTimer，其原理如上图。假设一次 tick 表示100毫秒，那么上面的时间轮 tick 一轮表示800毫秒，如果需要在300毫秒后触发超时，那么这个超时任务会被放到\u0026#39;2\u0026amp;rsquo;的 bucket 中，等到 tick 到\u0026#39;2\u0026amp;rsquo;时则被触发。如果一个超时任务需要在900毫秒后触发，那么它会被放到如\u0026#39;0\u0026amp;rsquo;的 bucket 中，并标记 task 的 remainingRounds=1，当第一次 tick 到\u0026#39;0\u0026amp;rsquo;时发现 remainingRounds 不等于0，会对 remainingRounds 进行减1操作，当第二次 tick 到\u0026#39;0\u0026#39;，发现这个任务的 remainingRounds 是0，则触发这个任务。\n如果将时间轮的一次 tick 设置为1秒，ticksPerWheel 设置为60，那么就是现实时钟的秒针，走完一圈代表一分钟。如果一个任务需要再1分15秒后执行，就是标记为秒针走一轮之后指向第15格时触发。关于时间轮的原理推荐阅读下面这篇论文： 《Hashed and Hierarchical Timing Wheels: data structures to efficiently implement a timer facility》。\n快速失败机制 超时控制机制可以保证客户端的调用在一个预期时间之后一定会拿到一个响应，无论这个响应是由服务端返回的真实响应，还是触发了超时。如果因为某些原因导致客户端的调用超时了，而服务端在超时之后实际将响应结果返回给客户端了会怎么样？\n这个响应结果在客户端会被丢弃，因为对应的请 …","date":1593694800,"description":"开源网络通信框架 SOFABolt 首次线上直播文字回顾。","dir":"blog/sofa-channel-17-retrospect/","fuzzywordcount":5500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"9f88cb52dccf190278f16c9eab448644","permalink":"/blog/sofa-channel-17-retrospect/","publishdate":"2020-07-02T21:00:00+08:00","readingtime":11,"relpermalink":"/blog/sofa-channel-17-retrospect/","summary":"SOFA:Channel/，有趣实用的分布式架构频道。 回顾视频以及 PPT 查看地址见文末。欢迎加入直播互动钉钉群 : 30315793，不错过每场直播","tags":["SOFAChannel","SOFABolt"],"title":"网络通信框架 SOFABolt 功能介绍及协议框架解析 | SOFAChannel#17 直播回顾","type":"blog","url":"/blog/sofa-channel-17-retrospect/","wordcount":5421},{"author":"敖小剑","categories":"微服务","content":" 最近社区频繁出现的对微服务的各种质疑和反思的声音，甚至放弃微服务回归单体。本文从“分布式单体”问题出发，介绍通过引入非侵入式方案和引入Event/EDA 来走出微服务实践误区：从单体到微服务，却最后沦为分布式单体。\n 回顾：从单体到微服务到 Function 在过去几年间，微服务架构成为业界主流，很多公司开始采用微服务，并迁移原有的单体应用迁移到微服务架构。从架构上，微服务和单体最大的变化在于微服务架构下应用的粒度被“拆小”：将所有业务逻辑都在一起的单体应用，按照领域模型拆分为多个内聚而自治的“更小”的应用。而 Function 则在拆分上更进一步，拆分粒度变成了“单个操作”，基于 Function 逐渐演进出现 FaaS 形态和 Serverless 架构。\n在微服务和 Serverless 的喧嚣中，也逐渐出现了很多质疑和反对的声音：越来越多的人发现，当他们兴冲冲的迁移单体应用到微服务和 Serverless 架构之后，得到的收益并没有期望中的那么理想。最近，出现了对微服务的各种质疑、反思的声音，甚至放弃微服务回归单体。举例，我在 InfoQ 中国网站 简单搜索关键字“微服务”，前三页中就出现了如下的内容：\n 我们为什么停用微服务？ 这些公司为什么放弃微服务？ 什么？你的团队没有100人，那就不要用微服务了！ 致传统企业朋友：不够痛就别微服务，有坑 微服务带来的心理阴影 微服务到底该多大？如何设计微服务的粒度？ Uber 团队放弃微服务改用宏服务，网友评论炸锅了 为什么 Segment 从微服务回归单体  无论是支持还是反对微服务的声音，大多都是着眼于组织架构（康威定律，对应用和代码的 ownership）、微服务拆分（粒度大小，如何识别领域模型和业务边界）、分布式事务（跨多个微服务调用时维持一致性），工具（自动化构建、部署，可测试性，监控，分布式链路跟踪，CI/CD），数据库分离（避免多个微服务尤其是领域模型外的微服务共享数据库）等方面进行合理性分析和观点阐述，相信大家都对这些问题都有了解。\n而我今天的文章，将从另外一个角度来看待微服务（也包括 Serverless）实践中存在的误区——辛辛苦苦从单体走到微服务，却最后沦为分布式单体。\n分布式单体 “Distributed Monolith”，分布式单体，这真是一个悲伤的技术术语。而这偏偏是企业采用微服务后通常最容易踏进去的一个“陷阱”，事实上我看到的很多微服务落地最终都是以\u0026amp;quot;分布式单体\u0026amp;quot;收场，无法获得微服务的完整收益。\n问题源于微服务实施的方式 —— 按照业务逻辑拆解单体，划分为多个微服务，定义 API 接口，然后通过 REST 或者 RPC 进行远程调用，最终把这些微服务组合起来提供各种业务功能。简单说，就是在业务拆分的基础上，用进程间的远程调用简单替代原来进程内的方法调用。期间，对于原来使用的各种分布式能力，继续沿用之前的方式，简单说：方式不变，只是粒度变小。\n从方法论说这样做无可厚非，这也是微服务采用过程中非常标准的做法。但问题在于，止步于此是不够的 —— 至少存在两个有待继续努力改进的地方。\n分布式单体起因之一：通过共享库和网络客户端访问分布式能力 分布式能力的共享库和网络客户端是造成分布式单体问题的原因之一，关于这一点，来自 verizon 的 Mohamad Byan 在他的名为 Avoid the Distributed Monolith!! 的演讲中有详细的阐述，我这里援引他的图片和观点：\n上图是微服务体系的逻辑架构，由两部分组成：\n 内层架构（图上浅蓝色部分），是每个微服务的实现架构； 外层架构（图上黄色部分），是构建强大微服务架构所需要的各种能力，这里通常有大家熟悉的各种分布式能力；   特别提示：这里说的“网络客户端”是各种分布式能力的客户端，如服务注册发现/ MQ 中间件/ Redis 等 key-value 存储/数据库/监控日志追踪系统/安全体系等，不是服务间通讯如 RPC 的客户端。\n 而内层的微服务是通过 共享类库 和 网络客户端 来访问外层架构提供的分布式能力：\n分布式能力的 共享类库 和 网络客户端 会迫使内层微服务和外层架构的各种分布式能力之间产生强耦合，增加运维的复杂性（如升级困难造成版本碎片化），多语言受限于类库和网络客户端支持的语言，各种组件（如消息中间件）往往使用自定义数据格式和通讯协议 —— 所有这些迫使内层微服务不得不实质性受限于外层架构的技术选型。\n对于 Function，这个问题就更加明显了：Function 的粒度更小，更专注业务逻辑。某些简短的 Function 可能只有几百行代码，但是，为了让这几百行代码运转起来而需要引入的共享类库和网络客户端可能相比之下就规模惊人了。援引一张网上图片作为示意：\n分布式单体起因之二：简单用远程调用替代进程内方法调用 在微服务架构改造过程中，熟悉单体系统和架构的开发人员，习惯性的会将这些单体时代的知识和经验重用到新的微服务架构之中。其中最典型的做法就是：在遵循领域模型将现有单体应用按照业务边界拆分为多个微服务时，往往选择用 REST 或者 RPC 等远程调用方式简单替代原有的进程内方法调用。\n当两个逻辑上的业务模块存在协作需求时：\n从单体到微服务，直接方法调用被替换为远程调用（REST 或者 RPC），即使采用 Service Mesh 也只是在链路中多增加了 Sidecar 节点，并未改变远程调用的性质：\n这导致了前面所说的 “分布式单体”：\n 在微服务之前：应用程序由多个耦合在一起的模块组成，这些模块通过内存空间进行方法调用….. 在微服务之后：应用程序由多个耦合在一起的微服务组成，这些微服务通过网络进行远程调用…..  抛开调用方式的差异来看采用微服务前后的系统架构，会发现：两者几乎是完全一样的！！\n而微服务版本在某些情况下可能表现的更糟糕：因为调用方式更脆弱，因为网络远比内存不可靠。而我们将网络当成 “胶水” 来使用，试图把分散的业务逻辑模块（已经拆分为微服务）按照单体时代的同样方式简单粘在一起，这当然比单体在同一个进程内直接方法调用更加的不可靠。\n 关于这一点，在 \u0026amp;ldquo;The Eight Fallacies of Distributed Computing/分布式计算的8个谬论\u0026amp;rdquo; 一文中有详细阐述。\n 类似的，在采用 Function 时，如果依然沿用上面的方式，以单体或微服务架构的思维方式和设计模式来创建 FaaS/Serverless 架构：\n其本质不会发生变化 —— 不过是将微服务变成粒度更小的函数，导致系统中的远程调用数量大为增加：\n系统内的耦合并没有发生变化，Serverless 并不能改变微服务中存在的这个内部耦合问题：调用在哪里，则耦合就在哪里！只是把将组件的粒度从 “微服务“换成了 “Function/函数”。\n耦合的存在是源于系统不同组件之间的通讯模式，而不是实现通讯的技术。\n如果让两个组件通过“调用”（后面再展开讲何为调用）进行远程通信，那么不管调用是如何实现的，这两个组件都是紧密耦合。因此，当系统从单体到微服务到 Serverless，如果止步于简单的用远程调用替代 …","date":1593414000,"description":"本文从“分布式单体”问题出发，介绍通过引入非侵入式方案和引入Event/EDA 来走出微服务实践误区：从单体到微服务，却最后沦为分布式单体。","dir":"blog/microservices-misunderstanding-avoid-monolith-to-distributed-monolith/","fuzzywordcount":9800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"9ab906cecb82200b18dceb4ab43ba46a","permalink":"/blog/microservices-misunderstanding-avoid-monolith-to-distributed-monolith/","publishdate":"2020-06-29T15:00:00+08:00","readingtime":20,"relpermalink":"/blog/microservices-misunderstanding-avoid-monolith-to-distributed-monolith/","summary":"最近社区频繁出现的对微服务的各种质疑和反思的声音，甚至放弃微服务回归单体。本文从“分布式单体”问题出发，介绍通过引入非侵入式方案和引入Eve","tags":["微服务","分布式"],"title":"走出微服务误区：避免从单体到分布式单体","type":"blog","url":"/blog/microservices-misunderstanding-avoid-monolith-to-distributed-monolith/","wordcount":9730},{"author":"王旭","categories":"镜像","content":" 众所周知，Docker 始于2013年的 dotCloud，迄今刚刚七年，如果你刚好在圈中经历了2013-2015年这段早期岁月的话，自然应该知道，最初的 Docker = LXC + aufs，前者就是所谓的 Linux 容器了，而后者则是我今天要聊的镜像。\n 千禧年：惊艳的 Live CD 说到 Linux distro，除了做差异化的界面主题之外，核心差异一般都在于：\n 如何更方便地安装； 如何更方便地升级；  而在 distro 界却有一股清流，超脱于这两件事情之外，它们就是 Live CD，它们装在一张光盘里，或者是一个 U盘上，不需要安装、也不会改变。之前创业的时候，我司的运维大佬——彤哥曾经说过：\n 第一次见到 liveCD 时我内心是震惊的。。\n 这我当然是赞同的，那时我也是震惊的同学之一，要知道 Knoppix 在 2000 千禧年就来到了世界，而它所基于的著名的 Debian，直到2005年6月，Sarge (3.1) 发布的时候才正式在 stable release 里带上了图形界面的安装程序 debian-installer （简称 d-i），此前版本的安装还在用文本菜单。就在这个年代，这样一个开光盘即用、启动起来就是图形界面的系统，给我们这些玩家带来的震撼，当然是可想而知的。那时候的 Live CD 就是十三年后的 Docker，绝对配得上“惊艳”两个字。\n要知道，一张 700MB 左右的光盘里塞下个完整的操作系统并不容易（当然有人开头之后也不太难，后来我爱的 DSL 可以做到 50MB）。Knoppix 有个很棒的想法——把装好的操作系统给压缩一下，放在光盘里， 随用随解压，这样，一张 700MB 光盘里可以放下大约 2GB 的根文件系统，这样就跑 KDE 桌面也就没啥问题了，当是时，distrowatch.com 上可以看到，一大片 distro 都是基于 Knoppix 魔改的，足见其影响力。\n进化：可读写层与 UnionFS Knoppix 在诞生之初的一个执念是“绝不碰本地存储一根指头”，而光盘，CD-ROM，所使用的 ISO9600 文件系统也是只读的，这无疑暗合了当今流行的“不可变基础设施”的潮流，但是，即使在今天，没有可写文件系统对于很多 Linux 软件仍然是非常困难的，毕竟随随便便一个程序也要写一点配置文件、状态信息、锁、日志之类的嘛。而诞生之初的 Knoppix 是不可写的，那么，要有什么东西要罗盘，就得手工挖掘出本地硬盘来挂上，或者是挂个 NAS 到 /home 或其他挂载点上来，当你不想只是做个紧急启动盘的时候，这就有点麻烦了。\n如果我们从今天穿越回去，毫不费力就可以指出，用 overlayfs 加上一个 tmpfs 做可写层嘛。但是，overlayfs 要到2010年才首次提交 patchset，2014年才被合并到 3.18内核（这中间，当时的淘宝内核组也有不少贡献和踩坑呢）。当然，比 overlay 早的类似的 unionfs 还是有的，Docker 最早采用的 Aufs 就是其中之一，它是2006年出现的，这里 AUFS 的 A，可以理解成 Advanced，但它最早的意思实际是 Another——是的，“另一个 UFS”，而它的前身就是 UnionFS。\n在2005年5月，也就是十五年前，Knoppix 创造性地引入了 UnionFS，而在一年半以后的 5.1 版本中，Knoppix 引入了当年诞生的更稳定的 aufs，此后，包括大家熟悉的 Ubuntu LiveCD、Gentoo LiveCD 全都使用了 aufs。可以说，正是 Live CD 们，提前了8年，为 Docker 和 Docker Image 的诞生，做好了存储上的准备。\n这里简单说一句给不了解的人听，所谓 union fs，是指多个不同文件系统联合（堆叠）在一起，呈现为一个文件系统，它和一般的 FHS 规定的那种树装组织方式是不同的，如下图，对于左边的标准的目录树结构，任何一个文件系统，挂载在树上的一个挂载点，根据路径，就可以指到一个确定的文件系统，比如，下图中，所有的 /usr/local/ 下面的路径都在一个文件系统上，而其他 /usr 就会在另一个文件系统上；而 UnionFS 是多层堆叠的，你写的文件会停留在最上层，比如图中，你修改过的 /etc/passwd 就会在最上的可写层，其他的文件就要去下面的层中去找，也就是说，它允许同一个目录中的不同文件在不同层中，这样，Live CD 操作系统跑起来就像真正的本地操作系统一样可以读写所有路径了。\n块或文件：Cloop 与 SquashFS 让我们把目光放在只读层上，这一层是 Live CD 的基础，在 Live CD 还没有 union FS 来做分层的时候就已经存在这个只读 rootfs 了。对 Knoppix 来说，这一层是不能直接放完整、无压缩的操作系统的，因为在21世纪初，大家都还在用 24x 到 40x 速光驱的时代，Knoppix Live CD 面临的一个大问题是 700MB 的光盘和庞大的桌面操作系统之间的矛盾。\n开头我们提到了，Knoppix 的想法就是“把装好的操作系统给压缩一下，放在光盘里， 随用随解压”，这样精心选择后的 2GB 的 Distro 就可以压到一张光盘里了，不过“随用随解压“不是说有就有的，文件系统访问块设备，是要找到块的偏移量的，压缩了之后，这个偏移量就并不那么好找了，全解压到内存里再找偏移并不那么容易。\n回到2000年，那时候还是2.2内核，Knoppix 的作者 Klaus Knopper 在创立 Knoppix 之初就引入了一种压缩的(compressed) loop 设备，称为 cloop，这种设备是一种特殊的格式，它包含了一个索引，从而让解压缩的过程对用户来说是透明的，Knoppix 的 cloop 设备看起来就是一个大约 2GB 大的块设备，当应用读写一个偏移的数据的时候，它只需要根据索引解压缩对应的数据块，并返回数据给用户就可以了，无需全盘解压缩。\n尽管 Knoppix 把众多 distro 带上了 Live CD 的船，但是，众多后继者，诸如 arch、Debian、Fedora、Gentoo、Ubuntu 等等 distro 的 LiveCD，以及大家熟悉的路由器上玩的 OpenWrt，都并没有选择 cloop 文件，它们选择了和应用语义更接近的文件系统级的解决方案——Squashfs。Squashfs 压缩了文件、inode 和目录，并支持从 4K 到 1M 的压缩单元尺寸。同样，它也是根据索引按需解压的，和 cloop 的不同之处是，当用户访问一个文件的时候，它来根据索引解压相应的文件所在的块，而非再经过一层本地文件系统到压缩块的寻址，更加简单直接。事实上，Knoppix 里也一直有呼声想要切换到 squashfs，比如，2004年就有开发者在转换 knoppix 到squashfs 上，而且，一些测试数据似乎也表明 Squashfs 的性能似乎要更好一些，尤其在元数据操作方面。\n在 wiki 上是这么评价 cloop 的缺点的：\n The …","date":1592895600,"description":"众所周知，Docker 始于2013年的 dotCloud，迄今刚刚七年，如果你刚好在圈中经历了2013-2015年这段早期岁月的话，自然应该知道，最初的 Docker = LXC + aufs，前者就是所谓的 Linux 容器了，而后者则是今天要聊的镜像。","dir":"blog/twenty-years-of-image-format-from-Knoppix-to-OCI-Image-v2/","fuzzywordcount":6200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"f918e4318b9157894559ba289b29553d","permalink":"/blog/twenty-years-of-image-format-from-knoppix-to-oci-image-v2/","publishdate":"2020-06-23T15:00:00+08:00","readingtime":13,"relpermalink":"/blog/twenty-years-of-image-format-from-knoppix-to-oci-image-v2/","summary":"众所周知，Docker 始于2013年的 dotCloud，迄今刚刚七年，如果你刚好在圈中经历了2013-2015年这段早期岁月的话，自然应该知","tags":["镜像"],"title":"镜像格式二十年：从 Knoppix 到 OCI-Image-v2","type":"blog","url":"/blog/twenty-years-of-image-format-from-knoppix-to-oci-image-v2/","wordcount":6109},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n SOFAStack 官网: https://www.sofastack.tech SOFAStack: https://github.com/sofastack  每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@雷霆 提问：\n 各位大佬 请问 TCC 拦截器这块为什么 xid 要先解绑，再绑定呢，这样做是有什么考虑吗？  A：执行 TCC 分支时，首先会解绑 xid，这是因为在 TCC 分支内，是不需要执行 AT 的 SQL 解析和自动补偿的（可以在 seata-rm-datasource 的 ExecuteTemplate 里看下实现），同时需要绑定下当前的拦截类型 TCC，这个拦截器类型在跨服务传递时也有特殊处理，建议也看下跨服务传递的源码。最后然后执行完 TCC 分支后的解绑、还原 xid 的操作，就是一个事务上下文的还原了。你目前看到的这个源码，后续我们还会优化下，更方便理解。这一系列操作是为了根据分支类型来区分分支事务的行为：AT 分支的行为是自动补偿，会走 SQL 解析和 undo 回滚，TCC 分支的行为是手动补偿，不会走 undo，而是执行用户自定义的 try 和 confirm。\n2、@taking 提问：\n 为何 TCC 模式的分支事务 commit 需要同步呢？\n A：因为如果异步 commit 会存在，退款的问题，如果没有 commit 那么事务没有完成，这时来了一笔退款交易，则原交易状态没有完成，会失败。当然也可以异步化，但是需要能够容忍一些反向交易的失败，或对反向交易做特殊处理。\n 如果 commit 被阻塞，退款请求也一样还是会失败吧？\n A：commit 被阻塞，说明支付还没有成功，前面不会发起退款的。\n 可以考虑在 LocalTCC 注解上加个属性表示是否允许异步执行。\n A：也可以的，然后在反向交易时需要能判断这个正交易是否已经完成，没有完成，触发一次事务恢复，进行 commit，然后再执行反交易。\nSeata：https://github.com/seata/seata\n本周推荐阅读  蚂蚁金服智能监控云原生可观测大盘设计概览 再启程，Service Mesh 前路虽长，尤可期许 蚂蚁金服在 Service Mesh 监控落地经验分享  SOFA 项目进展 本周发布详情如下：\n1、发布 SOFAJRaft v1.3.2 版本，主要变更如下：\n 抽象出网络通信层，增加 GRPC 实现并支持 Replication Pipeline，用户亦可自行对通信层进行其他实现的扩展； RheaKV 增加 reverseScan API ； 提供 Replicator 与 RPC 的线程池隔离，避免相互影响； read-index 线性一致读请求提供请求超时（timeout）配置； 几个 corner case 修复，比如 replicate logs 如果比 appliedIndex（follower）更小，那么可以认为是成功的； 致谢（排名不分先后） @shibd 、@SteNicholas 、@killme2008 、@zongtanghu   详细发布报告： https://github.com/sofastack/sofa-jraft/releases/tag/1.3.2\n2、发布 Occlum v0.13.0 版本，主要变更如下：\n 扩展了Occlum.json的配置格式，更强大，更易读； 增加了3个新的系统调用； 增强了编程语言支持：支持了 Rust、改进了 Python 和 Go 的 demo；  详细发布报告： https://github.com/occlum/occlum/releases/tag/0.13.0\n社区活动报名 SOFABolt 是蚂蚁金服开源的一套基于 Netty 实现的，轻量、易用、高性能、易扩展的网络通信框架。在蚂蚁金服的分布式技术体系下，我们有大量的技术产品都需要在内网进行节点间的通信。每个产品都需要考虑高吞吐、高并发的通信，私有协议设计、连接管理、兼容性等问题。\n为了将开发人员从通信框架的实现中解放出来，专注于自己产品的能力建设上，我们将在微服务与消息中间件在网络通信上解决的问题以及积累的经验进行了总结，设计并实现了 SOFABolt。\n本期分享将邀请 SOFABolt 开源负责人丞一，介绍 SOFABolt 的基本功能和部分实现原理，并介绍协议框架的实现。\n你将收获：\n 了解 SOFABolt 的基础使用及 SOFABolt 部分功能的实现原理； 了解 SOFABolt 协议框架的设计以及如何拓展实现自定义私有协议； 了解如何设计一个通信框架；  活动详情：\n **直播主题：**SOFAChannel#17：网络通信框架 SOFABolt 的功能介绍及协议框架解析 **分享嘉宾：**丞一，蚂蚁金服技术专家，主要从事通信中间件相关的开发工作，SOFABolt 开源负责人。 **直播时间：**2020/7/2（周四）19:00-20:00 **直播间：**点击“这里”，即可报名  ","date":1592550000,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20200619/","fuzzywordcount":1800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"4b795b006dbfdc77ff65a693f80f1e6c","permalink":"/blog/sofa-weekly-20200619/","publishdate":"2020-06-19T15:00:00+08:00","readingtime":4,"relpermalink":"/blog/sofa-weekly-20200619/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | SOFAJRaft、Occlum 发布、社区直播预告","type":"blog","url":"/blog/sofa-weekly-20200619/","wordcount":1742},{"author":"申尘","categories":"智能监控","content":"背景 蚂蚁金服业务自定义监控是蚂蚁金服监控产品中的一个重要功能，主要是通过自定义日志数据源并配置大盘的方式来解决蚂蚁金服业务实时监控的需求。在产品功能上，用户可以通过对一系列日志数据源的创建、组织、管理及表单配置化的方式，简单、快速组织出一个多维监控大盘。这项能力在当时是一个具有创新性的能力，从功能到产品体验上很好解决了当时蚂蚁金服复杂业务监控的痛点。\n但是，随着蚂蚁金服监控产品的不断迭代更新，以及云原生可观测性对于监控大盘的高要求，大家对自定义监控的体验诉求也越来越多，包括更便捷的交互方式、更丰富的图表、更丰富的数据源、更多扩展点等，因此对监控大盘的升级也势在必行。\n本文将介绍蚂蚁金服监控产品在监控大盘方面的创新设计与尝试，新版自定义监控大盘 Barad-Dur 目标成为业界体验最优秀的自定义监控大盘，在交互、体验与设计理念上有诸多创新点，同时将以模块的形式发布，支持二次开发，可以同时为蚂蚁金服内外监控系统服务。\n产品体验 WYSIWYG 当前优秀的监控大盘产品都标配一个“所见即所得（WYSIWYG）”编辑器，这方面能力是蚂蚁金服监控产品一直缺失的。在蚂蚁金服监控产品中配置大盘还是通过传统的表单方式，对用户非常不友好、学习曲线陡峭、配置效率不高。导致用户经常将配置大盘作为一项需求提给监控团队，由监控团队的“大盘配置专家”来进行配置，不仅存在较高的沟通成本，也给监控团队增加了很大的负担。\n在新版监控大盘 Barad-Dur 中，对 WYSIWYG 编辑器的交互体验进行了大量工作，力求做到市面上最优秀的编辑体验。\n体验1：缩放 Barad-Dur 的缩放是可以在四周以及四角上进行的，而市面上常见的大盘产品只支持右下角的缩放。由于坐标系统一般采用的是 (left, top, width, height) 来定义一个矩形，最容易实现的就是右下角缩放，只需要变动 width 和 height 两个参数即可。最难实现的是左上角的缩放，四个参数需要同时变动，且关系比较复杂。特别是在引入网格布局后，缩放时要自动“吸附”临近的网格点，难上加难。\n体验2：拖动 Barad-Dur 的图表拖动可以实现图表位置的一步交换，而市面上常见的大盘产品需要进行多次拖动才能实现两个图表的交换。且在拖动过程中，图表的整体布局会被打乱，而 Barad-Dur 不会存在这样的问题。\n体验3：自动重布局 Barad-Dur 的自动重布局功能非常强大，可以支持实时布局预览（当然市面上常见的大盘产品也支持），同时大盘的布局调整会根据具体操作（缩放、拖动）的方向进行。而市面上常见的大盘产品只能在垂直方向上进行布局调整，因为所用的算法非常简单，只是粗暴地把所有图表向页面上“推”。\n体验4：任意位置 Barad-Dur 的布局支持图表在任意位置摆放，而市面上常见的大盘产品由于上述的简陋算法，不支持此功能，所有的图表必须堆叠在页面的顶部。\n体验5：布局复位 Barad-Dur 的自动重布局能够在对单个图表进行调整时将其他图表“推开”，然后更强大的是可以再将被推开的图表复位。这里找到了市面上常见的大盘产品直接拿来用的开源布局框架进行对比。该框架其实提供了上述的任意位置功能，然而由于没有布局复位的功能，导致该功能一旦启用，会令整个大盘在编辑过程中布局被扰乱，对用户起不到任何帮助，所以市面上常见的大盘产品没有启用这个功能。\n体验6：文字编辑 Barad-Dur 支持在大盘中添加静态文字以及对于文字的编辑。静态文字可用于公告、标题、说明等一些常见的大盘场景。\n功能对比     Barad-Dur 市面上常见的大盘产品     任意拖动 ✔︎ ✔︎   任意缩放 ✔︎ ✘   多样图表 ✔︎ ✔︎   图表实时编辑 ✔︎ ✔︎   图表导入导出 ✔︎ ✔︎   任意布局 ✔︎ ✘   添加文字 ✔︎ ✘    综上对比，可以看出 Barad-Dur 的 WYSIWYG 编辑器在各项功能上已经领先于市面上常见的大盘产品。\n控制器 大盘，即 Dashboard (in an automobile or similar vehicle) a panel beneath the front window having various gauges and accessories for the use of the driver; instrument panel。其本意是指汽车上的仪表板，这里的仪表板包括了两类组成部分：监视器、控制器。在仪表板上不仅能看到汽车的当前状态，也能对汽车进行各种控制。这是大盘的本意，但是就目前看来，市面上所有的监控大盘产品都缺失了控制器这个重要的组成部分，导致监控大盘其实只是监视大盘。如果只是用来监视的，那大盘独立存在就没有意义，就像汽车的仪表板上只有转速表、时速表、里程表，却没有油门、刹车、换挡杆。\n我们再来看几个工业产品的大盘：\n面向普通消费者的量产产品\n面向专业消费者的量产产品\n面向专家的定制产品\n控制器是不可或缺的组成部分，甚至比监视器更加重要。Barad-Dur 提供了在大盘中设置控制按钮的功能，可以实现一些简单的控制，比如关闭/启动报警、打开钉钉聊天窗口、启动控制预案等。日后会不断加入更加强大的控制功能，让蚂蚁金服监控大盘变成一个完整的监控系统。\n技术实现 自定义数据源 上文提到 Barad-Dur 支持二次开发，支持自定义数据源，仅需一点点工作即可接入自己的数据源：\n 继承 AbstractDatasource，并实现 doRequestData 接口； 调用 registerDatasource 将数据源注册至 Barad-Dur（如果使用 Barad-Dur 的数据源编辑器，可在注册时指定自定义的数据源的编辑器）；  Barad-Dur 会对所有的数据源进行包装，提供缓存、增量加载、请求合并等功能。\n统一时序数据源 为了实现自定义数据源能够在任意图表中正确展现，Barad-Dur 定义了一种 universal 的时序数据格式，支持多 key 以及多 value。所有的时序数据源（以后可能会支持非时序数据源）都会将查询结果转换为这种格式，所有的图表也都会使用这种数据格式进行展现。\n使用统一数据格式的优势在于，图表和数据源都是按照同样的数据接口（约定）来实现的，所以图表和数据源是可以独立变化的。即图表可以任意切换而不需要改动数据源配置，数据源也可以任意切换而不需要调整图表配置。这是市面上常见的大盘产品做不到的。\n另一大优势在于计算。Barad-Dur 支持数据源的简单前端计算（如计算比率的场景需要将数据 A 与数据 B 相除），在使用了统一的数据格式之后，将计算也视为一个时序数据源，它的输入是一组时序数据源，也就是说一个计算数据源可以引用另一个计算数据源。这也是市面上常见的大盘产品做不到的。\nScene Graph Scene Graph 的概念常用于游戏引擎对于场景的渲染。由于场景中各个节点有父子关系且子节点的空间关系常常用相对于父节点的量来表示，所以需要一种数据结构来将这些 local 空间的量（translation、rotation）转变为 global 空间的量，才能最终转换成屏幕空间的量用于渲染。这 …","date":1592463600,"description":"本文将介绍蚂蚁金服监控产品在监控大盘方面的创新设计与尝试。","dir":"blog/antfin-monitoring-cloud-native-observable-market-design-overview/","fuzzywordcount":3500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"30e37e5824f0c80a9aef838c5db03a3c","permalink":"/blog/antfin-monitoring-cloud-native-observable-market-design-overview/","publishdate":"2020-06-18T15:00:00+08:00","readingtime":7,"relpermalink":"/blog/antfin-monitoring-cloud-native-observable-market-design-overview/","summary":"背景 蚂蚁金服业务自定义监控是蚂蚁金服监控产品中的一个重要功能，主要是通过自定义日志数据源并配置大盘的方式来解决蚂蚁金服业务实时监控的需求。在","tags":["智能监控"],"title":"蚂蚁金服智能监控云原生可观测大盘设计概览","type":"blog","url":"/blog/antfin-monitoring-cloud-native-observable-market-design-overview/","wordcount":3490},{"author":"涵畅","categories":"Service Mesh","content":"前言 几乎所有人都在说 Service Mesh；貌似没人知道怎么落地 Service Mesh；但是大家都觉得其他人在大力做 Service Mesh；所以大家都宣称自己在做 Service Mesh。\n上面只是开一个玩笑，但是从某种程度反映了一些实际情况：Service Mesh 是一种设计思想和理念，而不是具体的架构或者实现方式，虽然 Istio+Envoy 的配置似乎已经成了事实标准，当我们环顾四周，却发现理想太丰满，现实太骨感，因为各企业当前切实原因，导致各种形态的 Service Mesh 百花齐放。\n蚂蚁金服的 Service Mesh 就属于上面提到的百花齐放中的一员，我们已经渡过探索期，全面进入生产应用。去年的双十一完成了交易支付核心链路，几十万容器规模的生产级验证。但是业界对于 Service Mesh 仍然有很多种不同的声音，一方面是众星捧月式的支持，另一方面是困惑和质疑，包括对价值、架构以及性能的质疑。那么我们对此是什么态度？双十一深度实践之后蚂蚁金服的 Service Mesh 路又在何方？Service Mesh 架构是终点吗？\n本文将结合蚂蚁金服内部实际场景以及思考，讲述继 2019 双十一之后，蚂蚁金服在 Service Mesh 路上的规划和持续演进。\n蚂蚁金服 Service Mesh 实践回顾 上图是 2019 年蚂蚁金服双十一的实践架构，云原生网络代理 MOSN（https://github.com/mosn）作为蚂蚁金服自研数据面产品，承载了 Mesh 架构的东西向流量。对于控制平面，基于务实的前提我们探索出一套当前阶段切实可行的方案，基于传统服务发现体系落地了 Service Mesh 架构。\n这里是数据化的落地总结，在满足业务的同时，我们真正做到了对业务的低侵入：极低的资源消耗以及快速迭代能力，业务和基础技术都享受到云原生 Mesh 化所带来的红利。\nService Mesh 前路漫漫 我们再来看看 InfoQ 发布的 2020 年 4 月份 Software Architecture and Design 趋势报告，Service Mesh 目前处于 Early Adoption 代，在云原生技术圈仍处于大热阶段，各种技术论坛我们都能见到 Mesh 架构的专场，本篇文章我们不过多讨论 Service Mesh 的选型、使用场景、合理性等等问题，需要的同学可以参考一下文末历史文章，有很多蚂蚁金服对 Service Mesh 的思考。\n对于我们来说，既然在深度思考后选择了这条路，并且在去年双十一进行了深度实践，那么棋到中盘，下一步应该如何落子，除了务实落地之外，我们还要仰望星空，必须知道离诗和远方还有哪些 Gap：\n非全面云原生 前面提到我们落地 Service Mesh 时，仍然采用了传统微服务体系，虽然整体架构基于 K8s，但在控制面上并没有采用社区的方案，当然这些是有考虑的，但是随着整体架构的演进，非全面云原生化势必会成为我们持续享受云原生红利的最大障碍。\n平台能力不足 Service Mesh 的定位是解耦基础设施与业务，但是目前看来，不管是社区 Istio+Envoy 的组合，还是蚂蚁金服传统微服务+MOSN 的实践，均是把东西流量的治理作为了重点，离诗和远方还有很长的路。目前还有大量的基础设施逻辑作为 SDK 镶嵌在业务系统中，我们仍然要面临基础设施升级对业务带来的影响。\n边界流量覆盖不全 随着云原生在数据中心内部愈演愈烈，但是对于数据中心边界以及边缘网络，七层应用网络流量仍然没有形成一个全局体系，由于体系的缺失我们不得不在边界网关与 Mesh 网络两者之间各自分裂发展，均有独立的流量调度体系以及安全可信体系。\n生态融合度低 传统服务体系发展了这么多年，积累了大量宝贵的财富，Service Mesh 作为新贵出现，从两个方面来说：Service Mesh 需要传统服务体系的融入支撑，才能使现有业务迁移到 Mesh 体系；同时传统服务体系的组件也需要有和 Mesh 体系融合的能力才能持续保持竞争力。\n性能 性能是一个老生常谈的问题，Mesh 架构中质疑性能的声音也层出不穷 ，包括 Mixer 控制面，还有引入 Sidecar 造成的额外网络消耗、编解码消耗等等。不过我们可以看到社区一直在解决这些问题，包括对 Mixer 架构的重构，引入 ebpf 来加速流量劫持等等。\n综上所述，我们在 Service Mesh 上任重道远。\n将 Service Mesh 进行到底 今年我们的目标是 Mesh 全面覆盖主要业务，这将面临非常大的挑战：\n 金融级安全可信的要求，需要我们做到全链路加密与服务鉴权； 统一 Sidecar 与 Ingress Web Server； 云原生控制面的落地； 透明劫持能力； 需要承载更多的中间件能力下沉；  上面分析了目前存在的各种问题，同时结合蚂蚁金服自身的业务发展需求，那么我们可以很清晰的对症下药了，我们将上述问题抽象成三类，并进行专项攻坚：\n 以开源生态建设，来应对生态融合问题； 通过云原生标准演进，来解决非全面云原生问题； 最后通过基础核心能力增强，来治理平台能力，覆盖场景以及性能的不足的问题；  开源生态建设 我们再来回顾一下双十一之后我们做的第一个动作：在 2019 年 12 月 28 日由蚂蚁金服主办的第九期 Service Mesh Meetup 上，我们对外宣布了 MOSN 完成在 SOFAStack 的孵化，开始独立运营，以更加开放的姿态寻求合作共建伙伴：\n我们认为，未来会更多地属于那些告别大教堂、拥抱集市的人们。《大教堂与集市》\n在宣布独立运营的同时，我们也做了一系列措施：\n 独立的项目域名：mosn.io 项目地址：github.com/mosn/mosn 社区组织：MOSN Community Organization 项目管理条例：PMC、Committer 选举晋升机制等等  接下来，开源社区我们也持续做了非常多的事情，包括专题 Working Group的创建，例如 Isito WG， Dubbo WG 等等。\n同时也寻求了非常多的外部合作，超过一半的 contributor 均来自外部，接受了第一个来自 BOSS 直聘的 Committer 等等，针对生态融合，我们同Skywalking，Sentinel和Dubbo-go社区进行了深度合作。\nSkywalking 调用依赖以及服务与服务之间的调用状态，是微服务管理中一个重要指标。Skywalking 是该领域非常优秀的一款 APM 软件，MOSN 与 Skywalking 社区展开了合作，进行了两个系统的深度整合工作，目前支持：\n 调用链路拓扑展示； QPS 监控； 细粒度 RT 展示；  在今年五月份，SkyWalking 8.0 版本进行了一次全面升级，采用新的探针协议和分析逻辑，探针将更具互感知能力，更好的在 Service Mesh 下使用探针进行监控。同时，SkyWalking 将开放之前仅存在于内核中的 Metrics 指标分析体系。Prmoetheus、Spring Cloud Sleuth、Zabbix …","date":1592298000,"description":"本文将结合蚂蚁金服内部实际场景以及思考，讲述继 2019 双十一之后，蚂蚁金服在 Service Mesh 路上的规划和持续演进。","dir":"blog/service-mesh-the-road-ahead-long/","fuzzywordcount":7300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"81941474b0c2d163a199a461aaa3f2f3","permalink":"/blog/service-mesh-the-road-ahead-long/","publishdate":"2020-06-16T17:00:00+08:00","readingtime":15,"relpermalink":"/blog/service-mesh-the-road-ahead-long/","summary":"前言 几乎所有人都在说 Service Mesh；貌似没人知道怎么落地 Service Mesh；但是大家都觉得其他人在大力做 Service Mesh；所以大家都宣称自己在做 Service Mesh。 上","tags":["Service Mesh","源创会"],"title":"再启程，Service Mesh 前路虽长，尤可期许","type":"blog","url":"/blog/service-mesh-the-road-ahead-long/","wordcount":7212},{"author":"霄鸿","categories":"Service Mesh","content":"引言 Service Mesh 是目前社区最为炙手可热的技术方向，去年双11在蚂蚁金服得到全面的应用，并平稳顺滑的支撑了大促服务。作为目前规模最大的 Service Mesh 集群，本文从监控的领域对 Service Mesh 落地进行经验总结，主要从以下几方面进行介绍：\n 云原生监控，介绍蚂蚁金服 Metrics 监控的落地； 用户视角分析，介绍从应用 owner 的角度对这一基础服务设施的体验以及 SRE 从全站服务的稳定性对监控提出的要求； 未来的思考，介绍后续发展方向；  云原生监控 云原生应用的设计理念已经被越来越多的开发者接受与认可，今年蚂蚁金服应用服务全面云原生化，对我们监控服务提出更高的要求。目前 Metrics 指标监控服务也逐渐形成体系，如下图所示基于社区原生 Prometheus 采集方案在蚂蚁金服监控场景下落地。\n怎么采集 蚂蚁金服监控采集 AGENT 是部署在物理机上，支持多个采集插件，如下图，包括执行命令、日志、HTTP 请求、动态 SQL 采集、系统指标采集、JVM 采集以及进程监控等，同时支持多个解析插件自定义解析、单行文本解析、Lua 脚本解析、JSON 解析以及 Prometheus 解析等。\n在Service Mesh 监控落地中，业务方参考业界标准输出 Metrics 指标数据，监控采集该物理机不同 Pod、App 和 Sidecar 的各项指标，包含 Metrics 指标和系统服务指标（CPU、MEM、DISK、JVM、IO 等），然后计算清洗集群节点通过拉取最近周期数据进行数据汇总、groupby 等，数据采集周期又分为：5秒级数据和分钟级数据。 对于 Service Mesh 来说，主要关注的指标有系统指标和 Metrics 指标：\n 系统指标（包括 Pod、App 和 MOSN 等 Sidecar 多个维度的系统指标）：  系统指标, 包含 CPU、LOAD、MEM、BYTES、TCP、UCP 等信息； 磁盘，包含分区可用空间、使用率等信息； IO，包含 IOPS 等信息；   Metrics 指标：  PROCESSOR，包含 MOSN 进程打开的 fd 数量、申请的虚拟内存大小等进程资源信息； GO，包含 MOSN 进程 goroutine 数量(G)、thread 数量(M)以及 memstats 等 go runtime 信息； Downstream，包含全局下游累计建链数、总读取字节数、累计请求数、请求耗时等； Upstream，包含上游请求失败次数、集群累计建链数、累计断链数、异常断链次数、上游请求平均耗时等； MQ Mesh，包含发送消息总数、耗时、失败数等以及消费消息总数、耗时、失败数等； Gateway Mesh，包含 qps、rt、限流以及多维度的成功数和失败数等；    数据计算 对于 Agent 采集的数据需要从不同维度向上汇聚，满足不同用户对不同视角（LDC、IDC、APP、架构域、站点等视角）的数据需求，以适配蚂蚁金服运维架构体系。\n此时对于这么大规模的数据体系，我们团队建设蚂蚁金服统一的监控数据计算平台。\n 使用统一的监控数据标准、插件化的数据采集接入、通用的数据服务 API 服务来帮助不同的监控产品的快速迭代； 建立一套健全的数据质量体系、高可用计算集群来保障监控数据质量； 通过类 SQL 任务定义、自定义计算任务、插件化来提供丰富、开放的数据分析能力，来满足技术风险业务领域下各种复杂数据分析的需求；  其中计算任务调度（spark）执行的关键组件包括 GS(Global-Scheduler 全局图调度)和 CS (Compute-Space 计算空间)。\nGS 是平台的任务调度中心，如下图所示，它收集了所有业务的数据源配置，根据数据源之间的计算关系，构建出全局计算任务拓扑模型(GlobalGraph)。再根据不同的任务执行策略，将全局任务拓扑图切割成小范围的任务拓扑(Graph)。主要特性有：\n GS 根据任务优先级、资源质量、负载情况等策略，将 Graph 分发到不同的计算空间进行计算(Cspace)； 同一个 Graph 内部的数据依赖是计算过程中直接依赖的； 不同的 Graph 之间的数据依赖会通过存储进行数据解耦； GS 会管理所有 Graph 及计算节点的任务状态，根据 Graph 的依赖关系和依赖 Graph 的执行状态，控制 Graph 的执行时间；  CS 是计算平台抽象的计算任务执行空间，如下图所示，主要负责 Graph 的解析和具体计算任务的提交执行，适用于不同的计算引擎，如 Spark/Flink。以 Spark 为例，CS 接收到 GS 发出的 GraphTask，根据 GraphTask 中的 Node(Transform) 解析成 Spark 的 Transfomation 算子和 Action 算子，组成计算 DAG 并提交到 Spark 集群执行。\n在任务执行过程中，CS 会向 GS 同步各任务的执行状态，用于任务跟踪监控。\n多个 CSpace 组成一个 CSpaceGroup，CSpace 之间可以根据负载均衡、资源等级、蓝绿发布等具体场景划分不同的计算分组，多个 CSpace 之间的任务切流可以满足负载均衡、资源隔离、蓝绿发布、灰度等高可用的要求。\n规模化问题 对于蚂蚁金服这么大规模的 Service Mesh 集群数据，产品请求无法都通过 PromQL 方式实时查询结果，以及报警及时通知。此时我们对于监控数据进行分类，其中应用、机房、站点等维度数据进行预计算聚合，例如不同机房的 QPS、RPC 转发成功量、Error 错误等等，前端通过自定义配置出自己关注的大盘视图。\n其中今年大促 MOSN 容器达到几十万，在频繁的发布部署，上线下线过程中，对监控查看的实时性提出更高的要求。其中 Meta 元数据模块对接 K8s 集群，部署监控 operator 监控容器状态变化，达到秒级将最新采集配置通过 Agent registry 更新到 Agent 模块。\n大促保障 我们一方面对监控高可用进行保障，做到采集计算水平扩缩容，另一方面对容量进行评估，通过对不同任务进行分级处理，在大促的时候对高优先级任务进行重点保障，对低优先级任务和业务方进行沟通做降级处理。这样在监控计算资源紧张的情况下，保障核心数据稳定。\n产品视角 Service Mesh 是蚂蚁金服内部应用服务所使用的基础服务设施，对不同的用户看的视角不一样。在监控产品上，用户对产品的使用主要集中在“配、看、用”数据这三个层面。我们早期也做过类似的用户分析。在蚂蚁金服按使用方式将用户分为全局关注者，产品 owner、SRE、领域专家和普通用户等，这里监控产品对于 Service Mesh 也提供不同的视角满足不同的用户需求，举例来说：\n 产品 Owner 视角：特指 MOSN 产品的开发们，他们重点负责 MOSN 的监控指标数据覆盖、数据准确性以及重点调优目标； 普通用户视角：特指应用 Owner，应用 Owner 主要看 MOSN 服务对应用 RPC 调用的影响以及该应用使用 MOSN 服务带来的效率提升； SRE 视角：他 …","date":1592204400,"description":"作为目前规模最大的 Service Mesh 集群，本文从监控的领域对 Service Mesh 落地进行经验总结","dir":"blog/antfin-service-mesh-monitor-landing-experience/","fuzzywordcount":3800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"5728ecea53b7505a29fdd8d498a8f111","permalink":"/blog/antfin-service-mesh-monitor-landing-experience/","publishdate":"2020-06-15T15:00:00+08:00","readingtime":8,"relpermalink":"/blog/antfin-service-mesh-monitor-landing-experience/","summary":"引言 Service Mesh 是目前社区最为炙手可热的技术方向，去年双11在蚂蚁金服得到全面的应用，并平稳顺滑的支撑了大促服务。作为目前规模最大的 Service Mesh 集群，本文从","tags":["Service Mesh","智能运维"],"title":"蚂蚁金服在 Service Mesh 监控落地经验总结","type":"blog","url":"/blog/antfin-service-mesh-monitor-landing-experience/","wordcount":3749},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n SOFAStack 官网: https://www.sofastack.tech SOFAStack: https://github.com/sofastack  这里有个机会和 SOFAStack 一起玩，你要不要来？ 阿里巴巴编程之夏（Alibaba Summer of Code，以下简称 ASoC）是面向全球18岁及以上本科、硕士、博士高校学生的编程普惠计划，鼓励高校学生深度参与开源开发活动，以第一视角感受开源世界的魅力，成为开源社区新鲜“血液”。\n今年 SOFAStack 开源社区也加入了选题，有兴趣的同学可以尝试下以下 feature：\nSOFAJRaft\n是基于 RAFT 一致性算法的生产级高性能 Java 实现，支持 MULTI-RAFT-GROUP，适用于高负载低延迟的场景。 使用 SOFAJRaft 你可以专注于自己的业务领域，由 SOFAJRaft 负责处理所有与 RAFT 相关的技术难题，并且 SOFAJRaft 非常易于使用。\n  Feature1:当前 LogStorage 的实现，采用 index 与 data 分离的设计，我们将 key 和 value 的 offset 作为索引写入 rocksdb，同时日志条目（data）写入 Segnemt Log，因为使用 SOFAJRaft 的用户经常也使用了不同版本的 rocksdb，这就要求用户不得不更换自己的 rocksdb 版本来适应 SOFAJRaft， 所以我们希望做一个改进：移除对 rocksdb 的依赖，构建出一个纯 java 实现的索引模块。这个 feature 难度适中，https://github.com/sofastack/sofa-jraft/issues/453\n  Feature2:这个 feature 更有挑战些，在 multi raft group 场景中，可能有多个 raft node 在同一个进程中并且很多都是 leader，当他们各自向自己的 followers 发送心跳时会过多的消耗 CPU 和网络 IO。例如我们可以在同一个进程内共享心跳计时器并将这些 leaders 发往同一台机器的心跳请求合并起来发送出去，以此来减少系统消耗，当然你还可以提供更多的优化方案。欢迎尝试 https://github.com/sofastack/sofa-jraft/issues/454\n  SOFABolt\n是基于 Netty 最佳实践的轻量、易用、高性能、易扩展的通信框架。 这些年我们在微服务与消息中间件在网络通信上解决过很多问题，我们把总结出的解决方案沉淀到 SOFABolt 这个基础组件里，让更多的使用网络通信的场景能够统一受益。\n Feature：当前的SOFABolt实现中私有协议是直接和整体框架耦合在一起的，在使用SOFABolt的同时需要使用提供的私有协议，当用户希望使用自己的自定义协议时需要进行比较有挑战的代码拓展才能实现。因此我们希望对SOFABolt的协议框架做一些重构以支持快速方便的集成用户的自定义协议。这个 feature 稍有难度，欢迎尝试，https://github.com/sofastack/sofa-bolt/issues/224  每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动\n我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@明詹 提问：\n 问下 SOFATracer 现在支持 RabbitMQ 吗？\n A：原生 RabbitMQ API ，Tracer 是没有埋点的；如果和 Spring 集成的，可以基于 Spring Message 方式埋点。使用最新版本即可。 SOFATracer：https://github.com/sofastack/sofa-tracer\n2、@雷霆 提问：\n 请问一下，如果 TCC 在提交全局事务时失败了，比如网络或者 TC 服务异常，导致 TC 压根没有收到全局事务提交的通知，此时 TM 会抛一个异常，导致整个业务处理失败，这个时候已经在一阶段冻结的资源还会回滚吗？看了 Seata 源码，对于这种情况没有看到有触发回滚的操作。\n A：TCC 先注册分支再执行 Try，如果注册分支失败那么 Try 不会执行，如果注册分支成功了 Try 方法失败了，那应该抛出异常触发主动回滚或者触发 Server 超时回滚。\n 那如果分支已经注册成功，且 Try 也执行成功了，就是在 TM 向 TC 发起 global commit 时失败了，TM 多次重试失败后抛了异常，TC 没有收到 commit，这种情况下还会有 rollback 吗？\n A：这种情况触发超时回滚，TC 主动来回滚超时的事务。\n 明白了 谢谢~\n Seata：https://github.com/seata/seata\n本周推荐阅读  记一次在 MOSN 对 Dubbo、Dubbo-go-hessian2 的性能优化 Forrester 中国首席分析师戴鲲：云原生技术趋向成熟，金融企业选择云原生平台需满足三大要求  社区活动报名 SOFABolt 是蚂蚁金服开源的一套基于 Netty 实现的，轻量、易用、高性能、易扩展的网络通信框架。在蚂蚁金服的分布式技术体系下，我们有大量的技术产品都需要在内网进行节点间的通信。每个产品都需要考虑高吞吐、高并发的通信，私有协议设计、连接管理、兼容性等问题。\n为了将开发人员从通信框架的实现中解放出来，专注于自己产品的能力建设上，我们将在微服务与消息中间件在网络通信上解决的问题以及积累的经验进行了总结，设计并实现了 SOFABolt。\n本期分享将邀请 SOFABolt 开源负责人丞一，介绍 SOFABolt 的基本功能和部分实现原理，并介绍协议框架的实现。\n你将收获：\n 了解 SOFABolt 的基础使用及 SOFABolt 部分功能的实现原理； 了解 SOFABolt 协议框架的设计以及如何拓展实现自定义私有协议； 了解如何设计一个通信框架；  活动详情：\n **直播主题：**SOFAChannel#17：网络通信框架 SOFABolt 的功能介绍及协议框架解析 **分享嘉宾：**丞一，蚂蚁金服技术专家，主要从事通信中间件相关的开发工作，SOFABolt 开源负责人。 **直播时间：**2020/7/2（周四）19:00-20:00 **直播间：**点击“这里”，即可报名  ","date":1591945200,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20200612/","fuzzywordcount":2300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"a85bdf92bd596c0809df4b4464b8a85b","permalink":"/blog/sofa-weekly-20200612/","publishdate":"2020-06-12T15:00:00+08:00","readingtime":5,"relpermalink":"/blog/sofa-weekly-20200612/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | 绝妙的机会与 SOFAStack 一起玩、社区直播预告","type":"blog","url":"/blog/sofa-weekly-20200612/","wordcount":2217},{"author":"潘潘","categories":"SOFAChannel","content":"概要   活动主题：SOFAChannel#17：网络通信框架 SOFABolt 的功能介绍及协议框架解析\n  活动时间：7 月 2 日周四晚 7 点\n  活动形式：线上直播\n  报名方式：戳这里\n  介绍 | SOFAChannel \u0026amp;lt;SOFA:Channel/\u0026amp;gt; 有趣实用的分布式架构频道，前沿技术、直播 Coding、观点“抬杠”，多种形式。\n\u0026amp;lt;SOFA:Channel/\u0026amp;gt; 将作为 SOFA 所有在线内容的承载，包含直播/音视频教程，集中体现 SOFAStack 的能力全景图。\n| SOFAChannel#16：不得不说的云原生隔离性 SOFABolt 是蚂蚁金服开源的一套基于 Netty 实现的，轻量、易用、高性能、易扩展的网络通信框架。在蚂蚁金服的分布式技术体系下，我们有大量的技术产品都需要在内网进行节点间的通信。每个产品都需要考虑高吞吐、高并发的通信，私有协议设计、连接管理、兼容性等问题。\n为了将开发人员从通信框架的实现中解放出来，专注于自己产品的能力建设上，我们将在微服务与消息中间件在网络通信上解决的问题以及积累的经验进行了总结，设计并实现了 SOFABolt。本期分享将介绍 SOFABolt 的基本功能和部分实现原理，并介绍协议框架的实现。\n| 加入 SOFA 钉钉互动群 欢迎加入直播互动钉钉群：30315793（搜索群号加入即可）\n| 点击即可报名 https://tech.antfin.com/community/live/1265\n议程 19:00-19:05 主持人开场 SOFAGirl 主持人\n19:05-20:00 不得不说的云原生隔离性 丞一 SOFABolt 开源负责人\n你将收获  了解 SOFABolt 的基础使用及 SOFABolt 部分功能的实现原理； 了解 SOFABolt 协议框架的设计以及如何拓展实现自定义私有协议； 了解如何设计一个通信框架；  嘉宾  SOFAGirl 主持人 丞一 SOFABolt 开源负责人  ","date":1591945200,"description":"7 月 2 日周四晚 7 点，线上直播第 17 期。","dir":"activities/sofa-channel-17/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"6b021a35ee168e2bc4cb3350c6828d68","permalink":"/activities/sofa-channel-17/","publishdate":"2020-06-12T15:00:00+08:00","readingtime":2,"relpermalink":"/activities/sofa-channel-17/","summary":"概要 活动主题：SOFAChannel#17：网络通信框架 SOFABolt 的功能介绍及协议框架解析 活动时间：7 月 2 日周四晚 7 点 活动形式：线上直播 报名方式：戳","tags":["SOFAChannel","SOFABolt"],"title":"SOFAChannel#17：网络通信框架 SOFABolt 的功能介绍及协议框架解析","type":"activities","url":"/activities/sofa-channel-17/","wordcount":574},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"6月9日，在2020阿里云线上峰会上，蚂蚁联合全球知名市场研究与咨询机构 Forrester 发布《蚂蚁 SOFAStack 总体经济影响报告——金融级云原生市场趋势以及云原生平台带来的成本节省和业务优势》（以下简称“白皮书”）。《白皮书》指出，随着云计算在各行各业的落地不断深化，被技术赋能的企业早已加速构建企业级平台，通过推进数字化转型来塑造可持续的竞争力。其中云平台使能新型基础设施，赋能数字商业模式，成为了社会经济新旧动能转换和信息化应用创新发展的重要数字底座。\n云原生技术已趋向成熟 为金融企业带来全新业务价值与技术优势 Forrester 首席分析师戴鲲表示，越来越多的企业正在借助以云计算为代表的数字技术的巨大潜力，不断提供数字化的客户体验，改进卓越运营能力，加速数字创新进程，构建和扩展数字生态体系，从而加速数字化转型来塑造可持续的竞争力。\n他指出，尤其是一些积极采用新兴技术的泛金融企业，更在加速构建企业级云平台，取得了显著的早期业务成果。而伴随着在应用基础设施、应用软件架构、开发模式与部署架构四个层面协同进化与趋向成熟，云原生技术已为包括金融行业在内的各行各业的企业与机构带来了全新的业务价值与技术优势，具体表现在：\n应用基础设施 从物理机和虚拟机向大规模容器集群进化 容器技术可以实现更高密度的宿主机部署能力和伸缩性，提供更好的性能、更低的空间占用率以及更高的资源利用率，可以实现基础架构的自动化与高效率，帮助金融企业更好地满足大规模互联网业务的动态工作负载支撑要求，从而为客户获得一致的差异化体验提供有效保障。\n应用软件架构 从集中式单体和多层架构向分布式微服务架构进化 微服务框架进一步增强了应用架构伸缩性，通过模块化的复用能力与渐进式的变更能力加速应用价值交付；服务网格为微服务应用带来更为强大的服务间网络连接、可见性和安全性；无服务器计算以全新的编程模型实现应用松耦合和自动伸缩性，有效屏蔽基础架构的复杂性；而边缘计算与物联网技术的发展也使得企业计算架构从中心化向分布式演进，加速洞察的获得与决策反馈的闭环。\n开发模式 从瀑布式和敏捷式向 DevOps 进化 容器技术可以提供良好定义、一致的、高度可迁移的应用软件包，帮助改善开发和运营团队之间的协作过程。而微服务架构的细粒度可重用模块化特性可以帮助技术部门通过技术组件与业务服务的动态组装，通过与持续集成和持续交付流水线的有效集成，实现面向 DevOps 的软件交付，从而加速企业创新进程，有效提升市场响应效率，迅速满足企业内部不同业务部门与区域环境的差异化客户与业务需求。\n运营模式 从单一云环境向混合私有云与公有云的多云环境进化 根据 Forrester 的研究，面向多云、混合云环境的云平台管理能力已经成为了中国乃至全球企业的常态化需求。企业不仅需要在基础架构层面实现跨集群发布部署和跨云平台管控，而且需要具备面向异构资源的一体化管理能力，包括虚机与容器集群的混合管控、经典多层架构与微服务架构的混合支持、传统开发框架与包括大数据和机器学习等在内的新兴技术框架混合使能等。\n如何借助合作伙伴力量 以平台化方式构建金融级云原生能力？ 在迈向云原生的路上，新兴技术带来战略业务价值的同时，也必然引入更多的不确定性。一方面云原生技术依然处在快速演进阶段，距离金融行业所需要的在云端运行关键任务系统的金融级特性仍存在显著差距，另一方面，云原生技术本身在应用架构、开发测试部署过程、应用重构与迁移路径以及系统运维等各个领域都具有技术和管理复杂性。\n戴鲲指出，金融机构在云原生技术的落地实践过程中，必须通过审慎务实的整体战略规划，以平台化的方式有效构建金融级云原生能力，借助合作伙伴的技术深度、生态系统广度以及相关行业实践的专业度，加速可持续的信息化应用创新，真正释放数字基础设施的巨大潜能，需要从以下三大领域进行考虑。\n面向架构敏捷性 构建稳健的集成技术平台，打造业务创新引擎 金融行业的传统企业在长期发展历程中往往积累了大量的技术资产，因此，金融级云原生平台不仅必须具备融合支持能力，还应当以工具化、产品化的方式，帮助开发与运维团队实现云原生应用的快速开发迭代与对存量应用资产的平滑迁移，从而加速金融业务创新进程。\n聚焦业务连续性 基于金融技术风险防控，保障业务稳妥演进 金融级云原生平台必须能够在混合环境下，具备业务同城双活甚至异地多活的高可用容灾能力，而且能够基于单元化架构和数据分片等技术，实现多活容灾的单元化。同时，还应当具备灵活可控的应用发布进程，通过按需暂停回滚、分组灰度发布和原地升级等能力，实现应用的平滑演进；并具备可定制的流程编排能力，实现巡检诊断与容灾应急的自动化。\n追求运维精益性 关注安全可信稳定连续，降低运维保障成本 首先，金融级云原生平台必须具备基于策略的弹性规则配置能力，并通过多维度资源分析、网络流量调拨、实时指标评估以及灵活的回滚方式支持等技术，实现优雅的弹性伸缩。其次，平台必须为全链路可观测性提供支持，不仅提供多维度的监控数据，而且具备场景化的支持能力。最后，平台必须从应用视角出发，结合服务目录、服务网格、日志服务、链路跟踪等技术组件，为大规模分布式业务系统提供可视化的自动化运维能力，有效简化云原生运维过程。\nForrester 为众多希望推动完成数字化转型的金融企业和机构在云计算发展领域提出了以上有关发展方向的战略建议。蚂蚁金服自主研发的金融级分布式架构 SOFAStack（Scalable Open Financial Architecture Stack）作为构建金融级云原生架构的应用平台，沉淀了金融场景的最佳实践。在企业面向金融级环境采用云原生技术过程中面临困难时，蚂蚁 SOFAStack 能够提供从服务构建、应用开发、部署发布、服务治理、监控运维、容灾高可用等全生命周期、全栈式解决方案，兼容 Dubbo、Spring Cloud 等微服务运行环境，助力客户各类应用轻松转型分布式架构。\n点击，获取完整 《白皮书》\n","date":1591858800,"description":"云原生技术已趋向成熟 为金融企业带来全新业务价值与技术优势","dir":"blog/forrester-daipeng-white-paper-cloud-native/","fuzzywordcount":2400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"eb590c61c39c7b48afdb5abd95889b99","permalink":"/blog/forrester-daipeng-white-paper-cloud-native/","publishdate":"2020-06-11T15:00:00+08:00","readingtime":5,"relpermalink":"/blog/forrester-daipeng-white-paper-cloud-native/","summary":"6月9日，在2020阿里云线上峰会上，蚂蚁联合全球知名市场研究与咨询机构 Forrester 发布《蚂蚁 SOFAStack 总体经济影响报告——金融级云原生市场趋势以及云原生平台","tags":["SOFAStack","云原生"],"title":"Forrester 中国首席分析师戴鲲：云原生技术趋向成熟，金融企业选择云原生平台需满足三大要求","type":"blog","url":"/blog/forrester-daipeng-white-paper-cloud-native/","wordcount":2340},{"author":"诣极","categories":"MOSN","content":"背景 蚂蚁金服内部对 Service Mesh 的稳定性和性能要求是比较高的，内部 MOSN 广泛用于生产环境。在云上和开源社区，RPC 领域 Dubbo 和 Spring Cloud 同样广泛用于生产环境，我们在 MOSN 基础上，支持了 Dubbo 和 Spring Cloud 流量代理。我们发现在支持 Dubbo 协议过程中，经过 Mesh 流量代理后，性能有非常大的性能损耗，在大商户落地 Mesh 中也对性能有较高要求，因此本文会重点描述在基于 Go 语言库 dubbo-go-hessian2 、Dubbo 协议中对 MOSN 所做的性能优化。\n性能优化概述 根据实际业务部署场景，并没有选用高性能机器，使用普通 Linux 机器，配置和压测参数如下：\n Intel(R) Xeon(R) Platinum 8163 CPU @ 2.50GHz 4核16G； pod 配置 2c、1g，jvm 参数 -server -Xms1024m -Xmx1024m； 网络延迟 0.23ms, 2台 Linux 机器，分别部署 server+MOSN, 压测程序 rpc-perfomance；  经过3轮性能优化后，使用优化版本 MOSN 将会获得以下性能收益(框架随机512和1k字节压测)：\n 512字节：MOSN+Dubbo 服务调用 tps 整体提升55-82.8%，rt 降低45%左右，内存占用 40M； 1k数据：MOSN+Dubbo 服务调用 tps 整体提升51.1-69.3%，rt 降低41%左右, 内存占用 41M；  性能优化工具 pprof 磨刀不误砍柴工，在性能优化前首先要找到性能卡点，找到性能卡点后，另一个难点就是如何用高效代码优化替代 slow code。因为蚂蚁金服 Service Mesh 是基于 Go 语言实现的，我们首选 Go 自带的 pprof 性能工具，我们简要介绍这个工具如何使用。如果我们 Go 库自带 http.Server 时并且在 main 头部导入import _ \u0026amp;quot;net/http/pprof\u0026amp;quot;，Go 会帮我们挂载对应的 handler, 详细可以参考 godoc 。\n因为 MOSN 默认会在34902端口暴露 http 服务，通过以下命令轻松获取 MOSN 的性能诊断文件：\ngo tool pprof -seconds 60 http://benchmark-server-ip:34902/debug/pprof/profile # 会生成类似以下文件，该命令采样cpu 60秒 # pprof.mosn.samples.cpu.001.pb.gz 然后继续用 pprof 打开诊断文件，方便在浏览器查看，在图1-1给出压测后 profiler 火焰图：\n# http=:8000代表pprof打开8000端口然后用于web浏览器分析 # mosnd代表mosn的二进制可执行文件，用于分析代码符号 # pprof.mosn.samples.cpu.001.pb.gz是cpu诊断文件 go tool pprof -http=:8000 mosnd pprof.mosn.samples.cpu.001.pb.gz 在获得诊断数据后，可以切到浏览器 Flame Graph(火焰图，Go 1.11以上版本自带)，火焰图的 X 轴坐标代表 CPU 消耗情况，Y 轴代码方法调用堆栈。在优化开始之前，我们借助 Go 工具 pprof 可以诊断出大致的性能卡点在以下几个方面(直接压 Server 端 MOSN)：\n MOSN 在接收 Dubbo 请求，CPU 卡点在streamConnection.Dispatch； MOSN 在转发 Dubbo 请求，CPU 卡点在 downStream.Receive；  可以点击火焰图任意横条，进去查看长方块耗时和堆栈明细（请参考图1-2和1-3所示）：\n性能优化思路 本文重点记录优化了哪些 case 才能提升 50%+ 的吞吐量和降低 rt，因此后面直接分析当前优化了哪些 case。在此之前，我们以 Dispatch 为例，看下它为啥那么吃性能 。在 terminal 中通过以下命令可以查看代码行耗费 CPU 数据（代码有删减）：\ngo tool pprof mosnd pprof.mosn.samples.cpu.001.pb.gz (pprof) list Dispatch Total: 1.75mins 370ms 37.15s (flat, cum) 35.46% of Total 10ms 10ms 123:func (conn *streamConnection) Dispatch(buffer types.IoBuffer) { 40ms 630ms 125:\tlog.DefaultLogger.Tracef(\u0026amp;#34;stream connection dispatch data string = %v\u0026amp;#34;, buffer.String()) . . 126: . . 127:\t// get sub protocol codec  . 250ms 128:\trequestList := conn.codec.SplitFrame(buffer.Bytes()) 20ms 20ms 129:\tfor _, request := range requestList { 10ms 160ms 134:\theaders := make(map[string]string) . . 135:\t// support dynamic route  50ms 920ms 136:\theaders[strings.ToLower(protocol.MosnHeaderHostKey)] = conn.connection.RemoteAddr().String() . . 149: . . 150:\t// get stream id  10ms 440ms 151:\tstreamID := conn.codec.GetStreamID(request) . . 156:\t// request route  . 50ms 157:\trequestRouteCodec, ok := conn.codec.(xprotocol.RequestRouting) . . 158:\tif ok { . 20.11s 159:\trouteHeaders := requestRouteCodec.GetMetas(request) . . 165:\t} . . 166: . . 167:\t// tracing  10ms 80ms 168:\ttracingCodec, ok := conn.codec.(xprotocol.Tracing) . . 169:\tvar span types.Span . . 170:\tif ok { 10ms 1.91s 171:\tserviceName := tracingCodec.GetServiceName(request) . 2.17s 172:\tmethodName := …","date":1591686000,"description":"本文将重点描述在基于 Go 语言库 dubbo-go-hessian2、Dubbo 协议中对 MOSN 所做的性能优化。","dir":"blog/mosn-dubbo-dubbo-go-hessian2-performance-optimization/","fuzzywordcount":4500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"2584f4b7cd5bf07fb458ef9fbe60433c","permalink":"/blog/mosn-dubbo-dubbo-go-hessian2-performance-optimization/","publishdate":"2020-06-09T15:00:00+08:00","readingtime":9,"relpermalink":"/blog/mosn-dubbo-dubbo-go-hessian2-performance-optimization/","summary":"背景 蚂蚁金服内部对 Service Mesh 的稳定性和性能要求是比较高的，内部 MOSN 广泛用于生产环境。在云上和开源社区，RPC 领域 Dubbo 和 Spring Cloud 同样广泛用于生产环境，我们在","tags":["MOSN"],"title":"记一次在 MOSN 对 Dubbo、Dubbo-go-hessian2 的性能优化","type":"blog","url":"/blog/mosn-dubbo-dubbo-go-hessian2-performance-optimization/","wordcount":4450},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n **SOFAStack 官网: **https://www.sofastack.tech **SOFAStack: **https://github.com/sofastack  每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@林尤庆 提问：\n 请问 SOFARPC 支持 fegin 不？\n A：SOFARPC 发的 rest 服务，feign 的方式是可以调用的，但是跟 ribbon 是没打通的。\n 有具体的例子不？\n A：https://github.com/sofastack/spring-cloud-sofastack-samples\n 我想问下 SOFARegistry 能像 Nacos 那样注册的是整个服务的名称么，现在 SOFARegistry 是细到接口。Spring Cloud是以整个应用注册的，SOFARegistry 是以每一个SofaServicce 注册的。\n A：SOFARegistry 和 Nacos 都是注册中心服务端产品，存的都是 key: list\u0026amp;lt; string \u0026amp;gt; 这样的数据结构，里面存什么数据是由他们的客户端决定的。SOFARPC 就算是注册中心的客户端。\n SOFARegistry 是以每一个 SofaServicce 注册的，fegin 访问的话也是每一个 SofaServicce 去访问的，不是整个应用访问的？\n A：跟 SOFARegistry 没关系，是 SOFARPC 的实现，目前按接口维度注册的。\nSOFARegistry：https://github.com/sofastack/sofa-registry\n2、@姜哲 提问：\n SOFARPC 能发布一个 https 协议的服务吗？\n A：https 不行，h2（http/2+tls）是可以的。\n SOFABoot 环境下怎么发布？有 Demo 吗？\n A：基于 SOFABoot 可能没有适配， 可以先看下 API 方式的： https://github.com/sofastack/sofa-rpc/blob/master/example/src/test/java/com/alipay/sofa/rpc/http2/Http2WithSSLServerMain.java\nSOFARPC：https://github.com/sofastack/sofa-rpc\n本周推荐阅读  多点生活在 Service Mesh 上的实践 | 线上直播整理 Service Mesh 中的可观察性实践 | 线上直播整理 Apache SkyWalking 在 Service Mesh 中的可观察性应用 | 线上直播回顾 Service Mesh 高可用在企业级生产中的实践 | 线上直播回顾 陌陌的 Service Mesh 探索与实践 | 线上直播回顾  SOFA 项目进展 本周发布详情如下：\n发布 MOSN v0.13.0 版本，主要变更如下：\n 新增 Strict DNS Cluster、GZIP 处理、单机故障隔离； 集成 Sentinel 实现限流能力； 优化 EDF 算法，使用 EDF 算法重新实现 WRR 算法； 支持 Dubbo 服务发现 Beta 版本，优化 Dubbo Decode 性能； 部分实现优化与 Bug 修复；  详细发布报告： https://github.com/mosn/mosn/releases/tag/v0.13.0\n社区活动报名 SOFABolt 是蚂蚁金服开源的一套基于 Netty 实现的，轻量、易用、高性能、易扩展的网络通信框架。在蚂蚁金服的分布式技术体系下，我们有大量的技术产品都需要在内网进行节点间的通信。每个产品都需要考虑高吞吐、高并发的通信，私有协议设计、连接管理、兼容性等问题。\n为了将开发人员从通信框架的实现中解放出来，专注于自己产品的能力建设上，我们将在微服务与消息中间件在网络通信上解决的问题以及积累的经验进行了总结，设计并实现了 SOFABolt。\n本期分享将邀请 SOFABolt 开源负责人丞一，介绍 SOFABolt 的基本功能和部分实现原理，并介绍协议框架的实现。\n你将收获：\n 了解 SOFABolt 的基础使用及 SOFABolt 部分功能的实现原理； 了解 SOFABolt 协议框架的设计以及如何拓展实现自定义私有协议； 了解如何设计一个通信框架；  活动详情：\n **直播主题：**SOFAChannel#17：网络通信框架 SOFABolt 的功能介绍及协议框架解析 **分享嘉宾：**丞一，蚂蚁金服技术专家，主要从事通信中间件相关的开发工作，SOFABolt 开源负责人。 **直播时间：**2020/7/2（周四）19:00-20:00 **直播间：**点击“这里”，即可报名  ","date":1591340400,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20200605/","fuzzywordcount":1600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"9ba8595438771312ed9c187e57789bad","permalink":"/blog/sofa-weekly-20200605/","publishdate":"2020-06-05T15:00:00+08:00","readingtime":4,"relpermalink":"/blog/sofa-weekly-20200605/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | MOSN 发版、Service Mesh 相关文章整理、社区直播预告","type":"blog","url":"/blog/sofa-weekly-20200605/","wordcount":1504},{"author":"陈鹏","categories":"Service Mesh","content":" Service Mesh Webinar 是由 ServiceMesher 社区和 CNCF 联合发起的线上直播活动，活动将不定期举行，为大家带来 Service Mesh 领域的知识和实践分享。\n 本文根据5月28日晚 Service Mesh Webinar#1 多点生活平台架构组研发工程师陈鹏，线上主题分享《多点生活在 Service Mesh 上的实践 \u0026amp;ndash; Istio + Mosn 在 Dubbo 场景下的探索之路》整理，文末包含本次分享的视频回顾链接以及 PPT 下载地址。\n前言 随着多点生活的业务发展，传统微服务架构的面临升级困难的问题。在云原生的环境下，Service Mesh 能给我们带来什么好处。如何使用社区解决方案兼容现有业务场景，落地成符合自己的 Service Mesh 成为一个难点。\n今天主要给大家分享一下 Service Mesh 的一些技术点以及多点生活在 Service Mesh 落地过程中适配 Dubbo 的一些探索。\n首先我们从三个方面入手：\n 为什么需要 Service Mesh 改造； 探索 Istio 技术点； Dubbo 场景下的改造；  为什么需要 Service Mesh 改造 说到为什么需要改造，应该先说一下 Service Mesh 和传统微服务架构的一些特点。\n微服务 微服务一般有这些模块：\n 安全； 配置中心； 调用链监控； 网关； 监控告警； 注册和发现； 容错和限流；  这些模块在传统的微服务架构中有的是和 SDK 结合在一起，有的是一个独立的中间件。\n特点：\n 独立部署； 模块的边界； 技术多样性；  正是由于技术多样性，我的微服务系统可以使用不同的语言进行开发，比如我一个商城系统，订单系统使用 Java 开发，库存系统使用 Go 开发，支付系统使用 Python 开发，微服务之间通过轻量级通信机制协作，比如：HTTP/GRPC 等。比如目前多点使用的 Dubbo(服务治理框架)，随着多点生活的业务发展，目前遇到最棘手的问题就是中间件在升级过程中，推进很慢，需要业务方进行配合，接下来我们看看 Service Mesh。\nService Mesh 优点：\n 统一的服务治理； 服务治理和业务逻辑解藕；  缺点：\n 增加运维复杂度； 引入延时； 需要更多技术栈；  看了 Service Mesh 的优缺点，如果我们 Mesh 化了之后就可以解决我们目前的痛点，升级中间件只需要重新发布一下 Sidecar 就好了，不同语言开发的微服务系统可以采用同样的服务治理逻辑，业务方就可以尝试更多的技术。\n探索 Istio 技术点 在谈 Dubbo 场景下的改造之前我们先介绍一下 Istio 相关的技术点，然后结合 Dubbo 场景应该如何进行适配\nMCP MCP（Mesh Configuration Protocol）提供了一套用于订阅(Watch)、推送(Push)的 API，分为 Source 和 Sink 两个角色。\n Source 是资源提供方(server)，资源变化了之后推送给订阅者(Pilot)，Istio 1.5 之前这个角色就是 Galley 或者自定义 MCP Server； Sink 是资源的订阅者(client)，在 Istio 1.5 之前这个角色就是 Pilot 和 Mixer，都是订阅 Galley 或者自定义 MCP Server 的资源  MCP 的订阅、推送流程图:\n为了和实际情况结合，我们就以 MCPServer 作为 Source，Pilot 作为 Sink 来介绍订阅、推送流程，其中 MCP 通信过程中所传输的「资源」就是 Istio 定义的 CRD 资源，如：VirtualService、DestinationRules 等。\n订阅  Pilot 启动后会读取 Configmap 的内容，里面有一个 configSources 的一个数组配置（Istio 1.5 之后没有这个配置，需要自己添加）、存放的是 MCP Server 的地址； Pilot 连接 MCPServer 之后发送所关注的资源请求； MCPServer 收到资源请求，检查请求的版本信息（可能为空），判断版本信息和当前最新维护的版本信息是否一致，不一致则触发 Push 操作，一致则不处理； Pilot 收到 Push 数据，处理返回的数据（数据列表可能为空，为空也标示处理成功），根据处理结果返回 ACK（成功）/ NACK（失败），返回的应答中包含返回数据的版本信息，如果返回的是 NACK，Pilot 会继续请求当前资源； MCPServer 收到 ACK（和资源请求一致）之后对比版本号，如果一致则不推送，否则继续推送最新数据；  推送  MCPServer 自身数据发生变化，主动推送变化的资源给 Pilot； Pilot 收到之后处理这些数据，并根据处理结果返回 ACK / NACK； MCPServer 收到 ACK（和资源请求一致） 之后对比版本号，如果一致则不推送，否则继续推送最新数据；  这样的订阅、推送流程就保证了 MCPServer 和 Pilot 资源的一致。MCPServer 只能通过 MCP 协议告诉 Pilot 资源发生变化了么？当然不是，MCPServer 可以使用创建 CR 的方式，Pilot 通过 Kubernetes 的 Informer 机制也能感知到资源发生变化了，只是通过 MCP 传输的资源在 Kubernetes 里面看不到，只是存在于 Pilot 的内存里面，当然也可以通过 Pilot 提供的 HTTP debug 接口（istiod_ip:8080/debug/configz）来查。\nhttps://github.com/champly/mcpserver 提供了一个 MCPServer 的一个 demo，如果需要更加细致的了解 MCP 原理可以看一看。\n 更多 debug 接口可以查看: https://github.com/istio/istio/blob/5b926ddd5f0411aa50fa25c0a6f54178b758cec5/pilot/pkg/proxy/envoy/v2/debug.go#L103\n Pilot Pilot 负责网格中的流量管理以及控制面和数据面之前的配置下发，在 Istio 1.5 之后合并了 Galley、Citadel、Sidecar-Inject 和 Pilot 成为 Istiod。我们这里说的是之前 Pilot 的功能，源码里面 pilot-discovery 的内容。\n功能  根据不同平台（Kubernetes、Console）获取一些资源，Kubernetes 中使用 Informer 机制获取 Node、Endpoint、Service、Pod 变化； 根据用户的配置（CR、MCP 推送、文件）触发推送流程； 启动 gRPC server 用于接受 Sidecar 的连接；  推送流程  记录变化的资源类型； 根据变化的资源类型(数组)整理本地数据； 根据变化的资源类型判断需要下发的 xDS 资源； 构建 xDS 资源， …","date":1591264800,"description":"本文主要给分享 Service Mesh 的一些技术点以及多点生活在 Service Mesh 落地过程中适配 Dubbo 的一些探索。","dir":"blog/service-mesh-webinar-duodian-istio-mosn-dubbo/","fuzzywordcount":5600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"99f4c0638c5fbd0b762ce8d373142ae0","permalink":"/blog/service-mesh-webinar-duodian-istio-mosn-dubbo/","publishdate":"2020-06-04T18:00:00+08:00","readingtime":12,"relpermalink":"/blog/service-mesh-webinar-duodian-istio-mosn-dubbo/","summary":"Service Mesh Webinar 是由 ServiceMesher 社区和 CNCF 联合发起的线上直播活动，活动将不定期举行，为大家带来 Service Mesh 领域的知识和实践分享。 本文根据5月28日晚 Service Mesh Webinar#1 多点生活平台架构","tags":["Service Mesh","Service Mesh Webinar"],"title":"多点生活在 Service Mesh 上的实践 -- Istio + Mosn 在 Dubbo 场景下的探索之路","type":"blog","url":"/blog/service-mesh-webinar-duodian-istio-mosn-dubbo/","wordcount":5588},{"author":"叶志远","categories":"Service Mesh","content":"Service Mesh Virtual Meetup 是 ServiceMesher 社区和 CNCF 联合主办的线上系列直播。本期为 Service Mesh Virtual Meetup#1 ，邀请了四位来自不同公司的嘉宾，从不同角度展开了 Service Mesh 的应用实践分享，分享涵盖如何使用 SkyWalking 来观测 Service Mesh，来自陌陌和百度的 Service Mesh 生产实践，Service Mesh 的可观察性和生产实践以及与传统微服务监控的区别。\n本文根据5月14日晚，G7 微服务架构师叶志远的主题分享《Service Mesh 高可用在企业级生产中的实践》整理。文末包含本次分享的视频回顾链接以及 PPT 下载地址。\n前言 谈到 Service Mesh，人们总是想起微服务和服务治理，从 Dubbo 到 Spring Cloud (2016开始进入国内研发的视野，2017年繁荣)再到 Service Mesh (2018年开始被大家所熟悉)，正所谓长江后浪推前浪，作为后浪，Service Mesh 别无选择，而 Spring Cloud 对 Service Mesh 满怀羡慕，微服务架构的出现与繁荣，是互联网时代架构形式的巨大突破。Service Mesh 具有一定的学习成本，实际上在国内的落地案例不多，大多是云商与头部企业，随着性能与生态的完善以及各大社区推动容器化场景的落地，Service Mesh 也开始在大小公司生根发芽，弥补容器层与 Kubernetes 在服务治理方面的短缺之处。本次将以一个选型调研者的视角，来看看 Service Mesh 中的可观察性主流实践方案。\n可观察性的哲学 可观察性（Observability）不是一个新名词，它在很久之前就已经诞生了，但是它在 IT 领域却是一个新兴事物。可观察性在维基百科中原文是这样定义的：“In control theory, observability is a measure of how well internal states of a system can be inferred from knowledge of its external outputs. ”。云原生领域第一次出现这个词，是在云原生理念方兴未艾的2017年，在云原生的思潮之下，运用传统的描述方式已经不足以概括这个时代的监控诉求，而 Observability 就显得贴切许多。\n回想一下传统的监控方式，除去运维层面的主机监控、JVM 监控、消息队列监控之外，有多少监控是事先就想好怎么做的？很少！其实很多时候，我们做的事情就是在故障发生之后，对故障复盘的过程中，除了 bug 重现与修复，也会去定制加一些监控，以期望下次发生同样的情况时有一个实时的告警。研发人员收到告警之后得以快速地处理问题，尽可能地减少损失。所以，传统的监控模式大多都是在做亡羊补牢的事情，缺少一个主动性。\n在云原生时代的容器化体系当中就不一样了，容器和服务的生命周期是紧密联系在一起的，加上容器完美的隔离特性，再加上 Kubernetes 的容器管理层，应用服务跑在容器当中就显得更加地黑盒化，相较在传统物理主机或者虚拟机当中，排查问题的时候显得非常不便。所以在云原生时代强调的是可观察性，这样的监控永远都是兵马未动而粮草先行的，需要提前想好我们要如何观察容器内的服务以及服务之间的拓扑信息、各式指标的搜集等，这些监测能力相当重要。\n关于可观察性在云原生领域是何时开始流行起来的，没有一个很明确的时间。业界认为可观察性最早是由 Cindy Sridharan 提出的，其实一位德国柏林的工程师 Peter Bourgon 早在2017年2月就已经有文章在讨论可观察性了，Peter 算是业界最早讨论可观察性的开发者，他写的著名的博文《Metrics, Tracing, and Logging》被翻译成了多种语言。真正可观察性成为一种标准，是来自 Pivotal 公司的 Matt Stine 定义的云原生标准，可观察性位列其中，由此可观察性就成为了云原生时代一个标准主题。\nPeter Bourgon 提出的可观察性三大支柱围绕 Metrics、Tracing 和 Logging 展开，这三个维度几乎涵盖了应用程序的各种表征行为，开发人员通过收集并查看这三个维度的数据就可以做各种各样的事情，时刻掌握应用程序的运行情况，关于三大支柱的理解如下：\n Metrics：Metrics 是一种聚合态的数据形式，日常中经常会接触到的 QPS、TP99、TP95 等等都属于Metrics 的范畴，它和统计学的关系最为密切，往往需要使用统计学的原理来做一些设计； Tracing：Tracing 这个概念几乎是由 SOA 时代带来的复杂性补偿，服务化带来的长调用链，仅仅依靠日志是很难去定位问题的，因此它的表现形式比 Metrics 更复杂，好在业界涌现出来了多个协议以支撑 Tracing 维度的统一实现； Logging：Logging 是由请求或者事件触发，应用程序当中用以记录状态快照信息的一种形式，简单说就是日志，但这个日志不仅仅是打印出来这么简单，它的统一收集、存储以及解析都是一个有挑战的事情，比如结构化(Structured)与非结构化(Unstructed)的日志处理，往往需要一个高性能的解析器与缓冲器；  此外，Peter Bourgon 在博文中还提到了三大支柱结合态的一些理想输出形式，以及对存储的依赖，Metrics、Tracing、Logging 由于聚合程度的不同，对存储依赖由低到高。更多细节，感兴趣的同学可以查看文末的原文链接。\nPeter Bourgon 关于可观察性三大支柱的思考不止于此，他还在2018年的 GopherCon EU 的分享上面再次讨论了 Metrics、Tracing 和 Logging 在工业生产当中的深层次意义，这次他探讨了4个维度。\n CapEx：表示指标初始收集成本，很明显日志的成本最低，埋点即可；其次是 Metrics，最难是 Tracing 数据，在有了协议支撑的情况下，依然要定义许多数据点，以完成链路追踪必须的元数据定义收集； OpEx：表示运维成本，一般指存储成本，这个之前已经讨论过； Reaction：表示异常情况的响应灵敏度，显然聚合之后的数据可以呈现出波动情况，因此 Metrics 是对异常情况最灵敏的；Logging 次之，也可以从 Logging 清洗之中发现异常量；而 Tracing 在响应灵敏度上面似乎沾不上边，最多还是用在排障定位的场景； Investigation：标准故障定位能力，这个维度是 Tracing 的强项，可以直观看出链路当中的故障，精确定位；Logging 次之；Metrics 维度只能反馈波动，对定位故障帮助不大；  在 CNCF Landscape 当中，有一块区域专门用作展示云原生场景下的可观察性解决方案，里面又分为好几个维度，图中是截至2020年5月14日的最新版图，未来还会有更多优秀的解决方案涌现出来。CNCF 目前毕业的10个项目库当中，有3个是和可观察性有关的，可见 CNCF …","date":1591092000,"description":"本文根据 G7 微服务架构师叶志远线上分享整理，以一个选型调研者的视角，来看看 Service Mesh 中的可观察性主流实践方案。","dir":"blog/service-mesh-virtual-meetup1-service-mesh-observability-practice/","fuzzywordcount":8800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"a4bde9dc8721fabf285171be403d7f5a","permalink":"/blog/service-mesh-virtual-meetup1-service-mesh-observability-practice/","publishdate":"2020-06-02T18:00:00+08:00","readingtime":18,"relpermalink":"/blog/service-mesh-virtual-meetup1-service-mesh-observability-practice/","summary":"Service Mesh Virtual Meetup 是 ServiceMesher 社区和 CNCF 联合主办的线上系列直播。本期为 Service Mesh Virtual Meetup#1 ，邀请了四位来自不同公司的嘉宾，从不同角度展开了 Service Mesh 的应用实践分享，分享涵盖如何使","tags":["Service Mesh","Service Mesh Virtual Meetup"],"title":"Service Mesh 中的可观察性实践","type":"blog","url":"/blog/service-mesh-virtual-meetup1-service-mesh-observability-practice/","wordcount":8781},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n SOFAStack 官网: https://www.sofastack.tech SOFAStack: https://github.com/sofastack  每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@钱德鹏 提问：\n 官网的泛化调用 Demo 地址为https://www.sofastack.tech/projects/sofa-rpc/generic-invoke，代码如下： 这段代码里 consumerConfig 没有指定 directUrl，那么是如何获取服务地址的？自己测试时，如果不指定 directUrl，那么会报找不到服务的错误；如果指定 directUrl，可以正常调用。所以想问一下到底需不需要指定？\n ConsumerConfig consumerConfig = new ConsumerConfig() .setInterfaceId(\u0026amp;#34;com.alipay.sofa.rpc.quickstart.HelloService\u0026amp;#34;) .setGeneric(true); GenericService testService = consumerConfig.refer(); String result = (String) testService.$invoke(\u0026amp;#34;sayHello\u0026amp;#34;, new String[] { \u0026amp;#34;java.lang.String\u0026amp;#34; },new Object[] { \u0026amp;#34;1111\u0026amp;#34; }); A：你这个跟是否跟泛化调用没关系。 RPC 调用肯定是要拿到对方的服务端地址的，这里要么走注册中心去做服务发现，要么走指定直连地址。\n 明白，我的意思是官网的 Demo 里面没指定 URL，那么他是怎么调用成功的？既然官网没有指定，为什么我不指定就调用不到？另外附加一个问题，如果说一定要指定地址，那么我指定成 SLB 地址，由 SLB 去分发，是否可行？\n A：你说官网的 Demo 是哪个？\n https://www.sofastack.tech/projects/sofa-rpc/generic-invoke\n A：这里应该是代码片段，不是完整 Demo。Example 可以参加 https://github.com/sofastack/sofa-rpc/blob/master/example/src/test/java/com/alipay/sofa/rpc/invoke/generic/GenericClientMain.java 指定成 SLB 地址是可以的，不过是 slb 跟服务端是长连接，建立了就不断了，服务端负载不一定会均衡。\n 好的，是否可以认为如果像 Demo 里这样调用，就必须指定 directUrl？\n A：对，使用 ZK 为注册中心的例子就是： https://github.com/sofastack/sofa-rpc/blob/master/example/src/test/java/com/alipay/sofa/rpc/zookeeper/start/ZookeeperBoltClientMain.java\nSOFARPC：https://github.com/sofastack/sofa-rpc\n2、@王振 提问：\n 请问，配置 Nacos，如果 Nacos 是集群部署的话，那 Seata 配置 Nacos 地址的时候是不是只需要填写 Nacos 集群地址就行了，不要三个都填的吧？\n A：Nacos 集群不是填3个地址嘛？你自己做了前端负载？\n 用 Nginx 去做了，在 Nacos 之上加入了 Nginx 做了负载均衡，那在 Seata 配置上是不是只需要配置负载均衡的地址就可以了是吗？如果不做负载的话，那填三个地址是逗号隔开吗？\n A：是的，跟直接使用 Nacos 集群写法一致，我们把这个属性透传给 Nacos。\n 是 ip:port,ip:port,ip:port 这种形式对吧？\n A：是的。\n 另外，请问 Seata 对服务器有最低要求吗？\n A：server 推荐 2C4G+ 吧，jvm 内存2G+。\nSeata：https://github.com/seata/seata\n本周推荐阅读  Apache SkyWalking 在 Service Mesh 中的可观察性应用 Service Mesh 高可用在企业级生产中的实践 | 线上直播回顾 陌陌的 Service Mesh 探索与实践 - 直播回顾  剖析 SOFARPC 框架  【剖析 | SOFARPC 框架】系列之SOFARPC 序列化比较 【剖析 | SOFARPC 框架】系列之SOFARPC跨语言支持剖析 【剖析 | SOFARPC 框架】系列之 SOFARPC 注解支持剖析 【剖析 | SOFARPC 框架】系列之 SOFARPC 路由实现剖析 【剖析 | SOFARPC 框架】系列之 SOFARPC 优雅关闭剖析 【剖析 | SOFARPC 框架】系列之 SOFARPC 数据透传剖析 【剖析 | SOFARPC 框架】系列之 SOFARPC 泛化调用实现剖析 【剖析 | SOFARPC 框架】系列之 SOFARPC 单机故障剔除剖析 【剖析 | SOFARPC 框架】系列之 SOFARPC 线程模型剖析 【剖析 | SOFARPC 框架】系列之 SOFARPC 同步异步实现剖析 【剖析 | SOFARPC 框架】系列之连接管理与心跳剖析 【剖析 | SOFARPC 框架】系列之链路追踪剖析 【剖析 | SOFARPC 框架】系列之总体设计与扩展机制  ","date":1590735600,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20200529/","fuzzywordcount":1500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"2009de6439107016241e7f8efc5a665c","permalink":"/blog/sofa-weekly-20200529/","publishdate":"2020-05-29T15:00:00+08:00","readingtime":3,"relpermalink":"/blog/sofa-weekly-20200529/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | Service Mesh 系列直播回顾、SOFARPC 剖析回顾","type":"blog","url":"/blog/sofa-weekly-20200529/","wordcount":1431},{"author":"高洪涛","categories":"Service Mesh","content":"Service Mesh Virtual Meetup 是 ServiceMesher 社区和 CNCF 联合主办的线上系列直播。本期为 Service Mesh Virtual Meetup#1 ，邀请了四位来自不同公司的嘉宾，从不同角度展开了 Service Mesh 的应用实践分享，分享涵盖 Service Mesh 的可观察性和生产实践以及与传统微服务中可观察性的区别，还有如何使用 SkyWalking 来观测 Service Mesh，来自陌陌和百度的 Service Mesh 生产实践。\n本文根据5月7日晚，美国 Service Mesh 服务商 Tetrate 创始工程师高洪涛的主题分享《Apache SkyWalking 在 Service Mesh 中的可观察性应用》整理。文末包含本次分享的视频回顾链接以及 PPT 下载地址。\n前言 本次演讲为大家分享的是 Apache SkyWalking 对 Service Mesh 可观测性方面的应用实践，共分为三个部分：\n 第一部分是 Apache SkyWalking 的相关背景； 第二部分是 Service Mesh 场景下 SkyWalking 所面临的挑战； 最后是针对 Service Mesh 场景方案的演化；  SkyWalking 的历史沿革及其特点 SkyWalking 项目的建设目的是为了解决在微服务环境下，如何快速的定位系统稳定性问题。创始团队于2016年启动项目，经过一年的努力完善了最初的版本。2017年，团队启动将项目捐献给 Apache 基金会的流程。在 Apache 基金会孵化器内，经过了多轮系统升级迭代，并获得近乎翻倍的贡献者和关注度，于2019年顺利毕业。经过经年的升级与维护，SkyWalking 从最开始专注于分布式追踪系统的单一平台，发展为包含多个门类并拥有丰富的功能的全领域 APM 系统。\nSkyWalking 整体的系统架构包括有三个部分:\n 第一个是数据采集端，可以使用语言探针对系统的监控指标进行采集，同时也提供了一套完整的数据采集协议。第三方系统可以使用协议将相关的监控数据上报到分析平台。 第二部是分析平台，主要包括对监控指标数据的搜集，流式化处理，最终将数据写到存储引擎之中。存储引擎可使用Elasticsearch，MySQL数据库等多种方案。 第三部分是 UI。UI 组件有丰富的数据展示功能，包含指标展板，调用拓扑图，跟踪数据查询，指标比较和告警等功能。  在此基础上，SkyWalking 本身组件具有丰富的定制功能，方便用户去进行二次开发以支持自己特有的场景。\nSkyWalking 定义了三个维度用来绑定相关的监控指标数据。\n 服务(Service)：表示对请求提供相同行为的一系列或一组工作负载。在使用打点代理或 SDK 的时候, 你可以定义服务的名字。如果不定义的话，SkyWalking 将会使用你在平台上定义的名字, 如 Istio。 实例(Instance)：上述的一组工作负载中的每一个工作负载称为一个实例。就像 Kubernetes 中的 Pod 一样, 服务实例未必就是操作系统上的一个进程。但当你在使用打点代理的时候，一个服务实例实际就是操作系统上的一个真实进程。 端点(Endpoint)：对于特定服务所接收的请求路径，如 HTTP 的 URL 路径和 gRPC 服务的类名 + 方法签名。  预定义的维度可以方便的进行数据预汇集操作，是 SkyWalking 分析引擎重要的组成部分。虽然其相对的会有使用不够灵活的缺点，但在 APM 场景下，指标往往都是预先经过精心设计的，而性能才是关键因素。故 SkyWalking 采用这种预定义维度模式来进行数据汇集操作。\nService Mesh 场景下 SkyWalking 面对的挑战 在描述 Service Mesh 的场景下所面临的挑战之前，需要去解释可观测性所包含的含义。可观测性一般包含有三个部分:\n 第一点，日志系统。由其可以构建出系统运行的实时状态。故日志成为非常方便的观测手段。 第二点，分布式追踪。这部分数据在微服务场景下具有强大的生命力，可以提供给用户分布式系统观测指标。 第三点，指标监控。相比于日志和分布式追踪，其具有消耗小，处理简便等特点，通常作为系统监测告警的重要数据来源。  如上所示是 Istio1.5 的架构图。重点看一下他对可观测性的支持。从图上看，所有的监控指标都汇聚到中间的 Mixer 组件，然后由 Mixer 再发送给他左右的 Adapter，通过 Adapter 再将这些指标发送给外围的监控平台，如 SkyWalking 后端分析平台。在监控数据流经 Mixer 的时候，Istio 的元数据会被附加到这些指标中。另一种新的基于 Telemetry V2 观测体系是通过 Envoy 的 Proxy 直接将监控指标发送给分析平台，这种模式目前还处于快速的演进和开发中，但是它代表着未来的一种趋势。\n从架构图中我们可以看到，这里面的第一个挑战就是 Service Mesh 场景下，对于可观测性的技术体系的支持是非常多变的。\nIstio 本身就包括两种不融合的体系，第一种是基于 Mixer 的场景，第二种是 Mixerless 场景。\nMixer 是基于访问日志进行指标生成的，也就是说服务与服务之间的访问日志经过 Mixer 增加相关的原数据后再发给外围分析系统。其特点是这个模式非常的成熟、稳定，但是性能会非常的低。它的低效源于两个方面，第一点是他的数据发送通道很长，中间节点过多。可以看到数据需要到从 Proxy 发送到 Mixer 节点，再发送给外围的 Adapter 节点。另一个效能低下的原因主要是体现在它发送的是原始访问日志，其数据量是非常大的，会消耗过多的带宽，这对整体的数据搜集与分析提出了非常大的挑战。\n另一种模式是 Mixerless，它完全是基于 Metrics 指标的。通过可观测性包含的技术及其特点分析可知，它是一种消耗比较小的技术，对带宽以及分析后台都是非常友好的。但是它同时也有自己的问题，第一个问题就是他需要的技术门槛是比较高的（使用 WASM 插件来实现），并且对于 Proxy 端的性能消耗也是比较大的。同时由于是新的技术，稳定性较差，相关接口与规范并不完整。\n第二个挑战就是无 Tracing 数据。SkyWalking 最早是为了收集处理跟踪数据（Tracing）而设计的一套系统，但是我们可以从右边的图发现，对于 Service Mesh 上报的数据其实是基于调用的，也就是说它不存在一条完整的跟踪链路。这样就对后台的分析模型有比较大的挑战，如何才能同时支持好这两种模式成为后端分析系统所要处理的棘手问题。\n第三个挑战就是维度匹配的问题。我们从前一章可以看到 SkyWalking 是包括三个维度的，其中对于实例和端点，在 Service Mesh 场景下都是有比较好的支持。这里多说一句，不仅仅是对 Mesh 场景，对于大部分场景都可以很好的去匹配它们。但是对于服务的匹配是有相当大难度的，因为 SkyWalking 只有服务这一层的概念，而在 Istio 中有好几个概念可以称之为“服务”。 …","date":1590649200,"description":"本文根据5月7日晚，美国 Service Mesh 服务商 Tetrate 创始工程师高洪涛的主题分享《Apache SkyWalking 在 Service Mesh 中的可观察性应用》整理。","dir":"blog/service-mesh-virtual-meetup1-skywalking-observability-applications/","fuzzywordcount":4400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"2414682129ca15d4cfc86bffc6694aaa","permalink":"/blog/service-mesh-virtual-meetup1-skywalking-observability-applications/","publishdate":"2020-05-28T15:00:00+08:00","readingtime":9,"relpermalink":"/blog/service-mesh-virtual-meetup1-skywalking-observability-applications/","summary":"Service Mesh Virtual Meetup 是 ServiceMesher 社区和 CNCF 联合主办的线上系列直播。本期为 Service Mesh Virtual Meetup#1 ，邀请了四位来自不同公司的嘉宾，从不同角度展开了 Service Mesh 的应用实践分享，分享涵盖 Service Mesh 的","tags":["Service Mesh","Service Mesh Virtual Meetup"],"title":"Apache SkyWalking 在 Service Mesh 中的可观察性应用","type":"blog","url":"/blog/service-mesh-virtual-meetup1-skywalking-observability-applications/","wordcount":4354},{"author":"罗广明","categories":"Service Mesh","content":"Service Mesh Virtual Meetup 是 ServiceMesher 社区和 CNCF 联合主办的线上系列直播。本期为 Service Mesh Virtual Meetup#1 ，邀请了四位来自不同公司的嘉宾，从不同角度展开了 Service Mesh 的应用实践分享，分享涵盖来自陌陌和百度的 Service Mesh 生产实践，Service Mesh 的可观察性和生产实践以及与传统微服务中可观察性的区别，还有如何使用 SkyWalking 来观测 Service Mesh。\n本文根据5月13日晚，百度高级工程师罗广明的主题分享《Service Mesh 高可用在企业级生产中的实践》整理。文末包含本次分享的视频回顾链接以及 PPT 下载地址。\n前言 Service Mesh 在企业落地中有诸多挑战，当与传统微服务应用共同部署治理时可用性挑战更为严峻。本次分享将以 Service Mesh 与 Spring Cloud 应用互联互通共同治理为前提，着重介绍基于 Consul 的注册中心高可用方案，通过各种限流、熔断策略保证后端服务的高可用，以及通过智能路由策略（负载均衡、实例容错等）实现服务间调用的高可用。\nService Mesh 与 Spring Cloud 应用的互通、互联 微服务是时下技术热点，大量互联网公司都在做微服务架构的推广和落地。同时，也有很多传统企业基于微服务和容器，在做互联网技术转型。而在这个技术转型中，国内有一个现象，以 Spring Cloud 与 Dubbo 为代表的微服务开发框架非常普及和受欢迎。近年来，新兴的 Service Mesh 技术也越来越火热，受到越来越多开发者的关注，大有后来居上的趋势。\n在听到社区里很多人谈到微服务技术选型时，注意到他们讨论一个非此即彼的问题：采用 Spring Cloud 还是以 Istio 为代表的 Service Mesh 技术？然而这个答案并非非黑即白、非你即我，一部分应用采用 Spring Cloud，另一部分采用 Service Mesh（Istio）是完全可能的。今天我就和大家一起来讨论这个问题。\n首先，我们来看一下 Spring Cloud 这个传统侵入式微服务框架。它包含以下优点：\n 集大成者，Spring Cloud 包含了微服务架构的方方面面；选用目前各家公司开发的比较成熟的、经得住实践考验的服务框架； 轻量级组件，Spring Cloud 整合的组件大多比较轻量级，且都是各自领域的佼佼者； 开发简便，Spring Cloud 对各个组件进行了大量的封装，从而简化了开发； 开发灵活，Spring Cloud 的组件都是解耦的，开发人员可以灵活按需选择组件；  特别感谢 Netflix，这家很早就成功实践微服务的公司，几年前把自家几乎整个微服务框架栈贡献给了社区，早期的 Spring Cloud 主要是对 Netflix 开源组件的进一步封装。不过近两年，Spring Cloud 社区开始自研了很多新的组件，也接入了其他一些互联网公司的优秀实践。\n接下来，我们简单看一下 Service Mesh 框架。它带来了两大变革：微服务治理与业务逻辑的解耦，异构系统的统一治理。此外，服务网格相对于传统微服务框架，还拥有三大技术优势：可观察性、流量控制、安全。服务网格带来了巨大变革并且拥有其强大的技术优势，被称为第二代“微服务架构”。\n然而就像之前说的软件开发没有银弹，传统微服务架构有许多痛点，而服务网格也不例外，也有它的局限性。这些局限性包括：增加了链路与运维的复杂度、需要更专业的运维技能、带来了一定的延迟以及对平台的适配。\n更多关于 Spring Cloud 与 Service Mesh 的优缺点与比较，请阅读 Istio-Handbook [Service Mesh 概述]。\n前面提到过，对于传统微服务框架 Spring Cloud 与新兴微服务框架 Service Mesh，并非是个非黑即白，非你即我，延伸到微服务与单体架构，它们也是可以共存的。\n也可以将其与混合云相类比，混合云中包含了公有云、私有云，可能还有其它的自有基础设施。目前来看，混合云是一种流行的实践方式；实际上，可能很难找到一个完全单一云模式的组织。对多数组织来说，将一个单体应用完全重构为微服务的过程中，对开发资源的调动是一个很严峻的问题；采用混合微服务策略是一个较好的方式，对开发团队来说，这种方式让微服务架构触手可及；否则的话，开发团队可能会因为时间、经验等方面的欠缺，无法接受对单体应用的重构工作。\n构建混合微服务架构的最佳实践：\n 最大化收益的部分优先重构； 非 Java 应用优先采用 Service Mesh 框架；  混合微服务出现的原因是为了更好的支持平滑迁移，最大限度的提升服务治理水平，降低运维通信成本等，并且可能会在一个较长的周期存在着。而实现这一架构的前提，就是各服务的“互联互通”。\n要想实现上述“混合微服务架构”，运行时支撑服务必不可少，它主要包括服务注册中心、服务网关和集中式配置中心三个产品。\n传统微服务和 Service Mesh 双剑合璧（双模微服务），即“基于 SDK 的传统微服务”可以和“基于 Sidecar 的 Service Mesh 微服务”实现下列目标：\n 互联互通：两个体系中的应用可以相互访问； 平滑迁移：应用可以在两个体系中迁移，对于调用该应用的其他应用，做到透明无感知； 灵活演进：在互联互通和平滑迁移实现之后，我们就可以根据实际情况进行灵活的应用改造和架构演进；  这里还包括对应用运行平台的要求，即两个体系下的应用，既可以运行在虚拟机之上，也可以运行在容器/K8s 之上。我们不希望把用户绑定在 K8s 上，因此 Service Mesh 没有采用 K8s 的 Service 机制来做服务注册与发现，这里就突出了注册中心的重要性。\n百度智能云 CNAP 团队实现了上述混合微服务架构，即实现了两个微服务体系的应用互联互通、平滑迁移、灵活演进。上述混合微服务架构图包括以下几个组件：\n API Server：前后端解耦，接口权限控制、请求转发、异常本地化处理等等； 微服务控制中心：微服务治理的主要逻辑，包括服务注册的多租户处理、治理规则（路由、限流、熔断）的创建和转换、微服务配置的管理； 监控数据存储、消息队列：主要是基于 Trace 的监控方案使用的组件； 配置中心：微服务配置中心，最主要的功能是支持配置管理，包括治理规则、用户配置等所有微服务配置的存储和下发，微服务配置中心的特色是借助 SDK 可以实现配置/规则热更新；  接下来主要看一下注册中心的服务注册和发现机制：\n Spring Cloud 应用通过 SDK、Service Mesh 应用实现 Sidecar 分别向注册中心注册，注册的请求先通过微服务控制中心进行认证处理与多租户隔离； Mesh 控制面直接对接注册中心获取服务实例、Spring Cloud 应用通过 SDK 获取服务实例； 双模异构，支持容器与虚机两种模型；  注册中心与高可用方案 前面提到过，要想实现实现混合微服务架构，注册中心很关键。谈到注册中心，目前主流的开源注册 …","date":1590476400,"description":"本文根据5月13日晚，百度高级工程师罗广明的主题分享《Service Mesh 高可用在企业级生产中的实践》整理。","dir":"blog/service-mesh-virtual-meetup1-practice-in-enterprise-production/","fuzzywordcount":9100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"2cea7fee830cbfcc69ee7732909b231c","permalink":"/blog/service-mesh-virtual-meetup1-practice-in-enterprise-production/","publishdate":"2020-05-26T15:00:00+08:00","readingtime":18,"relpermalink":"/blog/service-mesh-virtual-meetup1-practice-in-enterprise-production/","summary":"Service Mesh Virtual Meetup 是 ServiceMesher 社区和 CNCF 联合主办的线上系列直播。本期为 Service Mesh Virtual Meetup#1 ，邀请了四位来自不同公司的嘉宾，从不同角度展开了 Service Mesh 的应用实践分享，分享涵盖来自陌","tags":["Service Mesh","Service Mesh Virtual Meetup"],"title":"Service Mesh 高可用在企业级生产中的实践 | 线上直播回顾","type":"blog","url":"/blog/service-mesh-virtual-meetup1-practice-in-enterprise-production/","wordcount":9014},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n **SOFAStack 官网: **https://www.sofastack.tech **SOFAStack: **https://github.com/sofastack  每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@张晓明 提问：\n 关于 SOFATracer 采样率的配置，只在请求经过的第一个服务配置采样率就可以吗，还是每个服务都需要配置采样率，每个服务都配置的话，要求各服务采样率必须一致吗？\n A：第一个，只在请求经过的第一个服务配置采样率就可以。\n 上报 Zipkin 的话，也只在第一个服务配置就可以吧，其他服务只需要引入 tracer-sofa-boot-starter 就行吧？\n A：上报每个服务节点都要配，不然你下游链路数据拿不到。\n 采样率支持动态更新吗，就是修改后需要重启服务吗？\n A：可以通过自定义采样，配合个配置中心就可以。\n 采样模式用 PercentageBasedSampler，配合配置中心可以吗？\n A：可以，比较麻烦，要反射去改配置类的值，配置类初始化时采样率就确定了，如果要动态改只能通过反射去改。或者通过拿到配置类对象去设置也行，思路差不多。\nSOFATracer：https://github.com/sofastack/sofa-tracer\n2、@李振鸿 提问：\n 请问，分布式事务执行 (只插入两条数据) 执行时间 0.3 会不会比较慢？\n A：嗯，Seata 是消耗了不少性能，尤其是跟 TC 通信、TC 那边的处理。 Seata：https://github.com/seata/seata\n本周推荐阅读  云原生网络代理 MOSN 透明劫持技术解读 | 开源 不得不说的云原生隔离性 | SOFAChannel#16 直播回顾  SOFA 项目进展 本周发布详情如下：\n1、发布 Occlum v0.12.0版，主要更新如下：\n 支持 Go 语言，并增加了 Demo； 新增三个命令行子命令：start, exec 和 stop； 新增 signal 子系统；  详细发布报告： https://github.com/occlum/occlum/releases/tag/0.12.0\n社区直播报名 随着多点生活的业务发展，传统微服务架构的面临升级困难的问题。在云原生的环境下，Service Mesh 能给我们带来什么好处？如何使用社区解决方案兼容现有业务场景，落地成符合自己的 Service Mesh 成为一个难点？服务之间主要通过 Dubbo 交互。本次分享将探索 Istio + MOSN 在 Dubbo 场景下的改造方案，结合现有业务场景和可切入点，明确需要修改的场景，制定符合自己业务场景的 Service Mesh 落地方案，介绍多点生活在 Dubbo 案例的探索及改造方案。\n将从以下几个方面，与大家交流分享：\n 传统微服务架构与 Service Mesh 架构   传统微服务架构在多点遇到的痛点； Service Mesh 架构能带来的福利；  Istio 技术点介绍 在 Dubbo 场景下的改造分析   对比 MOSN 和 Envoy 对现有场景的支持； Istio+MOSN 和 Istio+Envoy 在 Dubbo 场景下如何改造；  MOSN + Istio 具体实现探索   MOSN 配置文件介绍、从一个流量进来到转发到具体的远端的流程分析； Provider 配置信息如何下发到 Sidecar； 从多点现在的实际场景对现有的 Dubbo 改造方案；  Demo 演示  直播主题： Service Mesh Webinar#1：多点生活在 Service Mesh 上的实践——Istio + MOSN 在 Dubbo 场景下的探索之路\n分享嘉宾：陈鹏，多点生活平台架构组研发工程师，开源项目与云原生爱好者，有多年的网上商城、支付系统相关开发经验，2019年至今从事云原生和 Service Mesh 相关开发工作。\n**直播时间：**2020/5/28（周四）20:00-21:00\n**直播间：**点击“这里”，关注直播间即可\n","date":1590138000,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20200522/","fuzzywordcount":1500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"b5778b2bc8e9e6cd92abd8bd7bfc387b","permalink":"/blog/sofa-weekly-20200522/","publishdate":"2020-05-22T17:00:00+08:00","readingtime":3,"relpermalink":"/blog/sofa-weekly-20200522/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | Occlum 发布、技术直播回顾\u0026预告","type":"blog","url":"/blog/sofa-weekly-20200522/","wordcount":1440},{"author":"巴德","categories":"Kata Containers","content":" SOFA:Channel/，有趣实用的分布式架构频道。 回顾视频以及 PPT 查看地址见文末。欢迎加入直播互动钉钉群 : 30315793，不错过每场直播。\n 本文根据 SOFAChannel#16 直播分享整理，主题：不得不说的云原生隔离性。\n大家好，我是今天的讲师巴德，来自蚂蚁金服，主要从事 Kata 容器相关的开发，也是 Kata Containers 项目的维护者之一。今天我和大家分享一下云原生场景下容器隔离性的需求以及我们如何运用 Kata Containers 来提升容器的隔离性。\n从 Kubernetes Pod 说起 在讲云原生隔离性之前，我们先来回顾一下历史。这张图是生产环境应用部署形态的变迁过程。从最左边的物理机上直接部署，到后来的虚拟化兴起，大家把应用部署在虚拟机里，再到 Docker 兴起，大家都把应用部署到容器里面，到现在 Kubernetes 成为主流，大家都把应用部署在 Pod 里面。\n我们看一下 Kubernetes 的一个基本架构，它本身是一个容器的编排系统，主要角色是管理和调度 Pod 以及相关的资源。今天我们主要关注的就是在节点上部署的 Pod，这也是 Kubernetes 资源调度的基本单位。\nKubernetes 官方对 Pod 的定义是一个应用的逻辑主机，其中包含了一个或者多个应用容器，这些容器在资源上是相对紧密的耦合在一起的。Pod 包含了这些容器共享的网络和存储以及如何运行这些容器的声明。Pod 中的内容总是放置在一起并且一同调度，并在共享的上下文中运行。\n这段定义有些抽象，其目的是为了说明 Pod 是可以用不同的隔离技术来实现的。我们先来看一下一个经典的 Pod 实现，基于 Linux namespace 和 cgroups 做抽象的 Pod 实现。\n这个示意图中，我们在一台主机上运行了两个 Pod，这两个 Pod 之间通过主机内核提供的 namespace 和 cgroups 能力来进行隔离。他们之间的所有 namespace 资源都是隔离的。然后在 pod 内部，不同容器之间的 IPC 和网络 namespace 是共享的，但是他们的 mnt/pid/user/uts namespace 又是相互隔离的。这就是一个经典的基于 Linux namespace 和 cgroups 来做隔离的 Pod 的实现。\n对于这种 Pod 的实现，我们可以关注到这两个 Pod 虽然所有的 namespace 都是隔离的，但是他们共享了同一个内核。\n共享内核引入的问题 那么，我们来看一下 Pod 共享同一个内核可能造成什么问题。\n首先我们关注到的是安全问题。也就是说 Pod 中的容器应用会不会通过共享内核的漏洞逃逸出 Pod 的资源隔离？这里我们列了两个近几年的内核 bug，一个是 CVE-2016-5915，另外一个是 CVE-2017-5123，这两个 bug 都曾经造成容器应用通过触发内核 bug 获取宿主机 root 权限并逃逸出 Pod 资源隔离限制。\n另外一个点是故障影响。这个好理解，如果一个 Pod 中的容器应用触发了一个严重的内核 bug，造成内核 panic，这时候同一台宿主机上的所有 Pod 都会被牵连。\n还有一个我们非常关注的点，是共享内核造成的内核资源竞争。同一个宿主机上的不同 Pod，实际上是不同的用户态进程的集合，这些用户态进程虽然在 namespace 上是相互隔离的，但他们还是会共享很多内核资源，比如调度器、某些内核线程或者对象。这种级别的资源共享会引入很多可以观测到的性能抖动，对在线业务的影响也很明显。\n如何避免共享内核造成的这些问题呢？大家最直接的想法就是，把 Kubernetes 装到虚拟机里不就可以更好的隔离起来了吗？如图所示，这本质上是通过增加一个 VM 间接层来解决隔离性问题。\n看起来问题解决了，不是吗？这时候我们就需要抛出计算机届大佬 David Wheeler 的一个名言，“计算机科学中的所有问题都可以通过增加一个间接层来解决，当然，除了间接层过多的问题”。\n那么增加 VM 间接层的方案有什么问题呢？第一，同一个 VM 内的 Pod 之间还是共享内核的。第二，整个集群里出现了虚拟机和 Pod 两层调度系统。\n上帝说，要有光；我们说，要有 Kata 面对这些问题，我们要怎么做呢？我们要部署 Kata 容器 ：)\nKata 容器的一个基本思路是，用虚拟机来作为 Pod 的一种隔离方式。我们把 Pod 中的多个容器资源，放到同一个虚拟机里面，利用虚拟机来实现不同 Pod 独占内核的目的。而 Pod 仍然是 Kubernetes 的基本调度单位，集群里也不会有虚拟机和 Pod 两层调度系统。\n我们简单介绍一下 Kata Containers 这个项目，这是 Openstack 基金会管理下的开放基础设施顶级项目。Kata Containers 的 slogen 是 The speed of containers, the security of VMs。其设计是基于虚拟机完美符合 Pod 抽象这个理念，为用户提供强隔离，易用的容器基础设施。\nKata Containers：https://github.com/kata-containers/kata-containers\n这是 Kata Containers 项目的发展历史概要。在 2015 年的五月，一帮国内的创业者(就是我们) 和 Intel 的同学们分别独立发布了两个叫 runV 和 Clear Containers 的虚拟化容器项目，这就是 Kata Containers 的前身。这两个项目互相有很多交流，在分别独立发展了两年半之后，在 2017 年底，合并成了 Kata Containers 项目，并把这个项目捐给 Openstack 基金会管理，这也是 Openstack 基金会的第一个 Pilot 项目，有一些探索转型的味道。在去年的四月，Kata Containers 被 Openstack 基金会认可为其第二个顶级项目，在这之前的十多年里，Openstack 基金会都只有 Openstack 一个顶级项目。\n目前 Kata Containers 的稳定版本发布到了 1.10.0，而且 2.0 也正在紧锣密鼓地开发中。\n我们再简单介绍下 Kata Containers 的架构。左边蓝色部分是 Kata Containers 对接的上游组件，也就是 Kubernetes 通过 CRI 接口访问 CRI daemon，这里是用 containerd 做展示。 Containerd 通过一个 Shim API 来访问 Kata Containers。右边的就都是 Kata 的组件了。对每一个 Pod，我们有一个名叫 containerd-shim-kata-v2 的服务进程，这个服务进程会负责基于虚拟机的 Pod 的生命周期管理。最后边的 Pod Sandbox 就是我们基于虚拟机来实现的一个 Pod 抽象。在里面我们要运行一个叫 kata-agent 的服务进程，来负责 Pod 内容器的生命周期管理。\nKata 容器特性大放送 介绍了 Kata 的 …","date":1590123600,"description":"本文根据线上直播整理，一起来看看云原生场景下容器隔离性的需求以及我们如何运用 Kata Containers 来提升容器的隔离性。欢迎阅读","dir":"blog/sofa-channel-16-retrospect/","fuzzywordcount":3600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"c57953062af87158c42de61e48d1676f","permalink":"/blog/sofa-channel-16-retrospect/","publishdate":"2020-05-22T13:00:00+08:00","readingtime":8,"relpermalink":"/blog/sofa-channel-16-retrospect/","summary":"SOFA:Channel/，有趣实用的分布式架构频道。 回顾视频以及 PPT 查看地址见文末。欢迎加入直播互动钉钉群 : 30315793，不错过每场直播","tags":["Kata Containers","SOFAChannel"],"title":"不得不说的云原生隔离性 | SOFAChannel#16 直播回顾","type":"blog","url":"/blog/sofa-channel-16-retrospect/","wordcount":3573},{"author":"潘潘","categories":"SOFAChannel","content":"概要   活动主题：Service Mesh Webinar#1：多点生活在 Service Mesh 上的实践——Istio + MOSN 在 Dubbo 场景下的探索之路\n  活动时间：5 月 28 日周四晚 8 点\n  活动形式：线上直播\n  报名方式：戳这里\n  介绍 Service Mesh Webinar Service Mesh Webinar 是由 ServiceMesher 社区和 CNCF 联合发起的线上直播活动，活动将不定期举行，邀请社区成员为大家带来 Service Mesh 领域的知识和实践分享。\nService Mesh Webinar#1 Service Mesh Webinar#1，邀请多点生活平台架构组研发工程师陈鹏，带来分享《多点生活在 Service Mesh 上的实践——Istio + MOSN 在 Dubbo 场景下的探索之路》。\n随着多点生活的业务发展，传统微服务架构的面临升级困难的问题。在云原生的环境下，Service Mesh 能给我们带来什么好处。如何使用社区解决方案兼容现有业务场景，落地成符合自己的 Service Mesh 成为一个难点。服务之间主要通过 Dubbo 交互，本次分享将探索 Istio + MOSN 在 Dubbo 场景下的改造方案。\n分享主题：\n《多点生活在 Service Mesh 上的实践——Istio + MOSN 在 Dubbo 场景下的探索之路》\n分享嘉宾：\n陈鹏，多点生活平台架构组研发工程师，开源项目与云原生爱好者，有多年的网上商城、支付系统相关开发经验，2019年至今从事云原生和 Service Mesh 相关开发工作。\n**直播时间：**2020年5月28日（周四）20:00-21:00\n解决思路:\n从 MCP、Pilot、xDS、MOSN 技术，对 Service Mesh 的可切入点分析。\n成果：\n结合现有业务场景和可切入点，明确需要修改的场景，制定符合自己业务场景的 Service Mesh 落地方案，介绍多点生活在 Dubbo 案例的探索及改造方案。\n大纲：\n 传统微服务架构与 Service Mesh 架构  传统微服务架构在多点遇到的痛点 Service Mesh 架构能带来的福利   Istio 技术点介绍 在 Dubbo 场景下的改造分析  对比 MOSN 和 Envoy 对现有场景的支持 Istio+MOSN 和 Istio+Envoy 在 Dubbo 场景下如何改造   MOSN + Istio 具体实现探索  MOSN 配置文件介绍、从一个流量进来到转发到具体的远端的流程分析 Provider 配置信息如何下发到 Sidecar 从多点现在的实际场景对现有的 Dubbo 改造方案   Demo 演示  ","date":1589958000,"description":"5 月 28 日周四晚 8 点，Service Mesh Webinar#1 线上直播。","dir":"activities/service-mesh-webinar-1/","fuzzywordcount":800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"d146e6a876059c0f8da819f408add6fa","permalink":"/activities/service-mesh-webinar-1/","publishdate":"2020-05-20T15:00:00+08:00","readingtime":2,"relpermalink":"/activities/service-mesh-webinar-1/","summary":"概要 活动主题：Service Mesh Webinar#1：多点生活在 Service Mesh 上的实践——Istio + MOSN 在 Dubbo 场景下的探索之路 活动时间：5 月 28 日周四晚 8 点 活","tags":["MOSN","Service Mesh Webinar"],"title":"Service Mesh Webinar#1：多点生活在 Service Mesh 上的实践","type":"activities","url":"/activities/service-mesh-webinar-1/","wordcount":746},{"author":"无在","categories":"MOSN","content":" MOSN 是一款使用 Go 语言开发的网络代理软件，作为云原生的网络数据平面，旨在为服务提供多协议、模块化、智能化、安全的代理能力。MOSN 是 Modular Open Smart Network-proxy 的简称，可以与任何支持 xDS API 的 Service Mesh 集成，亦可以作为独立的四、七层负载均衡、API Gateway、云原生 Ingress 等使用。 MOSN：https://github.com/mosn/mosn\n 在由 Istio 定义的 Service Mesh 体系中，服务治理相关逻辑由独立的 Sidecar 进程处理，如服务发现、故障注入、限流熔断等等。这些处理逻辑是 Service Mesh 着重要解决的问题。通常在谈论到 Service Mesh 时，会优先关注在这些点上，但是在落地过程中，有一个问题同等重要但往往容易被忽视。这个问题概括起来，就是流量是如何被导入到 Sidecar 的监听端口的。\n在数据平面的 Sidecar 中拦截进出应用容器的流量，这一直以来就是 Istio Service Mesh 中一切功能的基础，如何实现透明高效的拦截也是 Service Mesh 设计中的一大难点，本文为大家介绍云原生网络代理 MOSN 是如何做到这一点的。\n流量接管 如果服务注册/发布过程能够允许适当的修改，这个问题会得到极大的简化，比如 Sidecar 将服务发布方的监听地址修改为 127.0.0.1:20882，订阅方 Sidecar 监听本机 20882 端口，当订阅方访问 127.0.0.1:20882 时，流量就自然到达了本端 Sidecar。在这种情况下，无需在网络层面使用重定向技术就可以达到目的。\n服务发布订阅修改逻辑框图\n流量转发流程图\n如上图中，在发布服务时，Sidecar 将服务端原本的地址转换为 Sidecar 自身的端口；服务订阅时，订阅方获取到的端口则是本地 Sidecar 监听的端口。这一方案的优势很明显，逻辑都收敛在了 Sidecar 中，除了需要对 Sidecar 服务注册/发布流程进行改造外，不需要其他组件的参与，但是缺点也很明显，如果业务模型不存在注册中心，或者是服务发布/订阅 SDK 不能进行改造，这个方案就行不通了，而在 Mesh 落地场景中，这个条件恰恰较难满足。\n目前大多数业务的逻辑架构都不符合 Istio 定义的云原生体系，为了享受到 Service Mesh 在服务治理方面的优势，需要选择合适的流量劫持方案。一般而言，流量劫持工作在 L4 层，在进行劫持技术选型时需要考虑三个方面的问题：\n 第一是环境适配，包括容器、虚拟机、物理机、内核、系统发行版等方面的考虑，确保劫持方案在运行环境中能够正常工作； 第二是控制灵活简单，包括如何维护劫持规则，劫持规则如何下发等； 第三是性能，确保在业务运行期间，劫持本身不会带来过大的开销；  下面将从这三个层面分析 MOSN 在落地过程中的一些思考。\n环境适配 在环境适配性上，最容易想到的是 iptables，作为一项古典网络技术，iptables 使用简单，功能灵活，几乎所有现代生产级内核版本与 OS 发行版都默认具备使用条件，Istio 社区也使用 iptables 做流量透明劫持。\niptables 流量劫持原理图\n尽管环境适应性强，但是基于 iptables 实现透明劫持存在以下问题：\n DNAT 模式下，需要借助于 conntrack 模块实现连接跟踪，在连接数较多的情况下，会造成较大的消耗，同时可能会造成 track 表满的情况。为了避免这个问题，可以使用 TProxy 取代 DNAT，但受限于内核版本，TProxy 应用于 outbound 存在一定缺陷。 iptables 属于常用模块，全局生效，不能显式的禁止相关联的修改，可管控性比较差。 iptables 重定向流量本质上是通过 loopback 交换数据，outbond 流量将两次穿越协议栈，在大并发场景下会损失转发性能。  针对 oubound 流量，还可以使用 hook connect 来实现，如图所示：\nhook connect 逻辑框图\n无论采用哪种透明劫持方案，均需要解决获取真实目的 IP/端口的问题，使用 iptables 方案通过 getsockopt 方式获取，TProxy 可以直接读取目的地址，通过修改调用接口，hook connect 方案读取方式类似于 TProxy。\n由于 MOSN 落地的场景十分复杂，有容器与 VM 甚至物理机环境，有基于 K8s 的云原生应用，有基于注册中心的微服务，也存在单体应用，有些场景对性能要求非常高，有些则是够用即可，针对不同的场景，我们选择不同的劫持方案进行适配。如果应用程序通过注册中心发布/订阅服务时，可以结合注册中心劫持流量；在需要用到透明劫持的场景，如果性能压力不大，使用 iptables DNAT 即可，大并发压力下使用 TProxy 与 sockmap 改善性能。\n配置管理 通常基于申明式体系构建的服务在部署时能够得到全局信息，而非申明式体系往往需要在运行期间进行动态的配置修改，由于缺乏全局信息，在运行期间很难获取到准确的服务间调用信息。在生成透明劫持规则时，我们需要明确哪些流量要被重定向到 Sidecar，否则一旦出错，而 Sidecar 又无法处理这部分流量时，将会使得 Sidecar 变成流量黑洞，比如，某一个容器内的 TCP 流量全部被重定向至 Sidecar，而该容器中存在一个使用私有协议承载应用数据的监控 Agent，而 Sidecar 不能识别该协议导致无法争取转发，只能选择丢弃。\n通常情况下，为了确保 Sidecar 能够正确的转发流量，需要满足两个条件，首先是要能够正确识别协议，其次是需要配置转发规则，明确下一跳。对于不满足这两个条件的流量，不应将其重定向至 Sidecar。对于现有的非云原生应用，同时满足这两个条件的代价非常高，比如，某个虚拟机上运行了一个业务，同时还运行了收集 Metrics 的 Agent、日志采集工具、健康检查工具等等。而基于 L4 规则很难精确的将业务流量重定向至 Sidecar，如果多个业务混部，可能导致无法在 L4 层进行业务流量的区分。总结起来，为了精确的把流量引至 Sidecar，需要获得全局的调用关系，这一目标原本应该由 Service Mesh 来完成，而在流量劫持的场景下，却成为了 Service Mesh 的前提。\n为了使用 Service Mesh 而引入大量的部署运维开销是得不偿失的。在落地的过程中，MOSN 引入了多项手段来降低流量劫持的配置难度。我们将需要精确配置重定向规则的工作模式定义为精确匹配，与之相对应的是模糊匹配，即不要求精确区分出需要劫持的流量。降低配置难度的关键在于取消对于精确规则的依赖，在配置模糊规则的前提下，既做到对于关心的业务流量的治理，同时也不影响非业务流量的正常流程。\n我们采用 L4 规则与 L7 规则融合的方式下发模糊的匹配规则，此规则下除了包含关心的业务流量外，还可能包含预期之外的非业务流量。对于业务流量，Sidecar 根据相应的服务治理 …","date":1589871600,"description":"如何实现透明高效的拦截也是 Service Mesh 设计中的一大难点，本文为大家介绍云原生网络代理 MOSN 是如何做到这一点的。","dir":"blog/mosn-transparent-hijacking/","fuzzywordcount":3500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"c2505ec6bd3034e6cf3222dca8e1b83e","permalink":"/blog/mosn-transparent-hijacking/","publishdate":"2020-05-19T15:00:00+08:00","readingtime":7,"relpermalink":"/blog/mosn-transparent-hijacking/","summary":"MOSN 是一款使用 Go 语言开发的网络代理软件，作为云原生的网络数据平面，旨在为服务提供多协议、模块化、智能化、安全的代理能力。MOSN 是 Modular Open Smart Network-proxy 的简","tags":["MOSN","Service Mesh"],"title":"云原生网络代理 MOSN 透明劫持技术解读 | 开源","type":"blog","url":"/blog/mosn-transparent-hijacking/","wordcount":3410},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n **SOFAStack 官网: **https://www.sofastack.tech **SOFAStack: **https://github.com/sofastack  每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n**1、@黄泽宏 **提问：\n SOFAJRaft 中 rheakv 不实现 region 新增删除，是因为分片迁移比较复杂么？\n A：不知道您说的新增删除是指什么？ 分裂与合并？ 分裂是有的，合并没有，不过分裂还没有经过严格的验证，也暂时不建议使用，分裂和合并确实比较复杂，复杂的不是分片迁移，分片迁移只要 raft 协议实现的没问题就是很自然的事情了。\n 对，sharding 合并分裂迁移，代码大概在哪个位置呢，想先看下实现。\n A：com.alipay.sofa.jraft.rhea.StoreEngine#applySplit 从这里看吧。 SOFAJRaft：https://github.com/sofastack/sofa-jraft\n2、@廖景楷 提问：\n 请教 Seata 在做超时处理时怎么协调多个节点不会同时对某个事务做多次处理？还是说要求业务容许多次commit，rollback，Seata 就不协调了？ 我在测试 seata-server 多节点 HA 部署，用 MySQL 存储，看代码貌似所有节点都是无差别无状态的，在多个实例的 DefaultCoordiantor 里头有定时器去扫描超时的事务进行重试或者回滚，打开 general log 也发现有多个客户端 IP 在用同样的语句在扫描 global_table 表进行超时等处理。想确认一下多节点间是否有协调机制？ 我在 K8s下面部署3节点的 seata-server statefulset，镜像 docker.io/seataio/seata-server:latest 使用 Nacos 作为 registry。\n A：目前没有，多次不会导致数据问题，不过确实浪费资源，可以考虑引入分布式 job。\n 也就是说比如同一个超时的未 commit Global Session 被多个节点同时扫描到，可能会调用业务做多次 commit，然后由业务自己去重？\n A：是的，不过不是业务处理，框架会处理。\n3、@Cheng cheng 提问：\n 最近正在做 Seata 跟我们产品集成到研究，问一个小白问题，我们需要把 Seata 部署到 K8s 里，那么如果 Seata server 的一个 pod 突然挂了，那在途的调用会突然中断，这样依然可以完美控制事务达成数据一致性吗？\n A：如果 Server 是公用的一个 DB，理论上没问题的。\n 没有理解你说的公用 DB\u0026amp;hellip;. Seata Server 在 K8s 上用独立的几个 pod 部署，那相应的我们会给它单独创建数据库。\n A：Seata 高可用要求就是需要 server 的集群共用同一个 Seata 库，不然无法数据共享，也就是无法知晓当前运作的事务信息。首先你要保证 Server 集群用的同一个注册中心集群，并且共用同一个 Seata 库，这样才能保障数据共享、高可用。\nSeata：https://github.com/seata/seata\n本周推荐阅读  Mecha：将 Mesh 进行到底 陌陌的 Service Mesh 探索与实践 | 线上直播回顾 《Service Mesh Virtual Meetup#1》：视频回顾  SOFA 项目进展 本周发布详情如下：\n1、发布 SOFABoot v3.4.0 版本，主要变更如下：\n 支持基于 gRPC 的 triple 协议； 修复 bolt callback 方式的兼容问题；  详细发布报告：https://github.com/sofastack/sofa-boot/releases/tag/v3.4.0\n2、发布 SOFAHessian v4.0.4 版本，主要变更如下：\n 修复 JDK 判断逻辑有锁问题； 修复 _staticTypeMap 为 ConcurrentMap，和 v3.x 对齐；  详细发布报告： https://github.com/sofastack/sofa-hessian/releases/tag/v4.0.4\n社区直播报名 在云原生时代，容器和 Kubernetes 在日常工作和实际生产中越来越普遍，随之而来的隔离性问题在不断被提起同时也受到了越来越多的关注。\nSOFAChannel#16 线上直播带来《不得不说的云原生隔离性》分享，将邀请 Kata Containers 维护者彭涛（花名：巴德）带我们走近云原生基础设施 \u0026amp;ndash; Kata Containers，详细分享它是如何在云原生框架下解决容器隔离性问题的。\n将从以下几个方面，与大家交流分享：\n 从 Kubernetes Pod 说起，经典容器场景下的 Pod 分享； 共享内核存在的问题以及解决办法； 上帝说，要有光；我们说，要有 Kata； The speed of containers, the security of VMs； Kata Containers 特性大放送； What? 你刚说过增加一个 VM 间接层的问题？  活动详情：\n **直播主题：**SOFAChannel#16：不得不说的云原生隔离性 **直播时间：**2020/5/21（周四）19:00-20:00 **报名方式：**点击“这里”，即可报名  ","date":1589533200,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20200515/","fuzzywordcount":1800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"f02bec7b5443778e602b655210ee33fb","permalink":"/blog/sofa-weekly-20200515/","publishdate":"2020-05-15T17:00:00+08:00","readingtime":4,"relpermalink":"/blog/sofa-weekly-20200515/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | SOFABoot\u0026SOFAHessian 发布、5/21 社区直播预告","type":"blog","url":"/blog/sofa-weekly-20200515/","wordcount":1792},{"author":"敖小剑","categories":"Service Mesh","content":"内容摘要：Service Mesh 落地实践三年，效果一直并不理想，到了该反思的时候了。Mecha 作为面向服务的分布式能力抽象层，是 Service Mesh 模式的自然进化版本，预计也将是云原生化和 Mesh 化的必然趋势，让我们将 Mesh 进行到底。\nMecha 介绍 什么是 Macha？ Mecha 一词，相信爱好动漫的同学应该都不陌生。是的，就是大家熟悉的那个 Mecha（机甲）：\nMecha 这个词之所以出现在这里，主要是因为 Bilgin Ibryam 的这个博客文章 “Multi-Runtime Microservices Architecture”，提出了微服务架构的一个新的设想：Multiple Runtime。\n 备注：这篇博客文章强烈推荐阅读，我甚至建议在阅读本文之前先阅读这篇文章，因为我今天的内容，可以视为对这个文章的深度解读和思考。为了方便，这里提供一份中文翻译版本 多运行时微服务架构。\n 在这篇博客中，Bilgin Ibryam 首先分析并总结了分布式应用的四大需求:\n 生命周期（Lifecycle） 网络（Networking） 状态（State） 捆绑（Binding）  由于每种需求存在的问题和局限性，导致传统解决方案如企业服务总线（ESB）及其变体（例如面向消息的中间件，更轻量级的集成框架等）不再适用。随着微服务架构的发展，以及容器和 Kubernetes 的普及和广泛使用，云原生思想开始影响这些需求的实现方式。未来的架构趋势是通过将所有传统的中间件功能移至其他运行时来全面发展，最后的目标是在服务中只需编写业务逻辑。\n 备注：详情请见原文，为了节约篇幅，这里只做简单概述，不完全引用原文内容。\n 下图是传统中间件平台和云原生平台的对比，传统中间件以各种SDK的方式提供能力，而云原生平台则通过各种外围Runtime（典型如大家熟悉的Servicemesh/Istio）：\n因此作者引入了 Multiple Runtime 的概念：\n作者提出：很可能在将来，我们最终将使用多个运行时来实现分布式系统。多个运行时，不是因为有多个微服务，而是因为每个微服务都将由多个运行时组成，最有可能是两个运行时-自定义业务逻辑运行时和分布式原语运行时。\n对多运行时微服务架构和 Mecha 的说明：\n 您还记得电影《阿凡达》和科学家们制作的用于去野外探索潘多拉的 Amplified Mobility Platform (AMP)“机车服”吗？这个多运行时架构类似于这些 Mecha-套装，为人形驾驶员赋予超能力。在电影中，您要穿上套装才能获得力量并获得破坏性武器。在这个软件架构中，您将拥有构成应用核心的业务逻辑（称为微逻辑/micrologic）和提供强大的开箱即用的分布式原语的 Sidecar Mecha 组件。Micrologic 与 Mecha 功能相结合，形成多运行时微服务，该服务将进程外功能用于其分布式系统需求。最棒的是，Avatar 2 即将面世，以帮助推广这种架构。我们最终可以在所有软件会议上用令人赞叹的机甲图片代替老式的边车摩托车；-)。接下来，让我们看看该软件架构的详细信息。 这是一个类似于客户端-服务器体系结构的双组件模型，其中每个组件都是独立的运行时。它与纯客户端-服务器架构的不同之处在于，这两个组件都位于同一主机上，彼此之间有可靠的网络连接。这两个组件的重要性相当，它们可以在任一方向上发起操作并充当客户端或服务器。其中的一个组件称为 Micrologic，拥有非常少的业务逻辑，把几乎所有分布式系统问题都剥离出去了。另一个伴随的组件是 Mecha，提供了我们在本文中一直讨论的所有分布式系统功能（生命周期除外，它是平台功能）。\n 作者在这里正式提出了 Mecha 的理念：\n思路大体是：Smart Runtime， Dumb Pipes。\n我对 Mecha 的理解是：业务逻辑在编码开始阶段应该是“裸奔”的，专注于业务逻辑的实现，而尽量不涉及到底层实现逻辑；而在运行时，则应该装备“机甲”，全副武装，大杀四方。熟悉的味道是吧？标准而地道的云原生思想。\nMecha 的本质 作者在原文中探讨了 Mecha 运行时的特性：\n Mecha 是通用的，高度可配置的，可重用的组件，提供分布式原语作为现成的能力。 Mecha 可以与单个 Micrologic 组件一起部署(Sidecar 模式)，也可以部署为多个共享(注：我称之为 Node 模式)。 Mecha 不对 Micrologic 运行时做任何假设，它与使用开放协议和格式（例如 HTTP/gRPC、JSON、Protobuf、CloudEvents）的多语言微服务甚至单体一起使用。 Mecha 以简单的文本格式（例如 YAML、JSON）声明式地配置，指示要启用的功能以及如何将其绑定到Micrologic 端点。 与其依靠多个代理来实现不同的目的（例如网络代理、缓存代理、绑定代理），不如使用一个 Mecha 提供所有这些能力。  下面是我对上述特性的个人理解：\n Mecha 提供的是能力，以分布式原语体现的各种能力，而不局限于单纯的网络代理。 Mecha 的部署模型，不局限于 Sidecar 模式，Node 模式在某些场景下（如 Edge/IoT，Serverless FaaS）可能会是更好的方式。至少，Mecha下有机会按需选择，而不是绑死在 Sidecar 模式上。 Mecha 和 Micrologic 之间的交互是开放而有 API 标准的，Mecha 和 Micrologic 之间的“协议”体现在 API 上，而不是 TCP 通讯协议。这提供了一个契机：一个统一 Micrologic 和 Mecha 之间通讯方式的契机。 Mecha 可以以声明式的方式进行配置和控制，这非常符合云原生的理念，同样也使得 API 更关注于能力本身，而不是能力如何配置。 应用需要的能力如此之多（参见上面的图：分布式应用的四大需求），如果每个能力都对应一个代理（不管是 Node 还是 Sidecar），数量会非常夸张，带来的运维压力会很可怕。因此，如 Mecha 这个名字暗示的，运行时应该是整套的形式提供能力，而不是分散。  如果用一句话来总结，那么我认为 Mecha 的本质应该是：\n“面向应用的分布式能力抽象层”\n如 Service Mesh 的本质是服务间通讯的抽象层一样，Mecha 的本质是应用需要的各种分布式能力和原语，包括但不限于服务间通讯。\n从这个角度上说，Mecha 覆盖的范围是 Service Mesh 的超集：毕竟 Service Mesh 只覆盖到应用的部分需求（服务间通讯，还只限于同步/一对一/request-response 模式），还有更多的分布式能力和原语有待覆盖。\n换一句话说，Mecha 的目标应该是：“将 Mesh 进行到底！”\nMecha 的优势和未来 作者指出：Mecha 的好处是业务逻辑和越来越多的分布式系统问题之间的松耦合。\n下图是业务逻辑和分布式系统问题在不同架构中的耦合：\n其实思路和 Service Mesh 是一脉相承的，只是覆盖的分布式能力更广泛一些。\n有一个问题：Mecha 会不会成为微服 …","date":1589364000,"description":"Mecha 作为面向服务的分布式能力抽象层，是 Service Mesh 模式的自然进化版本，预计也将是云原生化和 Mesh 化的必然趋势，让我们将 Mesh 进行到底。","dir":"blog/mecha-carry-mesh-to-the-end/","fuzzywordcount":7500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"2ef4b817d0dc0018551a25d24b174ee0","permalink":"/blog/mecha-carry-mesh-to-the-end/","publishdate":"2020-05-13T18:00:00+08:00","readingtime":15,"relpermalink":"/blog/mecha-carry-mesh-to-the-end/","summary":"内容摘要：Service Mesh 落地实践三年，效果一直并不理想，到了该反思的时候了。Mecha 作为面向服务的分布式能力抽象层，是 Service Mesh 模式的自然进化","tags":["Service Mesh"],"title":"Mecha：将 Mesh 进行到底","type":"blog","url":"/blog/mecha-carry-mesh-to-the-end/","wordcount":7479},{"author":"高飞航","categories":"Service Mesh","content":"Service Mesh Virtual Meetup 是 ServiceMesher 社区和 CNCF 联合主办的线上系列直播。本期为 Service Mesh Virtual Meetup#1 ，邀请了四位来自不同公司的嘉宾，从不同角度展开了 Service Mesh 的应用实践分享，分享涵盖来自陌陌和百度的 Service Mesh 生产实践，Service Mesh 的可观察性和生产实践以及与传统微服务中可观察性的区别，还有如何使用 SkyWalking 来观测 Service Mesh。\n本文根据5月6日晚，陌陌中间件架构师高飞航的主题分享《陌陌的 Service Mesh 探索与实践》整理。文末包含本次分享的视频回顾链接以及 PPT 下载地址。\n前言 本次演讲为大家分享的是陌陌目前正在进行的 Service Mesh 实践的相关内容。共分为三个部分：\n 第一部分是原有微服务架构的相关背景； 第二部分是原有架构遇到的问题以及决定采用 Service Mesh 方案的思考过程； 最后的部分对Service Mesh落地实践的方案进行介绍；  陌陌微服务体系演进历程 单体应用到微服务 各个应用的发展过程，都会经历从单体应用、到应用拆分再到微服务架构这样一个过程。陌陌的这个演进过程，有一点比较特别的是，在应用拆分时加入了由 PHP 开发、与客户端 App 进行对接的 API 层，并采用 Java 开发底层具有复杂运算的业务逻辑，这样能够兼得 PHP 的开发效率与 Java 高性能的优势。\n但这个选择的影响也是十分深远的，由于 PHP 在业务中的比重很高，我们在后续进行微服务改造和服务治理时，需要不断地去应对多语言架构带来的挑战。\n微服务体系演进 陌陌的微服务架构改造从 2013 年就开始了，在当时还没有较为完善的服务框架产品的情况下，我们自研了服务框架产品 MOA，支撑了陌陌 IM、附近动态、直播、短视频等核心业务的高速发展历程。\n在多年的迭代发展中，我们逐步完善了服务框架产品功能，同时也扩充了其他基础架构产品，最终形成了一个完善的微服务体系。其他基础架构产品也都是采用了自研的方案，因此整体是一个非常定制化的架构。这一点也成为后续 Service Mesh 落地选型时重点要考量的因素。\n微服务体系整体架构 下面对微服务体系的整体架构进行介绍。我们采用了一个 Redis 作为底层存储的注册中心。服务实例的存活检测主要依赖一个中心化的检测应用 MOA Watcher，能够将无法连通的实例从注册中心的在线列表中移除、摘除实例的业务流量。\n在多语言支持方面，我们除了支持最核心的 Java 与 PHP 应用之外，后续还支持了 Python、C++、Go、NodeJS 等非常多的语言接入微服务体系。由于陌陌的中间件团队是以 Java 工程师为主导的，服务框架组件的核心产品也是一个 Java 的 SDK。在没有足够的资源投入到其他语言 SDK 开发的情况下，我们采用了很多能够简化多语言开发工作的方案。\n例如跨语言调用和 Java 应用内部调用会采用不同的协议，Java 内部是较为传统的自定义二进制传输协议与 Hessian 序列化，跨语言则采用了 Redis 传输协议与 JSON 序列化。Redis 协议分别利用 GET 命令的 key 和 value 的位置传递 Request 和 Response，这样每种语言都可以基于成熟的 Redis 客户端开发 SDK，避免重复编写复杂的网络通信逻辑。此外还增加了一个地址发现服务 Lookup，使其他语言能够像调用普通服务的方式，轮询获取目标服务地址。跨语言场景的这些方案虽然简化了开发工作，但却不是最优方案。这也为整体架构的长期发展埋下了隐患。\n微服务体系的其他产品还包括统一的配置中心、监控平台、日志采集平台、分布式跟踪系统等，这些都是为微服务体系保驾护航的重要基础架构能力。\n流量代理机制 在多语言支持的场景中，我们很早就采用了两个和 Service Mesh 非常相近的方案。一个是为了支持多语言发布服务的入流量代理方案，使用 Java 开发的 Proxy 复用了 Java SDK 注册发现与监控等诸多服务治理能力，使得其他语言仅简单处理本地请求后就能实现发布服务。这些 Java Proxy 与多语言的业务进程是 1:1 部署的，但当时的方案是和业务进程放在一个容器里，升级时需要和业务进程一起重新发布。\n另外一个方案是为了解决 PHP 并行调用下游服务而实现的出流量代理，但这个方案中代理层的进程是运行在独立的服务器上，没有部署在与调用端相同的服务器。\n我们将流量代理机制应用于多语言服务治理的经历，在某种程度上突显了 Service Mesh 的价值，我们可能想到类似的方案去解决问题，但都没有像 Service Mesh 一样系统地给出一种最佳方案。不过这些相近方案的经验是有助于我们后续去推进 Service Mesh 落地的。\n微服务体系规模 随着业务的发展，整个微服务体系也达到了一个很具有挑战的量级。特别是在服务数量大幅增长后，Java 应用的服务治理问题也逐步暴露出来，其中最难以解决的是 SDK 升级的问题，这一点也是进一步推动我们转向 Service Mesh 架构的原因。\n借助 Service Mesh 解决现有架构痛点 架构痛点分析  前面我们提到的各种问题，其实都可以归结为微服务体系中服务治理能力滞后的问题。对于非 Java 的应用，由于没有足够的开发资源，会导致服务框架的 SDK 迭代进度非常缓慢。对于 Java 应用，虽然 SDK 具备最完善的功能，但使全量应用完成升级需要耗费大量人力和时间。根据以往的经验来看，一次推广至少需要一个季度的时间，并且为业务团队带来很多不必要的负担。\n两种场景最终的危害是一致的，都会导致架构能力上无法实现统一，先进的功能无法覆盖到全部应用，使应用稳定性受到损失，甚至引发故障。我们在多语言方案中依赖的中心化的 Lookup 服务，曾经就因为一次服务异常导致整个 API 层不可用，原因就是 PHP 的 SDK 采用了一种有缺陷的机制没有升级。在我们设计新方案时，也会因为架构能力无法统一而无法采用最佳的方案。例如我们在设计多机房架构时，由于流量调度机制无法快速覆盖到全部应用，因此只能采用从应用入口整体调度流量的一种粗粒度的方案。\n引入 Service Mesh Service Mesh 将基础架构逻辑与业务逻辑解耦、并支持独立升级的方式，能够很好地解决前面描述的架构痛点。但引入 Service Mesh 是一项非常重大的架构变更，并且需要多方面的成本投入。因此在实际落地实施前，我们必须思考以下几个问题，并在不同阶段完成对应的工作。\n 第一个是方案是否足够成熟。这里的方案不局限于 Service Mesh 本身，也依赖公司内其他基础设施的演进积累。例如我们在观察阶段实现了应用容化的推广覆盖、日志 Agent 方案的经验积累等。 第二个是遇到的问题是否有其他替代方案。例如我们之前急需在多语言场景覆盖的一个能力是流量调度机制，尝试过一个只提供地址路由机制，不代理流量的 Agent 方案。但发现很多逻辑还是要保留在 SDK …","date":1589266800,"description":"本文根据5月6日晚，陌陌中间件架构师高飞航的主题分享《陌陌的 Service Mesh 探索与实践》整理。","dir":"blog/momo-service-mesh-exploration-and-practice/","fuzzywordcount":6500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"9c4d2df383550d5412e3de24312862ed","permalink":"/blog/momo-service-mesh-exploration-and-practice/","publishdate":"2020-05-12T15:00:00+08:00","readingtime":13,"relpermalink":"/blog/momo-service-mesh-exploration-and-practice/","summary":"Service Mesh Virtual Meetup 是 ServiceMesher 社区和 CNCF 联合主办的线上系列直播。本期为 Service Mesh Virtual Meetup#1 ，邀请了四位来自不同公司的嘉宾，从不同角度展开了 Service Mesh 的应用实践分享，分享涵盖来自陌","tags":["Service Mesh"],"title":"陌陌的 Service Mesh 探索与实践 - 直播回顾","type":"blog","url":"/blog/momo-service-mesh-exploration-and-practice/","wordcount":6499},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\n社区大事件 MOSN 社区新认证一位 Committer\n孙福泽（@peacocktrain）认证成为 MOSN Committer：\n主要贡献： 贡献 3 个 feature PR\n 使 MOSN 支持 Istio 1.4； 协议支持 HTTP2 双向流式； 添加管道缓冲区；  MOSN：https://github.com/mosn/mosn\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动\n我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n**1、@chromosome **提问：\n 这个视频中提到因为 log server 中存储得到 commitedId 和 applyId 不是任意时刻都同步的，这样的话，如果说状态机的 apply 速度较慢，很可能 client 的 read request 并不能读取到状态机最新 committed 的操作的结果。 https://tech.antfin.com/community/live/821/data/902\n A：commitedIndex 和 applyIndex 的不完全同步，并不影响 read request 的结果，所以上面的后半句理解还是有点问题，可以看一下 SOFAJRaft 线性一致读的原理介绍，参考这个链接线性一致读章节 https://www.sofastack.tech/projects/sofa-jraft/consistency-raft-jraft/\n 所以 counter 例子中的 readindex 写法就是为了读线性一致性吗？例如 this.counterServer.getNode().readindex\n A：是的。\nSOFAJRaft：https://github.com/sofastack/sofa-jraft\n2、**@王勇 **提问：\n 在 AT 模式下，事务的回滚如何补偿三方的缓存操作呢？有没有额外的接口，还是只能是变成 TC 模式，或是自己写 aop？\n A：TCC 嵌套 AT，TCC 二阶段行为做补充。\n TCC 内应该说是不存在 AT 吧。\n A：AT 保证数据库的一致性，TCC 做来二阶段时的三方处理，比如发出 MQ 消息、缓存之类的。\n 就是 AT 和 TCC 在同一全局事务中一起使用是吧。这个 TCC 一阶段可以是空的，二阶段回滚时清理缓存嘛？\n A：嗯。\n OK，我明白了。就是让 TCC 嵌套 AT，通常情况下 TCC 为空，需要补偿的时候向 TCC 里写入东西。\n A：可以这么说，如果 TCC 触发二阶段是回滚，你就把缓存删掉，如果是提交就啥也不干，大概是这么个意思。\n TCC 模式下 AT 是默认的吗？对于大事务，Saga 模式，您用过吗？\n A：一、首先需要创建状态机引擎的 bean。 1.2.0里，状态机引擎的 bean 需要自己创建的。 1.3.0里，spring-boot-starter-seata 里会提供自动配置类。（可以先参考我修改过的代码吧。https://github.com/wangliang1986/seata） 二、需要创建 Saga 模式所需的三张表。github 上可以找到建表 SQL。 三、使用 Seata 的在线状态机设计器来定义流程。地址：http://seata.io/saga_designer/index.html 四、将设计器生成的 json 文件放到自己项目的 resources 中，由状态机引擎去加载它。状态机配置类中有一个配置项可以配置 json 文件路径。 五、使用状态机引擎启动 Saga 事务即可。（要注意的是 1.2.0 版本中，Saga 无法与 AT 一起启用。1.3.0 将修复此问题。） Seata：https://github.com/seata/seata\n本周推荐阅读  （含直播报名）Kata Containers 创始人：安全容器导论 蚂蚁金服 SOFAJRaft 优先级选举剖析 | 特性解析 Service Mesh 和 API Gateway 关系深度探讨  SOFA 项目进展 本周发布详情如下：\n1、发布SOFARPC v5.7.0,主要变更如下：\n 支持基于 grpc 的 triple 协议； 重构项目模块结构；  详细发布报告： https://github.com/sofastack/sofa-rpc/releases/tag/v5.7.0\n2、发布 SOFA MOSN v0.12.0，主要变更如下：\n 支持 SkyWalking； 支持流式 HTTP2； 熔断功能、负载均衡逻辑优化，负载均衡新增 ActiveRequest 和 WRR 算法； 优化 HTTP 连接建立性能； 底层实现优化； Bug Fix；  详细发布报告： https://github.com/sofastack/sofa-mosn/releases/tag/v0.12.0\n社区直播报名 本期为第一期 Service Mesh Virtual Meetup 线上系列直播第一期，邀请了四位来自不同公司的嘉宾，从四个角度对 Service Mesh 的应用实践展开分享。\n本次线直播分享涵盖 Service Mesh 的可观察性和生产实践，为大家介绍 Service Mesh 中的可观察性与传统微服务中可观察性的区别，如何使用 SkyWalking 来观测 Service Mesh，还有来自百度和陌陌的 Service Mesh 生产实践。\n本系列采用线上直播的形式，从 5 月 6 日开始到 5 月 14 日，每周三、周四晚上 19:00-20:00 我们相约进行一个主题分享。\n   时间 分享主题 分享嘉宾 嘉宾介绍     5/6 陌陌的 Service Mesh 实践 高飞航 陌陌中间件架构师   5/7 Apache SkyWalking 在 Service Mesh 中的可观察性应用 高洪涛 Tetrate 创始工程师   5/13 Servicre Mesh 高可用在企业级生产中的实践 罗广明 百度高级研发工程师   5/14 Servicre Mesh 中的可观察性实践 叶志远 G7 微服务架构师    观看直播方式：点击“这里”，关注直播间，即可观看直播\n","date":1588928400,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20200508/","fuzzywordcount":1900,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"c743041c871c1b4fdd685334ab29add6","permalink":"/blog/sofa-weekly-20200508/","publishdate":"2020-05-08T17:00:00+08:00","readingtime":4,"relpermalink":"/blog/sofa-weekly-20200508/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | MOSN\u0026amp;SOFARPC 发布、社区活动报名","type":"blog","url":"/blog/sofa-weekly-20200508/","wordcount":1872},{"author":"王旭","categories":"Kata Container","content":"从2015年5月初开始创业开发 HyperContainer (runV) 到现在，也快五年了，在这个时候还来写一篇什么是安全容器，显得略有尴尬。不过，也正是经过这五年，越来越多到人开始感到，我需要它却说不清它，这个时候来给大家重新解释 “\u0026amp;gt; 安全容器” 也正是时候。\n缘起：安全容器的命名 Phil Karlton 有一句名言—— 计算机科学界只有两个真正的难题——缓存失效和命名。 就容器圈而言，我相信命名绝对配得上这句话，这毫无疑问是一件让老开发者沉默，让新人落泪的事情。\n仅就系统软件而言，我们当今比较通行地称为 Linux 容器（LinuxContainer）的这个概念，曾经用过的名字大概还有——jail, zone, virtualserver, sandbox\u0026amp;hellip; 而同样，在早期的虚拟化技术栈里，也曾经把一个虚拟机环境叫做容器。毕竟这个词本身就指代着那些用来包容、封装和隔离的器物，实在是太过常见。以至于，以严谨著称的 Wikipedia 里，这类技术的词条叫做“系统级虚拟化”，从而回避了“什么是容器”这个问题。\n当2013年 Docker 问世之后，容器这个概念伴随着“不可变基础设施”、“云原生”这一系列概念，在随后的几年间，以摧枯拉朽之势颠覆了基于“软件包+配置”的细粒度组合的应用部署困境，用简单地声明式策略+不可变容器就清爽地描述了软件栈。应用怎么部署似乎离题了，我们这里想要强调的是——\n云原生语境下的容器，实质是“应用容器”——以标准格式封装的，运行于标准操作系统环境（常常是 Linux ABI）上的应用打包——或运行这一应用打包的程序/技术。\n这个定义是我在这里写下的，但是它并不是我的个人意志，这是基于 OCI (Open ContainerInitiative) 规范这一共识的，这个规范规定了容器之中的应用将被放置在什么环境中，如何运行，比如启动容器根文件系统上的哪个可执行文件，用什么用户，需要什么样的 CPU、内存资源，有什么外置存储，有什么样的共享需求等等。\n有了这一共识做基础，我们来说安全容器，这又是一段命名血泪史。当年，我的联合创始人赵鹏是用“虚拟化容器”命名的我们的技术的，为了搏人眼球，用了“Secure as VM, Fast asContainer”的大字标语，自此，被容器安全性问题戳中心坎的人们立刻用“Secure Container”来称呼这类东西，一发而不可收。而我们的内心中，这项技术提供了一层额外的隔离，隔离可能意味着安全性中的一环，也意味着某些运维效率、某些优化可能或者其他的功能。实际上，给安全容器这样的定义更合理——\n一种运行时技术，为容器应用提供一个完整的操作系统执行环境（常常是 LinuxABI），但将应用的执行与宿主机操作系统隔离开，避免应用直接访问主机资源，从而可以在容器主机之间或容器之间提供额外的保护。\n间接层：安全容器的精髓 安全问题的唯一正解在于允许那些（导致安全问题的）Bug 发生，但通过额外的隔离层来阻挡住它们。 —— LinuxCon NA 2015, Linus Torvalds 为了安全，为什么要引入间接层？因为以 Linux 之类的目前主流宿主机操作系统的规模，是无法从理论上验证程序是没有 Bug 的，而一旦合适的 Bug 被合适地利用，安全性风险就变成了安全性问题了，框架和修补并不能确保安全，所以，进行额外的隔离、缩减攻击面，就成了缓解安全问题的法宝——我们不能确保没有漏洞，但我们通过组合来减少漏洞被彻底攻破的风险。\nKata: 云原生化的虚拟化 2017年12月，我们在 KubeCon上对外发布了 Kata Containers 安全容器项目，这个项目的两个前身——我们发起的的 runV 和Intel 发起的 Clear Container 都发布于2015年5月（是的，早于上面 Linus 的引语）。这组项目的思路很简单 ——   操作系统本身的容器机制没办法解决安全性问题，需要一个隔离层；  虚拟机是一个现成的隔离层，AWS 这样的云服务已经让全世界相信，对户来说，\u0026amp;ldquo;secure of VM\u0026amp;rdquo; 是可以满足需求的；  虚机里面只要有个内核，就可以支持 OCI 规范的语义，在内核上跑个 Linux 应用这并不太难实现；  虚机可能不够快，阻碍了它在容器环境的应用，那么可不可以拥有 \u0026amp;ldquo;speed of container\u0026amp;rdquo; 呢？   现在，如果最后一个问题可以解决，那么它就是我们要的“安全的容器”了——这就是 Kata Containers。 目前 Kata Containers 通常是在 Kubernetes 环境中使用的，Kubelet 通过CRI 接口让 containerd 或 CRI-O 执行运行时操作，通常镜像操作由这些 CRI Daemon 来进行，而根据请求，把 Runtime 操作写成一个 OCI Spec 交给 OCI Runtime 执行。这里，对于 1.2 以上的 containerd 和 1.5 版本上后的 Kata Containers（对应 ），通常是利用 containerd 来完成的：\n 每个 Pod 会有一个 shim-v2 进程来为 containerd/CRI-O 执行各种运行时操作，这个进程和整个 Pod 的生命周期一致，通过一个 ttRPC 接口为 containerd/CRI-O 提供服务； Shim-v2 会为 Pod 启动一个虚拟机作为 PodSandbox提供隔离性，其中运行着一个 Linux 内核，通常这个 Linux 内核是一个裁剪过的内核，不会支持没有必要的设备； 这里用的虚拟机可以是 Qemu 或是 Firecracker，如果是 Firecracker，那么根本就没有模拟的设备，而如果是 Qemu，通过配置和补丁，也会让它尽量小一些，支持的其他虚拟机还包括 ACRN 和 cloud-hypervisor，未来后者可能会被越来越多的用到； 这个虚拟机在启动的时候可能根本就是一个 initrd 而没有完整操作系统，或者有个极小的操作系统，总之，它完全不是按照一台模拟机的操作系统来配置的，它只是支撑容器应用运行的基础设施，以及相关的应用环境 Metrics 采集或应用跟踪调试需要的资源； 容器本身的 rootfs 会在 Sandbox 启动之后，在收到 contaienrd/CRI-O 的创建容器的 OCI 请求之后，以热插拔的方式动态插入到虚机中，容器的 rootfs 准备和虚机本身的启动是可以并行的； 依照 CRI 语义和 OCI 规范，Pod 里可以启动多个相关联的容器，它们被放在同一个虚机里，并且可以互相共享 namespace； 外来的存储卷可以以块设备或文件系统共享的方式插入到 PodSandbox 中，但对于 Pod 里的容器来说，它们都是加载好的文件系统，目前开始逐渐普及的文件系统方式是专为 Kata 这样的场景设计的 virtio-fs，它不仅比传统的 9pfs 更快、有更完整的 POSIX 文件系统的支持，而且借由所谓 vhost-user 和 DAX 技术， …","date":1588921200,"description":"隔离，让云原生基础设施更完美。","dir":"blog/kata-container-introduction-to-safe-containers/","fuzzywordcount":4700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"6075ee3441970bada70f11c633f4ba85","permalink":"/blog/kata-container-introduction-to-safe-containers/","publishdate":"2020-05-08T15:00:00+08:00","readingtime":10,"relpermalink":"/blog/kata-container-introduction-to-safe-containers/","summary":"从2015年5月初开始创业开发 HyperContainer (runV) 到现在，也快五年了，在这个时候还来写一篇什么是安全容器，显得略有尴尬。不过，也正是经过这五年，越来越多到人","tags":["Kata Container"],"title":"（含直播报名）Kata Containers 创始人：安全容器导论","type":"blog","url":"/blog/kata-container-introduction-to-safe-containers/","wordcount":4682},{"author":"Committer 胡宗棠","categories":"SOFAJRaft","content":" SOFAStack（Scalable Open Financial Architecture Stack） 是蚂蚁金服自主研发的金融级云原生架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。\n SOFAJRaft 是一个基于 Raft 一致性算法的生产级高性能 Java 实现，支持 MULTI-RAFT-GROUP，适用于高负载低延迟的场景。\n本文作者胡宗棠，SOFAJRaft Committer，来自中国移动。本文主要介绍 SOFAJRaft 在 Leader 选举过程中的重要优化方案—一种半确定性的优先级选举机制，将会先简单地介绍下原 Raft 算法中随机超时选举机制的大致内容，如果读者对这块内容理解得不够深入，建议可以先阅读下《SOFAJRaft 选举机制剖析 | SOFAJRaft 实现原理》。阅读完这篇文章后，再来看本篇的内容会对半确定性的优先级选举机制有更为深刻的理解。\nSOFAJRaft：https://github.com/sofastack/sofa-jraft\n一、Raft 算法中选举机制的概念与特点 Raft 算法是一种“共识性”算法，这里所谓的“共识性”主要体现在让多个参与者针对某一件事达成完全一致：一件事一个结论，同时对已达成一致的结论，是不可推翻的。基于这个根本特征，就决定了 Raft 算法具有以下几个主要特点：\n Strong leader：Raft 集群中最多只能有一个 Leader，日志只能从 Leader 复制到 Follower 上； Leader election：Raft 算法采用随机超时时间触发选举来避免选票被瓜分的情况，保证选举的顺利完成。这是主要为了保证在任何的时间段内，Raft 集群最多只能存在一个 Leader 角色的节点； Membership changes：通过两阶段的方式应对集群内成员的加入或者退出情况，在此期间并不影响集群对外的服务；  在 Raft 算法中，选举是很重要的一部分。所谓选举就是在由多个节点组成的一个 Raft 集群中选出一个 Leader 节点，由他来对外提供写服务 （以及默认情况下的读服务）。\n这里先介绍一个任期的概念—Term， 其用来将一个连续的时间轴在逻辑上切割成一个个区间，它的含义类似于“美国第 26 届总统”这个表述中的“26”。同时，该 Term ID 的值是按照时间轴单调递增的，它构成了 Raft Leader 选举的必要属性。\n每一个 Term 期间集群要做的第一件事情就是选举 Leader。起初所有的 Server 都是 Follower 角色，如果 Follower 经过一段时间( election timeout )的等待却依然没有收到其他 Server 发来的消息时，Follower 就可以认为集群中没有可用的 Leader，遂开始准备发起选举。为了让 Raft 集群中的所有节点尽可能的客观公平公正，采用了随机超时时间触发选举，来避免若干个节点在同一时刻尝试选举而导致选票被瓜分的情况，保证选举的顺利完成。SOFAJRaft 的做法是，在 Node 触发选举的定时任务— electionTimer 中的设置每次定时执行的时间点：时间区间 [electionTimeoutMs，electionTimeoutMs + maxElectionDelayMs) 中的任何时间点。\n在发起选举的时候 Server 会从 Follower 角色转变成 Candidate，然后开始尝试竞选 Term + 1 届的 Leader，此时他会向其他的 Server 发送投票请求，当收到集群内多数机器同意其当选的应答之后，Candidate 成功当选 Leader。但是如下两种情况会让 Candidate 退回 (step down) 到 Follower，放弃竞选本届 Leader：\n 如果在 Candidate 等待 Servers 的投票结果期间收到了其他拥有更高 Term 的 Server 发来的投票请求； 如果在 Candidate 等待 Servers 的投票结果期间收到了其他拥有更高 Term 的 Server 发来的心跳；  同时，当一个 Leader 发现有 Term 更高的 Leader 时也会退回到 Follower 状态。当选举 Leader 选举成功后，整个 Raft 集群就可以正常地向外提供读写服务了，如上图所示，集群由一个 Leader 和两个 Follower 组成，Leader 负责处理 Client 发起的读写请求，同时还要跟 Follower 保持心跳和将日志 Log 复制给 Follower。\n但 Raft 算法的“随机超时时间选举机制”存在如下问题和限制：\n 下一个任期 Term，Raft 集群中谁会成为 Leader 角色是不确定的，集群中的其他节点成为 Leader 角色的随机性较强，无法预估。试想这样的一个场景：假设部署 Raft 集群的服务器采用不同性能规格，业务用户总是期望 Leader 角色节点总是在性能最强的服务器上，这样能够为客户端提供较好的读写能力，而上面这种“随机超时时间选举机制”将不能满足需求； 如上图所示，由于会存在选票被瓜分的场景，集群中的各个 Candidate 角色节点将在下一个周期内重新发起选举。而在这个极短的时间内，由于集群中不存在 Leader 角色所以是无法正常向客户端提供读写能力，因此业务用户需要通过其他方式来避免短时间的不可用造成的影响；  二、SOFAJRaft 基于优先级的半确定性选举机制 2.1 SOFAJRaft 基于优先级选举机制的原理 为了解决原本 Raft 算法“随机超时时间选举机制”带来的问题，增加选举的确定性，作者贡献了一种“基于优先级的半确定性选举机制”。主要的算法思想是：通过配置参数的方式预先定义 Raft 集群中各个节点的 priority 选举优先级的值，每个 Raft 节点进程在启动运行后是能够知道集群中所有节点的 priority 的值（包括它自身的、本地会维护 priority 变量）。\n对每个 Raft 节点的配置如下（下面以其中一个节点的配置举例），其中 PeerId 的字符串值的具体形式为：{ip}:{port}:{index}:{priority}；\n在 Raft 节点进程初始化阶段，通过对所有节点 priority 值求最大值来设置至节点自身维护的 targetPriority 本地全局变量里。在上面这个例子中，节点的 targetPriority 本地全局变量值就被设置为 160，而自身的 priority 值为 100。\n在每个 Raft 节点通过随机超时机制触发 PreVote 预选举阶段之前，会通过先比较自身的 priority 值和 targetPriority 值来决定是否参加本轮的 Leader 选举投票。所以，一组 Raft 节点组成的集群在刚启动运行的阶段，priority 值最大的节点（上面例子中 160 的那个节点）必然会优先被选择成为这个集群中 Leader 角色的节点向外提供读和写的服务。\n2.2 SOFAJRaft 优先级选举 …","date":1588759200,"description":"继源码解析系列后，推出特性解析系列，本文为 SOFAJRaft 特性解析第一篇，主要介绍 SOFAJRaft 在 Leader 选举过程中的重要优化方案—一种半确定性的优先级选举机制。","dir":"blog/sofa-jraft-priority-election/","fuzzywordcount":5500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"d867df257326471e46ce05ed548f72e8","permalink":"/blog/sofa-jraft-priority-election/","publishdate":"2020-05-06T18:00:00+08:00","readingtime":11,"relpermalink":"/blog/sofa-jraft-priority-election/","summary":"SOFAStack（Scalable Open Financial Architecture Stack） 是蚂蚁金服自主研发的金融级云原生架构，包含了构建金融级云原生架构所需的各个组件，是在金","tags":["SOFAJRaft","SOFAJRaft 特性解析"],"title":"蚂蚁金服 SOFAJRaft 优先级选举剖析 | 特性解析","type":"blog","url":"/blog/sofa-jraft-priority-election/","wordcount":5415},{"author":"敖小剑","categories":"Service Mesh","content":"前言 关于 Service Mesh 和 API Gateway 之间的关系，这个问题过去两年间经常被问起，社区也有不少文章和资料给出解答。其中不乏 Christian Posta 这样的网红给出过深度介绍。我在这里做一个资料的整理和汇总，结合个人的理解给出一些看法。另外在本文最后，介绍蚂蚁金服在 Service Mesh 和 API Gateway 融合的这个最新领域的一些开创性的实践和探索，希望给大家一个更有体感的认知。\n 备注1：为了节约篇幅，我们将直奔主题，假定读者对 Service Mesh 和 API Gateway 已有基本的了解。 备注2: 这边文章更关注于梳理整个脉络，内容不会展开的特别细，尤其是其他文章已经详细阐述的部分。如果您在浏览本文之后，还想更深入的了解细节，请继续阅读文章最后的参考资料和推荐阅读。\n 原本清晰的界限：定位和职责 首先，Service Mesh 和 API Gateway 在功能定位和承担的职责上有非常清晰的界限：\n Service Mesh：微服务的网络通信基础设施，负责（系统内部的）服务间的通讯； API Gateway： 负责将服务以 API 的形式暴露（给系统外部），以实现业务功能；  如上图所示：\n从功能和职责上说：\n 位于最底层的是拆分好的原子微服务，以服务的形式提供各种能力； 在原子微服务上是（可选的）组合服务，某些场景下需要将若干微服务的能力组合起来形成新的服务； 原子微服务和组合服务部署于 系统内部，在采用 Service Mesh 的情况下，由 Service Mesh 提供服务间通讯的能力； API Gateway 用于将系统内部的这些服务暴露给 系统外部，以 API 的形式接受外部请求；  从部署上说：\n Service Mesh 部署在系统内部：因为原子微服务和组合服务通常不会直接暴露给外部系统； API Gateway 部署在系统的边缘：一方面暴露在系统之外，对外提供 API 供外部系统访问；一方面部署在系统内部，以访问内部的各种服务。  在这里引入两个使用非常广泛的术语：\n 东西向通讯：指服务间的相互访问，其通讯流量在服务间流转，流量都位于系统内部； 南北向通讯：指服务对外部提供访问，通常是通过 API Gateway 提供的 API 对外部保罗，其通讯流量是从系统外部进入系统内部；   解释一下“东西南北”的由来：如上图所示，通常在地图上习惯性的遵循“上北下南，左东右西”的原则。\n 总结：Service Mesh 和 API Gateway 在功能和职责上分工明确，界限清晰。但如果事情就这么结束，也就不会出现 Service Mesh 和 API Gateway 关系的讨论了，自然也不会有本文。\n问题的根源在哪里？\n 强烈推荐阅读：附录中 Christian Posta 的文章 \u0026amp;ldquo;Do I Need an API Gateway if I Use a Service Mesh?\u0026amp;ldquo;对此有深度分析和讲解。\n 哲学问题：网关访问内部服务，算东西向还是南北向？ 如下图所示，图中黄色的线条表示的是 API Gateway 访问内部服务：\n问题来了，从流量走向看：这是外部流量进入系统后，开始访问对外暴露的服务，应该属于“南北向”通讯，典型如上图的画法。但从另外一个角度，如果我们将 API Gateway 逻辑上拆分为两个部分，先忽略对外暴露的部分，单独只看 API Gateway 访问内部服务的部分，这时可以视 API Gateway 为一个普通的客户端服务，它和内部服务的通讯更像是“东西向”通讯：\n所以，API Gateway 作为一个客户端访问内部服务时，到底算南北向还是东西向，就成为一个哲学问题：完全取决于我们如何看待 API Gateway ，是作为一个整体，还是逻辑上分拆为对内对外两个部分。\n这个哲学问题并非无厘头，在 API Gateway 的各种产品中，关于如何实现 “API Gateway 作为一个客户端访问内部服务” ，就通常分成两个流派：\n 泾渭分明：视 API Gateway 和内部服务为两个独立事物，API Gateway 访问内部服务的通讯机制自行实现，独立于服务间通讯的机制； 兼容并济：视 API Gateway 为一个普通的内部服务的客户端，重用其内部服务间通讯的机制；  而最终决策通常也和产品的定位有关：如果希望维持 API Gateway 的独立产品定位，希望可以在不同的服务间通讯方案下都可以使用，则通常选择前者，典型如 Kong；如果和服务间通讯方案有非常深的渊源，则通常选择后者，典型如 Spring Cloud 生态下的 Zuul 和 SpringCloud Gateway。\n但无论选择哪个流派，都改变不了一个事实，当 “API Gateway 作为一个客户端访问内部服务” 时，它的确和一个普通内部服务作为客户端去访问其他服务没有本质差异：服务发现、负载均衡、流量路由、熔断、限流、服务降级、故障注入、日志、监控、链路追踪、访问控制、加密、身份认证\u0026amp;hellip;\u0026amp;hellip; 当我们把网关访问内部服务的功能一一列出来时，发现几乎所有的这些功能都是和服务间调用重复。\n这也就造成了一个普遍现象：如果已有一个成熟的服务间通讯框架，再去考虑实现 API Gateway，重用这些重复的能力就成为自然而然的选择。典型如前面提到的 Spring Cloud 生态下的 Zuul 以及后面开发的 Spring Cloud Gateway，就是以重用类库的方式实现了这些能力的重用。\n这里又是一个类似的哲学问题：当 “API Gateway 作为一个客户端访问内部服务” 时，它以重用类库的方式实现了代码级别的能力重用，相当于自行实现了一个和普通服务间通讯方案完全一样的客户端，那这个“客户端”发出来的流量算东西向还是南北向？\n答案不重要。\nSidecar：真正的重合点 在进入 Service Mesh 时代之后，Service Mesh 和 API Gateway 的关系开始是这样：\n 功能和职责清晰划分； 客户端访问服务的功能高度重叠；  此时两者的关系很清晰，而且由于当时 Service Mesh 和 API Gateway 是不同的产品，两者的重合点只是在功能上。\n而随着时间的推移，当 Service Mesh 产品和 API Gateway 产品开始出现相互渗透时，两者的关系就开始变得暧昧。\n在 Service Mesh 出现之后，如何为基于 Service Mesh 的服务选择合适的 API Gateway 方案，就慢慢开始提上日程，而其中选择重用 Service Mesh 的能力也自然成为一个探索的方向，并逐步出现新式 API Gateway 产品，其想法很直接：\n如何融合东西向和南北向的通讯方案？\n其中的一个做法就是基于 Service Mesh 的 Sidecar 来实现 API Gateway，从而在南北向通讯中引入 Service Mesh 这种东西向通讯的方案。这里我们不展开细节，我这里援引一个图片(鸣谢赵化冰同学)来解释这个方案的思路：\n这个时候 Service …","date":1588143600,"description":"Service Mesh 和 API Gateway 之间的关系，是“泾渭分明”还是“兼容并进”？","dir":"blog/service-mesh-api-gateway-in-depth-discussion-of-relationships/","fuzzywordcount":5400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"17986a3e65f4db0f66b6ba707cf27a40","permalink":"/blog/service-mesh-api-gateway-in-depth-discussion-of-relationships/","publishdate":"2020-04-29T15:00:00+08:00","readingtime":11,"relpermalink":"/blog/service-mesh-api-gateway-in-depth-discussion-of-relationships/","summary":"前言 关于 Service Mesh 和 API Gateway 之间的关系，这个问题过去两年间经常被问起，社区也有不少文章和资料给出解答。其中不乏 Christian Posta 这样的网红给出过深度介绍。我在这里做","tags":["Service Mesh","API Gateway "],"title":"Service Mesh 和 API Gateway 关系深度探讨","type":"blog","url":"/blog/service-mesh-api-gateway-in-depth-discussion-of-relationships/","wordcount":5306},{"author":"卫恒","categories":"SOFATracer","content":" SOFA:Channel/，有趣实用的分布式架构频道。 回顾视频以及 PPT 查看地址见文末。欢迎加入直播互动钉钉群 : 21992058，不错过每场直播。\n 本文根据 SOFAChannel#15 直播分享整理，主题：分布式链路组件 SOFATracer 埋点机制解析。\n大家好，我是宋国磊，花名卫恒，是 SOFATracer 的开源负责人。今天要和大家分享的是分布式链路组件 SOFATracer 埋点机制解析，将通过具体 Demo 演示快速上手 SOFATracer，同时介绍 SOFATracer 功能点，并详细介绍其核心关键「埋点机制」的原理。\nSOFATracer 是蚂蚁金服开源的基于 OpenTracing 规范 的分布式链路跟踪系统，其核心理念就是通过一个全局的 TraceId 将分布在各个服务节点上的同一次请求串联起来。通过统一的 TraceId 将调用链路中的各种网络调用情况以日志的方式记录下来同时也提供远程汇报到 Zipkin 进行展示的能力，以此达到透视化网络调用的目的。\nSOFATracer：https://github.com/sofastack/sofa-tracer\nSOFATracer 作为 SOFAStack 中的分布式链路组件，也伴随着 SOFAStack 走过了两年的时间，在此首先对两年来对 SOFATracer 保持关注并且参与社区建设的同学表示感谢，也希望大家能够继续关注 SOFAStack 的发展，也欢迎更多的同学加入到 SOFAStack 的社区参与中来。\n今天的分享内容主要将会围绕以下三个部分展开：\n SOFATracer 功能点详细介绍； SOFATracer 埋点机制原理详解； 快速上手 SOFATracer 演示；  关于 SOFATracer 更多的问题也欢迎在 Github 上跟我们交流。\nSOFATracer 简介 首先简单介绍一下 SOFATracer。上图展示的是 SOFATracer 目前所包括的基本能力和所支持的插件。下面虚线框中绿色背景部分，是 SOFATracer 提供的基本功能，具体可以参考官方文档描述。上面虚线框中是 SOFATracer 目前所支持的组件，大概分了以下几种类型：客户端、Web、数据存储、消息、RPC、Spring Cloud。\n之前社区也发起过 剖析 | SOFATracer 框架 的源码解析系列文章，在此系列中对 SOFATracer 所提供的能力及实现原理都做了比较全面的分析，有兴趣的同学可以看下。\n今天主要聊一下埋点机制。不同组件的埋点机制也是有很大的差异，SOFATracer 是如何实现对上述组件进行埋点的，下面就详细分析下不同组件的埋点机制。\n埋点机制 目前 SOFATracer 已经支持了对以下开源组件的埋点支持：Spring MVC、RestTemplate、HttpClient、OkHttp3、JDBC、Dubbo(2.6/2.7)、SOFARPC、Redis、MongoDB、Spring Message、Spring Cloud Stream (基于 Spring Message 的埋点)、RocketMQ、Spring Cloud FeignClient、Hystrix。\n 大多数能力提供在 3.x 版本，2.x 版本从官方 issue 中可以看到后续将不再继续提供新的功能更新；这也是和 SpringBoot 宣布不再继续维护 1.x 版本有关系。\n 标准 Servlet 规范埋点原理 SOFATracer 支持对标准 Servlet 规范的 Web MVC 埋点，包括普通的 Servlet 和 Spring MVC 等，基本原理就是基于 Servelt 规范所提供的 javax.servlet.Filter 过滤器接口扩展实现。\n 过滤器位于 Client 和 Web 应用程序之间，用于检查和修改两者之间流过的请求和响应信息。在请求到达 Servlet 之前，过滤器截获请求。在响应送给客户端之前，过滤器截获响应。多个过滤器形成一个 FilterChain，FilterChain 中不同过滤器的先后顺序由部署文件 web.xml 中过滤器映射的顺序决定。最先截获客户端请求的过滤器将最后截获 Servlet 的响应信息。\n Web 应用程序一般作为请求的接收方，在 SOFATracer 中应用是作为 Server 存在的，其在解析 SpanContext 时所对应的事件为 sr (server receive)。\nSOFATracer 在 sofa-tracer-springmvc-plugin 插件中解析及产生 Span 的过程大致如下：\n Servlet Filter 拦截到 request 请求； 从请求中解析 SpanContext； 通过 SpanContext 构建当前 MVC 的 Span； 给当前 Span 设置 tag、log； 在 Filter 处理的最后，结束 Span；  当然这里面还会设计到其他很多细节，比如给 Span 设置哪些 tag 属性、如果处理异步线程透传等等。本次分享就不展开细节探讨，有兴趣的同学可以自行阅读代码或者和我们交流。\nDubbo 埋点原理 Dubbo 埋点在 SOFATracer 中实际上提供了两个插件，分别用于支持 Dubbo 2.6.x 和 Dubbo 2.7.x；Dubbo 埋点也是基于 Filter ，此 Filter 是 Dubbo 提供的 SPI 扩展-调用拦截扩展 机制实现。\n像 Dubbo 或者 SOFARPC 等 RPC 框架的埋点，通常需要考虑的点比较多。首先， RPC 框架分客户端和服务端，所以在埋点时 RPC 的客户端和服务端必须要有所区分；再者就是 RPC 的调用方式包括很多种，如常见的同步调用、异步调用、oneway 等等，调用方式不同，所对应的 Span 的结束时机也不同，重要的是基本所有的 RPC 框架都会使用线程池用来发起和处理请求，那么如何保证 SOFATracer 在多线程环境下不串也很重要。\n另外 Dubbo 2.6.x 和 Dubbo 2.7.x 在异步回调处理上差异比较大，Dubbo 2.7.x 中提供了 onResponse 方法（后面又升级为 Listener，包括 onResponse 和 onError 两个方法）；而 Dubbo 2.6.x 中则并未提供相应的机制，只能通过对 Future 的硬编码处理来完成埋点和上报。\n 这个问题 Zipkin Brave 对 Dubbo 2.6.x 的埋点时其实也没有考虑到，在做 SOFATracer 支持 Dubbo 2.6.x 时发现了这个 bug，并做了修复。\n SOFATracer 中提供的 DubboSofaTracerFilter 类：\n@Activate(group = { CommonConstants.PROVIDER, CommonConstants.CONSUMER }, value = \u0026amp;#34;dubboSofaTracerFilter\u0026amp;#34;, order = 1) public class …","date":1588068000,"description":"SOFATracer 埋点机制解析直播文字回顾。","dir":"blog/sofa-channel-15-retrospect/","fuzzywordcount":4600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"4e4c9d4539119eb12ece83c8228ee4a3","permalink":"/blog/sofa-channel-15-retrospect/","publishdate":"2020-04-28T18:00:00+08:00","readingtime":10,"relpermalink":"/blog/sofa-channel-15-retrospect/","summary":"SOFA:Channel/，有趣实用的分布式架构频道。 回顾视频以及 PPT 查看地址见文末。欢迎加入直播互动钉钉群 : 21992058，不错过每场直播","tags":["SOFATracer","SOFAChannel"],"title":"分布式链路组件 SOFATracer 埋点机制解析 | SOFAChannel#15 直播整理","type":"blog","url":"/blog/sofa-channel-15-retrospect/","wordcount":4573},{"author":"潘潘","categories":"SOFAChannel","content":"概要   活动主题：SOFAChannel#16：不得不说的云原生隔离性\n  活动时间：5 月 21 日周四晚 7 点\n  活动形式：线上直播\n  报名方式：戳这里\n  介绍 | SOFAChannel \u0026amp;lt;SOFA:Channel/\u0026amp;gt; 有趣实用的分布式架构频道，前沿技术、直播 Coding、观点“抬杠”，多种形式。\n\u0026amp;lt;SOFA:Channel/\u0026amp;gt; 将作为 SOFA 所有在线内容的承载，包含直播/音视频教程，集中体现 SOFAStack 的能力全景图。\n| SOFAChannel#16：不得不说的云原生隔离性 在云原生时代，容器和 Kubernetes 在日常工作和实际生产中越来越普遍，随之而来的隔离性问题在不断被提起同时也受到了越来越多的关注。\nKata Containers 是 OpenStack 基金会旗下又独立于 OpenStack 项目之外的开放基础设施顶级项目，旨在把虚拟机的安全隔离优势与容器的速度和可管理性统一起来，为用户提供安全快速易用的容器基础设施。\n本期直播，将邀请 Kata Containers 维护者彭涛（花名：巴德）带我们走近云原生的一项基础设施 \u0026amp;ndash; Kata Containers，看它是如何在云原生框架下解决容器隔离性问题的。\n| 加入 SOFA 钉钉互动群 欢迎加入直播互动钉钉群：30315793（搜索群号加入即可）\n| 点击即可报名 https://tech.antfin.com/community/live/1197\n议程 19:00-19:05 主持人开场 SOFAGirl 主持人\n19:05-20:00 不得不说的云原生隔离性 卫恒 SOFATracer 开源负责人\n你将收获  从 Kubernetes Pod 说起，经典容器场景下的 Pod 分享； 共享内核存在的问题以及解决办法； 上帝说，要有光；我们说，要有 Kata； The speed of containers, the security of VMs； Kata Containers 特性大放送； What? 你刚说过增加一个 VM 间接层的问题？  嘉宾  SOFAGirl 主持人 卫恒 SOFATracer 开源负责人  ","date":1588057200,"description":"5 月 21 日周四晚 7 点，线上直播第 16 期。","dir":"activities/sofa-channel-16/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"4756bc76f718255ad5fc4fd172a706b4","permalink":"/activities/sofa-channel-16/","publishdate":"2020-04-28T15:00:00+08:00","readingtime":2,"relpermalink":"/activities/sofa-channel-16/","summary":"概要 活动主题：SOFAChannel#16：不得不说的云原生隔离性 活动时间：5 月 21 日周四晚 7 点 活动形式：线上直播 报名方式：戳这里 介绍 | SOFAChannel \u0026lt;SOFA:Channel/\u0026gt; 有","tags":["SOFAChannel","Kata Container"],"title":"SOFAChannel#16：不得不说的云原生隔离性","type":"activities","url":"/activities/sofa-channel-16/","wordcount":568},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n@闫圣哲 提问：\n 请问：关于 SOFAJRaft 线性读，为什么读失败了要应用到状态机呢，是为了拉齐 readindex 吗？\n A：线性一直读不走 raft log （应该是你说的状态机的意思），在 rheakv 里面，如果线性一直读失败了，那么会和write操作一样通过 raft log 达成一致再走状态机读，这是个兜底策略，否则 readIndex 失败了能怎么办呢？ 另一只方式就是直接返回用户失败了。可以具体看一下「JRaft 实现细节解析之高效的线性一致读」这一小节的内容～\nhttps://www.sofastack.tech/projects/sofa-jraft/consistency-raft-jraft/\nSOFAJRaft：https://github.com/sofastack/sofa-jraft\nSOFA 项目进展 本周发布详情如下：\n发布 Seata v1.2.0 版本，主要变更如下：\n 支持 XA 事务模式； 支持事务传播机制； 支持批量更新和删除 SQL； TCC 模式支持 hsf 服务调用； Saga 模式性能优化默认不注册分支事务等；  本次发布涉及代码改动文件数 324个，代码行 +11,907 −3,437。 此版本在 feature 和稳定性相对 1.1.0 版本都有较大幅度增强，强烈推荐大家验证和升级到此版本。 详细发布报告：https://seata.io/zh-cn/blog/download.html\nService Mesh 大规模落地系列  蚂蚁金服 Service Mesh 大规模落地系列 - 质量篇 蚂蚁金服 Service Mesh 大规模落地系列 - 控制面篇 蚂蚁金服 Service Mesh 大规模落地系列 - Operator 篇 蚂蚁金服 Service Mesh 大规模落地系列 - 网关篇 蚂蚁金服 Service Mesh 大规模落地系列 - RPC 篇 蚂蚁金服 Service Mesh 大规模落地系列 - 运维篇 蚂蚁金服 Service Mesh 大规模落地系列 - 消息篇 蚂蚁金服 Service Mesh 大规模落地系列 - 核心篇 Service Mesh 落地负责人亲述：蚂蚁金服双十一四大考题  社区直播报名 本期为第一期 Service Mesh Virtual Meetup 线上系列直播第一期，邀请了四位来自不同公司的嘉宾，从四个角度对 Service Mesh 的应用实践展开分享。\n本次线上 meetup 分享涵盖 Service Mesh 的可观察性和生产实践。为大家介绍 Service Mesh 中的可观察性与传统微服务中可观察性的区别，如何使用 SkyWalking 来观测 Service Mesh，还有来自百度和陌陌的 Service Mesh 生产实践。\n本系列采用线上直播的形式，从 5 月 6 日开始到 5 月 14 日，每周三、周四晚上 19:00-20:00 我们相约进行一个主题分享。\n观看直播方式：保存图片扫码 或 点击“这里”，关注直播间，即可观看直播\n","date":1587722400,"description":"【04/20-04/24】 | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20200424/","fuzzywordcount":1100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"455d22426589849b45f59083c641ee7c","permalink":"/blog/sofa-weekly-20200424/","publishdate":"2020-04-24T18:00:00+08:00","readingtime":3,"relpermalink":"/blog/sofa-weekly-20200424/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | Service Mesh 系列直播预告、Seata 发布","type":"blog","url":"/blog/sofa-weekly-20200424/","wordcount":1092},{"author":"潘潘","categories":"SOFAChannel","content":"概要   活动主题：SOFAChannel#15：分布式链路组件 SOFATracer 埋点机制解析\n  活动时间：4 月 23 日周四晚 7 点\n  活动形式：线上直播\n  直播回顾：戳这里\n  介绍 | SOFAChannel \u0026amp;lt;SOFA:Channel/\u0026amp;gt; 有趣实用的分布式架构频道，前沿技术、直播 Coding、观点“抬杠”，多种形式。\n\u0026amp;lt;SOFA:Channel/\u0026amp;gt; 将作为 SOFA 所有在线内容的承载，包含直播/音视频教程，集中体现 SOFAStack 的能力全景图。\n| SOFAChannel#15：分布式链路组件 SOFATracer 埋点机制解析 SOFATracer 是蚂蚁金服开源的基于 OpenTracing 规范 的分布式链路跟踪系统，其核心理念就是通过一个全局的 TraceId 将分布在各个服务节点上的同一次请求串联起来。通过统一的 TraceId 将调用链路中的各种网络调用情况以日志的方式记录下来同时也提供远程汇报到 Zipkin 进行展示的能力，以此达到透视化网络调用的目的。\n| 加入 SOFA 钉钉互动群 欢迎加入直播互动钉钉群：30315793（搜索群号加入即可）\n| 点击即可报名 https://tech.antfin.com/community/live/1167\n议程 19:00-19:05 主持人开场 SOFAGirl 主持人\n19:05-20:00 分布式链路组件 SOFATracer 埋点机制解析 卫恒 SOFATracer 开源负责人\n你将收获  带你快速上手 SOFATracer； SOFATracer 功能点详细介绍； SOFATracer 埋点机制原理详解；  嘉宾  SOFAGirl 主持人 卫恒 SOFATracer 开源负责人  ","date":1587114000,"description":"4 月 23 日周四晚 7 点，线上直播第 15 期。","dir":"activities/sofa-channel-15/","fuzzywordcount":500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"e1323556a7e34b0937a8d3c1f6815a77","permalink":"/activities/sofa-channel-15/","publishdate":"2020-04-17T17:00:00+08:00","readingtime":1,"relpermalink":"/activities/sofa-channel-15/","summary":"概要 活动主题：SOFAChannel#15：分布式链路组件 SOFATracer 埋点机制解析 活动时间：4 月 23 日周四晚 7 点 活动形式：线上直播 直播回顾：戳这里 介绍 |","tags":["SOFAChannel","SOFATracer"],"title":"SOFAChannel#15：分布式链路组件 SOFATracer 埋点机制解析","type":"activities","url":"/activities/sofa-channel-15/","wordcount":442},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@杨俊 提问：\n AT 模式下，当 seata-server 挂掉之后，有未完成的全局事务还在 undo_log 表中，这里有两个问题问一下：\n seata-server 再次重启后，之前未完成的全局事务偶尔会出现回滚失败的问题，就是一直重试，但始终回滚失败，这个问题如何解决？ seata-server 再次重启后，大多数情况下会成功回滚，但是等待时间过长，感觉要至少3-5分钟才会回滚，这期间涉及到的相关业务服务无法处理其他请求，直至之前的未完成全局事务成功回滚了，才能处理其他请求，请问这个问题如何解决，还有回滚时间在哪里配置能够缩短？ ※上述两个问题都是基于 seata-sample 产生的。   A：1. 要确认下客户端日志中回滚失败的原因，重启后会恢复重启前未完成的事务。一般是出现脏写数据了，需要人工订正。如果单纯跳过可以删除 server 或 undo_log 对应记录。 2. server.recovery.rollbackingRetryPeriod , 是不是重启前未完成事务过多？\n 好的，谢谢。\n seata-sample 中三个服务，Account、Order 回滚成功，Storage 回滚失败，然后 seata-server 就一直反复重试，seata 和 storage 及其他服务重启也无用，然后手工将日志删除，依然不停重试，最后重启 seata 服务，系统把删掉的日志又给重写到日志表了，但是 log_status 为1，至此不再重试，但是事务未能成功回滚。 重启未完成的事务只有那么三个而已，并不多。   A：问题1，你还是要看下回滚失败的原因，客户端日志会打印。 问题2，你提个 issue ，我们排查下。\n2、@吕布 提问：\n 请教一下, AT 下分支事务提交后释放资源, 虽然资源释放了, 但别的事务操作它时还是被全局锁了, 这种释放的好处体现在哪些方面？  A：即使你数据库本地事务也是排队执行的，全局锁是 AT 模式的排队机制，所以如果是相同数据主键的这个与连接无关。释放连接是因为数据库连接资源是宝贵的，不会因为连接池连接数不够导致的其他数据无关的事务得不到执行，从更大的层面认为是一定程度提高了吞吐。\n 明白了，一方面就是说提高吞吐, 然后一方面是避免本地事务的间隙锁和表锁, 导致其他不相关数据被锁, 可以说锁粒度变小了。谢谢。\n Seata：https://github.com/seata/seata\nSOFATracerLab 系列阅读  蚂蚁金服分布式链路跟踪组件 SOFATracer 总览 | 剖析 蚂蚁金服分布式链路跟踪组件 SOFATracer 数据上报机制和源码分析 | 剖析 蚂蚁金服分布式链路跟踪组件链路透传原理与SLF4J MDC的扩展能力分析 | 剖析 蚂蚁金服分布式链路跟踪组件采样策略和源码 | 剖析 蚂蚁金服分布式链路跟踪组件埋点机制 | 剖析  SOFA 项目进展 本周发布详情如下：\n发布 SOFAJRaft v1.3.1 版本，主要变更如下：\n multi raft group 之间共享 timer 和 scheduler 等较重的线程资源，优化 multi group 场景中的多余资源占用； 提供 RPC adapter，用户可基于 SPI 扩展不同的 RPC 实现； 正式提供稳定的 RocksDBSegmentLogStorage，适合 value 较大的数据存储； SOFABolt 升级到 1.6.1，支持 SSL 以及具有更好的小数据包传输能力； 引入一个新的数据结构 segment list 来解决 LogManager 中过多的 log memory copy； 采纳 nacos 建议，对 raft Task 增加 join API； 修复 learner 启动晚于 leader 选举成功时无法复制日志的 bug； 致谢（排名不分先后）  @jovany-wang 、@SteNicholas 、@zongtanghu 、@OpenOpened\n详细发布报告：https://github.com/sofastack/sofa-jraft/issues/420\n社区直播报名 SOFATracer 是蚂蚁金服开源的基于 OpenTracing 规范 的分布式链路跟踪系统，其核心理念就是通过一个全局的 TraceId 将分布在各个服务节点上的同一次请求串联起来。通过统一的 TraceId 将调用链路中的各种网络调用情况以日志的方式记录下来同时也提供远程汇报到 Zipkin 进行展示的能力，以此达到透视化网络调用的目的。\n本期直播将通过具体 Demo 带你快速上手 SOFATracer，同时将介绍 SOFATracer 具体功能，并详细介绍其核心关键「埋点机制」的原理。\n 主题：SOFAChannel#15：分布式链路组件 SOFATracer 埋点机制解析 时间：2020年4月23日（周四）19:00-20:00 嘉宾：卫恒 SOFATracer 开源负责人 形式：线上直播 报名方式：点击“这里”，即可报名  ","date":1587106800,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20200417/","fuzzywordcount":1900,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"1bb16db78404cb9d09dd18ec48374246","permalink":"/blog/sofa-weekly-20200417/","publishdate":"2020-04-17T15:00:00+08:00","readingtime":4,"relpermalink":"/blog/sofa-weekly-20200417/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | SOFATracer 直播预告、SOFAJRaft 组件发布","type":"blog","url":"/blog/sofa-weekly-20200417/","wordcount":1832},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@熊胜 提问：\n 请教个问题，biz 卸载中的关闭 ApplicationContext 这一步是哪里处理的呢？我在 com.alipay.sofa.ark.container.model.BizModel#stop 方法中没看到相应的实现。\n A： biz stop 会发出一个事件，这个时间会被 runtime 拿到处理，可以看下 sofa-boot runtime 里面有处理 biz 卸载事件的 handler。\nSOFAArk：https://github.com/sofastack/sofa-ark\n2、@揭印泉 提问：\n 请问 registry.conf 中的 registry 作用是向 Seata 服务器注册分支事务？\n A：registry 是注册中心，seata server 和 client 都需要的，server 往注册中心注册服务，client 往注册中心找寻 server 服务。\n seata server 和 client 是共用 nacos-config.sh 脚本跑到 Nacos 配置？ 如果他们都配置了 Nacos。\n A：随你，你也可以分开，配置中心没约束，你可以 server 用 nacos，client 用 file，只要读取到即可。\n 服务器端配置了 store.mode=\u0026amp;ldquo;db\u0026amp;rdquo;, 启动参数需要加参数：-m db ?\n A：可以不加，优先级启动参数\u0026amp;gt;配置。\nSeata：https://github.com/seata/seata\nSOFARegistryLab 系列阅读  服务注册中心如何实现 DataServer 平滑扩缩容 | SOFARegistry 解析 服务注册中心数据一致性方案分析 | SOFARegistry 解析 服务注册中心如何实现秒级服务上下线通知 | SOFARegistry 解析 服务注册中心 Session 存储策略 | SOFARegistry 解析 服务注册中心数据分片和同步方案详解 | SOFARegistry 解析 服务注册中心 MetaServer 功能介绍和实现剖析 | SOFARegistry 解析 服务注册中心 SOFARegistry 解析 | 服务发现优化之路 海量数据下的注册中心 - SOFARegistry 架构介绍  SOFAChannel 线上直播合集  SOFAChannel#14：云原生网络代理 MOSN 扩展机制解析 | SOFAChannel#14 直播整理 SOFAChannel#13：云原生网络代理 MOSN 多协议机制解析 | SOFAChannel#13 直播整理 SOFAChannel#12：蚂蚁金服分布式事务实践解析 | SOFAChannel#12 直播整理 SOFAChannel#11：从一个例子开始体验轻量级类隔离容器 SOFAArk | SOFAChannel#11 直播整理 SOFAChannel#10：Seata 长事务解决方案 Saga 模式 | SOFAChannel#10 回顾 SOFAChannel#9：Service Mesh 落地负责人亲述：蚂蚁金服双十一四大考题 | SOFAChannel#9 回顾 SOFAChannel#8：从一个例子开始体验 SOFAJRaft | SOFAChannel#8 直播整理 SOFAChannel#7：自定义资源 CAFEDeployment 的背景、实现和演进 | SOFAChannel#7 直播整理 SOFAChannel#6：蚂蚁金服轻量级监控分析系统解析 | SOFAChannel#6 直播整理 SOFAChannel#5：给研发工程师的代码质量利器 | SOFAChannel#5 直播整理 SOFAChannel#4：分布式事务 Seata TCC 模式深度解析 | SOFAChannel#4 直播整理 SOFAChannel#3：SOFARPC 性能优化实践（下）| SOFAChannel#3 直播整理 SOFAChannel#2：SOFARPC 性能优化实践（上）| SOFAChannel#2 直播整理 SOFAChannel#1：从蚂蚁金服微服务实践谈起 | SOFAChannel#1 直播整理  SOFA 项目进展 本周发布详情如下：\n发布 SOFATracer v3.0.12 版本，主要变更如下：\n 2个 Dubbo 插件融合, 新的用户请直接使用 sofa-tracer-dubbo-common-plugin； 修复 Dubbo 插件传递错误 spanId 的问题；  详细发布报告： https://github.com/sofastack/sofa-tracer/releases/tag/v3.0.12\n社区直播报名 SOFATracer 是蚂蚁金服开源的基于 OpenTracing 规范 的分布式链路跟踪系统，其核心理念就是通过一个全局的 TraceId 将分布在各个服务节点上的同一次请求串联起来。通过统一的 TraceId 将调用链路中的各种网络调用情况以日志的方式记录下来同时也提供远程汇报到 Zipkin 进行展示的能力，以此达到透视化网络调用的目的。\n本期直播将通过具体 Demo 带你快速上手 SOFATracer，同时将介绍 SOFATracer 具体功能，并详细介绍其核心关键「埋点机制」的原理。\n 主题：SOFAChannel#15：分布式链路组件 SOFATracer 埋点机制解析 时间：2020年4月23日（周四）19:00-20:00 嘉宾：卫恒 SOFATracer 开源负责人 形式：线上直播 报名方式：点击“这里”，即可报名  ","date":1586509200,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20200410/","fuzzywordcount":1800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"9f805804c54d097bea99536c21da6387","permalink":"/blog/sofa-weekly-20200410/","publishdate":"2020-04-10T17:00:00+08:00","readingtime":4,"relpermalink":"/blog/sofa-weekly-20200410/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | SOFATracer 直播预告、SOFARegistry 解析系列合集、线上直播回顾合集","type":"blog","url":"/blog/sofa-weekly-20200410/","wordcount":1705},{"author":"永鹏","categories":"SOFAChannel","content":" SOFA:Channel/，有趣实用的分布式架构频道。 回顾视频以及 PPT 查看地址见文末。欢迎加入直播互动钉钉群 : 21992058，不错过每场直播。\n 本文根据 SOFAChannel#14 直播分享整理，主题：云原生网络代理 MOSN 扩展机制解析。\n大家好，我是今天的讲师永鹏，来自蚂蚁金服，目前主要负责 MOSN 的开发，也是 MOSN 的Committer。今天我为大家分享的是云原生网络代理 MOSN 的扩展机制，希望通过这次分享以后，能让大家了解 MOSN 的可编程扩展能力，可以基于 MOSN 的扩展能力，按照自己实际的业务需求进行二次开发。\n前言 今天我们将从以下几个方面，对 MOSN 的扩展机制进行介绍：\n MOSN 扩展能力和扩展机制的详细介绍； 结合示例对 MOSN 的 Filter 扩展机制与插件扩展机制进行详细介绍； MOSN 后续扩展能力规划与展望；  欢迎大家有兴趣一起共建 MOSN。在本次演讲中涉及到的示例就在我们的 Github 的 examples/codes/mosn-extensions 目录下，大家有兴趣的也可以下载下来运行一下，关于这些示例我们还做了一些小活动，也希望大家可以踊跃参与。\nMOSN：https://github.com/mosn/mosn\nMOSN 简介 MOSN 作为云原生的网络代理，旨在为服务提供多协议、模块化、智能化、安全的代理能力。在实际生产使用中，不同的厂商会有不同的使用场景，通用的网络代理能力面对具体的业务场景会显得有些不足，通常都需要进行二次开发以满足业务需求。MOSN 在核心框架中，提供了一系列的扩展机制和扩展点，就是为了满足需要基于业务进行二次开发的场景，同时 MOSN 提供的部分通用逻辑也是基于扩展机制和扩展点的实现。\n比如通过 MOSN “内置实现”的透明劫持的能力，就是通过 MOSN Filter 机制实现。而要实现消息的代理，则可以通过类似的扩展实现。在通用代理的情况下，可以通过 Filter 机制实现业务的认证鉴权，也可以实现定制的负载均衡逻辑；除了转发流程可以扩展实现以外，MOSN 还可以扩展日志的实现，用于对标已有的日志系统，也可以扩展 XDS 实现定制的配置更新；根据不同的业务场景还会有很多具体的扩展情况，就不在此展开了，有兴趣的可以关注MOSN 社区正在建设的源代码分析系列文章与文档。\nMOSN 作为一款网络代理，在转发链路上的网络层、协议层、转发层，在非转发链路上的配置、日志、Admin API 等都提供了扩展能力，对于协议扩展的部分，有兴趣的可以看一下上期直播讲的 MOSN 多协议机制解析，我们今天将重点介绍一下转发层的 Stream Filter 扩展机制与 MOSN 的插件机制。\nStream Filter 机制 在实际业务场景中，在转发请求之前或者回写响应之前，都可能需要对请求/响应做一些处理，如判断是否需要进行转发的认证/鉴权，是否需要限流，又或者需要对请求/响应做一些具有业务语义的记录，需要对协议进行转换等。这些场景都与具体的业务高度耦合，是一个典型的需要进行二次开发的情况。MOSN 的 Stream Filter 机制就是为了满足这样的扩展场景所设计的，它也成为目前 MOSN 扩展中使用频率最高的扩展点。\n在目前的内置 MOSN 实现中，Stream Filter 机制暂时与内置的 network filter: proxy 是绑定的，后面我们也考虑将这部分能力进行抽象，让其他 network filter 也可以复用这部分能力。\n关于 Stream Filter，今天会为大家讲解两个部分的内容：\n 一个 Stream Filter 包含哪些部分以及在 MOSN 中是如何工作的； 通过一个 Demo 演示来加深对 Stream Filter 的实现与应用；  一个完整的 Stream Filter 一个完整的 StreamFilter，包含三个部分的内容：\n 一个 StreamFilter 对象，存在于每一个请求/响应当中，在 MOSN 收到请求的时候发挥作用，我们称为 ReceiverFilter，在 MOSN 收到响应时发挥作用，我们称为 SenderFilter。一个 StreamFilter 可以是其中任意一种，也可以是两种都是； 一个 StreamFilterFactory 对象，用于 MOSN 在每次收到请求时，生成 StreamFilter 对象。在 Listener 配置解析时，一个 StreamFilter 的配置会生成一个其对于的 StreamFilterFactory。同一个 StreamFilter 在不同的 Listener 下可能对应不同的 StreamFilterFactory，但是也有的特殊情况下，StreamFilterFactory 可能需要实现为单例； 一个 CreateStreamFilterFactory 方法，配置解析时生成 StreamFilterFactory 就是调用它；  Stream Filter 在 MOSN 中是如何工作的 接下来，我们看下 Stream Filter 在 MOSN 中是如何工作的。\n当 MOSN 经过协议解析，收到一个完整的请求时，会创建一个 Stream。此时收到请求的 Listener 中每存在 StreamFilterFactory，就会生成一个 StreamFilter 对象，随后进入到 proxy 流程。\n进入 proxy 流程以后，如果存在 ReceiverFilter，那么就会执行对应的逻辑，ReceiverFilter 包括两个阶段，“路由前”和“路由后”，在每个 Filter 处理完成以后，会返回一个状态，如果是 Stop 则会中止后续尚未执行的 ReceiverFilter，通常情况下，返回 Stop 状态的 Filter 都会回写一个响应。如果是 Continue 则会执行下一个 ReceiverFilter，直到本阶段的 ReceiverFilter 都执行完成或中止；路由前阶段的 ReceiverFIlter 执行完成后，就会执行路由后阶段，其逻辑和路由前一致。如果是正常转发，那么随后 MOSN 会收到一个响应或者发现其他异常直接回写一个响应，此时就会进入到 SenderFilter 的流程中，完成 SenderFilter 的处理。SenderFilter 处理完成以后，MOSN 会写响应给 Client，并且完成最后的收尾工作，收尾工作包括一些数据的回收、日志的记录，以及 StreamFilter 的“销毁”（调用 OnDestroy）。\nStream Filter Demo 对 Stream Filter 有了一个基本的认识以后，我们来看一个实际的 Demo 代码来看下如何实现一个 StreamFilter 并且让它在 MOSN 中发挥作用。\n按照刚才我们的介绍，一个 StreamFIlter 要包含三部分：Filter、Factory、CreateFactory。\n 首先我们实现一个 Filter，其逻辑是模拟一个鉴权的 Filter：只有请求的 Header 中包含 …","date":1586437200,"description":"本文根据 SOFAChannel#14 直播分享整理，主题：云原生网络代理 MOSN 扩展机制解析。","dir":"blog/sofa-channel-14-retrospect/","fuzzywordcount":6200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"54f04c153ed4827819de6a6716ad46e2","permalink":"/blog/sofa-channel-14-retrospect/","publishdate":"2020-04-09T21:00:00+08:00","readingtime":13,"relpermalink":"/blog/sofa-channel-14-retrospect/","summary":"SOFA:Channel/，有趣实用的分布式架构频道。 回顾视频以及 PPT 查看地址见文末。欢迎加入直播互动钉钉群 : 21992058，不错过每场直播","tags":["SOFAChannel","MOSN","Service Mesh"],"title":"云原生网络代理 MOSN 扩展机制解析 | SOFAChannel#14 直播整理","type":"blog","url":"/blog/sofa-channel-14-retrospect/","wordcount":6139},{"author":"404P","categories":"SOFARegistry ","content":" SOFAStack（Scalable Open Financial Architecture Stack ）是蚂蚁金服自主研发的金融级云原生架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。  SOFARegistry 是蚂蚁金服开源的具有承载海量服务注册和订阅能力的、高可用的服务注册中心，最早源自于淘宝的初版 ConfigServer，在支付宝/蚂蚁金服的业务发展驱动下，近十年间已经演进至第五代。\n本文为《剖析 | SOFARegistry 框架》最后一篇，本篇作者404P(花名岩途)。《剖析 | SOFARegistry 框架》系列由 SOFA 团队和源码爱好者们出品，项目代号：SOFA:RegistryLab/，文末包含往期系列文章。\nGitHub 地址：https://github.com/sofastack/sofa-registry\n前言 在微服务架构体系下，服务注册中心致力于解决微服务之间服务发现的问题。在服务数量不多的情况下，服务注册中心集群中每台机器都保存着全量的服务数据，但随着蚂蚁金服海量服务的出现，单机已无法存储所有的服务数据，数据分片成为了必然的选择。数据分片之后，每台机器只保存一部分服务数据，节点上下线就容易造成数据波动，很容易影响应用的正常运行。本文通过介绍 SOFARegistry 的分片算法和相关的核心源码来展示蚂蚁金服是如何解决上述问题的。~~\n服务注册中心简介 在微服务架构下，一个互联网应用的服务端背后往往存在大量服务间的相互调用。例如服务 A 在链路上依赖于服务 B，那么在业务发生时，服务 A 需要知道服务 B 的地址，才能完成服务调用。而分布式架构下，每个服务往往都是集群部署的，集群中的机器也是经常变化的，所以服务 B 的地址不是固定不变的。如果要保证业务的可靠性，服务调用者则需要感知被调用服务的地址变化。\n图1 微服务架构下的服务寻址\n既然成千上万的服务调用者都要感知这样的变化，那这种感知能力便下沉成为微服务中一种固定的架构模式：服务注册中心。\n图2 服务注册中心\n服务注册中心里，有服务提供者和服务消费者两种重要的角色，服务调用方是消费者，服务被调方是提供者。对于同一台机器，往往兼具两者角色，既被其它服务调用，也调用其它服务。服务提供者将自身提供的服务信息发布到服务注册中心，服务消费者通过订阅的方式感知所依赖服务的信息是否发生变化。\nSOFARegistry 总体架构 SOFARegistry 的架构中包括4种角色：Client、Session、Data、Meta，如图3所示：\n图3 SOFARegistry 总体架构\n Client 层  应用服务器集群。Client 层是应用层，每个应用系统通过依赖注册中心相关的客户端 jar 包，通过编程方式来使用服务注册中心的服务发布和服务订阅能力。\n Session 层  Session 服务器集群。顾名思义，Session 层是会话层，通过长连接和 Client 层的应用服务器保持通讯，负责接收 Client 的服务发布和服务订阅请求。该层只在内存中保存各个服务的发布订阅关系，对于具体的服务信息，只在 Client 层和 Data 层之间透传转发。Session 层是无状态的，可以随着 Client 层应用规模的增长而扩容。\n Data 层  数据服务器集群。Data 层通过分片存储的方式保存着所用应用的服务注册数据。数据按照 dataInfoId（每一份服务数据的唯一标识）进行一致性 Hash 分片，多副本备份，保证数据的高可用。下文的重点也在于随着数据规模的增长，Data 层如何在不影响业务的前提下实现平滑的扩缩容。\n Meta 层  元数据服务器集群。这个集群管辖的范围是 Session 服务器集群和 Data 服务器集群的服务器信息，其角色就相当于 SOFARegistry 架构内部的服务注册中心，只不过 SOFARegistry 作为服务注册中心是服务于广大应用服务层，而 Meta 集群是服务于 SOFARegistry 内部的 Session 集群和 Data 集群，Meta 层能够感知到 Session 节点和 Data 节点的变化，并通知集群的其它节点。\nSOFARegistry 如何突破单机存储瓶颈 在蚂蚁金服的业务规模下，单台服务器已经无法存储所有的服务注册数据，SOFARegistry 采用了数据分片的方案，每台机器只保存一部分数据，同时每台机器有多副本备份，这样理论上可以无限扩容。根据不同的数据路由方式，常见的数据分片主要分为两大类：范围分片和 Hash（哈希）分片。\n图4 数据分片\n 范围分片  每一个数据分片负责存储某一键值区间范围的值。例如按照时间段进行分区，每个小时的 Key 放在对应的节点上。区间范围分片的优势在于数据分片具有连续性，可以实现区间范围查询，但是缺点在于没有对数据进行随机打散，容易存在热点数据问题。\n Hash （哈希）分片  Hash 分片则是通过特定的 Hash 函数将数据随机均匀地分散在各个节点中，不支持范围查询，只支持点查询，即根据某个数据的 Key 获取数据的内容。业界大多 KV（Key-Value）存储系统都支持这种方式，包括 cassandra、dynamo、membase 等。业界常见的 Hash 分片算法有哈希取模法、一致性哈希法和虚拟桶法。\n哈希取模 哈希取模的 Hash 函数如下：\nH(Key) = hash(key) mod K; 这是一个 key-machine 的函数。key 是数据主键，K 是物理机数量，通过数据的 key 能够直接路由到物理机器。当 K 发生变化时，会影响全体数据分布。所有节点上的数据会被重新分布，这个过程是难以在系统无感知的情况下平滑完成的。\n图5 哈希取模\n一致性哈希 分布式哈希表（DHT）是 P2P 网络和分布式存储中一项常见的技术，是哈希表的分布式扩展，即在每台机器存储部分数据的前提下，如何通过哈希的方式来对数据进行读写路由。其核心在于每个节点不仅只保存一部分数据，而且也只维护一部分路由，从而实现 P2P 网络节点去中心化的分布式寻址和分布式存储。DHT 是一个技术概念，其中业界最常见的一种实现方式就是一致性哈希的 Chord 算法实现。\n 哈希空间  一致性哈希中的哈希空间是一个数据和节点共用的一个逻辑环形空间，数据和机器通过各自的 Hash 算法得出各自在哈希空间的位置。\n图6 数据项和数据节点共用哈希空间\n图7是一个二进制长度为5的哈希空间，该空间可以表达的数值范围是0～31（2^5），是一个首尾相接的环状序列。环上的大圈表示不同的机器节点（一般是虚拟节点），用 $$Ni$$ 来表示，$$i$$ 代表着节点在哈希空间的位置。例如，某个节点根据 IP 地址和端口号进行哈希计算后得出的值是7，那么 N7 则代表则该节点在哈希空间中的位置。由于每个物理机的配置不一样，通常配置高的物理节点会虚拟成环上的多个节点。\n图7 长度为5的哈希空间\n环上的节点把哈希空间分成多个区间，每个节点负责存储其中一个区间的数据。例如 N14 节点负责存储 Hash 值为8～14范围内的数 …","date":1586340000,"description":"本文介绍 SOFARegistry 分片算法和相关核心源码来展示蚂蚁金服是如何解决数据分片带来的节点上下线数据波动的问题。","dir":"blog/sofa-registry-dataserver-smooth-expansion-contraction/","fuzzywordcount":6200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"35c77b7278ad2675b56540b1f97ecf8f","permalink":"/blog/sofa-registry-dataserver-smooth-expansion-contraction/","publishdate":"2020-04-08T18:00:00+08:00","readingtime":13,"relpermalink":"/blog/sofa-registry-dataserver-smooth-expansion-contraction/","summary":"SOFAStack（Scalable Open Financial Architecture Stack ）是蚂蚁金服自主研发的金融级云原生架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里","tags":["SOFARegistry ","剖析 | SOFARegistry 框架","SOFALab"],"title":"蚂蚁金服服务注册中心如何实现 DataServer 平滑扩缩容 | SOFARegistry 解析","type":"blog","url":"/blog/sofa-registry-dataserver-smooth-expansion-contraction/","wordcount":6179},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@王磊 提问：\n SOFARPC 注册的 Dubbo 服务和通过 Dubbo 组件注册的服务可以互通的吧？\n A：可以的， Dubbo 是桥接模式。\n 这个怎么配置的。现在注册的 Dubbo 服务 generic=false。  A：现在只支持泛化调用不支持泛化服务，可以关注一下这个 Issue，后期会排期做，也欢迎共建。 https://github.com/sofastack/sofa-rpc/issues/894\nSOFARPC：https://github.com/sofastack/sofa-rpc\n2、@黄振祥 提问：\n 使用 SOFAStack 快速构建微服务的 Demo 时遇到的一些问题，可以怎么解决呢？ https://github.com/sofastack-guides/kc-sofastack-demo\n A：可以详细看一下这个 issue： https://github.com/sofastack-guides/kc-sofastack-demo/issues/9\n3、@哈哈哈 提问：\n  AT 和 Saga 有什么区别吗，AT 我感觉是自动的 Saga。\n  A：也可以这么说，Saga 框架上没有加锁，AT 有加锁，事实上 Seata Saga 是一个具备“服务编排”和“Saga 分布式事务”能力的产品。\n**4、@全 **提问：\n 麻烦问一下，Seata TCC 只支持 Dubbo、SOFARPC 吗？\n A：还有 local，其他的 rpc 框架可以基于 local 包装一下或者扩展下 parser，也欢迎大家贡献。\n 如果通过 spring-cloud 整合的话需要扩展这个 Parser 是吧？\n A：是的，但是像 resttemplate 这种 rest 请求没办法走 parser，需要你 local 包一下。 Seata：https://github.com/seata/seata\nService Mesh 大规模落地系列  蚂蚁金服 Service Mesh 大规模落地系列 - 质量篇 蚂蚁金服 Service Mesh 大规模落地系列 - 控制面篇 蚂蚁金服 Service Mesh 大规模落地系列 - Operator 篇 蚂蚁金服 Service Mesh 大规模落地系列 - 网关篇 蚂蚁金服 Service Mesh 大规模落地系列 - RPC 篇 蚂蚁金服 Service Mesh 大规模落地系列 - 运维篇 蚂蚁金服 Service Mesh 大规模落地系列 - 消息篇 蚂蚁金服 Service Mesh 大规模落地系列 - 核心篇 Service Mesh 落地负责人亲述：蚂蚁金服双十一四大考题  SOFA 项目进展 本周发布详情如下：\n发布 SOFA MOSN v0.11.0 版本，主要变更如下：\n 重构 XProtocol Engine，优化了协议层的实现； 支持 Listener Filter 的扩展，基于 Listener Filter 重新实现了透明劫持能力； 优化了 LDS 接口，修改了路由配置结构，完善了变量机制； 完善了 TraceLog 的实现； Bug Fix；  详细发布报告： https://github.com/sofastack/sofa-mosn/releases/tag/v0.11.0\n社区直播报名 MOSN 是一款使用 Go 语言开发的网络代理软件，由蚂蚁金服开源并经过几十万容器的生产级验证。\nMOSN 作为云原生的网络数据平面，旨在为服务提供多协议，模块化，智能化，安全的代理能力。在实际的生产使用场景中，通用的网络代理总会与实际业务定制需求存在差异，MOSN 提供了一系列可编程的扩展机制，就是为了解决这种场景。\n本次分享将向大家介绍 MOSN 的扩展机制解析以及一些扩展实践的案例。\n本期直播包含 Demo，可以先下载 Demo，提前体验 MOSN 拓展机制的使用（报名页面有详细 Demo 链接）。\n 主题：SOFAChannel#14：云原生网络代理 MOSN 的扩展机制解析 时间：2020年4月9日（下周四）19:00-20:00 嘉宾：永鹏 蚂蚁金服高级开发工程师、MOSN Committer 形式：线上直播 报名方式：点击“这里”，即可报名  ","date":1585908000,"description":"【03/30-04/03】| 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20200403/","fuzzywordcount":1400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"e109585632269dffffd2819dd121da2b","permalink":"/blog/sofa-weekly-20200403/","publishdate":"2020-04-03T18:00:00+08:00","readingtime":3,"relpermalink":"/blog/sofa-weekly-20200403/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | MOSN 直播预告 \u0026 发布更新、Service Mesh 落地实践解析合辑","type":"blog","url":"/blog/sofa-weekly-20200403/","wordcount":1380},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动\n我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@John Deng 提问：\n 现在 MOSN 对 Dubbo 协议支持怎样？\n A：这儿，协议支持了：https://github.com/mosn/mosn/tree/master/pkg/protocol/xprotocol/dubbo 完整的支持，我们已经创建了 Dubbo WG 专门来做这个事情，https://github.com/mosn/community/blob/master/wg-dubbo.md\n 已经生产就绪了吗？\n A：如果是 Dubbo 的话，目前还没有生产可用，主要是相关生态还没对齐，我们正在推进 Dubbo WG kick off，有兴趣可以加入一起完善。 如果指 MOSN 的话，我们去年双11已经线上部署几十万容器，生产可用。 MOSN：https://github.com/mosn/mosn\n2、@Liang 提问：\n SOFAJRaft 的 Leader 节点执行完状态机，把这次的 index 提交之后，什么时候通知的 Follower 节点也提交呢？ 我看现象是 Follower 也立刻跟着提交了，但是这块代码没有找到。想问下具体是怎么实现的，谢谢~\n A：Leader 会往 Follower 发送 lastCommittedIndex， 详情见：\ncom.alipay.sofa.jraft.core.NodeImpl#handleAppendEntriesRequest com.alipay.sofa.jraft.core.BallotBox#setLastCommittedIndex SOFAJRaft：https://github.com/sofastack/sofa-jraft\n3、@琦玉 提问：\n 这种情况下，状态机怎么确定是执行回滚，还是执行重试呢？  A：这个是由开发者决定的。 Server 事务恢复的逻辑是：\n 当提交失败时，重试提交； 补偿失败时，重试补偿； 如果超时默认是进行重试补偿，如果配置了这个\u0026amp;quot;RecoverStrategy\u0026amp;quot;: \u0026amp;ldquo;Forward\u0026amp;quot;则进行重试向前执行；  这个\u0026amp;quot;RecoverStrategy\u0026amp;rdquo;: \u0026amp;ldquo;Forward\u0026amp;quot;配置是告诉状态机默认的事务恢复策略。如果发现这条事务无法向前，也可以通过手动调状态机“补偿”。\n 这种是否最终成功可能有其它业务上的条件，比如取决于另外一个步骤的成功与否。没法在状态语言里面定义。如果 A 充值成功，事务失败，B 就不能回退，必须重试到最终成功。如果 A 充值失败，事务失败，B 就可以回退。这种具体是要怎么去处理呢？分布式事务内先给用户 A 充值, 然后给用户 B 扣减余额, 如果在给 A 用户充值成功, 在事务提交以前, A 用户把余额消费掉了, 如果事务发生回滚, 这时则没有办法进行补偿了\n A：不允许这样设计，业务流水，必须先扣，再充，必须要遵循“宁可长款，不可短款”的原则。\n 意思是分成两个独立的事务，Saga 模式中不定义在同一个状态机流程里？先把B的扣钱流程执行完，再去执行 A 的充值流程 ？\n A：不是，是在同一个事务里，同一个流程，要先进行扣 B 的款，再给 A 充值，那和如果充值失败，可以回滚 B。\n 假如同时给 B 和 C 充值呢？\n A：那就都向前重试，因为充钱业务上不会失败。\n 如果做重试的话，是不是整个流程其它做回退的动作都要在充值动作之前完成?在重试动作之后的动作都只能做重试?\n A：也不是完全只能这样，要根据业务场景来吧。做一个合理的流程设计。 相关阅读：Seata 长事务解决方案 Saga 模式 | SOFAChannel#10 回顾 Seata：https://github.com/seata/seata\n本周推荐阅读  Service Mesh 通用数据平面 API（UDPA）最新进展深度介绍 云原生网络代理 MOSN 多协议机制解析 | SOFAChannel#13 直播整理  SOFA 项目进展 本周发布详情如下：\n发布 SOFARegistry v5.4.2 版本，主要变更如下：\n 修复 cloud 模式推送时客户端 cell 设置错误的问题；  详细发布报告： https://github.com/sofastack/sofa-registry/releases/tag/v5.4.2\n社区直播报名 MOSN 是一款使用 Go 语言开发的网络代理软件，由蚂蚁金服开源并经过几十万容器的生产级验证。\nMOSN 作为云原生的网络数据平面，旨在为服务提供多协议，模块化，智能化，安全的代理能力。在实际的生产使用场景中，通用的网络代理总会与实际业务定制需求存在差异，MOSN 提供了一系列可编程的扩展机制，就是为了解决这种场景。\n本次分享将向大家介绍 MOSN 的扩展机制解析以及一些扩展实践的案例。\n本期直播包含 Demo，可以先下载 Demo，提前体验 MOSN 拓展机制的使用（报名页面有详细 Demo 链接）。\n 主题：SOFAChannel#14：云原生网络代理 MOSN 的扩展机制解析 时间：2020年4月9日（周四）19:00-20:00 嘉宾：永鹏 蚂蚁金服高级开发工程师、MOSN Committer 形式：线上直播 报名方式：点击“这里”，即可报名  ","date":1585299600,"description":"【03/23-03/27】 | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-0327/","fuzzywordcount":2000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"0c6b194e66eeb4c95efa4260e279bab7","permalink":"/blog/sofa-weekly-0327/","publishdate":"2020-03-27T17:00:00+08:00","readingtime":4,"relpermalink":"/blog/sofa-weekly-0327/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | MOSN 直播预告、本周直播回顾整理、SOFARegistry 发布","type":"blog","url":"/blog/sofa-weekly-0327/","wordcount":1975},{"author":"潘潘","categories":"SOFAChannel","content":"概要   活动主题：SOFAChannel#14：云原生网络代理 MOSN 的扩展机制解析\n  活动时间：4 月 9 日周四晚 7 点\n  活动形式：线上直播\n  直播回顾：戳这里\n  介绍 | SOFAChannel \u0026amp;lt;SOFA:Channel/\u0026amp;gt; 有趣实用的分布式架构频道，前沿技术、直播 Coding、观点“抬杠”，多种形式。\n\u0026amp;lt;SOFA:Channel/\u0026amp;gt; 将作为 SOFA 所有在线内容的承载，包含直播/音视频教程，集中体现 SOFAStack 的能力全景图。\n| SOFAChannel#14：云原生网络代理 MOSN 的扩展机制解析 MOSN 是一款使用 Go 语言开发的网络代理软件，由蚂蚁金服开源并经过几十万容器的生产级验证。\nMOSN 作为云原生的网络数据平面，旨在为服务提供多协议，模块化，智能化，安全的代理能力。在实际的生产使用场景中，通用的网络代理总会与实际业务定制需求存在差异，MOSN 提供了一系列可编程的扩展机制，就是为了解决这种场景。\n本次分享将向大家介绍 MOSN 的扩展机制解析以及一些扩展实践的案例。\n欢迎先下载 Demo，提前体验 MOSN 拓展机制的使用，成功完成预习作业—— Demo 完整操作的，有机会获得小礼物哟（记得留下完成的证明，获得方式在直播中公布），我们将在直播中公布答案——进行 Demo 的详细演示。PS：在直播中也会发布闯关任务，完成闯关任务也有机会获得小礼物哟～\nDemo：https://github.com/mosn/mosn/tree/master/examples/codes/mosn-extensions\nDemo Readme：https://github.com/mosn/mosn/tree/master/examples/cn_readme/mosn-extensions\n欢迎了解 MOSN：https://github.com/mosn/mosn\n| 针对人群 对云原生、Service Mesh、网络代理有基本了解，想要了解云原生以及对云原生网络代理 MOSN 有二次开发需求的人群\n| 加入 SOFA 钉钉互动群 欢迎加入直播互动钉钉群：21992058（搜索群号加入即可）\n| 点击即可报名 https://tech.antfin.com/community/live/1131\n议程 19:00-19:05 主持人开场 SOFAGirl 主持人\n19:05-20:00 蚂蚁金服分布式事务实践解析 永鹏 蚂蚁金服高级开发工程师， MOSN Committer\n你将收获  快速了解 MOSN 的多种扩展能力 3 个案例，实际体验 MOSN 扩展能力 多案例多形式，使用 MOSN 实现个性化业务需求  嘉宾  SOFAGirl 主持人 永鹏 蚂蚁金服高级开发工程师， MOSN Committer  ","date":1585299600,"description":"4 月 9 日周四晚 7 点，线上直播第 14 期。","dir":"activities/sofa-channel-14/","fuzzywordcount":1000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"0e1d5c0ea19ec82218fbf675b891ee5a","permalink":"/activities/sofa-channel-14/","publishdate":"2020-03-27T17:00:00+08:00","readingtime":2,"relpermalink":"/activities/sofa-channel-14/","summary":"概要 活动主题：SOFAChannel#14：云原生网络代理 MOSN 的扩展机制解析 活动时间：4 月 9 日周四晚 7 点 活动形式：线上直播 直播回顾：戳这里 介绍","tags":["SOFAChannel","MOSN"],"title":"SOFAChannel#14：云原生网络代理 MOSN 的扩展机制解析","type":"activities","url":"/activities/sofa-channel-14/","wordcount":901},{"author":"无钩","categories":"MOSN","content":" SOFA:Channel/，有趣实用的分布式架构频道。 回顾视频以及 PPT 查看地址见文末。欢迎加入直播互动钉钉群 : 21992058，不错过每场直播。 本文根据 SOFAChannel#13 直播分享整理，主题：云原生网络代理 MOSN 多协议机制解析。\n 大家好，我是今天的讲师无钩，目前主要从事蚂蚁金服网络代理相关的研发工作，也是 MOSN 的 Committer。今天要和大家分享的是《云原生网络代理 MOSN 多协议机制解析》，并介绍对应的私有协议快速接入实践案例以及对 MOSN 实现多协议低成本接入的设计进行解读。\n我们将按以下顺序进行介绍：\n 多协议机制产生的背景与实践痛点； 常见的协议扩展思路初探； SOFABolt 协议接入实践；（重点） MOSN 多协议机制设计解读；（重点） 后续规划及展望；  其中第三点「接入实践」是今天分享的重点，希望能给大家就「如何在 MOSN 中快速扩展私有协议接入」有一个具体的感受。另外「MOSN 如何实现多协议框架」也是很多人关心和问题，我们将摘选几个技术功能，对其背后的设计思考进行解读。\nMOSN 简介 云原生网络代理 MOSN 定位是一个全栈的网络代理，支持包括网络接入层(Ingress)、API Gateway、Service Mesh 等场景，目前在蚂蚁金服内部的核心业务集群已经实现全面落地，并经受了 2019 年双十一大促的考验。今天要向大家介绍的是云原生网络代理 MOSN 核心特性之一的多协议扩展机制，目前已经支持了包括 SOFABolt、Dubbo、TARS 等多个协议的快速接入。\nMOSN：https://github.com/mosn\n多协议机制产生的背景与实践痛点 首先介绍一下多协议机制产生的背景。\n前面提到，蚂蚁金服 2019 年双十一核心链路百分之百 Mesh 化，是业界当时已知的最大规模的 Service Mesh 落地，为什么我们敢这么做？因为我们具备能够让架构平滑迁移的方案。\u0026amp;ldquo;兼容性\u0026amp;quot;是任何架构演进升级都必然要面对的一个问题，这在早已实践微服务化架构的蚂蚁金服内部同样如此。为了实现架构的平滑迁移，需要让新老节点的外在行为尽可能的表现一致，从而让依赖方无感知，这其中很重要的一点就是保持协议兼容性。\n因此，我们需要在 Service Mesh 架构下，兼容现有微服务体系中的通信协议——也就是说需要在 MOSN 内实现对目前蚂蚁金服内部通信协议的扩展支持。\n基于 MOSN 本身的扩展机制，我们完成了最初版本的协议扩展接入。但是在实践过程中，我们发现这并不是一件容易的事情：\n 相比编解码，协议自身的处理以及与框架集成才是其中最困难的环节，需要理解并实现包括请求生命周期、多路复用处理、链接池等等机制； 社区主流的 xDS 路由配置是面向 HTTP 协议的，无法直接支持私有协议，存在适配成本；  基于这些实践痛点，我们设计了 MOSN 多协议框架，希望可以降低私有协议的接入成本，加快普及 ServiceMesh 架构的落地推进。\n常见的协议扩展思路初探 前面介绍了背景，那么具体协议扩展框架要怎么设计呢？我们先来看一下业界的思路与做法。\n协议扩展框架 - Envoy 注：图片来自 Envoy 分享资料\n第一个要介绍的是目前发展势头强劲的 Envoy。从图上可以看出，Envoy 支持四层的读写过滤器扩展、基于 HTTP 的七层读写过滤器扩展以及对应的 Router/Upstream 实现。如果想要基于 Envoy 的扩展框架实现 L7 协议接入，目前的普遍做法是基于 L4 filter 封装相应的 L7 codec，在此基础之上再实现对应的协议路由等能力，无法复用 HTTP L7 的扩展框架。 协议扩展框架 - Nginx 第二个则是老牌的反向代理软件 Nginx，其核心模块是基于 Epoll/Kqueue 等 I/O 多路复用技术之上的离散事件框架，基于事件框架之上构建了 Mail、Http 等协议模块。与 Envoy 类似，如果要基于 Nginx 扩展私有协议，那么也需要自行对接事件框架，并完整实现包括编解码、协议处理等能力。\n协议扩展框架 - MOSN 最后回过头来，我们看一下 MOSN 是怎么做的。实际上，MOSN 的底层机制与 Envoy、Nginx 并没有核心差异，同样支持基于 I/O 多路复用的 L4 读写过滤器扩展，并在此基础之上再封装 L7 的处理。但是与前两者不同的是，MOSN 针对典型的微服务通信场景，抽象出了一套适用于基于多路复用 RPC 协议的扩展框架，屏蔽了 MOSN 内部复杂的协议处理及框架流程，开发者只需要关注协议本身，并实现对应的框架接口能力即可实现快速接入扩展。\n三种框架成本对比 最后对比一下，典型微服务通信框架协议接入的成本，由于 MOSN 针对此类场景进行了框架层面的封装支持，因此可以节省开发者大量的研发成本。\nSOFABolt 协议接入实践 初步了解多协议框架的设计思路之后，让我们以 SOFABolt 协议为例来实际体验一下协议接入的过程。\nSOFABolt 简介 这里先对 SOFABolt 进行一个简单介绍，SOFABolt 是一个开源的轻量、易用、高性能、易扩展的 RPC 通信框架，广泛应用于蚂蚁金服内部。\nSOFABolt：https://github.com/sofastack/sofa-bolt\n基于 MOSN 的多协议框架，实际编写了 7 个代码文件，一共 925 行代码(包括 liscence、comment 在内)就完成了接入。如果对于协议本身较为熟悉，且具备一定的 MOSN/Golang 开发经验，甚至可以在一天内就完成整个协议的扩展，可以说接入成本是非常之低。\nGithub: https://github.com/mosn/mosn/tree/master/pkg/protocol/xprotocol/bolt\n下面让我们进入正题，一步一步了解接入过程。\nStep1：确认协议格式 第一步，需要确认要接入的协议格式。为什么首先要做这个，因为协议格式是一个协议最基本的部分，有以下两个层面的考虑：\n 任何协议特性以及协议功能都能在上面得到一些体现，例如有无 requestId/streamId 就直接关联到协议是否支持连接多路复用； 协议格式与报文模型直接相关，两者可以构成逻辑上的映射关系；而这个映射关系也就是所谓的编解码逻辑；  以 SOFABolt 为例，其第一个字节是协议 magic，可以用于校验当前报文是否属于 SOFABolt 协议，并可以用于协议自动识别匹配的场景；第二个字节是 type，用于标识当前报文的传输类型，可以是 Request / RequestOneway / Response 中的一种；第三个字节则是当前报文的业务类型，可以是心跳帧，RPC 请求/响应等类型。后面的字段就不一一介绍了，可以发现，**理解了协议格式本身，其实对于协议的特性支持和模型编解码就理解了一大半，**因此第一步协议格式的确认了解是重中之重，是后续一切工作开展的前提。\nStep2：确认报文模型 顺应第一步，第二步的主要工作是确认报文编程模型。一般地， …","date":1585227600,"description":"本文根据昨晚直播整理，主要分享云原生网络代理 MOSN 多协议机制解析，并介绍对应私有协议快速接入实践案例以及对其实现多协议低成本接入的设计进行解读。","dir":"blog/sofa-channel-13-retrospect/","fuzzywordcount":6600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"683f36d11af9e48e910e694bf1a119fc","permalink":"/blog/sofa-channel-13-retrospect/","publishdate":"2020-03-26T21:00:00+08:00","readingtime":14,"relpermalink":"/blog/sofa-channel-13-retrospect/","summary":"SOFA:Channel/，有趣实用的分布式架构频道。 回顾视频以及 PPT 查看地址见文末。欢迎加入直播互动钉钉群 : 21992058，不错过每场直播","tags":["MOSN","Service Mesh","SOFAChannel"],"title":"云原生网络代理 MOSN 多协议机制解析 | SOFAChannel#13 直播整理","type":"blog","url":"/blog/sofa-channel-13-retrospect/","wordcount":6526},{"author":"敖小剑","categories":"Service Mesh","content":"在2019年5月，CNCF 筹建通用数据平面 API 工作组（Universal Data Plane API Working Group / UDPA-WG)，以制定数据平面的标准 API。\n当时我写了一个博客文章 “CNCF 正在筹建通用数据平面 API 工作组，以制定数据平面的标准 API” 对此进行了介绍。当时 UDPA 还处于非常早期的筹备阶段，信息非常的少。\n现在9个月过去了，我最近收集并整理了一下 UDPA 目前的情况和信息，给大家介绍一下 UDPA 目前最新的进展（截止2020年2月24日）。\n另外蚂蚁金服开源的云原生网络代理 MOSN 目前已经支持 xDS v2 API，后面也会逐步向着 UDPA 的方向去演进，兼容标准 Istio，感兴趣的读者可以去了解下。\nMOSN：https://github.com/mosn/mon\nUDPA 介绍 首先快速介绍一下什么是 UDPA：\n UDPA ：“Universal Data Plane API”的缩写， “通用数据平面 API” UDPA-WG：”Universal Data Plane API Working Group”的缩写，这是 CNCF 下的一个工作组，负责制定 UDPA；  UDPA 的目标，援引自 https://github.com/cncf/udpa 的描述：\n 通用数据平面 API 工作组（UDPA-WG）的目标是召集对数据平面代理和负载均衡器的通用控制和配置 API 感兴趣的业界人士。\n UDPA 的愿景，同样援引：\n 通用数据平面 API（UDPA）的愿景在 https://blog.envoyproxy.io/the-universal-data-plane-api-d15cec7a 中阐明。我们将寻求一组 API，它们为 L4/L7 数据平面配置提供事实上的标准，类似于 SDN 中 L2/L3/L4 的 OpenFlow 所扮演的角色。 这些 API 将在 proto3 中规范定义，并通过定义良好的、稳定 API 版本控制策略，从现有的 Envoy xDS API 逐步演进。API 将涵盖服务发现、负载均衡分配、路由发现、监听器配置、安全发现、负载报告、运行状况检查委托等。 我们将对 API 进行改进和成型，以支持客户端 lookaside 负载均衡（例如 gRPC-LB），Envoy 之外的数据平面代理，硬件 LB，移动客户端以及其他范围。我们将努力尽可能与供应商和实现无关，同时坚持支持已投入生产的 UDPA 的项目（到目前为止，Envoy 和 gRPC-LB）。\n 对 UDPA 感兴趣的同学，可以通过以下两个途径进一步深入了解：\n UDPA @ GitHub：UDPA 在 github 上的项目，UDPA API 定义的代码都在这里； Universal Data Plane API Working Group (UDPA-WG)：CNCF 的 UDPA 工作组，可以通过加入工作组的方式了解更多信息；  UDPA 和 xDS 的关系 在展开 UDPA 的细节之前，有必要先解释清楚 UDPA 和 xDS 的关系，因为这对理解 UDPA 会有很大帮助。\n在2019年11月的 EnvoyCon 上，Envoy 的开发者，也是目前 UDPA 最主要的负责人之一，来自 Google 的 Harvey Tuch，有一个演讲非常详细而清晰的解答了这个问题，这个演讲的标题是：“The Universal Dataplane API (UDPA): Envoy’s Next Generation APIs”。\n 备注：这里我直接援引这份演讲的部分内容，以下两张图片均出自 [这份演讲的PPT](https://static.sched.com/hosted_files/envoycon2019/ac/EnvoyCon UDPA 2019.pdf) 。鸣谢 Harvey。\n 下图展示了近年来 xDS 协议的演进历程和未来规划：\n 2017年，xDS v2 引入 proto3 和 gRPC，同年 Istio 项目启动； 2018和2019年，xDS v2 API 继续发展，陆续引入了新的 API 定义，如 HDS / LRS / SDS 等，尤其是为了改进 Pilot 下发性能，开始引入增量推送机制； xDS v3 API 原计划于2019年年底推出，但目前看技术推迟，目前 v3 还是 alpha1 状态，预计在即将发布的 Istio 1.5 中会有更多的 v3 API 引入。同时 v3 API 也引入了 UDPA 的部分内容，但是由于 UDPA 目前进展缓慢，对 xDS 的影响并不大，主要还是 xDS 自身的发展，比如对 API 和技术债务的清理； 但在2020年，预计 UDPA 会有很大的进展，尤其是下面我们将会展开的 UDPA-TP 和 UDPA-DM 的设计开始正式制定为 API 之后。而 xDS v4 预计将基于 UDPA ，因此 xDS v4 可能会迎来比较大的变动；  简单总结说：xDS 将逐渐向 UDPA 靠拢，未来将基于 UDPA 。\n下图则展示了 Envoy 在 xDS 版本支持上的时间线：\n目前看这个计划在执行时稍微有一点点延误，原计划于2019年年底推出的 v3 的 stable 版本实际上是在1月中定稿的。（备注：具体可参考 Envoy PR api: freeze v3 API ）。然后目前正在广泛使用的 v2 API 将被标记为 depreated。而且在2020年底，v3 API 预计被 v4 API 取代（注意 v4 API 将会是基于 UDPA），而目前我们最熟悉的 v2 API 将计划在2020年底移除，不再支持！\n上图也展示了未来 xDS 协议的大版本演进和更替的方式，总的来说规律是这样：\n 一年一个大版本：2019 v2 -\u0026amp;gt; 2020 v3 -\u0026amp;gt; 2021 v4 -\u0026amp;gt;2022 v5； 每个大版本都要经历 alpha -\u0026amp;gt; stable -\u0026amp;gt; deprecated -\u0026amp;gt; removed 四个阶段，每个阶段历时一年； 稳定后 Envoy 会同时存在三个 API 大版本：正在使用的稳定版本，已经弃用的上一个稳定版本，准备开发的新的下一个大版本（但只会是Alpha）； 发布一个新的 stable 的大版本，就一定会 deprecated 上一个稳定的大版本，同时 remove 更前一个已经 deprecated 的大版本；  所谓 “长江后浪推前浪，前浪死在沙滩上”，又或者说，“江山代有新版出，各领风骚12个月”。\n 备注：Envoy 具体的稳定 API 版本控制策略，可以参见 Envoy 的设计文档 “Stable Envoy API versioning” ，不过这个文档长的有点过分，嫌长的同学可以直接看这个文档的缩减版本 API versioning guidelines。\n UDPA API 进展 言归正传，我们来看一下 UDPA 目前的最新进展。从 https://github.com/cncf/udpa ，可以看到目前 UDPA 中 …","date":1585130400,"description":"本文收集并整理了一下 UDPA 目前的情况和信息，给大家介绍一下 UDPA 目前最新的进展。","dir":"blog/service-mesh-api-udpa-follow-up/","fuzzywordcount":11000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"7293f926580393ddac18da73da056d07","permalink":"/blog/service-mesh-api-udpa-follow-up/","publishdate":"2020-03-25T18:00:00+08:00","readingtime":22,"relpermalink":"/blog/service-mesh-api-udpa-follow-up/","summary":"在2019年5月，CNCF 筹建通用数据平面 API 工作组（Universal Data Plane API Working Group / UDPA-WG)，以制定数据平面的标准 API。 当时我写了一","tags":["Service Mesh"],"title":"Service Mesh 通用数据平面 API（UDPA）最新进展深度介绍","type":"blog","url":"/blog/service-mesh-api-udpa-follow-up/","wordcount":10968},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。 **SOFAStack 官网: **https://www.sofastack.tech **SOFAStack: **https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@木易 提问：\n 请问，这个并发隔离是怎么做到的？二阶段是一阶段的最后去做的对吧，在 TCC 模式下的，RPC 调用二阶段失败了或者 MQ 异步调二阶段失败了，那二阶段失败了可咋整？  A：一阶段如果都成功了，说明所有分支的事务的“资源”已经预留成功了，这时候的失败都是“技术上”的失败比如网络抖动，这时会要重试提交。举个例子，如果二阶段一部份服务 commit 成功了，然后有一个失败了，这时只能重试提交，不能回滚，因为那些二阶段已经成功的服务，不能回滚了。\n 是不是一阶段的发起方还得根据业务编号记录一条 response，然后参与方定时去扫状态未更新的记录，然后根据业务编号去查 response 中的状态再更新自己的状态？\n A：业务流水是肯定要记的。\n 有行锁可用余额肯定没问题，就是这个预扣冻结字段如果放这行数据里，一阶段一释放锁，另一个事务给他改了就不对了，所以我感觉表里加这个字段不行啊，还是得用业务流水加这个预扣字段形成一条记录，这样事务之间的这个才是隔离的 。\n A：是的，是在业务上还要记录一条流水，一来为是业务上的要求，二来可以做幂等和防悬挂控制，三也是在回滚的时候需要这条流水才知道要回滚多少金额。\n相关阅读：蚂蚁金服分布式事务实践解析 | SOFAChannel#12 直播整理\nSeata：https://github.com/seata/seata\n2、@邓从宝 提问：\n 您好，合并部署是个什么概念？什么时候会用到合并部署？\n A： 就是将原本独立开发的应用部署在一起，比如资源有限要高密度部署的时候，比如两个微服务应用频繁 rpc 交互想要部署到一个进程里提高性能的时候。\n3、@苏东东 提问：\n SOFAJRaft 能不能不通过 rpcserver 注册 GetValueRequestProcessor，我想用自己的 RPC 框架。\n A：暂时不能，请关注这个 pr 合并以后就可以了 https://github.com/sofastack/sofa-jraft/pull/402 详细 issue： https://github.com/sofastack/sofa-jraft/issues/268 SOFAJRaft：https://github.com/sofastack/sofa-jraft\nSOFAArk 解析文章集合  蚂蚁金服轻量级类隔离框架 Maven 打包插件解析 | SOFAArk 源码解析 蚂蚁金服轻量级类隔离框架概述 | SOFAArk 源码解析 从一个例子开始体验轻量级类隔离容器 SOFAArk | SOFAChannel#11 直播整理  SOFATracer 解析文章集合  蚂蚁金服分布式链路跟踪组件 SOFATracer 中 Disruptor 实践（含源码） 蚂蚁金服开源分布式链路跟踪组件 SOFATracer 埋点机制剖析 蚂蚁金服开源分布式链路跟踪组件 SOFATracer 采样策略和源码剖析 蚂蚁金服开源分布式链路跟踪组件 SOFATracer 链路透传原理与SLF4J MDC 的扩展能力剖析 蚂蚁金服分布式链路跟踪组件 SOFATracer 数据上报机制和源码剖析 蚂蚁金服分布式链路跟踪组件 SOFATracer 总览|剖析  社区直播报名 作为云原生网络代理，Service Mesh 是 MOSN 的重要应用场景。随着 Service Mesh 概念的日益推广，大家对这套体系都已经不再陌生，有了较为深入的认知。但是与理论传播相对应的是，生产级别的大规模落地实践案例却并不多见。这其中有多方面的原因，包括社区方案饱受诟病的“大规模场景性能问题”、“配套的运维监控基础设施演进速度跟不上”、“存量服务化体系的兼容方案”等等。\n现实场景中，大部分国内厂商都有一套自研 RPC 的服务化体系，属于「存量服务化体系的兼容方案」中的协议适配问题。为此，MOSN 设计了一套多协议框架，用于降低自研体系的协议适配及接入成本，加速 Service Mesh 的落地普及。SOFAChannel#13，将向大家介绍 MOSN 实现多协议低成本接入的设计思路以及相应的快速接入实践案例。\n 主题：SOFAChannel#13：云原生网络代理 MOSN 的多协议机制解析 时间：2020年3月26日（周四）19:00-20:00 嘉宾：无钩，蚂蚁金服技术专家、MOSN Committer 形式：线上直播 报名方式：点击“这里”，即可报名  欢迎参与投票 MOSN Logo 社区投票，在本期直播结束将公布投票结果，确定最新 Logo。\n 投票方式：回复 issue 你喜欢的方案编号以及原因  ","date":1584691200,"description":"【03/16-03/20】 | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20200320/","fuzzywordcount":1800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"e2add88606de2be4ddcf9c9ac2e4bbef","permalink":"/blog/sofa-weekly-20200320/","publishdate":"2020-03-20T16:00:00+08:00","readingtime":4,"relpermalink":"/blog/sofa-weekly-20200320/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | MOSN 直播预告、SOFAArk\u0026SOFATracer 解析文章合集","type":"blog","url":"/blog/sofa-weekly-20200320/","wordcount":1761},{"author":"盲僧","categories":"SOFAArk","content":" SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级云原生架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。\n 本文为《剖析 | SOFAArk 实现原理》第二篇，本篇作者盲僧，来自 OYO。《剖析 | SOFAArk 实现原理》系列由 SOFA 团队和源码爱好者们出品，项目代号：SOFA:ArkLab/，文末附系列共建列表，目前已完成领取。\n前言 SOFAArk 是 SOFA 团队开源的又一款扛鼎力作，它是一款基于 Java 实现的轻量级类隔离容器，主要提供类隔离和应用（模块）合并部署的能力。\n从 2016 年底开始，蚂蚁金服内部开始拥抱新的轻量级类隔离容器框架-SOFAArk。截止 2019 年底，SOFAArk 已经在蚂蚁金服内部 Serverless 场景下落地实践，并已经有数家企业在生产环境使用 SOFAArk ，包括网易云音乐、挖财、溢米教育等。\n本文主要介绍下 SOFAArk Biz 包的打包插件，帮助大家更好的去理解 Biz 包的结构，也是为系列文章做好铺垫。\nSOFAArk biz 的打包插件是 sofa-ark-maven-plugin ，它可以将普通 Java 工程或者 Spring Boot 工程打包成标准格式的 Ark 包或者 Ark Biz 包，关于 Ark 包和 Ark Biz 包可以参考这里：\n Ark 包：https://www.sofastack.tech/projects/sofa-boot/sofa-ark-ark-jar/ Ark Biz：https://www.sofastack.tech/projects/sofa-boot/sofa-ark-ark-biz/  本文将从如下三个方面进行介绍：先对插件的使用和打包出来的产物做一个简单介绍，然后告诉大家调试插件的方法，最后对整个插件的原理做一个流程图和阐述。\nSOFAArk ：https://github.com/sofastack/sofa-ark\nSOFAArk 插件使用  文中的示例代码可以参考 我的 github\n 插件使用 先将 Spring Boot 的打包插件 spring-boot-maven-plugin 删除或者注释，然后再引入如下插件即可：\n\u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;1.1.1\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;executions\u0026amp;gt; \u0026amp;lt;execution\u0026amp;gt; \u0026amp;lt;goals\u0026amp;gt; \u0026amp;lt;goal\u0026amp;gt;repackage\u0026amp;lt;/goal\u0026amp;gt; \u0026amp;lt;/goals\u0026amp;gt; \u0026amp;lt;/execution\u0026amp;gt; \u0026amp;lt;/executions\u0026amp;gt; \u0026amp;lt;/plugin\u0026amp;gt; 执行 mvn package 命令后，将会打出如下结构的 3 个 jar 包，大家可以自行解压这三个 jar 包，看一看里面的具体内容，下面我们简单分析一下：\ntutorial-sofa-ark-maven-plugin-1.0.0-SNAPSHOT.jar ：它是 maven 插件打出来的原生 jar 包，只包含我们写的代码和 manifest 文件，无特殊意义。\ntutorial-sofa-ark-maven-plugin-1.0.0-SNAPSHOT-ark-biz.jar ：这个 jar 包称之为 Ark Biz 包，因为 SOFAArk 容器是支持运行多个 Ark Biz 的，所以打成这种包是为了和别的项目一起合并部署使用，另外 Ark 包里也包含了这个。\ntutorial-sofa-ark-maven-plugin-1.0.0-SNAPSHOT-ark-executable.jar ：这个 jar 包称之为 Ark 包，从字面上来看它是一个可执行的 jar 包，即意味着它是一个可以用 java-jar 命令来单独运行的 Fat Jar，类似于我们用 Spring Boot 插件打出来的包。\n后面的分析主要是围绕 Ark 包来做讲解，因为它包含了 Ark Biz 包，所以只要搞明白它是如何生成的，那么对整个插件的原理也就基本了解了。\n与 Spring Boot 插件对比 要想分析出 sofa-ark-maven-plugin 插件的作用，我们需要先和 Spring Boot 的插件进行对比，从打包产物上直观的感受一下两者的区别。\nspring-boot-maven-plugin 插件 spring-boot-maven-plugin 是 SpringBoot 默认提供的打包插件，其功能就是将工程打包成一个可执行的 FATJAR。spring-boot-maven-plugin 打包产物的目录结构如下：\n. ├── BOOT-INF │ ├── classes # 应用的字节码目录 │ └── lib # 应用所依赖的 jar 包 ├── META-INF │ ├── MANIFEST.MF # manifest 文件信息 │ └── maven # 应用的坐标信息 └── org └── springframework └── boot └── loader # 存放的是 Spring Boot Loader 的 class 文件 ├── JarLauncher.class # Spring Boot 启动类 ├── archive ├── data ├── jar └── util MANIFEST.MF 文件内容：\nManifest-Version: 1.0 Archiver-Version: Plexus Archiver Built-By: rrz Start-Class: pers.masteryourself.tutorial.sofa.ark.maven.plugin.MavenP luginApplication Spring-Boot-Classes: BOOT-INF/classes/ Spring-Boot-Lib: BOOT-INF/lib/ Spring-Boot-Version: 2.1.4.RELEASE Created-By: Apache Maven 3.5.3 Build-Jdk: 1.8.0_101 Main-Class: org.springframework.boot.loader.JarLauncher MANIFEST.MF 文件中可以看到，描述了当前 jar 的一些核心元素，包括启动类、class 文件路径、lib 依赖路径、jdk 版本等等，这里需要关注的是 Main-Class，SpringBoot 就是通过该类来引导启动的。SOFAArk 应用也提供了类似的引导类及其自身特殊的结构，这主要就依托于 sofa-ark-maven-plugin 来完 …","date":1584612000,"description":"本文主要介绍下 SOFAArk Biz 包的打包插件，帮助大家更好的去理解 Biz 包的结构","dir":"blog/sofa-ark-maven- packaging-plugins/","fuzzywordcount":3400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"dd530d14f20a460c2f49300c0d784c32","permalink":"/blog/sofa-ark-maven-packaging-plugins/","publishdate":"2020-03-19T18:00:00+08:00","readingtime":7,"relpermalink":"/blog/sofa-ark-maven-packaging-plugins/","summary":"SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级云原生架构，包含了构建金融级云原生架构所需的各个组件，是在金","tags":["SOFAArk","SOFAArkLab"],"title":"蚂蚁金服轻量级类隔离框架 Maven 打包插件解析 | SOFAArk 源码解析","type":"blog","url":"/blog/sofa-ark-maven-packaging-plugins/","wordcount":3324},{"author":"卫恒","categories":"SOFATracer","content":" SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级云原生架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。\nSOFATracer 是一个用于分布式系统调用跟踪的组件，通过统一的 TraceId 将调用链路中的各种网络调用情况以日志的方式记录下来，以达到透视化网络调用的目的，这些链路数据可用于故障的快速发现，服务治理等。\nSOFATracer：https://github.com/sofastack/sofa-tracer\n Disruptor 简介 Disruptor 旨在在异步事件处理体系结构中提供低延迟，高吞吐量的工作队列。它确保任何数据仅由一个线程拥有以进行写访问，因此与其他结构相比，减少了写争用。目前，包括 Apache Storm、Camel、Log4j 2 在内的很多知名项目都应用了 Disruptor 以获取高性能。\nSOFATracer 也是基于 Disruptor 高性能无锁循环队列来提供异步打印日志到本地磁盘能力的，SOFATracer 提供两种类似的日志打印类型即摘要日志和统计日志，摘要日志：每一次调用均会落地磁盘的日志；统计日志：每隔一定时间间隔进行统计输出的日志；无论是哪种日志的输出，对于 SOFATracer 来说都需要保证较高的性能，以降低对于业务整体流程耗时的影响。\n关于 Disruptor 的 一些原理分析可以参考：Disruptor 。\n A High Performance Inter-Thread Messaging Library 高性能的线程间消息传递库\n 案例 先通过 Disruptor 的一个小例子来有个直观的认识；先看下它的构造函数：\npublic Disruptor( final EventFactory\u0026amp;lt;T\u0026amp;gt; eventFactory, final int ringBufferSize, final ThreadFactory threadFactory, final ProducerType producerType, final WaitStrategy waitStrategy) { this( RingBuffer.create(producerType, eventFactory, ringBufferSize, waitStrategy), new BasicExecutor(threadFactory)); }  eventFactory : 在环形缓冲区中创建事件的 factory； ringBufferSize:环形缓冲区的大小，必须是2的幂； threadFactory：用于为处理器创建线程； producerType：生成器类型以支持使用正确的sequencer和publisher创建RingBuffer；枚举类型，SINGLE、MULTI两个项。对应于 SingleProducerSequencer和MultiProducerSequencer两种Sequencer； waitStrategy : 等待策略；  如果我们想构造一个 disruptor，那么我们就需要上面的这些组件。从 eventFactory 来看，还需要一个具体的 Event 来作为消息事件的载体。【下面按照官方给的案例进行简单的修改作为示例】\n消息事件 LongEvent ，能够被消费的数据载体 public class LongEvent { private long value; public void set(long value) { this.value = value; } public long getValue() { return value; } } 创建消息事件的 factory public class LongEventFactory implements EventFactory\u0026amp;lt;LongEvent\u0026amp;gt; { @Override public LongEvent newInstance() { return new LongEvent(); } } ConsumerThreadFactory public class ConsumerThreadFactory implements ThreadFactory { private final AtomicInteger index = new AtomicInteger(1); @Override public Thread newThread(Runnable r) { return new Thread(r, \u0026amp;#34;disruptor-thread-\u0026amp;#34; + index.getAndIncrement()); } } OK ，上面的这些可以满足创建一个 disruptor 了：\nprivate int ringBufferCapacity = 8; //消息事件生产Factory LongEventFactory longEventFactory = new LongEventFactory(); //执行事件处理器线程Factory ConsumerThreadFactory consumerThreadFactory = new ConsumerThreadFactory(); //用于环形缓冲区的等待策略。 WaitStrategy waitStrategy = new BlockingWaitStrategy(); //构建disruptor Disruptor\u0026amp;lt;LongEvent\u0026amp;gt; disruptor = new Disruptor\u0026amp;lt;\u0026amp;gt;( longEventFactory, ringBufferCapacity, longEventThreadFactory, ProducerType.SINGLE, waitStrategy); 现在是已经有了 disruptor 了，然后通过：start 来启动：\n//启动 disruptor  disruptor.start(); 到这里，已经构建了一个disruptor；但是目前怎么使用它来发布消息和消费消息呢？\n发布消息 下面在 for 循环中 发布 5 条数据：\nRingBuffer\u0026amp;lt;LongEvent\u0026amp;gt; ringBuffer = disruptor.getRingBuffer(); for (long l = 0; l \u0026amp;lt; 5; l++) { long sequence = ringBuffer.next(); LongEvent event = ringBuffer.get(sequence); event.set(100+l); System.out.println(\u0026amp;#34;publish event :\u0026amp;#34; + l); ringBuffer.publish(sequence); Thread.sleep(1000); } 消息已经发布，下面需要设定当前 disruptor 的消费处理器。 …","date":1584439200,"description":"本文将对 SOFATracer 中使用 Disruptor 来进行日志输出的代码进行了具体的分析。","dir":"blog/sofa-trcaer-disruptor-practice/","fuzzywordcount":5500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"a97d804a20a7af180c889c55210ab2fa","permalink":"/blog/sofa-trcaer-disruptor-practice/","publishdate":"2020-03-17T18:00:00+08:00","readingtime":11,"relpermalink":"/blog/sofa-trcaer-disruptor-practice/","summary":"SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级云原生架构，包含了构建金融级云原生架构所需的各个组件，是在金","tags":["SOFATracer"],"title":"蚂蚁金服分布式链路跟踪组件 SOFATracer 中 Disruptor 实践（含源码）","type":"blog","url":"/blog/sofa-trcaer-disruptor-practice/","wordcount":5439},{"author":"潘潘","categories":"SOFAChannel","content":"概要   活动主题：SOFAChannel#13：云原生网络代理 MOSN 的多协议机制解析\n  活动时间：3 月 26 日周四晚 7 点\n  活动形式：线上直播\n  直播回顾：戳这里\n  介绍 | SOFAChannel \u0026amp;lt;SOFA:Channel/\u0026amp;gt; 有趣实用的分布式架构频道，前沿技术、直播 Coding、观点“抬杠”，多种形式。\n\u0026amp;lt;SOFA:Channel/\u0026amp;gt; 将作为 SOFA 所有在线内容的承载，包含直播/音视频教程，集中体现 SOFAStack 的能力全景图。\n| SOFAChannel#13：云原生网络代理 MOSN 的多协议机制解析 作为云原生网络代理，Service Mesh 是 MOSN 的重要应用场景。随着 Service Mesh 概念的日益推广，大家对这套体系都已经不再陌生，有了较为深入的认知。但是与理论传播相对应的是，生产级别的大规模落地实践案例却并不多见。这其中有多方面的原因，包括社区方案饱受诟病的“大规模场景性能问题”、“配套的运维监控基础设施演进速度跟不上”、“存量服务化体系的兼容方案”等等。\n现实场景中，大部分国内厂商都有一套自研 RPC 的服务化体系，属于「存量服务化体系的兼容方案」中的协议适配问题。为此，MOSN 设计了一套多协议框架，用于降低自研体系的协议适配及接入成本，加速 Service Mesh 的落地普及。本次演讲将向大家介绍 MOSN 实现多协议低成本接入的设计思路，以及相应的快速接入实践案例。\n本期为 SOFAChannel 线上直播第 13 期，将邀请蚂蚁金服技术专家\u0026amp;amp; MOSN Committer 无钩分享《云原生网络代理 MOSN 的多协议机制解析》。\n| 加入 SOFA 钉钉互动群 欢迎加入直播互动钉钉群：21992058（搜索群号加入即可）\n| 点击即可报名 https://tech.antfin.com/community/live/1131\n议程 19:00-19:05 主持人开场 SOFAGirl 主持人\n19:05-20:00 蚂蚁金服分布式事务实践解析 无钩 蚂蚁金服技术专家 MOSN Committer\n本期分享大纲  一个请求的 MOSN 之旅 如何在 MOSN 中接入新的协议 SOFABolt 协议接入实践 未来发展：统一路由框架  嘉宾  SOFAGirl 主持人 无钩 蚂蚁金服技术专家 MOSN Committer  ","date":1584349200,"description":"3 月 26 日周四晚 7 点，线上直播第 13 期。","dir":"activities/sofa-channel-13/","fuzzywordcount":700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"ba88bba5176867c90fb18dc045408d84","permalink":"/activities/sofa-channel-13/","publishdate":"2020-03-16T17:00:00+08:00","readingtime":2,"relpermalink":"/activities/sofa-channel-13/","summary":"概要 活动主题：SOFAChannel#13：云原生网络代理 MOSN 的多协议机制解析 活动时间：3 月 26 日周四晚 7 点 活动形式：线上直播 直播回顾：戳这里 介","tags":["SOFAChannel","MOSN"],"title":"SOFAChannel#13：云原生网络代理 MOSN 的多协议机制解析","type":"activities","url":"/activities/sofa-channel-13/","wordcount":692},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@胡秋林 提问：\n 请教一个问题，服务拆分然后使用分布式事务，会不会事务链路过长，然后整体性能下降很大呢？\n A：用了分布式事务性能肯定会下降，这是大家对一致性和性能的取舍。在性能对比这块我建议大家去和同类的分布式事务框架对比，而不是只和不用分布式事务去对比。分布式事务很大一部分是处理的系统异常时的一致性，如果针对系统异常这个点，大家如果相信自己的框架 100% 正常的，不会出现超时，网络和宕机等问题，那可以不使用分布式事务，所以保证一致性的很多场景是极端情况下的一致性，在同类框架的对比中，一定是看框架一致性场景的覆盖，如果场景覆盖不全的基础上和我们对比性能我觉得这个没太大意义。这就好比我系统有 1% 几率出现极端情况，我不用 Seata 和使用 Seata 的对比是一样的。\n2、@吴攀 提问：\n 麻烦问下，我现在做的一个销售订单的流程。需要监听审批的状态变化，然后状态机才往下进行流转。Saga 能否满足呢？  A：目前是不支持的，因为 Saga 的状态机定位是服务编排的事务处理，不应该包含人工审批动作，建议做成两个流程，包含人工审批动作，中间状态时间会很长。\n 我来状态想能否把“状态”配置成“IsAsync = true”来实现，然后异步任务来监听审批状态的变化。感觉有些负责。所以来咨询下？有没有更好其他的推荐的方案呢？Netflix Conductor 能满足这个场景么？我现在的场景是：一个销售单出库的流程。销售单建立成功后，要经过审批流程进行审批，然后进入仓库进行库存分配。分配成功后，进行分拣，然后进行打包。最后进行出库。老板想把这些状态流转编制成一个 Saga 支持的状态机。\n A：isAsync 是这个服务异步调用，应该解决不了你这个问题。我的建议是把这个流程差分一下，拆分成两个，或者，销售订单不要纳入状态机，只是插入一条记录，审批通过后，把后面的流程配置成状态机，而且我理解你们这流程是每一步都是人工做完，然后在系统里点一下，然后继续，如果是这样，这不是服务编排的需求，为是工作流的需求。\nSeata：https://github.com/seata/seata\n3、@兴元 提问：\n SOFABoot 版本 v3.3.0，目前官网文档里只有整合 Nacos 0.6.0 版本的，请问怎么使用 Nacos 的命名空间功能？SOFABoot 版本 v3.3.0，maven 引用里 nacos-client 版本是 1.0.0，请问现在支持 nacos 最新版本是多少。\n A：Nacos 配置格式参考：https://www.sofastack.tech/projects/sofa-rpc/registry-nacos/ 对于 namespace 的，可以配置成这样即可：namespace nacos://yyy:8848/namespaceNacos 客户端应该是兼容的，你可以直接升级这个包的版本。\n 命名空间问题解决了，感谢。因为我使用的时候指定了 nacos client 版本为0.6.0，升级到 0.8.0 以上nacos://yyy:8848/namespace 这种形式是可以的，而且只能使用 nacos://yyy:8848/namespace 这种形式，nacos://yyy:8848 是不行的。还望官方文档可以及时更新一下。\n A：这里应该是要配置成：nacos://yyy:8848/ 后面有个/。好的，最近我们升级一下 Nacos 的 client 版本。文档我们同步修改下。\n 刚试了nacos://yyy:8848/，服务依然无法发布到默认命名空间。Nacos server 是1.2.0，客户端是使用SOFABoot v3.3.0。\n A：不会发到默认的，这个会发到的是 SOFARPC 这个 Namespace：private static final String DEFAULT_NAMESPACE = \u0026amp;quot;sofa-rpc\u0026amp;quot;;\nSOFARPC：https://github.com/sofastack/sofa-rpc\n期待见到，每一个精彩的你  蚂蚁金服云原生团队实习生招聘开始啦 【岗位继续增了】蚂蚁金服云原生团队招聘~欢迎加入我们  SOFAChannel 直播回顾  SOFAChannel#12：蚂蚁金服分布式事务实践解析 | SOFAChannel#12 直播整理 SOFAChannel#11：从一个例子开始体验轻量级类隔离容器 SOFAArk | SOFAChannel#11 直播整理 SOFAChannel#10：Seata 长事务解决方案 Saga 模式 | SOFAChannel#10 回顾 SOFAChannel#9：Service Mesh 落地负责人亲述：蚂蚁金服双十一四大考题 | SOFAChannel#9 回顾 SOFAChannel#8：从一个例子开始体验 SOFAJRaft | SOFAChannel#8 直播整理 SOFAChannel#7：自定义资源 CAFEDeployment 的背景、实现和演进 | SOFAChannel#7 直播整理 SOFAChannel#6：蚂蚁金服轻量级监控分析系统解析 | SOFAChannel#6 直播整理 SOFAChannel#5：给研发工程师的代码质量利器 | SOFAChannel#5 直播整理 SOFAChannel#4：分布式事务 Seata TCC 模式深度解析 | SOFAChannel#4 直播整理 SOFAChannel#3：SOFARPC 性能优化实践（下）| SOFAChannel#3 直播整理 SOFAChannel#2：SOFARPC 性能优化实践（上）| SOFAChannel#2 直播整理 SOFAChannel#1：从蚂蚁金服微服务实践谈起 | SOFAChannel#1 直播整理  SOFA 项目进展 本周发布详情如下：\n1、发布 SOFABoot v3.3.1 版本，主要变更如下：\n 升级 Spring Boot 至 2.1.13.RELEASE； 修复 Tomcat AJP 漏洞； …","date":1584086400,"description":"【03/09-03/13】| 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20200313/","fuzzywordcount":3000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"cd22bd67fe25923bca65eae188627da8","permalink":"/blog/sofa-weekly-20200313/","publishdate":"2020-03-13T16:00:00+08:00","readingtime":6,"relpermalink":"/blog/sofa-weekly-20200313/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | 3/26 直播预告、多个组件发布、云原生团队校招社招信息汇总","type":"blog","url":"/blog/sofa-weekly-20200313/","wordcount":2967},{"author":"仁空","categories":"SOFA Weekly","content":" SOFA:Channel/，有趣实用的分布式架构频道。 本文根据 SOFAChannel#12 直播分享整理，主题：蚂蚁金服分布式事务实践解析。 回顾视频以及 PPT 查看地址见文末。欢迎加入直播互动钉钉群 : 30315793，不错过每场直播。\n 大家好，我是今天分享的讲师仁空，目前是蚂蚁金服分布式事务产品的研发。今天跟大家分享的是蚂蚁金服分布式事务实践解析，也就是分布式事务 Seata 在蚂蚁金服内部的实践。\n今天我们将从以下 4 个主题进行详细介绍：\n 为什么会有分布式事务产品的需求； 理论界针对这个需求提出的一些理论和解决方案； 蚂蚁金服在工程上是如何解决这个问题的； 针对蚂蚁金服业务场景的性能优化；  分布式事务产生背景 首先是分布式事务产生的背景。\n支付宝支付产品在 2003 年上线的时候，那时候的软件形态是单体应用，在一个应用内完成所有的业务逻辑操作。随着软件的工业化，场景越来越复杂，软件也越做越大，所有的业务在一个应用内去完成变的不可能，出现了软件模块化、服务化。\n在从单体应用升级到分布式架构过程中，很自然得需要进行业务服务拆分，将原来糅在一个系统中的业务进行梳理，拆分出能独立成体系的各个子系统，例如交易系统、支付系统、账务系统等，这个过程就是服务化。业务服务拆分之后，原来一个服务就能完成的业务操作现在需要跨多个服务进行了。\n另一个就是数据库拆分，分库分表。原来的单体数据库存不下的这么多信息，按服务维度拆库，比如把用户相关的存一起，形成用户库，订单放一块形成订单库，这个是拆库的过程；另一个是拆表，用户信息按照用户 ID 散列到不同的 DB 中，水平拆分，数据库的容量增大了。这样分库分表之后，写操作就会跨多个数据库了。\n分布式事务理论基础 我们可以看到，在分布式架构中，跨数据库、跨服务的问题是天然存在的。一个业务操作的完成，需要经过多个服务配合完成，这些服务操作的数据可能在一个机房中，也可能跨机房存在，如果中间某一个服务因为网络或机房硬件的问题发生了抖动，怎么保证这笔业务最终的状态是正确的，比如支付场景，怎么防止我转钱给你的过程中，我的钱扣了，而对方的账户并没有收到钱。这个就是业务最终一致性的问题，是分布式事务需要解决的问题。\n2PC 协议 针对这个问题，理论界也提出了解决方案，其中最为人熟知的就是二阶段协议了，简称2PC（Two Phase Commitment Protocol）两阶段提交协议。\n两阶段提交协议，就是把整个过程分成了两个阶段，这其中，它把参与整个过程的实体分成了两类角色，一个叫事务管理器或事务协调者，一个叫资源管理器，事务管理器我们也把它叫做事务发起方，资源管理器称为事务参与者。\n两个阶段，第一个阶段是资源准备阶段，比如我要转账，我要先查询下我的余额够不够，够的话我就把余额资源预留起来，然后告诉发起方“我准备好了”，第二个阶段，事务发起方根据各个参与者的反馈，决定事务的二阶段操作是提交还是取消。\nTCC 协议 另一个协议是 TCC 协议，各个参与者需要实现3个操作：Try、Confirm 和 Cancel，3个操作对应2个阶段，Try 方法是一阶段的资源检测和预留阶段，Confirm 和 Cancel 对应二阶段的提交和回滚。\n图中，事务开启的时候，由发起方去触发一阶段的方法，然后根据各个参与者的返回状态，决定二阶段是调 Confirm 还是 Cancel 方法。\n蚂蚁金服分布式事务介绍 2019年，蚂蚁金服跟阿里巴巴共同开源了分布式事务 Seata ，目前 Seata 已经有 TCC、AT、Saga 模式，Seata 意为：Simple Extensible Autonomous Transaction Architecture，是一套一站式分布式事务解决方案。今天的分享也是 Seata 在蚂蚁金服内部的实践。\n分布式事务在蚂蚁金服的发展 基于上述的理论，接下来我们详细看下蚂蚁金服的分布式事务实现。\n经过多年的发展，蚂蚁金服内部针对不同的场景发展了几种不同的模式，最早的是 TCC 模式，也就是上面讲的 Try - confirm - Cancel，我们定义接口规范，业务自己实现这3个操作。这个模式提供了更多的灵活性，因为是业务自己实现的，用户可以介入两阶段提交过程，以达到特殊场景下的自定义优化及特殊功能的实现，这个模式能几乎满足任何我们想到的事务场景，比如自定义补偿型事务、自定义资源预留型事务、消息事务等场景。TCC 模式广泛用于蚂蚁金服内部各金融核心系统。\n这里要强调一点的是，TCC 模式与底层数据库事务实现无关，是一个抽象的基于 Service 层的概念，也就是说，在 TCC 的范围内，无论是关系型数据库 MySQL，Oracle，还是 KV 存储 MemCache，或者列式存储数据库 HBase，只要将对它们的操作包装成 TCC 的参与者，就可以接入到 TCC 事务范围内。\nTCC 模式的好处是灵活性，弊端是牺牲了易用性，接入难度比较大，所有参与者需要进行改造提供 Try - Confirm - Cancel 三个方法。为了解决 TCC 模式的易用性问题，蚂蚁金服分布式事务推出了框架管理事务模式（Framework - Managed Transactions，简称 FMT），也就是 Seata 中的 AT 模式。FMT 模式解决分布式事务的易用性问题，最大的特点是易于使用、快速接入、对业务代码无侵入。\nXA 模式是依赖于底层数据库实现的。\nSaga 模式是基于冲正模型实现的一个事务模式，现在的银行业金融机构普遍用的是冲正模型。\n这期我们重点讲 TCC 和 FMT，关于 Saga 模式，之前 Saga 模式也有专场直播分享过，感兴趣的可以看一下之前的直播回顾：《Seata 长事务解决方案 Saga 模式 | SOFAChannel#10 回顾》。\nTCC 模式在蚂蚁金服内的使用 首先看下 TCC 模式，主要包含一下几个模块：\n 参与者，它要实现全部的三个方法，Try、Confirm 和 Cancel； 发起方，主要是作为协调者的角色，编排各个参与者，比如调用参与者的一阶段方法，决策二阶段是执行提交还是回滚；  举个例子，比如在这个流程图中，存在一个发起方和两个参与者，两个参与者分别实现了 Try、Confirm 和 Cancel 接口，第一阶段被包含在发起方的本地事务模版中（图中黄颜色的两条虚线就是发起方本地事务的范围），也就是说发起方负责调用各个参与者的一阶段方法，发起方的本地事务结束后，开始执行二阶段操作，二阶段结束则整个分布式事务结束。\n二阶段是通过 Spring 提供的事务同步器实现的，发起方在发起一个分布式事务的时候，会注册一个事务同步器，当发起方本地事务结束的时候，会进入事务同步器的回调方法中。如果发起方的本地事务失败，则在回调中自动回滚所有参与者。如果发起方的本地事务成功，则二阶段自动提交所有参与者。二阶段结束后，删除所有事务记录。\n总结一下：\n 事务发起方是分布式事务的协调者； 分布式事务必须在本地事务模板中进行，发起方本地事务的最终状态（提交或回滚）决定整个分布式事务的最终状态； 发起方主职责：开启一个分布式事务 + 调用参与 …","date":1584016200,"description":"分布式事务 TCC、FMT 模式在蚂蚁金服内部的实践分享。","dir":"blog/sofa-channel-12-retrospect/","fuzzywordcount":6600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"1aaf09602548f4204f00c7b02260e180","permalink":"/blog/sofa-channel-12-retrospect/","publishdate":"2020-03-12T20:30:00+08:00","readingtime":14,"relpermalink":"/blog/sofa-channel-12-retrospect/","summary":"SOFA:Channel/，有趣实用的分布式架构频道。 本文根据 SOFAChannel#12 直播分享整理，主题：蚂蚁金服分布式事务实践解析。 回顾视频以及 PPT 查看地址见文末","tags":["SOFAChannel","分布式事务"],"title":"蚂蚁金服分布式事务实践解析 | SOFAChannel#12 直播整理","type":"blog","url":"/blog/sofa-channel-12-retrospect/","wordcount":6522},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@水木今山 提问：\n 请问下 SOFAJRaft 能否在日志复制到大多数后就响应客户端？我看 rhea 和 counter 的例子好像都是应用到状态机后才通过 closure 响应客户端。\n A：SOFAJRaft 没有限制，可以在自己的 statemachine 里不直接返回客户端再应用， rheakv 不能。举个例子， compareAndSet 操作，需要先读取再设置，最后返回 client，那么怎么能做到不应用状态机就返回呢，对吧？\n 有道理，但直接返回客户端的逻辑只能在 StateMachine 提供的 onApply 方法里实现吗，因为 onApply 的调用应该会滞后许久吧？\n A：onApply 里面实现就可以，onApply 就可以理解为和达成多数派之间没有延迟。\n 我在文档中有看到 TaskClosure 这么一个接口，在它的 onCommitted 方法里响应客户端会不会更高效？据我所知，raft 仅需写入日志就可保证强一致性，可以异步去 apply，所以在复制日志给大多数后就通过 onCommitted方法响应客户端（尽管还没有任何一个节点 apply 了该日志），这样效率好像会高一点，不知道我对这个接口理解有没有误。\n A：com.alipay.sofa.jraft.core.FSMCallerImpl#doCommitted\n可以看看这个方法，里面会在调用状态机之前调用 TaskClosure，想用 TaskClosure 也可以，不过两者没什么延迟区别。\nSOFAJRaft：https://github.com/sofastack/sofa-jraft\n2、@匿名 提问：\n MOSN 支持 Istio 的什么版本？什么时候可以在 Istio 中可用？\n A：目前 MOSN 可基于 Istio 1.1.4 跑通 bookinfo example，由于最新版本的 Istio 对 XDS 协议进行了升级以及部分能力增强，MOSN 当前正在适配中，预计 2020 年 10 月份会完整支持高版本 Istio 的 HTTP 系能力；同时我们一直在关注 UDPA 的发展，也在尝试参与到标准的制定中。控制平面方面，我们和社区一直保持紧密沟通与合作，大力发展控制平面，MOSN 也将与控制平面共同前进。\nMOSN：https://github.com/mosn/mosn\n3、@孙俊 提问：\n 请问下，全局事务开启后，全局事务锁未释放时，此时又来个操作同一个数据的本地请求，这个请求没有开启全局事务，是可以修改这个数据的呀。\n A：全局事务的分支事务结束后，不在全局事务的本地数据请求可修改数据。\n 那这样，全局事务的其他分支出现异常，分支事务回滚，从undo里读，发现数据已经被修改了，就得人工处理了？\n A：是，从业务设计上来说如果使用 AT 模式要把数据修改都交给 AT 来管理来避免这类问题。 Seata：https://github.com/seata/seata\n剖析 SOFARegistry 系列  服务注册中心数据一致性方案分析 | SOFARegistry 解析 服务注册中心如何实现秒级服务上下线通知 | SOFARegistry 解析 服务注册中心 Session 存储策略 | SOFARegistry 解析 服务注册中心数据分片和同步方案详解 | SOFARegistry 解析 服务注册中心 MetaServer 功能介绍和实现剖析 | SOFARegistry 解析 服务注册中心 SOFARegistry 解析 | 服务发现优化之路 海量数据下的注册中心 - SOFARegistry 架构介绍  SOFA 项目进展 1、发布 SOFARegistry v5.4.0 版本，主要变更如下：\n SessionServer 与 DataServer 通讯性能优化； jraft 从 1.2.5 更新到 1.2.7.beta1； 解决 MethodHandle 在某些 jdk 版本存在内存泄露的 bug； Bug Fix；  详细发布报告：https://github.com/sofastack/sofa-registry/releases/tag/v5.4.0\n2、发布 SOFAArk v1.1.1 版本，主要变更如下：\n 优化biz 卸载，清理临时文件； 支持 biz 打包 指定 bizName -D 参数；  详细发布报告：https://github.com/sofastack/sofa-ark/releases/tag/v1.1.1\n社区直播预告 SOFAChannel#12 线上直播将邀请蚂蚁金服分布式事务核心开发仁空分享介绍蚂蚁金服内部的分布式事务实践，包括 TCC（Try-Confirm-Cancel） 模式以及 FMT （Framework-Managerment-Transaction，框架管理事务）模式。同时也会与大家分享在面对双十一大促这种世界级的流量洪峰前，我们又是如何应对这个挑战。\n主题：SOFAChannel#12：蚂蚁金服分布式事务实践解析\n时间：2020年3月12日（周四）19:00-20:00\n嘉宾：仁空，蚂蚁金服分布式事务核心开发\n形式：线上直播\n报名方式：点击“这里”，即可报名\n","date":1583481600,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20200306/","fuzzywordcount":2000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"762ff425feef89f406716a6c0c4fff9d","permalink":"/blog/sofa-weekly-20200306/","publishdate":"2020-03-06T16:00:00+08:00","readingtime":4,"relpermalink":"/blog/sofa-weekly-20200306/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | SOFARegistry 发版以及源码系列合辑、SOFAArk 发版、3/12直播预告","type":"blog","url":"/blog/sofa-weekly-20200306/","wordcount":1922},{"author":"SOFA 团队","categories":"云原生","content":" 2月19日-2月26日，蚂蚁金服开展了“共战‘疫情’，技术破局”数字课堂线上直播，邀请资深专家从“云原生”、“研发效能”、“数据库”三方面分享蚂蚁金服的实践经验并在线答疑，解析 PaaS 在金融场景的落地建设实践，解析支付宝移动端弹性动态架构，分享 OceanBase 2.2版本的特性和实践。\n 本文根据 蚂蚁金服 SOFAStack 产品专家俞仁杰，在蚂蚁金服数字课堂直播间分享的云原生应用 PaaS 平台的建设实践内容整理，以下为演讲整理全文：\n大家好，欢迎来到蚂蚁金服数字课堂直播间。今年 2 月，SOFAStack 金融分布式架构产品已经在阿里云上完成了商业化发布，为了让更多朋友了解到我们的产品的能力、定位以及背后的设计思路，后续我们会有一系列的直播分享。我们今天想分享给大家的话题叫《云原生应用 PaaS 平台的建设实践》，主要会围绕 PaaS 产品能力在一些需要稳妥创新的金融场景下的落地思路，并且能够更好地与云原生架构做好链接。\n金融场景云原生落地面临挑战 云原生是业务快速变化背景下的必然技术趋势 回顾 IT 的发展史，云计算分类为 IaaS PaaS 和 SaaS 已经有十几年了。而事实上，整个云计算行业的发展，我们能够明显看到企业在落地云计算战略的时候经历的三个阶段，Cloud-Based, Cloud-Ready, Cloud-Native。这三个阶段其实是因为业务的变化越来越敏捷，要求企业关注重心上移，把更多的精力和人才投入到业务逻辑的建设上，而把下层自已并不擅长并且越来越复杂的基础设施、中间件逐渐交给云计算厂商去实现，专业的人做专业的事。\n这本质是社会分工的进一步细化，也符合人类社会发展的规律。在云原生时代，业界所提出的容器技术，Service Mesh 技术，Serverless 技术都是希望让业务研发与基础技术更加的解耦，让业务创新和基础技术创新都更容易的发生。\n容器技术带来的是一种应用交付模式的变革 云原生就是业务快速变化背景下的必然技术趋势。而这个趋势背后的实质载体，就是我们所说的云原生、Kubernetes 以及以 Docker 为代表的容器技术，这些所带来的，本质是一种应用交付模式的变革。而为了真正能够使业界、社区所倡导的新兴应用交付模式落地到实际的企业环境，我们需要一个以应用为中心的平台来进行承载，贯穿应用运维的各项生命周期。\n围绕“云原生”这个关键词，其实在社区和业界已经有了非常多的交流和资料，围绕Docker/K8S 的最佳实践、DevOps CICD、容器网络存储设计、日志监控对接优化等等等等，而我们今天的分享，主要想表达的是我们围绕在 K8S 之上塑造一个 PaaS 平台的产品价值主张。Kubernetes 是一个非常好的编排和调度框架，它核心的贡献是让应用的编排和资源的调度更加的标准化，同时提供了一个高度可扩展的架构，方便上层进行各种控制器和调度器的定制。但是，它并不是一个 PaaS。PaaS 底层可以基于 Kubernetes 去实现，但是在上层要补足非常多的能力才能真正把 Kubernetes 用于生产环境，特别是金融行业的生产环境。\n金融场景需要“稳妥创新” 生产环境落地云原生需要着重考虑哪些挑战？\n我们之前做过一些调研和客户访谈。就现在 2020 年来说，绝大多数金融机构都展现出了对 Kubernetes、容器等技术的极大兴趣，有不少机构也已经在一些非关键的业务、或开发测试环境搭建了开源或商业版的集群。驱动力很简单，金融机构非常希望这一整套新的交付模式帮助到业务飞速迭代。然而对比落差非常明显的是，真正敢于在核心生产环境落地云原生架构的，又少之又少。因为金融业务创新的前提，是要保障稳妥。\n我们团队在服务蚂蚁内部业务、外部金融机构的过程中，总结了以上这几个方面，事实上这六大方面也是我们内部 SRE 不断挑战的几点。我们在今天以及未来的分享中，会逐步总结深化应对这些挑战的产品思路。\nK8S 体系下的应用变更与发布管控 我们今天分享的一个核心内容，就是我们如何在产品层面做应用变更的风险保障的。并围绕此话题向大家介绍变更“三板斧”的背景、K8S 原生部署能力、我们产品围绕变更需求做的扩展并向大家介绍我们在开源方面的规划。\n需求背景：变更“三板斧” 所谓“三板斧”就是可灰度、可监控、可应急。这是蚂蚁内部运维的一条红线准则，所有的变更，都必须要遵从这个规则，即使再细小的变更，再严密的测试，也不能忽略这条规则。为了满足这个需求，我们在 PaaS 产品层设计了各种各样的精细化发布策略，比如分组发布、beta 发布，灰度发布，蓝绿发布等。这些发布策略跟我们在做传统运维时用的手段是非常相似的，但很多使用容器的用户认为在 K8S 里实现会非常的困难。\n有些时候，由于对业务连续性的极高要求，也很难接受原生 K8S 模型标准化模式，比如原生 Deployment 做灰度或者金丝雀发布时，默认情况下在 Pod 变更和流量治理层面的管控还稍显不足，无法完全做到无损发布或按需过程管控。因此，我们在 PaaS 产品层面做了定制，在 Kubernetes 层面做了自定义资源的扩展，目的是能够在云原生的场景下，依然对整个发布过程实现精细化管控，使得大规模集群发布、灰度、回滚时更加优雅，符合技术风险三板斧原则。 Kubernetes 原生发布能力 我们先来回顾一下 K8S 的原生 Deployment 对象，及其背后的 ReplicaSet，其实已经是在最近好几个大版本中已经逐渐的稳定了。 简单的来说，最常见的 K8S 发布场景，我们会通过 Deployment 的对象，声明出我希望的发布模式以及 Pod Spec 定义。在运行时，会有 ReplicaSet 对象来管理 Pod 数量的预期，默认情况下会提供滚动发布或重建发布能力。\nimage.png\n这幅图的下半部分，是围绕 Deployment 作滚动发布时的示意图，这里不再做过多的展开，它的本质根据用户根据我们的运维需求设定好一定的步长，创建新的 Pod，销毁旧的 Pod，因此能做到整个应用版本的变更和发布过程中，都能有对应的容器对外提供服务。 对大部分场景来说，它是够用的，而且整个过程也是非常好的理解，事实上在 K8S 体系，大家除了 Pod/Node，看的最多的就是 Deployment了。\nCAFEDeployment：感知底层拓扑和领域模型 回顾完 Deployment，我们可以再给大家看一下我们根据实际需求作的 CRD 扩展，CAFEDeployment。CAFE 是我们 SOFAStack PaaS 产品线的名称，本文的最后会作一些介绍。\nCAFEDeployment 有一个很重要的能力，就是能够感知到底层拓扑，这个拓扑是什么意思呢？能够知道我想把我的 Pod 发布到哪里，哪边的 Node，不只是基于亲和性的规则作绑定，而是真正能把高可用、容灾、以及部署策略等场景息息相关的信息，带到整个围绕发布的领域模型中。对此，我们提出了一个叫部署单元的领域模型，他是一个逻辑概念，在 yaml 中简单的叫做 Cell。在实际使用中，Cell 的背后，可以是不同的 AZ 不同的物理机房，不同的机架，一切都是围绕着不同级别的高可用 …","date":1583395200,"description":"云原生应用 PaaS 平台的建设实践","dir":"blog/distributed-architecture-and-cloud-native/","fuzzywordcount":5600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"6c1ff3975ace44ac5189b1f845a43fcb","permalink":"/blog/distributed-architecture-and-cloud-native/","publishdate":"2020-03-05T16:00:00+08:00","readingtime":12,"relpermalink":"/blog/distributed-architecture-and-cloud-native/","summary":"2月19日-2月26日，蚂蚁金服开展了“共战‘疫情’，技术破局”数字课堂线上直播，邀请资深专家从“云原生”、“研发效能”、“数据库”三方面分","tags":["云原生"],"title":"技术破局：如何实现分布式架构与云原生？| 含 ppt 下载","type":"blog","url":"/blog/distributed-architecture-and-cloud-native/","wordcount":5557},{"author":"明不二","categories":"SOFARegistry","content":" SOFAStack （Scalable Open Financial Architecture Stack） 是蚂蚁金服自主研发的金融级云原生架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。\n SOFARegistry 是蚂蚁金服开源的具有承载海量服务注册和订阅能力的、高可用的服务注册中心，在支付宝/蚂蚁金服的业务发展驱动下，近十年间已经演进至第五代。\n本文为《剖析 | SOFARegistry 框架》第七篇，本篇作者明不二。《剖析 | SOFARegistry 框架》系列由 SOFA 团队和源码爱好者们出品，项目代号：SOFA:RegistryLab/，文末包含往期系列文章。\nGitHub 地址：https://github.com/sofastack/sofa-registry\n概述 在前面的文章已经做过介绍，与其他注册中心相比，SOFARegistry 主要特点在于支持海量数据、支持海量客户端、秒级的服务上下线通知以及高可用特性。本文将从如下几个方面来讲述 SOFARegistry 的一致性方案：\n MetaServer 数据一致性  为支持高可用特性，对于 MetaServer 来说，存储了 SOFARegistry 的元数据，为了保障 MetaServer 集群的一致性，其采用了 Raft 协议来进行选举和复制。\n SessionServer 数据一致性  为支持海量客户端的连接，SOFARegistry 在客户端与 DataServer 之间添加了一个 SessionServer 层，客户端与 SessionServer 连接，避免了客户端与 DataServer 之间存在大量连接所导致的连接数过多不可控的问题。客户端通过 SessionServer 与 DataServer 连接的时候，Publisher 数据同时会缓存在 SessionServer 中，此时就需要解决 DataServer 与 SessionServer 之间数据一致性的问题。\n DataServer 数据一致性  为支持海量数据，SOFARegistry 采用了一致性 Hash 来分片存储 Publisher 数据，避免了单个服务器存储全量数据时产生的容量瓶颈问题。而在这个模型中，每个数据分片拥有多个副本，当存储注册数的 DataServer 进行扩容、缩容时，MetaServer 会把这个变更通知到 DataServer 和 SessionServer，数据分片会在集群内部进行数据迁移与同步，此时就出现了 DataServer 内部数据的一致性问题。\nMetaServer 数据一致性 MetaServer 在 SOFARegistry 中，承担着集群元数据管理的角色，用来维护集群成员列表，可以认为是 SOFARegistry 注册中心的注册中心。当 SessionServer 和 DataServer 需要知道集群列表，并且需要扩缩容时，MetaServer 将会提供相应的数据。\n图1 MetaServer 内部结构 图源自 《蚂蚁金服服务注册中心 MetaServer 功能介绍和实现剖析 | SOFARegistry 解析》\n因为 SOFARegistry 集群节点列表数据并不是很多，因此不需要使用数据分片的方式在 MetaServer 中存储。如图 1 所示，集群节点列表存储在 Repository 中，上面通过 Raft 强一致性协议对外提供节点注册、续约、列表查询等 Bolt 请求，从而保障集群获得的数据是强一致性的。\nRaft 协议 关于 Raft 协议算法，具体可以参考 The Raft Consensus Algorithm 中的解释。在 SOFA 体系中，对于 Raft 协议有 SOFAJRaft 实现。下面对 Raft 协议算法的原理进行简要介绍。\nRaft 协议由三个部分组成，领导人选举（Leader Election）、日志复制（Log Replication）、安全性（Safety）。\n 领导人选举  通过一定的算法选举出领导人，用于接受客户端请求，并且把指令追加到日志中。\n图2 Raft 状态机状态转换图 图源自Understanding the Raft consensus algorithm: an academic article summary\n 日志复制  领导人接受到客户端请求之后，把操作追加到日志中，同时与其他追随者同步消息，最终 Commit 日志，并且把结果返回给客户端。\n图3 复制状态机 图源自 Raft一致性算法笔记\n 安全性  安全性保证了数据的一致性。\n基于 Raft 协议的数据一致性保障 图4 SOFARegistry 中的 Raft 存储过程 图源自 《蚂蚁金服服务注册中心 MetaServer 功能介绍和实现剖析 | SOFARegistry 解析》\n如图 4 所示，SOFARegistry 中的 Raft 协议数据存储经历了如上的一些流程。客户端发起 Raft 协议调用，进行数据注册、续约、查询等操作时，会通过动态代理实现 ProxyHandler 类进行代理，通过 RaftClient 把数据发送给 RaftServer ，并且通过内部的状态机 Statemachine ，最终实现数据的操作，从而保证了 MetaServer 内部的数据一致性。\nSessionServer 数据一致性 SessionServer 在 SOFARegistry 中，承担着会话管理及连接的功能。同时，Subscriber 需要通过 SessionServer 来订阅 DataServer 的服务数据，Publisher 需要通过 SessionServer 来把服务数据发布到 DataServer 中。\n在这个场景下，SessionServer 作为中间代理层，缓存从 DataServer 中获取的数据成了必然。DataServer 的数据需要通过 SessionServer 推送到 Subscriber 中，触发 SessionServer 推送的场景有两个：一个是 Publisher 到 DataServer 的数据发生变化；另外一个是 Subscriber 有了新增。\n而在实际的场景中，Subscriber 新增的情况更多，在这种场景下，直接把 SessionServer 缓存的数据推送到 Subscriber 中即可，能够大大减轻 SessionServer 从 DataServer 获取数据对 DataServer 的压力。因此，这也进一步确认了在 SessionServer 缓存数据的必要性。\n图5 两种场景的数据推送对比图\nSessionServer 与 DataServer 数据对比机制 当服务 Publisher 上下线或者断连时，相应的数据会通过 SessionServer 注册到 DataServer 中。此时，DataServer 的数据与 SessionServer 会出现短暂的不一致性。为了保障这个数据的一致性，DataServer 与 SessionServer 之间通过 推 和 拉 两种方式实现 …","date":1583224200,"description":" 本文为《剖析 | SOFARegistry 框架》第七篇，作者明不二","dir":"blog/sofa-registry-data-consistency/","fuzzywordcount":4400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"356cd2beadad494a22e2d480948fce8d","permalink":"/blog/sofa-registry-data-consistency/","publishdate":"2020-03-03T16:30:00+08:00","readingtime":9,"relpermalink":"/blog/sofa-registry-data-consistency/","summary":"SOFAStack （Scalable Open Financial Architecture Stack） 是蚂蚁金服自主研发的金融级云原生架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来","tags":["SOFARegistry","剖析 | SOFARegistry 框架","SOFALab"],"title":"服务注册中心数据一致性方案分析 | SOFARegistry 解析","type":"blog","url":"/blog/sofa-registry-data-consistency/","wordcount":4336},{"author":"潘潘","categories":"SOFALab","content":"| SOFALab \u0026amp;lt;SOFA:Lab/\u0026amp;gt; 源码研究实验室，由 SOFA 团队和源码爱好者们出品，欢迎你的加入~\n\u0026amp;lt;SOFA:BootLab/\u0026amp;gt;是《剖析 | SOFABoot 框架》系列，会逐步详细介绍 SOFABoot 各个部分的代码设计和实现，欢迎领取文章进行共建。\n| SOFABoot SOFABoot 是蚂蚁金服开源的基于 Spring Boot 的研发框架，它在 Spring Boot 的基础上，提供了诸如 Readiness Check，类隔离，日志空间隔离等能力。在增强了 Spring Boot 的同时，SOFABoot 提供了让用户可以在 Spring Boot 中非常方便地使用 SOFA 中间件的能力。\nSOFABoot :https://github.com/sofastack/sofa-boot\n| SOFA:Boot Lab   认领列表：\n 【已认领】《SOFABoot 总览》 【已认领】《SOFABoot runtime 机制解析》 【已认领】《SOFABoot HealthCheck 机制解析》 【已认领】《SOFABoot 日志隔离解析》 【已认领】《SOFABoot 上下文隔离机制解析》    领取方式：关注 「金融级分布式架构」 回复可领取的文章标题，我们将会主动联系你，确认资质后，即可加入 SOFA:BootLab/，It\u0026amp;rsquo;s your show time！\n  如果有同学对以上某个主题特别感兴趣的，可以留言讨论，我们会适当根据大家的反馈调整文章的顺序，谢谢大家关注 SOFAStack ，关注 SOFABoot，我们会一直与大家一起成长的。\n除了源码解析，也欢迎提交 issue 和 PR： SOFABoot：https://github.com/sofastack/sofa-boot\n欢迎领取，参与共建~\n","date":1583208000,"description":"","dir":"activities/sofa-boot-lab/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"ee08908ed6148190ca7ebcc0cdc5a3fc","permalink":"/activities/sofa-boot-lab/","publishdate":"2020-03-03T12:00:00+08:00","readingtime":2,"relpermalink":"/activities/sofa-boot-lab/","summary":"| SOFALab \u0026lt;SOFA:Lab/\u0026gt; 源码研究实验室，由 SOFA 团队和源码爱好者们出品，欢迎你的加入~ \u0026lt;SOFA:BootLab/\u0026gt;是《剖析 | SOFABoot 框架》系列，会逐步详细","tags":["SOFALab","SOFABoot","剖析 | SOFABoot 框架"],"title":"\u003cSOFA:BootLab/\u003e","type":"activities","url":"/activities/sofa-boot-lab/","wordcount":542},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n**1、@朱楠 **提问：\n SpringBoot 集成 Seata Saga 模式后启动报了这个错，有谁知道是什么情况吗？不知道问题出在哪，我就参照Saga 的 demo 来配置的。  A：这个事务异常了，然后 server 端出发了事务恢复，但是这条事务在客户端已经没有了。\n @Reference 这个注解没有 id 或者 name 的属性，试了几次还是不行，实在不行我就用配置文件的方式主入 Dubbo 服务了。  A：其实这也合理，因为 @Reference 是作用在一个类的 field 或 method 上面的，而状态机引擎它不是一个 field 或 method，所以状态机引擎不应该用访问这个类的 reference，而是应该访问一个 spring 上下文作用域的 reference 。我看了一下 Dubbo 的源码 @Reference 这种它并不会注册成为一个 bean，只是生成一个代理然后注入到这个引用它的属性里。所以状态机默认是取 bean 的形式拿不到 bean，你用 xml 的方式引用一个服务。状态机的编排本来就不是用 Java 代码上编排的，而 @Reference 是用于编程方式使用的。 Seata：https://github.com/seata/seata\n2、@魏敏 提问：\n 请问一下，关于 tomcat 的 ajp 漏洞，使用的 SOFABoot 是否受影响呢？https://www.cnvd.org.cn/webinfo/show/5415\n A：针对此次 Tomcat 的 AJP 协议漏洞，SOFABoot 内置的 Tomcat 默认是不会打开 AJP Connector 的，也就是说默认情况下所有版本的 SOFABoot 都是安全的。但是如果你自行打开了 AJP Connector，或者认为风险较大，可以通过覆盖 SOFABoot 管控的 Tomcat 版本进行升级，在主 pom 中的 properties section 指定 Tomcat 版本：\n\u0026amp;lt;properties\u0026amp;gt; \u0026amp;lt;!-- other properties goes here --\u0026amp;gt; \u0026amp;lt;tomcat.version\u0026amp;gt;9.0.31\u0026amp;lt;/tomcat.version\u0026amp;gt; \u0026amp;lt;!-- Tomcat 升级规则如下： - 9.x 版本升级至 9.0.31 及以上 - 8.x 版本升级至 8.5.51 及以上 - 7.x 版本升级至 7.0.100 及以上 --\u0026amp;gt; \u0026amp;lt;/properties\u0026amp;gt; SOFABoot：https://github.com/sofastack/sofa-boot\n3、@jinn 提问：\n MOSN 与 Envoy 不同点是什么？优势在哪里？\n A：简单描述一下：\n 语言栈的不同：MOSN 使用 Go 语言技能栈对于使用 Java 语言的公司和个人心智成本更低。 核心能力的差异化：  MOSN 支持多协议框架，用户可以比较容易的接入私有协议，具有统一的路由框架； 多进程的插件机制，可以通过插件框架很方便的扩展独立 MOSN 进程的插件，做一些其他管理，旁路等的功能模块扩展； 具备中国密码合规的传输层国密算法支持；    MOSN：https://github.com/mosn/mosn\nSOFAChannel 线上直播集锦  SOFAChannel#11：从一个例子开始体验轻量级类隔离容器 SOFAArk | SOFAChannel#11 直播整理 SOFAChannel#10：Seata 长事务解决方案 Saga 模式 | SOFAChannel#10 回顾 SOFAChannel#9：Service Mesh 落地负责人亲述：蚂蚁金服双十一四大考题 | SOFAChannel#9 回顾 SOFAChannel#8：从一个例子开始体验 SOFAJRaft | SOFAChannel#8 直播整理 SOFAChannel#7：自定义资源 CAFEDeployment 的背景、实现和演进 | SOFAChannel#7 直播整理 SOFAChannel#6：蚂蚁金服轻量级监控分析系统解析 | SOFAChannel#6 直播整理 SOFAChannel#5：给研发工程师的代码质量利器 | SOFAChannel#5 直播整理 SOFAChannel#4：分布式事务 Seata TCC 模式深度解析 | SOFAChannel#4 直播整理 SOFAChannel#3：SOFARPC 性能优化实践（下）| SOFAChannel#3 直播整理 SOFAChannel#2：SOFARPC 性能优化实践（上）| SOFAChannel#2 直播整理 SOFAChannel#1：从蚂蚁金服微服务实践谈起 | SOFAChannel#1 直播整理  SOFA 项目进展 本周发布详情如下：\n发布 MOSN v0.10.0 版本，主要变更如下：\n 分离部分 MOSN 基础库代码到 mosn.io/pkg； 分离部分 MOSN 接口定义到 mosn.io/api； 支持多进程插件模式； 部分代码实现细节优化； Bug Fix；  详细发布报告： https://github.com/mosn/mosn/releases/tag/v0.10.0\n社区直播预告 SOFAChannel#12 线上直播将邀请蚂蚁金服分布式事务核心开发仁空分享介绍蚂蚁金服内部的分布式事务实践，包括 TCC（Try-Confirm-Cancel） 模式以及 FMT （Framework-Managerment-Transaction，框架管理事务）模式。同时也会与大家分享在面对双十一大促这种世界级的流量洪峰前，我们又是如何应对这个挑战。\n主题：SOFAChannel#12：蚂蚁金服分布式事务实践解析\n时间：2020年3月12日（周四）19:00-20:00\n嘉宾：仁空，蚂蚁金服分布式事务核心开发\n形式：线上直播\n报名方式：点击“这里”，即可报名\n","date":1582873200,"description":"【02/24-02/28】| 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20200228/","fuzzywordcount":2000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"825d23ac19f5c5ae4cfaca517a9a87fd","permalink":"/blog/sofa-weekly-20200228/","publishdate":"2020-02-28T15:00:00+08:00","readingtime":4,"relpermalink":"/blog/sofa-weekly-20200228/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | MOSN 发布、直播系列整理、0312直播预告","type":"blog","url":"/blog/sofa-weekly-20200228/","wordcount":1939},{"author":"SOFA 团队","categories":"SOFAArk","content":" SOFA:Channel/，有趣实用的分布式架构频道。\n本文根据 SOFAChannel#11 直播分享整理，主题：从一个例子开始体验轻量级类隔离容器 SOFAArk。 回顾视频以及 PPT 查看地址见文末。欢迎加入直播互动钉钉群：23372465，不错过每场直播。\n 大家好，我是玄北，SOFAArk 开源负责人，今天跟大家分享的主题是《从一个例子开始体验轻量级类隔离容器 SOFAArk》，会跟大家一起解读 SOFAArk ，也会讲解一个 Demo 案例，希望大家可以跟我一起实际操作，体验 SOFAArk 具体操作以及功能实现。\nSOFAArk：https://github.com/sofastack/sofa-ark\n今天的分享将从一下面三个方面展开：\n 初识 SOFAArk； 组件运行时； 动手实践；  今天的重点是最后一个部分的动手实践，前面两部分会跟大家简单介绍一下 SOFAArk 的基础概念，希望在最后一个实践部分，大家可以跟着我一起通过 Demo 实际操作体验 SOFAArk，也可以在实践过程中帮助大家更好得了解前面介绍到的概念。\n一、初识 SOFAArk 现在我们就开始了解 SOFAArk，在实践之前，我们先来了解一下什么是 SOFAArk。SOFAArk 是蚂蚁金服开源的一款基于 Java 实现的轻量级类隔离容器，欢迎大家关注并 Star SOFAArk。\nSOFAArk：https://github.com/sofastack/sofa-ark\n在大型软件开发过程中，通常会推荐底层功能插件化，业务功能模块化的开发模式，以期达到低耦合、高内聚、功能复用的优点。基于此，SOFAArk 提供了一套较为规范化的插件化、模块化的开发方案。产品能力主要包括：\n 定义类加载模型，运行时底层插件、业务应用(模块)之间均相互隔离，单一插件和应用(模块)由不同的 ClassLoader 加载，可以有效避免相互之间的包冲突，提升插件和模块功能复用能力； 定义插件开发规范，提供 maven 打包工具，简单快速将多个二方包打包成插件（Ark Plugin，以下简称 Plugin）； 定义模块开发规范，提供 maven 打包工具，简单快速将应用打包成模块 (Ark Biz，以下简称 Biz)； 针对 Plugin、Biz 提供标准的编程界面，包括服务、事件、扩展点等机制； 支持多 Biz 的合并部署，开发阶段将多个 Biz 打包成可执行 Fat Jar，或者运行时使用 API 或配置中心(Zookeeper)动态地安装卸载 Biz；  SOFAArk 可以帮助解决依赖包冲突、多应用(模块)合并部署等场景问题。\nSOFAArk 中有三个最主要的概念，分别是 Ark 包、Ark Biz 包、Ark Plugin 包：\nArk 包：类似 Spring Boot 的打包产物，是一个 Fat Jar，即应用交付终态，一个 Ark 包，可以通过 Java-jar 的方式把它运行起来。\nArk Biz 包: 简称 Biz，是组件的交付终态，大家通过名字也可以理解，里面主要封装了一些业务逻辑。\nArk Plugin 包: 简称 Plugin，提供把非业务基础组件下沉的能力，比如 RPC、消息等。\n接下来按照上述三个的顺序，我们来看一下这三个包里主要是什么。\nArk 包目录结构 下图是 Ark 包的目录结构，Ark 包下有 Biz 目录，Container 目录，Plugin 目录，Biz 目录中就是一个一个的 Ark Biz，Plugin 目录保存了所有的 Ark Plugin，Container 是 Ark 容器，Ark 容器会负责启动 Ark Plugin 及 Ark Biz。\nArk Biz 包目录格式 介绍完 Ark 包的目录格式，接下来介绍 Ark Biz 包的格式：\n在 Ark Biz 包的目录格式里同样有几个比较关键的目录格式，分别是：\n application.properties：标准 Spring Boot/SOFABoot 工程配置文件； lib 目录：应用依赖目录； META-INF/MANIFEST：Biz 配置文件。  Ark Plugin 包目录结构 接下来跟大家介绍 **Ark Plugin 包，**Ark Plugin 包的目录结构与 Ark Biz 包的目录结构类似，但是 Ark Plugin 包的 META-INF/MANIFEST.MF 文件会比 Ark Biz 包复杂一点，Ark Plugin 支持在 META-INF/MANIFEST.MF 文件中定义 Import package、Export package、Import classes 以及 Export classes 等属性，这些属性支持 Plugin ClassLoader 在加载类或者资源文件时可以委托给其他 Plugin 加载。\n上文介绍了 Ark 包、Ark Biz 包、Ark Plugin 包的目录结构，接下来我们介绍下 Ark 包运行时的整个运行时结构。通过下面这张图我们可以看到，在整个运行时，Ark 包分为三层，底层是 Ark Container，中间层是 Ark Plugin，上层是 Ark Biz。Ark Container 负责启动所有 Ark Plugin 及 Ark Biz，Ark Plugin 支持类导入导出能力，所以 Ark Plugin 之间有双向箭头相互委托。为了简化 Ark Biz 的使用，Ark Biz 不支持导入导出类，Ark Biz默认会导入所有 Ark Plugin 的类。\nSOFAArk 的不同 Plugin 相互委托类加载的能力可以帮助我们解决一个文件场景，那就是依赖冲突：\n以上图的场景为例，有一个 Project，依赖了 Dependency A 以及 Dependency B，这两个依赖依赖了不同版本的 Hessian，Dependency A 依赖了 Hessian 3，Dependency B 依赖了 Hessian 4，Hessian 3 与 Hessian 4 是不兼容的，会出现冲突，那么要如何解决这个问题呢？\nSOFAArk 就给出了一个解决方案。如果我们的 Dependency A 跟 Dependency B 的 Hessian 依赖有冲突的话，我们可以把 Dependency A 作为一个整体打包成一个 Ark Plugin， Dependency B 作为一个整体打包成一个 Ark Plugin，每个 Ark plugin 都是一个单独的 Classloader，这样 Dependency A 使用的 Hessian 3 和 Dependency B 使用的 Hessian 4 将不再冲突。\n解决依赖冲突是 SOFAArk 的一个主要使用场景，但是今天我们不详细介绍这个场景，今天主要介绍 SOFAArk 的另一个能力，即组件运行时能力。\n二、组件运行时 组件运行时提供了一种能力，它能够在不重启应用的前提下，通过动态安装、卸载、切换 Biz 模块，实现修改应用运行方式的目的。下图展示了组件运行时的运行时结构，整个运行时结构与上文的 Ark 包运 …","date":1582700400,"description":"本文根据 SOFAChannel#11 直播分享整理。","dir":"blog/sofa-channel-11-retrospect/","fuzzywordcount":4400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"a3216377eb47b27325f279f124c2bfd8","permalink":"/blog/sofa-channel-11-retrospect/","publishdate":"2020-02-26T15:00:00+08:00","readingtime":9,"relpermalink":"/blog/sofa-channel-11-retrospect/","summary":"SOFA:Channel/，有趣实用的分布式架构频道。 本文根据 SOFAChannel#11 直播分享整理，主题：从一个例子开始体验轻量级类隔离容器 SOFAArk。 回顾视","tags":["SOFAArk","SOFAChannel"],"title":"从一个例子开始体验轻量级类隔离容器 SOFAArk | SOFAChannel#11 直播整理","type":"blog","url":"/blog/sofa-channel-11-retrospect/","wordcount":4360},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n**1、@朱楠 **提问：\n 请教下，我看文档上有说json可以热部署，有demo吗，没怎么看明白如何热部署  A：就是用这个回答里的这个方法 registerByResource，Java 代码的热部署可以用 SOFAArk，stateMachineEngine 是一个 bean，可以在代码里注入这个 bean，然后你可以实现一个 web 页面，可以上传 json 文件和 jar 包，调用图片中的方法注册状态机，用 SOFAArk 注册 jar 包。\n 我在看 registryByResources 这个方法的源码，注册状态机是不是就不需要修改本地的 json 文件了？\n A：注册了 json，如果数据库里有名称相同的，它会对比字节码，如果不一样，则创建新版本，一样则不注册，新启动的状态机实例用新版本，已启动的状态机实例用老的。\n 懂了，你这里说的上传 jar 包是什么意思？\n A：因为状态机里定义了要调用服务，这个服务可能是目前在系统里没有引用，所以需要上传 jar。\n2、**@刘川江 **提问：\n Seata Saga 模式服务（ServiceTask）之间如何在运行时传递业务参数？如将服务A运行后的生成的业务对象传递到后续的服务中进行处理。\n A：用 Output 和 Input 属性： Input: 调用服务的输入参数列表, 是一个数组, 对应于服务方法的参数列表, $.表示使用表达式从状态机上下文中取参数，表达使用的 SpringEL, 如果是常量直接写值即可； Ouput: 将服务返回的参数赋值到状态机上下文中, 是一个 map 结构，key 为放入到状态机上文时的 key（状态机上下文也是一个 map），value 中$.是表示 SpringEL 表达式，表示从服务的返回参数中取值，#root 表示服务的整个返回参数。\n 是否支持根据业务参数中的某些值作为条件判断状态机中的服务（ServiceTask）是否执行？\n A: 支持的，可以用 Status 属性来判断 Service 是否执行成功。 Status: 服务执行状态映射，框架定义了三个状态，SU 成功、FA 失败、UN 未知, 我们需要把服务执行的状态映射成这三个状态，帮助框架判断整个事务的一致性，是一个 map 结构，key 是条件表达式，一般是取服务的返回值或抛出的异常进行判断，默认是 SpringEL 表达式判断服务返回参数，带 $Exception{ 开头表示判断异常类型。value 是当这个条件表达式成立时则将服务执行状态映射成这个值。\n 是否支持状态机中的部分服务开启事务。如状态机配置了服务流程A-\u0026amp;gt;B-\u0026amp;gt;C，只在服务B和C上开启分布式事务。\n A：可以，比如 A 是一个查询类的服务，可以将 A 设置成 IsForUpdate=false，如果这个服务不想记录执行日志，可以设置这个服务为 IsPersist=false。\nSeata：https://github.com/seata/seata\n**3、@SUNBIAO **提问：\n 请问 SOFA 消费者端可以同时配置多个注册中心嘛？例如一个 web 控制器接入端当作消费者，配置连接多个注册中心，订阅不同注册中心上的生产者服务，但是这个消费者端不同的具体消费者调用不同注册中心的服务，前提是注册中心不能合成一个，现实有多个不同的注册中心。\n A：可以的，可以看这个类 com.alipay.sofa.rpc.config.AbstractInterfaceConfig#registry， 是个 list。\nSOFARPC：https://github.com/sofastack/sofa-rpc\n4、**@七美 **提问：\n SOFATracer 目前落盘的摘要 log 是固定格式的，能否直接以 zipkin 的 json 数据格式落盘？如果可以如何操作？\n A：使用自定义 reporter ： https://www.sofastack.tech/projects/sofa-tracer/reporter-custom/ + ZipkinV2SpanAdapter 来实现。\nSOFATracer：https://github.com/sofastack/sofa-tracer\n每周读者问答提炼  蚂蚁金服研发框架日志隔离解析 | SOFABoot 框架剖析 蚂蚁金服研发框架总览 | SOFABoot 框架剖析  SOFA 项目进展 本周发布详情如下：\n1、发布 Seata v1.1.0 版本，主要变更如下：\n 支持 postgreSQL； 支持自定义 Saga 恢复策略超时时间； 支持 Saga 模式跳过成功分支事务的 report； 支持httpClient 自动集成；  详情发布报告：https://seata.io/zh-cn/blog/download.html\n2、发布 SOFARPC v5.6.4 版本，主要变更如下：\n 试验性支持 RPC 可能的多版本发布； 升级 Dubbo 依赖版本到2.6.7； 优化 gRPC 支持代码； 升级 Netty 版本4.1.44.final，解决安全问题； 修复 Tracer 采样兼容问题； 修复注册中心虚拟端口的问题；  详细发布报告：https://github.com/sofastack/sofa-rpc/releases/tag/v5.6.4\n3、发布 SOFABoot v3.3.0 版本，主要变更如下：\n 健康检查页面显示组件的具体绑定类型； RPC XML 超时配置支持字符串变量； 修复无法使用 zk 以外注册中心的 bug； 修复控制台大量输出的 bug； 升级 Spring Boot 依赖版本至 2.1.11.RELEASE； 升级 RPC 版本至 5.6.4； 升级 sofa-common-tools 版本至 1.0.21；  详细发布报告：https://github.com/sofastack/sofa-boot/releases/tag/v3.3.0\n4、发布 sofa-common-tools v1.0.21 版本，主要变更如下： …","date":1582268400,"description":"【02/17-02/23】| 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20200221/","fuzzywordcount":2700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"b82b9b4c82bc3905d736962bd157238c","permalink":"/blog/sofa-weekly-20200221/","publishdate":"2020-02-21T15:00:00+08:00","readingtime":6,"relpermalink":"/blog/sofa-weekly-20200221/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | 3/12直播预告、SOFARPC、SOFABoot 组件发布","type":"blog","url":"/blog/sofa-weekly-20200221/","wordcount":2641},{"author":"盲僧","categories":"SOFABoot","content":" SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级云原生架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。\n 本文为《剖析 | SOFABoot 框架》第二篇，本篇作者盲僧，来自遨游酒店信息技术。《剖析 | SOFABoot 框架》系列由 SOFA 团队和源码爱好者们出品，项目代号：SOFA:BootLab/，文章尾部有参与方式，欢迎同样对源码热情的你加入。\nSOFABoot 是蚂蚁金服开源的基于 SpringBoot 的研发框架，提供了诸如 Readiness Check、类隔离、日志空间隔离等能力，用于快速、敏捷地开发 Spring 应用程序，特别适合构建微服务系统。\n本文将从 Java 的日志体系谈起，对 JCL、SLF4J 两个经典的日志框架做一个阐述，引出 SOFABoot 开源的日志隔离框架 sofa-common-tools ，并且有实战 Demo，能够帮助我们快速上手和了解这款框架的使用和作用，最后从源码角度对其进行分析，不仅知其然，还要知其所以然。\nSOFABoot ：https://github.com/sofastack/sofa-boot\nsofa-common-tools ：https://github.com/sofastack/sofa-common-tools\nJava 日志问题 业务开发对日志的选择 众所周知，Java 的日志体系非常复杂，有 Log4j、Log4j2、Logback、JUL 等实现，这么多的日志实现让开发人员在选择上不得不犯晕，因为每个日志实现都对外提供了不同的 API，而且还要担心与项目中现有的第三方框架依赖的日志实现产生冲突问题，甚至还要去维护第三方框架带来的日志依赖。在这些问题的基础上，Java 日志框架应运而生，典型的有 JCL 和 SLF4J。\nJCL JCL 即 Apache Commons Logging，它的原理是提供了一套接口，用户使用了它的接口进行编程，具体实现交由它的 LogFactoryImpl 去动态查找， 但是它并不能绑定所有的日志实现，因为查找绑定的日志实现是放在 classesToDiscover 数组里写死的，导致扩展起来比较麻烦，当前最新版本是 1.2 版本，还不支持绑定 Log4j2 和 Logback。\nSLF4J 于是乎，大名鼎鼎的 SLF4J 出现了，它的存在就是为了替换 JCL，所以肯定提供了比 JCL 更强大的功能。同样是面向接口编程的设计，但是 SLF4J 充分考虑到了后期的扩展问题：一旦市面上有新的日志实现，那么只需要提供新的绑定包即可，相对于 JCL 的动态绑定，SLF4J 实际上是静态绑定，因为应用程序具体要选用哪种日志组件是由开发人员使用哪个绑定包决定的。绑定原理请看下图：\n除此之外，SLF4J 还提供了桥接包，它的意思是指可以把使用某个具体 Log 组件的 API 重定向到 SLF4J 的 API 里（前提需要排除具体实现包，然后引入桥接包），然后 SLF4J 会根据具体的绑定包输出内容，从而达到多种日志实现统一输出的目的。绑定原理请看下图：\n中间件对日志的选择 上面解决了业务开发人员的问题，那么对于从事中间件的开发者来说呢？日志依旧是一个痛点。参考一些中间件项目，如 zookeeper 使用的是 log4j ，hibernate-validator 使用的是 jboss-logging，当业务开发人员去集成这些第三方组件时，就会感到头疼，因为这些组件的日志实现很有可能会和当前业务自身的日志依赖产生冲突。常用的解决方法就是排除某一种日志实现依赖，然后修改 appender 和 logger 达到日志隔离。但这并不是一个一劳永逸的方法，因为每次引入新的 jar 包，你都需要考虑是否有日志冲突。\n那么市面上是否有成熟的框架来解决这个问题呢？当然是有的，蚂蚁金服开源的 SOFABoot 就提供了这样的功能，底层主要是通过 sofa-common-tools 实现的。那么 sofa-common-tools 又是个啥呢？借用官网的描述： sofa-common-tools 是 SOFAStack 中间件依赖的一个通用工具包，通过自动感知应用的日志实现，提供中间件与应用隔离的日志空间打印能力。\n本篇将通过一个案例 demo 先来直观的体验下 sofa-common-tools 所能解决的问题，然后再在此基础上，通过源码解析了解其内部的具体实现原理，以帮助大家更好的认识和了解 sofa-common-tools 这个“小而美”的日志工具包。\n日志隔离实战  完整项目已经上传到 https://github.com/masteryourself/study-sofa.git ，工程是 study-sofa-common-tools\n 有这样一个场景：公司的中间件团队做了一款 middleware-apm 监控系统，并且通过以输出日志的方式向监控系统提供基础数据。由于公司并没有制定统一的日志规范，各个业务方所使用的日志也是千差万别；如：如订单系统使用的是 log4j，账务系统用的 Logback，用户中心用的是 Log4j2； 如果期望 apm 提供的日志输出和业务的不冲突，可以独立的并且完整的兼容业务日志的不同实现，此时便可以使用 SOFABoot 提供的日志隔离框架；其可以帮助我们解决日志实现冲突、日志文件隔离以及动态调试日志级别等功能。下面就先来看下 apm 是如何使用 sofa-commons-tools 来实现的。\nmiddleware-apm 项目 新建 middleware-apm 工程，然后执行 mvn clean install 命令，安装到本地仓库。具体代码可以参考 middleware-apm ，下面对一些核心代码进行简单的说明和分析。代码结构如下：\n日志资源文件配置 这里主要是在 pers.masteryourself.study.sofa.apm.log 目录下创建 log4j、log4j2、logback 的配置文件，详情请参考 github 链接。\n核心日志工厂类-ApmLoggerFactory ApmLoggerFactory 主要是对外提供获取 Logger 实例的 API 方法，其作用类似于 slf4j 中的 LoggerFactory 类；对于想使用 SOFABoot 日志特性的类，只要使用它调用 getLogger 方法获得的 Logger 实例即可。\nLoggerFactory 和 ApmLoggerFactory 的最本质区别在于 ApmLoggerFactory 引入了 LOG_SPACE 的概念。\npublic class ApmLoggerFactory { // 日志空间  private static final String APM_LOG_SPACE = \u0026amp;#34;pers.masteryourself.study.sofa.apm\u0026amp;#34;; static { if …","date":1582016400,"description":"本文将从 Java 的日志体系谈起，对 JCL、SLF4J 两个经典的日志框架做一个阐述，引出 SOFABoot 开源的日志隔离框架 sofa-common-tools，并且有实战 Demo，能够帮助我们快速上手和了解这款框架的使用和作用，最后从源码角度对其进行分析，不仅知其然，还要知其所以然。","dir":"blog/sofa-boot- log-isolation/","fuzzywordcount":4700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"a428e36a94180c1e33920579423b4402","permalink":"/blog/sofa-boot-log-isolation/","publishdate":"2020-02-18T17:00:00+08:00","readingtime":10,"relpermalink":"/blog/sofa-boot-log-isolation/","summary":"SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级云原生架构，包含了构建金融级云原生架构所需的各个组件，是在金","tags":["SOFABoot","剖析 | SOFABoot 框架","SOFALab"],"title":"蚂蚁金服研发框架日志隔离解析 | SOFABoot 框架剖析","type":"blog","url":"/blog/sofa-boot-log-isolation/","wordcount":4626},{"author":"SOFA 团队","categories":"Service Mesh","content":"2020 年 2 月 4 日到 2 月11 日，ServiceMesher 社区发起了 Service Mesh 终端用户调查，以下为问卷调查结果。\n参与问卷调查的人员情况 共收集到 516 份问卷结果，问卷填写者 94.2% 来自 ServiceMesher 社区，21.7% 的人参与过社区线上活动，27.5% 的人参与过社区 meetup，86.6% 看好 Service Mesh 的未来发展前景。\n下面是参与问卷调查人员的基本情况。\n公司所属行业\n所在公司的 Service Mesh 使用情况\n工作年限\n在公司中担任的职务\n关注 Service Mesh 技术的时长\n周围关注或了解 Service Mesh 技术的人员情况\n学习 Service Mesh 技术的方式\n关注的 Service Mesh 相关开源项目\n除了 Service Mesh 外关注的其他云原生领域\n对 Service Mesh 的了解程度\n关注 Service Mesh 技术中的哪部分\n社区参与 了解社区活动的情况\n对社区的建议\n还有很多对社区的建议，反馈比较多的如下：\n 更多落地实践和指南 发布一些入门级的文章，结合案例，让技术在中小企业中落地 组织一些线上或线下活动 对普通开发者的职业发展的建议 出系列教程  结论 从结果中可以看出，Service Mesh 在互联网公司中关注的比例最高，但是它仍然还在高速发展中，还缺乏完善的教程和案例。\n本次问卷调查旨在了解 ServiceMesher 社区成员对 Service Mesh 的了解及社区参与程度，帮助 ServiceMesher 社区做的更好，还需要社区成员们共同的努力。\n欢迎关注 Service Mesh 技术的小伙伴们加入 ServiceMesher 社区，共同交流学习和成长。\n关于本次调查问卷的最终解释权归 ServiceMesher 社区所有。\n","date":1581667200,"description":"2020 年 2 月 4 日到 2 月11 日，ServiceMesher 社区发起了 Service Mesh 终端用户调查，以下为问卷调查结果。","dir":"service-mesh-end-user-survey-report/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"894b42fb32c6c3c39986e020fd53a13e","permalink":"/service-mesh-end-user-survey-report/","publishdate":"2020-02-14T16:00:00+08:00","readingtime":2,"relpermalink":"/service-mesh-end-user-survey-report/","summary":"2020 年 2 月 4 日到 2 月11 日，ServiceMesher 社区发起了 Service Mesh 终端用户调查，以下为问卷调查结果。 参与问卷调查的人员情况 共收集到 516 份问卷结","tags":["Service Mesh"],"title":"Service Mesh 终端用户调查报告","type":"page","url":"/service-mesh-end-user-survey-report/","wordcount":530},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@乘疯破浪 提问：\n 咨询一个性能问题，一个 2C 的业务场景：本地库操作多次 db，再调用分布式服务，再 TC 端注册多个分支事务耗时较多，用户 C 端等待时间较长，这种问题有处理方案吗？client 已设置 report 分支状态 =false。\n A：确实比较长，个人建议从架构入手去改良，可以通过存入 redis 等一个消息，告诉用户正在插入-\u0026amp;gt;然后一步出力业务，出现异常同样 redis 里的信息改为异常。如果成功就为成功存储 id 或者其它看业务具体情况,然后用户端页面做个倒计时，或者转圈圈，或者直接告诉他正在插入稍等。比如以前用 MQ 削峰就差不多是这个思路吧。长事务尝试用用 Saga、AT 上手快，但是因为锁的存在，效率比较低，后续会逐步优化，性能高入侵也高的 TCC 如果能尝试也可以试试。\n2、@孟昊 提问：\n 请问一下，我今天看了一下文档，好像 cloud 通过 feign 调用方式只能使用 AT 模式, 在并发量比较高的场景下会有问题么(小事务)。\n A：微服务框架跟分布式事务模式没有绑定，还可以用 TCC、Saga。Saga 目前理论上支持所有 RPC 框架，只要是个 bean 即可。\n3、@小孟 提问：\n MOSN 是否支持了 Dubbo 协议？\n A：MOSN 在本周已通过 x-protocol 支持了 Dubbo 和 Tars 协议，具体可见： https://github.com/mosn/mosn/pull/950\n4、关于线上直播 SOFAChannel#11：从一个例子开始体验轻量级类隔离容器 SOFAArk 提问回答\n直播视频回顾：https://tech.antfin.com/community/live/1096\n@鸿关 提问：\n 用 SOFAArk 的话，能直接集成到 SOFABoot 工程不？还是说必须要建个 SOFAArk 的工程？SOFAArk 可以运用于非 SOFABoot 的项目么？\n A： 能直接继承到 SOFABoot 工程，不需要新建 SOFAArk 工程，也可以用于非 SOFABoot 工程，只要是 Spring Boot 工程即可，但是不引入 SOFA 相关依赖的话，@SofaService 及 @SofaReference 等注解就没法用了。\n@盲僧 提问：\n 运行期间安装 biz，然后激活模块这一过程做了哪些事情 ，如果这个 biz jar 包放在远程仓库怎么加载里面的代码呢？是拉下来放到本地的一个磁盘用 classloader 去加载使用吗？\n A：安装和激活是的两个操作，安装支持两种协议获取 biz 包：http 和 file，激活只是在内部调整了同 biz 不同版本的状态。\n 运行期间安装 biz 后，那个 execute jar 包里会有这个 biz 包吗？ A：可以尝试用插件打个包出来解压看下哦。\n @曾鹏 提问：\n SOFAArk 有什么实际的应用场景吗？\n A：可以看下这个：蚂蚁金服轻量级类隔离框架概述 | SOFAArk 源码解析\nSOFAArk：https://github.com/sofastack/sofa-ark\n本周推荐阅读  SOFAStack Community | 欢迎加入 蚂蚁金服研发框架总览 | SOFABoot 框架剖析  SOFA 项目进展 本周发布详情如下：\n1、发布 SOFATracer v2.4.5/3.0.9 版本，主要变更如下：\ni. 默认禁用上报数据到zipkin, 需要显式设置 com.alipay.sofa.tracer.zipkin.enabled=true 才能开启； 详细发布报告： https://github.com/sofastack/sofa-tracer/releases/tag/v2.4.5 https://github.com/sofastack/sofa-tracer/releases/tag/v3.0.9\n2、发布 SOFATracer v2.4.6v/v3.0.10 版本，主要变更如下：\ni. 支持使用 JVM系统属性 或 环境变量 SOFA_TRACER_LOGGING_PATH 来定制 tracelog 的路径 详细发布报告： https://github.com/sofastack/sofa-tracer/releases/tag/v2.4.6 https://github.com/sofastack/sofa-tracer/releases/tag/v3.0.10\n社区直播预告 本期为 SOFAChannel 线上直播第 12 期，将邀请蚂蚁金服分布式事务核心开发仁空分享《蚂蚁金服分布式事务实践解析》。\n软件开发模式从原来的单应用，到现在的微服务、分布式架构，一个大型分布式系统内，单业务链路往往需要编排多个不同的微服务，如何实现分布式场景下业务一致性，是摆在软件工程师面前的一个技术难题。\n本期分享将介绍蚂蚁金服内部的分布式事务实践，包括 TCC（Try-Confirm-Cancel） 模式以及 FMT （Framework-Managerment-Transaction，框架管理事务）模式。同时也会与大家分享在面对双十一大促这种世界级的流量洪峰前，我们又是如何应对这个挑战。\n主题：SOFAChannel#12：蚂蚁金服分布式事务实践解析\n时间：2020年3月12日（周四）19:00-20:00\n嘉宾：仁空，蚂蚁金服分布式事务核心开发\n形式：线上直播\n报名方式：点击“这里”，即可报名\n","date":1581667200,"description":"【02/10-02/14】| 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20200214/","fuzzywordcount":1800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"3deaf12dd1b6589f41c57291d9061534","permalink":"/blog/sofa-weekly-20200214/","publishdate":"2020-02-14T16:00:00+08:00","readingtime":4,"relpermalink":"/blog/sofa-weekly-20200214/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | 2/13直播回顾、3/12直播预告、SOFATracer 发版","type":"blog","url":"/blog/sofa-weekly-20200214/","wordcount":1781},{"author":"潘潘","categories":"SOFAChannel","content":"概要   活动主题：SOFAChannel#12：蚂蚁金服分布式事务实践解析\n  活动时间：3 月 12 日周四晚 7 点\n  活动形式：线上直播\n  直播回顾：戳这里\n  介绍 | SOFAChannel \u0026amp;lt;SOFA:Channel/\u0026amp;gt; 有趣实用的分布式架构频道，前沿技术、直播 Coding、观点“抬杠”，多种形式。\n\u0026amp;lt;SOFA:Channel/\u0026amp;gt; 将作为 SOFA 所有在线内容的承载，包含直播/音视频教程，集中体现 SOFAStack 的能力全景图。\n| SOFAChannel#12：蚂蚁金服分布式事务实践解析 软件开发模式从原来的单应用，到现在的微服务、分布式架构，一个大型分布式系统内，单业务链路往往需要编排多个不同的微服务，如何实现分布式场景下业务一致性，是摆在软件工程师面前的一个技术难题。\n蚂蚁金服作为一家金融科技公司，业务涉及金融核心的各个领域，从2007年开始就自主研发了分布式事务框架，解决跨数据库、跨服务的业务一致性问题；随着13来年的不断打磨和沉淀，历经双十一、双十二等大促的洗礼，如今所有核心业务都已经在使用这套框架来保障交易的完整性和最终一致性，做到知托付，让用户放心。\n本期分享将介绍蚂蚁金服内部的分布式事务实践，包括 TCC（Try-Confirm-Cancel） 模式以及 FMT （Framework-Managerment-Transaction，框架管理事务）模式。同时也会与大家分享在面对双十一大促这种世界级的流量洪峰前，我们又是如何应对这个挑战。\n本期为 SOFAChannel 线上直播第 12 期，将邀请蚂蚁金服分布式事务核心开发仁空分享《蚂蚁金服分布式事务实践解析》。\n| 加入 SOFA 钉钉互动群 欢迎加入直播互动钉钉群：23372465（搜索群号加入即可）\n| 点击即可报名 https://tech.antfin.com/community/live/1096\n议程 19:00-19:05 主持人开场 SOFAGirl 主持人\n19:05-20:00 蚂蚁金服分布式事务实践解析 仁空，蚂蚁金服分布式事务核心开发\n本期分享大纲  分布式事务产生的背景； 蚂蚁金服分布式事务理论与实践；  TCC 模式 FMT 模式   蚂蚁金服分布式事务极致性能提升； 蚂蚁金服分布式事务开源与展望；  嘉宾  SOFAGirl 主持人 仁空，蚂蚁金服分布式事务核心开发  ","date":1581498000,"description":"3 月 12 日周四晚 7 点，线上直播第 12 期。","dir":"activities/sofa-channel-12/","fuzzywordcount":800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"c80a24fd4e76747f0ed57c139a2bfae9","permalink":"/activities/sofa-channel-12/","publishdate":"2020-02-12T17:00:00+08:00","readingtime":2,"relpermalink":"/activities/sofa-channel-12/","summary":"概要 活动主题：SOFAChannel#12：蚂蚁金服分布式事务实践解析 活动时间：3 月 12 日周四晚 7 点 活动形式：线上直播 直播回顾：戳这里 介绍 | SOFAChannel","tags":["SOFAChannel","分布式事务"],"title":"SOFAChannel#12：蚂蚁金服分布式事务实践解析","type":"activities","url":"/activities/sofa-channel-12/","wordcount":784},{"author":"纶珥","categories":"SOFALab","content":" SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级云原生架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。\n 本文为《剖析 | SOFABoot 框架》第一篇，本篇作者纶珥，来自蚂蚁金服。《剖析 | SOFABoot 框架》系列由 SOFA 团队和源码爱好者们出品，项目代号：SOFA:BootLab/，文章尾部有参与方式，欢迎同样对源码热情的你加入。\nSOFABoot 是蚂蚁金服开源的基于 SpringBoot 的研发框架，提供了诸如 Readiness Check、类隔离、日志空间隔离等能力，用于快速、敏捷地开发 Spring 应用程序，特别适合构建微服务系统。\nSpringBoot 基于 Spring 的按条件配置（Conditional Configuration），结合 starter 依赖机制提供了快捷、方便开发 Spring 项目的体验，获得了极大的成功；SOFABoot 同样在这两个能力上基于 SpringBoot 扩展出适应于金融级应用开发框架。作为脱胎于蚂蚁金服内部对于 SpringBoot 的实践，SOFABoot 补充了 SpringBoot 在大规模金融级生产场景下一些不足的地方，例如 Readiness 检查、类隔离和日志空间隔离等等能力。在增强了 SpringBoot 的同时，SOFABoot 还提供了让用户可以在 SpringBoot 中非常方便地使用 SOFAStack 中间件的能力。\nSOFABoot ：https://github.com/sofastack/sofa-boot\n功能点概览 SOFABoot 完全兼容 SpringBoot，SpringBoot 技术栈可以快速切换到 SOFABoot 技术栈：修改项目 pom 依赖的 \u0026amp;lt;parent/\u0026amp;gt; 节点，例如将：\n\u0026amp;lt;parent\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-starter-parent\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${spring.boot.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;relativePath/\u0026amp;gt; \u0026amp;lt;/parent\u0026amp;gt; 替换为：\n\u0026amp;lt;parent\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofaboot-dependencies\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${sofa.boot.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/parent\u0026amp;gt; 当前 SOFABoot 的最新版本为 v3.2.2。\n应用 Readiness 检查 一个应用启动之后，是否是“准备”好能够处理外部请求呢？作为应用流量入口的组件是否可以接收外部连接？这就很有必要引入应用 Readiness 的检查，SOFABoot 提供除 SpringBoot 健康检查之外的应用 Readiness 检查能力，保证应用组件的正常启动、应用安全上线。\nSOFABoot 通过 HealthChecker 检查各组件的 ready 情况。在 Spring 上下文刷新完成之后（所有的 Spring Bean 已经实例化完成），SOFABoot 会获取 IoC 容器中所有的 HealthChecker 实现类，检查其返回的组件健康状况；在应用开启了模块化隔离之后，模块 HealthChecker 还会 kicks in，检查模块的健康状况。Spring 原生的 HealthIndicator 作为 Readiness 的一部分也会纳入 Readiness 的结果中，若 HealthIndicator 出现了失败的情况，那么应用的 Readiness 也是不通过。\nReadiness 检查包含组件的后置检查，流量入口组件（例如：RPC、REST）需要保证后置检查通过之后能接受外部流量的请求，应用才是真正 ready 了。\n应用 Readiness 与 Liveliness 不同的是 Readiness 表示的是应用启动完成之后是否“准备”好的状态，启动完成之后是不变的；两次部署间的 Readiness 的所有请求结果是一致的。\n应用模块化 应用模块化的方案多种多样。传统方案是以应用功能为边界做模块划分；研发期间，不同职责的类放在不同的模块下，但在运行期间都在同一个 classpath 下，没有任何隔离。而与传统的模块划分方案不同，人们发现可以利用 Java 的 ClassLoader 机制，将模块与模块间的类完全隔离；当某个模块需要与另一个模块通信时，可以通过类的导入和导出来实现。OSGi 和 SOFAArk 都是基于 ClassLoader 隔离的模块化实践方案。\n传统的模块化方案没有任何的隔离手段，模块间的边界得不到保障，容易出现模块间的紧耦合；而基于 ClassLoader 的模块化方案则过于彻底，研发人员必须十分清楚类的导入与导出、Java 的类加载体系，模块划分的负担转嫁到了普通研发人员身上。\nSOFABoot 综合以上两种方案的利弊，引入了介于两者之间的模块化方案：每个模块有独立的 Spring 上下文，通过上下文的隔离，让不同模块之间的 Bean 的引用无法直接进行，达到模块在运行时的隔离。这样既保证了不引入过多的复杂性，也避免了没有任何隔离措施的模块边界保障。如下图所示：\n所有的 SOFABoot 模块都会有一个相同的 Spring Context 的 Parent，称之为 Root Application Context。对于所有模块都需要引入的 Bean，可以选择将其放置于 Root Application Context 中，在所有的模块间共享。此外，SOFABoot 框架提供两种 Spring 上下文隔离方案后的模块间通信能力：\n JVM 服务的发布和引用：同一个应用内不同模块间的通信  // Publish a JVM service @Component @SofaService public class MyServiceImpl implements MyService { // implementation goes here } // Reference a JVM service public class AnyClass { @SofaReference private MyService myService; }  RPC 服务的发布和引用：不同应用间的通信  // Publish a RPC service @Component @SofaService(interfaceType = MyService.class, bindings = { …","date":1581321600,"description":"本文为《剖析 | SOFABoot 框架》第一篇，主要介绍 SOFABoot 的基础特效。","dir":"blog/sofa-boot-overview/","fuzzywordcount":3300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"d1a5fa7654f26a159c65061d4f7712d7","permalink":"/blog/sofa-boot-overview/","publishdate":"2020-02-10T16:00:00+08:00","readingtime":7,"relpermalink":"/blog/sofa-boot-overview/","summary":"SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级云原生架构，包含了构建金融级云原生架构所需的各个组件，是在金","tags":["SOFALab","剖析 | SOFABoot 框架","SOFABoot"],"title":"蚂蚁金服研发框架总览 | SOFABoot 框架剖析","type":"blog","url":"/blog/sofa-boot-overview/","wordcount":3215},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n**@张一心 **提问：\n 建议 Seata 全局加锁时候支持快速抢占机制，在不同重要程度事务处理中优先满足重要业务的加锁处理以优先保证紧急重要逻辑的处理，实现方式有多种的，可以根据情况直接回滚干掉非紧急事务也可以在等待加锁队列中做插队处理。\n A：不是通用场景，这个不是通过 API 来实现，后续添加控制台后，在控制台页面对活动事务可以进行控制，可单个事务降级或 redo。\n 之前我是通过改造其值来源于 Nacos 配置的全局事务注解完成的，有了单独事务控制台能起到各司其职更好，既然后续补充了控制台，是不是事务处理的各类统计也能在控制台上面看得到，作为一系列资源分配的参考指标。\n A：控制台主要包括监控统计和事务控制介入，你说的应该是动态降级，这个是全局的，细化不到刚才说的那种抢占机制比如手动在控制台的具体某个事务进行降级释放锁，直接通过 API 这个数据破坏性无法控制，对于这种需要人工去介入并且有 trace。\n 实际生产中涉及金钱交易的优先级往往高于非金钱交易的优先级。破坏性来源主要是加锁中的破坏性回滚，实际业务中往往会存在不能锁刚好被加在队列中等待一阵的现象，这时候完全可以根据全局标记做全局性插队，在处理中加快相关业务处理。监控粒度不应该忽视锁的名称，全局业务的加锁顺序和持有时间，不然当业务量大且相互交叉发生全局性死锁也是会存在的。确切说是业务量大并且分布在不同 TC 上加锁情况下可能会产生哲学家就餐问题带来的死锁。\n A：这里不存在死锁，先拿的是数据库的 X 锁，在拿的是全局锁，你可以举个栗子。一种优先级是处理前优先级类似于 mq 的优先级队列，这种是哪个事务优先被处理，这种是需要兼顾顺序和锁优先级排序，高优先级事务分支优先被处理。 一种是处理中的锁被剥夺，这种是破坏性的，如果在一个不重要的事务中分支1执行完成，另外一个重要事务请求分支1同样的锁，这个锁这时可被剥夺，不重要事务释放锁降级非分布式事务。大多数冲突的情况应该属于处理中而不是处理前。\n 根据测试经验，量小的时候会等，量大的时候会直接碰撞，量进一步加大则除了碰撞而且跑队列里一起挤挤的概率就会飙上去。这时候会遇到几个难点，1队列下是不是插队（这个通过认为设置比较好解决）2抢占是否必要，这时候需要通过对之前加锁的统计（包括业务处理时间与网络通信等综合指标）和潜在破坏性做评估，如果破坏性较小或无且不抢占下对业务预等待时间较长且其他回滚表较为独立则直接回滚抢占，最典型场景就是扣钱的时候充值，或者出货的时候补货。\n A：第2中的破坏性来源于不重要事务锁被剥夺降级为非分布式事务，但是由于后续事务分支出现异常，会导致这个事务分支无法参与回滚，若参与回滚必会导致重要事务全局回滚时数据校验不通过而无法回滚。\n 对，校验不通过关键在于目前采用的是全量型业务，而不是基于对 sql 语句解析之后的增量型业务（即 TCC 的 cancel 步骤里反向对冲）。\n A：对于 AT 模式都是基于数据的不是基于 sql 的，与 binlog 同步方式类型同理。\n 下面问题来了，数据破坏是因为先去 TC 报道还是先去数据库加锁造成的。如果先去 TC 报道，等报道成功再去 DB 加锁就不会发生数据破坏的问题，因为报道失败就直接返回了不会对 DB 造成影响。\n A：那个锁的范围更大些，肯定是 DB 的 X 锁。服务是操作 DB 的，如果连 DB 锁拿不到，拿全局锁有什么意义，假设先拿全局锁，数据库锁拿不到时是不是又需要 RPC 去释放全局锁？\n 不知道有没必要添加对全局读写锁的支持，这个个人未实践过，纯属个人观点，也不知道现在是否已经实现了？\n A：这个说的是类似 JUC 的读写锁嘛？如果单纯这样没什么实际意义，现在是类似数据库 select for update 的 X 锁上升到全局锁。\nService Mesh 大规模落地系列  蚂蚁金服 Service Mesh 大规模落地系列 - 质量篇 蚂蚁金服 Service Mesh 大规模落地系列 - 控制面篇 蚂蚁金服 Service Mesh 大规模落地系列 - Operator 篇 蚂蚁金服 Service Mesh 大规模落地系列 - 网关篇 蚂蚁金服 Service Mesh 大规模落地系列 - RPC 篇 蚂蚁金服 Service Mesh 大规模落地系列 - 运维篇 蚂蚁金服 Service Mesh 大规模落地系列 - 消息篇 蚂蚁金服 Service Mesh 大规模落地系列 - 核心篇 Service Mesh 落地负责人亲述：蚂蚁金服双十一四大考题  SOFA 项目进展 本周发布详情如下：\n1、发布 Occlum v0.9.0 版本，主要变更如下：\n 引入嵌入模式； 升级 SGX SDK 依赖到最新版； 大幅提升网络 I/O 的性能； 正式支持 Python 语言的应用； 正式支持 Ubuntu 18.04 和 CentOS 7.2； 修复了多个 bug；  详细发布报告： https://github.com/occlum/occlum/releases/tag/0.9.0\n社区直播预告 春节后直播预告来啦～本期为 SOFAChannel 线上直播第 11 期，将从 SOFAArk 的特性出发，了解轻量级类隔离容器 SOFAArk 的主要功能，并通过一个 Demo 案例，跟讲师一起操作，实际体验 SOFAArk 具体操作以及功能实现。\nSOFAArk 是一款基于 Java 实现的轻量级类隔离容器，主要提供类隔离和应用(模块)合并部署能力，由蚂蚁金服公司开源贡献。截止 2019 年底，SOFAArk 已经在蚂蚁金服内部 Serverless 场景下落地实践，并已经有数家企业在生产环境使用 SOFAArk ，包括网易云音乐、挖财、溢米教育等。\n主题：SOFAChannel#11：从一个例子开始体验轻量级类隔离容器 SOFAArk\n时间：2020年2月13日（周四）19:00-20:00\n嘉宾：玄北，蚂蚁金服技术专家 SOFAArk 开源负责人\n形式：线上直播\n报名方式：点击“这里”，即可报名\n","date":1581066000,"description":"【02/03 - 02/07】 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20200207/","fuzzywordcount":2300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"4e10f9b05976b3f0f8ce4d9128fa8d79","permalink":"/blog/sofa-weekly-20200207/","publishdate":"2020-02-07T17:00:00+08:00","readingtime":5,"relpermalink":"/blog/sofa-weekly-20200207/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | Service Mesh 落地系列文章、2/13直播预告","type":"blog","url":"/blog/sofa-weekly-20200207/","wordcount":2292},{"author":"柑橘、西经、柏翘","categories":"Service mesh","content":"本文为《蚂蚁金服 Service Mesh 大规模落地系列》最后 一篇 - 质量篇，该系列从核心、RPC、消息、无线网关、控制面、安全、运维、测试等模块对 Service Mesh 双十一大规模落地实践进行详细解析。文末包含往期系列文章。\n前言 Service Mesh 在蚂蚁金服内部已经大规模落地，经历刚刚双十一的检阅，将现有的体系快速演进至 Service Mesh 架构，无异于给飞机换发动机。本主题主要分享在蚂蚁金服当前的体量下，我们如何做到给飞机换发动机，还确保不出问题。同时在 Mesh 对外客户输出同样有高质量的保障。\n本文结合蚂蚁金服 Mesh 化落地质量保障落地的思考，给大家带来如下三个方面的一些质量保障的分享：\n Mesh 化质量保障体系； Mesh 化测试技术； Mesh 化双十一大规模落地的性能保障；  质量保障体系 首先给大家介绍下我们的质量保障体系。\n测试保障体系\n我们从测试环境、测试用例、基础功能测试原子镜像能力、测试工具平台、测试场景组合调度、测试方案制定、线上巡检监控、灰度发布三板斧、交付验证、性能、自动化测试等多个方面进行系统性测试保障。通过内外部的质量数据度量和双十一大促来检阅我们的质量能力。\nMesh 测试技术 在开始介绍测试技术之前，我们先了解一下什么是 Service Mesh 以及 Service Mesh 是如何工作的，在蚂蚁金服的技术架构中是以什么形式存在，发挥着怎样的作用。\n简单的说 Service Mesh 存在两个面，一个面叫数据面（比如 MOSN），就是处理应用数据请求的一个独立代理模块，脱离于应用，为应用提供请求代理及一些复杂通信逻辑处理，另外一个叫控制面（比如 SOFAMesh），管理应用配置及业务规则等（比如业务开关/服务路由规则），通过下发配置“指挥”数据面去执行，满足不同阶段实现不同的业务支持。\nMesh 框架简图\n我们先简单介绍下经典微服务请求路由。\n经典微服务模式请求路由\n经典微服务模式下 Docker 镜像化服务在一个 Pod 一般只有一个业务应用容器在运行，这种情况下测试框架只要关心业务应用即可。\n经典微服务测试架构\nMesh 测试架构改进 Mesh 测试架构在经典微服务测试架构上也做了新的演进。MOSN 作为 Sidecar 与业务容器共存在一个 Pod，资源与业务应用容器共享，每个业务逻辑都需要通过 MOSN 去处理，因而只关心业务应用肯定不够，需要再扩展支持到 MOSN 这类 Sidecar 的测试验证。在 MOSN 中集成了控制面 xds client，与控制面 pilot 建立通信，用于接收 pilot 下发的配置信息。在蚂蚁金服技术架构存在三地五中心/同城双活等容灾能力，因而产生了 LDC，一个集群多个 zone 情况，控制面 pilot下发是可以配置集群+zone+应用+ip 组合粒度，要验证这个多 zone 下发规则准确性，那就需要创建多个 xds client（或者 MOSN）。另外 Sidecar 是不能直接访问的，通过测试应用暴露出接口，给上层测试。\nMesh 化测试架构\n构建高仿真测试环境 那么，我们测试环境要做到足够仿真，面临哪些挑战呢？首先看下我们自研的 MOSN 具备的能力和技术复杂性。\n MOSN 能力大图\n应对 MOSN 测试场景复杂性，我们搭建了一套高仿真测试环境，这里以 MOSN 中的 RPC 功能为例，阐述这套环境的构成要素及环境部署架构。\n集成测试环境构成要素\n这里可以举一个 RPC 路由的例子来详细讲述。我们知道，业务在做跨 IDC 路由时，主要通过跨域 VIP 实现，这就需要业务在自己的代码中设置 VIP 地址，例如：\n\u0026amp;lt;sofa:reference interface=\u0026amp;#34;com.alipay.APPNAME.facade.SampleService\u0026amp;#34; id=\u0026amp;#34;sampleRpcService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.tr\u0026amp;gt; \u0026amp;lt;sofa:vip url=\u0026amp;#34;APPNAME-pool.zone.alipay.net:12200\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/sofa:binding.tr\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt; 这时候假如业务配置了不合法的 URL，如：\n\u0026amp;lt;sofa:reference interface=\u0026amp;#34;com.alipay.APPNAME.facade.SampleService\u0026amp;#34; id=\u0026amp;#34;sampleRpcService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.tr\u0026amp;gt; \u0026amp;lt;sofa:vip url=\u0026amp;#34;http://APPNAME-pool.zone.alipay.net:12200?_TIMEOUT=3000\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/sofa:binding.tr\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt; 上述 VIP URL 指定了 12200 端口，却又同时指定了 http，这种配置是不合法的，就会出现问题，这时候测试环境就需要跨 zone、跨 LDC 的测试环境。我们在多数复杂产品测试里都会遇到，极度复杂测试场景无法 100% 分析充分。一般对于这种场景，我们可以借助于线上流量回放的能力，将线上的真实流量复制到线下，作为我们测试场景的补充。这也需要非常仿真的测试环境做 MOSN 的流量回放支撑。\n兼容性测试 MOSN 兼容性验证\n我们通过一个例子来详细阐述：老版本的 RPC 中我们支持 TR 协议，后续的新版支持 BOLT 协议，应用升级过程中，存在同时提供 TR 协议和 BOLT 协议服务的情况，如下图：\n应用升级过程中，相同接口提供不同协议的服务\n首先，应用向 MOSN 发布服务订阅的请求，MOSN 向配置中心订阅，配置中心返回给 MOSN 两个地址，分别支持 TR 和 BOLT，MOSN 从两个地址中选出一个返回给应用 APP。\n这里兼容性风险是：MOSN 返回给 APP 的地址是直接取配置中心返回的第一条数据，这里可能是 TR 也可能是 BOLT。\n如果 MOSN 返回给应用的地址是支持 BOLT 协议的服务端，那么后续应用发起服调用时，会直接以 BOLT 协议请求 MOSN，MOSN 选址时，会以轮询的方式两个服务提供方，如果调用到 Server1，就会出现协议不支持的报错。 因此我们针对各种兼容性具体场景都要做好分析和相应的测试。\nMOSN 的鲁棒测试（稳定性、健壮性） 从 MOSN 的视角来看，其外部依赖如下：\nMOSN 外部依赖图\n除了验证 MOSN 自身的功能外，我们还通过故障注入的方式，对 MOSN 的外部依赖做了专项测试。通过这种方式，我们发现了一些上述功能测试未覆盖的场景，这里以应用和 MOSN 之间的 12199 端口举例。\n应用 APP 接入 MOSN 后，原先应用对外提供的 12200 端口改由 MOSN 去监听，应用的端口修改为 12199，MOSN 会向应用的 12199 端口发送心跳，检测应用是否存活。\n如果应用运行过程中出现问题，MOSN …","date":1579514400,"description":" 本文为《蚂蚁金服 Service Mesh 大规模落地系列》最后 一篇 - 质量篇，结合蚂蚁金服 Mesh 化落地质量保障落地的思考，给大家带来一些质量保障的分享。","dir":"blog/service-mesh-practice-in-production-at-ant-financial-part8-quantity/","fuzzywordcount":3200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"8dfd6e1dabd16bc85d9876ce9764e3ab","permalink":"/blog/service-mesh-practice-in-production-at-ant-financial-part8-quantity/","publishdate":"2020-01-20T18:00:00+08:00","readingtime":7,"relpermalink":"/blog/service-mesh-practice-in-production-at-ant-financial-part8-quantity/","summary":"本文为《蚂蚁金服 Service Mesh 大规模落地系列》最后 一篇 - 质量篇，该系列从核心、RPC、消息、无线网关、控制面、安全、运维、测试等模块对 Service Mesh 双十一大规模","tags":["Service mesh","Service Mesh 落地实践"],"title":"蚂蚁金服 Service Mesh 大规模落地系列 - 质量篇","type":"blog","url":"/blog/service-mesh-practice-in-production-at-ant-financial-part8-quantity/","wordcount":3163},{"author":"嘉祁","categories":"Service mesh","content":"本文根据蚂蚁金服中间件 SRE技术专家黄家琦（嘉祁）于 Service Mesh Meetup#9 杭州站上的分享整理。\n背景 Service Mesh 在软件形态上，是将中间件的能力从框架中剥离成独立软件。而在具体部署上，保守的做法是以独立进程的方式与业务进程共同存在于业务容器内。蚂蚁金服的做法是从开始就选择了拥抱云原生。\n大规模落地的过程中，我们在看到 Service Mesh 带来的巨大红利的同时，也面临过很多的挑战。为此，蚂蚁金服配备了“豪华”的技术团队阵容，除了熟悉的 SOFA 中间件团队，还有安全、无线网关以及专门配备了专属的 SRE 团队，使得 MOSN 能力更加全面更加可靠。\n今天我们详细聊聊技术风险这个方面。对于一个新的中间件技术，在落地过程中总会面临稳定性、运维模式变化等等很多的问题与挑战，需要建设相应的技术风险能力，确保整个落地过程以及长期运行的稳定和可靠。\n本次分享主要从以下三个方面展开：\n 落地过程中对于部署模式和资源分配的思考； 变更包括接入、升级的支持、问题与思考； 整个生产生命周期中稳定性面临的挑战与技术风险保障；  Sidecar 部署模式 业务容器内独立进程的好处在于与传统的部署模式兼容，易于快速上线；但独立进程强侵入业务容器，对于镜像化的容器更难于管理。而云原生化，则可以将 Service Mesh 本身的运维与业务容器解耦开来，实现中间件运维能力的下沉。在业务镜像内，仅仅保留长期稳定的 Service Mesh 相关 JVM 参数，从而仅通过少量环境变量完成与 Service Mesh 的联结。同时考虑到面向容器的运维模式的演进，接入 Service Mesh 还同时要求业务完成镜像化，为进一步的云原生演进打下基础。\n    优 劣     独立进程 兼容传统的部署模式；改造成本低；快速上线 侵入业务容器； 镜像化难于运维   Sidecar 面向终态；运维解耦 依赖 K8s 基础设施；运维环境改造成本高；应用需要镜像化改造    在接入 Service Mesh 之后，一个典型的 POD 结构可能包含多个 Sidecar：\n MOSN：RPC Mesh, MSG Mesh, \u0026amp;hellip;（扩展中）； 其它 Sidecar；  MOSN：https://github.com/mosn/mosn\n这些 Sidecar 容器与业务容器共享相同的网络 Namespace，使得业务进程可以以本地端口访问 Service Mesh 提供的服务，保证了与保守做法一致的体验。\n基础设施云原生支撑 我们也在基础设施层面同步推进了面向云原生的改造，以支撑 Service Mesh 的落地。\n运维平台模型支撑 首先是运维平台需要能够理解 Sidecar，支撑 Sidecar 模型的新增元数据，包括基于 POD 的 Sidecar 的多种标签，以及 Sidecar 基线配置的支持。\n业务全面镜像化 其次我们在蚂蚁金服内部推进了全面的镜像化，我们完成了内部核心应用的全量容器的镜像化改造。改造点包括：\n 基础镜像层面增加对于 Service Mesh 的环境变量支撑； 应用 Dockerfile 对于 Service Mesh 的适配； 推进解决了存量前后端分离管理的静态文件的镜像化改造； 推进了大量使用前端区块分发的应用进行了推改拉的改造； 大批量的 VM 模式的容器升级与替换；  容器 POD 化 除了业务镜像层面的改造，Sidecar 模式还需要业务容器全部跑在 POD 上，来适应多容器共享网络。由于直接升级的开发和试错成本很高，我们最终选择将接入 Service Mesh 的 数百个应用的数万个非 K8s 容器，通过大规模扩缩容的方式，全部更换成了 K8s PODs。\n经过这两轮改造，我们在基础设施层面同步完成了面向云原生的改造。\n资源的演进 Sidecar 模式的带来一个重要的问题，如何分配资源。\n理想比例的假设独占资源模型 最初的资源设计基于内存无法超卖的现实。我们做了一个假设：\n MOSN 的基本资源占用与业务选择的规格同比例这一假设。  CPU 和 Memory 申请与业务容器相应比例的额外资源。这一比例最后设定在了 CPU 1/4，Memory 1/16。\n此时一个典型 Pod 的资源分配如下图示：\n独占资源模型的问题 这一方式带来了两个问题：\n 蚂蚁金服已经实现了业务资源的 Quota 管控，但 Sidecar 并不在业务容器内，Service Mesh 容器成为了一个资源泄漏点； 业务很多样，部分高流量应用的 Service Mesh 容器出现了严重的内存不足和 OOM 情况；  共享资源模型 讨论之后，我们追加了一个假设：\n Service Mesh 容器占用的资源实质是在接入 Service Mesh 之前业务已使用的资源。接入 Service Mesh 的过程，同时也是一次资源置换。  基于这个假设，推进了调度层面支持 POD 内的资源超卖，新的资源分配方案如下图，Service Mesh 容器的 CPU、MEM 都从 POD 中超卖出来，业务容器内仍然可以看到全部的资源。\n考虑到内存超卖也引入了 POD OOM 的风险，因此对于 Sidecar 容器还调整了 OOM Score，保证在内存不足时，Service Mesh 进程能够发挥启动比 Java 业务进程更快的优势，降低影响。\n新的分配方案解决了同时解决了以上两个问题，并且平稳支持了蚂蚁金服的双十一大促。\n变更-Service Mesh 是如何在蚂蚁金服内部做变更的 Service Mesh 的变更包括了接入与升级，所有变更底层都是由 Operator 组件来接受上层写入到 POD annotation 上的标识，对相应 POD Spec 进行修改来完成，这是典型的云原生的方式。\n接入-从无至有 标准的云原生的接入方式，是在创建时通过 sidecar-operator webhook 注入一个 Sidecar 容器。\n这个方式的固有缺陷在于：\n 滚动替换过程需要 Buffer 资源； 过程缓慢； 回滚慢，应急时间长；  原地接入 原地接入是为了支撑大规模的快速接入与回滚，通过在存量的 POD 上操作修改 POD Spec。\n尽管看起来不太云原生，但期望能绕过以上几个痛点，从而可以：\n 不需要重新分配资源； 可原地回滚；  升级 Service Mesh 是深度参与业务流量的，最初的 Sidecar 的升级方式也需要业务伴随重启。\n带流量的平滑升级 为了规避 Java 应用重启带来的重新预热等问题，MOSN 提供了更为灵活的平滑升级机制：由 Operator 控制启动第二个 MOSN Sidecar，完成连接迁移，再退出旧的 Sidecar。整个过程业务可以做到流量不中断，几近无感。\n变更能力的取舍 虽然提供了原地接入与平滑升级，但从实践的效果来看，对存量 POD spec 的修改带来的问题，比收益要多得多。\n   创建时注入/普通升级 原地注入/平滑升级     不改变现存 POD spec 改变现存 POD   资源预分配，不影响调度； 逻辑简单，成功率高；与原有业务升级逻辑一致；变 …","date":1579514400,"description":" 本文根据蚂蚁金服中间件 SRE 技术专家黄家琦（嘉祁）于 Service Mesh Meetup#9 杭州站上的分享整理。","dir":"blog/service-mesh-meetup-9-retrospect-technical-risk-practice/","fuzzywordcount":4100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"7e1941c7099e109de92394b49df59a2b","permalink":"/blog/service-mesh-meetup-9-retrospect-technical-risk-practice/","publishdate":"2020-01-20T18:00:00+08:00","readingtime":9,"relpermalink":"/blog/service-mesh-meetup-9-retrospect-technical-risk-practice/","summary":"本文根据蚂蚁金服中间件 SRE技术专家黄家琦（嘉祁）于 Service Mesh Meetup#9 杭州站上的分享整理。 背景 Service Mesh 在软件形态上，是将中间件的能力从框架中剥离成独立软件。","tags":["Service mesh","Service Mesh Meetup"],"title":"蚂蚁金服 Service Mesh 技术风险思考和实践","type":"blog","url":"/blog/service-mesh-meetup-9-retrospect-technical-risk-practice/","wordcount":4057},{"author":"潘潘","categories":"SOFAChannel","content":"概要   活动主题：SOFAChannel#11：从一个例子开始体验轻量级类隔离容器 SOFAArk\n  活动时间：2 月 13 日周四晚 7 点\n  活动形式：线上直播\n  直播回顾：戳这里\n  介绍 | SOFAChannel \u0026amp;lt;SOFA:Channel/\u0026amp;gt; 有趣实用的分布式架构频道，前沿技术、直播 Coding、观点“抬杠”，多种形式。\n\u0026amp;lt;SOFA:Channel/\u0026amp;gt; 将作为 SOFA 所有在线内容的承载，包含直播/音视频教程，集中体现 SOFAStack 的能力全景图。\n| SOFAChannel#11：从一个例子开始体验轻量级类隔离容器 SOFAArk SOFAArk 是一款基于 Java 实现的轻量级类隔离容器，主要提供类隔离和应用(模块)合并部署能力，由蚂蚁金服公司开源贡献。SOFAArk 提供了一套较为规范化的插件化、模块化的开发方案。截止 2019 年底，SOFAArk 已经在蚂蚁金服内部 Serverless 场景下落地实践，并已经有数家企业在生产环境使用 SOFAArk ，包括网易云音乐、挖财、溢米教育等。\n本期为 SOFAChannel 线上直播第 11 期，将邀请 SOFAArk 开源负责人玄北和大家一起解读 SOFAArk ，将从 SOFAArk 的特性出发，了解轻量级类隔离容器 SOFAArk 的主要功能，并通过一个 Demo 案例，跟讲师一起操作，实际体验 SOFAArk 具体操作以及功能实现。\nSOFAArk：https://github.com/sofastack/sofa-ark\n你将收获：\n 快速认识轻量级类隔离容器 SOFAArk； Demo 案例实操，了解如何使用 SOFAArk 实现类隔离； SOFAArk 完整功能详解；  | 加入 SOFA 钉钉互动群 欢迎加入直播互动钉钉群：23372465（搜索群号加入即可）\n| 点击即可报名 https://tech.antfin.com/community/live/1096\n议程 19:00-19:05 主持人开场 SOFAGirl 主持人\n19:05-20:00 从一个例子开始体验轻量级类隔离容器 SOFAArk 玄北，蚂蚁金服技术专家 、SOFAArk 开源负责人\n本期分享大纲：  快速认识轻量级类隔离容器 SOFAArk； Demo 案例实操，了解如何使用 SOFAArk 实现类隔离； SOFAArk 完整功能详解；  嘉宾  SOFAGirl 主持人 玄北，蚂蚁金服技术专家 、SOFAArk 开源负责人  ","date":1579251600,"description":"2 月 13 日周四晚 7 点，线上直播第 11 期。","dir":"activities/sofa-channel-11/","fuzzywordcount":800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"b110f76087d52e5c6d8ccbe31c76a7f5","permalink":"/activities/sofa-channel-11/","publishdate":"2020-01-17T17:00:00+08:00","readingtime":2,"relpermalink":"/activities/sofa-channel-11/","summary":"概要 活动主题：SOFAChannel#11：从一个例子开始体验轻量级类隔离容器 SOFAArk 活动时间：2 月 13 日周四晚 7 点 活动形式：线上直播 直播回顾：戳这","tags":["SOFAChannel","SOFAArk"],"title":"SOFAChannel#11：从一个例子开始体验轻量级类隔离容器 SOFAArk","type":"activities","url":"/activities/sofa-channel-11/","wordcount":709},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n**1、@J~杰 **提问：\n 咨询一下，Seata TCC 中这个 BusinessActivityContext 是用于做什么的？\n A：比如说在 rollback 服务里需要用到 try 服务里的参数时，可以放到 BusinessActivityContext，然后在 rollback 和 comfirm 服务里可以取到这个参数。\n 那是要自己在 try 阶段需要手动实例化 BusinessActivityContext？\n A：不需要，可以在 try 方法上的参数加注解，它会自动把这个参数放入 BusinessActivityContext。\nSeata：https://github.com/seata/seata\n**2、王国柱 **提问：\n 有一个问题想要请教一下： HBX：如果是 spanner - \u0026amp;gt; gateway -\u0026amp;gt; app1 这种架构，每次上新的应用，应该是需要在 geteway 中配置新应用的 ip 地址路由信息。 如果是 spanner -\u0026amp;gt; gateway.jar,app1 这种架构，如果新增加 app2， spanner 如何知道新的应用地址在哪里。\nHBX：我理解集中式的 gateway，应该会把后端 app 的应用地址信息配置在集中式的 gateway 中。如果做成 jar，那 app 和 jar 的地址信息，该如何被 spanner 知道？\n A：Spanner 其实就是 ingress，不管是 gateway 还是 app x，都可以通过服务发现来发现服务器的 ip 信息。\n 那像这种的话，就是后台服务上线，可以自己注册到 spanner 上，然后外部应用就可以直接访问了。\n A：是的。 MOSN：https://github.com/mosn/mosn\nKubeCon NA2019 回顾  开箱即用的 Java Kubernetes Operator 运行时 基于 Knative 打造生产级 Serverless 平台 | KubeCon NA2019 将 Sidecar 容器带入新的阶段 | KubeCon NA 2019  本周推荐文章  10年后，阿里给千万开源人写了一封信 蚂蚁金服消息队列 SOFAMQ 加入 OpenMessaging 开源标准社区 蚂蚁金服 API Gateway Mesh 思考与实践  社区直播预告 春节后直播预告来啦～本期为 SOFAChannel 线上直播第 11 期，将从 SOFAArk 的特性出发，了解轻量级类隔离容器 SOFAArk 的主要功能，并通过一个 Demo 案例，跟讲师一起操作，实际体验 SOFAArk 具体操作以及功能实现。\nSOFAArk 是一款基于 Java 实现的轻量级类隔离容器，主要提供类隔离和应用(模块)合并部署能力，由蚂蚁金服公司开源贡献。截止 2019 年底，SOFAArk 已经在蚂蚁金服内部 Serverless 场景下落地实践，并已经有数家企业在生产环境使用 SOFAArk ，包括网易云音乐、挖财、溢米教育等。\n主题：SOFAChannel#11：从一个例子开始体验轻量级类隔离容器 SOFAArk\n时间：2020年2月13日（周四）19:00-20:00\n嘉宾：玄北，蚂蚁金服技术专家 SOFAArk 开源负责人\n形式：线上直播\n报名方式：点击“这里”，即可报名\n","date":1579248000,"description":"【01/13-01/17】 | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20200117/","fuzzywordcount":1300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"2fd8dd14cb119400890ef134622ad4d5","permalink":"/blog/sofa-weekly-20200117/","publishdate":"2020-01-17T16:00:00+08:00","readingtime":3,"relpermalink":"/blog/sofa-weekly-20200117/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":" SOFA Weekly | 2.13直播预告、KubeCon NA2019 回顾","type":"blog","url":"/blog/sofa-weekly-20200117/","wordcount":1218},{"author":"何子波、金敏","categories":null,"content":"本篇分享的内容难度为“初学者/Beginner”级别，以下是阅读本文前推荐您了解的背景知识：\n Java 语言编程基础； 了解过 Kubernetes 平台上的 Operator/Controller 工作机制；  也可以同步参考 Kubernetes 官方博客内容：https://kubernetes.io/blog/2019/11/26/develop-a-kubernetes-controller-in-java\n图为何子波和金敏在 KubeCon NA2019 大会分享后的交流\n何子波 蚂蚁金服技术专家： _(adohe@github) _Kubernetes 维护者，SIG CLI Co-Chair（包括 Kubectl 及其扩展插件，Kustomize 以及客户端运行时），同时关注安全容器，多租户等领域。\n金敏 蚂蚁金服软件工程师： _(yue9944882@github) _Kubernetes SIG API-Machinery 维护者及其子领域 Owner（CRD 服务实现，APIAggregation SDK 套件，控制面流控，OpenAPIv2/3，Java SDK 等），同时也是 OpenAPI 开源生态工具链openapitools.org 的 Techincal Committee。\n本文根据两位在 KubeCon NA2019 的分享内容整理。本次演讲与大家分享蚂蚁金服金融科技扩展云原生 Java 能力到云的实践和改造，并将收获的产出回馈开放给 Kubernetes 社区。\n分享概要 在 Kubernetes 平台上开发部署运行 Operator 已经是在 Kubernetes 上拓展开发能力的默认范式。最早是 CoreOS 的工程师们创新提出了 Operator 的开发理念并且在社区收获了良好的反响，在经过一段时间的波折、打磨和实践之后，我们今天才看到丰富多样的 Operator 层出不穷。实际上 Operator 的效力往往要结合 Kubernetes API 的扩展能力才能更好发挥。所以其广泛传播反过来锤炼演进了 Kubernetes 上 CustomResourceDefinition 承载第三方 API 模型的能力。水涨船高，这也是社区集中投入人力从 v1.14 开始启动 Extensibility GA Sprint 小组冲刺 Kubernetes 扩展性建设的推动原因。\n图为何子波和金敏在 KubeCon NA2019 大会现场演示\n随着 Operator 的受众越来越多，社区也衍生出了面向 Operator 开发提效的工具链项目比如 operator-sdk、kubebuilder、metacontroller 等等优秀的开源项目。可是这些项目大都是面向 Go 语言研发者的，虽然越来越多的研发者向 Go 靠扰已是事实，但是 Go 语言尚不及其他主流编程语言成熟，倒是慢慢铺开的 Kubernetes 等其他开源项目的工业实践在“倒逼”Go 语言底层库的修复和稳固，比如 http2 的底层网络库[1]。与此相似的，我们最早内部孵化的 Java 语言的 Operator 运行时框架也是被实际业务“倒逼”出来的，并在 Kubernetes 社区露头试水之初便收获了许多反馈推动发展直到今天走到全面开放。\n你为什么需要使用 Java 开发 Operator 如果你在犹豫不决是否要使用 Java 开发 Operator 并应用到实际中来，我们从以下几个方面进行对比看看哪一点是足够吸引你尝鲜：\n 适配存量系统：如果在登陆 Kubernetes 之前你的基础设施底层系统都是通过 Java 开发的，那么恭喜你已经有了使用 Java Operator 的天然土壤。反过来把存量系统接口逐个“翻译”为 Go 语言既消耗大量人力又引出持续同步维护 Go 语言库的成本。 堆内存快照：相比于 Java，Go 语言很难将运行中的程序的内存进行完整的快照分析，PProf 相关工具链能做的只是将内存的使用概况汇总输出，虽然也可以帮助分析锁定出泄漏的对象类型，但是粒度有限。反过来 Java 程序的堆内存进行快照分析已经具有成熟的工具链支持，研发者通过一份完整的堆快照可以直接锁定出比如 WorkQueue 中积压的内容，甚至限流器中逐个 Key 的瞬时状态，也可以在 Operator 静默不响应的场景下快速锁定问题。 性能诊断/在线调试：结合比如 JMX Exporter 等工具链的帮助，我们直接将 Java 虚拟机的细节运行状态以 Prometheus Metrics 的形式收集起来，虽然 Go 程序也可以暴露出其运行时的 Metrics，但是对比后我们发现 Java 的 Metrics 在分析 GC 状态和堆分布上更加强大。除此之外，Java Operator 的远程调试更加方便上手。 线程模型：与 Java 显著不同的是，Go 语言中的 Routine 不具有直接从外部“杀死”的功能，你需要结合 Channel/Context 等模型间接实现。而在 Java 虚拟机上的线程模型有和操作系统类似的生命周期管理，开发者可以白盒的操作干涉线程的生命周期。这对于某些业务场景是重要的。 OOP 范型编程接口： Go 语言本身的设计哲学是不认可面向对象编程的，尽管好处很多但是在 API 模型繁多的 Kubernetes 项目中，维护者不得己转向使用代码生成器批量为这些模型生成大量模版代码。Java 的优势之一是范型编程，这可以彻底取代代码生成器的工作，同一套代码可以自由地适配在各种模型，比如 Pod 到 Service 等等。 第三方研发者库生态：经过数十年的演进，Java 积累的第三方工具库远比 Go 语言丰富的多，至少目前而已可以算得上是一个优势。  示例代码速览 下面两张代码片段为你展示了具体开发 Java Operator 所需要的全部工作，相信接触过 Kubernetes Client-Go 的开发者通过名字大致了解如何使用了：\n（如何构造出一个 Informer 实例） https://github.com/kubernetes-client/java/blob/master/examples/src/main/java/io/kubernetes/client/examples/InformerExample.java\n（如何构造出一个 Operator 实例） https://github.com/kubernetes-client/java/blob/master/examples/src/main/java/io/kubernetes/client/examples/ControllerExample.java\n开发 Java Operator 需要额外注意什么 仅仅是通过代码开发 Operator 显然不是大结局，你还需要注意其他的问题，以下是我们在实际运用的获得的经验总结：\n 严谨管理 CRD Yaml 定义：如最开始提到的，当 Java Operator 操作的是自定义资源比如 CRD 时，我们自然需要操作/维护该 CRD 对应的 Java 模型。 …","date":1579176000,"description":" 本文介绍了如何快速上手使用 Java 开发 Operator，感兴趣的读者可以根据官方实例在本地开发环境体验。","dir":"blog/java-kubernetes-operator-kubecon-na2019/","fuzzywordcount":2800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"4af2ef3082aeed080e87501fd71134d9","permalink":"/blog/java-kubernetes-operator-kubecon-na2019/","publishdate":"2020-01-16T20:00:00+08:00","readingtime":6,"relpermalink":"/blog/java-kubernetes-operator-kubecon-na2019/","summary":"本篇分享的内容难度为“初学者/Beginner”级别，以下是阅读本文前推荐您了解的背景知识： Java 语言编程基础； 了解过 Kubernetes 平台上的 Operator/Controller 工作机制； 也可","tags":["Kubernetes"],"title":" 开箱即用的 Java Kubernetes Operator 运行时","type":"blog","url":"/blog/java-kubernetes-operator-kubecon-na2019/","wordcount":2778},{"author":"贾岛","categories":"Service Mesh","content":"本文整理自蚂蚁金服高级技术专家贾岛在 12 月 28 日 Service Mesh Meetup 杭州站现场分享。\nMOSN 完成孵化， 启用独立 Group 2020.2019.12.18，MOSN 项目负责人、蚂蚁金服应用网络组负责人涵畅宣布 MOSN 完成从 SOFAStack 的孵化，将启用独立 Group 进行后续运作，欢迎大家共同建设社区。\nMOSN 是一款使用 Go 语言开发的网络代理软件，作为云原生的网络数据平面，旨在为服务提供多协议，模块化，智能化，安全的代理能力。MOSN 是 Modular Open Smart Network-proxy 的简称，可以与任何支持 xDS API 的 Service Mesh 集成，亦可以作为独立的四、七层负载均衡，API Gateway，云原生 Ingress 等使用。\n项目地址：https://github.com/mosn/mosn\n导语 在 Service Mesh 微服务架构中，我们常常会听到东西流量和南北流量两个术语。蚂蚁金服开源的 Service Mesh Sidecar：MOSN（Modular Observable Smart Network）已经多次与大家见面交流，以往的议题重点在东西流量的服务发现与路由，那么蚂蚁金服在南北流量上的思考是怎样的？\n本次分享，将从蚂蚁金服 API 网关发展历程来看，Mesh 化的网关架构是怎样的、解决了什么问题、双十一的实践表现以及我们对未来的思考。\n今天的分享分为三个部分：\n API Gateway Mesh 的定义：我在 Google 上搜了下 API Gateway Mesh 这个词，找到的都是 API Gateway vs Service Mesh，大家估计也会很好奇：这个词具体的定义是怎样的呢？所以我们下面会做将 API Gateway 和 Service Mesh 做个对比，然后讲一下我个人对这个词有理解和思考。 API Gateway Mesh 在蚂蚁金服的实践：今年阿里巴巴核心系统 100% 云原生化，撑住了双11的世界级流量洪峰，这其中，蚂蚁金服的 Service Mesh 大放光彩，核心链路全上 Mesh，数万容器规模，我们 API Gateway 在其中也承担了部分钱包链路和支付链路 100% 的请求。这个章节，我会从蚂蚁金服 API 网关的发展历程来看，我们为什么做 API Gateway Mesh，我们的架构是如何的，以及我们在过程中的一些风险和考验。 云原生下 API Gateway 的思考：大家现在都在讲云原生，但是真正实践云原生的过程中，会越到各种各样的问题，怎么样的 API Gateway 方案和形态是最合适你们的业务的？在云原生的架构中，Service Mesh，API Gateway 都是最核心的组件之一，我们对于云原生下的 API Gateway 在 Service Mesh 架构中的定位是如何思考的？还有，未来我们的一些计划是怎样的？都会在这个章节跟大家分享一下。  API Gateway Mesh 的定义 上面这张图是一个云原生，南北+东西流量的架构图，这里面包含了核心的一些组件，我快速介绍一下：\n LB\\ingress：负责 ssl 卸载、入口流量的负载均衡，通常会做一些简单的路由； API Gateway：负责更偏向业务的 API 验签、限流、协议转换、用户会话、负载均衡等逻辑； Sidecar in POD：业务系统中的 Sidecar，代理机房内东西流量的转发，一般走内部的 RPC（比如SOFARPC \\ Dubbo \\ Thrift \\ SpringCloud），这里面的流量全部通过 Service Mesh 的 Sidecar Proxy 来承载，这个 Sidecar 负责路由（单元化\\灰度\\金丝雀），负载均衡、服务鉴权等等； Control Plane：流量控制「大管家」，云原生里目前最主流的方案是 Istio，负责路由策略、安全、鉴权等等下发和控制；  上面的架构大家都比较了解了，从上面的描述大家也看出来了，API Gateway 和 Service Mesh 的 Sidecar 很多能力都是类似的，比如都是一个网络代理，都具备负载均衡，都具备一些限流和鉴权能力。下面，我们将做一个 API Gateway 和 Service Mesh 的对比。\nAPI Gateway vs Service Mesh  从本质概念上来讲，API Gateway 用一句话概括：「Exposes your services as managed APIs」，将内部的服务以更加可控可管理的方式暴露出去，这里的关键词是「暴露」和「可控」。Service Mesh 用一句话概括：「A infrastructure to decouple the application network from your service code」，一种将服务代码与应用网络解耦的基础设施，这里的关键词是「解耦」。\n在流量上，API Gateway 是管理南北流量的，而 Servcie Mesh 中的 Sidecar 一般情况下是用来负载东西流量的Proxy。两者都具备负责均衡的能力，API Gateway 一般情况下是通过 lvs 、nginx 中心化的一个负载均衡器，我们管这个叫硬负载；而 Service Mesh 一般情况下是通过服务发现，Sidecar 之间是点对点的调用，我们叫软负载。\n通信协议上，API Gateway 一般对外接收开放的通信协议，一般是 HTTP、gRPC 等，而且可能涉及到协议的转换，将 HTTP 转换成内部的 RPC 协议，而 Service Mesh 代理的内部流量一般是内部的私有 RPC 协议（WebService、Dubbo、SOFABolt、Thrift 等等）。在鉴权、流控、安全等控制流量的层面上，对于 API Gateway 来讲都是强依赖的，这样才体现「可控」的特点，而 Service Mesh 代理的内部流量，由于一般处于内网环境，这些控制一般情况下都是弱依赖。\n我们对 Service Mesh 的真正理解 大家可以看到，API Gateway 和 Service Mesh 实际上有很多共同点，也有很多区别。那 API Gateway Mesh 到底是如何定义的呢？那要介绍下，我们对 Service Mesh 的真正理解！\nService Mesh 中的 Sidecar 就是这样一辆边车摩托车，Sidecar 将 Service Code 和内部通信 RPC 逻辑解耦掉。但是 Sidecar 的座位上，不仅仅可以坐「内部通信的 RPC」，也可以将其他中间件放到这辆 Sidecar 中，API Gateway + Sidecar = API Gateway Mesh，我们也可以把 MessageQueue Client 放在 Sidecar 中，就是 Message Mesh。\n所以，大家看，其实 Service Mesh 是一种模式和架构，关键词就是「解耦」你的服务代码和你的「中间件」。\nAPI Gateway Mesh  …","date":1579078800,"description":" 本次分享，将从蚂蚁金服 API 网关发展历程来看，Mesh 化的网关架构是怎样的、解决了什么问题、双十一的实践表现以及我们对未来的思考。","dir":"blog/service-mesh-meetup-9-retrospect-api-gateway-mesh/","fuzzywordcount":5200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"370ccd30a2edcf559eb2c82976bcb8a0","permalink":"/blog/service-mesh-meetup-9-retrospect-api-gateway-mesh/","publishdate":"2020-01-15T17:00:00+08:00","readingtime":11,"relpermalink":"/blog/service-mesh-meetup-9-retrospect-api-gateway-mesh/","summary":"本文整理自蚂蚁金服高级技术专家贾岛在 12 月 28 日 Service Mesh Meetup 杭州站现场分享。 MOSN 完成孵化， 启用独立 Group 2020.2019.12.18，MOSN 项目负责人、","tags":["Service Mesh","MOSN","Service Mesh Meetup"],"title":"蚂蚁金服 API Gateway Mesh 思考与实践","type":"blog","url":"/blog/service-mesh-meetup-9-retrospect-api-gateway-mesh/","wordcount":5174},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@李彦迎 提问：\n TCC 模式我可以作为 Saga 模式使用不？譬如 try 为空，永远成功。\n A：可以，不过应该是 confirm 为空，不是 try 为空。\n 请问 Seata 的 Saga 模式能支持 DB2 数据库吗？\n A：可以支持 DB2。\n 请教基础问题：Gateway 调用微服务 A、B，B内部失败了，补偿交易应该回退A的，这个补偿交易应该定义在微服A里面还是微服务B里面？\n A：原服务是谁提供的，补偿服务就应该谁提供。\n 请问能否 Client 用 DB2，Server 用 MySQL? Client 的必须和业务数据库保持一致吧？\n A：也可以的。是的，Client端必须与业务数据库保持一致。\n2、@米晓飞 提问：\n Saga 和现有框架有啥区别呢，优劣比较？\n A：我们在实践中发现，长流程的业务场景，往往有服务编排的需求，同时又要保证服务之间的数据一致性。目前开源社区也有一些 Saga 事务框架，也有一些服务编排的框架，但是它们要么只有 Saga 事务处理能力、要么只有服务编排能力，Seata Saga 是将这两者能力非常优雅的结合在一起，为用户提供一个简化研发、降低异常处理难度、高性能事件驱动的产品。\n3、@张春雨 提问：\n Saga 的模式补偿和 XA 回滚有啥区别呀？\n A：XA 是数据库提交的两阶段提交协议，Saga 的是需要业务层来实现的。\n Seata server 端使用 mysql 去记录事务日志,感觉性能上不是很好、 有没有其他的可替代的持久化方案吗？\n A：Seata 每个模块都设计有 SPI，持久化也一样，未来可以扩展更多持久化方式。 Seata：https://github.com/seata/seata 更多关于 Seata Saga 的内容可以看下文直播回顾。\n**4、@FAN **提问：\n MOSN 的平滑升级原理是什么？跟 Nginx 和 Envoy 的区别是什么？\n A：MOSN 的平滑升级方案和 Envoy 类似，都是通过 UDS 来传递 listener fd。但是其比 Envoy 更厉害的地方在于它可以把老的连接从 Old MOSN 上迁移到 New MOSN 上。也就是说把一个连接从进程 A 迁移到进程 B，而保持连接不断！Nginx 的实现是兼容性最强的。 可以详细阅读：https://ms2008.github.io/2019/12/28/hot-upgrade/ MOSN：https://github.com/mosn/mosn\nSOFAArkLab 系列  蚂蚁金服轻量级类隔离框架概述 | SOFAArk 源码解析  本篇开始将正式启动SOFA:ArkLab/源码共建系列，在此对长期以来对 SOFAStack 关注的朋友表示感谢。文中附共建列表，欢迎领取共建~\nSOFAChannel 集锦  Seata 长事务解决方案 Saga 模式 | SOFAChannel#10 回顾 从一个例子开始体验 SOFAJRaft | SOFAChannel#8 直播整理 自定义资源 CAFEDeployment 的背景、实现和演进 | SOFAChannel#7 直播整理 蚂蚁金服轻量级监控分析系统解析 | SOFAChannel#6 直播整理 给研发工程师的代码质量利器 | SOFAChannel#5 直播整理 分布式事务 Seata TCC 模式深度解析 | SOFAChannel#4 直播整理 SOFARPC 性能优化实践（下）| SOFAChannel#3 直播整理 SOFARPC 性能优化实践（上）| SOFAChannel#2 直播整理 从蚂蚁金服微服务实践谈起 | SOFAChannel#1 直播整理  SOFA 项目进展 本周发布详情如下：\n1、发布 MOSN v3.2.2 版本，主要变更如下：\n ReadinessCheckListener 的 Order 过高 删除 jaxrs-api 依赖项  详细发布报告：https://github.com/sofastack/sofa-boot/releases/tag/v3.2.2\n","date":1578643200,"description":"【01/05-01/10】 | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20200110/","fuzzywordcount":1500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"1143431da4314982069d5d5465391dc5","permalink":"/blog/sofa-weekly-20200110/","publishdate":"2020-01-10T16:00:00+08:00","readingtime":3,"relpermalink":"/blog/sofa-weekly-20200110/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | SOFABoot 发版、直播回顾、SOFAArkLab共建启动","type":"blog","url":"/blog/sofa-weekly-20200110/","wordcount":1467},{"author":"屹远","categories":"Seata","content":" SOFA:Channel/，有趣实用的分布式架构频道。 本文根据 SOFAChannel#10 直播分享整理，主题：分布式事务 Seata 长事务解决方案 Saga 模式详解。 回顾视频以及 PPT 查看地址见文末。欢迎加入直播互动钉钉群：23372465，不错过每场直播。\n 大家好，我是陈龙，花名: 屹远（long187@github），是蚂蚁金服分布式事务核心研发，也是 Seata Committer。今天分享的主题是《分布式事务 Seata 长事务解决方案 Saga 模式详解》，将从金融分布式应用开发的痛点出发，结合 Saga 分布式事务的理论和使用场景，讲解如何使用 Seata Saga 状态机来进行服务编排和分布式事务处理，构建更有弹性的金融应用，同时也会从架构、原理、设计、高可用、最佳实践等方面剖析 Saga 状态机的实现。\nSeata：https://github.com/seata/seata\n金融分布式应用开发的痛点 分布式系统有一个比较明显的问题就是，一个业务流程需要组合一组服务。这样的事情在微服务下就更为明显了，因为这需要业务上的一致性的保证。也就是说，如果一个步骤失败了，那么要么回滚到以前的服务调用，要么不断重试保证所有的步骤都成功。\u0026amp;mdash;《左耳听风-弹力设计之“补偿事务”》\n而在金融领域微服务架构下的业务流程往往会更复杂，流程很长，比如一个互联网微贷业务流程调十几个服务很正常，再加上异常处理的流程那就更复杂了，做过金融业务开发的同学会很有体感。\n所以在金融分布式应用开发过程中我们面临一些痛点：\n 业务一致性难以保障  我们接触到的大多数业务（比如在渠道层、产品层、集成层的系统），为了保障业务最终一致性，往往会采用“补偿”的方式来做，如果没有一个协调器来支持，开发难度是比较大的，每一步都要在 catch 里去处理前面所有的“回滚”操作，这将会形成“箭头形”的代码，可读性及维护性差。或者重试异常的操作，如果重试不成功可能要转异步重试，甚至最后转人工处理。这些都给开发人员带来极大的负担，开发效率低，且容易出错。\n 业务状态难以管理  业务实体很多、实体的状态也很多，往往做完一个业务活动后就将实体的状态更新到了数据库里，没有一个状态机来管理整个状态的变迁过程，不直观，容易出错，造成业务进入一个不正确的状态。\n 业务监控运维难  业务的执行情况监控一般通过打印日志，再基于日志监控平台查看，大多数情况是没有问题的，但是如果业务出错，这些监控缺乏当时的业务上下文，对排查问题不友好，往往需要再去数据库里查。同时日志的打印也依赖于开发，容易遗漏。\n 缺乏统一的差错守护能力  对于补偿事务往往需要有“差错守护触发补偿”、“人工触发补偿”操作，没有统一的差错守护和处理规范，这些都要开发者逐个开发，负担沉重。\n理论基础 对于事务我们都知道 ACID，也很熟悉 CAP 理论最多只能满足其中两个，所以，为了提高性能，出现了 ACID 的一个变种 BASE。ACID 强调的是一致性（CAP 中的 C），而 BASE 强调的是可用性（CAP 中的 A）。在很多情况下，我们是无法做到强一致性的 ACID 的。特别是我们需要跨多个系统的时候，而且这些系统还不是由一个公司所提供的。BASE 的系统倾向于设计出更加有弹力的系统，在短时间内，就算是有数据不同步的风险，我们也应该允许新的交易可以发生，而后面我们在业务上将可能出现问题的事务通过补偿的方式处理掉，以保证最终的一致性。\n所以我们在实际开发中会进行取舍，对于更多的金融核心以上的业务系统可以采用补偿事务，补偿事务处理方面在30多年前就提出了 Saga 理论，随着微服务的发展，近些年才逐步受到大家的关注。目前业界比较也公认 Saga 是作为长事务的解决方案。\n https://github.com/aphyr/dist-sagas/blob/master/sagas.pdf http://microservices.io/patterns/data/saga.html\n Saga 模式用一种非常纯朴的方式来处理一致性：补偿。上图左侧是正常的事务流程，当执行到 T3 时发生了错误，则开始执行右边的事务补偿流程，返向执行T3、T2、T1 的补偿服务，其中 C3 是 T3 的补偿服务、C2 是 T2 的补偿服务、C1 是 T1 的补偿服务，将T3、T2、T1 已经修改的数据补偿掉。\n使用场景 一些场景下，我们对数据有强一致性的需求时，会采用在业务层上需要使用“两阶段提交”这样的分布式事务方案。而在另外一些场景下，我们并不需要这么强的一致性，那就只需要保证最终一致性就可以了。\n例如蚂蚁金服目前在金融核心系统使用的就是 TCC 模式，金融核心系统的特点是一致性要求高（业务上的隔离性）、短流程、并发高。\n而在很多金融核心以上的业务（比如在渠道层、产品层、集成层的系统），这些系统的特点是最终一致即可、流程多、流程长、还可能要调用其它公司的服务（如金融网络）。这是如果每个服务都开发 Try、Confirm、Cancel 三个方法成本高。如果事务中有其它公司的服务，也无法要求其它公司的服务也遵循 TCC 这种开发模式。同时流程长，事务边界太长，加锁时间长，会影响并发性能。\n所以 Saga 模式的适用场景是：\n 业务流程长、业务流程多； 参与者包含其它公司或遗留系统服务，无法提供 TCC 模式要求的三个接口； 典型业务系统：如金融网路（与外部机构对接）、互联网微贷、渠道整合、分布式架构下服务集成等业务系统； 银行业金融机构使用广泛；  其优势：\n 一阶段提交本地事务，无锁，高性能； 参与者可异步执行，高吞吐； 补偿服务易于实现，因为一个更新操作的反向操作是比较容易理解的；  其缺点：\n 不保证隔离性，后面我们会讲到如何应对隔离性的缺失。  基于状态机引擎的 Saga 实现 基于状态机引擎的 Saga 实现的基本原理：\n 通过状态图来定义服务调用的流程并生成 json 定义文件； 状态图中一个节点可以是调用一个服务，节点可以配置它的补偿节点（虚线关联的节点）； 状态图 json 由状态机引擎驱动执行，当出现异常时状态引擎反向执行已成功节点对应的补偿节点将事务回滚； 异常发生时是否进行补偿也可由用户自定义决定； 可以实现服务编排需求，路由、异步、重试、参数转换、参数映射、服务执行状态判断、异常捕获等功能 ；  Seata 目前的 Saga 模式采用了状态机+DSL 方案来实现，原因有以下几个：\n 状态机+DSL 方案在实际生产中应用更广泛； 可以使用 Actor 模型或 SEDA 架构等异步处理引擎来执行，提高整体吞吐量； 通常在核心系统以上层的业务系统会伴随有“服务编排”的需求，而服务编排又有事务最终一致性要求，两者很难分割开，状态机+DSL 方案可以同时满足这两个需求； 由于 Saga 模式在理论上是不保证隔离性的，在极端情况下可能由于脏写无法完成回滚操作，比如举一个极端的例子，分布式事务内先给用户 A 充值，然后给用户 B 扣减余额，如果在给A用户充值成功，在事务提交以前，A 用户把线消费掉了，如果事务发生回滚，这时则没有办法进行补偿了，有些业务场景可以允许 …","date":1578574800,"description":"本文根据 SOFAChannel#10 直播分享整理，将从金融分布式应用开发的痛点出发，结合 Saga 分布式事务的理论和使用场景，讲解如何使用 Seata Saga 状态机来进行服务编排和分布式事务处理，构建更有弹性的金融应用","dir":"blog/sofa-channel-10-retrospect/","fuzzywordcount":6200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"2ba15ca1c710e1be2e6758950246d1ee","permalink":"/blog/sofa-channel-10-retrospect/","publishdate":"2020-01-09T21:00:00+08:00","readingtime":13,"relpermalink":"/blog/sofa-channel-10-retrospect/","summary":"SOFA:Channel/，有趣实用的分布式架构频道。 本文根据 SOFAChannel#10 直播分享整理，主题：分布式事务 Seata 长事务解决方案 Saga 模式详解。 回顾视频以及 PPT 查看","tags":["Seata","SOFAChannel"],"title":"Seata 长事务解决方案 Saga 模式 | SOFAChannel#10 回顾","type":"blog","url":"/blog/sofa-channel-10-retrospect/","wordcount":6157},{"author":"卫恒","categories":"SOFAArk","content":" 本篇开始将正式启动 SOFAArk:Lab/ 源码共建系列，在此对长期以来对 SOFAStack 关注的朋友表示感谢。\n本文为《剖析 | SOFAArk 源码》第一篇，本篇作者卫恒，SOFAArk 开源负责人。《剖析 | SOFAArk 源码》系列由 SOFA 团队和源码爱好者们出品，项目代号：SOFA:ArkLab/，文末附共建列表，欢迎领取共建~\n 在大型软件开发过程中，通常会推荐底层功能插件化、业务功能模块化的开发模式，以期达到低耦合、高内聚、功能复用的优点。对于模块化，从语言层面，原计划在 Java7 就有的模块化特性，终于在 Java9 里面提供了。在 Java语言级对模块化提供支持之前，业界内最知名的 Java 模块化规范当属 OSGi 了，直至到今天，OSGi 在众多企业、厂商中被广泛使用，比如我们常用的 Web 应用服务器、Eclipse 等均采用了 OSGi 规范。\n蚂蚁金服内部，CE 作为使用了 10 年的\u0026amp;quot;元老级\u0026amp;quot;容器组件，见证了和支撑了每年的大促、新春红包等流量场景。作为中间件的常青树，CE 以足够的稳定性为业务保驾护航。CE 容器也是基于 OSGi 实现了模块化，但是由于 CE 背负了太多包袱，使得其自身变得太重，在云原生及商业化输出上逐渐失去了优势。\n从 2016 年底开始，框架组内部开始在 CE 的基础上进行抽离和整合，开始拥抱新的轻量级类隔离容器框架-SOFAArk。截止 2019 年底，SOFAArk 已经在蚂蚁金服内部 Serverless 场景下落地实践，并已经有数家企业在生产环境使用 SOFAArk ，包括网易云音乐、挖财、溢米教育等。\nSOFAArk 简介 SOFAArk 是一款基于 Java 实现的轻量级类隔离容器，主要提供类隔离和应用(模块)合并部署能力，由蚂蚁金服公司开源贡献。SOFAArk 提供了一套较为规范化的插件化、模块化的开发方案，产品能力主要包括：\n 定义类加载模型，运行时底层插件、业务应用(模块)之间均相互隔离，单一插件和应用(模块)由不同的 ClassLoader 加载，可以有效避免相互之间的包冲突，提升插件和模块功能复用能力； 定义插件开发规范，提供 maven 打包工具，简单快速将多个二方包打包成插件（Ark Plugin，以下简称 Plugin） 定义模块开发规范，提供 maven 打包工具，简单快速将应用打包成模块 (Ark Biz，以下简称 Biz) 针对 Plugin、Biz 提供标准的编程界面，包括服务、事件、扩展点等机制 支持多 Biz 的合并部署，开发阶段将多个 Biz 打包成可执行 Fat Jar，或者运行时使用 API 或配置中心(Zookeeper)动态地安装卸载 Biz。  SOFAArk：https://github.com/sofastack/sofa-ark\n应用场景 基于模块化及模块的动态能力，SOFAArk 有非常丰富的落地场景，如：通过从 classloader 层面解决 依赖冲突问题、基于 arkcontainer 的多应用合并部署，基于动态 biz 的 SOFAServerless 等等。\n依赖冲突 日常使用 Java 开发，常常会遇到包依赖冲突的问题，尤其当应用变得臃肿庞大，包冲突的问题也会变得更加棘手，导致各种各样的报错，例如 LinkageError、NoSuchMethodError 等；实际开发中，可以采用多种方法来解决包冲突问题，比较常见的是类似 Spring Boot 的做法，统一管理应用所有依赖包的版本，保证这些三方包不存在依赖冲突；这种做法只能有效避免包冲突问题，不能根本上解决包冲突的问题；如果某个应用的确需要在运行时使用两个相互冲突的包，例如 protobuf2 和 protobuf3，那么类似 Spring Boot 的做法依然解决不了问题。\n为了彻底解决包冲突的问题，需要借助类隔离机制，使用不同的 ClassLoader 加载不同版本的三方依赖，进而隔离包冲突问题； OSGi 作为业内最出名的类隔离框架，自然是可以被用于解决上述包冲突问题，但是 OSGi 框架太过臃肿，功能繁杂；为了解决包冲突问题，引入 OSGi 框架，有牛刀杀鸡之嫌，且反而使工程变得更加复杂，不利于开发。\nSOFAArk 采用轻量级的类隔离方案来解决日常经常遇到的包冲突问题，在蚂蚁金服内部服务于整个 SOFABoot 技术体系，弥补 Spring Boot 没有的类隔离能力。SOFAArk 提出了一种特殊的包结构 – Ark Plugin，在遇到包冲突时，用户可以使用 Maven 插件将若干冲突包打包成 Plugin，运行时由独立的 PluginClassLoader 加载，从而解决包冲突。\n假设如下场景，如果工程需要引入两个三方包：A 和 B，但是 A 需要依赖版本号为 0.1 的 C 包，而恰好 B 需要依赖版本号为 0.2 的 C 包，且 C 包的这两个版本无法兼容：\n此时，即可使用 SOFAArk 解决该依赖冲突问题；只需要把 A 和版本为 0.1 的 C 包一起打包成一个 Ark 插件，然后让应用工程引入该插件依赖即可。\n合并部署 复杂项目通常需要跨团队协作开发，各自负责不同的组件，而众所周知，协调跨团队合作开发会遇到不少问题；比如各自技术栈不统一导致的依赖冲突，又比如往同一个 Git 仓库提交代码常常导致 merge 冲突。因此，如果能让每个团队将负责的功能组件当成一个个单独的应用开发，运行时合并部署，通过统一的编程界面交互，那么将极大的提升开发效率及应用可扩展性。SOFAArk 提出了一种特殊的包结构 - Ark Biz，用户可以使用 Maven 插件将应用打包成 Biz，允许多 Biz 在 SOFAArk 容器之上合并部署，并通过统一的编程界面交互。\n在开发阶段，应用可以将其他应用打成的 Biz 包通过 Maven 依赖的方式引入，而当自身被打成可执行 Fat Jar 时，可以将其他应用 Biz 包一并打入，启动时，则会根据优先级依次启动各应用。每个 Biz 使用独立的 BizClassLoader 加载，不需要考虑相互依赖冲突问题，Biz 之间则通过 SofaService / SofaReference JVM 服务进行交互。\n 静态合并部署是将多个应用打包在一个 ARK 可执行 JAR 包中，然后通过 java -jar 启动，这种方式可以在 ARK 容器内同时运行多个应用，对于一些资源要求不高、流量较少的应用可以使用这种方式部署以节省资源。\n 动态模块  模块是 ark biz 在动态模型场景下的一种别名，其实质就是一个 ark biz 包。\n 动态模块相对于静态合并部署最大的不同点是，运行时通过 API 或者配置中心（Zookeeper）来控制 Biz 的部署和卸载。动态模块的设计理念图如下：\n无论是静态合并部署还是动态模块都会有宿主应用（master biz）的概念, 如果 Ark 包只打包了一个 Biz，则该 Biz 默认成为宿主应用；如果 Ark 包打包了多个 Biz 包，需要配置指定宿主应用。宿主应用不允许被卸载，一般而言，宿主应用会作为 …","date":1578398400,"description":" 本文为《剖析 | SOFAArk 源码》第一篇，作者卫恒","dir":"blog/sofa-ark-overview/","fuzzywordcount":3900,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"56bc84e9737dbad9c77b9700b12bf63d","permalink":"/blog/sofa-ark-overview/","publishdate":"2020-01-07T20:00:00+08:00","readingtime":8,"relpermalink":"/blog/sofa-ark-overview/","summary":"本篇开始将正式启动 SOFAArk:Lab/ 源码共建系列，在此对长期以来对 SOFAStack 关注的朋友表示感谢。 本文为《剖析 | SOFAArk 源码》第一篇，本篇作者卫恒，SOFAArk 开源负责人","tags":["SOFAArk","剖析 | SOFAArk 源码 ","SOFALab"],"title":"蚂蚁金服轻量级类隔离框架概述 | SOFAArk 源码解析","type":"blog","url":"/blog/sofa-ark-overview/","wordcount":3808},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\nSeata：Simple Extensible Autonomous Transaction Architecture，是一套一站式分布式事务解决方案，提供了 AT、TCC、Saga 和 XA 事务模式，其中长事务解决方案 Saga 模式有着无锁高性能、异步架构高吞吐的优势。\nSeata：https://github.com/seata/seata\nSaga 状态机在线设计器：http://seata.io/saga_designer/index.html\nSaga 状态机设计器视频教程：http://seata.io/saga_designer/vedio.html\n**1、@李宇博 **提问：\n 您好，我这边看视频直接把 Catch 直接拖到 serviceTask 上，好像没有生效，需要连线还是配置什么属性吗？\n A：没有生效是指什么？Catch 要连一个线到一个其它的 state，意思是捕获到异常后，去执行一个分支，这个 state可以是任何类型的 state，比如 CompensationTrigger、ServiceTask，通常是 CompensationTrigger，立即触发补偿。\n 我是直接连接到 compensateTrigger 上的，然后我手动抛出异常，并没有执行补偿方法，而是在不停的重试调用之前抛出异常的方法。\n A：需要在线上配置异常类型：\n2、@J～杰 提问：\n 咨询一个问题，AT 模式分支事物注册的时候会获取锁，锁名就是和 table+主键有关系的，由于压力测试的时候，有个 check 去数据库查询同一个 rowkey，导致直接获取锁失败，在业务上就是业务失败回滚了，这种有啥办法？\n A：你的意思是热点数据问题吗？\n 可以理解成热点数据，我这边的测试场景就是下单减库存，2个微服务，库存由于基本上是同一行库存数据。\n A：热点数据撞锁是正常的，你可以用自旋锁，让其它事务等待一下再获取锁，而不是立即失败。http://seata.io/zh-cn/docs/user/configurations.html\n 本地调用 Dubbo 微服务是可以的，用 Saga 状态机就报这个问题，报服务没有提供者。\n A：你的 Service 是用的 XML 注册的还是用的注解注册的？\n 注解的方式。\n A：嗯嗯。你尝试用 XML 方法注册一个 Bean 看看行不行，机制上可能有不一样，因为 Saga 状态机是通过 getBean 反射去调方法。而 Dubbo 的注解是通过代理的方式来注入一个对象，这个对象是不是一个有完全成功的 Bean，不确定。之前我遇到过 TCC 用注解不好使，用 XML 好使的问题。\n本周推荐阅读  基于 Knative 打造生产级 Serverless 平台 | KubeCon NA2019 将 Sidecar 容器带入新的阶段 | KubeCon NA 2019  SOFARegistryLab 系列  服务注册中心如何实现秒级服务上下线通知 | SOFARegistry 解析 蚂蚁金服服务注册中心 Session 存储策略 | SOFARegistry 解析 蚂蚁金服服务注册中心数据分片和同步方案详解 | SOFARegistry 解析 蚂蚁金服服务注册中心 MetaServer 功能介绍和实现剖析 | SOFARegistry 解析 蚂蚁金服服务注册中心 SOFARegistry 解析 | 服务发现优化之路 海量数据下的注册中心 - SOFARegistry 架构介绍  SOFA 项目进展 本周发布详情如下：\n1、发布 MOSN v0.9.0 版本，主要变更如下： i. 重构了包引用路径，从 sofastack.io/sofa-mosn 变更为 mosn.io/mosn； ii. 支持变量机制，accesslog 修改为使用变量机制获取信息； iii. 修复在 proxy 协程 panic 时导致的内存泄漏； iv. 修复在特定的场景下，读写协程卡死导致的内存泄漏； v. 修复 HTTP2 Stream 计数错误的 bug；\n详细发布报告：https://github.com/mosn/mosn/releases/tag/0.9.0\n社区直播预告 新年快乐~2020年第一期线上直播来啦，SOFAChannel#10 将和大家一起探讨 《分布式事务 Seata 长事务解决方案 Saga 模式详解》，将从金融分布式应用开发的痛点出发，结合 Saga 分布式事务的理论和使用场景，讲解如何使用 Seata Saga 状态机来进行服务编排和分布式事务处理，构建更有弹性的金融应用，同时也会从架构、原理、设计、高可用、最佳实践等方面剖析 Saga 状态机的实现。\n主题：SOFAChannel#10：分布式事务 Seata 长事务解决方案 Saga 模式详解\n时间：2020年1月9日（下周四）19:00-20:00\n嘉宾：陈龙（花名：屹远） 蚂蚁金服分布式事务核心研发、Seata Committer\n形式：线上直播\n报名方式：点击“这里”，即可报名\n","date":1578038400,"description":"【12/31-01/03】 | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20200103/","fuzzywordcount":1900,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"aa8f76ccca9d7d700e3d9b16c2b0df21","permalink":"/blog/sofa-weekly-20200103/","publishdate":"2020-01-03T16:00:00+08:00","readingtime":4,"relpermalink":"/blog/sofa-weekly-20200103/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | 1.9直播预告、MOSN 发版、Saga 状态机设计器视频教程","type":"blog","url":"/blog/sofa-weekly-20200103/","wordcount":1866},{"author":"米麒麟","categories":"SOFARegistry","content":" SOFAStack （Scalable Open Financial Architecture Stack） 是蚂蚁金服自主研发的金融级云原生架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。\n SOFARegistry 是蚂蚁金服开源的具有承载海量服务注册和订阅能力的、高可用的服务注册中心，在支付宝/蚂蚁金服的业务发展驱动下，近十年间已经演进至第五代。\n本文为《剖析 | SOFARegistry 框架》第六篇，本篇作者子懿，来自阿里云。《剖析 | SOFARegistry 框架》系列由 SOFA 团队和源码爱好者们出品，项目代号：SOFA:RegistryLab/，文末包含往期系列文章。\nGitHub 地址：https://github.com/sofastack/sofa-registry\n前言 微服务架构为了保证所有服务可用，当服务发生问题时能及时摘除有问题的服务，需要定期检测服务可用性即健康检测。健康检测包括客户端心跳和服务端主动探测两种方式，定期发送 TCP 或 HTTP 请求根据响应确定服务是否正常。服务注册中心提供服务注册和订阅服务，在服务发布者服务信息发生变化、或者节点上下线时通知变更，动态更新消费方的服务地址列表信息，支持服务注册和下线的快速变更通知。\n本文重点围绕服务的健康检测、SOFARegistry 的健康检测以及基于 SOFARegistry 实现秒级服务注册下线等方面剖析 SOFARegistry 如何实现秒级服务上下线通知原理，阐述如何使用 SOFARegistry 对于服务的注册下线场景通过推送机制快速实现端到端的传达功能：\n 如何实现服务的健康检测？业界服务注册中心的健康机制是怎样的？SOFARegistry 的健康检测实现方式？ SOFARegistry 服务注册下线数据流转过程是怎样的？SOFARegistry 内部角色如何实现秒级服务上下线通知？  服务的健康检测 服务的健康检测是如何实现？健康检测分为客户端心跳和服务端主动探测两种方式：\n 客户端心跳  客户端采取每隔一定时间间隔主动发送心跳方式向服务端表明自己的服务状态正常，心跳是 TCP 或者 HTTP 的形式； 通过维持客户端和服务端的 Socket 长连接自己实现客户端心跳的方式； ZooKeeper 没有主动的发送心跳，而是依赖组件本身提供的临时节点的特性，通过 ZooKeeper 连接的 Session 维持临时节点； 客户端心跳中长连接的维持和客户端的主动心跳偏重服务链路是否正常，不一定是服务状态正常；服务端主动调用服务健康检查是比较准确的方式，通过返回结果成功判断服务状态健康情况；   服务端主动探测  服务端调用服务发布者 HTTP 接口来完成健康检测； 对于没有提供 HTTP 服务的 RPC 应用，服务端调用服务发布者的接口来实现健康检测； 通过执行脚本形式来进行定时检测； 服务端主动探测依然存在问题。服务注册中心主动调用 RPC 服务的某个接口无法做到通用性；在很多场景下服务注册中心到服务发布者的网络是不通的，服务端无法主动发起健康检查；    注册中心的健康检测 业界服务注册中心的健康检测机制：\n Eureka：定期有 Renew 心跳，数据具有 TTL（Time To Live）；并且支持自定义 HealthCheck 机制，当 HealthCheck 检测出系统不健康时主动更新 Instance 的状态； Zookeeper：定期发送连接心跳以保持会话 （Session），会话本身 （Session） 具有TTL； Etcd：定期通过 HTTP 对数据进行 Refresh，数据具有 TTL。申请 Lease 租约，设置服务生存周期TTL； Consul：Agent 定期对服务进行 healthcheck，支持 HTTP/TCP/Script/Docker；由服务主动定期向 agent 更新 TTL；  SOFARegistry 的健康检测 业界服务注册中心的健康检测都有个共同的关键词：“定期”。定期检测的时间周期通常设置为秒级，比如 3 秒、5 秒或 10 秒，甚至更长，也就是说服务的健康状态总是滞后的。蚂蚁金服的注册中心从最初的版本设计开始，就把健康状态的及时感知，当做一个重要的设计目标，特别是需要做到“服务宕机能被及时发现”。因此 SOFARegistry 在健康检测的设计方面决定“服务数据与服务发布者的实体连接绑定在一起，断连马上清数据”，简称此特点叫做连接敏感性。连接敏感性是指在 SOFARegistry 里所有 Client 都与 SessionServer 保持长连接，每条长连接都设置基于 SOFABolt 的连接心跳，如果长连接断连客户端立即发起重新建连，时刻保持 Client 与 SessionServer 之间可靠的连接。\nSOFARegistry 将服务数据 （PublisherRegister） 和服务发布者 （Publisher） 的连接的生命周期绑定在一起：每个 PublisherRegister 定义属性 connId，connId 由注册本次服务的 Publisher 的连接标识 （IP 和 Port）构成，也就是只要该 Publisher 和 SessionServer 断连，服务信息数据即失效。客户端重新建连成功后重新注册服务数据，重新注册的服务数据会被当成新的数据，考虑更换长连接后 Publisher 的 connId 是 Renew 新生成的。\n譬如当服务的进程宕机时，一般情况下 OS 立刻断开进程相关的连接（即发送 FIN），因此 SessionServer 能够实时感知连接断开事件，然后把该 connId 相关的所有 PublisherRegister 都清除，并且及时推送给所有服务订阅者 （Subscriber）。如果只是网络问题导致连接断开，实际的服务进程没有宕机，此时客户端立即发起重新连接 SessionServer 并且重新注册所有服务数据。对服务订阅者本身来说接收到的是服务发布者经历短暂的服务下线后以及再次重新上线。假如此过程耗时足够短暂（例如 500ms 内发生断连和重连），服务订阅者可能感受不到服务下线，因为 DataServer 内部的数据通过 mergeDatum 延迟合并变更的 Publisher 服务信息，version 是合并后最新的版本号。\n服务上下线过程 服务的上下线过程是指服务通过代码调用执行常规注册（Publisher#register） 和下线（Publisher#unregister）操作，不考虑因为服务宕机等意外情况导致的下线场景。\n“一次服务注册过程”的服务数据在 SOFARegistry 内部流转过程：\n 客户端 Client 调用服务发布者 Publisher 的 register 向 SessionServer 注册服务。 SessionServer 接收到服务数据即 PublisherRegister 写入内存 （SessionServer 存储 Client 的服务数据到内存，用于后续跟 DataServer 做定期检查）， …","date":1577955600,"description":" 本文为《剖析 | SOFARegistry 框架》第六篇，作者米麒麟","dir":"blog/sofa-registry-service-offline-notification/","fuzzywordcount":4200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"289ee5ccb8ee61cdd0a42ce60874284b","permalink":"/blog/sofa-registry-service-offline-notification/","publishdate":"2020-01-02T17:00:00+08:00","readingtime":9,"relpermalink":"/blog/sofa-registry-service-offline-notification/","summary":"SOFAStack （Scalable Open Financial Architecture Stack） 是蚂蚁金服自主研发的金融级云原生架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来","tags":["SOFARegistry","剖析 | SOFARegistry 框架","SOFALab"],"title":"服务注册中心如何实现秒级服务上下线通知 | SOFARegistry 解析","type":"blog","url":"/blog/sofa-registry-service-offline-notification/","wordcount":4114},{"author":"潘潘","categories":"SOFAChannel","content":"概要   活动主题：SOFAChannel#10：分布式事务 Seata 长事务解决方案 Saga 模式详解\n  活动时间：1 月 9 日周四晚 7 点\n  活动形式：线上直播\n  活动回顾：戳这里\n  介绍 | SOFAChannel \u0026amp;lt;SOFA:Channel/\u0026amp;gt; 有趣实用的分布式架构频道：前沿技术、直播 Coding、观点“抬杠”，多种形式。\n\u0026amp;lt;SOFA:Channel/\u0026amp;gt; 将作为 SOFA 所有在线内容的承载，包含直播/音视频教程，集中体现 SOFAStack 的能力全景图。\n| SOFAChannel#10：分布式事务 Seata 长事务解决方案 Saga 模式详解 Seata 意为：Simple Extensible Autonomous Transaction Architecture，是一套一站式分布式事务解决方案，提供了 AT、TCC、Saga 和 XA 事务模式，其中长事务解决方案 Saga 模式有着无锁高性能、异步架构高吞吐的优势。\n本期为 SOFAChannel 线上直播第 10 期，将邀请 蚂蚁金服 分布式事务核心研发 \u0026amp;amp; Seata Committer 屹远 和大家一起探讨 《分布式事务 Seata 长事务解决方案 Saga 模式详解》，将从金融分布式应用开发的痛点出发，结合 Saga 分布式事务的理论和使用场景，讲解如何使用 Seata Saga 状态机来进行服务编排和分布式事务处理，构建更有弹性的金融应用，同时也会从架构、原理、设计、高可用、最佳实践等方面剖析 Saga 状态机的实现。\n| 加入 SOFA 钉钉互动群 欢迎加入直播互动钉钉群：23372465（搜索群号加入即可）\n| 点击即可报名 https://tech.antfin.com/community/live/1076\n议程 19:00-19:05 主持人开场 SOFAGirl 主持人\n19:05-20:00 蚂蚁金服 Service Mesh 双十一落地详解 屹远 蚂蚁金服分布式事务核心研发、Seata Committer\n本期分享大纲：  金融分布式应用开发的痛点 Seata Saga 理论基础以及使用场景 基于状态机引擎的 Saga 实现 Seata Saga 模式最佳实践以及优势  嘉宾  SOFAGirl 主持人 屹远 蚂蚁金服分布式事务核心研发、Seata Committer  ","date":1577765400,"description":"1 月 9 日周四晚 7 点，线上直播第 10 期。","dir":"activities/sofa-channel-10/","fuzzywordcount":700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"a2f7bb983d4cbad1bda1a48a3c99abb7","permalink":"/activities/sofa-channel-10/","publishdate":"2019-12-31T12:10:00+08:00","readingtime":2,"relpermalink":"/activities/sofa-channel-10/","summary":"概要 活动主题：SOFAChannel#10：分布式事务 Seata 长事务解决方案 Saga 模式详解 活动时间：1 月 9 日周四晚 7 点 活动形式：线上直播 活动回顾：戳这","tags":["SOFAChannel","Seata"],"title":"SOFAChannel#10：分布式事务 Seata 长事务解决方案 Saga 模式详解","type":"activities","url":"/activities/sofa-channel-10/","wordcount":627},{"author":"董一韬、王轲","categories":null,"content":"本文推荐知道的背景知识：\n Kubernetes 的基本原理和各大组件的职责； Serverless 计算的基本概念和它的优势； Plus: 对社区 Knative 项目的基本了解；  本文根据董一韬和王轲在 KubeCon NA 2019 大会分享整理。\n**董一韬 蚂蚁金服，产品经理，**致力于驱动云计算相关产品，包括云原生 PaaS 平台、容器与 Serverless 产品等，与最终顾客紧密合作，帮助客户在规模化的金融场景下采用与落地云原生相关解决方案。\n**王轲 蚂蚁金服，软件工程师，**建设基于 Kubernetes/Knative 的企业级 Serverless 产品，Knative 的早期使用者，Kubernetes 社区成员、控制面流控早期维护者，长期致力于用创新的方式优化、落地云原生技术。\n一. 分享概要 Knative 是 Google 主导的基于 Kubernetes 的 Serverless 平台，在社区上有较高的知名度。然而，身为社区项目的 Knative 主要关心的是标准、架构。虽有先进的理念，却离可在生产上使用有不少的差距。\n本次 KubeCon 的演讲中，来自蚂蚁金服 SOFAStack-PaaS 平台产品技术团队的隐秀和仲乐与大家分享蚂蚁金服金融科技 Knative 的实践和改造：基于 Knative 构建一个优秀的 Serverless 计算平台，详细分析如何用独特的技术，解决性能、容量、成本三大问题。\n从 Serverless 计算的应用场景开始，提炼客户真正的 Use Case，分公有云、私有云、行业云等，讲述 Serverless 计算的多种用途。之后我们将介绍在 Kubernetes 上运行 Knative 平台的方案，详细介绍要使其生产可用，不得不克服的问题。演讲最后，将刚刚的这些问题一一攻破，做出一个比社区版本优秀的 Knative 平台。\n二. 解决性能问题：使用 Pod 预热池 熟悉 Kubernetes 的同学可能知道，Kubernetes 的首要目标并不是性能。\n在一个大规模的 Kubernetes 集群下，要创建一个新的 Pod 并让它跑起来，是很慢的。这是因为这整个链路很长：先要向 APIServer 发一个 POST 请求，再要等 Scheduler 收到新 Pod 资源被创建的事件，再等 Scheduler 在所有的 Node 上运行一遍筛选、优选算法并把调度结果返回给 API Server，再到被选中 Node 的 Kubelet 收到事件，再到Docker 镜像拉取、容器运行，再到通过安全检查并把新的容器注册到 Service Mesh 上…\n任何一个步骤都有可能出现延时、丢事件，或失败（如调度时资源不足是很常见的）。就算一切都正常工作，在一个大规模的 Kubernetes 集群里，整个链路延时达到20s，也是很常见的。\n这便导致在 Kubernetes 上做 Serverless 的窘境：Serverless 的一大特点是自动扩缩容，尤其是自动从0到1，不使用时不占任何资源。但如果一个用户用 Serverless 跑自己的网站/后端，但用户的首个请求花费20s才成功，这是无法接受的。\n为了解决冷启性能问题，我们团队提出了一个创造性的解决方案：使用 Pod 预热池（Pod Pool）。\n我们的产品会预先创建许多个 Pod 并让它们运行起来，当 Kubernetes 的控制器希望创建一个新的 Pod 的时候，我们不再是从零开始新建一个 Pod，而是找到一个处于待命状态的符合条件的 Pod，并把代码注入这个 Pod，直接使用。\n在演讲中，我们分享了一定技术实现的细节，例如如何创建 CRD 并 fork Kubernetes 的 ControllerManager，来以较小的成本实现新 Workload；如何自动根据历史的使用数据来自动伸缩 Pod 池的水位；如何做代码注入等。我们提了3种方式，分别是给容器发指令让容器中的进程下载并执行代码包、使用 Ephemeral Container、魔改 Kubelet允许替换 Container。\n实际的实现比这个还要复杂，要考虑的问题更多，例如如何响应 Pod 中不同的资源 request、limit。我们实际上也实现了一个调度器。当某个预热好的 Pod 不能满足，会看那个 Pod 所在 Node 上的资源余量，如果余量够则动态改 Kubernetes 控制面数据和 cgroups，实现“垂直扩容”。\n实际操作证明，这个冷启优化的效果非常好，当 Pod 大小固定、代码包缓存存在时，启动一个最简单的 HTTP 服务器类型应用的耗时从近20秒优化到了2秒，而且由于不需要当场调度 Pod，从0到1的稳定性也提升了很多。\n这个优化主要是跳过了若干次 API Server 的交互、Pod Schedule 的过程和 Service Mesh 注册的过程，用户程序从零到一的体验得到极大的提升，又不会招致过多的额外成本。一般来讲多预留10-20个 Pod 就可以应付绝大多数情况，对于少见的短时间大量应用流量激增，最坏情况也只是 fallback 到原先的新创建 Pod 的链路。\nPod 预热池不光可以用来做冷启优化，还有很多其他的应用场景。演讲中我呼吁将这种技术标准化，来解决 Kubernetes 数据面性能的问题。会后有观众提出 cncf/wg-serverless 可能有兴趣做这件事情。\n三. 降低成本：共享控制面组件 在成本方面，我们和大家分享了多租户改造和其他的降低成本的方式。\n如果以单租户的方式运行社区版的 Knative，成本是昂贵的：需要部署 Kubernetes 控制面和 Service Mesh 控制面，因为这些都是 Knative 的依赖，Knative 本身的控制面也很占资源。十几C几十G 的机器就这样被使用了，不产生任何业务价值。因此，共享这些控制面的组件是非常必要的。\n通过共享，用户不必再单独为基础设施买单。控制面的成本也只和每个租户创建的应用的数量之和有关，而不会再和租户多少产生关联。\n我们推荐两种共享的方式，一种是 Namespace 隔离+ RBAC 权限控制，这种控制面共享的方法是最简单、Kubernetes 原生支持，也广为使用的一种方法。另一种方法是蚂蚁金服金融科技自研 Kubernetes 实现的多租户方案，通过在 etcd 中多加一级目录并把每个用户的数据存在他们自己的目录中，实现真正全方位多租户的 Kubernetes。\n演讲中还提到了其他的一些降低成本的方法，如通过 Virtual Kubelet 对接阿里云的 ECI（按需的容器服务）、通过 Cluster AutoScaler 来自动释放使用率低的 Kubernetes 节点或从阿里云购置 ECS 来增加新的节点以水平扩容等。还简单提了一下多个租户的容器共享同一个宿主机可能面临的安全问题，如 Docker 逃逸。一种可能的解决方法是使用 Kata Container（虚拟机）以避免共享 Linux 内核。\n四. 解决容量问题：每个层级都做好对分片的支持 容量方面的挑战在于当 Workload 数量增 …","date":1577707200,"description":" 本文基于 Knative 构建一个优秀的 Serverless 计算平台，详细分析如何用独特的技术，解决性能、容量、成本三大问题。","dir":"blog/knative-serverless-kubecon-na2019/","fuzzywordcount":3500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"ceeb7bee775048b0c23fe553fc5cd335","permalink":"/blog/knative-serverless-kubecon-na2019/","publishdate":"2019-12-30T20:00:00+08:00","readingtime":7,"relpermalink":"/blog/knative-serverless-kubecon-na2019/","summary":"本文推荐知道的背景知识： Kubernetes 的基本原理和各大组件的职责； Serverless 计算的基本概念和它的优势； Plus: 对社区 Knative 项目的基本了解； 本文根据董一韬和王轲在 KubeCon NA 2019 大会","tags":["Knative","Serverless"],"title":" 基于 Knative 打造生产级 Serverless 平台 | KubeCon NA2019","type":"blog","url":"/blog/knative-serverless-kubecon-na2019/","wordcount":3408},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\n社区 Big News SOFAStack 社区上线了 SOFA Community 试运行方案，欢迎社区内更多的同学参与我们，加入共建❤\n社区随时都欢迎各种贡献，无论是简单的错别字修正、bug 修复还是增加新功能，欢迎提 issue 或 pull request 至 Github 社区。\nSOFA Community 期待你的加入：https://www.sofastack.tech/community/\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n**1、@包和平 **提问：\n 请问 Seata Saga 状态机可以跨服务来配置吗？案例中的 springcloud-eureka-feign-mybatis-seata 这个和我们的情况类似。这个默认的不是 AT 模式吗？我想使用 Saga 的状态机来配置整个流程，这个情况就涉及了三个服务 storage order account，我看 demo 中都是在单个服务中配置的状态机，所以想询问一下怎么配置。  A：可以跨服务调用，而且服务用不同的 RPC 框架也是可以的，Saga 的事例在 seata-sample 仓库有，Seata 仓库的 test 模块也有很多事例。文档地址：http://seata.io/zh-cn/docs/user/saga.html\n 有 Saga 模式的 spring feign 方式的配置 demo 吗？\n A：没有，不过 Seata Saga 只需要是一个 bean 就可以调用，理论上和什么 RPC 框架无关。\n A 服务的状态机 a_state.json 设置的子状态机是在 B 服务上配置的 b_state.json，可以这样设置吗？\n A：A 服务如果是通过状态机实现的，例如 a_state.json，这个状态机可以调用 B 服务，B 服务也可以是状态机实现的，例如 b_state.json，这两个状态机都不是子状态机，而 a_state.json 其实只知道调到了一个服务，而它内部是什么实现的它不知道。子状态机是要再同一个应用内，才可以被其它状态机调用，跨了应用，则认为只是一个服务。\n Seata 还支持其他方式实现 Saga？ 我看好像都是状态机呢，是我遗漏了哪里吗?\n A：目前是只有状态机。未来会有通过注解+拦截器实现。我所说的“A 服务如果是通过状态机实现的”，服务的实现是可以任何方式的，不是 Saga 的实现。实现一个服务，自己编码也能实现，和框架无关。\n 这个意思其实只是在 A 中调用了 feignClient 是这个意思吧?\n A：是的。\n2、@李宇博 提问：\n Saga 状态机设计器很多属性和文档不太一样呢。\n A：没有和文档不一致的属性吧。你看到的设计器生成的 json，是因为它带了布局信息，它的 stateProps 是和文档是一致的，其它属性是设计器生成的，不需要关心。\n 我没有找到 startState 属性，然后我以为要自己写 next 属性，好像是连线解决了这个问题，还有一点不太明白，就是一个事务只用设计一个 compensationTrigger么？\n A：是的，是用 Start 后面的连线解决，所以不需要 startState 属性了。 compensationTrigger 可以有任意多个，看怎么画好看就行。\n start、success、fail、choice 节点都省去了配置么？还有 compensationtrigger。\n A： Start 里有配置状态机的名称，描述，版本什么的、fail 里可以配置错误码和错误信息，succed 和 choice 应该只有一个名称，没其他的了。\n 嗯嗯，compensationTrigger 是不是也不用配置了?\n A：不用，也是 id 不重就行。\n3、@赵润泽 提问：\n TCC 模式下的事务发起者和 AT 模式下的事务发起者，被代理后执行的操作是一样的吗？\n A：TccActionInterceptor 拦截的是 TwoPhaseBusinessAction 注解也就是拦截的是分支事务，在之前 TM 已经做了 begin，这个是通过 GlobalTransactional 的 intercept 开启的。\n TCC 事务的开启和 AT 事务的开启流程是一样的吗，毕竟都是一个注解？\n A： 是一样的，都是发起方加 GlobalTransactional 注解，对于 TCC 分支来说都要额外加一个 TwoPhaseBusinessAction 注解。\n本周推荐阅读  将 Sidecar 容器带入新的阶段 | KubeCon NA 2019  Mesh 化落地实践特辑阅读  蚂蚁金服 Service Mesh 大规模落地系列 - 控制面篇 蚂蚁金服 Service Mesh 大规模落地系列 - Operator 篇 蚂蚁金服 Service Mesh 大规模落地系列 - 网关篇 蚂蚁金服 Service Mesh 大规模落地系列 - RPC 篇 蚂蚁金服 Service Mesh 大规模落地系列 - 运维篇 蚂蚁金服 Service Mesh 大规模落地系列 - 消息篇 蚂蚁金服 Service Mesh 大规模落地系列 - 核心篇 Service Mesh 落地负责人亲述：蚂蚁金服双十一四大考题  社区活动预告 就在明天，Service Mesh Meetup 第9期杭州站，本期与滴滴联合举办，将深入 Service Mesh 的落地实践，并带领大家探索 Service Mesh 在更广阔领域的应用，现场还有机会获得 Istio 官方 T 恤 以及 相关技术书籍。明天，不见不散~\n主题：Service Mesh Meetup#9 杭州站：To Infinity and Beyond\n时间：2019年12月28日（明天）13:00-17:30\n地点：杭州西湖区紫霞路西溪谷G座8楼\n报名方式：点击“这里”，即可报名\n","date":1577430000,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20191227/","fuzzywordcount":2000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"026916366f7c75abaf698dabaed81047","permalink":"/blog/sofa-weekly-20191227/","publishdate":"2019-12-27T15:00:00+08:00","readingtime":4,"relpermalink":"/blog/sofa-weekly-20191227/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | 明日活动信息、社区方案上线、落地系列阅读","type":"blog","url":"/blog/sofa-weekly-20191227/","wordcount":1953},{"author":"封尘","categories":"Service mesh","content":"本文为《蚂蚁金服 Service Mesh 大规模落地系列》第七篇 - 控制面篇，该系列将会从核心、RPC、消息、无线网关、控制面、安全、运维、测试等模块对 Service Mesh 双十一大规模落地实践进行详细解析。文末包含往期系列文章。\n引言 Service Mesh 是蚂蚁金服下一代架构的核心，本次主题主要分享在蚂蚁金服当前的体量下，控制面平稳支撑大规模 Sidecar 的落地实践。聚焦控制面核心组件 Pilot 和 Citadel，分享蚂蚁金服双十一控制面如何管理并服务好全站 Sidecar。\n本次分享主要分为两大部分，分别是：\n Pilot 落地实践； Citadel 安全加固；  Pilot 落地实践 在开始分享落地实践之前，我们先来看看 Istio 的架构图：\n理想很丰满，现实很骨感。由于性能等方面的综合考虑，我们在落地过程中，将控制面的组件精简为 Pilot 和 Citadel 两个组件了，不使用因性能问题争议不断的 Mixer，不引入 Galley 来避免多一跳的开销。\n在架构图中，控制面组件 Pilot 是与 Sidecar 交互最重要的组件，负责配置转化和下发，直面 Sidecar 规模化带来的挑战。这也是双十一大促中，控制面最大的挑战。\n规模化的问题在生产实践中，是一个组件走向生产可用级的必经之路。接下来将会分别从稳定性、性能优化、监控这三个方面分别展开。\n稳定性增强 我们先梳理下 Pilot 提供的服务能力，从功能实现上来看，Pilot 是一个 Controller + gRPC Server 的服务，通过 List/Watch 各类 K8s 资源，进行整合计算生成 XDS 协议的下发内容，并提供 gRPC 接口服务。本次分享我们先把关注点放在 gRPC 接口服务这个环节，如何保证接口服务支撑大规模 Sidecar 实例，是规模化的一道难题。\n负载均衡\n要具备规模化能力，横向扩展能力是基础。Pilot 的访问方式我们采用常用的 DNSRR 方案，Sidecar 随机访问 Pilot 实例。由于是长连接访问，所以在扩容时，原有的连接没有重连，会造成负载不均。为解决这个问题，我们给 Pilot 增加了连接限流、熔断、定期重置连接功能，并配合 Sidecar 散列重连逻辑，避免产生连接风暴。\n 连接限流  为了降低大量 MOSN 同时连接同一个 Pilot 实例的风险，在 gRPC 首次连接时，Pilot 增加基于令牌桶方案的流控能力，控制新连接的处理响应，并将等待超时的连接主动断连，等待 Sidecar 下一次重连。\n 熔断  基于使用场景的压测数据，限制单实例 Pilot 同时可服务的 Sidecar 数量上限，超过熔断值的新连接会被Pilot 主动拒绝。\n 定期重置  为了实现负载均衡，对于已经存在的旧连接，应该怎么处理呢？我们选择了 Pilot 主动断开连接，不过断开连接的周期怎么定是个技术活。要考虑错开大促峰值，退避扩缩容窗口之类，这个具体值就不列出来了，大家按各自的业务场景来决定就好了。\n Sidecar 散列重连  最后还有一点是 Client 端的配合，我们会控制 Sidecar 重连 Pilot 时，采用退避式重试逻辑，避免对 DNS 和 Pilot 造成负载压力。\n性能优化 规模化的另一道难题是怎么保证服务的性能。在 Pilot 的场景，我们最关注的当然是配置下发的时效性了。性能优化离不开细节，其中部分优化是通用的，也有部分优化是面向业务场景定制的，接下来会分享下我们优化的一些细节点。\n 首次请求优化  社区方案里 Pilot 是通过 Pod.Status 来获取 Pod 的 IP 信息，在小集群的测试中，这个时间基本秒级内可以完成。然而在大集群生产环境中，我们发现 Status 的更新事件时间较慢，甚至出现超过 10s 以上的情况，而且延迟时间不稳定，会增加 Pilot 首次下发的时延。我们通过与基础设施 K8s 打通，由 PaaS 侧将 Pod 分配到的 IP 直接标记到Pod.Annotation 上，从而实现在第一次获取 Pod 事件时，就可以获取到 IP，将该环节的时延减少到0。\n 按需获取 \u0026amp;amp; Custom Resource 缓存  这是一个面向 DBMesh 业务场景的定制性优化，是基于按需获取的逻辑来实现的。其目的在于解决 DBMesh CR 数量过多，过大导致的性能问题，同时避免 Pilot 由于 List/Watch CR 资源导致 OOM 问题，Pilot 采用按需缓存和过期失效的策略来优化内存占用。  局部推送  社区方案中当 Pilot List/Watch 的资源发生变更时，会触发全部 Sidecar 的配置推送，这种方案在生产环境大规模集群下，性能开销是巨大的。举个具体例子，如果单个集群有 10W 以上的 Pod 数量，任何一个 Pod 的变更事件都会触发全部 Sidecar 的下发，这样的性能开销是不可接受的。\n优化的思路也比较简单，如果能够控制下发范围，那就可以将配置下发限制在需要感知变更的 Sidecar 范围里。为此，我们定义了 ScopeConfig CRD 用于描述各类资源信息与哪些 Pod 相关，这样 Pilot 就可以预先计算出配置变更的影响范围，然后只针对受影响的 Sidecar 推送配置。\n 其他优化  强管控能力是大促基本配备，我们给 Pilot Admin API 补充了一些额外能力，支持动态变更推送频率、推送限流、日志级别等功能。\n监控能力 安全生产的基本要求是要具备快速定位和及时止血能力，那么对于 Pilot 来说，我们需要关注的核心功能是配置下发能力，该能力有两个核心监控指标：\n 下发时效性  针对下发的时效性，我们在社区的基础上补充完善了部分下发性能指标，如下发的配置大小分布，下发时延等。\n 配置准确性  而对于配置准确性验证是相对比较复杂的，因为配置的准确性需要依赖 Sidecar 和 Pilot 的配置双方进行检验，因此我们在控制面里引入了 Inspector 组件，定位于配置巡检，版本扫描等运维相关功能模块。\n配置巡检的流程如下：\n Pilot 下发配置时，将配置的摘要信息与配置内容同步下发； MOSN 接收配置时，缓存新配置的摘要信息，并通过 Admin API 暴露查询接口； Inspector 基于控制面的 CR 和 Pod 等信息，计算出对应 MOSN 的配置摘要信息，然后请求 MOSN 接口，对比配置摘要信息是否一致；  由于 Sidecar 的数量较大，Inspector 在巡检时，支持基于不同的巡检策略执行。大体可以分为以下两类：\n 周期性自动巡检，一般使用抽样巡检； SRE 主动触发检查机制；  Citadel 安全方案 证书方案 Sidecar 基于社区 SDS 方案 （Secret Discovery Service），支持证书动态发现和热更新能力。同时蚂蚁金服是一家金融科技公司，对安全有更高的要求，不使用 Citadel 的证书自签发能力，而是通过对接内部 KMS 系统获取证书。同时提供证书缓存和证书推送更新能力。\n我们先来看看架构图，请看图：\n对整体 …","date":1577271600,"description":" 本文为《蚂蚁金服 Service Mesh 大规模落地系列》第七篇 - 控制面篇，聚焦控制面核心组件 Pilot 和 Citadel，分享蚂蚁金服双十一控制面如何管理并服务好全站 Sidecar。","dir":"blog/service-mesh-practice-in-production-at-ant-financial-part7-control-plane/","fuzzywordcount":3800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"f7e9ad6fafaa6db46864cf0704d2b145","permalink":"/blog/service-mesh-practice-in-production-at-ant-financial-part7-control-plane/","publishdate":"2019-12-25T19:00:00+08:00","readingtime":8,"relpermalink":"/blog/service-mesh-practice-in-production-at-ant-financial-part7-control-plane/","summary":"本文为《蚂蚁金服 Service Mesh 大规模落地系列》第七篇 - 控制面篇，该系列将会从核心、RPC、消息、无线网关、控制面、安全、运维、测试等模块对 Service Mesh 双十一大","tags":["Service mesh","Service Mesh 落地实践"],"title":"蚂蚁金服 Service Mesh 大规模落地系列 - 控制面篇","type":"blog","url":"/blog/service-mesh-practice-in-production-at-ant-financial-part7-control-plane/","wordcount":3783},{"author":"徐迪、张晓宇","categories":null,"content":"图为 KubeCon NA 2019 大会分享现场照\nSpeaker:\n 徐迪 蚂蚁金服技术专家：负责蚂蚁金融云PaaS平台建设，Kubernetes 社区老兵，核心代码库贡献量社区前50； 张晓宇 阿里云技术专家：负责阿里巴巴云原生应用容器平台的生态建设，主要设计和研发节点稳定性和资源利用率相关解决方案，同时也是 Kubernetes 社区热心的成员和贡献者。  本文根据徐迪和张晓宇在 KubeCon NA2019 大会分享整理。分享将会从以下几个方面进行切入：首先会简单介绍一下什么是 Sidecar 容器；其次，我们会分享几个蚂蚁金服和阿里巴巴集团的通用场景，以及我们是如何解决这些挑战的。当然，现在还是有很多的挑战需要后续继续解决，邀请大家与我们一同努力。\nSidecar 简介 Sidecar 容器并不是一个新鲜事物。它是一种设计模式，主要用来做一些辅助的工作，比如网络连通性、下载拷贝文件之类的事情；如果大家熟悉 Docker Swarm 的话，就会发现 Docker Ambassador 其实就是 Sidecar。\n看看如上这个例子，Service Consumer 和 Redis Provider 强耦合，部署在同一个节点上。如果这个时候，Redis Provider 出现问题，需要连接到另外一个 Redis 实例上，需要重新配置，并重启 Service Provider。\n那么在引入了 Ambassador 以后，问题变得相对简单些，只需要重启这里的 Redis Ambassador 即可，并不需要 Service Consumer 进行任何变动。\n当然这种模式，还可以进行跨节点通信，比如下图。这样 Service Consumer 和 Redis Provider 就可以部署在不同的节点上。在某种程度上，很容易地就将两种服务进行了解耦。\nSidecar 案例分享 Sidecar 容器能用来干什么？ 一般来讲，Sidecar 容器可以：\n 日志代理/转发，例如 fluentd； Service Mesh，比如 Istio，Linkerd； 代理，比如 Docker Ambassador； 探活：检查某些组件是不是正常工作； 其他辅助性的工作，比如拷贝文件，下载文件等； \u0026amp;hellip;  仅此而已？ 事实上，Sidecar 越来越被大家接受，并且使用越来越广泛。Sidecar 容器通常和业务容器（非 Sidecar 容器）部署在同一个 Pod 里，共享相同的生命周期，为业务容器提供辅助功能。这是一个非常好的模式，能够极大程度解耦应用，并且支持异构组件，降低技术壁垒。\n但目前 Kubernetes 对 Sidecar 的管理还不完善，越来越不满足我们的使用，尤其是在生产环境中使用 Sidecar。\n几个典型案例 1. 顺序依赖 假设我们在一个 Pod 内注入了多个 Sidecar，但是 Sidecar 之间或者 Sidecar 和业务容器之间有相互依赖关系。\n如下这个例子，我们需要先启动 proxy Sidecar 容器用于建立网络连接，这样 mysql client 才能连接到远端的 mysql 集群，并在本地暴露服务。而后主的业务容器才能正常工作。\n#1 proxy_container (sidecar) #2 mysql_client #3 svc_container 当然，有的人会觉得这个地方，可以通过诸如更改镜像启动脚本延迟启动等方法来解决。但是这些方法侵入性太强，不利于扩展，还很难进行准确的配置。\n2. Sidecar 管理 我们来看看另外一个案例。Sidecar 容器和业务容器耦合在同一个 Pod 内，共享相同的生命周期。因此，单独来管控 Sidecar 容器非常不方，比如更新 Sidecar 的镜像。\n比如，我们已经给很多 Pod 注入了 Istio Proxy 这样的 Sidecar 容器，目前运行状态良好。但是如果这个时候我们想升级这个 Proxy 镜像的话，该怎么办？\n如果按照 Istio 社区官方的文档，我们需要重新注入这些 Sidecar 容器。具体来说，需要删除原有 Pod，重新生成一份新的 Pod（有些 workload 关联的 Pod，会由相应的 workload 控制器自动生成）。\n那如果我们有很多个这样的 Pod 需要处理的话，怎么办？通过命令行的话，太不方便，而且容易出错。通过自己单独写的代码的话，可扩展性是个问题，需要频繁更改这些代码。\n而且这里还有另外一个问题，我们肯定不会一下子升级所有的 Sidecar，肯定要有个灰度的过程，也就是只升级一部分 Sidecar，这个时候又该怎么办呢？\n社区进展 上游社区 这里我们非常感谢 Joseph Irving (@Joseph-Irving) 提出了一个 Sidecar kep，通过定义 LifecycleType 来区分是否是 Sidecar 容器。\ntype Lifecycle struct { // Type  // One of Standard, Sidecar.  // Defaults to Standard  // +optional  Type LifecycleType `json:\u0026amp;#34;type,omitempty\u0026amp;#34; protobuf:\u0026amp;#34;bytes,3,opt,name=type,casttype=LifecycleType\u0026amp;#34;` } // LifecycleType describes the lifecycle behaviour of the container type LifecycleType string const ( // LifecycleTypeStandard is the default container lifecycle behaviour  LifecycleTypeStandard LifecycleType = \u0026amp;#34;Standard\u0026amp;#34; // LifecycleTypeSidecar means that the container will start up before standard containers and be terminated after  LifecycleTypeSidecar LifecycleType = \u0026amp;#34;Sidecar\u0026amp;#34; ) 未来只需要在 Pod Spec 中，按如下方式标记即可：\nname: sidecarContainer image: foo lifecycle: type: Sidecar Pod 内容器的启动顺序按照：初始化容器-\u0026amp;gt;Sidecar 容器-\u0026amp;gt;业务容器 的顺序依次启动。\n其中上述 kep 的 kubelet 端实现 正在进行中。\n为了支持 Sidecar 更多的使用场景，我们以此为基础提出了 PreSidecar 和 PostSidecar，分别用于在业务容器之前和之后启动。具体的使用场景见 我们的 PR。\n为什么我们觉得 Sidecar 应该区分前置和后置呢？\n这是因为在一些场景下，我们需要 Sidecar 容器优先 …","date":1577188800,"description":" 本文主要介绍了什么是 Sidecar 容器，蚂蚁金服和阿里巴巴集团的通用场景，以及我们是如何解决这些挑战的。","dir":"blog/sidacar-kubecon-na2019/","fuzzywordcount":3000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"db0769ed83607e39fba6020d4eba87b8","permalink":"/blog/sidacar-kubecon-na2019/","publishdate":"2019-12-24T20:00:00+08:00","readingtime":6,"relpermalink":"/blog/sidacar-kubecon-na2019/","summary":"图为 KubeCon NA 2019 大会分享现场照 Speaker: 徐迪 蚂蚁金服技术专家：负责蚂蚁金融云PaaS平台建设，Kubernetes 社区老兵，核心代码库贡献量社区前50； 张","tags":["Sidecar 容器"],"title":" 将 Sidecar 容器带入新的阶段 | KubeCon NA 2019","type":"blog","url":"/blog/sidacar-kubecon-na2019/","wordcount":2993},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动\n我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@番番 提问：\n MOSN 的配置信息在哪里呢？\n A：MOSN 配置信息已更新到文档中：https://www.sofastack.tech/projects/sofa-mosn/configuration/overview/\n2、@古月 提问：\n 请问 SOFARPC 服务注册 ip 怎么使用主机 ip，不使用分配给容器的 ip？开发时调用容器内的服务调用不到，容器内的服务注册 ip 为 docker 分配的 ip。\n A：https://www.sofastack.tech/projects/sofa-rpc/application-rpc-config/ com.alipay.sofa.rpc.enabled.ip.range # 多网卡 ip 范围 com.alipay.sofa.rpc.bind.network.interface # 绑定网卡 可以通过网卡/ip段过滤；\nSOFARPC：https://github.com/sofastack/sofa-rpc\n SOFABoot 的服务运行在容器内，注册到注册中心的 ip 为容器的 ip，开发机器的调用不到。\n A：下面的两个参数，容器内端口映射到宿主机，virtual.host 用宿主机的去注册， com.alipay.sofa.rpc.virtual.host com.alipay.sofa.rpc.virtual.port\nSOFABoot：https://github.com/sofastack/sofa-boot\n3、@聂风 提问：\n SpringCloud 的项目怎么迁移到 SOFA 有这方面的教程文档吗？\n A：可以先参考下这个工程 https://github.com/sofastack/spring-cloud-sofastack-samples ，SOFAStack 集成 SpringCloud 的案例工程，不知道是不是对你有帮助。\n4、@周小斌 提问：\n Seata 以后会考虑集成分库分表和读写分离功能吗（无业务入侵的方式）？\n A：一般是分库分表组件内部中集成 Seata，负载均衡本质上是在切换数据源，一种是通过 DB URL 这种对外是个黑盒，Seata 不需要关注。另外一种是分库分表组件中使用配置中心做对等库物理库配置，这种需要通过 Resource 的 Group 来定义，比如我在一个节点上执行完一阶段，但是在进行二阶段的时候进行了主备切换，这时候需要在新主节点完成回滚。\n5、@温明磊 提问：\n Saga 项目开启时间长了后，会报 java.sql.SQLException: No operations allowed after statement closed. 这个错误。这个类 DbAndReportTcStateLogStore 方法 recordStateMachineStarted。\n A：是不是因为你的数据源连接池配置有问题呢？可能没有配置 testOnBorrow 或者 testOnReturn。\n 是没有。\n A：你配置一个 testOnBorrow。\n 那能不能在数据库连接的代码里判断，还是必须配置 testOnBorrow？Seata Saga 的数据库连接那代码处理异常。\n A：testOnBorrow 是数据源连接池的配置，和 Seata Saga 无关的，连接池你可以用任何连接池，比如 durid，dbcp。\nSeata：https://github.com/seata/seata\n本周推荐阅读  蚂蚁金服 ZSearch 在向量检索上的探索  Mesh 化落地实践特辑阅读  蚂蚁金服 Service Mesh 大规模落地系列 - Operator 篇 蚂蚁金服 Service Mesh 大规模落地系列 - 网关篇 蚂蚁金服 Service Mesh 大规模落地系列 - RPC 篇 蚂蚁金服 Service Mesh 大规模落地系列 - 运维篇 蚂蚁金服 Service Mesh 大规模落地系列 - 消息篇 蚂蚁金服 Service Mesh 大规模落地系列 - 核心篇 Service Mesh 落地负责人亲述：蚂蚁金服双十一四大考题  SOFA 项目进展 本周发布详情如下：\n1、发布 Occlum v0.8.0 版本，主要变更如下：\n 重构 futex 实现，增加 FUTEX_REQUEUE 支持 支持 SGX 远程证明 增加 sendmsg 和 recvmsg 系统调用 增加 gRPC demo 增加 Intel OpenVINO demo 增加 SGX 远程证明 demo  详细发布报告： https://github.com/occlum/occlum/releases/tag/0.8.0\n2、发布 SOFABolt v1.6.1 版本，主要变更如下：\n 支持 SSL 支持 UserProcessor 生命周期的方法 支持用户自定义 SO_SND_BUF 和 SO_RCV_BUF 支持 RejectedException 的处理策略 优化了生命周期的检查，避免组件在关闭或启动前后仍然能够提供服务 优化了 DefaultConnectionManager 的构造方法以及其它的部分代码 修复 DefaultConnectionManager#check(Connection) 异常信息不完整的问题 修复 AbstractLifeCycle 启动/关闭的并发问题  详细发布报告： https://github.com/sofastack/sofa-bolt/releases/tag/v1.6.1\n社区活动预告 下周六 Service Mesh Meetup 第9期杭州站来啦，本期与滴滴联合举办，将深入 Service Mesh 的落地实践，并带领大家探索 Service Mesh 在更广阔领域的应用。欢迎参加~\n主题：Service Mesh Meetup#9 杭州站：To Infinity and Beyond\n时间：2019年12月28日（下周六）13:00-17:30\n地点：杭州西湖区紫霞路西溪谷G座8楼\n报名方式：点击“这里”，即可 …","date":1576825200,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20191220/","fuzzywordcount":1800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"c9e61e735545e48bd341dd6da7310440","permalink":"/blog/sofa-weekly-20191220/","publishdate":"2019-12-20T15:00:00+08:00","readingtime":4,"relpermalink":"/blog/sofa-weekly-20191220/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | MOSN 配置文档、SOFABolt 等组件发布、社区活动预告","type":"blog","url":"/blog/sofa-weekly-20191220/","wordcount":1781},{"author":"十倍","categories":null,"content":"图为 ZSearch 基础架构负责人十倍 2019 Elastic Dev Day 现场分享\n引言 ElasticSearch（简称 ES）是一个非常受欢迎的分布式全文检索系统，常用于数据分析，搜索，多维过滤等场景。蚂蚁金服从2017年开始向内部业务方提供 ElasticSearch 服务，我们在蚂蚁金服的金融级场景下，总结了不少经验，此次主要给大家分享我们在向量检索上的探索。\nElasticSearch 的痛点 ElasticSearch 广泛应用于蚂蚁金服内部的日志分析、多维分析、搜索等场景。当我们的 ElasticSearch 集群越来越多，用户场景越来越丰富，我们会面临越来越多的痛点：\n 如何管理集群； 如何方便用户接入和管理用户； 如何支持用户不同的个性化需求； \u0026amp;hellip;  为了解决这些痛点，我们开发了 ZSearch 通用搜索平台：\n 基于 K8s 底座，快速创建 ZSearch 组件，快捷运维，故障机自动替换； 跨机房复制，重要业务方高保； 插件平台，用户自定义插件热加载； SmartSearch 简化用户搜索，开箱即用； Router 配合 ES 内部多租户插件，提高资源利用率；  向量检索需求 基于 ElasticSearch 的通用搜索平台 ZSearch 日趋完善，用户越来越多，场景更加丰富。\n随着业务的飞速发展，对于搜索的需求也会增加，比如：搜索图片、语音、相似向量。\n为了解决这个需求，我们是加入一个向量检索引擎还是扩展 ElasticSearch 的能力使其支持向量检索呢？\n我们选择了后者，因为这样我们可以更方便的利用 ElasticSearch 良好的插件规范、丰富的查询函数、分布式可扩展的能力。\n接下来，我来给大家介绍向量检索的基本概念和我们在这上面的实践。\n向量检索基本概念 向量从表现形式上就是一个一维数组。我们需要解决的问题是使用下面的公式度量距离寻找最相似的 K 个向量。\n 欧式距离：  两点间的真实距离，值越小，说明距离越近；   余弦距离：  就是两个向量围成夹角的 cosine 值，cosine 值越大，越相似；   汉明距离：  一般作用于二值化向量，二值化的意思是向量的每一列只有0或者1两种取值。 汉明距离的值就两个向量每列数值的异或和，值越小说明越相似，一般用于图片识别；   杰卡德相似系数：  把向量作为一个集合，所以它可以不仅仅是数字代表，也可以是其他编码，比如词，该值越大说明越相似，一般用于相似语句识别；    因为向量检索场景的向量都是维度很高的，比如256，512位等，计算量很大，所以接下来介绍相应的算法去实现 topN 的相似度召回。\n向量检索算法 KNN 算法 KNN 算法表示的是准确的召回 topK 的向量，这里主要有两种算法，一种是 KDTtree，一种是 Brute Force。我们首先分析了 KDTree 的算法，发现 KDTree 并不适合高维向量召回，于是我们实现的 ES 的 Brute Force 插件，并使用了一些 Java 技巧进行加速运算。\nKDTree 算法 简单来讲，就是把数据按照平面分割，并构造二叉树代表这种分割，在检索的时候，可以通过剪枝减少搜索次数。\n构建树\n以二维平面点(x,y)的集合(2,3)，(5,4)，(9,6)，(4,7)，(8,1)，(7,2)为例：\n图片来源\n 按照 x 排序，确定中间值7，其他坐标分两边； 第二层按照 y 排序，第三层按照 x 排序； 并且在构建时维护每个节点中的 x 最大最小，y 最大最小四个值；  查找最近点\n图片来源\n搜索(3,5)的最近邻：\n 到根节点距离为5； 遍历到右节点(9,6)，发现整棵右子树的x轴，最小值是8，所以所有右子树的节点到查询节点的距离一定都大于8-3=5，于是所有右子树的节点都不需要遍历； 同理，在左子树，跟(5，4)节点比较，(7,2)被排除； 遍历完(2,3),(4,7)，最近点(5,4) 返回；  结论 Lucene 中实现了 BKDTree，可以理解为分块的 KDTree，并且从源码中可以看到 MAX_DIMS = 8，因为 KDTree 的查询复杂度为 O(kn^((k-1)/k))，k 表示维度，n 表示数据量。说明 k 越大，复杂度越接近于线性，所以它并不适合高维向量召回。\nBrute Force 顾名思义，就是暴力比对每一条向量的距离，我们使用 BinaryDocValues 实现了 ES 上的 BF 插件。更进一步，我们要加速计算，所以使用了 JAVA Vector API 。JAVA Vector API 是在 openJDK project Panama 项目中的，它使用了 SIMD 指令优化。\n结论 使用 avx2 指令优化，100w 的 256 维向量，单分片比对，RT 在 260ms，是常规 BF 的 1/6。 ElasticSearch 官方在7.3版本也发布了向量检索功能，底层也是基于 Lucene 的 BinaryDocValues，并且它还集成入了 painless 语法中，使用起来更加灵活。\nANN 算法 可以看到 KNN 的算法会随着数据的增长，时间复杂度也是线性增长。例如在推荐场景中，需要更快的响应时间，允许损失一些召回率。\nANN 的意思就是近似 K 邻近，不一定会召回全部的最近点。ANN 的算法较多，有开源的 ES ANN 插件实现的包括以下这些：\n 基于 Hash 的 LSH； 基于编码的 IVFPQ； 基于图的 HNSW；  ZSearch 依据自己的业务场景也开发了 ANN 插件（适配达摩院 Proxima 向量检索引擎的 HNSW 算法）。\nLSH 算法 Local Sensitive Hashing 局部敏感 hash，我们可以把向量通过平面分割做 hash。例如下面图例，0表示点在平面的左侧，1表示点在平面的右侧，然后对向量进行多次 hash，可以看到 hash 值相同的点都比较靠近，所以在 hash 以后，我们只需要计算 hash 值类似的向量，就能较准确的召回 topK。\nIVF-PQ 算法 PQ 是一种编码，例如图中的128维向量，先把向量分成4份，对每一份数据做 kmeans 聚类，每份聚类出256个聚类中心，这样，原始向量就可以使用聚类中心的编号重新编码，可以看出，现在表示一个向量，只需要用4个字节就行。然后当然要记录下聚类中心的向量，它被称之为码本。\n图片来源\nPQ 编码压缩后，要取得好的效果，查询量还是很大，所以前面可以加一层粗过滤，如图，把向量先用 kmeans 聚类成1024个类中心，构成倒排索引，并且计算出每个原始向量与其中心的残差后，对这个残差数据集进行 PQ 量化。用 PQ 处理残差，而不是原始数据的原因是残差的方差能量比原始数据的方差能量要小。\n这样在查询的时候，我们先找出查询出靠近查询向量的几个中心点，然后再在这些中心点中去计算 PQ 量化后的 top 向量，最后把过滤出来的向量再做一次精确计算，返回 topN 结果。\n图片来源\nHNSW 算法 讲 HNSW 算法之前，我们先来讲 NSW 算法，如下图，它是一个顺序构建图流程：\n 例如第5 …","date":1576670400,"description":" 本文整理自 2019 Elastic Dev Day 现场分享，主要给大家分享蚂蚁金服在向量检索上的探索。","dir":"blog/antfin-zsearch-vector-search/","fuzzywordcount":4700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"194a0b7104c5147b2fd54e8c74b17e22","permalink":"/blog/antfin-zsearch-vector-search/","publishdate":"2019-12-18T20:00:00+08:00","readingtime":10,"relpermalink":"/blog/antfin-zsearch-vector-search/","summary":"图为 ZSearch 基础架构负责人十倍 2019 Elastic Dev Day 现场分享 引言 ElasticSearch（简称 ES）是一个非常受欢迎的分布式全文检索系统，常用于数据分析，搜索","tags":["ZSearch"],"title":" 蚂蚁金服 ZSearch 在向量检索上的探索","type":"blog","url":"/blog/antfin-zsearch-vector-search/","wordcount":4634},{"author":"应明","categories":"Service mesh","content":"本文为《蚂蚁金服 Service Mesh 大规模落地系列》第六篇 - Operator 篇，该系列将会从核心、RPC、消息、无线网关、控制面、安全、运维、测试等模块对 Service Mesh 双十一大规模落地实践进行详细解析。文末包含往期系列文章。\n引言 Service Mesh 是蚂蚁金服下一代技术架构的核心，也是蚂蚁金服内部双十一应用云化的重要一环，本文主要分享在蚂蚁金服当前的体量下，如何支撑应用从现有微服务体系大规模演进到 Service Mesh 架构并平稳落地。\n本文作者：杜宏伟（花名：应明），蚂蚁金服技术专家，关注 API 网关，Service Mesh 和容器网络，蚂蚁金服 Service Mesh 核心成员。\n为什么需要 Service Mesh 在此之前，SOFAStack 作为蚂蚁金服微服务体系下服务治理的核心技术栈，通过提供 Cloud Engine 应用容器、SOFABoot 编程框架（已开源）、SOFARPC（已开源） 等中间件，来实现服务发现和流量管控等能力。经过若干年的严苛金融场景的锤炼，SOFAStack 已经具备极高的可靠性和可扩展性，通过开源共建，也已形成了良好的社区生态，能够与其他开源组件相互替换和集成。在研发迭代上，中间件类库已经与业务解耦，不过避免不了的是，运行时两者在同一个进程内，意味着基础库的升级需要推动业务方升级对应的中间件版本。\n我们一直在探索更好的技术实现方式。我们发现，Service Mesh 通过将原先通过类库形式提供的服务治理能力进行提炼和优化后，下沉到与业务进程协同，但独立运行的 Sidecar Proxy 进程中，大量的 Sidecar Proxy 构成了一张规模庞大的服务网络，为业务提供一致的，高质量的用户体验的同时，也实现了服务治理能力在业务无感的条件下独立进行版本迭代的目标。\n应用 Service Mesh 的挑战 Service Mesh 带给我们的能力很美好，但现实为我们带来的挑战同样很多。比方说数据面技术选型和私有协议支持，控制面与蚂蚁金服内部现有系统对接，配套监控运维体系建设，以及在调用链路增加两跳的情况下如何优化请求延迟和资源使用率等等。\n本文着重从 MOSN（Sidecar Proxy）的运维和风险管控方面，分享我们的实践经验，其他方面的挑战及应对方案，请参考系列分享中的其他文章。\nMOSN：https://github.com/sofastack/sofa-mosn\nSidecar 注入 创建注入 已经完成容器化改造，运行在 Kubernetes 中的应用，如何接入到 Service Mesh 体系中？最简单的方式，也是以 Istio 为代表的 Service Mesh 社区方案所采用的方式，即是在应用发布阶段，通过 mutating webhook 拦截 Pod 创建请求，在原始 Pod Spec 的基础上，为 Pod 注入一个新的 MOSN 容器。\n值得注意的是，在资源分配上，起初我们依据经验值，在应用 8G 内存的场景下，为 Sidecar 分配 512M 内存，即：\nApp: req=8G, limit=8G Sidecar: req=512M, limit=512M\n很快我们就发现了这种分配方案带来的问题，一方面部分流量比较高的应用的 MOSN 容器，出现了严重的内存不足甚至 OOM；另一方面注入进去的 Sidecar 容器额外向调度器申请了一部分内存资源，这部分资源脱离了业务的 quota 管控。\n因此，为了消除内存 OOM 风险和避免业务资源容量规划上的偏差，我们制定了新的“共享内存”策略。在这个策略下，Sidecar 的内存 request 被置为0，不再向调度器额外申请资源；同时 limit 被设置为应用的 1/4，保障 Sidecar 在正常运行的情况下，有充足的内存可用。为了确实达到“共享”的效果，蚂蚁金服 sigma 团队针对 kubelet 做了调整，使之在设置 Sidecar 容器 cgroups limit 为应用 1/4 的同时，保证整个 Pod 的 limit 没有额外增加（细节这里不展开）。\n当然，Sidecar 与应用“共享”分配到的内存资源，也导致了在异常情况（比如内存泄露）下，sidecar 跟应用抢内存资源的风险。如何应对这个风险？我们的做法是，通过扩展 Pod Spec（及相应的 apiserver, kubelet 链路），我们为 Sidecar 容器额外设置了 Linux oom_score_adj 这个属性，以保障在内存耗尽的情况下，Sidecar 容器会被 OOM Killer 更优先选中，以发挥 sidecar 比应用能够更快速重启，从而更快恢复到正常服务的优势。\n此外，在 CPU 资源的分配上，我们也遇到过在一些场景下，MOSN 抢占不到 CPU 资源从而导致请求延迟大幅抖动，解决方案是确保在注入 Sidecar 时，根据 Pod 内的容器数量，为每个 Sidecar 容器计算出相应的 cpushare 权重，并通过工具扫描并修复全站所有未正确设置的 Pod。\n原地注入 在创建 Pod 的时候注入 Sidecar，是一件相对比较“舒服“的接入方式，因为这种做法，操作起来相对比较简单，应用只需先扩容，再缩容，就可以逐步用带有 Sidecar 的 Pod，替换掉旧的没有 Sidecar 的 Pod。可问题是，在大量应用，大规模接入的时候，需要集群有较大的资源 buffer 来供应用实例进行滚动替换，否则替换过程将变得十分艰难且漫长。而蚂蚁金服走向云原生的目标之一则是，双十一大促不加机器，提高机器使用率。如果说我们要花更多的钱购买更多的机器来支持云原生，就多少有点事与愿违了。\n为了解决这个问题，我们提出了“原地注入”的概念，也就是说在 Pod 不销毁，不重建的情况下，原地把 Sidecar 注入进去。\n如图所示，原地注入由以下步骤构成：\n 在 PaaS 提交工单，选择一批需要原地注入的 Pod； PaaS 调用中间件接口，关闭业务流量并停止应用容器； PaaS 以 annotation 的形式打开 Pod 上的原地注入开关； Operator 观察到 Pod 原地注入开关打开，渲染 sidecar 模版，注入到 Pod 中并调整 cpu/memory 等参数； Operator 将 Pod 内容器期望状态置为运行； kubelet 将 Pod 内容器重新拉起； PaaS 调用中间件接口，打开业务流量；  Sidecar 升级 我们将 RPC 等能力从基础库下沉到 Sidecar 之后，基础库升级与业务绑定的问题虽然消除了，但是这部分能力的迭代需求依然存在，只是从升级基础库变成了如何升级 Sidecar。\n最简单的升级就是替换，即销毁 Pod 重新创建出一个新的，这样新建出来的 Pod 所注入的 Sidecar 自然就是新版本了。但通过替换的升级方式，与创建注入存在相似的问题，就是需要大量的资源 buffer，并且，这种升级方式对业务的影响最大，也最慢。\n非平滑升级 为了避免销毁重建 Pod，我们通过 Operator 实现了“非平滑升级”能力。\n如图所 …","date":1576501200,"description":" 本文着重从 MOSN（Sidecar Proxy）的运维和风险管控方面，分享我们的实践经验。","dir":"blog/service-mesh-practice-in-production-at-ant-financial-part6-operator/","fuzzywordcount":3800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"3528d4d6bd82bd170eccd20d98f5f7e2","permalink":"/blog/service-mesh-practice-in-production-at-ant-financial-part6-operator/","publishdate":"2019-12-16T21:00:00+08:00","readingtime":8,"relpermalink":"/blog/service-mesh-practice-in-production-at-ant-financial-part6-operator/","summary":"本文为《蚂蚁金服 Service Mesh 大规模落地系列》第六篇 - Operator 篇，该系列将会从核心、RPC、消息、无线网关、控制面、安全、运维、测试等模块对 Service Mesh 双十一大规模","tags":["Service mesh","Service Mesh 落地实践"],"title":" 蚂蚁金服 Service Mesh 大规模落地系列 - Operator 篇","type":"blog","url":"/blog/service-mesh-practice-in-production-at-ant-financial-part6-operator/","wordcount":3725},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动\n我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@温明磊 提问：\n 我用的 ShardingSqhere 分库分表，按照各个业务方分库。\u0026amp;gt; 所以我们项目里所有分库的表都带了业务方字段biz_code，这个字段的值也就是虚库的名字，都是写在配置里的。 A：从你的需求看，比较简单只是需要按业务方进行分库，而 biz_code 不在状态机日志表的字段里，你可以考虑先算好分库位，然后用 ShadingJDBC 的 hint 功能来设置分库位即可。\n A：我看了一下 ShardingJDBC 也是用的 ThreadLocal 来设置 hint：https://shardingsphere.apache.org/document/current/cn/manual/sharding-jdbc/usage/hint/\n ShadingJDBC 的 hint 功能是基于 ThreadLocal 的，Saga 异步的方式不能用 sharding jdbc 的吗?\n A：有一个优雅的办法：你实现 StateLogStore 接口，然后代理 Seata Saga 的DbAndReportTcStateLogStore，在每个方法前后加上：hintManager.addDatabaseShardingValue();、hintManager.close()，这样就和同步异步没有关系了，因为设置 hint 和 sql 执行都在同一个线程。\n另外，DbAndReportTcStateLogStore 如何传到你自己实现的 StateLogStore 里，你需要继承 DbStateMachineConfig，然后在 afterProperties 方法，先调 super.afterProperties 方法，然后 getStateLogStore()，传入你自己实现的 StateLogStore 里，然后把自己实现的 StateLogStore 调 setStateLogStore 覆盖。\n2、@Purge yao 提问：\n Saga 状态机在线设计器： http://seata.io/saga_designer/index.html 这个状态机可以让流程引擎用吗？\n A：不可以当工作流用，没有人工节点。\n Seata 用这个流程是干嘛用的？\n A：事实上 Seata Saga 模式 是一个具备“服务编排”和“Saga 分布式事务”能力的产品，总结下来它的适用场景是：\n 适用于微服务架构下的“长事务”处理； 适用于微服务架构下的“服务编排”需求； 适用于金融核心系统以上的有大量组合服务的业务系统（比如在渠道层、产品层、集成层的系统）； 适用于业务流程中需要集成遗留系统或外部机构提供的服务的场景（这些服务不可变不能对其提出改造要求）。  Seata：https://github.com/seata/seata\n**3、@anorqiu9 **提问：\n 关于 MOSN 我们目前遇到一个架构方面的问题，就是原基于 Dubbo 的服务和现在基于 Spring Cloud 的服务互调如何做？一种方案设计服务同时开启两个服务框架的服务接口为两个框架的服务同时提供服务;另一种方案是异构系统基于网关交互.这两种方案有什么优缺点？大家有没有碰到过类似的场景，是如何处理的？谢谢！\n A：Dubbo 和 Spring Cloud 互相调用，需要使用的是 http 接口来调用，个人推荐用网关来做交互，这样 API 的管理上更方便，当然也可以通过 Sidecar 来解决。\n 是的，我也倾向于网关交互，由网关完成协议的转换，进行包括流量控制、安全访问控制等在内的 API 管理工作。如果一个服务同时处于两种服务框架治理之下，就意味着对这个服务的治理（如限流、熔断及安全访问等）必须在两个地方进行，这将会是一个挑战。 当然，如果使用 Service Mesh 架构，通过 Sidecar 如 MOSN 来实现多 RPC 协议的支持，同时又能通过 Service Mesh 的控制平面实现服务治理的统一，这样就不存在上述说的挑战。 MOSN：https://github.com/sofastack/sofa-mosn\n 本周推荐阅读  蚂蚁金服 DB Mesh 的探索与实践  Mesh 化落地实践特辑阅读  蚂蚁金服 Service Mesh 大规模落地系列 - 网关篇 蚂蚁金服 Service Mesh 大规模落地系列 - RPC 篇 蚂蚁金服 Service Mesh 大规模落地系列 - 运维篇 蚂蚁金服 Service Mesh 大规模落地系列 - 消息篇 蚂蚁金服 Service Mesh 大规模落地系列 - 核心篇 Service Mesh 落地负责人亲述：蚂蚁金服双十一四大考题  SOFA 项目进展 本周发布详情如下：\n1、发布SOFARPC v5.6.3，主要变更如下：\n 试验性支持 grpc； 试验性支持 H2 的 tls； 序列化方式支持 msgpack； 修复直接通过线程上下文指定的地址调用； 扩展加载过程日志改为 debug，防止错误信息过多； 升级 jackson 和 netty 的小版本；  详细发布报告： https://github.com/sofastack/sofa-rpc/releases/tag/v5.6.3\n2、发布 SOFAArk v1.1.0，主要变更如下：\n 支持在 Biz 中使用 Ark 扩展点机制； 修复遗漏处理加载 ark spi 类资源 bug； 提供全新的biz/plugin 生命周期事件； 优化SOFAArk 自身日志输出； 优化 SOFAArk 与 SOFABoot 日志依赖管控； telnet 服务支持退出指令； 升级 netty 版本到 4.1.42.Final； 迁移 sofa-ark-samples 到 https://github.com/sofastack-guides/sofa-ark-samples  详细发布报告： https://github.com/sofastack/sofa-ark/releases/tag/v1.1.0\n3、发布 SOFABoot v3.2.1，主要变更如下：\n 版本升 …","date":1576220400,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20191213/","fuzzywordcount":2300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"37b96cc1a849775521b4d2b78d6602ce","permalink":"/blog/sofa-weekly-20191213/","publishdate":"2019-12-13T15:00:00+08:00","readingtime":5,"relpermalink":"/blog/sofa-weekly-20191213/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"活动报名、本周 QA、组件发布 | SOFA Weekly","type":"blog","url":"/blog/sofa-weekly-20191213/","wordcount":2262},{"author":"潘潘","categories":"Service Mesh","content":"概要  活动主题：Service Mesh Meetup#9 杭州站：To Infinity and Beyond 活动时间：时间：2019 年 12 月 28 日（周六）13:00-17:30 活动地点：杭州西湖区紫霞路西溪谷G座8楼 活动形式：线下活动 活动回顾：请戳这里  活动介绍 关于 Service Mesh\n服务网格（Service Mesh）是致力于解决服务间通讯的基础设施层。它负责在现代云原生应用程序的复杂服务拓扑来可靠地传递请求。实际上，Service Mesh 通常是通过一组轻量级网络代理（Sidecar proxy），与应用程序代码部署在一起来实现，而无需感知应用程序本身。\n关于 ServiceMesher 社区\nServiceMesher 社区，专注于 Service Mesh 和云原生技术，立足开源，分享技术资讯和实践，致力于新技术的推广和普及。\nService Mesh Meetup #9 杭州站\nService Mesh Meetup 是由蚂蚁金服联合 CNCF 官方共同出品，ServiceMesher 社区主办，主题围绕服务网格、Kubernetes 及云原生，在全国各地循环举办的技术沙龙。\n本期 Meetup 与滴滴联合举办，将深入 Service Mesh 的落地实践，并带领大家探索 Service Mesh 在更广阔领域的应用。\n活动议程    时间 环节（分享主题） 分享嘉宾     13:00-13:30 签到    13:30-14:15 《蚂蚁金服 API Gateway Mesh 的思考与实践》 贾岛 蚂蚁金服 高级技术专家   14:15-15:00 《酷家乐的 Istio 与 Knative 踩坑实录》 付铖 酷家乐 容器化负责人   15:00-15:10 MOSN 社区化发布 涵畅   15:10-15:20 茶歇    15:20-16:00 圆桌环节-《Service Mesh 落地的务实与创新》 鲁直   16:00-16:45 《蚂蚁金服 Service Mesh 技术风险思考和实践》 嘉祁 蚂蚁金服 技术专家   16:45-17:30 《网易严选的 Service Mesh 实践》 王国云 网易严选 架构师    本期议题以及嘉宾详解 13:30-14:15《蚂蚁金服 API Gateway Mesh 的思考与实践》\n 讲师：贾岛 蚂蚁金服 高级技术专家 讲师介绍：靳文祥（花名贾岛），2011年毕业后加入支付宝无线团队，一直从事移动网络接入、API 网关、微服务等相关的研发工作，目前负责蚂蚁金服移动网络接入架构设计与优化。 Topic 介绍：在 Service Mesh 微服务架构中，我们常常会听到东西流量和南北流量两个术语。蚂蚁金服开源的Service Mesh Sidecar MOSN 已经多次与大家见面交流了，以往的议题重点在东西流量的服务发现与路由，那么蚂蚁金服在南北流量上的思考是怎样的？本次分享，将从蚂蚁金服 API 网关发展历程来看，Mesh 化的网关架构是怎样的，解决了什么问题，双十一的实践表现，以及我们对未来的思考。  14:15-15:00《酷家乐的 Istio 与 Knative 踩坑实录》\n 讲师：付铖 酷家乐 技术专家 讲师介绍：先后负责酷家乐户型图, 渲染引擎等模块，目前负责酷家乐国际站的研发。在业务开发过程中推动和布道云原生技术，并在部分业务落地了 Istio 服务治理和基于 Knative 的 Serverless 基础设施。 Topic 介绍：酷家乐在部分业务模块，自2018年使用了 Istio 进行服务治理，自2019年使用了 Knative 作为 FaaS 基础设施，在实践过程中解决了大量问题，也积累了不少第一手经验。本次分享，将重点讨论服务网格的性能损耗，存量业务迁移难题，函数计算的冷启动时间问题以及解决方案等。  15:20-16:00 圆桌环节《Service Mesh 落地的务实与创新》\n 主持人：鲁直 蚂蚁金服云原生落地负责人 嘉宾：  涵畅 蚂蚁金服高级技术专家 张超盟 华为云微服务平台架构师 付铖 酷家乐技术专家 王国云 网易严选架构师    16:00-16:45《蚂蚁金服 Service Mesh 技术风险思考和实践》\n 讲师：嘉祁 蚂蚁金服 技术专家 讲师介绍：黄家琦（花名：嘉祁）2012年毕业后加入阿里巴巴技术保障，2015年转入蚂蚁金服SRE，长期从事稳定性相关工作，当前重点关注于中间件，Service Mesh 与云原生基础设施的稳定性。 Topic 介绍：Servish Mesh 是微服务架构与云原生碰撞出的火花，对于传统的中间件体系与运维支撑能力是极大的挑战。本次分享的主题主要关注于在蚂蚁金服内部如何应对这些挑战，并建设相应的技术风险能力来保障其稳定。  16:45-17:30《网易严选的 Service Mesh 实践》\n 讲师：王国云 网易高级技术专家、网易严选架构师 讲师介绍：2008年加入网易，长期从事一线的研发与管理工作，曾参与或负责过网易博客、网易邮箱、网易有钱等多个核心产品的研发工作，擅长服务端架构及技术体系建设，现任严选支持业务研发部技术负责人，负责严选的容器化及 Service Mesh 演进。 Topic 介绍：网易严选在2016年选择了 Service Mesh 作为未来微服务改造的基础架构，并在过去几年支持了业务的持续快速增长。本次分享主要介绍 Service Mesh 在严选的落地和演进情况，讨论 Service Mesh 在混合云架构下落地遇到的挑战和我们的解决方案，同时也希望和大家交流一下在架构方面的一些思考。  加入 SOFA 钉钉互动群 群号：23390449，使用钉钉搜索群号即可加入，获取一手开源技术干货。\n主办方与合作伙伴  主办方：CNCF、ServiceMesher 协办方：蚂蚁金服、SOFAStack、滴滴 合作伙伴：掘金社区、开源中国、养码场、SegmentFault、麦思博、开源社  ","date":1576051200,"description":"本次 Meetup 与滴滴联合举办，将深入 Service Mesh 的落地实践，并带领大家探索 Service Mesh 在更广阔领域的应用。","dir":"activities/service-mesh-meetup-9/","fuzzywordcount":1900,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"a7103ed15ed823b9156082c37b7d464a","permalink":"/activities/service-mesh-meetup-9/","publishdate":"2019-12-11T16:00:00+08:00","readingtime":4,"relpermalink":"/activities/service-mesh-meetup-9/","summary":"概要 活动主题：Service Mesh Meetup#9 杭州站：To Infinity and Beyond 活动时间：时间：2019 年 12 月 28 日（周六）13:00-17:30 活动地点：杭州西湖区紫霞路","tags":["Meetup","Service Mesh"],"title":"Service Mesh Meetup#9 杭州站：To Infinity and Beyond","type":"activities","url":"/activities/service-mesh-meetup-9/","wordcount":1855},{"author":"改之","categories":"Service mesh","content":"蚂蚁金服数据访问层有三个核心组件：数据访问框架 ZDAL、数据访问代理 DBP 和 OceanBase 代理服务器 OBProxy。本篇主要涉及 ZDAL 和 OBProxy 两个组件。ZDAL 作为全站数据访问的标准组件，不仅提供了分库分表、读写分离、分布式 Sequence等标准的应用能力，还提供了链路跟踪、影子压测、单元化、容灾切换等技术风险能力 。OBProxy 作为 OceanBase 的访问入口，提供了 OceanBase 路由寻址、读写分离等数据库能力，同时从执行效率和资源成本角度考虑，从 OBProxy 诞生那天我们就采用了近应用的独立进程部署模式，目前生产环境上保持在几十万级别的进程数。\n本篇文章通过介绍当前蚂蚁金服数据访问层遇到的问题，解决的思路，演进的方向三个方面，期望能够用阐述下 DB Mesh 发展的一些思考并让更多同学认识到 DB Mesh。期望能够 DB Mesh 的方式将数据访问层下沉到统一的基础设施之上，让新业务快速使用上全站多年的技术风险能力，并能够持续享受到更多的性能、资源等技术红利。\n背景 随着业务的快速发展，ZDAL 作为客户端模式的组件，一直存在业务耦合、版本迭代推进、多语言支持等问题。OBProxy 是为 OceanBase 数据库专门量身定制的代理服务器，天然就是业务无耦合、支持多语言。用户的数据在 OceanBase 上以多副本的形式存放在各个 OBServer 上，OBProxy 则负责接收用户发过来的 SQL 请求，解析 SQL 请求并计算分区信息后，将用户请求转发到最佳目标 OBServer 上，并将执行结果给用户。在蚂蚁金服内部也存在分库分表组件 ZDAL，用在多 OceanBase 集群以及单元化的场景。两者配合使用，分库分表组件 ZDAL 做业务层的流量调拨，OceanBase 分区功能支持数据库的水平扩容能力。\n我们进一步看 ZDAL 和 OBProxy 这两个组件的核心逻辑。\nZDAL 的核心逻辑：\n SQL 解析器：获得表名及分库分表字段； 规则引擎：计算分库分表结果； 执行层：将 SQL 改写发给数据库，并做结果集合并用户；  OBProxy 的核心逻辑：\n 协议解析器：解析协议中的 SQL，Parse 后获得表名及分区字段； 路由器：计算分区表所在的 OBServer； IO 层：将请求转发给 OBServer，将结果集返回给客户端；  可以看出，OBProxy 和 ZDAL 这两个组件的执行路径有一定的重复度，比如两个组件都做了 SQL 解析，并分析表名和字段。这对性能带来一定的损耗，而且这种重复给研发迭代带来更多的工作量。\n基于前面的考虑将 ZDAL 和 OBProxy 两者合并成一个组件的是一个自然的方案，通过将 ZDAL 逻辑下沉到 OBProxy 中，让 OBProxy 提供了分库分表、读写分离、分布式序列等中间件能力，这个组件我们命名为 ODP（Open Database Proxy）。\nODP 作为近业务端部署的进程，虽然逻辑独立出来，升级时但是依然需要去改动业务的容器，所以迭代过程中的升级推进工作也是比较费时费力，而且 ODP 只是整个产品的冰山一角，需要大量的精力来构建冰山之下的基础设施，比如说如何解决 ODP 的运维问题、用户透明切换的方案、复杂配置的推送问题、金融级数据库密钥管理问题等。我们发现这部分与蚂蚁金服内部大规模实践的 ServiceMesh 遇到的问题有比较大的重合度，所以与 ServiceMesh 一起共建底层基础设施，为这块的完整产品方案命名为 DBMesh。下文会简单介绍一下我们的演进路线和发展方向。\n解决思路 Sidecar 模式以解耦部署 从执行效率和资源成本角度考虑，OBProxy 在蚂蚁金服一直都在采用近业务端部署的方式，日常保有的服务数在数十万的级别。近业务端部署虽然提供了高效率，但是也带来了运维上的复杂度，同时需要升级版本时，也需要和通知业务一起来做发布和升级。要让单个应用升级，基本都是按月计，如果涉及到全站层面的升级，时间基本不太好估算。\n但是随着云原生以及 Kubernetes 的发展，让 Sidecar 模式更为成熟，即在业务的容器旁边再运行一个容器，这个非常贴合我们近业务端部署的 OBProxy 进程，只需要将 OBProxy 进程改造成 OBProxy Sidecar，即可进行独立升级、发布、运维等。同时蚂蚁金服在云原生领域有非常深的实践，有着世界上最大规模的 Kubernetes 集群和 ServiceMesh 集群，将 OBProxy 变成 Sidecar 也是比较合理和方便实施的了。\n今年双十一切了约 10% 的数万个的 PODs 到 ODP Sidecar 模式，通过 Sidecar 的方式能够让业务快速享受到基础软件迭代的好处，本次双十一 ODP 修复了一个非预期日志打印导致某个机房出现慢 SQL 问题，在传统的本地进程方式，需要推动所有的业务进行拉迭代、发布、打包时间周期基本不太可控。而今年让所有涉及应用独立的灰度、升级仅花费两天时间。\n合并重复逻辑拿技术红利 解决了部署模式的问题，通过快速迭代并且独立升级的方式，才能让功能下沉的落地成为可能。我们将分库分表组件的大多数功能都下沉到了 ODP 上，比如：分库分表功能、读写分离功能、分布式 Sequence 功能、全链路跟踪等。如下图：\n整个分库分表组件功能下沉之后，在今年双十一我们在核心系统上线，拿到了一些非常可观的技术红利：\n **性能提升：**通过功能的合并可以省去额外的 SQL 解析和路由计算过程，双十一上线的系统 SQL 平均响应时间可以下降上百微秒； **启动速度：**应用只需要和 ODP 建立连接即可，无需初始化多个分库的数据源，初始化时间从数十秒降到数十毫秒； **内存下降：**和启动速度一样，由于应用和 ODP 的连接数减少了，同样也可以节省应用端的内存使用，生产上能够下降上百 MB；  共建 Mesh 基础设施完善技术风险 研发同学会将更多的关注点放在 ODP 数据链路上，如何提高数据平面的性能，如何增加更多的 SQL 特性，而会忽略非 SQL 执行链路上的诉求。DBMesh 作为应用侧的基础设施，更多的要考虑如何更好的管理 Sidecar、数据访问高安全防控、满足配置变更的三板斧要求、最大程度的节省资源成本等。\n我们在与蚂蚁金服 ServiceMesh 团队共建整个云原生下 Mesh 的技术风险能力，优先完善 Sidecar 的运维能力和变更三板斧能力，后续会将 ODP Sidecar 部署到宿主机上以最大程度优化 ODP 的资源占用，也会逐步下沉更多如影子压测、灰度机房、流量镜像等的技术风险能力。\n总结 DBMesh 让数据访问从客户端模式切换到代理模式，给应用带来了启动速度的极大优化。Sidecar 的部署模式则是 SQL 平均响应时间、资源利用的最优模式。将更多的技术风险能力沉淀进来，让新应用快速享受到金融级的技术风险能力，存量应用的技术风险指标更完善。我们期望通过统一的数据访问基础设施，让业务都使用标准的技术组件，降低学习以及维护成本，仅专注在业务开发和创新上。\n作者介 …","date":1575982800,"description":" 本篇文章通过介绍当前蚂蚁金服数据访问层遇到的问题，解决的思路，演进的方向三个方面，期望能够用阐述下 DB Mesh 发展的一些思考并让更多同学认识到 DB Mesh。","dir":"blog/ant-financial-db-mesh-explore-practice/","fuzzywordcount":2600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"9732786e2e2be0688d1e6a594838f87e","permalink":"/blog/ant-financial-db-mesh-explore-practice/","publishdate":"2019-12-10T21:00:00+08:00","readingtime":6,"relpermalink":"/blog/ant-financial-db-mesh-explore-practice/","summary":"蚂蚁金服数据访问层有三个核心组件：数据访问框架 ZDAL、数据访问代理 DBP 和 OceanBase 代理服务器 OBProxy。本篇主要涉及 ZDAL 和 OBProxy 两个组件。ZDAL 作为","tags":["Service mesh","DB Mesh"],"title":"蚂蚁金服 DB Mesh 的演进之路","type":"blog","url":"/blog/ant-financial-db-mesh-explore-practice/","wordcount":2573},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@温明磊 提问：\n 我们还是想用 redis 存状态机上下文一个大的实体，输入输出只放 id，我想问下，redis 宕机或者其它情况下，状态机 redis 宕机节点之前的节点都是幂等可重复的，那我怎样让它重新跑一边状态机？只能人工干预吗？\n A：你的意思是因为参数没有了，所以你想重跑状态机回放参数？\n 是的。从最开始跑，因为之前的节点幂等， 也没有变更数据，或者数据已经被 catch 住然后补偿了。\n A：我理解是你可以新启动一个状态机事例，把之前的生成的 id 传进上下文，这样和从新开始没有区别吧？不然你人工处理的话，需要把 state_inst 表里的数据删除。\n 嗯 ，我明白 ，通过定时就可以，因为在状态机开始之前 数据已经落库了。redis 宕机捕获异常后，可以给最开始的数据设置状态，然后定时开启状态机。但是 Saga 确实不能帮我完成定时重启状态机这个事情对吧，或者我就设置个补偿节点，专门用来重启新状态机实例的？这样可以？\n A：我建议是不要搞个补偿节点来处理非补偿的事，我觉得可以自己做个定时任务，然后处理这种情况。\nSeata：https://github.com/seata/seata\n2、@李林 提问：\n 数据面默认是能感知到所有服务的变更么？\n A：是的，因为对接了 SOFARegistry。\n 那当集群规模比较大的时候，是不是会出现感知较慢的情况呢？\n A：SOFARegistry 里有全量的服务订阅信息，MOSN 和 SOFARegistry 对接只会感知当前 MOSN 必须的服务信息，所以 MOSN 内的数据总量不会很大。\n Istio 控制面占用的资源比较多，MOSN 是做了优化么？\n A：你指的 Istio 控制面占用资源比较多指的是哪一部分？Mixer 么？\n 可以理解为只告知当前服务需要依赖的信息吧，这样的话数据量就小多了。\n A：是的。\n Pilot 在我们自己的集群里部署了，占用资源也挺多的，不过比 Mixer 小。 另外我查看数据面 Envoy 从 Pilot 拿到的数据信息挺多的，config_dump 的信息有 30 万行左右。\n A：我们暂时没有从 Pilot 拿服务注册数据，只有一些服务流量管控的配置从 Pilot 下发，Mixer 的能力是集成在 MOSN 内部的所以控制面的消耗还好，不是很重。\n 那应该是做了挺多优化调整的吧。\n A：是的，集成后省去了 Mixer 的两跳，Metrics 数据可以直接被采集。\n 那服务的依赖关系需要通过配置提供才能做到只感知需要依赖的服务吧？Metrics 的直接采集是通过 prometheus 直接抓取每个数据面节点的数据么？\n A：是的，通过 prometheus 协议定时有专门的 agent 抓取的数据。\nMOSN：https://github.com/sofastack/sofa-mosn\n3、@NameHaibinZhang 提问：\n 将 MOSN 按照容器化的方式部署，通过读取默认配置，暴露 15001 端口，MOSN 能够同时在一个端口接收不同协议的请求么，如 Http、SOFARPC 请求。\n A：MOSN 的默认配置都是一些 example，没有 15001 端口，你需要按照你的需求写你的配置。一个 listener 目前不能同时处理两种协议，listener 中 proxy 的配置指定了可以处理的协议。\n 15001 端口是按 Sidecar 方式部署的时候开启的端口，比如通过 Istio 来部署，iptables 中 Envoy 开启 15001 端口。\n A：目前同一个端口支持 tls/明文自定识别， http1/http2 的自动识别，协议哪儿配置 Auto。Http 和 SOFA 的识别目前不支持，有需求的话支持也很方便。\n 嗯，因为作为 Sidecar 部署的时候，http 的接口和 SOFA 接口都希望能通过 Sidecar 来做流量劫持，Auto 可以做 rpc 协议的支持和识别不？\n A：如果是做流量劫持的话，其实是不需要支持识别的，这个 15001 不会实际处理请求，会转发给正确的端口来处理。\n Sidecar 内部做一个转发是吧，开另外2个端口，那15001这个端口配置 TCP 协议了，然后接收到之前做判断是什么协议，转给对应的端口。\n A：可以看一下这篇文章：《SOFAMesh中的多协议通用解决方案x-protocol介绍系列（1）——DNS通用寻址方案》。\nSOFA 项目进展 本周发布详情如下：\n发布 Occlum v0.7.0 版本，主要变更如下：\n 重构了 ioctl 的实现； 增加了 socketpair； 实现了与Alpine Linux的二进制兼容性； 增加了 nanosleep； 增加了外部可调用命令的路径检查（即 occlum run 的）； 增加了 XGBoost 的 demo；  详细发布报告： https://github.com/occlum/occlum/releases/tag/0.7.0\n社区活动 回顾： 11月24日 Kubernetes \u0026amp;amp; Cloud Native X Service Mesh Meetup 活动回顾（含现场PPT以及视频回顾）：\n Service Mesh 在『路口』的产品思考与实践：务实是根本 深入Kubernetes 的“无人区” — 蚂蚁金服双十一的调度系统  12月5日 SOFAChannel#9 直播回顾：\n https://tech.antfin.com/community/live/1021/data/957  预告-专享福利： “剑指源码，尖峰对话”2019 OSC源创会是由 OSCHINA 主办的线下技术沙龙，理念为“自由、开放、分享”，SOFAStack 也受邀参加本次年终盛会，并带来主题分享。\n主题：《蚂蚁金服 Service Mesh 超大规模实践以及开源》\n嘉宾：卓与，蚂蚁金服 Mesh 化落地负责人\n时间：2019年12月15日下午14:05-14:40（架构分会场）\n专享福利：点击“这里”，验证码填写“SOFAStack”即可获得大会免费票。 …","date":1575615600,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20191206/","fuzzywordcount":2400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"aa9ec52b9b85a6c8830ff752423d1248","permalink":"/blog/sofa-weekly-20191206/","publishdate":"2019-12-06T15:00:00+08:00","readingtime":5,"relpermalink":"/blog/sofa-weekly-20191206/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | 每周精选【12/2 - 12/6】","type":"blog","url":"/blog/sofa-weekly-20191206/","wordcount":2358},{"author":"曹寅","categories":"Kubernetes","content":"一、前言 经过超过半年的研发，蚂蚁金服在今年完成了 Kubernetes 的全面落地，并使得核心链路100% 运行在 Kubernetes。到今年双十一，蚂蚁金服内部通过 Kubernetes 管理了数以万计的机器以及数十万的业务实例，超过90%的业务已经平稳运行在 Kubernetes 上。整个技术切换过程平稳透明，为云原生的资源基础设施演进迈好了关键的一步。\n本文主要介绍 Kubernetes 在蚂蚁金服的使用情况，双十一大促对 Kubernetes 带来史无前例的挑战以及我们的最佳实践。希望通过分享这些我们在实践过程中的思考，让大家在应用 Kubernetes 时能够更加轻松自如。\n二、蚂蚁金服的 Kubernetes 现状 2.1 发展历程与落地规模 Kubernetes 在蚂蚁金服落地主要经历了四个阶段：\n 平台研发阶段：2018年下半年蚂蚁金服和阿里集团共同投入 Kubernetes 技术生态的研发，力求通过 Kubernetes 替换内部自研平台； 灰度验证：2019年初 Kubernetes 在蚂蚁金服灰度落地，通过对部分资源集群进行架构升级以及灰度替换生产实例两种方式，让 Kubernetes 得以小规模的验证； 云化落地（蚂蚁金服内部基础设施云原生化）：2019年4月蚂蚁金服内部完成 Kubernetes 适配云化环境的目标，并于618之前完成云化机房100% 使用 Kubernetes 的目标，这是 Kubernetes 第一次在蚂蚁金服内部得到规模化的验证； 规模化落地：2019年618之后，蚂蚁金服内部开始全面推动 Kubernetes 落地，在大促之前完成核心链路100% 运行在 Kubernetes的目标，并完美支撑了双十一大考。  2.2 统一资源调度平台 Kubernetes 承载了蚂蚁金服在云原生时代对资源调度的技术目标：统一资源调度。通过统一资源调度，可以有效提升资源利用率，极大的节省资源成本。要做到统一调度，关键在于从资源层面将各个二层平台的调度能力下沉，让资源在 Kubernetes 统一分配。\n蚂蚁金服在落地 Kubernetes 实现统一调度目标时遵循了标准化的扩展方式：\n 一切业务扩展均围绕 Kubernetes APIServer，通过CRD + Operator方式完成业务功能的适配和扩展； 基础服务通过 Node 层定义的资源接口完成个性化适配，有益于形成资源接入的最佳实践。  得益于持续的标准化工作，我们在落地 Kubernetes 的大半年内应用了多项技术，包含安全容器，统一日志，GPU 精细调度，网络安全隔离及安全可信计算等，并通过 Kubernetes 统一使用和管理这些资源服务了大量在线业务以及计算任务型业务。\n三、双十一 Kubernetes 实践 下面我们通过以下几种场景介绍蚂蚁金服内部是如何使用 Kubernetes，以及在此过程中我们面对的挑战和实践之路。\n3.1 资源分时复用 在大促过程中，不同业务域的洪峰流量通常都是在不同时间段来临，而应对这些不同时间到来的业务流量往往都需要大量的额外计算资源做保障。在以往的几次活动中，我们尝试了通过应用快速腾挪的方式来做到资源上的分时复用，但是服务实例上下线需要预热，腾挪耗时不可控，大规模调度的稳定性等因素都影响了最终腾挪方案的实践效果。\n今年双十一我们采用了资源共享调度加精细化切流的技术以达到资源分时利用的目标，为了达到资源充分利用和极速切换的目标，我们在以下方面做了增强：\n 在内部的调度系统引入了联合资源管理（Union-Resource Management），他可以将波峰波谷不重叠的业务实例摆放在相同的资源集合内，达到最大化的资源利用。 研发了一套融合资源更新，流量切换及风险控制的应用分时复用平台，通过该平台SRE可以快速稳定的完成资源切换以应对不同的业务洪峰。  整套平台和技术最终实现了令人激动的成果：蚂蚁金服内部不同业务链路数以万计的实例实现了最大程度的资源共享，这些共享资源的实例可分钟级完成平滑切换。这种技术能力也突破了当下资源水平伸缩能力的效率限制，为资源的分时复用打开了想象空间。\n3.2 计算型任务混部 Kubernetes 社区的落地案例中，我们往往看到的都是各种各样的在线业务，计算型业务往往通过“圈地”式的资源申请和独立的二层调度跑在 Kuberentes 集群中。但是在蚂蚁内部我们从决定使用 Kubernetes 的第一天起，就将 Kubernetes 融合计算型业务实现资源的统一调度作为我们的目标。\n在蚂蚁金服内部我们持续的使用 Kubernetes 支持各类计算业务，例如各类AI 训练任务框架，批处理任务和流式计算等。他们都有一个共同的特点：资源按需申请，即用即走。\n我们通过 Operator 模型适配计算型任务，让任务在真正执行时才会调用 Kubernetes API 申请 Pod 等资源，并在任务退出时删除 Pod 释放资源。同时我们在调度引擎中引入了动态资源调度能力和任务画像系统，这为在线和计算的不同等级业务提供了分级资源保障能力，使在线业务不受影响的情况下资源被最大化的利用。\n今年双十一除了洪峰时间段（00：00~02：00），蚂蚁金服 Kubernetes 上运行的任务均未做降级，每分钟仍有数以百计的计算任务在 Kubernetes 上申请和释放。未来蚂蚁金服内部将会持续推动业务调度融合，将 Kubernetes 打造成为资源调度的航空母舰。\n3.3 规模化核心 蚂蚁金服是目前少数运行了全球最大规模的 Kubernetes 集群的公司之一，单集群机器规模过万，Pods 数量数十万。随着类似计算型任务混部和资源分时复用这类业务的落地，资源的动态使用以及业务自动化运维都对 Kubernetes 的稳定性和性能带来的巨大的挑战。\n首先需要面对的挑战是调度性能，社区的调度器在5k规模测试中调度性能只有1~2 pods/s，这显然无法满足蚂蚁金服的调度性能需求。\n针对同类业务的资源需求往往相同的特点，我们自研了批量调度功能，再加上例如局部的filters性能优化等工作，最终达到了百倍的调度性能提升！\n在解决了调度性能问题后，我们发现规模化场景下 APIServer 逐渐成为了影响 Kubernetes 可用性的关键组件，CRD+Operator 的灵活扩展能力更是对集群造成巨大的压力。业务方有100种方法可以玩垮生产集群，让人防不胜防。 造成这种现象一方面是由于社区今年以前在规模化上的投入较少 APIServer 能力较弱，另一方面也是由 Operator 模式的灵活性决定。开发者在收益于 Operator 高灵活度的同时，往往为集群管理者带来业务不受控制的风险。即使对 Kubernetes 有一定熟悉程度的开发者，也很难保障自己写出的 Operator 在生产中不会引爆大规模的集群。\n面对这种“核按钮”不在集群管理员手上的情况，蚂蚁内部通过两方面入手解决规模化带来的问题：\n 我们通过持续总结迭代过程中的经验，形成了内部的最佳实践原则，以帮助业务更好的设计Operator   CRD 在定义时需要明确未来的最大数量，大量CR …","date":1575464400,"description":"本文主要介绍 Kubernetes 在蚂蚁金服的使用情况，双十一大促对 Kubernetes 带来史无前例的挑战以及我们的最佳实践。","dir":"blog/kubernetes-practice-antfinal-shopping-festival/","fuzzywordcount":4000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"5e1572fd3da2309cb49050bc05e24450","permalink":"/blog/kubernetes-practice-antfinal-shopping-festival/","publishdate":"2019-12-04T21:00:00+08:00","readingtime":8,"relpermalink":"/blog/kubernetes-practice-antfinal-shopping-festival/","summary":"一、前言 经过超过半年的研发，蚂蚁金服在今年完成了 Kubernetes 的全面落地，并使得核心链路100% 运行在 Kubernetes。到今年双十一，蚂蚁金服内部通","tags":["Kubernetes"],"title":"深入 Kubernetes 的“无人区” — 蚂蚁金服双十一的调度系统","type":"blog","url":"/blog/kubernetes-practice-antfinal-shopping-festival/","wordcount":3956},{"author":"齐天","categories":"Service mesh","content":"一、引言 Service Mesh 是蚂蚁金服下一代架构的核心，经过了2年的沉淀，我们探索出了一套切实可行的方案并最终通过了双十一的考验。本文主要分享在当下『路口』，我们在产品设计上的思考和实践，希望能给大家带来一些启发。\n二、为什么需要 Service Mesh? 2.1 微服务治理与业务逻辑解耦 在 Service Mesh 之前，微服务体系的玩法都是由中间件团队提供一个 SDK 给业务应用使用，在 SDK 中会集成各种服务治理的能力，如：服务发现、负载均衡、熔断限流、服务路由等。\n在运行时，SDK 和业务应用的代码其实是混合在一个进程中运行的，耦合度非常高，这就带来了一系列的问题：\n 升级成本高  每次升级都需要业务应用修改 SDK 版本号，重新发布； 在业务飞速往前跑的时候，是不太愿意停下来做这些和自身业务目标不太相关的事情的；   版本碎片化严重  由于升级成本高，但中间件还是会向前发展，久而久之，就会导致线上 SDK 版本各不统一、能力参差不齐，造成很难统一治理；   中间件演进困难  由于版本碎片化严重，导致中间件向前演进过程中就需要在代码中兼容各种各样的老版本逻辑，戴着『枷锁』前行，无法实现快速迭代；    有了 Service Mesh 之后，我们就可以把 SDK 中的大部分能力从应用中剥离出来，拆解为独立进程，以 Sidecar 的模式部署。通过将服务治理能力下沉到基础设施，可以让业务更加专注于业务逻辑，中间件团队则更加专注于各种通用能力，真正实现独立演进，透明升级，提升整体效率。\n2.2 异构系统统一治理 随着新技术的发展和人员更替，在同一家公司中往往会出现使用各种不同语言、不同框架的应用和服务，为了能够统一管控这些服务，以往的做法是为每种语言、每种框架都重新开发一套完整的 SDK，维护成本非常高，而且对中间件团队的人员结构也带来了很大的挑战。\n有了 Service Mesh 之后，通过将主体的服务治理能力下沉到基础设施，多语言的支持就轻松很多了，只需要提供一个非常轻量的 SDK、甚至很多情况都不需要一个单独的 SDK，就可以方便地实现多语言、多协议的统一流量管控、监控等治理需求。\n图片来源\n2.3 金融级网络安全 当前很多公司的微服务体系建设都建立在『内网可信』的假设之上，然而这个原则在当前大规模上云的背景下可能显得有点不合时宜，尤其是涉及到一些金融场景的时候。\n通过 Service Mesh，我们可以更方便地实现应用的身份标识和访问控制，辅之以数据加密，就能实现全链路可信，从而使得服务可以运行于零信任网络中，提升整体安全水位。\n三、在当下『路口』的思考 3.1 云原生方案？ 正因为 Service Mesh 带来了上述种种的好处，所以这两年社区中对 Service Mesh 的关注度越来越高，也涌现出了很多优秀的 Service Mesh 产品，Istio 就是其中一款非常典型的标杆产品。\nIstio 以其前瞻的设计结合云原生的概念，一出现就让人眼前一亮，心之向往。不过深入进去看了之后发现，在目前阶段要落地的话，还是存在一些 gap 的。\n图片来源\n3.2 Greenfield vs Brownfield 在正式展开讨论之前，我们先来看一副漫画。\n图片来源\n上面这幅漫画描绘了这样一个场景：\n 有两个工人在工作，其中一个在绿色的草地（Greenfield）上，另一个在棕色的土地（Brownfield）上； 在绿色草地上的工人对在棕色土地上的工人说：“如果你没有给自己挖这么深的坑，那么你也可以像我一样做一些很棒的新东西”； 然后在棕色土地上的工人回答道：“你倒是下来试试！”；  这是一幅很有意思的漫画，从表面上看我们可以认为在绿色草地上的工人是站着说话不腰疼，不过其实本质的原因还是两者所处的环境不同。\n在一片未开发过的土地上施工确实是很舒服的，因为空间很大，也没有周遭各种限制，可以使用各种新技术、新理念，我们国家近几十年来的一些新区新城的建设就属于这类。而在一片已经开发过的土地上施工就大不一样了，周围环境会有各种限制，比如地下可能有各种管线，一不小心就挖断了，附近还有各种大楼，稍有不慎就可能把楼给挖塌了，所以做起事来就要非常小心，设计方案时也会受到各种约束，无法自由发挥。\n对于软件工程，其实也是一样的，Greenfield 对应着全新的项目或新的系统，Brownfield 对应着成熟的项目或遗留系统。\n我相信大部分程序员都是喜欢做全新的项目的，包括我自己也是一样。因为可以使用新的技术、新的框架，可以按照事物本来的样子去做系统设计，自由度很高。而在开发/维护一个成熟的项目时就不太一样了，一方面项目已经稳定运行，逻辑也非常复杂，所以无法很方便地换成新的技术、新的框架，在设计新功能时也会碍于已有的架构和代码实现做很多妥协，另一方面前人可能不知不觉挖了很多坑，稍有不慎就会掉进坑里，所以行事必须要非常小心，尤其是在做大的架构改变的时候。\n3.3 现实场景 3.3.1 Brownfield 应用当道 在现实中，我们发现目前大部分的公司还没有走向云原生，或者还刚刚在开始探索，所以大量的应用其实还跑在非 k8s 的体系中，比如跑在虚拟机上或者是基于独立的服务注册中心构建微服务体系。\n虽然确实有少量 Greenfield 应用已经在基于云原生来构建了，但现实是那些大量的 Brownfield 应用是公司业务的顶梁柱，承载着更大的业务价值，所以如何把它们纳入 Service Mesh 统一管控，从而带来更大的价值，也就成了更需要优先考虑的话题。\n图片来源 独立的服务注册中心\n3.3.2 云原生方案离生产级尚有一定距离 另一方面，目前 Istio 在整体性能上还存在一些有待解决的点（引述小剑老师在蚂蚁金服 Service Mesh 深度实践中的观点）：\n Mixer  Mixer 的性能问题，一直都是 Istio 中最被人诟病的地方； 尤其在 Istio 1.1/1.2 版本之后引入了 Out-Of-Process Adapter，更是雪上加霜； 从落地的角度看，**Mixer V1 **糟糕至极的性能，已经是“生命无法承受之重”。对于一般规模的生产级落地而言，Mixer 性能已经是难于接受，更不要提大规模落地…… Mixer V2 方案则给了社区希望：将 Mixer 合并进 Sidecar，引入 web assembly 进行 Adapter 扩展，这是我们期待的 Mixer 落地的正确姿势，是 Mixer 的未来，是 Mixer 的『诗和远方』。然而社区望穿秋水，但Mixer V2 迟迟未能启动，长期处于 In Review 状态，远水解不了近渴；   Pilot  Pilot 是一个被 Mixer 掩盖的重灾区：长期以来大家的性能关注点都在 Mixer，表现糟糕而且问题明显的Mixer 一直在吸引火力。但是当选择放弃 Mixer（典型如官方在 Istio 新版本中提供的关闭 Mixer 的配置开关）之后，Pilot 的性能问题也就很快浮出水面； 我们实践下来发现 Pilot 目前主要有两大问题：1）无法支撑海量数据 2）每次变化都会触发全量推送，性能较差；    图片来源\n3.4  …","date":1575291600,"description":"Service Mesh 是蚂蚁金服下一代架构的核心，经过了2年的沉淀，我们探索出了一套切实可行的方案并最终通过了双十一的考验。本文主要分享在当下『路口』，我们在产品设计上的思考和实践。","dir":"blog/service-mesh-practice-in-production-at-ant-financial-wushi/","fuzzywordcount":6300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"30414154356f38408eac8044657b5d63","permalink":"/blog/service-mesh-practice-in-production-at-ant-financial-wushi/","publishdate":"2019-12-02T21:00:00+08:00","readingtime":13,"relpermalink":"/blog/service-mesh-practice-in-production-at-ant-financial-wushi/","summary":"一、引言 Service Mesh 是蚂蚁金服下一代架构的核心，经过了2年的沉淀，我们探索出了一套切实可行的方案并最终通过了双十一的考验。本文主要分享在当下『路口』","tags":["Service mesh","Service Mesh 落地实践"],"title":"Service Mesh 在『路口』的产品思考与实践：务实是根本","type":"blog","url":"/blog/service-mesh-practice-in-production-at-ant-financial-wushi/","wordcount":6230},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\n社区 Big News NO.1 社区新认证一位 Committer\nGithub ID @zongtanghu 成为 SOFAJRaft Committer：\n主要贡献：\n 贡献了两个重要 Feature：   基于优先级配置的自动选举； 为 Replicator 日志复制实现 ReplicatorStateListener 监听器；  添加一些优化功能和 Bugfix：   优化 SOFAJRaft 的工具类，减少冗余代码，增加单元测试用例代码； 优化常量类，实现 Copiable 接口；  原创文章贡献   《SOFAJRaft Snapshot 原理剖析 | SOFAJRaft 实现原理》; 《中国移动苏州研发中心消息队列高可用设计之谈 | SOFAStack 用户说》;  目前，社区已经认证超过四十位 Committer。\n感谢对 SOFAStack 的支持和帮助，也欢迎你加入 SOFAStack community~ SOFAStack 社区：https://www.sofastack.tech/awesome/\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n@kaka19ace 提问：\n 为什么 MOSN 热重启机制需要新老进程，两个 unix domain socket server 通信交互? 目前分为 旧进程 reconfigerServer 新进程 transferServer,\n reconfigerServer 只是新进程主动判断 isReconfigure() 就结束了连接； 迁移 listener fd 以及 connection fd 让旧进程作为 client 角色；  如果仅使用 reconfigerServer 作为交互通信会存在哪些问题？\n A：你的意思就是旧进程 reconfigerServer在收到 isReconfigure() 后，直接传输旧进程的fd给新进程。原理上也是可以的。这儿其实有个历史原因，最开始支持信号 fork 子进程的方式，是不需要 isReconfigure() 来判断是否存在旧进程的，通过环境变量就可以了，后来为了支持容器升级的方式，单独启一个新的进程，才需要一个机制来判断是否存在旧进程，为了改动更小，之前的逻辑不受影响，才加了这个新的 us 来通讯。\n 翻了老版本代码阅读： reconfigure 这块是基于环境变量设置 fd. fork exec 参数使用 sys.ProcAttr 继承 fd 信息。 这块有一个问题确认，老版本场景里如果升级新版的二进制文件，也是基于同目录下替换了相同的 bin 文件，然后再给老进程 hup 信号触发重启吧？\n A：是的，老版本是发送 hup 信号，然后 fork 一个子进程来做二进制升级，这个适用于虚拟机升级。而基于容器的话，是重新拉起一个容器，一个新的进程，就需要跟老的进程来交互。\n 早期版本和 Envoy uds 迁移方式不同，当时设计是有什么考虑吗？后续基于 SCM_RIGHTS 传输 fd 方式与 Envoy 类似，这块重构原因有哪些?想了解代码演进的过程。\n A：你看到代码是 listen fd 的迁移，和 Envoy 最大的不同是我们会把存量的长链接也做迁移。 代码演进是： 第一阶段， 只支持 listen fd 的迁移。 第二阶段， 支持存量长链接的迁移，hup 信号，然后 fork 的方式。 第三阶段， 支持容器间存量长链接的迁移，通过 uds 查找子进程。\n 非常感谢丰富的演进说明。重新拉起容器这块不太明白，对 Envoy 的场景理解：\n 热重启是同一个容器内，Sidecar 新老进程的交接，业务进程继续运行； Sidecar 进程管理是由 pilot-agent 进行管理，当前容器内 agent 发送热重启信号，非重新拉起容器；  MOSN 这里指的是拉起新容器, 容器间迁移数据？uds 的路径是挂载盘?\n A：Envoy 的方式不能用镜像来管理二进制了。MOSN 除了支持 Envoy 这种容器内热升级，也支持容器间。MOSN 会拉起新容器，然后做容器间的连接迁移，uds 的路径是共享卷，2个 container 共享。\n 容器间迁移是否和业务场景有关，为何不是让旧容器自己销毁（摘掉服务发现, 并延迟一段时间自己销毁）？\n A：是的，就是为了 Sidecar 的发布对用户无感知，连接不断，升级 Sidecar 的时候服务也一直在运行。 MOSN：https://github.com/sofastack/sofa-mosn\n双十一落地实践特辑阅读  蚂蚁金服 Service Mesh 大规模落地系列 - 运维篇 蚂蚁金服 Service Mesh 大规模落地系列 - 消息篇 蚂蚁金服 Service Mesh 大规模落地系列 - 核心篇 Service Mesh 落地负责人亲述：蚂蚁金服双十一四大考题  SOFA 项目进展 本周发布详情如下：\n1、发布 SOFAJRaft v1.3.0 版本，主要变更如下：\n 新增 Read-only member(learner) 角色，支持 learner 节点上的线性一致读 实现优先级选举 在 multi-raft-group 的场景中，随机打散每个 group 的第一次 snapshot timeout 时间，避免一个进程内多个 group 同时 snapshot RheaKV 实现 snapshot checksum 以及异步 snapshot 致谢（排名不分先后）：@zongtanghu @devYun @masaimu @SteNicholas @yetingsky  详细发布报告： https://github.com/sofastack/sofa-jraft/issues/362\n社区活动 回顾 11月24日 Kubernetes \u0026amp;amp; Cloud Native X Service Mesh Meetup 活动回顾：\n 蚂蚁金服 Service Mesh 大规模落地系列 - RPC 篇（文末含分享视频回顾以及 PPT 查看地址）  预告 Service Mesh 是蚂蚁金服下一代架构的核心，本期直播主要分享在蚂蚁金服当前的体量下，我 …","date":1575010800,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20191129/","fuzzywordcount":2100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"af340bf3bee03aa71221229aee4c986b","permalink":"/blog/sofa-weekly-20191129/","publishdate":"2019-11-29T15:00:00+08:00","readingtime":5,"relpermalink":"/blog/sofa-weekly-20191129/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | 每周精选【11/25 - 11/29】","type":"blog","url":"/blog/sofa-weekly-20191129/","wordcount":2056},{"author":"鲁直、碧远","categories":"Service mesh","content":"蚂蚁金服云原生负责人鲁直 双十一后首次线下分享\n引言 Service Mesh 是蚂蚁金服下一代架构的核心，本主题主要分享在蚂蚁金服当前的体量下，我们如何做到在奔跑的火车上换轮子，将现有的 SOA（service-oriented architecture，面向服务的架构）体系快速演进至 Service Mesh 架构。聚焦 RPC 层面的设计和改造方案，本次将分享蚂蚁金服双十一核心应用是如何将现有的微服务体系平滑过渡到 Service Mesh 架构下并降低大促成本。\n蚂蚁金服每年双十一大促会面临非常大的流量挑战，在已有 LDC（Logical Data Center，逻辑数据中心，是蚂蚁金服原创的一种“异地多活单元化架构”实现方案）微服务架构下已支撑起弹性扩容能力。本次分享主要分为 5 部分：\n Service Mesh 简介； 为什么要 Service Mesh； 方案落地； 分时调度案例； 思考与未来；  作者简介 黄挺（花名：鲁直）：蚂蚁金服云原生负责人 主要 Focus 领域：\n SOFAStack 微服务领域； Service Mesh，Serverless 等云原生领域；  雷志远（花名：碧远）：蚂蚁金服 RPC 框架负责人 主要 Focus 领域：\n 服务框架：SOFARPC（已开源）； Service Mesh：MOSN（已开源）；  SOFARPC：https://github.com/sofastack/sofa-rpc\nMOSN：https://github.com/sofastack/sofa-mosn\nService Mesh 简介 在讲具体的蚂蚁金服落地之前，想先和大家对齐一下 Service Mesh 的概念，和蚂蚁金服对应的产品。这张图大家可能不陌生，这是业界普遍认可的 Service Mesh 架构，对应到蚂蚁金服的 Service Mesh 也分为控制面和数据面，分别叫做 SOFAMesh 和 MOSN，其中 SOFAMesh 后面会以更加开放的姿态参与到 Istio 里面去。\n今天我们讲的实践主要集中在 MOSN 上，以下我的分享中提到的主要就是集中在数据面上的落地，这里面大家可以看到，我们有支持 HTTP/SOFARPC/Dubbo/WebService。\n为什么我们要 Service Mesh 有了一个初步的了解之后，可能大家都会有这样一个疑问，你们为什么要 Service Mesh，我先给出结论：\n因为我们要解决在 SOA 下面，没有解决但亟待解决的：基础架构和业务研发的耦合，以及未来无限的对业务透明的稳定性与高可用相关诉求。\n那么接下来，我们一起先看看在没有 Service Mesh 之前的状况。\n在没有 Service Mesh 之前，整个 SOFAStack 技术演进的过程中，框架和业务的结合相当紧密，对于一些 RPC 层面的需求，比如流量调度，流量镜像，灰度引流等，是需要在 RPC 层面进行升级开发支持，同时，需要业务方来升级对应的中间件版本，这给我们带来了一些困扰和挑战。如图所示：\n 线上客户端框架版本不统一； 业务和框架耦合，升级成本高，很多需求由于在客户端无法推动，需要在服务端做相应的功能，方案不够优雅； 机器逐年增加，如果不增加机器，如何度过双十一； 在基础框架准备完成后，对于新功能，不再升级给用户的 API 层是否可行；  流量调拨，灰度引流，蓝绿发布，AB Test 等新的诉求；  这些都困扰着我们。我们知道在 SOA 的架构下，负责每个服务的团队都可以独立地去负责一个或者多个服务，这些服务的升级维护也不需要其他的团队的接入，SOA 其实做到了团队之间可以按照接口的契约来接耦。但是长期以来，基础设施团队需要推动很多事情，都需要业务团队进行紧密的配合，帮忙升级 JAR 包，基础设施团队和业务团队在工作上的耦合非常严重，上面提到的各种问题，包括线上客户端版本的不一致，升级成本高等等，都是这个问题带来的后果。\n而 Service Mesh 提供了一种可能性，能够将基础设施下沉，让基础设施团队和业务团队能够解耦，让基础设施和业务都可以更加快步地往前跑。\n我们的方案 说了这么多，那我们怎么解决呢？我们经历了这样的选型思考。\n总体目标架构 我们的 MOSN 支持了 Pilot、自有服务发现 SOFARegistry 和自有的消息组件，还有一些 DB 的组件。在产品层，提供给开发者不同的能力，包括运维、监控、安全等能力，这个是目前我们的一个线上的状态。\n SOFARegistry 是蚂蚁金服开源的具有承载海量服务注册和订阅能力的、高可用的服务注册中心，在支付宝/蚂蚁金服的业务发展驱动下，近十年间已经演进至第五代。\n 看上去很美好，要走到这个状态，我们要回答业务的三个灵魂拷问。\n这三个问题后面，分别对应着业务的几大诉求，大家做过基础框架的应该比较有感触。\n框架升级方案 准备开始升级之后，我们要分析目前我们的线上情况，而我们现在线上的情况，应用代码和框架有一定程度的解耦，用户面向的是一个 API，最终代码会被打包，在 SOFABoot 中运行起来。\n SOFABoot 是蚂蚁金服开源的基于 Spring Boot 的研发框架，它在 Spring Boot 的基础上，提供了诸如 Readiness Check，类隔离，日志空间隔离等能力。在增强了 Spring Boot 的同时，SOFABoot 提供了让用户可以在 Spring Boot 中非常方便地使用 SOFA 中间件的能力。\n 那么，我们就可以在风险评估可控的情况下，直接升级底层的 SOFABoot。在这里，我们的 RPC 会检测一些信息，来确定当前 Pod 是否需要开启 MOSN 的能力。然后我们完成如下的步骤。\n我们通过检测 PaaS 传递的容器标识，知道自己是否开启了 MOSN，则将发布和订阅给 MOSN，然后调用不再寻址，直接完成调用。\n可以看到，通过批量的运维操作，我们直接修改了线上的 SOFABoot 版本，以此，来直接使得现有的应用具备了 MOSN 的能力。有些同学可能会问，那你一直这么做不行吗？不行，因为这个操作是要配合流量关闭等操作来运行的，也不具备平滑升级的能力，而且直接和业务代码强相关，不适合长期操作。\n这里我们来详细回答一下，为什么不采用社区的流量劫持方案？\n主要的原因是一方面 iptables 在规则配置较多时，性能下滑严重。另一个更为重要的方面是它的管控性和可观测性不好，出了问题比较难排查。蚂蚁金服在引入 Service Mesh 的时候，就是以全站落地为目标的，而不是简单的“玩具”，所以我们对性能和运维方面的要求非常高，特别是造成业务有损或者资源利用率下降的情况，都是不能接受的。\n容器替换方案 解决了刚刚提到的第一个难题，也只是解决了可以做，而并不能做得好，更没有做得快，面对线上数十万带着流量的业务容器， 我们如何立刻开始实现这些容器的快速稳定接入？\n这么大的量，按照传统的替换接入显然是很耗接入成本的事情，于是我们选择了原地接入，我们可以来看下两者的区别：\n在之前，我们做一些升级操作之类的，都是需要有一定的资源 Buffer，然后批量的进行操作， …","date":1574946000,"description":" 聚焦 RPC 层面的设计和改造方案，本次将分享蚂蚁金服双十一核心应用是如何将现有的微服务体系平滑过渡到 Service Mesh 架构下并降低大促成本。","dir":"blog/service-mesh-practice-in-production-at-ant-financial-part4-rpc/","fuzzywordcount":4500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"3d67d3c4d38ced6f9de8a92364c0827c","permalink":"/blog/service-mesh-practice-in-production-at-ant-financial-part4-rpc/","publishdate":"2019-11-28T21:00:00+08:00","readingtime":9,"relpermalink":"/blog/service-mesh-practice-in-production-at-ant-financial-part4-rpc/","summary":"蚂蚁金服云原生负责人鲁直 双十一后首次线下分享 引言 Service Mesh 是蚂蚁金服下一代架构的核心，本主题主要分享在蚂蚁金服当前的体量下，我们如何做到在奔跑的火","tags":["Service mesh","Service Mesh 落地实践"],"title":"蚂蚁金服 Service Mesh 大规模落地系列 - RPC 篇","type":"blog","url":"/blog/service-mesh-practice-in-production-at-ant-financial-part4-rpc/","wordcount":4496},{"author":"悟尘","categories":"Service mesh","content":"本文为《蚂蚁金服 Service Mesh 大规模落地系列》第五篇 - 网关篇，该系列将会从核心、RPC、消息、无线网关、控制面、安全、运维、测试等模块对 Service Mesh 双十一大规模落地实践进行详细解析。文末包含往期系列文章。\n引言 本文结合无线网关的发展历程，解读进行 Service Mesh 改造的缘由和价值，同时介绍在双十一落地过程中如何保障业务流量平滑迁移至新架构下的 Mesh 网关。分享将从如下三个方面展开：\n 网关的前世今生，解释网关为什么要 Mesh 化； 网关 Mesh 化，阐述如何进行 Mesh 化改造； 双十一落地，介绍在此过程中实现三板斧能力；  前世今生 蚂蚁金服无线网关当前接入数百个业务系统，提供数万个 API 服务，是蚂蚁金服客户端绝对的流量入口，支持的业务横跨支付宝、网商、财富、微贷、芝麻和国际 A+ 等多种场景。面对多种业务形态、复杂网络结构，无线网关的架构也在不断演进。\n中心化网关 在 All In 无线的年代，随着通用能力的沉淀，形成了中心化网关 Gateway。\n 客户端连接到网关接入层集群 Spanner ； Spanner 会把客户端请求转发到无线网关集群 Gateway； Gateway 提供通用能力如鉴权、限流等处理请求，并根据服务标识将请求路由到正确的后端服务；服务处理完请求，响应原路返回；  2016 年新春红包爆发，蚂蚁森林等新兴业务发展壮大，网关集群机器数不断增长。这加剧了运维层面的复杂性，IT成本也不能承受之重。同时，一些核心链路的业务如无线收银台、扫一扫等，迫切需要与其他业务隔离，避免不可预知的突发流量影响到这些高保业务的可用性。因此，2016 年下半年开始建设和推广去中心化网关。\n去中心化网关 去中心化网关将原先集中式网关的能力进行了拆分：\n 转发逻辑：将 Gateway 中根据服务标识转发的能力迁移到 Spanner 上； 网关逻辑：将网关通用能力如鉴权、限流、LDC 等功能，抽成一个 mgw jar 集成到业务系统中，与后端服务同JVM 进程运行；  此时，客户端请求的处理流程如下：\n 客户端请求到 Spanner 后，Spanner 会根据服务标识转发请求到后端服务的 mgw 中； mgw 进行通用网关能力处理，90% 的请求随即进行 JVM 内部调用；  去中心化网关与集中式网关相比，具有如下优点：\n 提升性能：  少一层网关链路，网关 jar 调用业务是 JVM 内部调用； 大促期间，无需关心网关的容量，有多少业务就有多少网关；   提高稳定性：  集中式网关形态下，网关出现问题，所有业务都会收到影响； 去中心化后，网关的问题，不会影响去中心化的应用；    但凡事具有两面性，随着在 TOP30 的网关应用中落地铺开，去中心化网关的缺点也逐步显现：\n 研发效能低：  接入难：需要引入 15+ pom 依赖、20+ 的配置，深度侵入业务配置； 版本收敛难：当前 mgw.jar 已迭代了 40+ 版本，当前还有业务使用的是初版，难以收敛； 新功能推广难：新能力上线要推动业务升级和发布，往往需要一个月甚至更久时间；   干扰业务稳定性：  依赖冲突，干扰业务稳定性，这种情况发生了不止一次； 网关功能无法灰度、独立监测，资源占用无法评估和隔离；   不支持异构接入：财富域大部分系统是 Node 技术栈，无法使用去中心化网关；   Mesh 网关 去中心化网关存在的诸多问题，多数是由于网关功能与业务进程捆绑在一起造成的。这引发了我们的思考：如果网关功能从业务进程中抽离出来，这些问题是否就可以迎刃而解了？这种想法，与 Service Mesh 的 Sidecar 模式不谋而合。因此在去中心化网关发展了三年后，我们再出发对蚂蚁金服无线网关进行了 Mesh 化改造，以期籍此解决相关痛点。\nMesh 网关与后端服务同 Pod 部署，即 Mesh 网关与业务系统同服务器、不同进程，具备网关的全量能力。客户端请求的处理流程如下：\n 客户端请求到 Spanner 后，Spanner 会根据服务标识转发请求到后端服务同 Pod 中的 Mesh 网关； Mesh 网关执行通用逻辑后调用同机不同进程的业务服务，完成业务处理；  对比去中心化网关的问题，我们来分析下 Mesh 网关所带来的优势：\n 研发效能：  接入方便：业务无需引入繁杂的依赖和配置，即可接入 Mesh 网关； 版本容易收敛、新功能推广快：新版本在灰度验证通过后，即可全网推广升级，无需维护和排查多版本带来的各种问题；   业务稳定性：  无损升级：业务系统无需感知网关的升级变更，且网关的迭代升级将可利用 MOSN 现有的特性进行细粒度的灰度和验证，做到无损升级； 独立监测：由于和业务系统在不同进程，可以实时遥测 Mesh 网关进程的表现，并据此评估和优化，增强后端服务稳定性；   异构系统接入：Mesh 网关相当于一个代理，对前端屏蔽后端的差异，将支持 SOFARPC、Dubbo 和 gRPC 等主流 RPC 协议，并支持非 SOFA 体系的异构系统接入；  至此，我们卖瓜自夸式地讲完了无线网关的前世今生，解释了为何要撸起袖子进行网关 Mesh 化。但细心的你想必怀疑：\n Mesh 化之后的请求处理流程不是同进程调用，比起去中心化网关多了一跳，是否有性能损耗？ 毕竟进行了大刀阔斧的变革，在上线过程中如何保障稳定性？  接下来的章节将对上述问题进行解释。\nMesh 化 架构 首先，从架构层面详细介绍网关 Mesh 化所做的相关工作。依照 Service Mesh 的分层模型，Mesh 网关分为数据面和控制面。\n解读：\n 蓝色箭头线是客户端请求的处理流程，Mesh 网关数据面在蚂蚁金服内部 MOSN 的 Sidecar 中； 绿色箭头线是网关配置下发过程，Mesh 网关控制面当前还是由网关管控平台来承载； 红色箭头线条是 MOSN Sidecar 的运维体系；  MOSN：https://github.com/sofastack/sofa-mosn\n数据面 采用 Go 语言实现了原先网关的全量能力，融合进 MOSN 的模型中，复用了其他组件已有的能力。 同时网络接入层 Spanner 也实现了请求分发决策能力。\n数据转换 将客户端的请求数据转换成后端请求数据，将后端响应数据转换成客户端响应。利用 MOSN 协议层扩展能力，实现了对网关自有协议 Mmtp 的解析能力。\n通用功能 授权、安全、限流、LDC 和重试等网关通用能力。利用 MOSN Stream Filter 注册机制以及统一的 Stream Send/Receive Filter 接口扩展而来。\n请求路由 客户端请求按照特定规则路由到正确的后端系统。在网关层面实现 LDC 逻辑后，复用 MOSN RPC 组件的路由匹配能力。其中大部分请求都会路由到当前 Zone，从而直接请求到当前 Pod 的业务进程端口。\n后端调用 支持调用多种类型的后端服务，支持对 SOFARPC、Chair 等后端，后期计划支持更多的 RPC 框架和异构系统。\n控制面 为网关用户提供新增、配置 API 等服务的管控系统， …","date":1574946000,"description":" 本文结合无线网关的发展历程，解读进行 Service Mesh 改造的缘由和价值，同时介绍在双十一落地过程中如何保障业务流量平滑迁移至新架构下的 Mesh 网关。","dir":"blog/service-mesh-practice-in-production-at-ant-financial-part5-gateway/","fuzzywordcount":3600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"a51651ca16ad1df8e867f4e25296c50b","permalink":"/blog/service-mesh-practice-in-production-at-ant-financial-part5-gateway/","publishdate":"2019-11-28T21:00:00+08:00","readingtime":8,"relpermalink":"/blog/service-mesh-practice-in-production-at-ant-financial-part5-gateway/","summary":"本文为《蚂蚁金服 Service Mesh 大规模落地系列》第五篇 - 网关篇，该系列将会从核心、RPC、消息、无线网关、控制面、安全、运维、测试等模块对 Service Mesh 双十一大规","tags":["Service mesh","Service Mesh 落地实践"],"title":"蚂蚁金服 Service Mesh 大规模落地系列 - 网关篇","type":"blog","url":"/blog/service-mesh-practice-in-production-at-ant-financial-part5-gateway/","wordcount":3545},{"author":"嘉祁","categories":"Service mesh","content":"《蚂蚁金服 Service Mesh 大规模落地系列》将会从核心、RPC、消息、无线网关、控制面、安全、运维、测试等模块对 Service Mesh 双十一大规模落地实践进行详细解析，文末包含往期系列文章。本文为该系列文章的第三篇 - 运维篇。\n引言 Service Mesh 是蚂蚁金服下一代架构的核心，也是蚂蚁金服内部向云原生演进的重要一环。本文为 Service Mesh 系列文章的运维篇，作者：黄家琦 （花名：嘉祁），蚂蚁金服运维专家，Service Mesh SRE，主要关注云原生基础设施、中间件及 Service Mesh 的稳定性，同时也是 Pythoner，sofa-bolt-python 作者。\n本文将主要分享大规模服务网格在蚂蚁金服当前体量下落地到支撑蚂蚁金服双十一大促过程中，运维角度所面临的挑战与演进。内容包括云原生化的选择与问题，对资源模型的挑战，大规模下运维设施的演进，以及周边技术风险能力的建设。\nService Mesh 在2019年得到了大规模的应用与落地，截止目前，蚂蚁金服的 Service Mesh 数据平面 MOSN 已接入应用数百个，接入容器数量达数十万，是目前已知的全世界最大的 Service Mesh 集群。同时，在刚刚结束的双十一大促中，Service Mesh 的表现也十分亮眼，RPC 峰值 QPS 达到了几千万，消息峰值 TPS 达到了几百万，且引入 Service Mesh 后的平均 RT 增长幅度控制在 0.2 ms 以内。\n拥抱云原生 Service Mesh 在软件形态上，是将中间件的能力从框架中剥离成独立软件。而在具体部署上，保守的做法是以独立进程的方式与业务进程共同存在于业务容器内。我们在蚂蚁金服内部的做法，则从开始，就选择了拥抱云原生。\nSidecar 模式 业务容器内独立进程的好处在于与传统的部署模式兼容，易于快速上线；但独立进程强侵入业务容器，对于镜像化的容器更难于管理。而云原生化，则可以将 Service Mesh 本身的运维与业务容器解耦开来，实现中间件运维能力的下沉。在业务镜像内，仅仅保留长期稳定的 Service Mesh 相关 JVM 参数，从而仅通过少量环境变量完成与 Service Mesh 的联结。同时考虑到面向容器的运维模式的演进，接入 Service Mesh 还同时要求业务完成镜像化，为进一步的云原生演进打下基础。\n    优 劣     独立进程 兼容传统的部署模式；改造成本低；快速上线 侵入业务容器；镜像化难于运维   Sidecar 面向终态；运维解耦 依赖 K8s 基础设施；运维环境改造成本高；应用需要镜像化改造    在接入 Service Mesh 之后，一个典型的 POD 结构可能包含多个 Sidecar：\n MOSN：RPC Mesh, MSG Mesh, \u0026amp;hellip;（扩展中）； 其它 Sidecar；  MOSN：https://github.com/sofastack/sofa-mosn\n这些 Sidecar 容器，与业务容器共享相同的网络 Namespace，使得业务进程可以以本地端口访问 Service Mesh 提供的服务，保证了与保守做法一致的体验。\n基础设施云原生支撑 我们也在基础设施层面同步推进了面向云原生的改造，以支撑 Service Mesh 的落地。\n业务全面镜像化 首先是在蚂蚁金服内部推进了全面的镜像化，我们完成了内部核心应用的全量容器的镜像化改造。改造点包括：\n 基础镜像层面增加对于 Service Mesh 的环境变量支撑； 应用 Dockerfile 对于 Service Mesh 的适配； 推进解决了存量前后端分离管理的静态文件的镜像化改造； 推进了大量使用前端区块分发的应用进行了推改拉的改造； 大批量的 VM 模式的容器升级与替换；  容器 POD 化 除了业务镜像层面的改造，Sidecar 模式还需要业务容器全部跑在 POD 上，来适应多容器共享网络。由于直接升级的开发和试错成本很高，我们最终选择将接入 Service Mesh 的 数百个应用的数万个非 K8s 容器，通过大规模扩缩容的方式，全部更换成了 K8s PODs。\n经过这两轮改造，我们在基础设施层面同步完成了面向云原生的改造。\n资源的演进 Sidecar 模式的带来一个重要的问题，如何分配资源。\n理想比例的假设 最初的资源设计基于内存无法超卖的现实。我们做了一个假设：\n MOSN 的基本资源占用与业务选择的规格同比例这一假设。  CPU 和 Memory 申请与业务容器相应比例的额外资源。这一比例最后设定在了 CPU 1/4，Memory 1/16。\n此时一个典型 Pod 的资源分配如下图示：\n这一方式带来了两个问题：\n 蚂蚁金服已经实现了业务资源的 Quota 管控，但 Sidecar 并不在业务容器内，Service Mesh 容器成为了一个资源泄漏点； 业务很多样，部分高流量应用的 Service Mesh 容器出现了严重的内存不足和 OOM 情况；  完美分割的不完美 不止于此，为了快速支撑 Service Mesh 在非云环境的铺开，上线了原地接入 Service Mesh。而原地接入 Service Mesh 的资源无法额外分配，在内存不能超卖的情况下，采取了二次分割的分配方式。此时的 POD 内存资源被切分为1/16内存给 Sidecar，与15/16给业务容器。除了以上两个问题，还带来一些新的问题：\n 业务可见内存不一致，业务监控偏差，业务进程 OOM 风险。  讨论之后，我们追加了一个假设：\n Service Mesh 容器占用的资源实质是在接入 Service Mesh 之前业务已使用的资源。接入 Service Mesh 的过程，同时也是一次资源置换。  共享 基于这个假设，推进了调度层面支持 POD 内的资源超卖，新的资源分配方案如下图，Service Mesh 容器的 CPU、MEM 都从 POD 中超卖出来，业务容器内仍然可以看到全部的资源。\n考虑到内存超卖也引入了 POD OOM 的风险，因此对于 Sidecar 容器还调整了 OOM Score，保证在内存不足时，Service Mesh 进程能够发挥启动比 Java 业务进程更快的优势，降低影响。\n新的分配方案解决了同时解决了以上两个问题，并且平稳支持了大促前的多轮压测。\n重建 但新的分配方案上线时，Service Mesh 已经在弹性建站时同步上线。同时我们还发现在一些场景下，Service Mesh 容器无法抢占到 CPU 资源，导致业务 RT 出现了大幅抖动，原因是在 CPU Share 模式下，POD 内默认并没有等额的分配 CPU Quota 给 Sidecar。\n于是还有两个问题待解决：\n 存量的已分配 Sidecar 仍有 OOM 风险； Sidecar 无法抢占到 CPU；  我们已经无法承受更换全部 POD 的代价。最终在调度的支持下，通过对 Pod Annotation 的手动重新计算+修改，在 POD 内进行了全部资源的重分配，来修复这两个风险。最终的修复容器总数约 25w 个。\n …","date":1574859600,"description":" 本文将主要分享大规模服务网格在蚂蚁金服当前体量下落地到支撑蚂蚁金服双十一大促过程中，运维角度所面临的挑战与演进。","dir":"blog/service-mesh-practice-in-production-at-ant-financial-part3-operation/","fuzzywordcount":4100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"b4428f1c979dfa574a7ec8b4d96bc191","permalink":"/blog/service-mesh-practice-in-production-at-ant-financial-part3-operation/","publishdate":"2019-11-27T21:00:00+08:00","readingtime":9,"relpermalink":"/blog/service-mesh-practice-in-production-at-ant-financial-part3-operation/","summary":"《蚂蚁金服 Service Mesh 大规模落地系列》将会从核心、RPC、消息、无线网关、控制面、安全、运维、测试等模块对 Service Mesh 双十一大规模落地实践进行详细解析，文末","tags":["Service mesh","Service Mesh 落地实践"],"title":"蚂蚁金服 Service Mesh 大规模落地系列 - 运维篇","type":"blog","url":"/blog/service-mesh-practice-in-production-at-ant-financial-part3-operation/","wordcount":4049},{"author":"潘潘","categories":"SOFAChannel","content":"概要   活动主题：SOFAChannel#9：蚂蚁金服 Service Mesh 双十一落地详解\n  活动时间：12 月 5 日周四晚 7 点\n  活动形式：线上直播\n  直播回看：戳这里\n  介绍 | SOFAChannel \u0026amp;lt;SOFA:Channel/\u0026amp;gt; 有趣实用的分布式架构频道：前沿技术、直播 Coding、观点“抬杠”，多种形式。\n\u0026amp;lt;SOFA:Channel/\u0026amp;gt; 将作为 SOFA 所有在线内容的承载，包含直播/音视频教程，集中体现 SOFAStack 的能力全景图。\n| SOFAChannel#9：蚂蚁金服 Service Mesh 双十一落地详解 Service Mesh 是蚂蚁金服下一代架构的核心，本期直播主要分享在蚂蚁金服当前的体量下，我们如何做到在奔跑的火车上换轮子，将现有的 SOA 体系快速演进至 Service Mesh 架构。\n12 月 5 日周四晚 7 点，将邀请蚂蚁金服技术专家卓与 ，聚焦 RPC 层面的设计和改造方案，分享蚂蚁金服双十一核心应用如何将现有的微服务体系平滑过渡到 Service Mesh 架构下并降低大促成本，并从核心、RPC、消息等模块展开本次双十一落地实践的实现细节分享。\n| 加入 SOFA 钉钉互动群 欢迎加入直播互动钉钉群：23390449（搜索群号加入即可）\n| 点击即可报名 https://tech.antfin.com/community/live/1021\n议程 19:00-19:05 主持人开场 SOFAGirl 主持人\n19:05-20:00 蚂蚁金服 Service Mesh 双十一落地详解 卓与 蚂蚁金服 Service Mesh 落地负责人\n本期分享大纲：  蚂蚁金服 Service Mesh 架构双十一大规模落地实践案例分析； 从核心、RPC、消息等模块分享蚂蚁金服 Service Mesh 落地实践细节； 欢迎先阅读(https://www.sofastack.tech/tags/service-mesh-落地实践/)Service Mesh 落地系列文章，收看直播收获更好的效果；  嘉宾  SOFAGirl 主持人 卓与 蚂蚁金服 Service Mesh 落地负责人  ","date":1574741400,"description":"12 月 5 日周四晚 7 点，线上直播第 9 期。","dir":"activities/sofa-channel-9/","fuzzywordcount":700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"33ec75a1b0e23d96934a7ec43dfa5df5","permalink":"/activities/sofa-channel-9/","publishdate":"2019-11-26T12:10:00+08:00","readingtime":2,"relpermalink":"/activities/sofa-channel-9/","summary":"概要 活动主题：SOFAChannel#9：蚂蚁金服 Service Mesh 双十一落地详解 活动时间：12 月 5 日周四晚 7 点 活动形式：线上直播 直播回看：戳这里 介绍 | SOFAChannel","tags":["SOFAChannel","Service Mesh"],"title":"SOFAChannel#9：蚂蚁金服 Service Mesh 双十一落地详解","type":"activities","url":"/activities/sofa-channel-9/","wordcount":606},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动\n我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@J～杰 提问：\n 帮我看个问题，标红的这个状态没执行是啥原因？  A：没有 Next 属性，可以下载 seata-sample，里面有例子，https://github.com/seata/seata-samples。\n 好的，CompensateState 这个属性是正向失败后，重试这个状态？\n A：正向失败后，触发这个补偿状态。 https://github.com/seata/seata/tree/develop/test/src/test/java/io/seata/saga/engine 为里有很多单元测试案例，代码对应的json在：https://github.com/seata/seata/tree/develop/test/src/test/resources/saga/statelang。 正向失败后，触发这个 CompensateState 状态，但失败后并不会默认就触发补偿流程，需要在 Catch 属性里，Next 到一个 CompensateTrigger。\n 那 Saga 模式下，如果 TC 端发出回滚命令，Saga 怎么处理，没发现有回滚状态？\n A：Saga 模式的 TCC 模式有点不一样的是，Saga 的回滚不是由 TC 来协调，而是只 TC 触发，回滚流程是由状态机执行的。 https://github.com/seata/seata/blob/develop/test/src/test/resources/saga/statelang/simple_statelang_with_compensation.json\n这里是 Catch 到异常后，可以自定义捕获某些异常，然后 Next 到一个处理 state，这个 state 可以是任何 state，如果是 CompensateTrigger 则立即进行回滚。\n Saga 是通过检测异常来识别回滚命令？\n A：Catch 属性是用来检测异常的，但异常的处理可能不仅仅是进行回滚，可能有别的处理逻辑，因业务不同而不同，catch 到这些异常处理，你可以 Next 到任何一个 state 来处理异常；如果希望回滚，框架提供了 CompensateTrigger 这种一个特定的 state，Next 到 CompensateTrigger，则立即进行回滚。\n 如果一个 Saga 状态失败后，RM 一直会重试，这个重试有没有次数限制的？\n A：https://github.com/seata/seata/blob/develop/server/src/main/resources/file.conf.example 重试间隔和重试超时时间, -1是无限重试，比如可以配置成 1d ，只重度一天。\n 还有个问题，发现 catch 没有捕捉到 RuntimeExcepeion 异常：  A：它走到 Fail 那个状态去了吗？另外就是 Status 是会执行的，catch 异常和状态判断是两个互不干扰的事情。\n 就是没有走到 Fail 那个状态才奇怪，刚开始我是把 Status 给去掉的，也没走，后来就加上的。这个重试是状态为 un 的时候，TC 就会一直发起重试的吧？\n A：如果没有发起过回滚（补偿流程），失败后 TC 会重试继续完成状态机正向执行，如果发了回滚，回滚失败后 TC 会重试回滚。\n 那如果发生回滚，是从哪个状态节点开始回滚的？\n A：从失败的节点开始。\n 是通过读这张表的数据 seata_state_inst？\n A：对。\nSeata：https://github.com/seata/seata\n2、@胡文伟 提问：\n 双模微服务是指什么？\n A：所谓双模，是指 SOFA 微服务和 Service Mesh 技术的双剑合璧，即“基于 SDK 的 SOFA 微服务”可以和“基于 Sidecar 的 Service Mesh 微服务”实现下列目标： 互联互通：两个体系中的应用可以相互访问； 平滑迁移：应用可以在两个体系中迁移，对于调用该应用的其他应用，做到透明无感知； 异构演进：在互联互通和平滑迁移实现之后，我们就可以根据实际情况进行灵活的应用改造和架构演进。\n双十一落地实践特辑阅读  蚂蚁金服 Service Mesh 大规模落地系列 - 消息篇 蚂蚁金服 Service Mesh 大规模落地系列 - 核心篇 Service Mesh 落地负责人亲述：蚂蚁金服双十一四大考题  SOFA 项目进展 本周发布详情如下：\n1、发布 MOSN v0.8.1，主要变更如下：\n 新增 MOSN 处理失败请求数的统计； 提升写共享内存时的性能； 优化内存占用与日志输出； 修复日志文件轮转的 Bug；  详细发布报告：https://github.com/sofastack/sofa-mosn/releases/tag/0.8.1\nSOFAChannel 直播推荐 Service Mesh 是蚂蚁金服下一代架构的核心，本期直播主要分享在蚂蚁金服当前的体量下，我们如何做到在奔跑的火车上换轮子，将现有的 SOA 体系快速演进至 Service Mesh 架构。聚焦 RPC 层面的设计和改造方案，分享蚂蚁金服双十一核心应用如何将现有的微服务体系平滑过渡到 Service Mesh 架构下并降低大促成本，并从核心、RPC、消息等模块展开分享本次双十一落地实践的实现细节。\n你将收获：\n 蚂蚁金服 Service Mesh 架构双十一大规模落地实践案例分析； 从核心、RPC、消息等模块分享蚂蚁金服 Service Mesh 落地实践细节；  时间：2019年12月5日（周四）19:00-20:00 形式：线上直播 报名方式：点击“这里”即可报名\n","date":1574406000,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20191122/","fuzzywordcount":2100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"d1021e16b4acefdf05a527584900ba69","permalink":"/blog/sofa-weekly-20191122/","publishdate":"2019-11-22T15:00:00+08:00","readingtime":5,"relpermalink":"/blog/sofa-weekly-20191122/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | 每周精选【11/18 - 11/22】","type":"blog","url":"/blog/sofa-weekly-20191122/","wordcount":2007},{"author":"无勤","categories":"Service mesh","content":"本文为《蚂蚁金服 Service Mesh 大规模落地系列》第二篇，该系列将会从核心、RPC、消息、无线网关、控制面、安全、运维、测试等模块对 Service Mesh 双十一大规模落地实践进行详细解析。文末包含往期系列文章。\n引言 Service Mesh 作为蚂蚁金服向下一代云原生架构演进的核心基础设施，在2019年得到了大规模的应用与落地，截止目前，蚂蚁金服的 Service Mesh 数据平面 MOSN 已接入应用数百个，接入容器数量达数十万，一举成为全世界最大的 Service Mesh 集群。同时，在刚刚结束的双十一大促中，Service Mesh 的表现也十分亮眼，RPC 峰值 QPS 达到了几千万，消息峰值 TPS 达到了几百万，且引入 Service Mesh 后的平均 RT 增长幅度控制在 0.2 ms 以内。\n本文作为整个 Service Mesh 系列文章的消息篇，作者：刘翔（花名：无勤），蚂蚁金服消息 Mesh 负责人， 消息中间件核心研发成员，专注于高吞吐、低延迟的消息中间件研发，以及云原生时代下一代消息系统的架构设计与研发。本文将从以下几个方面对消息 Mesh 进行解读：\n 对消息 Mesh 进行介绍，解答消息 Mesh 在整个 Service Mesh 中的地位是什么，它又能为业务带来哪些价值； 结合蚂蚁金服消息中间件团队 Mesh 化的实践与思考，阐述如何在消息领域进行 Mesh 化改造； 消息 Mesh 在蚂蚁金服内部大规模落地过程中遇到的问题与挑战，以及对应的解决方案； 消息流量精细化调度上的思考与在 Mesh 上的实现与落地；  消息 Mesh 简介 Service Mesh 作为云原生场景下微服务架构的基础设施（轻量级的网络代理），正受到越来越多的关注。Service Mesh 不仅负责在微服务架构的复杂拓扑中可靠地传递请求，也将限流、熔断、监控、链路追踪、服务发现、负载均衡、异常处理等与业务逻辑无关的流量控制或服务治理行为下沉，让应用程序能更好地关注自身业务逻辑。\n微服务架构中的通信模式实际上是多种多样的，既包含同步的请求调用，也包含异步的消息/事件驱动，然而流行的 Service Mesh 实现（Istio，Linkerd，Consul Connect等），都仍局限在对微服务中同步请求调用的关注，却无法管理和追踪异步消息流量。而消息 Mesh 则是对这一块的重要补充，通过将消息 Mesh 有机地融合到 Service Mesh 中，可以帮助 Service Mesh 实现对所有微服务流量的管控和追踪，从而进一步完善其架构目标。\n消息 Mesh 的价值 在传统的消息中间件领域，我们更关注的是消息服务端的性能、服务可用性、数据可靠性等核心指标，而与业务应用密切相关的一些能力，包括消息的流量控制（限流、熔断、灰度、着色、分组等），消息的服务治理（消息量级与消息应用拓扑等），消息链路的追踪（消息轨迹）却往往不尽如人意。\n这不仅是因为传统模式下上述能力的提供和优化都涉及客户端的改造与大规模升级，整个过程常常比较漫长，难以快速根据有效反馈不断优化，更重要的是缺乏一个统一的架构指导思想，混乱无序地向客户端叠加相关功能只会让消息客户端变得越来越臃肿和难以维护，也变向增加了业务系统的接入、调试和排查问题的成本。而消息 Mesh 作为 Service Mesh 的补充，能显著带来如下价值和收益：\n 快速升级 - 通过将与业务逻辑无关的一些核心关键能力下沉到 Sidecar 中，使这些能力的单独快速迭代与升级成为可能； 流量控制 - 可以向 Sidecar 中集成各种流量控制策略，例如可根据消息类型、消息数量、消息大小等多种参数来控制消息的发送和消费速率； 流量调度 - 通过打通 Sidecar 节点之间的通信链路，可以利用 Sidecar 的流量转发来实现任意精度的消息流量调度，帮助基于事件驱动的微服务应用进行多版本流量管理、流量着色、分组路由、细粒度的流量灰度与A/B策略等； 消息验证 - 消息验证在基于事件驱动的微服务架构中正变得越来越重要，通过将这部分能力下沉到 Sidecar，不仅可以让业务系统无缝集成消息验证能力，也可以让 Sidecar 通过 Schema 理解消息内容，并进一步具备恶意内容识别等安全管控能力； 可观测性 - 由于所有的消息流量都必须通过 Sidecar，因此可以为 Sidecar 上的消息流量按需增加 Trace 日志，Metrics 采集，消息轨迹数据采集等能力，并借此进一步丰富消息服务的治理能力；  消息 Mesh 化改造 在蚂蚁金服内部，Msgbroker 基于推模型提供高可靠、高实时、事务消息、header 订阅等特性，帮助核心链路进行异步解耦，提升业务的可扩展能力，并先后伴随蚂蚁金服众多核心系统一起经历了分布式改造、单元化改造与弹性改造，目前主要承载蚂蚁内部交易、账务、会员、消费记录等核心在线业务的异步消息流量。\n由于 Service Mesh 的推进目标也是优先覆盖交易支付等核心链路，为在线业务赋能，因此我们优先选择对 Msgbroker 系统进行 Mesh 化改造。下面将以 Msgbroker 为例，重点剖析 Mesh 化后在整体架构和核心交互流程上的变化，为消息领域的 Mesh 化改造提供参考。\n整体架构 消息 Mesh 化后的整体架构如上图所示，与原有的消息架构相比，主要的变化有：\n 客户端不再与服务端直连，而是通过 Sidecar 进行请求的中转，对客户端而言，Sidecar 实际上是它唯一能感知到的消息服务端，对服务端而言，Sidecar 则扮演着客户端的角色； 所有 Sidecar 都会与控制平面交互，接收服务端地址列表、流量管控和调度配置、运行时动态配置等的下发，从而使数据平面具备限流、熔断、异常重试、服务发现、负载均衡、精细化流量调度等能力；  核心交互流程 当 Sidecar 代理了消息客户端的所有请求后，一旦 Sidecar 完成消息服务的发现与服务端/客户端路由数据的缓存，无论是客户端的发消息请求还是服务端的推消息请求，都能由 Sidecar 进行正确的代理转发，而这一切的关键，则是 Sidecar 与消息客户端协同完成一系列的初始化操作。\n消息 Mesh 化后具体的初始化流程如下所示，与原有的初始化流程相对比，主要有如下不同：\n 在经过 Mesh 化改造后，消息客户端不再直接向 SOFARegistry 订阅消息服务端的地址，而是将所有消息元数据（包含业务应用声明的消息 Topic、发送/订阅组 GroupId 等关键信息）通过 HTTP 请求上报给 MOSN，由 MOSN 进行元数据的持久化（用于 MOSN 异常 Crash 后的恢复）以及消息服务端地址的订阅和处理； 当客户端收到 MOSN 对于注册请求的响应时，会主动与 MOSN 建立连接，并将与该连接相关的 Group 集合信息通过控制指令发送给 MOSN，由于客户端与 MOSN 可能存在多个连接，且不同连接上的 Group 集合可以不同，而 MOSN 与同一个消息服务端只维持一个连接，因此控制指令无法向消息数据一样直接进行转发，而是需要汇 …","date":1574326800,"description":" 本文为《蚂蚁金服 Service Mesh 大规模落地系列》第二篇-消息篇","dir":"blog/service-mesh-practice-in-production-at-ant-financial-part2-mesh/","fuzzywordcount":4800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"1778dffdda6a839ad3e72183df3393d6","permalink":"/blog/service-mesh-practice-in-production-at-ant-financial-part2-mesh/","publishdate":"2019-11-21T17:00:00+08:00","readingtime":10,"relpermalink":"/blog/service-mesh-practice-in-production-at-ant-financial-part2-mesh/","summary":"本文为《蚂蚁金服 Service Mesh 大规模落地系列》第二篇，该系列将会从核心、RPC、消息、无线网关、控制面、安全、运维、测试等模块对 Service Mesh 双十一大规模落地实","tags":["Service mesh","Service Mesh 落地实践"],"title":"蚂蚁金服 Service Mesh 大规模落地系列 - 消息篇","type":"blog","url":"/blog/service-mesh-practice-in-production-at-ant-financial-part2-mesh/","wordcount":4722},{"author":"卓与","categories":"Service mesh","content":" 2019 年的双十一是蚂蚁金服的重要时刻，大规模落地了 Service Mesh 并顺利保障双十一平稳渡过。我们第一时间与这次的落地负责人进行了交流。\n采访的开头： 花肉：“这次大规模上了 Service Mesh ，双十一值班感觉是什么？” 卓与：“Service Mesh 真的稳。”\n 图为卓与 TOP100 北京峰会分享现场图\n落地负责人介绍 Service Mesh 是蚂蚁金服下一代架构的核心，今年蚂蚁金服大规模的 Service Mesh 落地，我有幸带领并面对了这个挑战，并非常平稳的通过了双十一的大考。\n我个人主要专注在微服务领域，在服务注册与服务框架方向深耕多年，主导过第五代服务注册中心（SOFARegistry）设计与实施，在微服务的架构演进中持续探索新方向，并在蚂蚁金服第五代架构演进中负责内部 Service Mesh 方向的架构设计与落地。\nSOFAStack：https://github.com/sofastack SOFAMosn：https://github.com/sofastack/sofa-mosn\nService Mesh 在蚂蚁金服 蚂蚁金服很早开始关注 Service Mesh，并在 2018 年发起 ServiceMesher 社区，目前已有 4000+ 开发者在社区活跃。在技术应用层面，Service Mesh 的场景已经渡过探索期，今年已经全面进入深水区探索。\n2019 年的双十一是我们的重要时刻，我们进行了大规模的落地，可能是目前业界最大规模的实践。作为技术人能面对世界级的流量挑战，是非常紧张和兴奋的。当 Service Mesh 遇到双十一又会迸发出怎样的火花？蚂蚁金服的 LDC 架构继续演进的过程中，Service Mesh 要承载起哪方面的责任？我们借助四个“双十一考题”一一为大家揭晓。\nService Mesh 背景知识 Service Mesh 这个概念社区已经火了很久，相关的背景知识从我们的公众号内可以找到非常多的文章，我在这里不做过于冗余的介绍，仅把几个核心概念统一，便于后续理解。\n图1. Service Mesh 开源架构来自 https://istio.io/\nIstio 的架构图上清晰的描述了 Service Mesh 最核心的两个概念：数据面与控制面。数据面负责做网络代理，在服务请求的链路上做一层拦截与转发，可以在链路中做服务路由、链路加密、服务鉴权等，控制面负责做服务发现、服务路由管理、请求度量（放在控制面颇受争议）等。\nService Mesh 带来的好处不再赘述，我们来看下蚂蚁金服的数据面和控制面产品，如下图：\n图2. 蚂蚁金服 Service Mesh 示意架构\n**数据面：SOFAMosn。**蚂蚁金服使用 Golang 研发的高性能网络代理，作为 Service Mesh 的数据面，承载了蚂蚁金服双十一海量的核心应用流量。\n**控制面：SOFAMesh。**Istio 改造版，落地过程中精简为 Pilot 和 Citadel，Mixer 直接集成在数据面中避免多一跳的开销。\n2019 Service Mesh 双十一大考揭秘 双十一 SOFAMosn 与 SOFAMesh 经历海量规模大考，顺利保障双十一平稳渡过。今年双十一蚂蚁金服的百十多个核心应用全面接入 SOFAMosn，生产 Mesh 化容器几十万台，双十一峰值 SOFAMosn 承载数据规模数千万 QPS，SOFAMosn 转发平均处理耗时 0.2ms。\n图3. 双十一落地数据\n在如此大规模的接入场景下，我们面对的是极端复杂的场景，同时需要多方全力合作，更要保障数据面的性能稳定性满足大促诉求，整个过程极具挑战。下面我们将从几个方面来分享下我们在这个历程中遇到的问题及解决方案。\n双十一考题  如何让 Service Mesh 发挥最大的业务价值？ 如何达成几十万容器接入 SOFAMosn 的目标？ 如何处理几十万容器 SOFAMosn 的版本升级问题？ 如何保障 Service Mesh 的性能与稳定性达标？  落地架构 为了更加方便的理解以上问题的解决与后续介绍中可能涉及的术语等，我们先来看下 Service Mesh 落地的主要架构：\n图4. Service Mesh 落地架构\n以上架构图中主要分几部分：\n 数据面：借助 Kubernetes 中的 Pod 模型，SOFAMosn 以独立镜像和 App 镜像共同编排在同一个 Pod 内，共享相同的 Network Namespace、CPU、Memory，接入 SOFAMosn 后所有的 App RPC 流量、消息流量均不在直接对外，而是直接和 SOFAMosn 交互，由 SOFAMosn 直接对接服务注册中心做服务发现，对接 Pilot 做配置下发，对接 MQ Server 做消息收发等； 控制面：由 Pilot、Citadel 和服务注册中心等组件组成，负责服务地址下发、服务路由下发、证书下发等； 底层支撑：Sidecar 的接入与升级等均依赖 Kubernetes 能力，通过 webhook 做 Sidecar 的注入，通过 Operator 做 Sidecar 的版本升级等，相关运维动作均离不开底层的支撑； 产品层：结合底层提供的原子能力做运维能力封装，监控对接，采集 Sidecar 暴露的 Metrics 数据做监控与预警，流量调控，安全等产品化能力；  蚂蚁金服的答卷 1. 如何让 Service Mesh 发挥最大的业务价值？ 作为一个技术人，我们非常坚持不要为了技术革新本身去做技术革新，一定要让技术帮助业务，用技术驱动业务。这几年随着大家消费习惯以及网络行为的改变，双十一面对的业务场景远比想象中复杂。举个例子大家感受下，大家有没有发现你的女友或者老婆每天对着李佳琦的淘宝直播购物，主播们不断的、实时的红包、上新等等，带来了远比秒杀更复杂的业务场景和体量。大促的模式也更加丰富，不同场景下的大促涉及的应用是不同的，每一类应用在应对独特的洪峰时都需要有足够的资源。\n假如运营同学在不同时间点设计了两种活动，两种活动分别会对应两类不同的应用，如果这两类应用都在大促前准备充足的资源自然是轻松渡过大促峰值，但大促洪峰时间短暂，大量的资源投入有很长一段时间都处于空闲状态，这自然不符合技术人的追求。\n那么如何在不增加资源的场景下渡过各种大促呢？\n核心问题就是如何在足够短的时间内做到大规模资源腾挪，让一批机器资源可以在不同时间点承载起不同的大促洪峰。\n面对这样的挑战，我们会有怎样的解法呢？\nService Mesh 618 大促落地试点时，我们有介绍到为什么要做这个事情，核心价值是业务与基础设施解耦，双方可以并行发展，快速往前走。那么并行发展究竟能为业务带来哪些实际的价值？除了降低基础组件的升级难度之外，我们还在资源调度方向做了以下探索：\n1.1 腾挪调度 说到资源调度，最简单的自然是直接做资源腾挪，比如大促A峰值过后，大促A对应的应用通过缩容把资源释放出来，大促B对应的应用再去申请资源做扩容，这种方式非常简单，难点在于当资源规模非常庞大时，缩容扩容的效率极低，应用需要把资源申请出来并启动应用，耗时很 …","date":1574154000,"description":" 当 Service Mesh 遇到双十一又会迸发出怎样的火花？蚂蚁金服的 LDC 架构继续演进的过程中，Service Mesh 要承载起哪方面的责任？我们借助四个“双十一考题”一一为大家揭晓。","dir":"blog/service-mesh-practice-antfinal-shopping-festival-big-exam/","fuzzywordcount":6300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"269c9444948a5f83a5a17f907b72ce4a","permalink":"/blog/service-mesh-practice-antfinal-shopping-festival-big-exam/","publishdate":"2019-11-19T17:00:00+08:00","readingtime":13,"relpermalink":"/blog/service-mesh-practice-antfinal-shopping-festival-big-exam/","summary":"2019 年的双十一是蚂蚁金服的重要时刻，大规模落地了 Service Mesh 并顺利保障双十一平稳渡过。我们第一时间与这次的落地负责人进行了交流。 采访的开头： 花肉：“这","tags":["Service mesh","Service Mesh 落地实践"],"title":"Service Mesh 落地负责人亲述：蚂蚁金服双十一四大考题","type":"blog","url":"/blog/service-mesh-practice-antfinal-shopping-festival-big-exam/","wordcount":6255},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@瀚墨 提问：\n 请问 SOFARPC 本地多人开发有没有最佳实践分享一下了？\n A：你说的多人开发具体是指啥协作场景？\n 开发人员开发本地的服务时，需要依赖的服务可以来自一个开发环境！这样的开发人员就不需要启动自己本地所有的服务了。我们已经有一个开发环境，会部署所有的服务，但是当开发人员开发某一个功能时，可能只希望其中几个接口走本地，其他的接口走开发环境！\n A：你的这个开发环境是一组不确定的机器，还是一台指定 IP 的机器？\nSOFARPC：https://github.com/sofastack/sofa-rpc\n 指定的 IP 地址。\n A：一种方法本地调用方直接配开发环境的机器直连调用， 另外一个方法就是开发环境统一使用一个 uniqueId，和本地用不同的uniqueId。\n2、@温明磊 提问：\n Seata Saga 向前重试状态机 json 该怎么配置，节点代码内部和节点 json 的 catch 都不捕获异常吗，这样就会一直调用该节点。\n A：运行过程中向前重试：通过 Catch 到异常然后 Next 到当前节点（这种实现了 Retry 配置之后就不需要了），事后向前重试：直接调 forward 方法即可（一般不需要自己调，server 端会自动触发）。\n Retry 配置什么时候实现，事后向前重试是一定会发生的吗？\n A：Retry 配置正在做了。事后向前重试目前 server 端的逻辑是这样的：失败时，如果没有触发回滚，那么 server 端会不断发起重试，如果触发过回滚（也就是回滚失败了）server 端会不断触发 compensate。\n 这个没用触发回滚，是不是像我上面说的这个出错节点，代码内部没用捕获异常，json 也没有 catch 异常，然后就不断重试了。\n A：是的。\n3、@金雷-上海 提问：\n 看代码，Saga 二阶段提交成功不删分支事务？回滚也是不删，有特殊原因？\n A：你是 server 端的分支事务吗？客户端的状态机日志不会删，server 端没有显示删除分支事务，只是提交或回滚全局事务。\n 嗯，我看了代码是这样，不清楚为什么这么操作。 全局事务表删了，分支事务不删。\n A：是这样的，Saga 模式的回滚是在客户端状态机协调的，不是用 TC 协调的，TC 只是触发，客户端回滚或成功后会调 server 端上报回滚成功。所以我理解是 server 端这时会删除全局事务记录，而没有删除分支事务记录。因为是客户端协调，所以 TC 也没有循环去调每一个分支事务的 rollback，所以分支事务实际上是留下了，没有被删除。\n 既然全局事务都删除了，如果留着没有什么意义，我觉得可以删除分支事务。\n A：是的。提个 issue，修改一下。\n你提的那个 issue 修复了 ，https://github.com/seata/seata/pull/1893 同时做了一个优化，重试和补偿服务不向 Seata server 注册分支事务，仅原始服务注册分支事务，重试和补偿服务执行完成时向原始服务注册的分支事务上报成功与否的状态。\nRetry 功能，\u0026amp;ldquo;BackoffRate\u0026amp;rdquo;: 1.5，表示重试间隔增量，1.5表示本次重试间隔是上次的1.5倍：https://github.com/seata/seata/issues/1899\n还有一个点，当重试过程中生了别的异常，框架会重新匹配这个异常对应的重试规则，并按新规则来重试，但同一种规则的总次数的不会超过它配置的 MaxAttempts，避免不同异常来回切换而一直重试。\n 新规则就是下面这个配置吗？\n A： 就是你可以配置多个重试规则，根据 Exceptions 属性来匹配，下面那个没有带 Exceptions 表示框架自动匹配网络超时异常。\n 配置了 Exceptions，不只是可以匹配节点的异常，还可以匹配重试的异常，执行新的重试规则。\n A：对的。\n4、@J～杰 提问：\n 我看整个 Saga 流程引擎都是自己开发的，那个 json 的参数属性含义哪里可以参考？\n A：这是官网文档，每个属性的含义，可以看 State language referance 节。 http://seata.io/zh-cn/docs/user/saga.html\n 如果用了 @GlobalTransactional，在并发场景中，是不是还要用 @GlobalLock 保证数据的隔离性？\n A：@GlobalLock 是用于非分布式事务场景下的读分布式事务中数据。在分布式事务的场景本身有全局锁来隔离。\nSeata：https://github.com/seata/seata\n双十一落地实践特辑阅读  蚂蚁金服 Service Mesh 大规模落地系列 - 核心篇 万字长文丨1分36秒，100亿，支付宝技术双11答卷：没有不可能  SOFA 项目进展 本周发布详情如下：\n发布 SOFATracer v2.4.2/3.0.8，主要变更如下：\n 迁移 samples 到 sofastack-guides空间下 修复 Server Receive 阶段出现 spanId 增长问题 优化 Zipkin 远程上报问题  详细发布报告： https://github.com/sofastack/sofa-tracer/releases/tag/v2.4.2 https://github.com/sofastack/sofa-tracer/releases/tag/v3.0.8\n云原生活动推荐  本期为 Service Mesh Meetup#8 特别场，联合 CNCF、阿里巴巴及蚂蚁金服共同举办。\n不是任何一朵云都撑得住双 11。\n成交 2684 亿，阿里巴巴核心系统 100% 上云。\n蚂蚁金服的核心交易链路大规模上线 Service Mesh。\n这次，让双 11 狂欢继续，让云原生经得起双 11 大考，也让云原生走到开发者身边。\n你将收获 3 大经验加持：\n 双 11 洗礼下的阿里巴巴 K8s 超大规模实践经验 蚂蚁金服首次 Service Mesh 大规模落地经验 阿里巴巴超大规模神龙裸金属 K8s 集 …","date":1573801200,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20191115/","fuzzywordcount":2400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"c08a41ec62ae153bbc0ce35958093192","permalink":"/blog/sofa-weekly-20191115/","publishdate":"2019-11-15T15:00:00+08:00","readingtime":5,"relpermalink":"/blog/sofa-weekly-20191115/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | 每周精选【11/11 - 11/15】","type":"blog","url":"/blog/sofa-weekly-20191115/","wordcount":2320},{"author":"烈元","categories":"Service mesh","content":"揭秘 2019 Service Mesh 双十一大考 蚂蚁金服很早开始关注 Service Mesh，并在 2018 年发起 ServiceMesher 社区，目前已有 4000+ 开发者在社区活跃。在技术应用层面，Service Mesh 的场景已经渡过探索期，今年已经全面进入深水区探索。\n2019 年的双十一是我们的重要时刻，我们进行了大规模的落地。作为技术人能面对世界级的流量挑战，是非常紧张和兴奋的。当 Service Mesh 遇到双十一又会迸发出怎样的火花？蚂蚁金服的 LDC 架构继续演进的过程中，Service Mesh 要承载起哪方面的责任？让我们一起来揭秘蚂蚁金服 Service Mesh 双十一实战。\nService Mesh 基础概念 Istio 清晰的描述了 Service Mesh 最核心的两个概念：数据面与控制面。数据面负责做网络代理，在服务请求的链路上做一层拦截与转发，可以在链路中做服务路由、链路加密、服务鉴权等，控制面负责做服务发现、服务路由管理、请求度量（放在控制面颇受争议）等。\nService Mesh 带来的好处不再赘述，我们来看下蚂蚁金服的数据面和控制面产品：\n  **数据面：SOFAMosn。**蚂蚁金服使用 Golang 研发的高性能网络代理，作为 Service Mesh 的数据面，承载了蚂蚁金服双十一海量的核心应用流量。\n  **控制面：SOFAMesh。**Istio 改造版，落地过程中精简为 Pilot 和 Citadel，Mixer 直接集成在数据面中避免多一跳的开销。\n  双十一落地情况概览 今年，蚂蚁金服的核心应用全面接入 SOFAMosn，生产 Mesh 化容器几十万台，双十一峰值 SOFAMosn 承载数据规模数千万 QPS，SOFAMosn 转发平均处理耗时 0.2ms。\n在如此大规模的接入场景下，我们面对的是极端复杂的场景，同时需要多方全力合作，更要保障数据面的性能稳定性满足大促诉求，整个过程极具挑战。\n同时，Service Mesh 的落地也是一个跨团队合作的典范案例，集合了核心、RPC、消息、无线网关、控制面、安全、运维、测试等团队的精诚合作，接下来我们会按照以上几个模块来解析 Service Mesh 的双十一落地情况，更多解析关注本网站。\n本文为《蚂蚁金服 Service Mesh 落地实践系列》第一篇 - 核心篇，作者：田阳（花名：烈元），蚂蚁金服技术专家，专注于高性能网络服务器研发，Tengine 开源项目核心成员，蚂蚁金服开源 SOFAMosn 项目核心成员。\n基础能力建设 SOFAMosn 的能力大图 SOFAMosn 主要划分为如下模块，包括了网络代理具备的基础能力，也包含了 XDS 等云原生能力。\n业务支持 SOFAMosn 作为底层的高性能安全网络代理，支撑了 RPC，MSG，GATEWAY 等业务场景。\nIO 模型 SOFAMosn 支持两种 IO 模型，一个是 Golang 经典模型，goroutine-per-connection；一个是 RawEpoll 模型，也就是 Reactor 模式，I/O 多路复用(I/O multiplexing) + 非阻塞 I/O(non-blocking I/O)的模式。\n在蚂蚁金服内部的落地场景，连接数不是瓶颈，都在几千或者上万的量级，我们选择了 Golang 经典模型。而对于接入层和网关有大量长链接的场景，更加适合于 RawEpoll 模型。\n协程模型  一条 TCP 连接对应一个 Read 协程，执行收包，协议解析； 一个请求对应一个 worker 协程，执行业务处理，proxy 和 Write 逻辑；  常规模型一个 TCP 连接将有 Read/Write 两个协程，我们取消了单独的 Write 协程，让 workerpool 工作协程代替，减少了调度延迟和内存占用。\n能力扩展 协议扩展\nSOFAMosn 通过使用同一的编解码引擎以及编/解码器核心接口，提供协议的 plugin 机制，包括支持：\n SOFARPC； HTTP1.x/HTTP2.0； Dubbo；  NetworkFilter 扩展\nSOFAMosn 通过提供 network filter 注册机制以及统一的 packet read/write filter 接口，实现了 Network filter 扩展机制，当前支持：\n TCP proxy； Fault injection；  StreamFilter 扩展\nSOFAMosn 通过提供 stream filter 注册机制以及统一的 stream send/receive filter 接口，实现了 Stream filter 扩展机制，包括支持：\n 流量镜像； RBAC鉴权；  TLS 安全链路 作为金融科技公司，资金安全是最重要的一环，链路加密又是其中最基础的能力，在 TLS 安全链路上我们进行了大量的调研测试。\n通过测试，原生的 Go 的 TLS 经过了大量的汇编优化，在性能上是 Nginx(OpenSSL）的80%，Boring 版本的 Go(使用 cgo 调用 BoringSSL) 因为 cgo 的性能问题， 并不占优势，所以我们最后选型原生 Go 的 TLS，相信 Go Runtime 团队后续会有更多的优化，我们也会有一些优化计划。\n go 在 RSA 上没有太多优化，go-boring（CGO）的能力是 go 的1倍； p256 在 go 上有汇编优化，ECDSA 优于go-boring； 在 AES-GCM 对称加密上，go 的能力是 go-boring 的20倍； 在 SHA、MD 等 HASH 算法也有对应的汇编优化；  为了满足金融场景的安全合规，我们同时也对国产密码进行了开发支持，这个是 Go Runtime 所没有的。虽然目前的性能相比国际标准 AES-GCM 还是有一些差距，大概是 50%，但是我们已经有了后续的一些优化计划，敬请期待。\n平滑升级能力 为了让 SOFAMosn 的发布对应用无感知，我们调研开发了平滑升级方案，类似 Nginx 的二进制热升级能力，但是有个最大的区别就是 SOFAMosn 老进程的连接不会断，而是迁移给新的进程，包括底层的 socket FD 和上层的应用数据，保证整个二进制发布过程中业务不受损，对业务无感知。除了支持 SOFARPC、Dubbo、消息等协议，我们还支持 TLS 加密链路的迁移。\n容器升级\n基于容器平滑升级 SOFAMosn 给了我们很多挑战，我们会先注入一个新的 SOFAMosn，然后他会通过共享卷的 UnixSocket 去检查是否存在老的 SOFAMosn，如果存在就和老的 SOFAMosn 进行连接迁移，然后老的 SOFAMosn 退出。这一块的细节较多，涉及 SOFAMosn 自身和 Operator 的交互。\nSOFAMosn 的连接迁移\n连接迁移的核心主要是内核 Socket 的迁移和应用数据的迁移，连接不断，对用户无感知。\nSOFAMosn 的 metric 迁移\n我们使用了共享内存来共享新老进程的 metric 数据， …","date":1573779600,"description":" 当 Service Mesh 遇到双十一又会迸发出怎样的火花？蚂蚁金服的 LDC 架构继续演进的过程中，Service Mesh 要承载起哪方面的责任？让我们一起来揭秘蚂蚁金服 Service Mesh 双十一实战。","dir":"blog/service-mesh-practice-in-production-at-ant-financial-part1-core/","fuzzywordcount":3500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"f758a3d4476cd3e8516947fa6fff5747","permalink":"/blog/service-mesh-practice-in-production-at-ant-financial-part1-core/","publishdate":"2019-11-15T09:00:00+08:00","readingtime":7,"relpermalink":"/blog/service-mesh-practice-in-production-at-ant-financial-part1-core/","summary":"揭秘 2019 Service Mesh 双十一大考 蚂蚁金服很早开始关注 Service Mesh，并在 2018 年发起 ServiceMesher 社区，目前已有 4000+ 开发者在社区活跃。在技术应用层面，Service Mesh 的场景已","tags":["Service mesh","Service Mesh 落地实践"],"title":"蚂蚁金服 Service Mesh 大规模落地系列 - 核心篇","type":"blog","url":"/blog/service-mesh-practice-in-production-at-ant-financial-part1-core/","wordcount":3402},{"author":"潘潘","categories":"Service Mesh","content":"概要  活动主题：Kubernetes \u0026amp;amp; Cloud Native X Service Mesh Meetup 活动时间：2019 年 11 月 24 日（星期日）9:30-16:30 活动地点：北京朝阳大望京科技商务园区宏泰东街浦项中心B座2层多功能厅 活动形式：线下活动 活动报名：请戳这里  活动介绍 Service Mesh Meetup#8 特别场 本期为 Service Mesh Meetup#8 特别场，联合 CNCF、阿里巴巴及蚂蚁金服 共同举办。\n不是任何一朵云都撑得住双 11。\n成交 2684 亿，阿里巴巴核心系统 100% 上云。\n蚂蚁金服的核心交易链路大规模上线 Service Mesh。\n这次，让双 11 狂欢继续，让云原生经得起双 11 大考，也让云原生走到开发者身边。\n你将收获 3 大经验加持：\n 双 11 洗礼下的阿里巴巴 K8s 超大规模实践经验； 蚂蚁金服首次 Service Mesh 大规模落地经验； 阿里巴巴超大规模神龙裸金属 K8s 集群运维实践经验；  错过一次，再等一年哦。\n议程    时间 环节（分享主题） 分享嘉宾     9:00-9:30 签到    9:30-10:10 《释放云原生价值，双 11 洗礼下的阿里巴巴 K8s 超大规模实践》 曾凡松（逐灵），阿里巴巴高级技术专家；汪萌海（木苏），阿里巴巴技术专家   10:10-10:50 《蚂蚁金服双十一Service Mesh超大规模落地揭秘》 黄挺（鲁直），蚂蚁金服云原生负责人；雷志远（碧远），蚂蚁金服技术专家   10:50-11:30 《阿里巴巴超大规模神龙裸金属 K8s 集群运维实践》 周涛 （广侯），阿里巴巴高级技术专家   11:30-12:10  《深入Kubernetes的“无人区” — 蚂蚁金服双十一的调度系统》 曹寅，蚂蚁金服 Kubernetes 落地负责人   12:10-13:30 午休    13:30-14:10  《服务网格在“路口”的产品思考与实践》 宋顺（齐天），蚂蚁金服高级技术专家，开源配置中心Apollo作者   14:10-14:50 《阿里集团核心应用落地 Service Mesh 的挑战与机遇》 李云（至简），阿里巴巴高级技术专家   14:50-13:10 茶歇    15:10-15:50 《蚂蚁金服云原生 PaaS 实践之路》 王成昌（晙曦），蚂蚁金服技术专家   15:50-16:30 《函数计算在双十一小程序场景的应用》 吴天龙（木吴），阿里云函数计算技术专家    加入 SOFA 钉钉互动群 群号：23390449，使用钉钉搜索群号即可加入，获取一手开源技术干货。\n","date":1573639200,"description":"11月24日，Service Mesh Meetup#8 双十一特别场邀您参加，本期联合 CNCF、阿里巴巴及蚂蚁金服共同举办。","dir":"activities/service-mesh-meetup-8/","fuzzywordcount":800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"f127ede30ff37760f648b79ecf887ffa","permalink":"/activities/service-mesh-meetup-8/","publishdate":"2019-11-13T18:00:00+08:00","readingtime":2,"relpermalink":"/activities/service-mesh-meetup-8/","summary":"概要 活动主题：Kubernetes \u0026amp; Cloud Native X Service Mesh Meetup 活动时间：2019 年 11 月 24 日（星期日）9:30-16:30 活动地点：北京朝阳大望京科技商务园","tags":["Meetup","Service Mesh","Kubernetes"],"title":"Kubernetes \u0026 Cloud Native X Service Mesh Meetup","type":"activities","url":"/activities/service-mesh-meetup-8/","wordcount":758},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n@温明磊 提问：\n 出参入参都放在 Saga 的上下文中，如果参数内容较多较大，业务量又大的话，对内存有限制吗?\n A: 没有做限制，建议无关的参数不要放到上下文。下一个服务需要用的参数、或用于分支判断的参数可以放入上下文。\n 确认个事情：每个节点，要么自己方法内部 Catch 异常处理，使最终有返回信息。要么自己内部可以不处理，交由状态机引擎捕获异常，在 json 中定义 Catch 属性。 而不是补偿节点能够自动触发补偿，需要补偿必须手动在 json，由 Catch 或者 Choices 属性路由到 CompensationTrigger。\n A：对的，这个是为了提高灵活性。用户可以自己控制是否进行回滚，因为并不是所有异常都要回滚，可能有一些自定义处理手段。\n 所以 Catch 和 Choices 可以随便路由到想要的 state 对吧？\n A：是的。这种自定义出发补偿的设计是参考了 bpmn2.0 的。\n 还有关于 json 文件，我打算一条流程，就定义一个 json，虽然有的流程很像，用 Choices，可以解决。但是感觉 json 还是要尽量简单。这样考虑对吗？\n A：你可以考虑用子状态机来复用，子状态机会多生成一行 stateMachineInstance 记录，但对性能影响应该不大。\nService Mesh 相关阅读   从网络接入层到 Service Mesh，蚂蚁金服网络代理的演进之路\n  诗和远方：蚂蚁金服 Service Mesh 深度实践 | QCon 实录\n  Service Mesh 发展趋势(续)：棋到中盘路往何方 | Service Mesh Meetup 实录\n  蚂蚁金服 Service Mesh 落地实践与挑战 | GIAC 实录\n  Service Mesh 发展趋势：云原生中流砥柱\n  企业服务行业如何试水 Istio | Service Mesh Meetup 分享实录\n  蚂蚁金服Service Mesh新型网络代理的思考与实践 | GIAC 分享实录\n  蚂蚁金服 Service Mesh 渐进式迁移方案|Service Mesh Meetup 实录\n  蚂蚁金服 Service Mesh 实践探索 | Qcon 实录\n  干货 | 蚂蚁金服是如何实现经典服务化架构往 Service Mesh 方向的演进的？\n  活动推荐 2019年度TOP100全球软件案例研究峰会即将举行，蚂蚁金服也受邀参与本次案例分享。\nService Mesh 是蚂蚁金服下一代架构的核心，本主题主要分享在蚂蚁金服当前的体量下，我们如何做到在奔跑的火车上换轮子，将现有的 SOA 体系快速演进至 Service Mesh 架构。RPC、消息、DB、安全、运维等每一个环节均充满挑战。本次实战分享蚂蚁金服双十一核心应用如何大规模落地 Service Mesh 架构并降低大促成本。\n主题：《蚂蚁金服 Service Mesh 双十一实战》\n嘉宾：石建伟，花名：卓与，蚂蚁金服中间件技术专家，主要负责蚂蚁金服服务注册中心、配置中心与 Service Mesh 的研发与架构。当前专注在蚂蚁金服 Service Mesh 内部落地。\n时间：2019年11月15日（周五）16:50-17:50\n地点：北京国际会议中心\n报名方式：点击“这里”即可锁定席位\n","date":1573196400,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20191108/","fuzzywordcount":1300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"4615f39bbae97f3f8b4b1705fcbc5d2f","permalink":"/blog/sofa-weekly-20191108/","publishdate":"2019-11-08T15:00:00+08:00","readingtime":3,"relpermalink":"/blog/sofa-weekly-20191108/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | 每周精选【11/04 - 11/08】","type":"blog","url":"/blog/sofa-weekly-20191108/","wordcount":1254},{"author":"涵畅","categories":"Service mesh","content":"本文作者：肖涵（涵畅）\n上篇文章《诗和远方：蚂蚁金服 Service Mesh 深度实践 | QCon 实录》中，介绍了 Service Mesh 在蚂蚁金服的落地情况和即将来临的双十一大考，帮助大家了解 Service Mesh 未来发展方向和前景。蚂蚁金服持续在进行 Service Mesh 布道和交流。本文内容整理自 10 月 26 日 Service Mesh Meetup#7 成都站主题演讲，现场视频以及分享 PPT 获取方式见文章底部。\n从网络硬件设备到自研平台，从传统服务治理到 Service Mesh，本文将介绍蚂蚁金服网络代理在接入层以及 Service Mesh 化道路上是如何一步步支撑起秒级百万支付，千万春晚咻一咻的。\n前言 在云计算和 SDN 下，我们经常听到流量的东西南北向概念，简单来说从外部 Internet 等到数据中心内部的流量走向被称为南北流量，数据中心内部的 VM 之间的流量被称为东西流量。\n当我们追踪南北向的网络流，请求通常会经过四层负载均衡，七层负载均衡等，这通常被我们称为网络接入层代理。当数据中心内部主动访问公网时候，流量通常也会经过 NAT 网关等做网络地址的转换，这也被我们称为网络代理。当我们把视角转向数据中心内部，网络代理的存在感似乎不是那么强，随着 SOA 的发展我们形成了各种成熟的服务通信框架，例如蚂蚁金服的 SOFAStack，阿里集团的 HSF，Google 的 gRPC 等等，网络代理功能被集成进了各种通信框架中，似乎已经 Proxyless 化了，但是随着微服务以及 Service Mesh 的架构提出，东西向的网络代理以独立的姿态又出现了。\n本文将围绕蚂蚁金服近十年网络代理的变迁，揭示整个蚂蚁金服接入层网络以及 Service Mesh 的演进过程，同时带来我们的思考。\n旧瓶新装 我们先来看看业界情况，传统四层负载均衡的代表产品当然是 IPVS，百度阿里等公司早年均对 IPVS 做了非常深度的定制功能，支撑了早期业务的飞速发展。接着也有 DPDK(阿里云 SLB)，类 DPDK 技术的代表 Google 的 Maglev 以及 eBPF 技术的代表 Facebook 的 Katran 出现。\n七层网络代理各个大厂均有产品代表，Google 的 GFE、百度 的 BFE、腾讯 的 TGW，阿里经济体内部也因为场景等原因有众多，例如手淘的 Aserver，集团 web 统一接入 Tengine，当然还有蚂蚁金服的 Spanner（后面会详细介绍）。同时随着 Service Mesh 概念的提出和技术的逐渐成熟，Mesh 中 Sidecar 角色的网络代理也像雨后春笋一样多了起来，包括蚂蚁金服的 SOFAMosn，Istio 社区方案的 Envoy 以及 Rust 编写的 Linkerd，当然 Service Mesh 场景的网络代理和网络接入层的代理我认为没有本质的差别，随着云原生的深入化，大家终将会形成合力并保持一致的形态。\n上图是2019年 Gartner Networking 方向的曲线，可以看到在上升和爆发区有着非常多的网络代理的影子（Secure Access Service Edge，Service Mesh，Edge Networking，Firewall as a Service etc.），虽然网络代理是一项古老的技术以及产品形态，但是仍然随着基础设施以及业务的变化以新的能力和角色展现在世人眼前。\n网络代理的十年 网络代理技术一直围绕“高效接入，访问加速，稳定高可用，安全合规”四个关键词，不断升级核心能力，架构以及运维能力，底层基础网络物理带宽从1G到10G、25G、100G；阿里骨干广域网络走出杭州扩展到全国、全球规模，不断地通过前瞻技术架构研发，技术自主能力的提升和转变，助力业务发展。\n蚂蚁金服应用网络架构概览 产品理念 我们应该以什么样的业务设计来满足上层业务以及市场的需要？产品理念决定了产品的走向，我们设定了网络产品的核心理念模型：\n网络产品设计理念\n接入层代理十年变迁 接入层网络代理的十年变迁之路，我们可以总结为三个时代，四个阶段：PC 时代、移动时代和万物互联云原生时代，伴随着这三个时代，我们经历了四个关键路径。\n前世 2010年前蚂蚁金服网络代理是商用设备的时代，包括 F5 的 bigip，Netscaler 等产品，对于商业设备白盒化，大家比较熟知的是去 IOE，其实网络设备走在了更前面。使用商用设备主要有几个问题，厂商的 Lockin，成本以及灵活扩展等问题，所以从2010年蚂蚁金服开始向自主研发演进。\n自主研发 我们同时开启了四七层网络接入的自研之路，四七层网络由于场景的不同，在整个演进路线上也有较大的差异。\n四层负载均衡 四层网络由于不理解业务语义，主要进化路线是伴随着系统技术，硬件技术的变化，围绕提高吞吐，降低延迟的目标而演进。2014年全面使用 DPDK 进行技术重构，将传统基于内核技术的 IPVS 新建，转发指标分别从万级，十万级提高到百万和千万级的每秒包转发。\n同时随着 Ebpf，Xdp 技术的出现，基于内核的高速转发平面产品又横空出世（包括 Facebook 开源的 Katran）打破了 DPDK 技术的垄断，同时可编程交换芯片以及 P4 语言也加入了这一站场，这里不具体讨论每种技术的优劣。\nSpanner Spanner 是蚂蚁金服的统一接入网关，其意为扳手，主要是为蚂蚁金服 SSL 卸载和网络接入提供了白盒化解决方案，承载了蚂蚁金服所有的业务流量，包括支付宝 App，Web，商户等的终端访问。\n金融级三地五中心架构的流量调度\n上图展示了 Spanner 的编年史，在2013年蚂蚁金服上架了自己的逻辑数据中心架构 LDC，同时随着演进支持了目前的蚂蚁金服金融级的三地五中心容灾架构：\n为了支持这套架构，蚂蚁金服的所有基础设施都进行了改造和技术升级，流量调拨能力作为最基础的能力，是一个基本盘，Spanner 通过对请求头的识别以及全站转发规则映射来实现流量调度，支撑并不限于以下场景：\n 机房内随机路由； 蓝绿发布； 容灾：  逻辑机房内容灾； 机房级别； 城市级别；   弹性调度； 压测流量调度； 灰度流量调度；  SSL/TLS 实践\n蚂蚁金服作为全集团最早实践 https 全站的 BU，一直围绕着安全，合规，性能的主题进行全站加密体系的建设。\n成本之战\n前面提到2012年 Spanner 全面上线后，我们接入层具备了定制业务逻辑的能力，在2013年很好支撑了 LDC 的上线，同时我们在性能成本方面也有机会去进行持续的提升，同年我们引入 SSL 加速卡软硬件一体解决方案，从现在来看该套方案已经非常成熟了，集团 Tengine，Openssl 都提供了非常方便的接入框架，但是当年这一块还一直处于探索阶段。我们在 Spanner 里做了 Nginx 的 SSL 握手异步化改造，改造了 Openssl 同 Cavium 的 SSL 加速卡进行适配，整套方案在当时的机型上较 CPU 提升了基于 RSA2048 算法的 SSL 握手3倍的性能，同时也对后续各大厂商在这方面的实践产生了指导性意 …","date":1573030800,"description":" 从网络硬件设备到自研平台，从传统服务治理到 Service Mesh，本文将介绍蚂蚁金服网络代理在接入层以及 Service Mesh 化道路上是如何一步步支撑起秒级百万支付，千万春晚咻一咻的。","dir":"blog/antfin-service-mesh-network-agents/","fuzzywordcount":7600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"b539a4c29754f9e761c2027426566250","permalink":"/blog/antfin-service-mesh-network-agents/","publishdate":"2019-11-06T17:00:00+08:00","readingtime":15,"relpermalink":"/blog/antfin-service-mesh-network-agents/","summary":"本文作者：肖涵（涵畅） 上篇文章《诗和远方：蚂蚁金服 Service Mesh 深度实践 | QCon 实录》中，介绍了 Service Mesh 在蚂蚁金服的落地情况和即将来临的双十一大考，帮助大家了","tags":["Service mesh"],"title":"从网络接入层到 Service Mesh，蚂蚁金服网络代理的演进之路","type":"blog","url":"/blog/antfin-service-mesh-network-agents/","wordcount":7507},{"author":"敖小剑","categories":"Service mesh","content":" 2019 年，蚂蚁金服在 Service Mesh 领域继续高歌猛进，进入大规模落地的深水区。本文整理自蚂蚁金服高级技术专家敖小剑在 QCon 全球软件开发大会（上海站）2019 上的演讲，他介绍了 Service Mesh 在蚂蚁金服的落地情况和即将来临的双十一大考，以及大规模落地时遇到的困难和解决方案，助你了解 Service Mesh 的未来发展方向和前景。\n 前言 大家好，我是敖小剑，来自蚂蚁金服中间件团队，今天带来的主题是“诗和远方：蚂蚁金服 Service Mesh 深度实践”。\n在过去两年，我先后在 QCon 做过两次 Service Mesh 的演讲：\n 2017年，当时 Service Mesh 在国内还属于蛮荒时代，我当时做了一个名为“Service Mesh: 下一代微服务”的演讲，开始在国内布道 Service Mesh 技术； 2018年，做了名为“长路漫漫踏歌而行：蚂蚁金服 Service Mesh 实践探索”的演讲，介绍蚂蚁金服在 Service Mesh 领域的探索性的实践，当时蚂蚁金服刚开始在 Service Mesh 探索。  今天，有幸第三次来到 QCon，给大家带来的依然是蚂蚁金服在 Service Mesh 领域的实践分享。和去年不同的是，今年蚂蚁金服进入了 Service Mesh 落地的深水区，规模巨大，而且即将迎来双十一大促考验。\n 备注：现场做了一个调研，了解听众对 Servicve Mesh 的了解程度，结果不太理想：在此之前对 Service Mesh 有了解的同学目测只有10%多点（肯定不到20%）。Service Mesh 的技术布道，依然任重道远。\n 今天给大家带来的内容主要有三块：\n 蚂蚁金服落地情况介绍：包括大家最关心的双十一落地情况； 大规模落地的困难和挑战：分享一下我们过去一年中在大规模落地上遇到的问题； 是否采用 Service Mesh 的建议：这个问题经常被人问起，所以借这个机会给出一些中肯的建议供大家参考；  蚂蚁金服落地情况介绍 发展历程和落地规模 Service Mesh 技术在蚂蚁金服的落地，先后经历过如下几个阶段：\n 技术预研 阶段：2017年底开始调研并探索 Service Mesh 技术，并确定为未来发展方向； 技术探索 阶段：2018年初开始用 Golang 开发 Sidecar SOFAMosn，年中开源基于 Istio 的 SOFAMesh； 小规模落地 阶段：2018年开始内部落地，第一批场景是替代 Java 语言之外的其他语言的客户端 SDK，之后开始内部小范围试点； 规模落地 阶段：2019年上半年，作为蚂蚁金融级云原生架构升级的主要内容之一，逐渐铺开到蚂蚁金服内部的业务应用，并平稳支撑了618大促； 全面大规模落地 阶段：2019年下半年，在蚂蚁金服内部的业务中全面铺开，落地规模非常庞大，而且准备迎接双十一大促；  目前 ServiceMesh 正在蚂蚁金服内部大面积铺开，我这里给出的数据是前段时间（大概9月中）在云栖大会上公布的数据：应用数百个，容器数量（pod 数）超过10万。当然目前落地的pod数量已经远超过10万，这已经是目前全球最大的 Service Mesh 集群，但这仅仅是一个开始，这个集群的规模后续会继续扩大，明年蚂蚁金服会有更多的应用迁移到 Service Mesh。\n主要落地场景 目前 Service Mesh 在蚂蚁金服内部大量落地，包括支付宝的部分核心链路，落地的主要场景有：\n 多语言支持：目前除了支持 Java 之外，还支持 Golang，Python，C++，NodeJS 等语言的相互通信和服务治理； 应用无感知的升级：关于这一点我们后面会有特别的说明； 流量控制：经典的 Istio 精准细粒度流量控制； RPC 协议支持：和 Istio 不同，我们内部使用的主要是 RPC 协议； 可观测性；  Service Mesh 的实际性能数据 之前和一些朋友、客户交流过，目前在 Service Mesh 方面大家最关心的是 Service Mesh 的性能表现，包括对于这次蚂蚁金服 Service Mesh 上双十一，大家最想看到的也是性能指标。\n为什么大家对性能这么关注？\n因为在 Service Mesh 工作原理的各种介绍中，都会提到 Service Mesh 是将原来的一次远程调用，改为走 Sidecar（而且像 Istio 是客户端和服务器端两次 Sidecar，如上图所示），这样一次远程调用就会变成三次远程调用，对性能的担忧也就自然而然的产生了：一次远程调用变三次远程调用，性能会下降多少？延迟会增加多少？\n下图是我们内部的大促压测数据，对比带 SOFAMosn 和不带 SOFAMosn 的情况（实现相同的功能）。其中 SOFAMosn 是我们蚂蚁金服自行开发的基于 Golang 的 Sidecar/数据平面，我们用它替代了 Envoy，在去年的演讲中我有做过详细的介绍。\nSOFAMosn：https://github.com/sofastack/sofa-mosn\n CPU：CPU 使用在峰值情况下增加8%，均值约增加2%。在最新的一次压测中，CPU 已经优化到基本持平（低于1%）； 内存：带 SOFAMosn 的节点比不带 SOFAMosn 的节点内存占用平均多 15M； 延迟：延迟增加平均约0.2ms。部分场景带 SOFAMosn 比不带 SOFAMosn RT 增加约5%，但是有部分特殊场景带 SOFAMosn 比不带 SOFAMosn RT 反而降低7.5%；  这个性能表现，和前面\u0026amp;quot;一次远程调用变三次远程调用\u0026amp;quot;的背景和担忧相比有很大的反差。尤其是上面延迟的这个特殊场景，居然出现带 SOFAMosn（三次远程调用）比不带 SOFAMosn（一次远程调用） 延迟反而降低的情况。\n是不是感觉不科学？\nService Mesh 的基本思路 我们来快速回顾一下 Service Mesh 实现的基本思路：\n在基于 SDK 的方案中，应用既有业务逻辑，也有各种非业务功能。虽然通过 SDK 实现了代码重用，但是在部署时，这些功能还是混合在一个进程内的。\n在 Service Mesh 中，我们将 SDK 客户端的功能从应用中剥离出来，拆解为独立进程，以 Sidecar 的模式部署，让业务进程专注于业务逻辑：\n 业务进程：专注业务实现，无需感知 Mesh； Sidecar 进程：专注服务间通讯和相关能力，与业务逻辑无关；  我们称之为\u0026amp;quot;关注点分离\u0026amp;quot;：业务开发团队可以专注于业务逻辑，而底层的中间件团队（或者基础设施团队）可以专注于业务逻辑之外的各种通用功能。\n通过 Sidecar 拆分为两个独立进程之后，业务应用和 Sidecar 就可以实现“独立维护”：我们可以单独更新/升级业务应用或者 Sidecar。\n性能数据背后的情景分析 我们回到前面的蚂蚁金服 Service Mesh 落地后的性能对比数据：从原理上说，Sidecar 拆分之后，原来 SDK 中的各种功能只是拆分到 Sidecar 中。整体上并没有增减， …","date":1572922800,"description":" 本文整理自蚂蚁金服高级技术专家敖小剑在 QCon 全球软件开发大会（上海站）2019 上的演讲。","dir":"blog/service-mesh-antfin-deep-practice-qcon/","fuzzywordcount":12500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"561edcf88763b36e72894da214d2b123","permalink":"/blog/service-mesh-antfin-deep-practice-qcon/","publishdate":"2019-11-05T11:00:00+08:00","readingtime":25,"relpermalink":"/blog/service-mesh-antfin-deep-practice-qcon/","summary":"2019 年，蚂蚁金服在 Service Mesh 领域继续高歌猛进，进入大规模落地的深水区。本文整理自蚂蚁金服高级技术专家敖小剑在 QCon 全球软件开发大会（上海站）2019 上的","tags":["Service mesh"],"title":"诗和远方：蚂蚁金服 Service Mesh 深度实践 | QCon 实录","type":"blog","url":"/blog/service-mesh-antfin-deep-practice-qcon/","wordcount":12422},{"author":"屹远","categories":"Seata","content":"Seata 意为：Simple Extensible Autonomous Transaction Architecture，是一套一站式分布式事务解决方案，提供了 AT、TCC、Saga 和 XA 事务模式，本文详解其中的 Saga 模式。 项目地址：https://github.com/seata/seata\n本文作者：屹远（陈龙），蚂蚁金服分布式事务核心研发 。\n金融分布式应用开发的痛点 分布式系统有一个比较明显的问题就是，一个业务流程需要组合一组服务。这样的事情在微服务下就更为明显了，因为这需要业务上的一致性的保证。也就是说，如果一个步骤失败了，那么要么回滚到以前的服务调用，要么不断重试保证所有的步骤都成功。\u0026amp;mdash;《左耳听风-弹力设计之“补偿事务”》\n而在金融领域微服务架构下的业务流程往往会更复杂，流程很长，比如一个互联网微贷业务流程调十几个服务很正常，再加上异常处理的流程那就更复杂了，做过金融业务开发的同学会很有体感。\n所以在金融分布式应用开发过程中我们面临一些痛点：\n 业务一致性难以保障  我们接触到的大多数业务（比如在渠道层、产品层、集成层的系统），为了保障业务最终一致性，往往会采用“补偿”的方式来做，如果没有一个协调器来支持，开发难度是比较大的，每一步都要在 catch 里去处理前面所有的“回滚”操作，这将会形成“箭头形”的代码，可读性及维护性差。或者重试异常的操作，如果重试不成功可能要转异步重试，甚至最后转人工处理。这些都给开发人员带来极大的负担，开发效率低，且容易出错。\n 业务状态难以管理  业务实体很多、实体的状态也很多，往往做完一个业务活动后就将实体的状态更新到了数据库里，没有一个状态机来管理整个状态的变迁过程，不直观，容易出错，造成业务进入一个不正确的状态。\n 幂等性难以保障  服务的幂等性是分布式环境下的基本要求，为了保证服务的幂等性往往需要服务开发者逐个去设计，有用数据库唯一键实现的，有用分布式缓存实现的，没有一个统一的方案，开发人员负担大，也容易遗漏，从而造成资损。\n 业务监控运维难，缺乏统一的差错守护能力  业务的执行情况监控一般通过打印日志，再基于日志监控平台查看，大多数情况是没有问题的，但是如果业务出错，这些监控缺乏当时的业务上下文，对排查问题不友好，往往需要再去数据库里查。同时日志的打印也依赖于开发，容易遗漏。对于补偿事务往往需要有“差错守护触发补偿”、“工人触发补偿”操作，没有统一的差错守护和处理规范，这些都要开发者逐个开发，负担沉重。\n理论基础 一些场景下，我们对数据有强一致性的需求时，会采用在业务层上需要使用“两阶段提交”这样的分布式事务方案。而在另外一些场景下，我们并不需要这么强的一致性，那就只需要保证最终一致性就可以了。\n例如蚂蚁金服目前在金融核心系统使用的就是 TCC 模式，金融核心系统的特点是一致性要求高（业务上的隔离性）、短流程、并发高。\n而在很多金融核心以上的业务（比如在渠道层、产品层、集成层的系统），这些系统的特点是最终一致即可、流程多、流程长、还可能要调用其它公司的服务（如金融网络）。这是如果每个服务都开发 Try、Confirm、Cancel 三个方法成本高。如果事务中有其它公司的服务，也无法要求其它公司的服务也遵循 TCC 这种开发模式。同时流程长，事务边界太长会影响性能。\n对于事务我们都知道 ACID，也很熟悉 CAP 理论最多只能满足其中两个，所以，为了提高性能，出现了 ACID 的一个变种 BASE。ACID 强调的是一致性（CAP 中的 C），而 BASE 强调的是可用性（CAP 中的 A）。我们知道，在很多情况下，我们是无法做到强一致性的 ACID 的。特别是我们需要跨多个系统的时候，而且这些系统还不是由一个公司所提供的。BASE 的系统倾向于设计出更加有弹力的系统，在短时间内，就算是有数据不同步的风险，我们也应该允许新的交易可以发生，而后面我们在业务上将可能出现问题的事务通过补偿的方式处理掉，以保证最终的一致性。\n所以我们在实际开发中会进行取舍，对于更多的金融核心以上的业务系统可以采用补偿事务，补偿事务处理方面在30年前就提出了 Saga 理论，随着微服务的发展，近些年才逐步受到大家的关注。目前业界比较也公认 Saga 是作为长事务的解决方案。\n https://github.com/aphyr/dist-sagas/blob/master/sagas.pdf http://microservices.io/patterns/data/saga.html\n 社区和业界的方案 Apache Camel Saga Camel 是实现 EIP（Enterprise Integration Patterns）企业集成模式的一款开源产品，它基于事件驱动的架构，有着良好的性能和吞吐量，它在2.21版本新增加了 Saga EIP。\nSaga EIP 提供了一种方式可以通过 camel route 定义一系列有关联关系的 Action，这些 Action 要么都执行成功，要么都回滚，Saga 可以协调任何通讯协议的分布式服务或本地服务，并达到全局的最终一致性。Saga 不要求整个处理在短时间内完成，因为它不占用任何数据库锁，它可以支持需要长时间处理的请求，从几秒到几天，Camel 的 Saga EIP 是基于 Microprofile 的 LRA（Long Running Action），同样也是支持协调任何通讯协议任何语言实现的分布式服务。\nSaga 的实现不会对数据进行加锁，而是在给操作定义它的“补偿操作”，当正常流程执行出错的时候触发那些已经执行过的操作的“补偿操作”，将流程回滚掉。“补偿操作”可以在 Camel route 上用 Java 或 XML DSL（Definition Specific Language）来定义。\n下面是一个 Java DSL 示例：\n// action from(\u0026amp;#34;direct:reserveCredit\u0026amp;#34;) .bean(idService, \u0026amp;#34;generateCustomId\u0026amp;#34;) // generate a custom Id and set it in the body  .to(\u0026amp;#34;direct:creditReservation\u0026amp;#34;) // delegate action from(\u0026amp;#34;direct:creditReservation\u0026amp;#34;) .saga() .propagation(SagaPropagation.SUPPORTS) .option(\u0026amp;#34;CreditId\u0026amp;#34;, body()) // mark the current body as needed in the compensating action  .compensation(\u0026amp;#34;direct:creditRefund\u0026amp;#34;) .bean(creditService, \u0026amp;#34;reserveCredit\u0026amp;#34;) .log(\u0026amp;#34;Credit ${header.amount} reserved. Custom Id …","date":1572861600,"description":" 一起来解读 Seata Saga 模式到底解决了什么问题。","dir":"blog/seata-saga-flexible-financial-applications/","fuzzywordcount":6400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"9c17449b81e0f1fe51d46bbaeaaa5516","permalink":"/blog/seata-saga-flexible-financial-applications/","publishdate":"2019-11-04T18:00:00+08:00","readingtime":13,"relpermalink":"/blog/seata-saga-flexible-financial-applications/","summary":"Seata 意为：Simple Extensible Autonomous Transaction Architecture，是一套一站式分布式事务解决方案，提供了 AT、TCC、Saga 和 XA 事务模式，本文详解其中的","tags":["Seata"],"title":"基于 Seata Saga 设计更有弹性的金融应用","type":"blog","url":"/blog/seata-saga-flexible-financial-applications/","wordcount":6349},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@罗健 提问：\n SOFAJRaft 跨机房支持吗？\n A： 跨机房不需要特殊支持，只是网络延时大一点而已。\n 延时大了，读写性能就会降低了吧？ 像 ZooKeeper 一样。\n A：1. SOFAJRaft 支持 transfer leader，把 leader transfer 到和业务就近的机房（目前需要手动调用 cli 服务）； 2. SOFAJRaft 1.3.0 会增加一个选举优先级特性，可以将指定机房节点优先级调高，尽量保证 leader 在指定机房。 SOFAJRaft：https://github.com/sofastack/sofa-jraft\n2、@阮仁照 提问：\n SOFAArk 在打多个 ark-biz 包时，如果有多个 biz 包之间互相调用，默认是会走 injvm 协议的，这是如何做到的。我看了 SOFABoot 那块对 injvm 的支持，是通过 sofaRuntimeContext 来查找实现类，sofaRuntimeContext 是被 spring 容器管理的 bean，这就要求多个 biz 包之间是共用一套 spring 环境（或者说有个统一的父容器），是这样的吗？还是有什么其他实现的思路？\n A：可以看下 com.alipay.sofa.runtime.invoke.DynamicJvmServiceProxyFinder 这个类。\n 懂了，原来在这之上还有个 SofaFramework维护一个静态变量，真巧妙，用这个来解决多个 spring 容器里的 rpc 调用问题吗？\n A：多个 spring 容器之间的调用，不是 rpc 调用，是进程内调用。\n 对的， 这里不是 rpc 调用了， 所以这里也是 filter 会失效的原因。这样的话，那 SofaFramework 这个类就要被所有子容器都共享才对，但是我看打出来的 executable-ark 包，并没有在 classpath 下加载这个类啊，子容器咋共享的？\n A：这个会打包成一个插件，放在 ark plugin 层。  既然说插件之间是隔离的，那你把 SofaFramework 打在插件里，别的 biz 包启动时从会从 plugin里拿一个 SofaFramework ，互相不可见，这不是有问题吗？\n A：不同 biz 会共享同一个。 SOFAArk：https://github.com/sofastack/sofa-ark\n**3、@温明磊 **提问：\n Seata 的 Saga 模式的 json 文件，支持热部署吗？\n A：支持，stateMachineEngine.getStateMachineConfig().getStateMachineRepository().registryByResources()。不过 Java 代码和服务需要自己实现支持热部署。\n Seata 服务部署集群是需要怎么配置? 还是现在不支持\n A：异步执行一个服务，已实现。https://github.com/seata/seata/issues/1843\n Saga 的参数是不是只能在状态机启动时定义。如果第二个服务，依赖第一个服务返回的信息，或者里面组装好的信息怎么办？\n A：有个 Output 参数定义，可以把服务返回的参数映射到状态机上下文，然后在下一个服务的 Input 里定义参数引用。\n 异步执行服务的话，需要在 file 加上这个配置吗?  A：这个是状态机定义的 Json 文件，不是 Seata 的客户端配置文件。 Seata：https://github.com/seata/seata\n本周推荐阅读   备战双 11！蚂蚁金服万级规模 K8s 集群管理系统如何设计？\n  K8s 1.14 发布了，Release Note 该怎么读？\n  SOFA 项目进展 本周发布详情如下：\n发布 SOFAMosn v0.8.0，主要变更如下： i. 内存占用优化，优化在连接数、并发数较多的场景下的内存占用 ii. Metrics 统计优化，RPC 心跳场景不计入 QPS 等 Metrics 统计 iii. XDS 处理优化，修改为完全无阻塞启动，并且降低了重试的频率 详细发布报告，请见： https://github.com/sofastack/sofa-mosn/releases/tag/0.8.0\n","date":1572591600,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20191101/","fuzzywordcount":1600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"cd5f758d6d5d28784524b55169ae0a98","permalink":"/blog/sofa-weekly-20191101/","publishdate":"2019-11-01T15:00:00+08:00","readingtime":4,"relpermalink":"/blog/sofa-weekly-20191101/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | 每周精选【10/28 - 11/01】","type":"blog","url":"/blog/sofa-weekly-20191101/","wordcount":1513},{"author":"潘潘","categories":"SOFALab","content":"| SOFALab \u0026amp;lt;SOFA:Lab/\u0026amp;gt; 源码研究实验室，由 SOFA 团队和源码爱好者们出品，欢迎你的加入~\n\u0026amp;lt;SOFA:ArkLab/\u0026amp;gt;是《剖析 | SOFAArk 源码》系列，会逐步详细介绍 SOFAArk 各个部分的代码设计和实现，欢迎领取文章进行共建。\n| SOFAArk SOFAArk 是一款基于 Java 实现的轻量级类隔离容器，主要提供类隔离和应用(模块)合并部署能力。在大型软件开发过程中，通常会推荐底层功能插件化，业务功能模块化的开发模式，以期达到低耦合、高内聚、功能复用的优点。SOFAArk 提供了一套较为规范化的插件化、模块化的开发方案，帮助解决依赖包冲突、多应用(模块)合并部署等场景问题。\nSOFAArk :https://github.com/sofastack/sofa-ark\n|\u0026amp;lt; SOFA:ArkLab/\u0026amp;gt;   认领列表：\n 【已完成】轻量级类隔离框架 SOFAArk 简介 【已认领】 SOFAArk 容器模型解析 【已认领】 SOFAArk 类加载模型机制解析 【已认领】 SOFAArk 合并部署能力解析 【已认领】 SOFAArk SPI 机制和 ClassLoaderHook 机制解析 【已认领】 SOFAArk 动态配置机制解析 【已认领】 SOFAArk maven 打包插件解析 【已认领】 （实践）SOFAArk 插件化机制解析与实践    领取方式：关注**「金融级分布式架构」** 回复可领取的文章标题，我们将会主动联系你，确认资质后，即可加入 SOFA:ArkLab/，It\u0026amp;rsquo;s your show time！\n  如果有同学对以上某个主题特别感兴趣的，可以留言讨论，我们会适当根据大家的反馈调整文章的顺序，谢谢大家关注 SOFAStack ，关注 SOFAArk，我们会一直与大家一起成长的。\n除了源码解析，也欢迎提交 issue 和 PR： SOFAArk :https://github.com/sofastack/sofa-ark\n欢迎领取，参与共建~\n","date":1572408000,"description":"欢迎参与 SOFAArk 源码解析系列文章共建。","dir":"activities/sofa-ark-lab/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"02869baa65a4730cea247cf1763d920c","permalink":"/activities/sofa-ark-lab/","publishdate":"2019-10-30T12:00:00+08:00","readingtime":2,"relpermalink":"/activities/sofa-ark-lab/","summary":"| SOFALab \u0026lt;SOFA:Lab/\u0026gt; 源码研究实验室，由 SOFA 团队和源码爱好者们出品，欢迎你的加入~ \u0026lt;SOFA:ArkLab/\u0026gt;是《剖析 | SOFAArk 源码》系列，会逐步详细介","tags":["SOFALab","SOFAArk","剖析 | SOFAArk 源码"],"title":"\u003cSOFA:ArkLab/\u003e","type":"activities","url":"/activities/sofa-ark-lab/","wordcount":576},{"author":"沧漠","categories":"Kubernetes","content":"本文 PPT 下载\n**导读：**Kubernetes 的出现使得广大开发同学也能运维复杂的分布式系统，它大幅降低了容器化应用部署的门槛，但运维和管理一个生产级的高可用 Kubernetes 集群仍十分困难。本文将分享蚂蚁金服是如何有效可靠地管理大规模 Kubernetes 集群的，并会详细介绍集群管理系统核心组件的设计。\nKubernetes 以其超前的设计理念和优秀的技术架构，在容器编排领域拔得头筹。越来越多的公司开始在生产环境部署实践 Kubernetes，在阿里巴巴和蚂蚁金服 Kubernetes 已被大规模用于生产环境。\n系统概览 Kubernetes 集群管理系统需要具备便捷的集群生命周期管理能力，完成集群的创建、升级和工作节点的管理。在大规模场景下，集群变更的可控性直接关系到集群的稳定性，因此管理系统可监控、可灰度、可回滚的能力是系统设计的重点之一。除此之外，超大规模集群中，节点数量已经达到 10K 量级，节点硬件故障、组件异常等问题会常态出现。面向大规模集群的管理系统在设计之初就需要充分考虑这些异常场景，并能够从这些异常场景中自恢复。\n设计模式 基于这些背景，我们设计了一个面向终态的集群管理系统。系统定时检测集群当前状态，判断是否与目标状态一致，出现不一致时，Operators 会发起一系列操作，驱动集群达到目标状态。这一设计参考控制理论中常见的负反馈闭环控制系统，系统实现闭环，可以有效抵御系统外部的干扰，在我们的场景下，干扰对应于节点软硬件故障。\n架构设计 如上图，元集群是一个高可用的 Kubernetes 集群，用于管理 N 个业务集群的 Master 节点。业务集群是一个服务生产业务的 Kubernetes 集群。SigmaBoss 是集群管理入口，为用户提供便捷的交互界面和可控的变更流程。元集群中部署的 Cluster-Operator 提供了业务集群集群创建、删除和升级能力，Cluster-Operator 面向终态设计，当业务集群 Master 节点或组件异常时，会自动隔离并进行修复，以保证业务集群 Master 节点达到稳定的终态。这种采用 Kubernetes 管理 Kubernetes 的方案，我们称作 Kube on Kube 方案，简称 KOK 方案。业务集群中部署有 Machine-Operator 和节点故障自愈组件用于管理业务集群的工作节点，提供节点新增、删除、升级和故障处理能力。在 Machine-Operator 提供的单节点终态保持的能力上，SigmaBoss 上构建了集群维度灰度变更和回滚能力。\n核心组件 集群终态保持器 基于 K8s CRD，在元集群中定义了 Cluster CRD 来描述业务集群终态，每个业务集群对应一个 Cluster 资源，创建、删除、更新 Cluster 资源对应于实现业务集群创建、删除和升级。Cluster-Operator watch Cluster 资源，驱动业务集群 Master 组件达到 Cluster 资源描述的终态。业务集群 Master 组件版本集中维护在 ClusterPackageVersion CRD 中，ClusterPackageVersion 资源记录了 Master 组件（如：api-server、controller-manager、scheduler、operators 等）的镜像、默认启动参数等信息。Cluster 资源唯一关联一个 ClusterPackageVersion，修改 Cluster CRD 中记录的 ClusterPackageVersion 版本即可完成业务集群 Master 组件发布和回滚。\n节点终态保持器 Kubernetes 集群工作节点的管理任务主要有：\n 节点系统配置、内核补丁管理； docker / kubelet 等组件安装、升级、卸载； 节点终态和可调度状态管理（如关键 DaemonSet 部署完成后才允许开启调度）； 节点故障自愈。  为实现上述管理任务，在业务集群中定义了 Machine CRD 来描述工作节点终态，每一个工作节点对应一个 Machine 资源，通过修改 Machine 资源来管理工作节点。\nMachine CRD 定义如下图所示，spec 中描述了节点需要安装的组件名和版本，status 中记录有当前这个工作节点各组件安装运行状态。除此之外，Machine CRD 还提供了插件式终态管理能力，用于与其它节点管理 Operators 协作，这部分会在后文详细介绍。\n工作节点上的组件版本管理由 MachinePackageVersion CRD 完成。MachinePackageVersion 维护了每个组件的 rpm 版本、配置和安装方法等信息。一个 Machine 资源会关联 N 个不同的 MachinePackageVersion，用来实现安装多个组件。\n在 Machine、MachinePackageVersion CRD 基础上，设计实现了节点终态控制器 Machine-Operator。Machine-Operator watch Machine 资源，解析 MachinePackageVersion，在节点上执行运维操作来驱动节点达到终态，并持续守护终态。\n节点终态管理 随着业务诉求的变化，节点管理已不再局限于安装 docker / kubelet 等组件，我们需要实现如等待日志采集 DaemonSet 部署完成才可以开启调度的需求，而且这类需求变得越来越多。如果将终态统一交由 Machine-Operator 管理，势必会增加 Machine-Operator 与其它组件的耦合性，而且系统的扩展性会受到影响。因此，我们设计了一套节点终态管理的机制，来协调 Machine-Operator 和其它节点运维 Operators。设计如下图所示：\n **全量 ReadinessGates: **记录节点可调度需要检查的 Condition 列表； **Condition ConfigMap: **各节点运维 Operators 终态状态上报 ConfigMap；  协作关系：\n 外部节点运维 Operators 检测并上报与自己相关的子终态数据至对应的 Condition ConfigMap； Machine-Operator 根据标签获取节点相关的所有子终态 Condition ConfigMap，并同步至 Machine status 的 conditions 中； Machine-Operator 根据全量 ReadinessGates 中记录的 Condition 列表，检查节点是否达到终态，未达到终态的节点不开启调度。  节点故障自愈 我们都知道物理机硬件存在一定的故障概率，随着集群节点规模的增加，集群中会常态出现故障节点，如果不及时修复上线，这部分物理机的资源将会被闲置。\n为解决这一问题，我们设计了一套故障发现、隔离、修复的闭环自愈系统。\n如下图所示，故障发现方面，采取 Agent 上报和监控系统主动探测相结合的方式，保证了故障发现的实时性和可靠性（Agent 上报实时性比较好， …","date":1572246000,"description":"本文将分享蚂蚁金服是如何有效可靠地管理大规模 Kubernetes 集群的，并会详细介绍集群管理系统核心组件的设计。","dir":"blog/ant-financial-managing-large-scale-kubernetes-clusters/","fuzzywordcount":5000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"0fbce82d736863f9039c6a8f15c6f5d5","permalink":"/blog/ant-financial-managing-large-scale-kubernetes-clusters/","publishdate":"2019-10-28T15:00:00+08:00","readingtime":10,"relpermalink":"/blog/ant-financial-managing-large-scale-kubernetes-clusters/","summary":"本文 PPT 下载 **导读：**Kubernetes 的出现使得广大开发同学也能运维复杂的分布式系统，它大幅降低了容器化应用部署的门槛，但运维和管理一","tags":["Kubernetes"],"title":"备战双 11！蚂蚁金服万级规模 K8s 集群管理系统如何设计？","type":"blog","url":"/blog/ant-financial-managing-large-scale-kubernetes-clusters/","wordcount":4989},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级云原生架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\nSOFAStack 官网: https://www.sofastack.tech SOFAStack: https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题 通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@罗健 提问：\n 请问，SOFAJRaft 跨机房支持吗？\n A：跨机房不需要特殊支持，只是网络延时大一点而已。\n 延时大了，读写性能就会降低了吧？ 像 ZooKeeper 一样。\n A：1. SOFAJRaft 支持 transfer leader，把 leader transfer 到和业务就近的机房（目前需要手动调用 cli 服务） 2. SOFAJRaft 1.3.0 会增加一个选举优先级特性，可以将指定机房节点优先级调高，尽量保证 leader 在指定机房。\n2、@梁开心 提问：\n 使用 Seata 的时候，现在是 AT 模式 如果改成 Saga 模式的话，改造会大吗？\n A：AT 模式完全是透明的，Saga 是有侵入性的，要配置状态机 json，如果服务多改造会比较大。\n Saga 模式是不是基于 AT 来加强的长事务处理呢？\n A：没有基于 AT，客户端完全是两套，Server 端是复用的。你也可以看 Saga 的单元测试，那里有很多示例：https://github.com/seata/seata/tree/develop/test/src/test/java/io/seata/saga/engine\n Saga 服务流程可以不配置吗，使用全局事务 id 串起来，这样省去配置的工作量，再加上人工配置难免会配置错误。\n A：Saga 一般有两种实现，一种是基于状态机定义，比如 apache camel saga、eventuate，一种是基于注解+拦截器实现，比如 service comb saga，后者是不需要配置状态图的。由于 Saga 事务不保证隔离性, 在极端情况下可能由于脏写无法完成回滚操作, 比如举一个极端的例子, 分布式事务内先给用户 A 充值, 然后给用户B扣减余额, 如果在给 A 用户充值成功, 在事务提交以前, A 用户把余额消费掉了, 如果事务发生回滚, 这时则没有办法进行补偿了，有些业务场景可以允许让业务最终成功, 在回滚不了的情况下可以继续重试完成后面的流程, 基于状态机引擎除可以提供“回滚”能力外, 还可以提供“向前”恢复上下文继续执行的能力, 让业务最终执行成功, 达到最终一致性的目的，所以在实际生产中基于状态机的实现应用更多。后续也会提供基于注解+拦截器实现。\n3、@温明磊 提问：\n 关于 Saga 的使用，有两个问题咨询下 1、比如有服务 A 在系统1里面，服务 B 在系统2里面。全局事务由 A 开启，流程调用 B 开启子事务，那系统2也需要维护 Saga 状态机的三个表吗，也需要在 Spring Bean 配置文件中配置一个 StateMachineEngine 吗？\n2、如果 系统1和系统2里面的服务，可以相互调用。系统12都可以开启全局事务，可以这样使用吗。那1和2 都需要维护Saga状态机的三个表，也需要在Spring Bean配置文件中配置一个StateMachineEngine。\n A：1、不需要，只在发起方记录日志。由于只在发起方记录日志同时对参与者服务没有接口参数的要求，使得Saga可以方便集成其它机构或遗留系统的服务。 2、可以这样使用，如果两个系统都开启 Saga 事务，那就要记录那三个表配置 StateMachineEngine。\n 这个 EventQueue 只是开启分布式事务的系统 来进行事件驱动，调用其它系统服务像调用本地一样。系统之间还是 RPC 调用是吧，而不是系统之前也是纯事件驱动的？  A：是的。你指的\u0026amp;quot;系统之间也是纯事件驱动的\u0026amp;quot; 是不是说 RPC 也是非阻塞的？\n 是的，也可以是异步的。\n A：那 RPC 的非阻塞需要 rpc client 支持，理论上也是可以的。rpc client 如果也是非阻塞 IO，那么所有环节都是异步了。\n 就是考虑一个业务流程， 它后续的子流程， 不管谁先运行都不会相互影响，可以异步调用。子流程是其它系统服务。Seata Saga 是不是实现了这点，其实我没看明白 ，Seata Saga 异步调用具体是不是各个节点异步了。是不是两个 ServiceTask 类型，可以同时 process ？\n A：你说的是并发节点类型，还未实现，接下来会实现。目前的事件驱动是指的节点的执行是事件驱动的，流程的顺序是同步的。上一个节点执行完成后，产生事件，触发下一个节点执行。如果要满足你刚说的需求要扩展并发节点。\n 那目前区分同步 BUS 和异步 BUS 是什么作用？\n A：同步 BUS 是线程阻塞的，等整个状态机执行完毕才返回，异步 BUS 是非线程阻塞的，调用后立即返回，状态机执行完毕后回调你的 Callback。\n IsPersist: 执行日志是否进行存储，默认是 true，有一些查询类的服务可以配置在 false，执行日志不进行存储提高性能，因为当异常恢复时可以重复执行？\n A：是的，可以配置成 false, 不过建议先保持默认，这样在查询执行日志比较全，真的要做性能调优再配，一般不会有性能问题。\n每周推荐阅读  蚂蚁金服开源背后的“有意思”工程师 | 1024快乐 蚂蚁金服云原生专家招聘 | 1024有你更快乐  SOFA 项目进展 本周发布详情如下：\n1、Occlum 是一个多任务、内存安全的库操作系统，专门针对可信执行环境（如 Intel SGX）。\n发布 Occlum v0.6.0，主要变更如下： i. 支持 release 模式运行 enclave，轻松发布基于 Occlum 的 SGX 应用； ii. 给 SEFS 增加额外的 MAC 和权限检查，保证 Occlum 的 FS 镜像的完整性； iii. 重构底层错误处理机制，使得报错对用户友好，且附带详细的调试信息； iv. 增加3个新 demo，包括 Bazel、HTTPS file server 和 Tensorflow Lite； v. 在 Docker 镜像中默认安装 Occlum，使得用户开箱即用； 详细发布报告： https://github.com/occlum/occlum/releases/tag/0.6.0\n2、发布SOFARPC v5.5.9，主要变更如下： i. 修改 …","date":1571986800,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20191025/","fuzzywordcount":2600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"7927ee3392339de5283b8c4e75f9b4e9","permalink":"/blog/sofa-weekly-20191025/","publishdate":"2019-10-25T15:00:00+08:00","readingtime":6,"relpermalink":"/blog/sofa-weekly-20191025/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级云","tags":["SOFA Weekly"],"title":"SOFA Weekly | 每周精选【10/21 - 10/25】","type":"blog","url":"/blog/sofa-weekly-20191025/","wordcount":2573},{"author":"SOFAStack","categories":"1024","content":"!important 希望我们是最早给你祝福的朋友\n去年的1024，我们回顾了第一代到第五代架构 去年的今天，我们和大家分享了 SOFAStack 背后的这群工程师。比如程立，花名鲁肃，蚂蚁金服 CTO。胡喜，蚂蚁金服副总裁、副CTO。杨冰，蚂蚁金服智能科技产品技术部总监。\n也与大家分享了从第一代到第五代架构的进化历程，详解了 SOFAStack 走的这一条跟传统金融行业不同的分布式架构之路。要基于不可靠的硬件系统实现金融级的性能和可靠性，要应对支付宝这样的超大规模互联网金融应用，有很多难题要解决。蚂蚁金服构建了一整套处理金融级交易的分布式架构与平台，在金融级的一致性要求和海量并发处理能力上达到了很好的平衡，并在快速容灾恢复、弹性伸缩能力、多地多活高可用保证能力和按需供给的精细化资源调度能力方面沉淀了丰富的实践经验。\n前往去年此刻的时光机：蚂蚁金服自研架构SOFA背后的工程师|1024快乐\n今年，SOFAStack 团队在忙什么呢？ 近几年来，“云原生架构”的相关话题讨论比较热烈，我们也相信这也将是金融 IT 架构的关键发展趋势之一。IT 架构转型绝不是一蹴而就的，积极探索和应用以“云原生”为代表的新兴技术的同时，还需考虑与传统模式和技术融合并存，沿着一条稳妥的可落地路径进行创新变革，确保架构转型的价值交付能够稳妥支撑甚至积极引领业务创新。\nService Mesh 是蚂蚁金服下一代架构的核心，这一年，我们在奔跑的火车上换轮子，将现有的微服务架构快速演进到云原生架构。RPC、消息、DB、安全、运维等每一个环节均充满挑战。\n蚂蚁金服每年双十一大促会面临非常大的流量挑战，在已有 LDC 微服务架构下已支撑起弹性扩容能力。当有多个大促分阶段进行时，如何在架构上保障资源最大程度复用降低大促成本极具挑战。期望在最小规模的资源集群下可通过灵活的架构来支撑起快速的资源腾挪来达成多个大促链路最大化利用资源的目的。通过 Service Mesh 架构的支持，基础设施层在应用外具备更强的管控能力，通过流量的调拨，JVM 内存的动态 Swap 等手段可以使用技术手段达成节省资源的目的。 今年即将到来的双十一，蚂蚁金服这套 Service Mesh 将迎来第一次大考 — 双十一实战，也或许是业界第一个如此大规模的实战，请持续关注本公众号，我们会逐步进行技术揭秘。\n今天，我们想介绍蚂蚁金服开源背后的这位“有意思”工程师：  对于蚂蚁金服研究员王益而言，2019年是个颇有纪念意义的年份。今年他整40岁。从10岁开始，写代码整30年。这30年来，他当过“不务正业”的学生，创纪录地在大一就考下系统分析员，“单枪匹马”闯荡过从国内到硅谷的多家知名互联网科技公司，和AI领域许多传奇人物都有所交集。不惑之年对于许多工程师来说，或许已是需要焦虑的年龄，但40岁的王益在蚂蚁金服每天都过得很充实：起床，自由泳一千米，然后去做他最喜欢的事——写代码和组织大家一起写代码。\n 2019年9月11日，在上海举办的Google开发者大会上，蚂蚁金服研究员王益分享了新开发的分布式深度学习系统ElasticDL。这是他来到蚂蚁金服的一年之中所做的第二个开源项目，主要用于大幅提升集群总体利用率以及深度学习团队的工作效能。之前开源的 SQLFlow系统在短短的几个月之间，已经在GitHub上获得了三千多颗星星。\n2019对于王益而言是个颇有纪念意义的年份，今年他整40岁，写代码整30年。 这听上去是一件不可思议的事——30年前，上世纪的80年代末，他在⻓沙上小学，全城都很难找出一位能教编程的老师，个人电脑更是一个陌生名词，一台以苹果2为原型、可以用BASIC语言编程的 “中华学习机”售价7000人民币，在当时几乎可以买下一套房子。\n幸运的是，王益在10岁那年得到了这样一件贵重的礼物，从这台学习机和一本BASIC语言教材开始，他开启了与代码结缘的人生。\n“我那时不是个好学生，经常受‘别人家的孩子’打击，老师和同学都觉得写代码是不务正业。”回想起30年来的经历，这位清华博士、足迹从国内到硅谷历经多家知名互联网科技公司的学霸笑谈自己“活得比较任性”，“但我就是想做与众不同的事。别人越说这样不行，我就越想用这种方式证明自己。”\n初中毕业那年的暑假，他用“中华学习机”和自己焊接的电路板，把自家的老式“威力牌”双筒洗衣机改造成了自动洗衣机。同时，他用Apple BASIC语言和6502汇编混合编程，写了人生中第一个游戏。高中三年，其他同学努力备考，他却加班加点自学了大学计算机系所有课程，随后参加计算机水平考试，先后获得了程序员、高级程序员、以及最高级别系统分析员资格。2018年，他获得Google APAC Innovation Award。从不断摸索代码世界的少年时代，到专注于AI基础架构和系统开发的求学工作生涯，这份“任性”一直伴随他走到今天。\n“我经常从零开始。选择去做什么的一大标准是‘有意思’。”\n相比于规划一条稳妥的职业发展道路，王益更愿意顺应自己强烈的好奇心，去选择最困难但最有意思的探索方向。他在中国和美国互联网公司都工作过，也分别在美国公司的中国分部和中国公司的美国分部工作过。他的足迹遍及国内BAT三家。任性的是，每次跳槽， 他都从一个人coding一个创新项目开始，吸引同事们加入，从而组建团队。虽然2011年就在腾讯作为广告系统技术总监，但是他从不在跳槽时要求带何等规模的团队。\n2014年，王益带着妻子和两个月大的女儿离开腾讯移居硅谷。“一切都归零了。工资减半。”他笑笑说。不过凭着多位学界和业界领袖的推荐，他很快就安顿下来，不到一年就开始在硅谷创业，作为Head of Research Scienets 参与创建了AI创业公司 ScaledInference。这是一家人才济济的创业公司。人工智能行业的领袖人物、加州大学伯克利分校的Michael Jordan教授是这家公司顾问。陆奇曾代表微软到访，讨论技术合作。“可惜我们不够关注业务落地，做的不够好。技术研发一定要有落地的能力。”事后，王益不无遗憾的说。\n在加入蚂蚁金服之前，王益在百度硅谷研究院工作，负责开源深度学习系统PaddlePaddle。在历经两年的艰苦开发，新一代技术Fluid开始系统地落地百度各个业务之后，他发起了他在 PaddlePaddle的最后一个子项目——一条太阳能驱动的无人驾驶船。这是一条双体船，由他和五岁女儿的两条划艇构成。船上的笔记本电脑运行基于immitation learning的人工智能系统，自动学习驾驶者的技巧。为了船体稳定，他在自家车库里焊接了连接两条划艇的金属框架。便于拆装的结构，可以装上他的皮卡，方便下水测试。\n做出加入蚂蚁金服的决定，也是出于同样的理由——“有意思”。“这里的业务很新颖，对AI 有着更加多样化的需求。”如何用AI解决金融行业的问题，是和他以往所面对的完全不同的全新挑战。 SQLFlow：分析师与AI模型间的翻译  加入蚂蚁金服不久，王益就意识到自己之前的朦胧猜想越来越清晰地被验证：和主要依靠流量与广告赚钱的传统互联网公司不同，蚂蚁金服不是纯互联网公司，它有独特的商业模式和对于工具的独到需求。\n此前的十多年中，他的大部分经历是在传统互联网行 …","date":1571883840,"description":"不管世界如何，永远永远希望开发者能感觉技术“有意思”，永远希望开发者快乐不复杂。","dir":"blog/ant-financial-happy-1024/","fuzzywordcount":5900,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"c89decd5fb9b75c59f487dc58bac0365","permalink":"/blog/ant-financial-happy-1024/","publishdate":"2019-10-24T10:24:00+08:00","readingtime":12,"relpermalink":"/blog/ant-financial-happy-1024/","summary":"!important 希望我们是最早给你祝福的朋友 去年的1024，我们回顾了第一代到第五代架构 去年的今天，我们和大家分享了 SOFAStack 背后的这群工程师。比如程立，花名鲁肃","tags":["1024"],"title":"蚂蚁金服开源背后的“有意思”工程师 | 1024快乐","type":"blog","url":"/blog/ant-financial-happy-1024/","wordcount":5810},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级云原生架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\nSOFAStack 官网: https://www.sofastack.tech\nSOFAStack: https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题 通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n@温明磊 提问：\n 最近在选型 Zeebe 还是 Seata Saga 来实现微服务编排。Zeebe 使用了基于行业标准 BPMN 2.0 的可视工作流。 但是考虑到 Seata 的开源和生态，如果 Seata 能实现流程可视就好了。\n A：未来我们会做可视化的也可以社区贡献。另外给一个调研服务编排选型的建议，遵循 bpmn 2.0 行业标准没有问题的，不过 bmpn2.0 xml 格式太复杂了，我们微服务的编排不需要那么多标签，另外微服务的编排里有很重要一块就是要保证编排的服务的事务一致性，所以需有能支持分布式事务的处理能力，这里面就会涉及服务的状态判断定义，异常处理定义，复杂服务参数的映射，这些在 bpmn 2.0 标准里是没有定义的（当然框架可以在扩展节点里自己扩展）。用 json 定义之后，你会发现其实有没有可视化开发工具没有那么重要了，只是如果有个可视化监控更好。\n 是的，json 我们都可以自己组装。只要把业务接口做成可视可配，完全可以用配置信息组装 json。这样说不知道对不对。但是像您说的，有个可视化的工具 肯定要更好点。\n A：是的，json 还有一个好处是，服务调用的参数可以直接在 json 里组织好。\nSOFARegistryLab 系列阅读  服务注册中心 Session 存储策略 | SOFARegistry 解析 服务注册中心数据分片和同步方案详解 | SOFARegistry 解析 服务注册中心 MetaServer 功能介绍和实现剖析 | SOFARegistry 解析 服务注册中心 SOFARegistry 解析 | 服务发现优化之路 海量数据下的注册中心 - SOFARegistry 架构介绍  云原生推荐阅读  云原生时代，什么是蚂蚁金服推荐的金融架构？ 当金融科技遇上云原生，蚂蚁金服是怎么做安全架构的？  SOFA 项目进展 发布 Seata v0.9.0，主要变更如下：\ni. 长事务解决方案: Saga 模式（基于状态机实现） ii. 支持自定义配置和注册中心类型 iii. 支持 spring cloud config 配置中心 iv. 修复对象锁和全局锁可能造成的死锁和优化锁的粒度 v. 修复 oracle 的批量获取问题 vi. 优化了一些基于 java5 的语法结构 vii. 抽象 undologManager 的通用方法\n详细发布报告： https://github.com/seata/seata/releases/tag/v0.9.0\n云原生活动推荐 Service Mesh Meetup 是由蚂蚁金服联合 CNCF 官方共同出品，ServiceMesher 社区主办，主题围绕服务网格、Kubernetes 及云原生，在全国各地循环举办的技术沙龙。\n本期 Meetup 邀请社区大咖，从服务网格下微服务架构设计、在 5G 时代的应用、如何使用开源的 Traefik 构建云原生边缘路由及蚂蚁金服的服务网格代理演进角度给大家带来精彩分享。\n时间：2019年10月26日（周六）13:00-17:0 0地点：成都武侯区蚂蚁C空间 报名方式：点击这里，即可锁定席位\n","date":1571382000,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20191018/","fuzzywordcount":1200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"91ccf1c351bfb03d7e18f70fad5f5224","permalink":"/blog/sofa-weekly-20191018/","publishdate":"2019-10-18T15:00:00+08:00","readingtime":3,"relpermalink":"/blog/sofa-weekly-20191018/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级云","tags":["SOFA Weekly"],"title":"SOFA Weekly | 每周精选【10/14 - 10/18】","type":"blog","url":"/blog/sofa-weekly-20191018/","wordcount":1197},{"author":"力鲲","categories":"SOFARegistry","content":" SOFAStack （Scalable Open Financial Architecture Stack） 是蚂蚁金服自主研发的金融级云原生架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。\n SOFARegistry 是蚂蚁金服开源的具有承载海量服务注册和订阅能力的、高可用的服务注册中心，在支付宝/蚂蚁金服的业务发展驱动下，近十年间已经演进至第五代。\n本文为《剖析 | SOFARegistry 框架》第五篇，本篇作者力鲲，来自蚂蚁金服。《剖析 | SOFARegistry 框架》系列由 SOFA 团队和源码爱好者们出品，项目代号：SOFA:RegistryLab/，文末包含往期系列文章。\nGitHub 地址：https://github.com/sofastack/sofa-registry\n回顾：服务注册 SOFARegistry 作为服务注册中心，面临的一个很重要的挑战就是如何解决海量的客户端连接问题，这也是本文要剖析的内容。不过作为一篇完整的文章，我们还是会先花一点时间介绍 SOFARegistry 的相关信息，以便读者了解其背景。\n服务注册中心在服务调用的场景中，扮演一个“中介”的角色，服务发布者 (Publisher) 将服务发布到服务注册中心，服务调用方 (Subscriber) 通过访问服务注册中心就能够获取到服务信息，进而实现调用。\n图1 - 服务的“中介”\n流程：订阅 / 发布 在《海量数据下的注册中心 - SOFARegistry 架构介绍》一文中，我们提到了一个典型的 “RPC 调用的服务寻址” 应用场景，服务的提供方通过如下两个步骤完成服务发布：\n 注册，将自己以 Publisher 的角色注册到 SOFARegistry； 发布，将需要发布的数据 (通常是IP 地址、端口、调用方式等) 发布到 SOFARegistry；  与此相对应的，服务的调用方通过如下步骤实现服务调用：\n 注册，将自己以 Subscriber 的角色注册到 SOFARegistry； 订阅，收到 SOFARegistry 推送的服务数据；  从上面我们可以看到，整个流程中很重要的一个步骤就是注册，不管是 Publisher 还是 Subscriber 都只能在注册成功后才能实现发布订阅的需求。因此 SOFARegistry 要解决的一个问题就是如何维护与 Client 连接而产生的 Session，尤其是当 Client 数量众多的时候。\n图2 - 海量啊海量\n设计：分层隔离 在 SOFARegistry 的应用场景中，体量庞大的数据主要有两类：Session 数据、服务信息数据。两类数据的相同之处在于其数据量都会不断扩展，而不同的是其扩展的原因并不相同：Session 是对应于 Client 的连接，其数据量是随着业务机器规模的扩展而增长，而服务信息数据量的增长是由 Publisher 的发布所决定。所以 SOFARegistry 通过分层设计，将两种数据隔离，从而使二者的扩容互不影响。\n图3 - 分层，扩容互不影响\n当然，对于分层设计的概念介绍，在《海量数据下的注册中心 - SOFARegistry 架构介绍》的 “如何支持海量客户端” 章节已经有了很完整的介绍，这里不再赘述。本文是想从代码层面来看看其设计实现的方式。\n通信 Exchange Exchange 作为 Client / Server 连接的抽象，负责节点之间的连接。在建立连接中，可以设置一系列应对不同任务的 handler (称之为 ChannelHandler)，这些 ChannelHandler 有的作为 Listener 用来处理连接事件，有的作为 Processor 用来处理各种指定的事件，比如服务信息数据变化、Subscriber 注册等事件。\n图4 - 每一层各司其职，协同实现节点通信\nSession 节点在启动的时候，利用 Exchange 设置了一系列 ChannelHandler：\n  PublisherHandler\n  SubscriberHandler\n  WatcherHandler\n  ClientNodeConnectionHandler\n  CancelAddressRequestHandler\n  SyncConfigHandler\n  其中 SubscriberHandler 和 PublisherHandler 主要是与服务发布方 (Publisher) 以及服务调用方 (Subscriber) 的行为相关，我们在下面说明。\n任务处理 由于 SubscriberHandler 在 Session 节点启动时就已经初始化并设置，所以当有 Subscriber 注册时，就由 SubscriberHandler 负责后续一系列的处理逻辑。\n图5 - Subscriber 的注册过程\n上面的流程图展示了 Subscriber 注册的处理过程，SessionSever 在处理注册请求时，除了保存 Subscriber 的会话信息，还要为新注册的 Subscriber 提供其所订阅的服务信息数据，最后通过推送的方式将数据发送 Subscriber。\n下面是上述流程在代码模块上的实现，我们依然用图的方式展示出来，大家按图索骥也便于查阅相关源码中的细节。\n图6 - 代码流转：Subscriber 注册\n可以看到，SOFARegistry 采用了 Handler - Task \u0026amp;amp; Strategy - Listener 的方式来应对服务注册中的各种场景和任务，这样的处理模型能够尽可能的让代码和架构清晰整洁。\nPublisher 的注册过程和 Subscriber 基本一致，略有不同的是 Publisher 在注册完毕之后将要发布的数据写到 DataServer 上。\n图7 - Publisher 的注册过程\n这个过程也是采用了 Handler - Task \u0026amp;amp; Strategy - Listener 的方式来处理，任务在代码内部的处理流程和订阅过程基本一致。\n图8 - 代码流转：Publisher 注册\n会话缓存 在二层架构中 (即 Client 直接连接 DataServer)，连接数是一个很难收敛的指标，因为当一个 Subscriber 订阅的服务位于不同 DataServer 上时，他就会与多个 DataServer 同时保持连接，这样“每台 DataServer 承载的连接数会随 Client 数量的增长而增长，每台 Client 极端的情况下需要与每台 DataServer 都建连，因此通过 DataServer 的扩容并不能线性的分摊 Client 连接数”。\n图9 - 两层结构中，扩容无法减少连接数\n这也是 SOFARegistry 设计三层模型的原因，通过 SessionServer 来负责与 Client 的连接，将每个 Client 的连接数收敛到 1，这样当 Client 数量增长时，只需要扩容 SessionServer 集群就可以了。 所以从设计初衷上我们就能够看出来 SessionServer 必须要满足的两个主要能力： …","date":1571223600,"description":" 本文为《剖析 | SOFARegistry 框架》第五篇，作者力鲲","dir":"blog/sofa-registry-session-storage/","fuzzywordcount":2900,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"5ae2be3be1d395dd7ccb2bddc97b346f","permalink":"/blog/sofa-registry-session-storage/","publishdate":"2019-10-16T19:00:00+08:00","readingtime":6,"relpermalink":"/blog/sofa-registry-session-storage/","summary":"SOFAStack （Scalable Open Financial Architecture Stack） 是蚂蚁金服自主研发的金融级云原生架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来","tags":["SOFARegistry","剖析 | SOFARegistry 框架","SOFALab"],"title":"服务注册中心 Session 存储策略 | SOFARegistry 解析","type":"blog","url":"/blog/sofa-registry-session-storage/","wordcount":2811},{"author":"杨延昭","categories":"云原生","content":" 蚂蚁金服在过去十五年重塑支付改变生活，为全球超过十二亿人提供服务，这些背后离不开技术的支撑。在 2019 杭州云栖大会上，蚂蚁金服将十五年来的技术沉淀，以及面向未来的金融技术创新和参会者分享。我们将其中的优秀演讲整理成文并将陆续发布在本网站，本文为其中一篇。\n 本文作者：杨延昭（杨冰），蚂蚁金服智能科技产品技术部总监\n互联网技术发展日新月异，我们正在进入云原生时代，这个过程中金融行业要如何拥抱云原生？在近两年蚂蚁金服将云原生在金融领域落地，沉淀下一些实践经验，接下来我想分享在蚂蚁的演进过程当中，我们心中的云原生是什么样的，在金融领域落地的时候遇到什么问题，以及我们是怎么解决的。\n经过多年云计算的蓬勃发展，上云已经不是太大问题，接下来的问题是怎么把云用好，用得更高效。RightScale 2019年最新数据显示，现在公有云规模占22%，只使用私有云的客户占3%，更多客户通过混合的模式去使用云，通过混合云取得数据隐私、安全与效率、弹性的平衡。\n再看全球整个 IT 行业，公有云的比例只占整个基础 IT 市场的10%，市场空间仍然很大，IT 市场中剩下很多都是传统企业客户。为什么传统行业无法很好地利用公有云，一个重要的原因是因为他们的 IT 系统经过很长时间建设，很多都有自己的机房。另外有些则业务比较稳定，对上公有云没有很强的需求。它们通常会发展混合云策略，把一些核心业务留在私有云，而把一些边缘业务或创新业务放在公有云上。\n这些特点在金融行业也非常明显，除此之外金融行业还有两个特征：\n 业务形态走向开放和互联网化：随着互联网和数字化经济的发展，金融机构需要进行数字化转型，以及业务敏捷化、服务场景化，以应对新的商业模式带来的冲击； 监管合规的诉求：金融行业的业务特点决定了必须是强隔离，强监管的，所以公有云上的资源共享模式在监管方面会有比较大的挑战。  因此，混合云战略对金融机构更为适用。这一结论也得到研究支持，根据调研机构 Nutanix 的报告，全球金融业在混合云应用方面的发展速度超过其它行业，目前部署普及率达到21%，而全球平均水平为18.5%。\n那么，什么样的混合云是适合金融机构的呢？以蚂蚁的演进历程为例。\n蚂蚁在第四代架构的时候演变成为云平台架构，而且为了应对互联网业务形态下突发性业务对资源的弹性需求，蚂蚁也在同一阶段将架构直接进化成弹性混合云架构。现在蚂蚁已经演进到第五代云原生架构。蚂蚁又是如何在云原生的架构下，把混合云变成金融级的混合云，我想会对各位有些启发。在这个发展过程中，有一条主线，是不同阶段蚂蚁对研发的标准和要求，包括：自主、成本、安全、稳定、海量、敏捷，这也是在在线金融的时代，我们对云原生架构的要求。\n从分布式到云原生 建立金融级交易支付系统  建立金融级的在线交易系统，第一步是要实现金融级分布式的架构，蚂蚁在这方面的代表技术是 SOFAStack 和 OceanBase，目前都已对外商业化，并有丰富的案例。SOFAStack 代表的是，在整个应用层或者无状态服务这个层面上，如何去做可伸缩、可扩展的一套架构。OceanBase 代表的是以数据库为代表的存储或者是有状态服务层面，如何在架构上面去进行分布式。它们拥有四个特性：\n 高可用，99.99%+的可用性保证，确保系统始终连续运行不中断； 一致性，在任何异常情况下数据最终一致，确保资金安全； 可扩展，支持应用级、数据库级、机房级、地域级的快速扩展； 高性能，存储采用读写分离架构，计算引擎全链路性能优化，准内存数据库性能。  而这四个关键的特性都是金融业务最为看重的，而且需要在应用和存储上端到端实现。 以一致性为例，在单个数据库内是可以确保数据一致性的，但在大规模应用的情况下，单个数据库总是会出现瓶颈，数据往往会像服务或者应用一样，按照类似交易、支付、账目等粒度垂直拆开，当这些数据分别存储在不同的数据库集群后，就需要在应用层来解决一致性问题了，同时为了支持海量数据，数据库集群内部也会做分别和多副本，OceanBase 就是这样一套分布式数据库，在其内部也要实现分布式事务。只有这样上下配合才能解掉所有分布式架构下的一致性问题，缺一不可。\n再比如可扩展性方面，有些系统号称做了分布式架构，实际可能只是用了微服务框架，做了应用层的服务化改造，但数据库层既没有用水平扩展的技术，也没用分布式数据库，整个系统的可扩展性就卡在数据层的短板上。\n所以，真正的分布式系统，需要实现端到端的分布式，才能实现无限可扩展和高性能，而真正的金融级分布式系统则要实现端到端的高可用和一致性。\n蚂蚁金服三地五中心异地多活架构我们认为，高可用架构最关键的目标是数据不丢，业务不停。在这个目标的基础上，我们设计并实施了三地五中心的异地多活架构。它的核心优势包括城市级容灾，低成本交易，无限可扩展，以及 RPO=0，PTO\u0026amp;lt;30s. 大家知道我们在去年云栖大会上做了一次剪网线的demo，它演示了整个架构层面上怎么样做到跨城市多活和灾难情况下的恢复快速恢复能力。同时在高可用达标的情况下，我们也做了很多风险相关的事情，总结起来就是在高可用的基础上还要做到资金的安全、变更的免疫和故障的快速恢复。\n解决了高可用的问题，其实金融级最被高频提到的话题就是安全，在云原生时代，我们要解决的是全链路、端到端的安全风险。具体分为三个层面：\n 云原生网络安全，包括策略化高效流量控制，全链路加密，流量劫持与分析； 云原生基础设施安全，包括安全容器，不共享内核，以及安全沙箱； 云原生业务安全，包括 SOFAEnclave 机密计算中间件，以及内存安全的、多任务 Enclave LibOS Occlum。   这个部分我的同事在《金融服务的云原生安全架构》演讲中会详细介绍。小结一下，所谓金融级的能力，最主要是要实现端到端的金融级的高可用，同时实现端到端的安全。接下来我想分享的是，在云原生这个阶段往前走遇到了哪些问题。\n从单元化到弹性架构 应对互联网爆炸式的流量脉冲  从单元化到云原生下的弹性架构\n首先解释下什么是单元化，大家可能比较容易理解数据库层的分库分表或者说 Sharding，能够通过分片的方式解决集中存储计算性能问题，单元化的核心思想是把数据的分片提前到了入口请求的分片，在机房的网络接入层将用户请求根据某个纬度（比如用户 ID）进行 Sharding，这就好比把每个机房就当做了一个巨大无比的有状态的数据库分片，当你是一个 ID 尾号为007或者008用户的时候，当请求通过手机端或者网页域名发送到机房，接入层就已经识别出应该将你路由到华东地区还是在华南地区。当你进入到某个地区的机房时，大部分请求处理工作可以在机房内部完成。偶尔会有一些业务可能会发生跨机房的服务调用，比如说数据在 A 机房的用户给数据在 B 机房的用户转账。这个时候就需要在这个机房上去做有状态的设计。\n我们走向云原生时代的时候，在大的架构上面用 Kubernetes 为基础来设计，在单元化架构下，我们选择在每个单元里部署一个 Kubernetes 集群，将支持多 K8s 集群管理和管控指令下发的 Federated APIServer 做逻辑上的全局部署，其中管控元数据是存储在一个 ETCD 集群的，以保持全局数据一致， …","date":1571209200,"description":"本文将分享在蚂蚁金服的演进过程当中，我们心中的云原生是什么样的，在金融领域落地的时候遇到什么问题，以及我们是怎么解决的。","dir":"blog/ant-financial-native-cloud-financial-architecture/","fuzzywordcount":5400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"b0fce431d72c523e27e31f1fe831fdee","permalink":"/blog/ant-financial-native-cloud-financial-architecture/","publishdate":"2019-10-16T15:00:00+08:00","readingtime":11,"relpermalink":"/blog/ant-financial-native-cloud-financial-architecture/","summary":"蚂蚁金服在过去十五年重塑支付改变生活，为全球超过十二亿人提供服务，这些背后离不开技术的支撑。在 2019 杭州云栖大会上，蚂蚁金服将十五年来的技术沉淀","tags":["云原生"],"title":"云原生时代，什么是蚂蚁金服推荐的金融架构？","type":"blog","url":"/blog/ant-financial-native-cloud-financial-architecture/","wordcount":5366},{"author":"何征宇","categories":"云原生","content":" 蚂蚁金服在过去十五年重塑支付改变生活，为全球超过十二亿人提供服务，这些背后离不开技术的支撑。在 2019 杭州云栖大会上，蚂蚁金服将十五年来的技术沉淀，以及面向未来的金融技术创新和参会者分享。我们将其中的优秀演讲整理成文并将陆续发布在“ 金融级分布式架构”公众号上，本文为其中一篇。\n 本文作者：何征宇，gVisor 创始人，蚂蚁金服研究员\n在云原生发展趋势之下，金融行业想要应用云原生技术，安全问题是一个非常大的拦路虎，而云原生社区对安全问题的重视程度远远不够。蚂蚁金服在落地云原生的时候，解决安全问题是重中之重，经过探索与实践，我们沉淀出了一套从底层硬件到软件、从系统到应用层的全链路金融级云原生安全架构。\n金融行业最重要的就是信任，我们认为，安全所带来的信任，是一种无形的产品，支撑着所有金融业务。\n顺应互联网时代发展，金融行业与机构也发生了很多的变化，包括 App、小程序等更多的访问渠道，更快的业务变化，更多的第三方供应商。但是，不管怎么变化，金融行业有一点始终不变，那就是 Zero Fault，对错误的零容忍，也就是对稳定性和安全性的极高要求。\n这里，我还想澄清大家对金融行业的一个错误看法，就是，大家都说金融机构有很多遗留系统，很多技术是十几年前的，就认为金融机构的技术是落后的。但其实，金融行业一直是科技含量非常高的。前段时间有一部电影上映，叫《蜂鸟计划》，根据真实事件改编，讲一帮做高频交易的人，为了降低从堪萨斯到纽约交易所的时间，建造了一条上千英里直通两地的光纤，想尽办法去争取那最后一毫秒。所以，金融行业并不只有平庸保守的科技，它同样也在追逐最前沿最先进的技术，我们的使命就是要用科技来进一步武装金融行业，为金融科技注入更多的活力。\n云原生架构其实代表一种新的生产力，金融行业肯定是需要云原生的，它为我们带来了节约成本和敏捷开发的能力，但是在它前面还需要加一个定语，就是安全的云原生架构，它里面不仅仅包含之前的相对简单的安全方案，而是一个从端到端的全链路可信的安全解决方案。包括明晰代码所有权，做到可信启动，对镜像的制作和发布收口，配合账号体系，明晰应用的所有权和访问权限；以及安全可独立部署的精细化隔离方案，将安全策略和实施集成在基础架构中，对软件开发和测试透明。\n这里我们着重分享蚂蚁金服正在实践的几项云原生安全技术，包括云原生网络安全 Service Mesh，安全容器，以及机密计算。\n云原生网络安全：SOFAMesh  当前，云原生里除了容器之外第二大技术其实就是 Service Mesh，从蚂蚁的实践来看，其实它对金融安全有非常高的帮助。它至少可以做到三点：\n 策略化高效流量控制，可以帮助运维迅速适应业务快速变化； 全链路加密，保护端到端数据安全； 流量劫持与分析，当发现异常流量与容器时，进行流量阻断。  并且，这些工作对业务是透明的，不需要给业务开发增加负担，同时我们还可以对流量进行实时的语义分析等等，做比传统的防火墙更多的事情。\n蚂蚁金服在对 Service Mesh 的探索中，推出了自己用 Golang 打造的 SOFAMesh，并且已经对外开源，希望和社区一起努力，让 Service Mesh 的理念和技术更加普及。\nSOFAMesh 是基于 Istio 改进和扩展而来的 Service Mesh 大规模落地实践方案。在继承 Istio 强大功能和丰富特性的基础上，为满足大规模部署下的性能要求以及应对落地实践中的实际情况，所做的改进包括采用 Golang 编写的 SOFAMosn 取代 Envoy，极大降低了 Mesh 本身的开发难度，并做了一些创新性工作，例如合并Mixer到数据平面以解决性能瓶颈，增强 Pilot 以实现更灵活的服务发现机制，增加对 SOFARPC、Dubbo 的支持，等等。\n更多详情可查看 SOFAMesh 的 GitHub 主页：https://github.com/sofastack/sofa-mesh\n蚂蚁金服率先在生产环境中大规模落地 SOFAMesh，超过 10W+ 容器做到了 Mesh 化，平稳支撑了 618 大促，给我们带来了多协议支持、UDPA、平滑升级、安全等多方面的好处，并且对性能仅有轻微的影响，单跳 CPU 增加 5% 损耗，RT增加不到 0.2ms，甚至部分业务经过 Mesh 化改造将业务链路下沉，RT 反而下降 7%。\n安全容器：Kata Containers  传统容器架构\n提云原生大家肯定都会提容器，传统容器从虚拟机到容器，其实是牺牲了隔离性的，从上图可以很清楚的看到，当我们的应用在容器里，其实共享着同一个 CPU、内存、网络和存储，只是从外面看起来是不同的。这会导致安全上的问题，就是不同的容器之间不存在真正的隔离，一旦一个容器发生安全问题，很可能影响到其它容器，甚至入侵整个系统。蚂蚁金服在这方面做的工作就是安全容器，具体就是 Kata Containers。\n安全容器架构\nKata Containers 安全容器是 OpenStack 基金会的顶级开放基础设施项目，由蚂蚁金服和 Intel 共同主导开发。在安全容器里，每个 Pod 运行在独立的沙箱中，彼此不共享内核，提供强安全保障。这里给大家分享一下 Kata Containers 的近期进展，针对大家最关注的性能问题有了非常大的提升：\n 引入 shimv2 每 Pod 辅助进程数量从 2N+2 减少到 1 个； 引入 virtiofs，提升文件系统性能约 70% 到 90%； 引入 Firecracker， VMM 内存开销从 60MB 降到约 15MB； 改用 rust 实现 agent，占用内存从 11MB 下降到约 1MB。  我们也会和社区一起继续共建 Kata Containers，让安全容器成为云原生的标配。\n安全容器可以有效的保护主机，但是，金融业务本身仍然需要更强的隔离保护，蚂蚁金服引入了机密计算，并根据实际场景研发了大规模落地解决方案 SOFAEnclave。\n机密计算中间件：SOFAEnclave 所谓机密计算，也就是基于例如 Inte SGX，ARM Trustzone 等可信执行环境（Trusted Execution Environment, TEE），也称为 Enclave ，访问计算机内存时隔离用户数据，以避免将数据暴露给其他应用程序、操作系统或其他云服务器租户的解决方案。\nEnclave架构\nEnclave 是运行时的双向保护，比如说你的金融业务跑在 Enclave 上的时候，操作系统都看不到 Enclave 里的内存，同时会进行完整性检查，保证访问 Enclave 的代码不被替换。\n但是 Enclave 目前存在一些问题，阻碍了它在实际生产环境中的应用。总结这些问题包括：\n第一，需要改写应用，因为可信执行环境里面没有内核和基础库，所以没法把应用直接在 Enclave 中执行；第二，需要分割应用，需要把业务程序划分为 Enclave 内和 Enclave 外的部分；第三，未集群化，与客户端场景不同，Enclave 中的应用如何 failover，容灾也是阻止其在数据中心中大规模使用的一个原因。 …","date":1571036400,"description":"本文着重分享蚂蚁金服正在实践的几项云原生安全技术，包括云原生网络安全 Service Mesh，安全容器，以及机密计算。","dir":"blog/ant-financial-native-cloud-security-architecture/","fuzzywordcount":3500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"d65835b57ec0e3e24af2c65db5f41824","permalink":"/blog/ant-financial-native-cloud-security-architecture/","publishdate":"2019-10-14T15:00:00+08:00","readingtime":7,"relpermalink":"/blog/ant-financial-native-cloud-security-architecture/","summary":"蚂蚁金服在过去十五年重塑支付改变生活，为全球超过十二亿人提供服务，这些背后离不开技术的支撑。在 2019 杭州云栖大会上，蚂蚁金服将十五年来的技术沉淀","tags":["云原生"],"title":"当金融科技遇上云原生，蚂蚁金服是怎么做安全架构的？","type":"blog","url":"/blog/ant-financial-native-cloud-security-architecture/","wordcount":3402},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\nSOFAStack 官网: https://www.sofastack.tech\nSOFAStack: https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题 通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n@陈文龙 提问：\n 请问一下，使用 Seata 时，undo_log 表的 rollback_info 字典的内容为｛｝（相当于空），事务回滚后记录又没被清除，而服务的日志打出的是成功回滚，log_status 是 1，这是什么原因呢？\n A：1 是防御性的，是收到 globalrollback 回滚请求，但是不确定某个事务分支的本地事务是否已经执行完成了，这时事先插入一条 branchid 相同的数据，插入的假数据成功了，本地事务继续执行就会报主键冲突自动回滚。假如插入不成功说明表里有数据这个本地事务已经执行完成了，那么取出这条 undolog 数据做反向回滚操作。\n相关阅读：分布式事务 Seata Saga 模式首秀以及三种模式详解 | Meetup#3 回顾\nSOFARegistryLab 系列阅读  服务注册中心数据分片和同步方案详解 | SOFARegistry 解析 服务注册中心 MetaServer 功能介绍和实现剖析 | SOFARegistry 解析 服务注册中心 SOFARegistry 解析 | 服务发现优化之路 海量数据下的注册中心 - SOFARegistry 架构介绍  SOFA 活动推荐 2019中国开源年会 (COSCon\u0026#39;19) 正式启动啦~\n时间： 2019-11-02 09:00 ~ 11-03 17:00\n地址： 上海普陀区中山北路3663号华东师范大学（中北校区）\n本次大会的主题是“开源无疆、携手出航”（Let’s Cross the Boundaries Together!），这也代表主办方对于中国开源，走向世界，走向辉煌的殷切期望。\nSOFAStack 开源社区也受到主办方的邀请参加此次开源年会。\n更多重磅议题与开源嘉宾，点击“这里”，即可了解。\n","date":1570777200,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20191011/","fuzzywordcount":800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"98ed37338b0cd1036114b205bcb980c2","permalink":"/blog/sofa-weekly-20191011/","publishdate":"2019-10-11T15:00:00+08:00","readingtime":2,"relpermalink":"/blog/sofa-weekly-20191011/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | 每周精选【10/7 - 10/11】","type":"blog","url":"/blog/sofa-weekly-20191011/","wordcount":776},{"author":"明不二","categories":"SOFARegistry","content":" SOFAStack （Scalable Open Financial Architecture Stack） 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。\n SOFARegistry 是蚂蚁金服开源的具有承载海量服务注册和订阅能力的、高可用的服务注册中心，在支付宝/蚂蚁金服的业务发展驱动下，近十年间已经演进至第五代。\n本文为《剖析 | SOFARegistry 框架》第四篇，本篇作者明不二。《剖析 | SOFARegistry 框架》系列由 SOFA 团队和源码爱好者们出品，项目代号：SOFA:RegistryLab/，文末包含往期系列文章。\nGitHub 地址：https://github.com/sofastack/sofa-registry\n概述 在前面的章节中我们已经提到，SOFARegistry 与其他服务发现领域的产品相比，最大的不同点在于支持海量数据。本章即将讲述 SOFARegistry 在支撑海量数据上的一些特性。\n本文将从如下几个方面进行讲解：\n DataServer 总体架构：对 SOFARegistry 中支持海量数据的总体架构做一个简述，讲解数据分片和同步方案中所涉及到的关键技术点； DataServer 启动：讲解 DataServer 启动的服务，从而为接下来更直观地理解数据分片、数据同步的触发时机以及触发方式等做一个铺垫； 数据分片：讲解 SOFARegistry 中采用的一致性 Hash 算法进行数据分片的缘由以及具体实现方法； 数据同步方案：讲解 SOFARegistry 采用的数据同步方案；  DataServer 总体架构 在大部分的服务注册中心系统中，每台服务器都存储着全量的服务注册数据，服务器之间通过一致性协议（paxos、Raft 等）实现数据的复制，或者采用只保障最终一致性的算法，来实现异步数据复制。这样的设计对于一般业务规模的系统来说没有问题，而当应用于有着海量服务的庞大的业务系统来说，就会遇到性能瓶颈。\n为解决这一问题，SOFARegistry 采用了数据分片的方法。全量服务注册数据不再保存在单机里，而是分布于每个节点中，每台服务器保存一定量的服务注册数据，同时进行多副本备份，从理论上实现了服务无限扩容，且实现了高可用，最终达到支撑海量数据的目的。\n在各种数据分片算法中，SOFARegistry 采用了业界主流的一致性 Hash 算法做数据分片，当节点动态扩缩容时，数据仍能均匀分布，维持数据的平衡。\n在数据同步时，没有采用与 Dynamo、Casandra、Tair、Codis、Redis cluster 等项目中类似的预分片机制，而是在 DataServer 内存里以 dataInfoId 为粒度进行操作日志记录，这种实现方式在某种程度上也实现了“预分片”，从而保障了数据同步的有效性。\n图 1 SOFARegistry 总体架构图\nDataServer 启动 启动入口 DataServer 模块的各个 bean 在 JavaConfig 中统一配置，JavaConfig 类为 DataServerBeanConfiguration， 启动入口类为 DataServerInitializer，该类不由 JavaConfig 管理配置，而是继承了 SmartLifecycle 接口，在启动时由 Spring 框架调用其 start 方法。\n该方法中调用了 DataServerBootstrap#start 方法（图 2），用于启动一系列的初始化服务。\n从代码中可以看出，DataServer 服务在启动时，会启动 DataServer、DataSyncServer、HttpServer 三个 bolt 服务。在启动这些 Server 之时，DataServer 注册了一系列 Handler 来处理各类消息。\n图2 DataServerBootstrap 中的 start 方法\n这几个 Server 的作用如下：\n DataServer：数据服务，获取数据的推送，服务上下线通知等； DataSyncServer：数据同步服务； HttpServer：提供一系列 REST 接口，用于 dashboard 管理、数据查询等；  各 Handler 具体作用如图 3 所示：\n图 3 各 Handler 作用\n同时启动了 RaftClient 用于保障 DataServer 节点之间的分布式一致性，启动了各项启动任务，具体内容如图 4 所示：\n图 4 DataServer 各项启动任务\n各个服务的启动监听端口如图 5 所示：\n图5 监听端口\n其他初始化 Bean 除上述的启动服务之外，还有一些 bean 在模块启动时被初始化, 系统初始化时的 bean 都在 DataServerBeanConfiguration 里面通过 JavaConfig 来注册，主要以如下几个配置类体现（配置类会有变更，具体内容可以参照源码实现）：\n  DataServerBootstrapConfigConfiguration：该配置类主要作用是提供一些 DataServer 服务启动时基本的 Bean，比如 DataServerConfig 基础配置 Bean、DataNodeStatus 节点状态 Bean、DatumCache 缓存 Bean 等；\n  LogTaskConfigConfiguration：该配置类主要用于提供一些日志处理相关的 Bean；\n  SessionRemotingConfiguration：该配置类主要作用是提供一些与 SessionServer 相互通信的 Bean，以及连接过程中的一些请求处理 Bean。比如 BoltExchange、JerseyExchange 等用于启动服务的 Bean，还有节点上下线、数据发布等的 Bean，为关键配置类；\n  DataServerNotifyBeanConfiguration：该配置类中配置的 Bean 主要用于进行事件通知，如用于处理数据变更的 DataChangeHandler 等；\n  DataServerSyncBeanConfiguration：该配置类中配置的 Bean 主要用于数据同步操作；\n  DataServerEventBeanConfiguration：该配置类中配置的 Bean 主要用于处理与数据节点相关的事件，如事件中心 EventCenter、数据变化事件中心 DataChangeEventCenter 等；\n  DataServerRemotingBeanConfiguration：该配置类中配置的 Bean 主要用于 DataServer 的连接管理；\n  ResourceConfiguration：该配置类中配置的 Bean 主要用于提供一些 Rest 接口资源；\n  AfterWorkingProcessConfiguration：该配置类中配置一些后处理 Handler Bean，用于处理一些业务逻辑结束后的后处理动作；\n  ExecutorConfiguration：该配置类主要配置一 …","date":1570690800,"description":" 本文为《剖析 |  SOFARegistry 框架》第四篇，作者明不二","dir":"blog/sofa-registry-data-fragmentation-synchronization-scheme/","fuzzywordcount":5800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"e4e0cf21756799897553099d37f73100","permalink":"/blog/sofa-registry-data-fragmentation-synchronization-scheme/","publishdate":"2019-10-10T15:00:00+08:00","readingtime":12,"relpermalink":"/blog/sofa-registry-data-fragmentation-synchronization-scheme/","summary":"SOFAStack （Scalable Open Financial Architecture Stack） 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来","tags":["SOFARegistry","剖析 | SOFARegistry 框架","SOFALab"],"title":"服务注册中心数据分片和同步方案详解 | SOFARegistry 解析","type":"blog","url":"/blog/sofa-registry-data-fragmentation-synchronization-scheme/","wordcount":5784},{"author":"闫守孟等","categories":"SOFAEnclave","content":" 近日，Linux 基金会宣布全球多家巨头企业成立机密计算联盟（Confidential Computing Consortium），在对于数据安全和隐私担忧的不断增长下，基于可信执行环境技术的机密计算作为一种可行的解决方案，成为互联网巨头关注的焦点。 蚂蚁金服很早就关注此类技术，并基于机密计算打造了蚂蚁金服新一代可信编程中间件 SOFAEnclave，为金融业务保驾护航。 机密计算是蚂蚁安全计算的一环，也是金融级云原生的一块重要版图，蚂蚁金服表示：相信未来机密计算将和 HTTPS 一样，成为云计算的标配。\n 作者 | 闫守孟、肖俊贤、田洪亮 引言 互联网金融本质上是对大量敏感数据的处理以及由此沉淀的关键业务智能。近年来涌现出来的新业态更是将数据处理的范畴从单方数据扩展到了涉及合作方的多方数据。\n另一方面，从 GDPR 到 HIPAA，数据隐私监管保护的范围愈加扩大，力度日益增强。可见，对金融数据和关键业务智能的安全保护，不仅是互联网金融业务的基础，也是其创新发展的依托，更是攸关合规的关键因素。\n近年来迅速发展的机密计算技术是一种创新的数据隔离和加密处理技术，其重要特点是，TCB(trusted computing base 可信计算基) 中仅包含应用自身和基础硬件，即使 OS kernel、Hypervisor、甚至 BIOS 等特权软件都已经遭到破坏甚至本来就是恶意的，敏感数据和代码依然能安全无虞。\n蚂蚁金服在自身的实践过程中，基于机密计算底层技术发展出金融级的机密计算中间件，确保金融应用数据和代码的机密性和完整性，为关键业务提供易用、安全、集群化的计算环境。\n本文从机密计算的技术背景、关键问题、蚂蚁的技术突破、以及典型应用场景等方面展开。\n机密计算的技术背景 随着云计算的快速发展，越来越多的关键性服务和高价值数据被迁移到了云端。云安全也因此成为学术界和工业界关注的一个焦点。\n近年来，云安全领域最重要的一项技术进展名为机密计算（Confidential Computing）。机密计算填补了当前云安全的一项空白——使用中数据（Data-in-use）的加密。过去通行的做法是对数据在存储中（比如硬盘）和传输中（比如网络）加密，而在使用中（比如内存）解密，以便处理。而机密计算可以保护使用中数据的机密性和完整性。\n目前，多家云计算巨头都在不约而同地推广这项技术：微软已于 2017 年 7 月宣布开始接受 Azure 机密计算的早期试用申请；IBM 于 2017 年 12 月宣布 IBM 云数据保护（Cloud Data Guard）的预览版；谷歌也于 2018 年 5 月开源了名为 Asylo 的机密计算框架。\n那么，机密计算究竟是如何实现的呢？\n实际上，上述所有云计算巨头在实现机密计算时都离不开一种称为“可信执行环境（TEE）”的技术。\n顾名思义，TEE 提供一种与不可信环境隔离的安全计算环境，正是这种隔离和可信验证机制使得机密计算成为可能。\nTEE 一般是直接基于硬件实现的，比如 Intel SGX，AMD SEV，ARM TrustZone，以及 RISC-V Keystone 等；基于虚拟化技术也可以构造 TEE，比如微软的 VSM，Intel 的 Trusty for iKGT \u0026amp;amp; ACRN，但尚不能匹敌硬件 TEE 的安全性。\n其中，Intel 软件防护拓展（Software Guard Extensions，简称 SGX）是目前商用 CPU 中最为先进的 TEE 实现，它提供了一套新的指令集使得用户可以定义称为 Enclave 的安全内存区域。CPU 保证 Enclave 与外界隔离，从而保护其中的代码和数据的机密性、完整性和可验证性。不同于之前的 TEE 实现，比如 ARM TrustZone，SGX 每个 APP 都可以有自己独立的 TEE，甚至可以创建多个 TEE，而 TrustZone 是整个系统有一个 TEE；这里也省去了向设备厂商申请将 TA 装入 TEE 的过程。由于 SGX 的先进性，目前云端机密计算领域甚至已公认用 Enclave 这个词来指代 TEE。\n典型 TEE 安全特性和使用流程 [1]\n典型的 Enclave 达到的安全目标可以用 CIA 概括，即机密性（Confidentiality）、完整性（Integrity）和真实性（Authenticity）。在实现上具有以下基本要求：\n Enclave 内存保护  Enclave 内存只有 Enclave 本身的代码可以访问。CPU 通过内存隔离和加密来防止对安全内存的软件攻击和硬件嗅探。SGX 更通过内存控制器的 integrity tree 防止了对 Enclave 内存的物理篡改。\nEnclave 的可信验证  CPU 支持对 Enclave 中数据和代码的测量，以及对 Enclave 合法性的本地或远程验证。有了测量和验证，本地的 Enclave 之间、客户端与远程 Enclave 之间，就可以认证身份，进而建立安全的通信信道。\n如何开发受 Enclave 保护的应用程序呢？\n以 SGX 为例，其中一种方法是利用 Intel SGX SDK。如下图所示，基于 SGX SDK 的应用程序分为两部分：Enclave 外的不可信组件（左边黄色部分）和 Enclave 内的可信组件（右边绿色部分）。两边可以通过跨 Enclave 的函数调用通信：不可信组件可以通过 ECall 调用可信组件中定义的函数；反之，可信组件也可以通过 OCall 调用不可信组件中定义的函数。\nEnclave 编程模型 [2]\n机密计算面临的关键问题 Enclave 给我们带来了前文所谓 CIA 的安全保障，但是目前面临较大的易用性问题。主要体现在几个方面。\n第一，需要将原有应用分割成两部分，一部分是 enclave 外的 untrusted 部分，一部分在 enclave 里面作为 trusted 部分；\n第二，需要精心设计两部分之间的接口，规划好什么时候进入 Enclave，什么时候退出 Enclave——这存在一定技术门槛，而且比较繁琐容易出错；\n第三，即使我们做了完美的分割， Enclave 里面的环境相对于我们熟悉的通常的 Linux 运行环境来说是非常受限的。例如，enclave 里面不能进行系统调用，libc、pthread 不完整，没有 openmp，多进程支持欠缺等等。\n可见，把应用移植到 Enclave 里面是极具挑战的，在某些时候甚至是不可能做到的。而且，由于开发过程中必须考虑业务无关的繁杂琐细的方面，即使最终能完成应用开发移植目标，也会导致低下的开发效率，极高的开发成本，这对于快节奏的互联网业务来说是难以接受的。\n机密计算走向工程实用面临的另一较大问题是，如何将机密计算从单节点向集群扩展。由于缺乏标准的做法，或者没有一个 best practice 作为参考，很多时候各个业务不得不各自从头造轮子，搭建跟业务逻辑过度耦合的 Enclave 集群基础设施。从而导致低下的开发效率和重复的资源投入。\n另一方面，互联网业务日趋云原生化， …","date":1570258800,"description":"基于机密计算打造的新一代可信编程中间件。","dir":"blog/sofa-enclave-confidential-computing/","fuzzywordcount":6300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"f994d83c7c4b263b08e4d2fd22a461b4","permalink":"/blog/sofa-enclave-confidential-computing/","publishdate":"2019-10-05T15:00:00+08:00","readingtime":13,"relpermalink":"/blog/sofa-enclave-confidential-computing/","summary":"近日，Linux 基金会宣布全球多家巨头企业成立机密计算联盟（Confidential Computing Consortium），在对于数据安全和隐私担忧的不断","tags":["SOFAEnclave"],"title":"SOFAEnclave：蚂蚁金服新一代可信编程环境，让机密计算为金融业务保驾护航102年","type":"blog","url":"/blog/sofa-enclave-confidential-computing/","wordcount":6265},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\nSOFALab 系列文章 十一特刊带来 SOFALab 系列源码解析文章集合~\nSOFA:RPCLab/ 系列文章  【剖析 | SOFARPC 框架】系列之总体设计与扩展机制 【剖析 | SOFARPC 框架】系列之链路追踪剖析 【剖析 | SOFARPC 框架】系列之连接管理与心跳剖析 【剖析 | SOFARPC 框架】系列之 SOFARPC 同步异步实现剖析 【剖析 | SOFARPC 框架】系列之 SOFARPC 线程模型剖析 【剖析 | SOFARPC 框架】系列之 SOFARPC 单机故障剔除剖析 【剖析 | SOFARPC 框架】系列之 SOFARPC 泛化调用实现剖析 【剖析 | SOFARPC 框架】系列之 SOFARPC 数据透传剖析 【剖析 | SOFARPC 框架】系列之 SOFARPC 优雅关闭剖析 【剖析 | SOFARPC 框架】系列之 SOFARPC 路由实现剖析 【剖析 | SOFARPC 框架】系列之 SOFARPC 注解支持剖析 【剖析 | SOFARPC 框架】系列之 SOFARPC 跨语言支持剖析 【剖析 | SOFARPC 框架】系列之 SOFARPC 序列化比较  SOFA:BoltLab/ 系列文章  蚂蚁金服通信框架SOFABolt解析 | 编解码机制 蚂蚁金服通信框架SOFABolt解析 | 序列化机制(Serializer) 蚂蚁金服通信框架SOFABolt解析 | 协议框架解析 蚂蚁金服通信框架SOFABolt解析 | 连接管理剖析 蚂蚁金服通信框架SOFABolt解析 | 超时控制机制及心跳机制  SOFA:TracerLab/ 系列文章  蚂蚁金服分布式链路跟踪组件 SOFATracer 总览 | 剖析 蚂蚁金服分布式链路跟踪组件 SOFATracer 数据上报机制和源码分析 | 剖析 蚂蚁金服分布式链路跟踪组件链路透传原理与SLF4J MDC的扩展能力分析 | 剖析 蚂蚁金服分布式链路跟踪组件采样策略和源码 | 剖析 蚂蚁金服分布式链路跟踪组件埋点机制 | 剖析  SOFA:JRaftLab/ 系列文章  SOFAJRaft Snapshot 原理剖析 | SOFAJRaft 实现原理 SOFAJRaft-RheaKV 分布式锁实现剖析　| SOFAJRaft 实现原理 SOFAJRaft 日志复制 - pipeline 实现剖析 | SOFAJRaft 实现原理 SOFAJRaft-RheaKV MULTI-RAFT-GROUP 实现分析 | SOFAJRaft 实现原理 SOFAJRaft 选举机制剖析 | SOFAJRaft 实现原理 SOFAJRaft 线性一致读实现剖析 | SOFAJRaft 实现原理 SOFAJRaft-RheaKV 是如何使用 Raft 的 | SOFAJRaft 实现原理 生产级 Raft 算法库 SOFAJRaft 存储模块剖析 | SOFAJRaft 实现原理  SOFA 项目进展 本周发布详情如下：\n1、发布 SOFARPC v5.5.8，主要变更如下：\n 优化 log4j2 日志异步化 修复故障剔除模块的事件接收问题 修复 tracelog 日志 local 地址打印不正确的问题 优化泛化调用的方法名显示 修复特殊场景下的泛化调用超时设置  详细发布报告：https://github.com/sofastack/sofa-rpc/releases/tag/v5.5.8\n","date":1570172400,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20191004/","fuzzywordcount":1100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"81a2a8115038fb193b50618c4d845bf4","permalink":"/blog/sofa-weekly-20191004/","publishdate":"2019-10-04T15:00:00+08:00","readingtime":3,"relpermalink":"/blog/sofa-weekly-20191004/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | 每周精选【9/30 - 10/4】","type":"blog","url":"/blog/sofa-weekly-20191004/","wordcount":1056},{"author":"SQLFlow","categories":"SQLFlow","content":"2018 年 1 月，Oracle 的官方博客上发表了一篇文章，标题是“It\u0026amp;rsquo;s Pervasive：AI Is Everywhere”。作为全球最著名的商业数据库系统提供商，Oracle 在这篇文章里历数了 AI 在企业信息系统中的发展空间。在面向最终用户的互联网行业，巨头们招募 AI 专家，用 Python 和 C++ 打造服务大众的特定 AI 能力——搜索、推荐、以及精准定向的互联网广告系统。在企业业务中，使用 SQL 的分析师是大多数。\n滴滴首席数据科学家谢梁（左）与蚂蚁金服研究员王益开启共建SQLFlow之旅\n2019 年 7 月，滴滴的数据科学（Data Science）团队的几名数据科学家在北京新澄海大厦见到了来自蚂蚁金服的几位工程师。在那之前两个月，蚂蚁金服从事 AI 基础架构研发的王益团队开源了一款机器学习工具 SQLFLow，将 SQL 程序翻译成 Python 程序，调用数据库和 AI 引擎，实现端到端的 AI。滴滴首席数据科学家谢梁敏锐地关注到这个项目。这次拜访双方一拍即合，开启了共建 SQLFlow 之旅。\n用 SQLFlow 构建 AI 的训练和预测任务\n数据分析师的普适 AI  数据驱动决策是很多公司的追求，在国内很多业务人员都了解 SQL，但是对于 AI、深度学习模型的训练，需要长时间系统性的学习，有一定的门槛。SQLFLow 的出现让包括数据分析师在内的业务人员通过写简单的 SQL 去调用 AI 模型成为了可能。滴滴数据科学团队长期地直面一线业务，了解业务需求，也沉淀了很多常用模型。本次合作双方希望优势互补共同助力 AI 的落地，据悉合作分为三步，第一步滴滴为蚂蚁金服贡献更多针对于业务产品的理解和洞见；第二步滴滴将公司自身业务场景最有价值用的最好的模型贡献到 SQLFLow；第三步滴滴加入到建设到整个 SQLFLow 开源社区的建设，双方要在模型、社区、文化等全方位共建。\nSQLFlow的技术架构\n一个多月的时间，滴滴已经为 SQLFLow 贡献了基于 DNN 分类预测模型、可解释模型和无监督聚类模型三个高价值模型。这三个模型覆盖的场景非常广泛，对于滴滴内部来说，包括网约车、单车、金融等在内的诸多业务场景都可应用起来，于外部而言，“因为整个模型它是一种基础能力，其实它不会局限于某一个公司或某一个行业，它具有普适性。”滴滴高级数据科学家高梓尧强调。\nSQLFlow 和滴滴数据的整合逻辑\n比如分类预测模型，适用于做产品增长的场景，对特定人群进行定向推荐。而无监督聚类模型，也就是模式识别，在滴滴的产品的应用非常广，比如会根据司机出车时长分布，去整合归纳司机出车的偏好，更好地为司机提供调度建议，进而帮助缓解出行供需。\n滴滴首席数据科学家谢梁认为在共建 SQLFlow 过程中，充分体现了算法和数据科学在对数据的理解和应用上的两个不同，以及双方优势互补形成 1+1 大于 2 的合力效果。因为对于传统的算法来讲主要强调对于预测一个给定事件的预测精准性。但是数据科学在预测精准性之上，还强调预测的可解释性。实际上在更广泛的商业层面上，比如运营、营销等更需要了解为什么会这这样发生，这对于业务战略制定、营销方案的确定，以及整个产品序列的设计都有非常大的帮助。\n滴滴数据科学团队在过去不到两个月的共建工作中显著扩大了 SQLFlow 的应用场景。根据蚂蚁金服 SQLFlow 项目的产品负责人刘勇峰介绍，滴滴的同事们建议并且参与研发了 SQLFlow 对接 XGBoost 的功能，从而在深度学习模型之外支持树模型；以及对接 unsupervised learning 的能力，支持聚类分析。此外，SQLFlow 基于 SHAP 支持了深度学习模型和树模型的图示化解释。SQLFlow 也支持了滴滴常用的 Hive 数据库系统。\n基于 XGBoost 的汽车价格预测模型（数据来自 Kaggle）的 SHAP 解释图（注：SHAP 值表征了每个特征对模型输出的影响，如图中，较小的 engine_hp“引擎马力”值会降低汽车的预测价格）\n“我们是希望通过 SQLFlow 真正能够把数据驱动业务、科学决策的思想，能够在中国传播得更好更远，也希望就是能够通过我们自己的努力，真正让 AI 模型能力大众化和普及化，然后使得我们整个国内的数据分析的科学性、合理性和洞察性，能够逐步提升，甚至达到国际领先。”高梓尧说。\n而所有参与项目的同事们对 SQLFlow 的未来都有更大的期待，这是对于开源社区作为一种高效率的工作模式的信任。\n打造一个 SQL 花园生态 在强调数据驱动的滴滴其实一直积极参与到开源建设中，截至目前，滴滴和蚂蚁金服分别开源了数十个项目。SQLFlow 是双方开源共建的首秀。\n对于双方仅一个多月的时间就能够共建三个高价值的模型，谢梁认为很重要的原因是 SQLFlow 已经给滴滴搭建好了底层能力，滴滴相当于做了一个交通领域的几个核心插件，并且通过滴滴插件能力，对整个 SQLFlow 覆盖面和深度方面的底层能力进行了验证和提升，“那么再把这个基础打好之后，我们就相当于造了一个大的花园，我们把土都铺好了，需要什么营养的土，要种什么类型的花，都给他做好了，之后就需要有更多的农民伯伯一起来种田，他们要去种向日葵，我们毕竟精力有限可能就是以种小麦和种主粮为主，更多的经济作物就需要其他开源社区的同学一起来贡献。”\n在整个 SQLFlow 开源社区建设方面双方都有更大的愿景，滴滴的分析团队总结的很多模型在 BI 领域具备普适性，而 SQLFlow 在蚂蚁的场景使用模型在金融领域颇有普适性，未来要让更多的人去用上普适的 AI 能力，在 SQLFlow 社区之上会形成一个开源货架式的交易市场，更多懂业务的人把更多商业场景抽象成模型打造成模型库，模型库是 SQLFlow 生态中的重要一环，双方正在讨论如何共建。“你就像走进一个超市，里面有 10万个 SQL，每一个 SQL 就是一个实现了你商业逻辑的模型，你就拿来用就行了，这是终极的一个目标”，谢梁兴奋地谈到。\n当然现在的 SQLFlow 还是一个非常年轻的开源项目，需要更多的呵护。虽然目前在开源合作方面中国相比美国还有不少差距，但正是因为越来越多的公司和个人去投身其中为之贡献，差距正在缩小。实际上，几乎所有的 SQLFlow 项目成员都是利用业余时间参与到开源项目中。比如滴滴资深算法工程师陈祥，他平时负责数据治理和应用方向上数据、应用与算法的结合和落地, 在 8 月初听到 SQLFlow 项目就决定参与进来，未来他也会号召很多的人参与到开源建设中。\n“开源社区所说的构建大生态，其实大生态还包含着另外一层，就是大家互相学习，然后行业内的所有从业人员进行知识交流。所以当各行各业的同学都在里面贡献自己的经验、技能时，我们其实也能从其他的同学那学习到很多处理数据，或者解决实际问题的方法。”高梓尧所言恰如其分地诠释了开源社区众人拾柴火焰高的魅力。\nGartner 预测“到 2020 年，AI 技术将普遍出现在几乎每一个新的软件产品和服务中。”这其中有蚂蚁金服与滴滴 DS 团队的一份力。\n项目地址 欢迎感兴趣的同学加入社区讨论： 项目官 …","date":1569740400,"description":"让AI 像 SQL 查询一样简单。","dir":"blog/sqlflow-ai-didi-antfin-open-source-construction/","fuzzywordcount":2800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"d8e2fdbfc1d48f984a2adf17474cb983","permalink":"/blog/sqlflow-ai-didi-antfin-open-source-construction/","publishdate":"2019-09-29T15:00:00+08:00","readingtime":6,"relpermalink":"/blog/sqlflow-ai-didi-antfin-open-source-construction/","summary":"2018 年 1 月，Oracle 的官方博客上发表了一篇文章，标题是“It\u0026rsquo;s Pervasive：AI Is Everywhere”。作为全球最著","tags":["SQLFlow"],"title":"让 AI 无处不在：滴滴与蚂蚁金服开源共建 SQLFlow","type":"blog","url":"/blog/sqlflow-ai-didi-antfin-open-source-construction/","wordcount":2732},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题 通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、关于 SOFAJRaft 的提问：\n@LoFi 提问：\n 关于 SOFAJRaft，请教几个问题：不管 raft log 是并行，batch 还是 pipeline 复制，都是为了提高 throughput，但对 latency 没有好处，因为最终日志必须要顺序 commit 和顺序 Apply ，这是 Raft 论文的要求。但是在某些简单的 KV 场景，上层业务可以根据需求去乱序 commit 和 Apply 么？这样可以降低 latency 。\n A：pipeline 对 latency 会有一些好处，总体上讲 batch 对吞吐有好处，SOFAJRaft 里的 batch 设计也不会对 latency 有坏处，所以它还是好的，乱序 apply 理论上影响一致性。\n 如果 raft log commit 成功，但是 apply 失败，系统目前的处理方式是什么？直接 crash?\n A：apply 异常失败会阻塞住状态机，只有重启才可能恢复，为了保证一致性。\n 如果 leader 本地磁盘 error 或者本地 log flush 失败, 但收到了多数派的响应，日志会 commit 么？怎么处理这种情况？\n A：你说的这种异常状态机就挂掉了，原因同上一条。\n关于扩容：\n 扩容时，新节点的角色不能为 follow 吧？会影响 ballot，不应该先增加一个 Follow 角色，等 snapshot 加载成功后再变为 follow 么？\n A：新加节点首先要求日志追上才行，你说的这个不存在。\n 扩容时，如果是 follow 的话，根据论文就会影响 leader 的投票吧\n A：那首先得你说的这个 follower 在这个组里呀。首先要追上数据，才能变更配置，这个节点才会进入 group，另外再退一步，没有最新日志的 follower 也无法影响投票。SOFAJRaft 比 Raft 论文里面多了一个 preVote。\n 明白，就是先追上数据，然后才能再走一遍 addpeer raftlog ?\n A：不是额，是 addPeer 的流程里第一步就是要先追数据。\n 你的意思是：当新的节点加入集群时，会先追日志 , 然后再把这个节点加入到 raft goup 中，成为投票中的一员 是么？ 也就是说在追日志的过程中，这个新的节点是不会参与 raft log 的投票么？那如果说我只是为一个 raft goup 增加副本数，比如从 3 副本变成 4 副本时，这个时候是怎么处理的呢？反正就是不管哪种情况，都是先追数据，然后再加入到 Goup 里？\n A：新加的 follower 一启动，就会 electiontimeout 发起选举，但是不会成功，然后 leader 会为这个节点新起一个 replicator 开始复制数据日志（通常包含 snapshot），等到数据追上后，leader 会再提交一条配置变更日志，此时这个节点就正式加入到 group 了。\n2、关于 Seata 的提问：\n@姜伟锋 提问：\n 最近在看 Seata 的源码，发现 rpc 相关的 Request、Response 网络传输对象太多了，在保证扩展性的基础上是不是可以优化下，因为主要参数也就是事务组 id、事务组 status、分支事务 id、分支事务 status，再加上附加信息字段，感觉这块设计还有相关序列化设计有点复杂了，这样设计的目的是什么呢，求大佬解。\n A：是指字段冗余还是指外层的包装协议复杂了？\n rpc 传输对象感觉有点冗余，一些 request response 对象是不是可以合并，主要字段应该是固定的，这样设计的目的扩展性是很好，复用性是不是还有优化空间呢？\n A： 这里是按照非事务消息（注册鉴权之类）和事务消息，事务消息又按照 RM，TM 角色以及传输的方向做了分类，你说的冗余能举个栗子嘛？\n 看到是按角色定义的 rpc req，res 传输对象，这些词传输对象中主要的字段是全库事务 id，全库事务状态，分支事务 id，分支事务状态，资源 id，还有一些附加字段，TM、TC、RM 交互时为什么不设计成一个 req res 对象公用或者是否可以在现有框架上提高下复用性，个人是觉得这块设计了好多传输对象，每个对象有对应的序列化和反序列化，有点复杂，这样设计扩展性这个点我明白，复用性不是太好，还有其他考虑吗？\n A：每个消息都有一个名称（code），消息名对于整个事务的链路流程上理解比较清晰，结合着我们的事务流程图来看，每个阶段的 rpc 都有一个确切的含义，即使从字段上来说是相同的比如GlobalRollbackRequest，GlobalCommitRequest 从名称上来看不一样，但从传输层面来看除了code 不一样其他的是一样的。但是大部分消息的字段还是不一样的，对于这种通用字段比如 xid begin 消息就是空的，设计成通用这里只能是 null，非通用比如 lockkey 那这里如果使用通用消息就可能直接塞到一个 applicationData 的扩展字段里，这种写法我觉得不确切，同时有增加了我私有协议序列化时不必要的长度标识字段，每条消息都是由确切的所需的字段，宁愿复杂一些，也要从设计上更清晰些。\nSeata：https://github.com/seata/seata\nSOFAJRaft 解析文章全系列 《剖析 | SOFAJRaft 实现原理》系列文章完结啦，感谢 SOFAStack 社区的核心贡献者们的编写，也欢迎更多感兴趣的技术同学加入。\nSOFAJRaft：https://github.com/sofastack/sofa-jraft\n SOFAJRaft Snapshot 原理剖析 | SOFAJRaft 实现原理 SOFAJRaft-RheaKV 分布式锁实现剖析　| SOFAJRaft 实现原理 SOFAJRaft 日志复制 - pipeline 实现剖析 | SOFAJRaft 实现原理 SOFAJRaft-RheaKV MULTI-RAFT-GROUP 实现分析 | SOFAJRaft 实现原理 SOFAJRaft 选举机制剖析 | SOFAJRaft  …","date":1569567600,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20190927/","fuzzywordcount":2500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"d1709ae51d5099a6263d7269a435e264","permalink":"/blog/sofa-weekly-20190927/","publishdate":"2019-09-27T15:00:00+08:00","readingtime":5,"relpermalink":"/blog/sofa-weekly-20190927/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | 每周精选【9/23 - 9/27】","type":"blog","url":"/blog/sofa-weekly-20190927/","wordcount":2458},{"author":"胡宗棠","categories":"SOFAJRaft","content":" SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。\n SOFAJRaft 是一个基于 Raft 一致性算法的生产级高性能 Java 实现，支持 MULTI-RAFT-GROUP，适用于高负载低延迟的场景。\n本文为《剖析 | SOFAJRaft 实现原理》最后一篇，本篇作者胡宗棠，来自中国移动。《剖析 | SOFAJRaft 实现原理》系列由 SOFA 团队和源码爱好者们出品，项目代号：SOFA:JRaftLab/，文末包含往期系列文章。\nSOFAJRaft：https://github.com/sofastack/sofa-jraft\n导读 本文主要介绍 SOFAJRaft 在日志复制和管理中所采用的快照机制。考虑到单独介绍 SOFAJRaft 中的快照机制原理和实现或许有一些唐突，我会先通过一个读者都能够看得明白的例子作为切入点，让大家对快照这个概念、它可以解决的主要问题，先有一个比较深刻的理解。\n一、快照的概念与特点 SOFAJRaft 是对 Raft 共识算法的 Java 实现。既然是共识算法，就不可避免的要对需要达成共识的内容，在多个服务器节点之间进行传输，一般将这些共识的内容称之为日志块（LogEntry）。如果读过《剖析 | SOFAJRaft 实现原理》系列前面几篇文章的同学，应该了解到在 SOFAJRaft 中，可以通过“节点之间并发复制日志”、“批量化复制日志”和“复制日志pipeline机制”等优化手段来保证服务器节点之间日志复制效率达到最大化。\n但如果遇到下面的两个场景，仅依靠上面的优化方法并不能有效地根本解决问题：\n 当对某个 SOFAJRaft Group 集群以新增节点方式来扩容，新节点需要从当前的 Leader 中获取所有的日志并重放到本身的状态机中，这对 Leader 和网络带宽都会带来不小的开销，还有其他方法可以优化或解决这个问题么？ 因为服务器节点需要存储的日志不断增加，但是磁盘空间有限，除了对磁盘卷大小扩容外，还有其他方式来解决么？  带着上面两个疑问，我们可以先来看一个大家日常生活中都会遇到的场景—重新安装操作系统，然后再通俗易懂地为大家介绍快照的概念与特点。\n有一天，你的笔记本电脑的 Windows 操作系统因为某一些原因出现启动后多次崩溃问题，不管通过任何方式都没办法解决。这时候，我们想到解决问题的第一个方案就是为这台电脑重新安装操作系统。如果，我们平时偶尔为自己电脑的操作系统做过镜像，直接用之前的镜像文件即可快速还原系统至之前的某一时间点的状态，而无需从零开始安装 Windows 操作系统后，再花大量时间来重新安装一些自己所需要的系统软件（比如 Chrome 浏览器、印象笔记和 FoxMail 邮件客户端等）。\n在上面的例子中，电脑操作系统的镜像就是系统某一时刻的“快照”，因为它包含了这一时刻，系统当前状态机的值（对于用户来说，就是安装了哪些的应用软件）。在需要重新安装操作系统时候，通过镜像这一“快照”，可以很高效地完成还原电脑操作系统这个任务，而无需从零开始安装系统和相应的应用软件。所以，我们这里可以为“快照”下一个简单的定义：一种通过某种数据格式文件来保存系统当前的状态值的一个副本。\n“快照”的特点，就如同它字面意思一样，可以分为“快”和“照”：\n “快”：高效快捷，通过快照可以很方便的将系统还原至某一时刻的状态； “照”：通过快照机制是保存系统某一时刻的状态值；  二、SOFAJRaft 的 Snapshot 机制 2.1 SOFAJRaft Snapshot 机制的原理 读到这里，再去回顾第一节内容开头提出的两个问题，大家应该可以想到解决问题的方法就是通过引入快照机制。\n1. 解决日志复制与节点扩容的瓶颈问题 在 SOFAJRaft 中，Snapshot 为当前 Raft 节点状态机的最新状态打了一个“镜像”单独保存，保存成功后在这个时刻之前的日志即可删除，减少了日志文件在磁盘中的占用空间。而在 Raft 节点启动时，可以直接加载最新的 Snapshot 镜像，直接重放在此之后的日志文件即可。如果设置保存 Snapshot 的时间间隔比较合理，那么节点加载镜像后重放的日志文件较少，启动速度也会比较快。对于新 Raft 节点加入某个 SOFAJRaft Group 集群的场景，新节点可先从 Leader 节点上拷贝最新的 Snapshot 安装到本地状态机，然后拷贝后续的日志数据即可，这样可以在快速跟上整个 SOFAJRaft Group 集群进度的同时，又不会占用 Leader 节点较大的网络带宽资源。\n2. 解决 Raft 节点故障恢复中的时效问题 在一个正常运行的 SOFAJRaft Group 集群中，当其中某一个 Raft 节点出现故障了（假设该故障的原因不是由磁盘损坏等不可逆因素导致的），该 Raft 节点修复故障重新启动时，如果节点禁用 Snapshot 快照机制，那么会重放所有本地的日志到状态机以跟上最新的日志，这样节点启动和达到日志备份完整的耗时均会比较长。但是，如果此时节点开启了 Snapshot 快照机制，那么一切就会变得非常高效，节点只需要加载最新的 Snapshot 至状态机，然后以 Snapshot 数据的日志为起点开始继续回放日志至状态机，直到使得状态机达到最新状态。\n图1 在 Snapshot 禁用情况下集群节点扩容\n图2 在 Snapshot 启用情况下集群节点扩容\n从上面两张 SOFAJRaft 集群的结构图上，可以很明显地看出在开启和禁用 Snapshot 时，扩容的新 Raft 节点需要从 Leader 节点传输过来不同的日志数量。在禁用 Snapshot 情况下，新 Raft 节点需要把 Leade 节点内从起始的 T1 时刻至当前 T3 时刻这一时间范围内的所有日志都重新传至本地后提交给状态机。而在开启 Snapshot 情况下，新 Raft 节点则无需像 图1 中那么逐条复制 T1~T3 时刻内的所有日志，而只需先从 Leader 节点加载最新的镜像文件 Snapshot_Index_File 至本地，然后仅复制 T3 时刻以后的日志至本地并提交状态机即可。\n在这里可能有同学会有疑问：“在 图 1 中，从 Leader 节点传给新扩容的 Raft 节点的数据是 T1~T3 的日志，而 图2 中取而代之的是 Snapshot_Index_File 快照镜像文件，似乎还是不可避免额外的数据传输么？”仔细看下图 2，会发现其中 Snapshot_Index_File 快照镜像文件是对 T1~T3 时刻内日志数据指令的合并（包括数集合[Add 1,Add 6,Add 4,Sub 3,Sub 4,Add 3]），也即为最终的数据状态值。\n2.2 SOFAJRaft Snapshot 机制的实践应用 如果用户需开启 SOFAJRaft 的 Snapshot 机制，则需要在其客户端中设置配置参数类 NodeOptions  …","date":1569232800,"description":"本文为《剖析 | SOFAJRaft 实现原理》最后一篇，本篇作者胡宗棠。","dir":"blog/sofa-jraft-snapshot-principle-analysis/","fuzzywordcount":4500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"39ff132d4c11bccb0059665f6e9c4b31","permalink":"/blog/sofa-jraft-snapshot-principle-analysis/","publishdate":"2019-09-23T18:00:00+08:00","readingtime":9,"relpermalink":"/blog/sofa-jraft-snapshot-principle-analysis/","summary":"SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金","tags":["SOFAJRaft","SOFALab","剖析 | SOFAJRaft 实现原理"],"title":"SOFAJRaft Snapshot 原理剖析 | SOFAJRaft 实现原理","type":"blog","url":"/blog/sofa-jraft-snapshot-principle-analysis/","wordcount":4407},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题 通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n@wy223170 提问：\n 你好，请问下 SOFAJRaft 如何在虚拟化环境下使用，比如部署三个实例，三个实例都是 docker 的。因为虚拟化实例可能漂移，怎么保证 snapshot 的迁移呢？另外怎么控制多个实例的同时漂移，导致集群不可用的问题？\n A：SOFAJRaft 本身是有状态的，你说的实例漂移就可以理解为这个节点挂掉并新拉起了一个节点，我们内部的做法是通过一个 manager 节点监听容器上下线并执行 CliService removePeer 和 addPeer，利用 raft 协议本身的能力达到数据迁移的目的，但是对于半数以上节点同时漂移是无解的，可能出现丢数据的情况。这是 etcd 的一个解决类似问题的方式，供参考：https://github.com/coreos/etcd-operator\n 感谢回答，是不是只要 manager 节点监听到容器变化就会立刻进行 removePeer 或 addPeer，需不需等待容器已经达到某种状态，比如迁移完 snapshot 等才进行 addPeer 之类的，这可能就需要实例迁移后完成一个打标记的功能标志迁移完成了。\n A：流程是先 addPeer 成功以后再 removePeer。其中 addPeer 在追数据成功后才会返回成功。看到你多次强调 snapshot，其实这里你不用关注 snapshot，这是 SOFAJRaft 内部会考虑的 raft 层的东西，不需要额外做特殊处理。\n开源项目  ElasticDL：蚂蚁金服开源基于 TensorFlow 的弹性分布式深度学习系统 蚂蚁金服开源机器学习工具 SQLFlow，技术架构独家解读  SOFA 项目进展 本周发布详情如下：\n发布 Seata v0.8.1，主要变更如下：\n 支持配置文件使用绝对路径 支持 DataSource 的自动代理 支持通信协议的 kryo 编解码 修复 file 存储模式的 selectForUpdate lockQuery exception 修复数据库连接使用后的 autocommit 问题 优化 etcd3 中 watcher 订阅的效率 优化当数据表无索引时抛出显式异常  详细发布报告： https://github.com/seata/seata/releases/tag/v0.8.1\nSOFAJRaftLab 系列阅读  SOFAJRaft-RheaKV 分布式锁实现剖析　| SOFAJRaft 实现原理 SOFAJRaft 日志复制 - pipeline 实现剖析 | SOFAJRaft 实现原理 SOFAJRaft-RheaKV MULTI-RAFT-GROUP 实现分析 | SOFAJRaft 实现原理 SOFAJRaft 选举机制剖析 | SOFAJRaft 实现原理 SOFAJRaft 线性一致读实现剖析 | SOFAJRaft 实现原理 SOFAJRaft-RheaKV 是如何使用 Raft 的 | SOFAJRaft 实现原理 生产级 Raft 算法库 SOFAJRaft 存储模块剖析 | SOFAJRaft 实现原理  ","date":1568962800,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20190920/","fuzzywordcount":1100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"4519012918ba68bf9e39b0daed78cfc4","permalink":"/blog/sofa-weekly-20190920/","publishdate":"2019-09-20T15:00:00+08:00","readingtime":3,"relpermalink":"/blog/sofa-weekly-20190920/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | 每周精选【9/16 - 9/20】","type":"blog","url":"/blog/sofa-weekly-20190920/","wordcount":1043},{"author":"米麒麟","categories":"SOFAJRaft","content":" SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。\n SOFAJRaft 是一个基于 Raft 一致性算法的生产级高性能 Java 实现，支持 MULTI-RAFT-GROUP，适用于高负载低延迟的场景。\n本文为《剖析 | SOFAJRaft 实现原理》第七篇，本篇作者米麒麟，来自陆金所。《剖析 | SOFAJRaft 实现原理》系列由 SOFA 团队和源码爱好者们出品，项目代号：SOFA:JRaftLab/，文末包含往期系列文章。\nSOFAJRaft ：https://github.com/sofastack/sofa-jraft\n前言 在分布式部署、高并发、多线程场景下，我们经常会遇到资源的互斥访问的问题，最有效、最普遍的方法是给共享资源或者对共享资源的操作加一把锁。在 JDK 中我们可以使用 ReentrantLock 重入锁或者 synchronized 关键字达成资源互斥访问目的，但是由于分布式系统的分布性（即多线程和多进程并且分布在不同机器中），使得两种锁失去原有锁的效果，需要用户自定义来实现分布式锁。\n本文重点围绕分布式锁概览、实现方式以及基于 SOFAJRaft 实现等方面剖析 SOFAJRaft-RheaKV 基于 SOFAJRaft 实现分布式锁原理，阐述如何使用 SOFAJRaft 组件提供分布式锁服务功能：\n 什么是分布式锁？分布式锁具备哪些条件？分布式锁有哪些实现方式？ RheaKV 基于 SOFAJRaft 如何实现分布式锁？解决分布式锁哪些问题？  分布式锁 分布式锁是控制分布式系统之间同步访问共享资源的一种方式，用于在分布式系统中协调他们之间的动作。如果不同的系统或是同一个系统的不同主机之间共享了一个或一组资源，那么访问这些资源的时候，往往需要互斥来防止彼此干扰来保证一致性，在这种情况下便需要使用到分布式锁。分布式锁通过共享标识确定其唯一性，对共享标识进行修改时能够保证原子性和对锁服务调用方的可见性。\n分布式锁概览 Martin Kleppmann 是英国剑桥大学的分布式系统研究员，之前和 Redis 之父 Antirez 关于 RedLock 红锁是否安全的问题激烈讨论过。Martin 认为一般我们使用分布式锁有两个场景：\n 效率：使用分布式锁能够避免不同节点重复相同的工作导致浪费资源，譬如用户付款之后有可能不同节点发出多条短信； 正确性：添加分布式锁同样避免破坏正确性事件的发生，如果两个节点在同一条数据上面操作，譬如多个节点机器对同一个订单操作不同的流程有可能导致该笔订单最后状态出现错误造成资金损失；  分布式锁需要具备的条件包括：\n 获取锁和释放锁的性能要好； 判断获得锁是否是原子性的，否则可能导致多个请求都能获取到锁； 网络中断或者宕机无法释放锁时，锁必须被清除； 可重入一个线程中多次获取同一把锁，譬如一个线程在执行带锁的方法，该方法调用另一个需要相同锁的方法，则该线程直接执行调用的方法，而无需重新获得锁； 阻塞锁和非阻塞锁，阻塞锁即没有获取到锁，则继续等待获取锁；非阻塞锁即没有获取到锁，不继续等待直接返回获取锁失败；  分布式锁实现 分布式 CAP 理论告诉我们“任何一个分布式系统都无法同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition Tolerance），最多只能同时满足两项。”，很多系统在设计之初就要对这三者做出取舍。在互联网领域的绝大多数的场景中，都需要牺牲强一致性来换取系统的高可用性，系统往往只需要保证“最终一致性”，只要这个最终时间是在用户可以接受的范围内即可。在很多场景中为了保证数据的最终一致性，需要很多的技术方案来支持，比如分布式事务、分布式锁等。有的时候需要保证一个方法在同一时间内只能被同一个线程执行。 分布式锁一般有三种实现方式：\n 基于数据库实现分布式锁； 基于缓存（Redis，Memcached，Tair）实现分布式锁； 基于 ZooKeeper 实现分布式锁；  基于数据库实现分布式锁 基于数据库实现分布式锁的核心思想：在数据库中创建一张表，表里包含方法名等字段，并且在方法名字段上面创建唯一索引，执行某个方法需要使用此方法名向表中插入数据，成功插入则获取锁，执行结束则删除对应的行数据释放锁。\n基于缓存实现分布式锁 基于缓存通常选用 Redis 实现分布式锁，考虑到 Redis 有非常高的性能，Redis 命令对分布式锁支持友好，并且实现方便。基于单 Redis 节点的分布式锁在 Failover 的时候产生解决不了的安全性问题，Redlock 是 Redis 的作者 Antirez 提出的集群模式 Redis 分布式锁，基于 N 个完全独立的 Redis 节点（通常情况下 N 可以设置成5），运行 Redlock 算法依次执行下面各个步骤完成获取锁的操作\n 获取当前时间（毫秒数）； 按顺序依次向 N 个 Redis 节点执行获取锁的操作。此获取操作包含随机字符串 my_random_value，也包含过期时间(比如 PX 30000，即锁的有效时间)。为了保证在某个 Redis 节点不可用的时候算法能够继续运行，获取锁的操作还有超时时间(time out)，它要远小于锁的有效时间（几十毫秒量级）。客户端在向某个 Redis 节点获取锁失败以后应该立即尝试下一个Redis 节点。这里的失败包含任何类型的失败，比如该 Redis 节点不可用，或者该 Redis 节点上的锁已经被其它客户端持有（注：Redlock 原文中这里只提及 Redis 节点不可用的情况，但也应该包含其它的失败情况）； 计算整个获取锁的过程总共消耗了多长时间，计算方法是用当前时间减去第1步记录的时间。如果客户端从大多数 Redis 节点（\u0026amp;gt;= N/2+1）成功获取到了锁，并且获取锁总共消耗的时间没有超过锁的有效时间（lock validity time），那么这时客户端才认为最终获取锁成功；否则认为最终获取锁失败； 如果最终获取锁成功了，那么此锁的有效时间应该重新计算，它等于最初锁的有效时间减去第3步计算出来的获取锁消耗的时间； 如果最终获取锁失败（可能由于获取到锁的 Redis 节点个数少于 N/2+1，或者整个获取锁的过程消耗的时间超过了锁的最初有效时间），那么客户端立即向所有 Redis 节点发起释放锁的操作；  基于 ZooKeeper 实现分布式锁 ZooKeeper 是以 Paxos 算法为基础的分布式应用程序协调服务，为分布式应用提供一致性服务的开源组件，其内部是分层的文件系统目录树结构，规定同一个目录下只能有一个唯一文件名。基于 ZooKeeper 实现分布式锁步骤包括：\n 创建一个锁目录 lock； 希望获得锁的线程 A 在 lock 目录下创建临时顺序节点； 当前线程获取锁目录下所有的子节点，然后获取比自己小的兄弟节点，如果不存在表示当前线程顺序号最小，获得锁； 线程 B 获取所有节点，判断自己不是最小 …","date":1568721600,"description":"本文为《剖析 | SOFAJRaft 实现原理》第七篇，本篇作者米麒麟。","dir":"blog/sofa-jraft--rheakv-distributedLock/","fuzzywordcount":6200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"be578aa3941f24a603a7053e7c7e1107","permalink":"/blog/sofa-jraft-rheakv-distributedlock/","publishdate":"2019-09-17T20:00:00+08:00","readingtime":13,"relpermalink":"/blog/sofa-jraft-rheakv-distributedlock/","summary":"SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金","tags":["SOFAJRaft","剖析 | SOFAJRaft 实现原理","SOFALab"],"title":"SOFAJRaft-RheaKV 分布式锁实现剖析　| SOFAJRaft 实现原理","type":"blog","url":"/blog/sofa-jraft-rheakv-distributedlock/","wordcount":6176},{"author":"Oschina","categories":"ElasticDL","content":"9 月 11 日，蚂蚁金服在2019谷歌开发者大会上海站上开源了 ElasticDL 项目，这是业界首个基于 TensorFlow 实现弹性深度学习的开源系统。\n开源地址为：https://github.com/sql-machine-learning/elasticdl/\n开源中国采访了 ElasticDL 项目负责人王益，对该深度学习系统的技术细节进行了全面介绍。\n基于 TensorFlow 2.0 和 Kubernetes实现弹性深度学习 这个基于 Eager Execution 模式的开源项目名为“ElasticDL”，它是一个Kubernetes 原生深度学习框架，根据介绍，ElasticDL 主要有四大特点：\n 容错性 弹性调度 易用性 高效  其中又以容错与弹性调度特性最具特色。\nElasticDL 实现了容错和弹性调度的分布式深度学习，可以极大提升集群的总体利用率，同时显著减少用户提交作业之后等待作业启动的时间（pending time）。\n王益介绍：“ElasticDL 是我们知道的第一个基于 TensorFlow 实现弹性深度学习的开源系统。具体地说，ElasticDL 是基于 TensorFlow 2.0 和 Kubernetes 实现弹性深度学习的。”\n集群效用从 1/N 到 N/N 在深度学习技术研发的早期，公用一个计算集群的人相对少， 计算作业之间的协调可以通过口头交流实现。开发者更关心缩短运行时间，也就是从作业启动到结束的这段时间。高性能计算技术（HPC）是解决这个问题的有效途径，比如 NVIDIA 的 cuBLAS 和 cuDNN 优化高性能数学计算、NCCL 优化 GPU 之间的通信效率。\n随着深度学习技术的大规模应用，在许多工程师和研究员公用一个集群的情况下，通过商量来协调调度显然不可行，于是大家开始使用集群管理系统调度分布式作业。\nKubernetes 近年来已经逐渐成为集群管理的重要工具，目前已经在各大公有云中广泛采用。因此，让 TensorFlow 能更好地运行在 Kubernetes 集群上，同时提升利用集群进行深度学习的效率和资源利用率（效用），显得非常具有实际意义。\n关于提升集群资源利用率，王益举了一个比较极端的例子：假设一个集群有 N 个 GPU，而一个任务只使用其中一个，现在有一个任务占用了一个 GPU。当没有弹性调度机制时，一个要求所有 N 个 GPU 的任务需要等待前一个任务结束才能开始，这个等待时间可能高达数天甚至数周，在等待期间，集群的效用是 1/N；而拥有弹性调度能力之后，新的任务可以在 N-1 个 GPU 上立即运行，并且 Kubernetes 可以在第一个任务完成后将占用的 GPU 赋予这个任务，这种情况下，集群整体效用是 100%。\nElasticDL 在容错与弹性调度上都有不错的表现，它的现实意义便是高效解决集群效用问题。\nElasticDL 如何实现？ 前边讲到集群资源利用率提高的前提其实就是ElasticDL 的“弹性调度”特性带来的，而弹性调度依赖于容错能力。\n容错是指作业不受其中进程数量变化的影响，在弹性调度过程中，作业里的进程数量会随集群 workload 情况相应增减，所以作业必须是容错的，才能配合调度系统，实现弹性调度。\n在这个过程中，容错通常由分布式框架实现，比如 Spark 和 ElasticDL 都可以做到当有进程挂掉，或者新的进程加入时，作业不会暂停或者重启，而是平滑地继续。而弹性调度是由分布式框架和分布式操作系统（集群管理系统）一起实现的。比如，当有进程挂掉的时候，分布式框架应该通知集群管理系统新启进程来补位 —— 至于集群管理系统能不能启动起来，取决于用户剩余 quota 和集群的忙碌情况。\n1. 基于 Kubernetes-native 通常使用 Keras 的 model-fit API 和 Estimator，开发者只需要调用 API 即可进行分布式训练或预测，然而 ElasticDL 不依赖于 TensorFlow runtime 实现分布式计算，它的实现在 runtime 之外。\nElasticDL 通过 Kubernetes-native 机制来完成分布式计算，而这也为其带来了容错性与弹性调度的能力。\n所谓 Kubernetes-native指的是一个程序调用 Kubernetes API 来起止进程，它与 Google MapReduce 的机制类似。MapReduce 是一个 Borg-native 的分布式计算框架，用户通过运行一个 Borg 客户端程序启动一个 MapReduce 作业；Borg 客户端调用 Borg API 提交作业，并且启动一个 master 进程；这个 master 调用 Borg API 启动其它 workers 进程。\n在 ElasticDL 中，用户调用 ElasticDL 的命令行客户端程序启动作业；这个客户端程序调用Kubernetes API 启动 master 进程，master进程继续调用 Kubernetes API 启动其它进程。\n“ElasticDL 的整个容错和弹性调度机制都依赖于 Kubernetes-native 架构”，王益介绍：“如果 worker 挂了，按照分布式深度学习训练算法的数学特性，可以不用处理，即可确保训练过程继续。如果一个 parameter server 进程挂了，master会选择一个 worker 进程，让它转换角色替补上挂掉的parameter server 进程。”\n在这两种情况下，master 都会调用 Kubernetes API，请它再启动一个额外的 worker 进程。如果启动成功，master 会带其加入到与其它进程的协作中。master 进程的状态（主要是三个 task queues：todo、doing与 done）可以保留在 Kubernetes 集群的 etcd 存储系统中。\n“这样，万一 master 挂了，重启的 master 进程可以从 etcd 继承前世的状态。任何进程挂了，master 都会请 Kubernetes 去启动一个新的进程代替挂掉的进程。而 Kubernetes 是否能完成使命取决于用户剩余 quota 和集群剩余资源情况。”\n2. 基于 TensorFlow 2.0 EagerExecution 为什么 ElasticDL 又基于 TensorFlow 2.0 呢？王益介绍，这是因为 TensorFlow 2.0 带来了 Eager Execution 特性，正是针对这一特性的尝试，让开发团队实现了Kubernetes-native 的调度方式，从而让 ElasticDL 支持容错和弹性调度。\n分布式学习需要了解每个进程根据局部训练数据计算得到的 gradients，才能汇总这些 gradients 来更新模型。\nTensorFlow 1.x 的执行方式被称为 Graph Mode —— 深度学习计算步骤被表示成一个 graph 数据结构，TensorFlow runtime 会解释执行这个 graph。其中，gradients 的计算过程是 graph  …","date":1568635200,"description":"业界首个基于 TensorFlow 实现弹性深度学习的开源系统 ElasticDL 项目的技术细节全面介绍。","dir":"blog/alipay-deep-learning-tensorflow-elasticdl/","fuzzywordcount":4700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"74eedc82d0b4a438d332dd5443605318","permalink":"/blog/alipay-deep-learning-tensorflow-elasticdl/","publishdate":"2019-09-16T20:00:00+08:00","readingtime":10,"relpermalink":"/blog/alipay-deep-learning-tensorflow-elasticdl/","summary":"9 月 11 日，蚂蚁金服在2019谷歌开发者大会上海站上开源了 ElasticDL 项目，这是业界首个基于 TensorFlow 实现弹性深度学习的开源系统。 开源地址为：https://g","tags":["ElasticDL"],"title":"ElasticDL：蚂蚁金服开源基于 TensorFlow 的弹性分布式深度学习系统","type":"blog","url":"/blog/alipay-deep-learning-tensorflow-elasticdl/","wordcount":4668},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\n中秋特辑推荐阅读  【中秋特辑】（含视频回顾）SOFAStack 活动回顾整理集合  SOFARegistry 系列解析文章  服务注册中心 MetaServer 功能介绍和实现剖析 | SOFARegistry 解析 蚂蚁金服服务注册中心 SOFARegistry 解析 | 服务发现优化之路 海量数据下的注册中心 - SOFARegistry 架构介绍  SOFA 项目进展 本周发布详情如下：\n发布 SOFARPC v5.6.1，主要变更如下：\n 升级 sofa-bolt 的版本到 1.5.6 修复 com.alipay.sofa.rpc.log.LoggerFactory 提供的 Logger 实现方案在多 classloader 场景下存在会出现类型不匹配的问题 修复 providerInfo 中可能出现的 staticAttrs 空指针问题  详细发布报告： https://github.com/sofastack/sofa-rpc/releases/tag/v5.6.1\nHey，中秋快乐呀 ","date":1568271600,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20190913/","fuzzywordcount":500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"85b998cb10df30ee42c04a8571b73598","permalink":"/blog/sofa-weekly-20190913/","publishdate":"2019-09-12T15:00:00+08:00","readingtime":1,"relpermalink":"/blog/sofa-weekly-20190913/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | 每周精选【9/9 - 9/13】","type":"blog","url":"/blog/sofa-weekly-20190913/","wordcount":423},{"author":"Yavin","categories":"SOFARegistry","content":" SOFAStack （Scalable Open Financial Architecture Stack） 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。\n SOFARegistry 是蚂蚁金服开源的具有承载海量服务注册和订阅能力的、高可用的服务注册中心，在支付宝/蚂蚁金服的业务发展驱动下，近十年间已经演进至第五代。\n本文为《剖析 | SOFARegistry 框架》第三篇，本篇作者 Yavin，来自考拉海购。《剖析 | SOFARegistry 框架》系列由 SOFA 团队和源码爱好者们出品，项目代号：SOFA:RegistryLab/，文末包含往期系列文章。\nGitHub 地址：https://github.com/sofastack/sofa-registry\n导读 集群成员管理是分布式系统中绕不开的话题。MetaServer 在 SOFARegistry 中，承担着集群元数据管理的角色，用来维护集群成员列表。本文希望从 MetaServer 的功能和部分源码切入剖析，为学习研究、或者项目中使用SOFARegistry 的开发者带来一些启发，分为三个部分：\n 功能介绍 内部架构 源码分析  功能介绍 MetaServer 作为 SOFARegistry 的元数据中心，其核心功能可以概括为集群成员管理。分布式系统中，如何知道集群中有哪些节点列表，如何处理集群扩所容，如何处理集群节点异常，都是不得不考虑的问题。MetaServer 的存在就是解决这些问题，其在 SOFARegistry 中位置如图所示： MetaServer 通过 SOFAJRaft 保证高可用和一致性，类似于注册中心，管理着集群内部的成员列表：\n 节点列表的注册与存储 节点列表的变更通知 节点健康监测  内部架构 内部架构如下图所示：\nMetaServer 基于 Bolt, 通过 TCP 私有协议的形式对外提供服务，包括 DataServer, SessionServer 等，处理节点的注册，续约和列表查询等请求。\n同时也基于 Http 协议提供控制接口，比如可以控制 session 节点是否开启变更通知, 健康检查接口等。\n成员列表数据存储在 Repository 中，Repository 被一致性协议层进行包装，作为 SOFAJRaft 的状态机实现，所有对 Repository 的操作都会同步到其他节点, 通过Rgistry来操作存储层。\nMetaServer 使用 Raft 协议保证数据一致性， 同时也会保持与注册的节点的心跳，对于心跳超时没有续约的节点进行驱逐，来保证数据的有效性。\n在可用性方面，只要未超过半数节点挂掉，集群都可以正常对外提供服务， 半数以上挂掉，Raft 协议无法选主和日志复制，因此无法保证注册的成员数据的一致性和有效性。整个集群不可用 不会影响 Data 和 Session 节点的正常功能，只是无法感知节点列表变化。\n源码分析 服务启动 MetaServer 在启动时，会启动三个 Bolt Server，并且注册 Processor Handler，处理对应的请求, 如下图所示：\n DataServer：处理 DataNode 相关的请求； SessionServer：处理 SessionNode 相关的请求； MetaServer：处理MetaNode相关的请求；  然后启动 HttpServer, 用于处理 Admin 请求，提供推送开关，集群数据查询等 Http 接口。\n最后启动 Raft 服务， 每个节点同时作为 RaftClient 和 RaftServer, 用于集群间的变更和数据同步。\n各个 Server 的默认端口分别为：\nmeta.server.sessionServerPort=9610 meta.server.dataServerPort=9611 meta.server.metaServerPort=9612 meta.server.raftServerPort=9614 meta.server.httpServerPort=9615 节点注册 由上节可知，DataServer 和 SessionServer 都有处理节点注册请求的 Handler。注册行为由 Registry 完成。注册接口实现为：\n@Override public NodeChangeResult register(Node node) { StoreService storeService = ServiceFactory.getStoreService(node.getNodeType()); return storeService.addNode(node); } Regitsry 根据不同的节点类型，获取对应的StoreService，比如DataNode，其实现为 DataStoreService 然后由 StoreService 存储到 Repository 中，具体实现为：\n// 存储节点信息 dataRepositoryService.put(ipAddress, new RenewDecorate(dataNode, RenewDecorate.DEFAULT_DURATION_SECS)); //... // 存储变更事件 dataConfirmStatusService.putConfirmNode(dataNode, DataOperator.ADD); 调用 RepositoryService#put 接口存储后，同时会存储一个变更事件到队列中，主要用于数据推送，消费处理。\n节点数据的存储，其本质上是存储在内存的哈希表中，其存储结构为：\n// RepositoryService 底层存储 Map\u0026amp;lt;String/*dataCenter*/, NodeRepository\u0026amp;gt; registry; // NodeRepository 底层存储 Map\u0026amp;lt;String/*ipAddress*/, RenewDecorate\u0026amp;lt;T\u0026amp;gt;\u0026amp;gt; nodeMap; 将RenewDecorate存储到该 Map 中，整个节点注册的流程就完成了，至于如何和 Raft 协议进行结合和数据同步，下文介绍。\n节点移除的逻辑类似，将节点信息从该 Map 中删除，也会存储一个变更事件到队列。\n注册信息续约和驱逐 不知道有没有注意到，节点注册的时候，节点信息被 RenewDecorate 包装起来了，这个就是实现注册信息续约和驱逐的关键：\nprivate T renewal; // 节点对象封装  private long beginTimestamp; // 注册事件  private volatile long lastUpdateTimestamp; // 续约时间  private long duration; // 超时时间 该对象为注册节点信息，附加了注册时间、上次续约时间、过期时间。那么续约操作就是修改lastUpdateTimestamp，是否过期就是判 …","date":1568271600,"description":" 本文为《剖析 |  SOFARegistry 框架》第三篇，作者 Yavin ，来自考拉海购。","dir":"blog/sofa-registry-metaserver-function-introduction/","fuzzywordcount":3400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"6e08281a1d2851d95121fc739cf80669","permalink":"/blog/sofa-registry-metaserver-function-introduction/","publishdate":"2019-09-12T15:00:00+08:00","readingtime":7,"relpermalink":"/blog/sofa-registry-metaserver-function-introduction/","summary":"SOFAStack （Scalable Open Financial Architecture Stack） 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来","tags":["SOFARegistry","剖析 | SOFARegistry 框架","SOFALab"],"title":"服务注册中心 MetaServer 功能介绍和实现剖析 | SOFARegistry 解析","type":"blog","url":"/blog/sofa-registry-metaserver-function-introduction/","wordcount":3311},{"author":"潘潘","categories":"SOFAStack","content":"SOFAStack 是蚂蚁金服完全自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，如微服务研发框架、RPC 框架、服务注册中心、分布式定时任务、限流/熔断框架、动态配置推送、分布式链路追踪、Metrics 监控度量、分布式高可用消息队列、分布式事务框架和分布式数据库代理层等。\nSOFAStack：https://github.com/sofastack\n本文为 SOFAStack 相关线上线下活动的回顾集合，并且会不定时更新。\n/ SOFAChannel 线上直播系列 / SOFAChannel#8  从一个例子开始体验 SOFAJRaft | SOFAChannel#8 直播整理 视频回顾资料  SOFAChannel#7  自定义资源 CAFEDeployment 的背景、实现和演进 | SOFAChannel#7 直播整理 视频回顾资料  SOFAChannel#6  蚂蚁金服轻量级监控分析系统解析 | SOFAChannel#6 直播整理 视频回顾资料  SOFAChannel#5  给研发工程师的代码质量利器 | SOFAChannel#5 直播整理 视频回顾资料  SOFAChannel#4  分布式事务 Seata TCC 模式深度解析 | SOFAChannel#4 直播整理 视频回顾资料  SOFAChannel#3  SOFARPC 性能优化实践（下）| SOFAChannel#3 直播整理 视频回顾资料  SOFAChannel#2  SOFARPC 性能优化实践（上）| SOFAChannel#2 直播整理 视频回顾资料  SOFAChannel#1  从蚂蚁金服微服务实践谈起 | SOFAChannel#1 直播整理 视频回顾资料  / SOFAMeetup 系列 / SOFAMeetup#3\u0026amp;lt;广州站\u0026amp;gt;   分布式事务 Seata Saga 模式首秀以及三种模式详解 | Meetup#3 回顾 视频回顾资料\n  蚂蚁金服在云原生架构下的可观察性的探索和实践 | Meetup#3 回顾 视频回顾资料\n  SOFAMeetup#2\u0026amp;lt;上海站\u0026amp;gt;   当 Spring Cloud 遇上 SOFAStack | Meetup#2 回顾 视频回顾资料\n  基于 SOFAArk 和 SOFADashboard 实现动态模块管控 | Meetup#2 回顾 视频回顾资料\n  SOFAMeetup#1\u0026amp;lt;北京站\u0026amp;gt;   蚂蚁金服开源服务注册中心 SOFARegistry | SOFA 开源一周年献礼 视频回顾资料\n  蚂蚁金服分布式事务开源以及实践 | SOFA 开源一周年献礼 视频回顾资料\n  详解蚂蚁金服 SOFAJRaft | 生产级高性能 Java 实现 视频回顾资料\n  / 技术大会系列 / 2019 年技术大会实录集合   五小时构建云原生电商平台 | KubeCon SOFAStack Workshop 详解\n  蚂蚁金服大规模分布式事务实践和开源历程 | GIAC 实录\n  蚂蚁金服 Service Mesh 落地实践与挑战 | GIAC 实录\n  2018 年技术大会实录集合   企业实施分布式架构的挑战以及应对建议 | 上海 ATEC 大会实录\n  企业服务行业如何试水 Istio | Service Mesh Meetup 分享实录\n  Knative：重新定义 Serverless | GIAC 实录\n  蚂蚁金服微服务实践 | 开源中国年终盛典分享实录\n  蚂蚁金服Service Mesh新型网络代理的思考与实践 | GIAC 分享实录\n  蚂蚁金服 Service Mesh 渐进式迁移方案|Service Mesh Meetup 实录\n  蚂蚁金服SOFAMesh在多语言上的实践 | CNUTCon 实录\n  从平台到中台 | Elaticsearch 在蚂蚁金服的实践经验\n  从“挖光缆”到“剪网线”|蚂蚁金服异地多活单元化架构下的微服务体系\n  蚂蚁金服 Service Mesh 实践探索 | Qcon 实录\n  ","date":1568260800,"description":"本文为 SOFAStack 相关线上线下活动的回顾集合，并且会不定时更新。","dir":"blog/sofa-activity-retrospect-collection/","fuzzywordcount":1000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"b1f0034b1e2c249a33c57be88f5a184c","permalink":"/blog/sofa-activity-retrospect-collection/","publishdate":"2019-09-12T12:00:00+08:00","readingtime":2,"relpermalink":"/blog/sofa-activity-retrospect-collection/","summary":"SOFAStack 是蚂蚁金服完全自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，如微服务研发框架、RPC 框架、服务注册中心、分布式定时","tags":["SOFAStack"],"title":"（含视频回顾）SOFAStack 活动回顾整理集合","type":"blog","url":"/blog/sofa-activity-retrospect-collection/","wordcount":986},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动\n我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n**1、@王冰 **提问：\n 请问个问题，SOFATracer 在采样计算时 rootSpan 为什么会计算两次，第一次是生成 span 时，第二次是在上报前又计算了一次？\n A：这种是考虑到产生 span 的逻辑是业务自己来构建，非正常逻辑情况下的一种兼容处理。对于 Tracer 来说，所有的上报是必须 SOFATracer 的行为，因此在 report 之前也会基于当前采样策略计算一次计算。默认情况下产生跟 span 时的计算更多是 span 或者说 span context 的，这个会作为向下透传的。另外产生不一致的情况不会出现，上报那段逻辑会先检查当前 span 的父 span，如果父 span 是 null 也就意味着当前 span 是 root span，所以也必须要计算。\n2、@迟广文 提问：\n 在使用 Seata 的时候，使用了 restful 框架，我的 TCC 调通了，是在接口上加了 @LocalTCC，实现类加 @Component，本以为会冲突，结果没有。\n A：TCC 的代理会代理二种类型的分支：在本地标注为 localTcc，第二种是 RPC 框架（dubbo、sofa-rpc）当 consumer 端使用作为 reference bean 且在 provider 端标注了二阶段注解时，这二种类型时互斥的，一个 TCC 分支只属于其一类型。\nSOFAChannel 回顾集合  SOFAChannel#8：从一个例子开始体验 SOFAJRaft | SOFAChannel#8 直播整理 SOFAChannel#7：自定义资源 CAFEDeployment 的背景、实现和演进 | SOFAChannel#7 直播整理 SOFAChannel#6：蚂蚁金服轻量级监控分析系统解析 | SOFAChannel#6 直播整理 SOFAChannel#5：给研发工程师的代码质量利器 | SOFAChannel#5 直播整理 SOFAChannel#4：分布式事务 Seata TCC 模式深度解析 | SOFAChannel#4 直播整理 SOFAChannel#3：SOFARPC 性能优化实践（下）| SOFAChannel#3 直播整理 SOFAChannel#2：SOFARPC 性能优化实践（上）| SOFAChannel#2 直播整理 SOFAChannel#1：从蚂蚁金服微服务实践谈起 | SOFAChannel#1 直播整理  SOFA 项目进展 本周发布详情如下：\n1、SOFATracer v2.4.1/v3.0.6 版本发布，主要变更如下：\n  支持自定义埋点 (FlexibleTracer)\n  支持 Dubbo 2.6.x\n  日志输出支持非 json 格式(xstringbuilder)\n  支持自定义扩展 Repoter 上报\n  Dubbo 2.7.x 系列支持 2.7.3 版本\n  修复 BasePreparedStatement 初始化问题\n  修复 SQLException 被覆盖问题\n  优化常量命名及代码注释等\n  更新案例及官方文档\n  详细发布报告：\nhttps://github.com/sofastack/sofa-tracer/releases/tag/v2.4.1\nhttps://github.com/sofastack/sofa-tracer/releases/tag/v3.0.6\n官方文档：\nhttps://www.sofastack.tech/projects/sofa-tracer/overview/\n2、SOFABoot v3.2.0 版本发布，主要变更如下：\n 升级 sofa-bolt 版本至 1.5.6 根据 Spring Boot 官方文档建议重构工程代码和组织结构  详细发布报告：\nhttps://github.com/sofastack/sofa-boot/releases/tag/v3.2.0\n官方文档：\nhttps://www.sofastack.tech/projects/sofa-boot/overview/\nSOFA 用户召集 如果您已经在生产环境使用了 SOFAStack 相关组件，请在下方链接登记告诉我们，方便我们更好地为您服务，我们将会把您加入到 “SOFAStack金牌用户服务群【邀约制】”里面，以便更加快捷的沟通和更加高效的线上使用问题支持。 https://github.com/sofastack/sofastack.tech/issues/5 已有用户查看： https://www.sofastack.tech/awesome\n","date":1567753200,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20190906/","fuzzywordcount":1400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"94743dfe34353e1f6910291d127a73d6","permalink":"/blog/sofa-weekly-20190906/","publishdate":"2019-09-06T15:00:00+08:00","readingtime":3,"relpermalink":"/blog/sofa-weekly-20190906/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | 每周精选【9/2 - 9/6】","type":"blog","url":"/blog/sofa-weekly-20190906/","wordcount":1300},{"author":"潘潘","categories":"SOFALab","content":"| SOFALab \u0026amp;lt;SOFA:Lab/\u0026amp;gt; 源码研究实验室，由 SOFA 团队和源码爱好者们出品，欢迎你的加入~\n\u0026amp;lt;SOFA:RegistryLab/\u0026amp;gt;是《剖析 | SOFARegistry 实现原理》系列，会逐步详细介绍 SOFARegistry 各个部分的代码设计和实现，欢迎领取文章进行共建。\n| SOFARegistry SOFARegistry 是蚂蚁金服开源的具有承载海量服务注册和订阅能力的、高可用的服务注册中心，最早源自于淘宝的初版 ConfigServer，在支付宝/蚂蚁金服的业务发展驱动下，近十年间已经演进至第五代。\nSOFARegistry:https://github.com/sofastack/sofa-registry\n| SOFA:RegistryLab   认领列表：\n 【已完成】海量数据下的注册中心 - SOFARegistry 架构介绍 【已完成】SOFARegistry 服务发现优化之路 【已完成】SOFARegistry 数据分片和同步方案详解 【已完成】SOFARegistry MetaServer 功能介绍和实现剖析 【已完成】SOFARegistry Session 存储策略 【已领取】SOFARegistry 如何实现秒级服务上下线通知 【已领取】SOFARegistry 如何实现 DataServer 平滑扩缩容    参与方式：关注**「金融级分布式架构」**回复可领取的文章标题，会有相关同学联系进行确认。\n  欢迎领取，参与共建~\n","date":1567483200,"description":"","dir":"activities/sofa-registry-lab/","fuzzywordcount":500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"ebbc0e9574d88e21f39926e750c848e9","permalink":"/activities/sofa-registry-lab/","publishdate":"2019-09-03T12:00:00+08:00","readingtime":1,"relpermalink":"/activities/sofa-registry-lab/","summary":"| SOFALab \u0026lt;SOFA:Lab/\u0026gt; 源码研究实验室，由 SOFA 团队和源码爱好者们出品，欢迎你的加入~ \u0026lt;SOFA:RegistryLab/\u0026gt;是《剖析 | SOFARegistry 实现原理》系列","tags":["SOFALab","SOFARegistry"],"title":"\u003cSOFA:RegistryLab/\u003e","type":"activities","url":"/activities/sofa-registry-lab/","wordcount":439},{"author":"力鲲","categories":"SOFAJRaft","content":" SOFA:Channel/，有趣实用的分布式架构频道。\n本文根据 SOFAChannel#8 直播分享整理，主题：从一个例子开始体验 SOFAJRaft。 回顾视频以及 PPT 查看地址见文末。 欢迎加入直播互动钉钉群：23390449，不错过每场直播。\n 大家好，我是力鲲，来自蚂蚁金服， 现在是 SOFAJRaft 的开源负责人。今天分享主题是《从一个例子开始体验 SOFAJRaft》，其实从这个题目大家也能看出来，今天是要从一个用户而非 owner 的视角来了解 SOFAJRaft。这么设计题目的原因是 SOFAJRaft 作为一种共识算法的实现，涉及到了一些概念和术语，而这些内容更适合通过一系列文章进行阐述，而在直播中我们希望能够分享对用户更有用、更容易理解的信息——SOFAJRaft 是什么，以及我们怎么去用它。\n首先介绍一下 SOFAJRaft 的背景知识，接下来说说这个例子源于什么需求，第三部分是架构的选型，第四部分来看看我们如何使用 SOFAJRaft，最后运行代码，看看 SOFAJRaft 是如何支撑业务运行的。\n欢迎加入社区成为 Contributor，SOFAJRaft。\nRaft 共识算法 Raft 是一种共识算法，其特点是让多个参与者针对某一件事达成完全一致：一件事，一个结论。同时对已达成一致的结论，是不可推翻的。可以举一个银行账户的例子来解释共识算法：假如由一批服务器组成一个集群来维护银行账户系统，如果有一个 Client 向集群发出“存 100 元”的指令，那么当集群返回成功应答之后，Client 再向集群发起查询时，一定能够查到被存储成功的这 100 元钱，就算有机器出现不可用情况，这 100 元的账也不可篡改。这就是共识算法要达到的效果。\nRaft 算法和其他的共识算法相比，又有了如下几个不同的特性：\n Strong leader：Raft 集群中最多只能有一个 Leader，日志只能从 Leader 复制到 Follower 上； Leader election：Raft 算法采用随机选举超时时间触发选举来避免选票被瓜分的情况，保证选举的顺利完成； Membership changes：通过两阶段的方式应对集群内成员的加入或者退出情况，在此期间并不影响集群对外的服务；  共识算法有一个很典型的应用场景就是复制状态机。Client 向复制状态机发送一系列能够在状态机上执行的命令，共识算法负责将这些命令以 Log 的形式复制给其他的状态机，这样不同的状态机只要按照完全一样的顺序来执行这些命令，就能得到一样的输出结果。所以这就需要利用共识算法保证被复制日志的内容和顺序一致。\n图1 - 复制状态机\nSOFAJRaft SOFAJRaft 是基于 Raft 算法的生产级高性能 Java 实现，支持 MULTI-RAFT-GROUP。应用场景有 Leader 选举、分布式锁服务、高可靠的元信息管理、分布式存储系统。\n图2 - SOFAJRaft 结构\n这张图就是 SOFAJRaft 的设计图，Node 代表了一个 SOFAJRaft Server 节点，这些方框代表他内部的各个模块，我们依然用之前的银行账户系统举例来说明 SOFAJRaft 的各模块是如何工作的。\n当 Client 向 SOFAJRaft 发来一个“存 100 元”的命令之后，Node 的 Log 存储模块首先将这个命令以 Log 的形式存储到本地，同时 Replicator 会把这个 Log 复制给其他的 Node，Replicator 是有多个的，集群中有多少个 Follower 就会有多少个 Replicator，这样就能实现并发的日志复制。当 Node 收到集群中半数以上的 Follower 返回的“复制成功” 的响应之后，就可以把这条 Log 以及之前的 Log 有序的送到状态机里去执行了。状态机是由用户来实现的，比如我们现在举的例子是银行账户系统，所以状态机执行的就是账户金额的借贷操作。如果 SOFAJRaft 在别的场景中使用，状态机就会有其他的执行方式。\nSnapshot 是快照，所谓快照就是对数据当前值的一个记录，Leader 生成快照有这么几个作用：\n 当有新的 Node 加入集群的时候，不用只靠日志复制、回放去和 Leader 保持数据一致，而是通过安装 Leader 的快照来跳过早期大量日志的回放； Leader 用快照替代 Log 复制可以减少网络上的数据量； 用快照替代早期的 Log 可以节省存储空间；  图3 - 需要用户实现：StateMachine、Client\nSOFAJRaft 需要用户去实现两部分：StateMachine 和 Client。\n因为 SOFAJRaft 只是一个工具，他的目的是帮助我们在集群内达成共识，而具体要对什么业务逻辑达成共识是需要用户自己去定义的，我们将用户需要去实现的部分定义为 StateMachine 接口。比如账务系统和分布式存储这两种业务就需要用户去实现不同的 StateMachine 逻辑。而 Client 也很好理解，根据业务的不同，用户需要去定义不同的消息类型和客户端的处理逻辑。\n图4 - 需要用户实现一些接口\n前面介绍了这么多，我们引出今天的主题：如何用 SOFAJRaft 实现一个分布式计数器？\n需求 我们的需求其实很简单，用一句话来说就是：提供一个 Counter，Client 每次计数时可以指定步幅，也可以随时发起查询。\n我们对这个需求稍作分析后，将它翻译成具体的功能点，主要有三部分：\n 实现：Counter server，具备计数功能，具体运算公式为：Cn = Cn-1 + delta； 提供写服务，写入 delta 触发计数器运算； 提供读服务，读取当前 Cn 值；  除此之外，我们还有一个可用性的可选需求，需要有备份机器，读写服务不能不可用。\n系统架构 根据刚才分析出来的功能需求，我们设计出 1.0 的架构，这个架构很简单，一个节点 Counter Server 提供计数功能，接收客户端发起的计数请求和查询请求。\n图5 - 架构 1.0\n但是这样的架构设计存在这样两个问题：一是 Server 是一个单点，一旦 Server 节点故障服务就不可用了；二是运算结果都存储在内存当中，节点故障会导致数据丢失。\n图6 - 架构 1.0 的不足：单点\n针对第二个问题，我们优化一下，加一个本地文件存储。这样每次计数器完成运算之后都将数据落盘，当节点故障之时，我们要新起一台备用机器，将文件数据拷贝过来，然后接替故障机器对外提供服务。这样就解决了数据丢失的风险，但是同时也引来另外的问题：磁盘 IO 很频繁，同时这种冷备的模式也依然会导致一段时间的服务不可用。\n图7 - 架构 1.0 的不足：冷备\n所以我们提出架构 2.0，采用集群的模式提供服务。我们用三个节点组成集群，由一个节点对外提供服务，当 Server 接收到 Client 发来的写请求之后，Server 运算出结果，然后将结果复制给另外两台机器，当收到其他所有节点的成功响应之后，Server 向 Client 返回运算结果。\n图8 - 架构 2.0\n但是这样的架构也 …","date":1567400400,"description":"本文根据 SOFAChannel#8 直播分享整理，以 Counter 为例，介绍 SOFAJRaft 的概念，并从需求提出开始，一步步完善架构，明确业务要实现哪些接口，最后启动日志观察 SOFAJRaft 如何支撑业务执行。","dir":"blog/sofa-channel-8-retrospect/","fuzzywordcount":5600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"7eab29bc73ad095706ad2daef197b1bb","permalink":"/blog/sofa-channel-8-retrospect/","publishdate":"2019-09-02T13:00:00+08:00","readingtime":12,"relpermalink":"/blog/sofa-channel-8-retrospect/","summary":"SOFA:Channel/，有趣实用的分布式架构频道。 本文根据 SOFAChannel#8 直播分享整理，主题：从一个例子开始体验 SOFAJRaft。 回顾视频以及 PPT 查看","tags":["SOFAJRaft","SOFAChannel"],"title":"从一个例子开始体验 SOFAJRaft | SOFAChannel#8 直播整理","type":"blog","url":"/blog/sofa-channel-8-retrospect/","wordcount":5537},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动\n我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n**1、@柴炜晨 **提问：\n 求问下 SOFAJRaft rhea split 后，原片1 [0,100) 分裂为 1 [0, 50) , 新片 2[50, 100)，新片 2 上的初始数据是从怎么来的呢？\n A：一个 store 里的所有 region 实际上是共享一个存储，split 只是新增一个逻辑 region 并修改被分裂的和新 region 的 range，后续的 snoapshot ，副本迁移等就均以新的 region 为最小单位了。\nSOFAJRaft：https://github.com/sofastack/sofa-jraft\n2、关于 SOFARegistry 的几个问题：\n@虞家成 提问：\n 服务 Sub 数据的一致性问题，其中主要的机制是通过 client, session 对缓存的逐级回放和比对，再加上版本号机制来实现最终一致性，问题是：这个版本号的生成，与递增是由谁来管理与维护？client? session? 还是 data ?\n A：这个版本号主要是在 data 上产生，版本号和最终写入内存时间戳关联产生，所有数据是指服务发布数据保证一致性。\n 对于每条服务的 Pub 数据，是否需要维护一个 ttl 值，否则在某些情况下，这条数据不能释放？\n A：如果你说的 ttl 值是指 pub 数据的生存时间，是有的，我们 pub 数据会有租约机制进行定时更新保证一致性，如果过期会进行清理释放。\n Data 节点是通过广播的方式来通知每个 session 节点？那每个 session 节点是否会存在所有服务的全量 Pub 数据？ 这对内存及网络资源消耗会不会过大？\n A：Data 是通过广播方式通知每个 session 节点，session上有订阅关系按照自己订阅关系判断是否需要推送给客户端。每个 session 没有全量的 pub 数据，但会存在和其连接部分客户端发布数据作为一致性备份回放使用。这个堆内存目前看压力还是可以的。\nSOFARegistry：https://github.com/sofastack/sofa-registry\n**3、@黄剑 **提问：\n 关于 Seata 有一个问题，全局锁用进去之后，意思就是要等 2 阶段完成后，进行当前资源释放，全局锁那边的接口才进行调用到，如果业务有很多地方都操作到相同表的某一条数据，那岂不是每个业务上面加全局锁？可是我并不知道哪些业务可能会有冲突的哇！\n A：目前只查锁不加锁。\n 我需要查到最终 2 阶段的那张表数据，意思自己的业务上面全部都要使用 @GlobalLock 注解？是这个意思么？\n A：如果你查询的业务接口没有 GlobalTransactional 包裹，也就是这个方法上压根没有分布式事务的需求，这时你可以在方法上标注 @GlobalLock 注解，并且在查询语句上加 for update。如果你查询的接口在事务链路上外层有 GlobalTransactional 注解，那么你查询的语句只要加 for update 就行。设计这个注解的原因是在没有这个注解之前，需要查询分布式事务读已提交的数据，但业务本身不需要分布式事务。若使用 GlobalTransactional 注解就会增加一些没用的额外的 rpc 开销比如 begin 返回 xid，提交事务等。GlobalLock 简化了 rpc 过程，使其做到更高的性能。\n 好的，感谢回复，因为现在出现了一个业务，但是不同接口，上游有全局事务来调用，然后又有其他业务操作了相同的表，所以现在导致我现在根本不知道哪些业务要考虑使用 GlobalLock。\n Seata：https://github.com/seata/seata\n本周推荐阅读  Service Mesh 发展趋势(续)：棋到中盘路往何方 | Service Mesh Meetup 实录 Service Mesh 发展趋势：云原生中流砥柱  SOFA 项目进展 本周发布详情如下：\n发布 SOFA Mosn v0.7.0，主要变更如下：\n 新增 FeatureGates 的支持 新增一项 Metrics 统计:mosn_process_time 支持 Listener 重启 升级 Go 版本到 1.12.7 修改 XDS Client 启动时机，优先于 MOSN Server 的启动 BUG 修复  详细发布报告： https://github.com/sofastack/sofa-mosn/releases/tag/0.7.0\n","date":1567148400,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20190830/","fuzzywordcount":1700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"afd535d1a14ed1fc010e93bcff36553d","permalink":"/blog/sofa-weekly-20190830/","publishdate":"2019-08-30T15:00:00+08:00","readingtime":4,"relpermalink":"/blog/sofa-weekly-20190830/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | 每周精选【8/26 - 8/30】","type":"blog","url":"/blog/sofa-weekly-20190830/","wordcount":1607},{"author":"敖小剑","categories":"Service Mesh","content":" 敖小剑，蚂蚁金服高级技术专家，十七年软件开发经验，微服务专家，Service Mesh 布道师，ServiceMesher 社区联合创始人。\n本文内容整理自 8 月 11 日 Service Mesher Meetup 广州站主题演讲，完整的分享 PPT 获取方式见文章底部。\n 前言 标题“Service Mesh发展趋势(续)”中的“续”是指在今年5月底，我在 CloudNative Meetup上做了一个“Service Mesh发展趋势：云原生中流砥柱”的演讲，当时主要讲了三块内容：Service Mesh 产品动态、发展趋势、与云原生的关系。后来有同学反应希望部分感兴趣的内容能讲的更深一些，所以今天将继续“Service Mesh 发展趋势”这个话题。\n今天给大家分享的内容有部分是上次演讲内容的深度展开，如社区关心的 Mixer v2 以及最近看到的一些业界新的技术方向，如 web assembly 技术，还有产品形态上的创新，如 google traffic director 对 Service Mesh 的虚拟机形态的创新支持。\n在 Service Mesh 出道四年之际，也希望和大家一起带着问题来对 Service Mesh 未来的发展进行一些深度思考。\n在正式开始分享之前，让我们先轻松一下，下面是最近流行的梗，各种灵魂拷问：\n我们今天的分享内容，将效仿上面的方式，对 Servic Mesh 进行四个深入灵魂的拷问。\nService Mesh 灵魂拷问一：要架构还是要性能？ 第一个灵魂拷问针对 Istio 的：要架构还是要性能？\nIstio 的回答：要架构 Istio 的回答很明确：架构优先，性能靠边。\n左边是 Istio 的架构图，从 2017 年的 0.1 版本开始，一直到 Istio1.0，控制平面和数据平面完全物理分离，包括我们今天要关注的 Mixer 模块。Sidecar 通过和 Mixer 的交互实现策略检查和遥测报告。\n右边是 Mixer 的架构图，在 Mixer 内部提供了很多 Adapter 实现，用来提供各种功能。这些 Adapter 运行在 Mixer 进程中，因此被称为进程内适配器（In-Process Adapter）。\n为什么 Istio 选择 Mixer 和 Proxy 分离的架构？\n我们先来看这个架构的优点，概括地说优点主要体现为：\n 架构优雅 职责分明 边界清晰  特别指出，上图右侧的红色竖线，是 Istio0.1 到 Istio1.0 版本中 Istio 和后台基础设施的边界。这意味着，从 k8s API Server 中读取 Adapter 相关的配置信息 （以 Istio CRD 的形式存在），是作为 Istio 功能的一部分。\n具体的优点是：\n Mixer 的变动不影响 Sidecar：包括 Mixer 的部署调整和版本升级； Sidecar 无需和 Adapter 耦合，具体有：  Sidecar 不需要读取配置，因此也无需直接连接到 k8s AP Server/Istio Galley； Adapter 的运行时资源开销和 Sidecar 无关； Sidecar 不受 Adapter 增减/更新/升级影响；   保持 Sidecar 代码简单：数以几十计的 Adapter 的代码无需直接进入 Sidecar 代码； 数据平面可替换原则：如果有替换数据平面的需求，则 Mixer 分离的架构会让事情简单很多；  至于缺点，只有一个：性能不好。\n而 1.1 版本之后，Istio 给出了新的回答：架构继续优先，性能继续靠边。\n上图是 Istio1.1 版本之后新的架构图，和之前的差异在于 Mixer 发生了变化，增加了进程外适配器（Out-of-Process Adapter），而 Mixer 和新的 Out-of-Process Adapter 之前依然是远程调用。\n为什么 Istio 改而选择 Out-of-Process Adapter?\n下图是采用 Out-of-Process Adapter 之后的请求处理流程图，Mixer 通过 Bypass Adapter 选择需要的属性列表，然后通过远程调用发送给 Out-of-Process Adapter。Out-of-Process Adapter 实现和之前的 In-Process Adapter 类似的功能，但是改为独立于 Mixer 的单独进程。\n采用 Out-of-Process Adapter 之后，Istio 的优点更加明显了，简单说就是：架构更优雅，职责更分明，边界更清晰。\n而且，请注意：按照 Istio 的设想，此时 Out-of-Process Adapter 已经不再作为 Istio 的组成部分，它的代码实现、安装部署、配置、维护等职责也不再由 Istio 承担，请留意上图中的红色竖线位置。Out-of-Process Adapter 的引入，对于 Istio 来说职责和边界的改变会让 Istio 简单，但是对于使用者（主要指运维）来说则增加了额外的负担，因此造成了很大的争议。\n至于缺点，除了上述的职责转移造成争议外，依然只有一个：性能不好，原来 Sidecar 和 Mixer 之间的远程调用已经让性能变得非常糟糕，现在 Mixer 和 Out-of-Process Adapter 之间再增多加一次远程调用，可谓雪上加霜。\nMixer v1 架构的优缺点分析 Mixer v1 架构的优点主要体现为：\n 集中式服务：提高基础设施后端的可用性，为前置条件检查结果提供集群级别的全局 2 级缓存； 灵活的适配器模型，使其以下操作变得简单：   运维添加、使用和删除适配器； 开发人员创建新的适配器（超过20个适配器）；  而 Mixer v1 架构的缺点，则主要体现为：\n 管理开销：   管理 Mixer 是许多客户不想负担的； 而进程外适配器强制运维管理适配器，让这个负担更加重；  性能：   即使使用缓存，在数据路径中同步调用 Mixer 也会增加端到端延迟； 进程外适配器进一步增加了延迟； 授权和认证功能是天然适合 mixer pipeline 的，但是由于 mixer 设计的延迟和 SPOF（单点故障）特性，导致直接在 Envoy 中实现(Envoy SDS)；  复杂性：   Mixer 使用一组称为模板的核心抽象，来描述传递给适配器的数据。这些包括“metrics”，“logentry”，“tracepan”等。这些抽象与后端想要消费的数据不匹配，导致运维需要编写一些手动配置，以便在规范的 Istio 样式和后端特定的样式之间进行映射。原本期望这种映射可以在适配器中实现很大程度上的自动化，但是最终还是太复杂并需要手动配置。   备注：上述优点和缺点的描述摘录自 mixer v2 proposal 。\n 其中，Mixer 性能问题一直以来都是 Istio 最被人诟病的地方。\n那问题来了：如果要性能，该怎么做？\n下图是 Mixer v1 的调用流程，Proxy/Sidecar 是请求数据的起点，Infrastructure Backend 是终点。Mixer …","date":1566972000,"description":"继续探讨 Service Mesh 发展趋势：深度分析 Istio 的重大革新 Mixer v2，Envoy 支持 Web Assembly 的意义所在；深入介绍 Google Traffic Director 对虚拟机模式的创新支持方式，以及最近围绕 SMI 发生的故事。","dir":"blog/service-mesh-development-trend-2/","fuzzywordcount":8100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"51e4af6a0771823fe055c5aebd2e76bd","permalink":"/blog/service-mesh-development-trend-2/","publishdate":"2019-08-28T14:00:00+08:00","readingtime":17,"relpermalink":"/blog/service-mesh-development-trend-2/","summary":"敖小剑，蚂蚁金服高级技术专家，十七年软件开发经验，微服务专家，Service Mesh 布道师，ServiceMesher 社区联合创始人。 本文内容整理","tags":["Service mesh"],"title":"Service Mesh 发展趋势(续)：棋到中盘路往何方 | Service Mesh Meetup 实录","type":"blog","url":"/blog/service-mesh-development-trend-2/","wordcount":8086},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n1、@廖春涛 提问：\n 在 SOFAJRaft 中，snapshot load 后应该会有个日志重放的实现，但是我目前看代码没看到说 snapshot 和 LogEntry 有关联的地方，请问是什么关系呢？\n A：snapshot 就是为了压缩日志，以及加快新节点加入。snapshot 后，会将上上次的 snapshot 当时对应的日志级之前的删掉，为什么是上上次？ 因为本次 snapshot 的日志，可能还没有复制到所有 follower，这是一个小优化。 具体到日志重放，如果启动是 leader，会写入一条当前配置的日志，触发 fsm caller 的 onCommitted，然后去重放从 snapshot 的日志到最新的 committed 的日志到状态机。如果是 follower，安装 snapshot 后， leader 会发送该 snapshot 对应的日志之后的日志，走正常的复制流程，因此也会重放到最新的状态机。\n SOFAJRaft 当 Leader 的 Node 执行 apply 后，将 LogEntry 提交给 follower 是通过通知来进行的吗？是不是在 LogManagerImpl 里面的这串代码  A：这段是 wakeup replicators，复制日志到 follower 都是在 Replicator 中实现的。\n2、关于 Seata 的 grouplist 问题：\n 什么时候会用到 file.conf 中的 default.grouplist？\n A：当 registry.type=file 时会用到，其他时候不读。\n default.grouplist 的值列表是否可以配置多个？\n A：可以配置多个，配置多个意味着集群，但当 store.mode=file 时，会报错。原因是在 file 存储模式下未提供本地文件的同步，所以需要使用 store.mode=db，通过 db 来共享 TC 集群间数据\n 是否推荐使用 default.grouplist？\n A：不推荐，如问题1，当 registry.type=file 时会用到，也就是说这里用的不是真正的注册中心，不具体服务的健康检查机制当tc不可用时无法自动剔除列表，推荐使用 nacos 、eureka、redis、zk、consul、etcd3、sofa。registry.type=file 或 config.type=file 设计的初衷是让用户再不依赖第三方注册中心或配置中心的前提下，通过直连的方式，快速验证 Seata 服务。\n3、关于 Seata 事务分组：\n 什么是事务分组？\n A：事务分组是 Seata 的资源逻辑，类似于服务实例。在 file.conf 中的 my_test_tx_group 就是一个事务分组。\n 通过事务分组如何找到后端集群？\n A：首先程序中配置了事务分组（GlobalTransactionScanner 构造方法的 txServiceGroup 参数），程序会通过用户配置的配置中心去寻找 service.vgroup_mapping. 事务分组配置项，取得配置项的值就是 TC 集群的名称。拿到集群名称程序通过一定的前后缀+集群名称去构造服务名，各配置中心的服务名实现不同。拿到服务名去相应的注册中心去拉取相应服务名的服务列表，获得后端真实的 TC 服务列表。\n 为什么这么设计，不直接取服务名？\n A：这里多了一层获取事务分组到映射集群的配置。这样设计后，事务分组可以作为资源的逻辑隔离单位，当发生故障时可以快速 failover。\nSOFA 项目进展 本周发布详情如下：\n1、发布 Seata v0.8.0 版本，主要变更如下：\n 支持 oracle 数据库的 AT 模式 支持 oracle 数据库的批量操作 支持 undo_log 表名可配置 修复 xid 在 db 模式可重复的问题 优化数据镜像比对日志  详细参考发布报告：https://github.com/seata/seata/releases/tag/v0.8.0\n2、发布 SOFAARK v1.0.0 版本，主要变更如下：\n 支持插件批量导出资源和 ark-biz 禁止批量导入资源 支持指定版本调用，解决对于非激活状态的ark-biz服务访问问题（主要用于灰度验证，测试等） 支持打包时跳过打ark-executable 包的过程（优化） 支持从目录运行启动 ArkClient api 支持指定 biz 的 arguments 参数 使用 netty 代替 java NIO 实现 telnet server 支持 SpringBoot testNG 优化示例工程   详细发布报告：https://github.com/sofastack/sofa-ark/releases/tag/v1.0.0\nSOFA 活动推荐 SOFA:Channel/线上直播第 8 期报名中~ 8 月 29 日周四晚 7 点，将邀请 SOFAJRaft 开源负责人力鲲，从一个 SOFAJRaft 实例出发，带大家体验 SOFAJRaft 的应用。\n 本期主题：SOFAChannel#8：从一个例子开始体验 SOFAJRaft 直播时间：8 月 29 日下周四晚 7点 你将收获：  如何使用 SOFAJRaft 实现自己的分布式应用 基于实例理解 SOFAJRaft 中的概念和术语   报名方式：点击“这里” 欢迎加入直播互动钉钉群：23390449（搜索群号加入即可）  ","date":1566543600,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20190823/","fuzzywordcount":1900,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"067db1c93be21087cc809be0294c1b32","permalink":"/blog/sofa-weekly-20190823/","publishdate":"2019-08-23T15:00:00+08:00","readingtime":4,"relpermalink":"/blog/sofa-weekly-20190823/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | 每周精选【8/19 - 8/23】","type":"blog","url":"/blog/sofa-weekly-20190823/","wordcount":1855},{"author":"苟利","categories":"SOFAMeetup","content":"作者：苟利（陈自欣），蚂蚁金服中间件产品专家， 负责蚂蚁金服分布式链路跟踪系统的产品化工作，在日志分析、监控领域有多年工作经验。\n本文根据 8 月 11 日 SOFA Meetup#3 广州站 《蚂蚁金服在云原生架构下的可观察性的探索和实践》主题分享整理。现场回顾视频以及 PPT 查看地址见文末链接。\n前言 随着应用架构往云原生的方向发展，传统监控技术已经不能满足云原生时代运维的需求，因此，可观察性的理念被引入了 IT 领域。\n下面我将会就可观察性在云原生的起源，可观察性发展动力， 可观察性与监控的关系，可观察性的三大支柱，社区发展方向及产品现状，以及蚂蚁金服对相关问题的理解及实践进行探讨。\n才疏学浅，欢迎拍砖。\n为什么云原生时代需要可观察性 可观察性的由来 在云原生语境下的可观察性这个词，最早出现于2017年7月， Cindy Sridharan 在 Medium 写的一篇博客， \u0026amp;ldquo;Monitoring and Observability\u0026amp;quot;，谈到了可观察性与云原生监控的关系。\n而在2017年10月， 来自 Pivotal 公司的 Matt Stine，在接受 InfoQ 采访的时候，对云原生的定义进行了调整， 将Cloud Native Architectures 定义为具有以下六个特质：\n 模块化 （Modularity） (通过微服务) 可观察性 （Observability） 可部署性 （Deployability） 可测试性 （Testability） 可处理性 （Disposability） 可替换性 （Replaceability）  可见，在2017年下半年， 可观察性成为了一个 buzzword（时髦词） ，正式出现在了云计算领域。\n可观察性的定义 虽然“可观察性”这个词在 IT 行业是一个新的术语，但它其实是在上世纪60年代，由匈牙利裔工程师鲁道夫·卡尔曼提出的概念。\n术语“可观察性”，源于控制论，是指系统可以由其外部输出推断其内部状态的程度。\n这个外部输出， 在云原生的语境下，即 Telemetry ，遥测，通常由服务（services）产生，划分为三个维度或者说支柱， Tracing（跟踪），Metrics（指标） , Logging（日志）。\n为什么云原生需要可观察性 近年可以看到，云计算对基础架构改变甚为巨大，无论是互联网行业，还是传统行业，云化在提升资源利用率，提高业务敏捷性的价值已经成为了公式。而在应用层面，由于业务特性的原因，互联网公司大部分已经完成云化，应用架构也不同程度上，完成了从单体应用向微服务应用演进。 在转型后，整体系统复杂性大大增加，倒逼相应的工具及方法论进行升级改造， 去 hold 住这么复杂的局面。\n上图为 Uber 展示的总体调用链图。考虑到业务多样性及复杂度，在蚂蚁金服内部，相关调用关系只会更为复杂，用人类的智力，已经没有办法去理解如此复杂的调用关系。而上图只是展示了可观察性的链路调用， 如果再加上指标及日志， 不对工具及方法论进行革新， 是难以实现对复杂微服务架构的管控的。\n微服务只是云原生的模块化特性的体现， 再考虑到近年被广泛应用容器，Kubernetes , 以及大家关注度极高的 Service Mesh , Istio， 每一个新的技术的出现，在带来了更优雅的架构、更灵活的调度、更完善的治理的同时，也带来更多新的复杂性。\n因此，可观察性对于云原生的应用架构，是必不可少的特性。\n可观察性和传统监控的区别 说半天，不少同学就会说，这个可观察性与我们谈的最多的监控有什么区别。 虽然有不少的人认为， 这词就是个buzzword，就是赶时髦的，没有太大的意义， 但是我结合网上的讨论， 个人认为可观察性与监控， 含义上虽然接近，但是也有一些理念上的差别，使得讨论可观察性这个词，是有具有现实意义，并能真正产生相应的价值。\n 监控更多关注的是基础设施，更多与运维工程师相关，更强调是从外部通过各种技术手段去看内部，打开黑盒系统。 可观察性更多的是描述应用，在我们谈论具体某应用，或者是某些应用是否具备客观性的时候，通常与开发人员相关，因为在常见的可观察性的实践之中，开发人员需要在应用的开发过程中嵌入例如 statd 或者是 opentracing，或者是 opencensus 等所提供的库，对相关的 telemetry 进行输出，或者是俗话说的埋点。通过埋点，将服务内部的状态白盒化，使得其在运维阶段具备可观察性。某种程度上可以说，可观察性遵循了 DevOps 及 SRE 的理念，即研发运维一体化，从开发侧就考虑系统的可运维性。   这里值得补充说明的是，目前市面上，有商用或者开源APM 方案，通过入侵 JVM 或者其他技术手段，对应用进行自动埋点的，输出 trace 及 metrics 信息。 这同样也是一种可观察性的实现方式，这样做的最大的好处是，不需要对现有的应用进行改造，但是相应的 agent 对应用进行实时的监控， 必然会或多或少的增加资源的占用，例如每实例额外 30+MB 内存，5~10% 的 CPU 占用，在大规模的运行环境之中， 会有不少的成本增加。\n可观察性的三大支柱及社区进展 可观察性的三大支柱 可观察性的三大支柱及其之间的关系， Peter Bourgon 在2017年2月撰写了一篇简明扼要的文章， 叫 \u0026amp;ldquo;Metrics, tracing, and logging\u0026amp;rdquo; ， 有兴趣的可以去看一下， 以下仅为简单的提及。\n指标数据（Metrics Data） 描述具体某个对象某个时间点的值。在 Prometheus 中， 指标有四种类型，分别 Counter（计数器）、Gauge（瞬时值）、Histogram（直方图）和 Summary （概要）， 通过这四种类型，可以实现指标的高效传输和存储。\n日志数据 ( Logging Data） 描述某个对象的是离散的事情，例如有个应用出错，抛出了 NullPointerExcepction，或者是完成了一笔转账，个人认为 Logging Data 大约等同于 Event Data，所以告警信息在我认为，也是一种 Logging Data。 但是也有技术团队认为，告警应该算是可观察性的其中一个支柱。 跟踪数据（Tracing Data） Tracing Data 这词貌似现在还没有一个权威的翻译范式，有人翻译成跟踪数据，有人翻译成调用数据，我尽量用Tracing 这个词。 Tracing 的特点就是在单次请求的范围内处理信息，任何的数据、元数据信息都被绑定到系统中的单个事务上。 一个Trace 有一个唯一的Trace ID ，并由多个Span 组成。\n社区方案进展 由于可观察性在云原生中，是一个非常重要的特性， 因此，在开源世界中，先后出现了两个定位都比较类似的项目，分别是源自 Google 的 OpenCensus （定位上报 Tracing + metris） 和由 CNCF 孵化的 OpenTracing（定位上报 Tracing）。 两者都定位于提供厂商中立的技术规范，及实现该规范各种编程语言遥测库，使得用户在使用了相关的库以后，可以将 …","date":1566381600,"description":"本文根据 8 月 11 日 SOFA Meetup#3 广州站 《蚂蚁金服在云原生架构下的可观察性的探索和实践》主题分享整理，文中包含本次分享视频回顾以及 PPT 查看地址。","dir":"blog/sofa-meetup-3-cloud-original-retrospect/","fuzzywordcount":4800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"85eba21fd9adf73841d7b7ee103723ae","permalink":"/blog/sofa-meetup-3-cloud-original-retrospect/","publishdate":"2019-08-21T18:00:00+08:00","readingtime":10,"relpermalink":"/blog/sofa-meetup-3-cloud-original-retrospect/","summary":"作者：苟利（陈自欣），蚂蚁金服中间件产品专家， 负责蚂蚁金服分布式链路跟踪系统的产品化工作，在日志分析、监控领域有多年工作经验。 本文根据 8 月 11","tags":["SOFAMeetup"],"title":"蚂蚁金服在云原生架构下的可观察性的探索和实践 | Meetup#3 回顾","type":"blog","url":"/blog/sofa-meetup-3-cloud-original-retrospect/","wordcount":4757},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\n本周推荐阅读  分布式事务 Seata Saga 模式首秀以及三种模式详解 | Meetup#3 回顾 中国移动苏州研发中心消息队列高可用设计之谈 | SOFAStack 用户说 溢米教育推荐平台的效率与稳定性建设 | SOFAStack 用户说  SOFA 项目进展 本周发布详情如下：\n发布 SOFAJRaft v1.2.6, 主要变更如下：\n i. 修复 ReadIndex 并发情况下可能出现的读超时 ii. 保存 raft meta 失败后终止状态机 iii. 增加 LogEntry checksum validation iv. 优化 log replication 线程模型减少锁竞争 v. 优化 RheaKV multi group snapshot vi. 致谢（排名不分先后）@SteNicholas @zongtanghu  详细参考发布报告：https://github.com/sofastack/sofa-jraft/releases/tag/1.2.6\nSOFA 活动推荐  SOFA:Channel/线上直播第 8 期《**从一个例子开始体验 SOFAJRaft》**报名中~\n8 月 29 日周四晚 7 点，将邀请 SOFAJRaft 开源负责人力鲲，从一个 SOFAJRaft 实例出发，带大家体验 SOFAJRaft 的应用。 在本次直播中，我们将重点放在如何去使用这个工具上，用示例来说明如何使用 SOFAJRaft 实现自己的分布式应用。在此过程中，我们会对涉及到的一些 SOFAJRaft 经典概念进行讲解。\n| 点击“这里”即可报名\n| 本期将带来：\n 如何使用 SOFAJRaft 实现自己的分布式应用 基于实例理解 SOFAJRaft 中的概念和术语  | 加入 SOFA 钉钉互动群 欢迎加入直播互动钉钉群：23390449（搜索群号加入即可）\n","date":1565942400,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20190816/","fuzzywordcount":800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"277754f72430d4473dc3920edbaf2ddb","permalink":"/blog/sofa-weekly-20190816/","publishdate":"2019-08-16T16:00:00+08:00","readingtime":2,"relpermalink":"/blog/sofa-weekly-20190816/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | 每周精选【8/12 - 8/16】","type":"blog","url":"/blog/sofa-weekly-20190816/","wordcount":722},{"author":"潘潘","categories":"SOFAChannel","content":"概要   活动主题：SOFAChannel#8：从一个例子开始体验 SOFAJRaft\n  活动时间：8 月 29 日周四晚 7 点\n  活动形式：线上直播\n  视频回顾：https://tech.antfin.com/community/live/821\n  介绍 | SOFAChannel \u0026amp;lt;SOFA:Channel/\u0026amp;gt; 有趣实用的分布式架构频道：前沿技术、直播 Coding、观点“抬杠”，多种形式。\n\u0026amp;lt;SOFA:Channel/\u0026amp;gt; 将作为 SOFA 所有在线内容的承载，包含直播/音视频教程，集中体现 SOFAStack 的能力全景图。\n| SOFAChannel#8：从一个例子开始体验 SOFAJRaft SOFAJRaft 是 Raft 算法的 Java 实现，其本质是一个工具项目。在本次直播中，我们将重点放在如何去使用这个工具上，用示例来说明如何使用 SOFAJRaft 实现自己的分布式应用。在此过程中，我们会对涉及到的一些 SOFAJRaft 经典概念进行讲解。\n为了更好地直播体验，可以在直播前，预习 SOFAJRaft 相关源码解析文章，文章集合：https://www.sofastack.tech/tags/sofajraft/\n8 月 29 日周四晚 7 点，将邀请 SOFAJRaft 开源负责人力鲲，从一个 SOFAJRaft 实例出发，带大家体验 SOFAJRaft 的应用。\n| 加入 SOFA 钉钉互动群 欢迎加入直播互动钉钉群：23195297（搜索群号加入即可）\n| 点击即可报名 https://tech.antfin.com/community/live/737\n议程 19:00-19:05 主持人开场 SOFAGirl 主持人\n19:05-20:00 SOFAChannel#8：从一个例子开始体验 SOFAJRaft 力鲲 SOFAJRaft 开源负责人\n本期分享大纲：  如何使用 SOFAJRaft 实现自己的分布式应用 基于实例理解 SOFAJRaft 中的概念和术语  嘉宾  SOFAGirl 主持人 力鲲 SOFAJRaft 开源负责人  ","date":1565842200,"description":"8 月 29 日周四晚 7 点，线上直播第 8 期。","dir":"activities/sofa-channel-8/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"92590333a35992bc201c798645cbf7ea","permalink":"/activities/sofa-channel-8/","publishdate":"2019-08-15T12:10:00+08:00","readingtime":2,"relpermalink":"/activities/sofa-channel-8/","summary":"概要 活动主题：SOFAChannel#8：从一个例子开始体验 SOFAJRaft 活动时间：8 月 29 日周四晚 7 点 活动形式：线上直播 视频回顾：https://tec","tags":["SOFAChannel","SOFAJRaft"],"title":"SOFAChannel#8：从一个例子开始体验 SOFAJRaft","type":"activities","url":"/activities/sofa-channel-8/","wordcount":561},{"author":"屹远","categories":"Seata","content":"作者：屹远（陈龙），蚂蚁金服分布式事务核心研发 。 本文根据 8月11日 SOFA Meetup#3 广州站 《分布式事务 Seata 及其三种模式详解》主题分享整理，着重分享分布式事务产生的背景、理论基础，以及 Seata 分布式事务的原理以及三种模式（AT、TCC、Saga）的分布式事务实现。\n本次分享的视频回顾以及 PPT 查看地址：https://tech.antfin.com/community/activities/779/review\n一、分布式事务产生的背景 1.1 分布式架构演进之 - 数据库的水平拆分 蚂蚁金服的业务数据库起初是单库单表，但随着业务数据规模的快速发展，数据量越来越大，单库单表逐渐成为瓶颈。所以我们对数据库进行了水平拆分，将原单库单表拆分成数据库分片。\n如下图所示，分库分表之后，原来在一个数据库上就能完成的写操作，可能就会跨多个数据库，这就产生了跨数据库事务问题。\n1.2 分布式架构演进之 - 业务服务化拆分 在业务发展初期，“一块大饼”的单业务系统架构，能满足基本的业务需求。但是随着业务的快速发展，系统的访问量和业务复杂程度都在快速增长，单系统架构逐渐成为业务发展瓶颈，解决业务系统的高耦合、可伸缩问题的需求越来越强烈。\n如下图所示，蚂蚁金服按照面向服务架构（SOA）的设计原则，将单业务系统拆分成多个业务系统，降低了各系统之间的耦合度，使不同的业务系统专注于自身业务，更有利于业务的发展和系统容量的伸缩。\n业务系统按照服务拆分之后，一个完整的业务往往需要调用多个服务，如何保证多个服务间的数据一致性成为一个难题。\n二、分布式事务理论基础 2.1 两阶段提交协议 两阶段提交协议：事务管理器分两个阶段来协调资源管理器，第一阶段准备资源，也就是预留事务所需的资源，如果每个资源管理器都资源预留成功，则进行第二阶段资源提交，否则协调资源管理器回滚资源。\n2.2 TCC TCC（Try-Confirm-Cancel） 实际上是服务化的两阶段提交协议，业务开发者需要实现这三个服务接口，第一阶段服务由业务代码编排来调用 Try 接口进行资源预留，所有参与者的 Try 接口都成功了，事务管理器会提交事务，并调用每个参与者的 Confirm 接口真正提交业务操作，否则调用每个参与者的 Cancel 接口回滚事务。\n2.3 Saga Saga 是一种补偿协议，在 Saga 模式下，分布式事务内有多个参与者，每一个参与者都是一个冲正补偿服务，需要用户根据业务场景实现其正向操作和逆向回滚操作。\n分布式事务执行过程中，依次执行各参与者的正向操作，如果所有正向操作均执行成功，那么分布式事务提交。如果任何一个正向操作执行失败，那么分布式事务会退回去执行前面各参与者的逆向回滚操作，回滚已提交的参与者，使分布式事务回到初始状态。\nSaga 理论出自 Hector \u0026amp;amp; Kenneth 1987发表的论文 Sagas。\nSaga 正向服务与补偿服务也需要业务开发者实现。\n三、Seata 及其三种模式详解 3.1 分布式事务 Seata 介绍 Seata（Simple Extensible Autonomous Transaction Architecture，一站式分布式事务解决方案）是 2019 年 1 月份蚂蚁金服和阿里巴巴共同开源的分布式事务解决方案。Seata 开源半年左右，目前已经有超过 1.1 万 star，社区非常活跃。我们热忱欢迎大家参与到 Seata 社区建设中，一同将 Seata 打造成开源分布式事务标杆产品。\nSeata：https://github.com/seata/seata\n3.2 分布式事务 Seata 产品模块 如下图所示，Seata 中有三大模块，分别是 TM、RM 和 TC。 其中 TM 和 RM 是作为 Seata 的客户端与业务系统集成在一起，TC 作为 Seata 的服务端独立部署。\n在 Seata 中，分布式事务的执行流程：\n TM 开启分布式事务（TM 向 TC 注册全局事务记录）； 按业务场景，编排数据库、服务等事务内资源（RM 向 TC 汇报资源准备状态 ）； TM 结束分布式事务，事务一阶段结束（TM 通知 TC 提交/回滚分布式事务）； TC 汇总事务信息，决定分布式事务是提交还是回滚； TC 通知所有 RM 提交/回滚 资源，事务二阶段结束；  3.3 分布式事务 Seata 解决方案 Seata 会有 4 种分布式事务解决方案，分别是 AT 模式、TCC 模式、Saga 模式和 XA 模式。\n3.3.1 AT 模式 今年 1 月份，Seata 开源了 AT 模式。AT 模式是一种无侵入的分布式事务解决方案。在 AT 模式下，用户只需关注自己的“业务 SQL”，用户的 “业务 SQL” 作为一阶段，Seata 框架会自动生成事务的二阶段提交和回滚操作。\nAT 模式如何做到对业务的无侵入 ：  一阶段：  在一阶段，Seata 会拦截“业务 SQL”，首先解析 SQL 语义，找到“业务 SQL”要更新的业务数据，在业务数据被更新前，将其保存成“before image”，然后执行“业务 SQL”更新业务数据，在业务数据更新之后，再将其保存成“after image”，最后生成行锁。以上操作全部在一个数据库事务内完成，这样保证了一阶段操作的原子性。\n 二阶段提交：  二阶段如果是提交的话，因为“业务 SQL”在一阶段已经提交至数据库， 所以 Seata 框架只需将一阶段保存的快照数据和行锁删掉，完成数据清理即可。\n 二阶段回滚：  二阶段如果是回滚的话，Seata 就需要回滚一阶段已经执行的“业务 SQL”，还原业务数据。回滚方式便是用“before image”还原业务数据；但在还原前要首先要校验脏写，对比“数据库当前业务数据”和 “after image”，如果两份数据完全一致就说明没有脏写，可以还原业务数据，如果不一致就说明有脏写，出现脏写就需要转人工处理。\nAT 模式的一阶段、二阶段提交和回滚均由 Seata 框架自动生成，用户只需编写“业务 SQL”，便能轻松接入分布式事务，AT 模式是一种对业务无任何侵入的分布式事务解决方案。\n3.3.2 TCC 模式 2019 年 3 月份，Seata 开源了 TCC 模式，该模式由蚂蚁金服贡献。TCC 模式需要用户根据自己的业务场景实现 Try、Confirm 和 Cancel 三个操作；事务发起方在一阶段执行 Try 方式，在二阶段提交执行 Confirm 方法，二阶段回滚执行 Cancel 方法。\nTCC 三个方法描述：\n Try：资源的检测和预留； Confirm：执行的业务操作提交；要求 Try 成功 Confirm 一定要能成功； Cancel：预留资源释放；  蚂蚁金服在 TCC 的实践经验\n1 TCC 设计 - 业务模型分 2 阶段设计：\n用户接入 TCC ，最重要的是考虑如何将自己的业务模型拆成两阶段来实现。\n以“扣钱”场景为例，在接入 TCC 前，对 A 账户的扣钱，只需一条更新账户余额的 SQL 便能完成；但是在接入 TCC 之后，用户就需要考虑如何将原来一步就能完成 …","date":1565776800,"description":"本文根据 8月11日 SOFA Meetup#3 广州站 《分布式事务 Seata 及其三种模式详解》主题分享整理，文中包含本次分享视频回顾以及 PPT 查看地址。","dir":"blog/sofa-meetup-3-seata-retrospect/","fuzzywordcount":5800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"841ac02b2ce20e10748bf97db9d644ec","permalink":"/blog/sofa-meetup-3-seata-retrospect/","publishdate":"2019-08-14T18:00:00+08:00","readingtime":12,"relpermalink":"/blog/sofa-meetup-3-seata-retrospect/","summary":"作者：屹远（陈龙），蚂蚁金服分布式事务核心研发 。 本文根据 8月11日 SOFA Meetup#3 广州站 《分布式事务 Seata 及其三种模式详解》主题分享整理，着重分享分布式事务","tags":["Seata","SOFAMeetup"],"title":"分布式事务 Seata Saga 模式首秀以及三种模式详解 |  Meetup#3 回顾","type":"blog","url":"/blog/sofa-meetup-3-seata-retrospect/","wordcount":5793},{"author":"胡宗棠","categories":"SOFAJRaft","content":"文章摘要：BC-MQ 是中国移动苏州研发中心结合自身在云计算产品和技术的较多积累、自主研发的大云消息队列中间件产品，本文详细解读了 SOFAJRaft 在其消息云服务中的最佳应用实践。\n前言： 高可用的定义，指的是“一个系统经过特有的设计与改造，减少因不确定故障停服的时间，从而对业务使用方来说可以保证其服务的高度可用性”。在生产环境中，往往会存在很多不可预知的故障因素，比如虚拟机宕机、磁盘损坏和网络故障等，因此系统自身的高可用是任何工业级产品所需重点考虑的因素。\n对于消息队列服务来说，考虑到故障切换和业务感知等问题，传统的高可用方式（冷备或者热备）一般都不太适用。在经过多种技术方案对比后，我们发现采用基于 Raft 共识算法的多副本设计方案可以满足我们产品的要求，因此在鉴权认证组件和API计量服务组件中，我们集成了蚂蚁金服开源的 SOFAJRaft 库，实现这两个组件应对单点故障的高可用。\nGitHub 地址：https://github.com/sofastack/sofa-jraft\n一、背景知识：Raft 共识性算法是什么？ Raft 是一种分布式系统中易于理解的共识算法，该协议本质上是 Paxos 算法的精简版，而不同的是依靠 Raft 模块化的拆分以及更加简化的设计，其实现起来更加容易和方便。[1]\n模块化的拆分主要体现在 Raft 把一致性协议划分为如下几部分：\n Leader 选举； Membership 变更； 日志复制； Snapshot。  而更加简化的设计则体现在：Raft 不允许类似 Paxos 中的乱序提交、简化系统中的角色状态（算法定义 Leader、Follower 和 Candidate 三种角色）、限制仅 Leader 可写入、采用随机超时触发 Leader Election 机制来避免“瓜分选票”等等。[2]\n1.1 Raft 算法的整体结构概览 从上面的 Raft 算法整体结构图中可以看出，整个分布式系统中同一时刻有且仅有一个 Leader 角色的节点（如图最右边的服务器），只有 Leader 节点可以接受 Client 发送过来的请求。Leader 节点负责主动与所有 Follower 节点进行网络通信（如图左边两个服务器），负责将本地的日志发送给所有 Follower 节点，并收集分布式系统中多数派的 Follower 节点的响应。此外，Leader 节点，还需向所有 Follower 节点主动发送心跳维持领导地位（即：保持存在感）。\n所以，只要各个节点上的日志保持内容和顺序是一致的，那么节点上的状态机就能以相同的顺序执行相同的命令，这样它们执行的结果也都是一样的。\n1.2 Raft 算法的三种角色及转换  Follower：完全被动，不能发送任何请求，只接受并响应来自 Leader 和 Candidate 的 Message，每个节点启动后的初始状态一般都是 Follower； Leader：处理所有来自客户端的请求、复制 Log 到所有 Follower，并且与 Follower 保持心跳请求； Candidate：节点竞选 Leader 时的状态。Follower 节点在参与选举之前，会将自己的状态转换为 Candidate。  1.3 任期与逻辑时钟概念  时间被划分为多个任期 term（如同总统选举一样），term id 按时间轴单调递增； 每一个任期开始后要做的第一件事都是选举 Leader 节点，选举成功之后，Leader 负责在该任期内管理整个分布式集群，“日志复制”、“通过心跳维护自己的角色”； 每个任期至多只有一个 Leader 节点，也可能没有 Leader (由于“分票”导致)。  1.4 Raft 算法的实际应用实现 目前，Raft 算法已经成熟地应用于诸多知名的开源项目中。业界非常著名的 Etcd(Kubernetes 高可用强一致性的服务发现组件)和 TiKV (高性能开源 KV 存储)均是 Raft 算法的实现。\n二、BC-MQ 基于 Raft 的高可用设计 为满足企业上云和构建万物相连的物联网业务需求，中国移动苏州研发中心结合自身在云计算产品和技术的较多积累，研发了大云消息队列中间件产品 BC-MQ。该产品基于 Apache 开源社区的 RocketMQ 内核，同时结合云端 PAAS 产品架构和消息中间件的应用业务需求进行深度优化和定制化的研发，提供了一款可以满足于云端场景的高性能、高可靠、低延迟和高可用的工业级产品。\n本节从解决原有高可用技术方案的问题视角出发，同时结合选型 SOFAJRaft 库的缘由，将详细阐述 BC-MQ 产品中的安全认证和 API 计量采集服务的高可用设计方案（注：这里不会涉及到安全认证和 API 计量采集组件本身的技术方案细节）。\n2.1 GlusterFS+Keepalived 高可用方案与问题 1. GlusterFS+Keepalived 高可用设计方案 在BC-MQ原有的方案中，多组安全认证服务各自独立部署组建集群，各个安全认证服务相互独立，没有主从关联，服务本身无状态，可水平任意扩展。安全认证服务的高可用依赖于RPC通信的客户端保证，其主要通过负载均衡算法从安全认证服务集群选择一个节点发送RPC请求来实现租户级鉴权认证元数据的获取。在生产环境中，如果出现其中一个安全认证节点宕机不可用时，客户端的RPC通信层能够及时感知并从本地的Node列表中剔除不可用节点。\n集群中有状态的租户级安全认证元数据的强一致性由GlusterFS分布式文件存储的同步机制来保证。安全认证服务组建高可用集群的具体设计方案图如下所示：\n而 BC-MQ 中 API 计量采集服务组件的高可用性则是依靠 Keepalived 组件的冷备模式结合 GlusterFS 分布式文件存储的同步机制共同保证，从而在一定程度上解决了 API 计量采集服务的单点不可用问题。API 计量采集服务的具体高可用设计方案图如下所示：\n2. GlusterFS+Keepalived 高可用方案遇到的问题 初步看上面的这种高可用技术方案挺完美的。但是经过验证和仔细推敲后就发现在生产环境中可能会存在如下几个问题：\n 上面所述的高可用设计方案中引入了 GlusterFS 分布式文件存储系统和 Keepalived 组件，这增加了系统整体的运维复杂度，给运维人员带来很多人工介入排查和部署的工作负担；另一方面，GlusterFS 和 Keepalived 本身的可靠性、稳定性和性能指标等问题也需要软件研发人员重点关注，这增加了系统整体设计的复杂度； 在实际的生产环境中，Keepalived 组件采用冷备方式作为高可用方案需要考虑主机故障宕机后切换到备机的时间成本消耗。在这段时间内，API 计量服务是短暂不可用的。因此，Keepalived 组件的主备切换会造成业务感知影响，导致一些业务的风险发生。  2.2 基于 SOFAJRaft 库的高可用设计方案 由于“GlusterFS+Keepalived”的高可用方案存在上一节阐述的两个问题，所以我们考虑是否可以采用其他的高可用方案来解决这两个问题？目标：即使生产环境出现部分节点故障后， …","date":1565694000,"description":"BC-MQ 是中国移动苏州研发中心结合自身在云计算产品和技术的较多积累、自主研发的大云消息队列中间件产品，本文详细解读了 SOFAJRaft 在其消息云服务中的最佳应用实践。","dir":"blog/sofa-jraft-user-china-mobile/","fuzzywordcount":6200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"a7eb984bdb11d8c0b47133af4c16f48f","permalink":"/blog/sofa-jraft-user-china-mobile/","publishdate":"2019-08-13T19:00:00+08:00","readingtime":13,"relpermalink":"/blog/sofa-jraft-user-china-mobile/","summary":"文章摘要：BC-MQ 是中国移动苏州研发中心结合自身在云计算产品和技术的较多积累、自主研发的大云消息队列中间件产品，本文详细解读了 SOFAJRaft 在其消息云","tags":["SOFAJRaft"],"title":"中国移动苏州研发中心消息队列高可用设计之谈 | SOFAStack 用户说","type":"blog","url":"/blog/sofa-jraft-user-china-mobile/","wordcount":6179},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。 **SOFAStack 官网: **https://www.sofastack.tech **SOFAStack: **https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动 我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n关于 SOFAJRaft 日志复制 - pipeline 实现剖析 | SOFAJRaft 实现原理 的讨论： @龚小涛 提问：\n 对于快照部分讲解是对某一刻时间点的数据做的快照吗，然后此快照最新的记录下 logindex term 等信息？\n A：快照里记录的数据不是日志复制的数据，而是状态机执行的结果，这个快照数据保存的动作是由用户通过实现这个接口来实现的： com.alipay.sofa.jraft.StateMachine#onSnapshotSave 。当然，里面的快照里面还包括了一些 index、term 等元信息。所以如果你理解的数据是由状态机执行的结果，那理解是对的。\n 关于快照的解决方案中是对数据集合的快照，这里可以细说下吗？\n A：快照中保存的是用户自定义的状态机的当前的状态，具体内容需要用户自己去实现，你可以看下这个接口： com.alipay.sofa.jraft.StateMachine#onSnapshotSave，比如 Counter 这个 example 中，保存的就是计数器当前的 value。\nSOFAJRaftLab 系列阅读  SOFAJRaft 日志复制 - pipeline 实现剖析 | SOFAJRaft 实现原理 SOFAJRaft-RheaKV MULTI-RAFT-GROUP 实现分析 | SOFAJRaft 实现原理 SOFAJRaft 选举机制剖析 | SOFAJRaft 实现原理 SOFAJRaft 线性一致读实现剖析 | SOFAJRaft 实现原理 SOFAJRaft-RheaKV 是如何使用 Raft 的 | SOFAJRaft 实现原理 生产级 Raft 算法库 SOFAJRaft 存储模块剖析 | SOFAJRaft 实现原理  SOFA 项目进展 本周发布详情如下：\n发布 SOFARegistry 5.2.1, 主要变更如下： i. 安全修改，升级 Jettyserver 版本到 9.4.17.v20190418. ii. jraft bug 修正版本到1.2.5 iii. 修复 dataServer 启动没有 working 时刻一些操作延迟处理问题 iv. data 重连 meta 逻辑 bug 导致所有 data 无法连接 meta 修改 v. data 从 working 状态变回 init 状态 bug 修改 详细发布报告： https://github.com/sofastack/sofa-registry/releases/tag/v5.2.1\nSOFA 活动推荐 SOFA Meetup #3**《从开源技术到产品能力》，**本周日我们在广州等你~\n本期活动将为大家带来蚂蚁金服在这些方面的探索和实践，解析 SOFARPC、分布式事务 Seata、无线自动化测试框架 SoloPi 等开源项目的内部大规模落地和社区发展，并且通过可观察性的理念，实现对微服务，Service Mesh 以至未来的 Serverless 架构的应用进行监控，帮助大家应对从应用架构过渡到云原生架构的挑战。\n报名方式：点击“这里”了解活动详情。\n","date":1565337600,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20190809/","fuzzywordcount":1100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"31aa100cb2b1edaacaa1874644af50ff","permalink":"/blog/sofa-weekly-20190809/","publishdate":"2019-08-09T16:00:00+08:00","readingtime":3,"relpermalink":"/blog/sofa-weekly-20190809/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | 每周精选【8/5 - 8/9】","type":"blog","url":"/blog/sofa-weekly-20190809/","wordcount":1021},{"author":"力鲲、徐家锋","categories":"SOFAJRaft","content":" SOFAStack（Scalable Open Financial Architecture Stack） 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。\n SOFAJRaft 是一个基于 Raft 一致性算法的生产级高性能 Java 实现，支持 MULTI-RAFT-GROUP，适用于高负载低延迟的场景。\n本文为《剖析 | SOFAJRaft 实现原理》第六篇，本篇作者徐家锋，来自专伟信息，力鲲，来自蚂蚁金服。《剖析 | SOFAJRaft 实现原理》系列由 SOFA 团队和源码爱好者们出品，项目代号：\u0026amp;lt;SOFA:JRaftLab/\u0026amp;gt;，文章尾部有参与方式，欢迎同样对源码热情的你加入。\nSOFAJRaft ：https://github.com/sofastack/sofa-jraft\n本文的目的是要介绍 SOFAJRaft 在日志复制中所采用的 pipeline 机制，但是作者落笔时突然觉得这个题目有些唐突，我们不应该假设读者理所应当的对日志复制这个概念已经了然于胸，所以作为一篇解析，我觉得还是应该先介绍一下 SOFAJRaft 中的日志复制是要解决什么问题。\n概念介绍 SOFAJRaft 是对 Raft 共识算法的 Java 实现。既然是共识算法，就不可避免的要对需要达成共识的内容在多个服务器节点之间进行传输，在 SOFAJRaft 中我们将这些内容封装成一个个日志块 (LogEntry)，这种服务器节点间的日志传输行为在 SOFAJRaft 中也就有了专门的术语：日志复制。\n为了便于阅读理解，我们用一个象棋的故事来类比日志复制的流程和可能遇到的问题。\n假设我们穿越到古代，要为一场即将举办的象棋比赛设计直播方案。当然所有电子通讯技术此时都已经不可用了，幸好象棋比赛是一种能用精简的文字描述赛况的项目，比如：“炮二平五”, “马８进７”, “车２退３”等，我们将这些描述性文字称为棋谱。这样只要我们在场外同样摆上棋盘 (可能很大，方便围观)，通过棋谱就可以把棋手的对弈过程直播出来。\n图1 - 通过棋谱直播\n所以我们的直播方案就是：赛场内两位棋手正常对弈，设一个专门的记录员来记录棋手走出的每一步，安排一个旗童飞奔于赛场内外，棋手每走一步，旗童就将其以棋谱的方式传递给场外，这样观众就能在场外准实时的观看对弈的过程，获得同观看直播相同的体验。\n图2 - 一个简单的直播方案\n这便是 SOFAJRaft 日志复制的人肉版，接下来我们完善一下这个“直播系统”，让它逐步对齐真实的日志复制。\n改进1. 增加记录员的数量 假设我们的比赛获得了很高的关注度，我们需要在赛场外摆出更多的直播场地以供更多的观众观看。\n这样我们就要安排更多的旗童来传递棋谱，场外的每一台直播都需要一个旗童来负责，这些旗童不停的在赛场内外奔跑传递棋谱信息。有的直播平台离赛场远一些，旗童要跑很久才行，相应的直播延迟就会大一些，而有些直播平台离得很近，对应的旗童就能很快的将对弈情况同步到直播。\n随着直播场地的增加，负责记录棋局的记录员的压力就会增加，因为他要针对不同的旗童每次提供不同的棋谱内容，有的慢有的快。如果记录员一旦记混了或者眼花了，就会出现严重的直播事故(观众看到的不再是棋手真正的棋局)。\n图4 - 压力很大的记录员\n为此我们要作出一些优化，为每个场外的直播平台安排一个专门的记录员，这样 “赛局-记录员-旗童-直播局” 就构成了单线模式，专人专职高效可靠。\n图5 - “赛局-记录员-旗童-直播棋局”\n改进2. 增加旗童每次传递的信息量 起初我们要求棋手每走一步，旗童就向外传递一次棋谱。可是随着比赛进行，其弊端也逐渐显现，一方面记录员记录了很多棋局信息没有传递出去，以至于不得不请求棋手停下来等待 (不可思议)；另一方面，场外的观众对于这种“卡帧”的直播模式也很不满意。\n所以我们做出改进，要求旗童每次多记几步棋，这样记录员不会积攒太多的待直播信息，观众也能一次看到好几步，而这对于聪明的旗童来说并不是什么难事，如此改进达到了共赢的局面。\n图6 - 旗童批量携带信息\n改进3. 增加快照模式 棋局愈发精彩，应棋迷的强烈要求，我们临时增加了几个直播场地，这时棋手已经走了很多步了，按照我们的常规手段，负责新直播的记录员和旗童需要把过去的每一步都在直播棋盘上还原一遍(回放的过程)，与此同时棋手还在不断下出新的内容。\n从直觉上来说这也是一种很不聪明的方式，所以这时我们采用快照模式，不再要求旗童传递过去的每一步棋谱，而是把当前的棋局图直接描下来，旗童将图带出去后，按照图谱直接摆子。这样新直播平台就能快速追上棋局进度，让观众欣赏到赛场同步的棋局对弈了。\n图7 - 采用快照模式\n改进4. 每一个直播平台用多个旗童传递信息 虽然我们之前已经在改进 2 中增加了旗童每次携带的信息量，但是在一些情况下(棋手下快棋、直播平台很远等)，记录员依然无法将信息及时同步给场外。这时我们需要增加多个旗童，各旗童有次序的将信息携带到场外，这样记录员就可以更快速的把信息同步给场外直播平台。\n图8 - 利用多个旗童传递信息，实现 pipeline 效果\n现在这个人肉的直播平台在我们的逐步改进下已经具备了 SOFAJRaft 日志复制的下面几个主要特点：\n特点1: 被复制的日志是有序且连续的 如果棋谱传递的顺序不一样，最后下出的棋局可能也是完全不同的。而 SOFAJRaft 在日志复制时，其日志传输的顺序也要保证严格的顺序，所有日志既不能乱序也不能有空洞 (也就是说不能被漏掉)。\n图9 - 日志保持严格有序且连续\n特点2: 复制日志是并发的 SOFAJRaft 中 Leader 节点会同时向多个 Follower 节点复制日志，在 Leader 中为每一个 Follower 分配一个 Replicator，专用来处理复制日志任务。在棋局中我们也针对每个直播平台安排一个记录员，用来将对弈棋谱同步给对应的直播平台。\n图10 - 并发复制日志\n特点3: 复制日志是批量的 SOFAJRaft 中 Leader 节点会将日志成批的复制给 Follower，就像旗童会每次携带多步棋信息到场外。\n图11 - 日志被批量复制\n特点4: 日志复制中的快照 在改进 3 中，我们让新加入的直播平台直接复制当前的棋局，而不再回放过去的每一步棋谱，这就是 SOFAJRaft 中的快照 (Snapshot) 机制。用 Snapshot 能够让 Follower 快速跟上 Leader 的日志进度，不再回放很早以前的日志信息，即缓解了网络的吞吐量，又提升了日志同步的效率。\n特点5: 复制日志的 pipeline 机制 在改进 4 中，我们让多个旗童参与信息传递，这样记录员和直播平台间就可以以“流式”的方式传递信息，这样既能保证信息传递有序也能保证信息传递持续。\n在 SOFAJRaft 中我们也有类似的机制来保证日志复制流式的进行，这种机制就是 pipeline。Pipeline 使得 Leader 和 Follower 双方不再需要严格遵从 “Request - Response - Request” 的交互模式，Leader 可 …","date":1565080200,"description":"本文为《剖析 | SOFAJRaft 实现原理》第六篇，本篇作者徐家锋、力鲲。","dir":"blog/sofa-jraft-pipeline-principle/","fuzzywordcount":4000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"c88030d7b6620240943e8326565b0ec2","permalink":"/blog/sofa-jraft-pipeline-principle/","publishdate":"2019-08-06T16:30:00+08:00","readingtime":8,"relpermalink":"/blog/sofa-jraft-pipeline-principle/","summary":"SOFAStack（Scalable Open Financial Architecture Stack） 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金","tags":["SOFAJRaft","SOFALab","剖析 | SOFAJRaft 实现原理"],"title":"SOFAJRaft 日志复制 - pipeline 实现剖析 | SOFAJRaft 实现原理","type":"blog","url":"/blog/sofa-jraft-pipeline-principle/","wordcount":3903},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答\n同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\n每周读者问答提炼 欢迎大家向公众号留言提问或在群里与我们互动\n我们会筛选重点问题通过 \u0026amp;quot; SOFA WEEKLY \u0026amp;quot; 的形式回复\n@屈冉 提问：\n SOFAJRaft 目前支持 Multi-Raft 嘛?\n A：支持的，可以参考 rheakv 实现，就是用的 multi raft group。\n 好的，另外想问一下，SOFAJRaft 有没有和 Braft 的性能比较数据，或者同类实现的？\n A：这里有一份 Benchmark 数据可以参考一下，我们暂时没有计划和同类实现对比性能：\nhttps://github.com/sofastack/sofa-jraft/wiki/Benchmark-%E6%95%B0%E6%8D%AE\nSOFA 开源系列  SoloPi：支付宝 Android 专项测试工具 | 开源 蚂蚁金服开源服务注册中心 SOFARegistry | SOFA 开源 蚂蚁金服分布式事务开源以及实践 | SOFA 开源 蚂蚁金服开源自动化测试框架 SOFAACTS 蚂蚁金服开源 SOFAJRaft：生产级 Java Raft 算法库  SOFA 项目进展 本周发布详情如下：\n1、发布 SOFATracer 2.4.1/3.0.6, 主要变更如下：\ni. 升级 Dubbo 版本至 2.7.3.\nii. 修复 Dubbo 插件中相关埋点参数获取问题\niii. 修复 Datasource 埋点中的若干问题\niv. Cheery pick 代码优化至 3.x 分支\n详细发布报告：\nhttps://github.com/sofastack/sofa-tracer/releases/tag/v2.4.1\nhttps://github.com/sofastack/sofa-tracer/releases/tag/v3.0.6\n2、发布 SOFA MOSN v0.6.0，主要变更如下：\ni. Listener 支持配置空闲连接超时关闭\nii. 日志新增 Alertf 接口\niii. 支持 SDS 方式获取证书\niv. Metrics统计与输出优化\nv. IO 协程优化\nvi. 后端模块实现重构，提升了动态更新性能，降低了内存的使用\nvii. racer 模块实现重构，支持更完善的扩展机制\n详细发布报告：\nhttps://github.com/sofastack/sofa-mosn/releases/tag/0.6.0\nSOFA 活动推荐 SOFA Meetup #3 广州站**《从开源技术到产品能力》**报名进行中~\n本期 SOFA Meetup 将带来开源技术：SOFARPC、Seata 模式详解以及发展进程，并拓展分享云原生产品能力，更有无线自动化测试框架 SoloPi 的首秀分享~\n8 月 11 日，我们广州见~\n报名方式：点击“这里”即可报名。\n","date":1564732800,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20190802/","fuzzywordcount":900,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"4edd066a5855f1a118fd562cfc299571","permalink":"/blog/sofa-weekly-20190802/","publishdate":"2019-08-02T16:00:00+08:00","readingtime":2,"relpermalink":"/blog/sofa-weekly-20190802/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | 每周精选【7/29- 8/2】","type":"blog","url":"/blog/sofa-weekly-20190802/","wordcount":822},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech\n**SOFAStack: **https://github.com/sofastack\n本周推荐阅读  大公司开源怎么做？SOFAStack 给出了一个很好的例子 对话鲁直：蚂蚁金服中间件的开源头羊 | 穿山甲专访  SOFAJRaftLab 系列阅读  SOFAJRaft-RheaKV MULTI-RAFT-GROUP 实现分析 | SOFAJRaft 实现原理 SOFAJRaft 选举机制剖析 | SOFAJRaft 实现原理 SOFAJRaft 线性一致读实现剖析 | SOFAJRaft 实现原理 SOFAJRaft-RheaKV 是如何使用 Raft 的 | SOFAJRaft 实现原理 生产级 Raft 算法库 SOFAJRaft 存储模块剖析 | SOFAJRaft 实现原理  SOFA 活动推荐  SOFA Meetup #3 广州站**《从开源技术到产品能力》**报名开始啦~\n本期 SOFA Meetup 将带来开源技术：SOFARPC、Seata 模式详解以及发展进程，并拓展分享云原生产品能力，更有无线自动化测试框架 Soloπ 的首秀分享~\n8 月 11 日，我们广州见~\n报名方式：点击“这里”了解活动详情。\n","date":1564124400,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20190726/","fuzzywordcount":500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"70e3dace7979772fdf90f9f5a47d2e13","permalink":"/blog/sofa-weekly-20190726/","publishdate":"2019-07-26T15:00:00+08:00","readingtime":1,"relpermalink":"/blog/sofa-weekly-20190726/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"（含活动报名）SOFA Weekly | 每周精选【7/22 - 7/26】","type":"blog","url":"/blog/sofa-weekly-20190726/","wordcount":489},{"author":"潘潘","categories":"SOFAMeetup","content":"概要  活动主题：SOFA Meetup#3 广州站-从开源技术到产品能力 活动时间：8 月 11 日周日下午 13 点 活动地点：广州市广电平云 B 塔 15F 活动形式：线下活动 报名方式：https://tech.antfin.com/community/activities/779  蚂蚁金服 SOFAStack SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，历经蚂蚁金服超过十年的业务历练。SOFAStack 于 2018 年 4 月宣布开源，并逐步开源 SOFABoot、SOFARPC、SOFALookout、SOFATracer、SOFAMosn、SOFAMesh 等组件。\n欢迎 Star 我：https://github.com/sofastack\nSOFA Meetup#3 广州站-从开源技术到产品能力 适合自身企业的技术架构才是最佳的方案，SOFAStack 提供了一套的金融级解决方案，提供多种场景下需要的多种组件。\n本期 SOFA Meetup 将带来开源技术：SOFARPC、Seata 模式详解以及发展进程，并拓展分享云原生产品能力，更有无线自动化测试框架 Soloπ 的首秀分享~\n随着应用架构往云原生的方向发展，传统监控手段已经不能满足云原生时代运维的需求，因此，可观察性的理念被引入了 IT 领域。如何通过可观察性的理念，对微服务，Service Mesh 以至未来的 Serverless 架构的应用进行监控， 将是应用架构往云原生迁移过程中的一个重要命题。\n加入 SOFA 钉钉互动群 欢迎加入直播互动钉钉群：23195297（搜索群号加入即可）\n点击即可报名 https://tech.antfin.com/community/activities/779\n议程    时间 环节 分享大纲 分享嘉宾     13:00-13:30 签到     13:30-14:15 《RPC 服务框架 SOFARPC 在蚂蚁金服的发展与进化》 - SOFARPC 在蚂蚁金服的应用现状- 协议和通信层的变化与设计- 跨机房与弹性的挑战- RPC 框架发展中的经验与教训- 拥抱开源，SOFARPC 的未来 碧远@SOFARPC 开源负责人   14:15-15:00 《蚂蚁金服在云原生架构下的可观察性的探索和实践》 - 为什么云原生时代需要可观察性- 可观察性的三大支柱- 现在社区方案的缺陷- 蚂蚁金服对云原生的可观察性的理解及实践 苟利@蚂蚁金服中间件团队产品专家   15:00-15:10 茶歇     15:10-15:55 《分布式事务 Seata 三种模式详解》 - 分布式事务产生的背景- 分布式事务理论基础- 蚂蚁金服分布式事务实践- 开源分布式事务 Seata 简介(AT，TCC，SAGA) 屹远@Seata 核心贡献者   15:55-16:40 《无线自动化测试框架 Soloπ 的跨平台实践》 - 移动端自动化测试转向轻量化- “Android+iOS”双端核心功能介绍- “Android+iOS”双端功能打通介绍- 结合云测平台、用例管理、IDE 的自动化测试解决方案 茅舍@Soloπ 核心作者不溯@Soloπ 核心作者    ","date":1564038000,"description":"SOFA Meetup#3 广州站-从开源技术到产品能力，8 月 11 日周日下午 13 点，广州市广电平云 B 塔 15F 等你。","dir":"activities/sofa-meetup-3/","fuzzywordcount":1100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"0e50b11d1a8e52f8cefbac0bb4826ffe","permalink":"/activities/sofa-meetup-3/","publishdate":"2019-07-25T15:00:00+08:00","readingtime":3,"relpermalink":"/activities/sofa-meetup-3/","summary":"概要 活动主题：SOFA Meetup#3 广州站-从开源技术到产品能力 活动时间：8 月 11 日周日下午 13 点 活动地点：广州市广电平云 B 塔 15F 活动形式：线下活动 报名方式：","tags":["SOFAMeetup","SOFAStack"],"title":"SOFA Meetup#3 广州站-从开源技术到产品能力","type":"activities","url":"/activities/sofa-meetup-3/","wordcount":1067},{"author":"袖扣","categories":"SOFAJRaft","content":" SOFAStack Scalable Open Financial Architecture Stack 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。\n SOFAJRaft 是一个基于 Raft 一致性算法的生产级高性能 Java 实现，支持 MULTI-RAFT-GROUP，适用于高负载低延迟的场景。\n本文为《剖析 | SOFAJRaft 实现原理》第五篇，本篇作者袖扣，来自蚂蚁金服。\n《剖析 | SOFAJRaft 实现原理》系列由 SOFA 团队和源码爱好者们出品，项目代号：\u0026amp;lt;SOFA:JRaftLab/\u0026amp;gt;，文章尾部有参与方式，欢迎同样对源码热情的你加入。\nSOFAJRaft ：https://github.com/alipay/sofa-jraft\n前言 RheaKV 是首个以 JRaft 为基础实现的一个原生支持分布式的嵌入式键值（key、value）数据库，现在本文将从 RheaKV 是如何利用 MULTI-RAFT-GROUP 的方式实现 RheaKV 的高性能及容量的可扩展性的，从而进行全面的源码、实例剖析。\nMULTI-RAFT-GROUP 通过对 Raft 协议的描述我们知道：用户在对一组 Raft 系统进行更新操作时必须先经过 Leader，再由 Leader 同步给大多数 Follower。而在实际运用中，一组 Raft 的 Leader 往往存在单点的流量瓶颈，流量高便无法承载，同时每个节点都是全量数据，所以会受到节点的存储限制而导致容量瓶颈，无法扩展。\nMULTI-RAFT-GROUP 正是通过把整个数据从横向做切分，分为多个 Region 来解决磁盘瓶颈，然后每个 Region 都对应有独立的 Leader 和一个或多个 Follower 的 Raft 组进行横向扩展，此时系统便有多个写入的节点，从而分担写入压力，图如下：\n此时磁盘及 I/O 瓶颈解决了，那多个 Raft Group 是如何协作的呢，我们接着往下看。\n选举及复制 RheaKV 主要由 3 个角色组成：PlacementDriver（以下成为 PD） 、Store、Region。由于 RheaKV 支持多组 Raft，所以比单组场景多出一个 PD 角色，用来调度以及收集每个 Store 及 Region 的基础信息。\nPlacementDriver PD 负责整个集群的管理调度、Region ID 生成等。此组件非必须的，如果不使用 PD，设置 PlacementDriverOptions 的 fake 属性为 true 即可。PD 一般通过 Region 的心跳返回信息进行对 Region 调度，Region 处理完后，PD 则会在下一个心跳返回中收到 Region 的变更信息来更新路由及状态表。\nStore 通常一个 Node 负责一个 Store，Store 可以被看作是 Region 的容器，里面存储着多个分片数据。Store 会向 PD 主动上报 StoreHeartbeatRequest 心跳，心跳交由 PD 的 handleStoreHeartbeat 处理，里面包含该 Store 的基本信息，比如，包含多少 Region，有哪些 Region 的 Leader 在该 Store 等。\nRegion Region 是数据存储、搬迁的最小单元，对应的是 Store 里某个实际的数据区间。每个 Region 会有多个副本，每个副本存储在不同的 Store，一起组成一个Raft Group。Region 中的 Leader 会向 PD 主动上报 RegionHeartbeatRequest 心跳，交由 PD 的 handleRegionHeartbeat 处理，而 PD 是通过 Region的Epoch 感知 Region 是否有变化。\nRegionRouteTable 路由表组件 MULTI-RAFT-GROUP 的多 Region 是通过 RegionRouteTable 路由表组件进行管理的，可通过 addOrUpdateRegion、removeRegion 进行添加、更新、移除 Region，也包括 Region 的拆分。目前暂时还未实现 Region 的聚合，后面会考虑实现。\n分区逻辑与算法 Shard “让每组 Raft 负责一部分数据。”\n数据分区或者分片算法通常就是 Range 和 Hash，RheaKV 是通过 Range 进行数据分片的，分成一个个 Raft Group，也称为 Region。这里为何要设计成 Range 呢？原因是 Range 切分是按照对 Key 进行字节排序后再做每段每段切分，像类似 scan 等操作对相近 key 的查询会尽可能集中在某个 Region，这个是 Hash 无法支持的，就算遇到单个 Region 的拆分也会更好处理一些，只用修改部分元数据，不会涉及到大范围的数据挪动。\n当然 Range 也会有一个问题那就是，可能会存在某个 Region 被频繁操作成为热点 Region。不过也有一些优化方案，比如 PD 调度热点 Region 到更空闲的机器上，或者提供 Follower 分担读的压力等。\nRegion 和 RegionEpoch 结构如下：\nclass Region { long id; // region id  // Region key range [startKey, endKey)  byte[] startKey; // inclusive  byte[] endKey; // exclusive  RegionEpoch regionEpoch; // region term  List\u0026amp;lt;Peer\u0026amp;gt; peers; // all peers in the region } class RegionEpoch { // Conf change version, auto increment when add or remove peer  long confVer; // Region version, auto increment when split or merge  long version; } class Peer { long id; long storeId; Endpoint endpoint; } Region.id：为 Region 的唯一标识，通过 PD 全局唯一分配。\nRegion.startKey、Region.endKey：这个表示的是 Region 的 key 的区间范围 [startKey, endKey)，特别值得注意的是针对最开始 Region 的 startKey，和最后 Region 的 endKey 都为空。\nRegion.regionEpoch：当 Region 添加和删除 Peer，或者 split 等，此时 regionEpoch 就会发生变化，其中 confVer 会在配置修改后递增，version 则是每次有 split 、merge（还未实现）等操作时递增。 …","date":1563955200,"description":"本文为《剖析 | SOFAJRaft 实现原理》第五篇，本篇作者袖扣，来自蚂蚁金服。","dir":"blog/sofa-jraft-rheaKV-multi-raft-group/","fuzzywordcount":4600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"fbebe45fe1ffaa4e8f134c2531cde55c","permalink":"/blog/sofa-jraft-rheakv-multi-raft-group/","publishdate":"2019-07-24T16:00:00+08:00","readingtime":9,"relpermalink":"/blog/sofa-jraft-rheakv-multi-raft-group/","summary":"SOFAStack Scalable Open Financial Architecture Stack 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 SOFAJRaft 是一个基于 Raft","tags":["SOFAJRaft","SOFALab","剖析 | SOFAJRaft 实现原理"],"title":"SOFAJRaft-RheaKV MULTI-RAFT-GROUP 实现分析 | SOFAJRaft 实现原理","type":"blog","url":"/blog/sofa-jraft-rheakv-multi-raft-group/","wordcount":4507},{"author":"SOFA 团队","categories":"SOFA Weekly","content":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动\nSOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics 监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，也是在金融场景里锤炼出来的最佳实践。\n**SOFAStack 官网: **https://www.sofastack.tech **SOFAStack: **https://github.com/sofastack\n社区 Big News NO.1 社区新认证一位 Committer\n@SteNicholas 成为 SOFAJRaft Committer。\n主要贡献\n一、贡献了 SOFAJRaft 源码剖析系列一共三篇文章\n 蚂蚁金服生产级 Raft 算法库 SOFAJRaft 存储模块剖析 | SOFAJRaft 实现原理 SOFAJRaft-RheaKV 是如何使用 Raft 的 | SOFAJRaft 实现原理 SOFAJRaft 线性一致读实现剖析 | SOFAJRaft 实现原理  二、贡献了 4 个 feature PR\n Multi-raft-group 的手动集群 Leader 平衡实现 实现了 RheaKV 的 CompareAndPut API 实现了 RheaKV 的 putIfAbsent batch 优化 实现了 RheaKV 的 batch delete API  目前，社区已经认证超过四十位 Committer。 感谢对 SOFAStack 的支持和帮助~\n也欢迎你加入 SOFAStack community，指南：\nhttps://github.com/sofastack/community\nSOFARegistryLab 系列阅读  蚂蚁金服服务注册中心 SOFARegistry 解析 | 服务发现优化之路 海量数据下的注册中心 - SOFARegistry 架构介绍 蚂蚁金服开源服务注册中心 SOFARegistry | SOFA 开源一周年献礼  SOFAChannel 回顾集合  SOFAChannel#7：自定义资源 CAFEDeployment 的背景、实现和演进 | SOFAChannel#7 直播整理 SOFAChannel#6：蚂蚁金服轻量级监控分析系统解析 | SOFAChannel#6 直播整理 SOFAChannel#5：给研发工程师的代码质量利器 | SOFAChannel#5 直播整理 SOFAChannel#4：分布式事务 Seata TCC 模式深度解析 | SOFAChannel#4 直播整理 SOFAChannel#3：SOFARPC 性能优化实践（下）| SOFAChannel#3 直播整理 SOFAChannel#2：SOFARPC 性能优化实践（上）| SOFAChannel#2 直播整理 SOFAChannel#1：从蚂蚁金服微服务实践谈起 | SOFAChannel#1 直播整理  SOFA 项目进展 本周发布详情如下\nSOFAActs 1.0.1 版本发布，主要变更如下：\n 插件兼容性问题修复  详细参考 发布报告\n","date":1563519600,"description":"SOFA WEEKLY | 每周精选，筛选每周精华问答，同步开源进展，欢迎留言互动。","dir":"blog/sofa-weekly-20190719/","fuzzywordcount":800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"03bd5ad0ca023620792ed7ee60d4c448","permalink":"/blog/sofa-weekly-20190719/","publishdate":"2019-07-19T15:00:00+08:00","readingtime":2,"relpermalink":"/blog/sofa-weekly-20190719/","summary":"SOFA WEEKLY | 每周精选，筛选每周精华问答 同步开源进展，欢迎留言互动 SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分","tags":["SOFA Weekly"],"title":"SOFA Weekly | 每周精选【7/15 - 7/19】","type":"blog","url":"/blog/sofa-weekly-20190719/","wordcount":776},{"author":"枫晟","categories":"CafeDeployment","content":"本文简单介绍了蚂蚁金服 SOFAStack 的 Kubernetes 自定义资源 CafeDeployment 的开发背景和功能特性。\n相关直播视频以及 PPT 查看地址\n背景介绍 Kubernetes 原生社区 Deployment 和 StatefulSet 解决了“服务节点版本一致性”的问题，并且通过 Rolling Update 实现了滚动升级，提供了基本的回滚策略。对于高可用建设要求不高的“年轻”业务，是一个不错的选择。\n但是，在金融场景下，要解决的场景复杂得多。因此我们在金融分布式架构-云应用引擎（SOFAStack-CAFE，参见《金融级云原生探索实践系列——开篇》）中提出了 **CafeDeployment **的云原生模型，致力于解决以下问题：\n1. IP 不可变\n对于很多运维体系建设较为早期的用户，使用的服务框架、监控、安全策略，大量依赖 IP 作为唯一标识而被广泛使用。迁移到 Kubernetes 最大的改变就是 IP 会飘，而这对于他们来说，无异于运维、服务框架的推倒重来。\n2. 金融体系下的高可用\nDeployment/StatefulSet 无法根据特定属性进行差异化部署。而在以同城双活为建设基础的金融领域，为了强管控 Pod 的部署结构（即保证每个机房/部署单元都有副本运行），若通过原生组件进行部署，我们不得不维护多个几乎一模一样的 Deployment/StatefulSet，来保证 Pod 一定会飘到指定机房/部署单元的 node 上。在规模上到一定程度后，这无疑加大了运维管控的复杂度和成本。\n3. 灵活的部署策略\nDeployment 无法控制发布步长，StatefulSet 虽然可以控制步长，但是每次都需要人工计算最新版本需要的副本数并修改 Partition，在多机房/部署单元的情况下，光想想发布要做的操作都脑袋炸裂。\n在面对以上这些问题的时候，我们思考：能不能有一个类似 Deployment 的东西，不仅可以实现副本保持，并且能协助用户管控应用节点部署结构、做 Beta 验证、分批发布，减少用户干预流程，实现最大限度减少发布风险的目标，做到快速止损，并进行修正干预。这就是我们为什么选择定义了自己的资源——CafeDeployment。\n模型定义 CafeDeployment 主要提供跨部署单元的管理功能，其下管理多个 InPlaceSet。每个 InPlaceSet 对应一个部署单元。部署单元是逻辑概念，他通过 Node 上的 label 来划分集群中的节点，而 InPlaceSet 则通过 NodeAffinity 能力，将其下的 Pod 部署到同一个部署单元的机器上。由此实现 CafeDeployment 跨部署单元的管理。\nCafeDeployment 作为多个部署单元的上层，除了提供副本保持，历史版本维护等基本功能，还提供了跨部署单元的分组扩容，分组发布，Pod 调度等功能。模型定义如下：\napiVersion: apps.cafe.cloud.alipay.com/v1alpha1 kind: CafeDeployment metadata: ...... spec: historyLimit: 20 podSetType: InPlaceSet\t# 目前支持底层PodSet：InPlaceSet，ReplicaSet，StatefulSet replicas: 10 selector: matchLabels: instance: productpage name: bookinfo strategy: batchSize: 4\t# 分组发布时，每组更新的Pod数目 minReadySeconds: 30 needWaitingForConfirm: true\t# 分组发布中，每组结束时是否需要等待确认 upgradeType: Beta\t# 目前支持发布策略：Beta发布，分组发布 pause: false template: ...... volumeClaimTemplates:\t# 用于支持statefulSet serviceName:\t# 用于支持statefulSet topology: autoReschedule: enable: true\t# 是否启动Pod自动重调度 initialDelaySeconds: 10 unitType: Cell\t# 部署单元类型：Cell，Zone，None unitReplicas: CellA: 4\t# 固定某部署单元的Pod数目 values:\t# 部署单元 - CellA - CellB 因为我们将大部分的控制逻辑都抽取到上层 CafeDeployment 中，因此我们重新设计了 InPlaceSet，将它做得足够简单，只关注于“InPlace”相关的功能，即副本保持和原地升级，保持 IP 不变的能力，模型定义如下：\nspec: minReadySeconds: 30 replicas: 6 selector: matchLabels: instance: productpage name: bookinfo deployUnit: CellB strategy: partition: 6\t# 控制发布时更新Pod的进度 template: ...... 功能特性 灵活的分组定义 CafeDeployment 支持跨部署单元的分组扩容，Pod 调度，分组发布。分组策略主要分为两种，Beta 分组和 Batch 分组：\n Batch 分组  即根据 BatchSize 将 Pod 分为多个批次，每批中的 Pod 会同时发布。待用户确认（needWaitingForConfirm=true时）无误时，或当前批次所有 Pod 都 ready 后（needWaitingForConfirm=false 时），则会开始进行下一组的发布。\n在分组暂停时，CafeDeployment 会被打上 Annotation: cafe.sofastack.io/upgrade-confirmed=false，用户可通过将 Annotation 的值改为 true，确认当前分组。 Beta 分组  相比 Batch 发布，会在第一组发布之前多一步 Beta 分组。此组会在每个部署单元内选择一个 Pod 进行发布，以减小错误配置带来的影响。若用户确认无误，可以确认继续，以进入正常的 Batch 发布流程。\n安全的分组扩容和发布能力 分组扩容 为预防不正确的配置造成大量错误 Pod 同时创建，占用大量资源等意外情况出现，CafeDeployment 支持分组扩容，以降低风险。\n在如下配置时，CafeDeployment 会创建两个 InPlaceSet 实例，并开始分组创建（扩容）Pod。\nspec: ...... replicas: 10\t# 副本数为10 strategy: upgradeType: Beta\t# Beta发布 batchSize: 4\t# 每组Pod数为4 needWaitingForConfirm: true\t# 分组暂停 topology: ...... values:\t#  …","date":1563454800,"description":"本文根据 SOFAChannel#7 直播分享整理，介绍了蚂蚁金服 SOFAStack 的 Kubernetes 自定义资源 CafeDeployment 的开发背景和功能特性。","dir":"blog/sofa-channel-7-retrospect/","fuzzywordcount":3500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"a1185b6bb7c21fd49c4118950c16a2a9","permalink":"/blog/sofa-channel-7-retrospect/","publishdate":"2019-07-18T21:00:00+08:00","readingtime":7,"relpermalink":"/blog/sofa-channel-7-retrospect/","summary":"本文简单介绍了蚂蚁金服 SOFAStack 的 Kubernetes 自定义资源 CafeDeployment 的开发背景和功能特性。 相关直播视频以及 PPT 查看地址 背景介绍 Kubernetes 原生社区 Deployment 和 StatefulSet 解决了“服务节点版本一致性”","tags":["CafeDeployment","SOFAChannel"],"title":"自定义资源 CAFEDeployment 的背景、实现和演进 | SOFAChannel#7 直播整理","type":"blog","url":"/blog/sofa-channel-7-retrospect/","wordcount":3478},{"author":"尚彧","categories":"SOFARegistry","content":" SOFAStack Scalable Open Financial Architecture Stack 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。\n SOFARegistry 是蚂蚁金服开源的具有承载海量服务注册和订阅能力的、高可用的服务注册中心，最早源自于淘宝的初版 ConfigServer，在支付宝/蚂蚁金服的业务发展驱动下，近十年间已经演进至第五代。\n本文为《剖析 | SOFARegistry 框架》第二篇，本篇作者尚彧，是 SOFARegistry 开源负责人。《剖析 | SOFARegistry 框架》系列由 SOFA 团队和源码爱好者们出品，项目代号：SOFA:RegistryLab/，文末附共建列表，欢迎领取共建~\nGitHub 地址：https://github.com/sofastack/sofa-registry\n概述 无论传统的 SOA 还是目前的微服务架构，都离不开分布式的特性，既然服务是分布的就必须解决服务寻址的问题。服务注册中心是这个过程最主要的组件，通过服务注册和服务发现特性收集服务供求关系，解耦服务消费方对服务提供方的服务定位问题。\n服务注册中心的最主要能力是服务注册和服务发现两个过程。服务注册的过程最重要是对服务发布的信息进行存储，服务发现的过程是把服务发布端的所有变化（包括节点变化和服务信息变化）及时准确的通知到订阅方的过程。\n本文详细描述服务注册中心 SOFARegistry 对于服务发现的实现和技术演进过程，主要涉及 SOFARegistry 的服务发现实现模式以及服务数据变化后及时推送到海量客户端感知的优化过程。\n服务发现分类 分布式理论最重要的一个理论是 CAP 原理。关于注册中心的解决方案，根据存储数据一致性维度划分业界有很多实现，比如最有代表性的强一致性 CP 系统 ZooKeeper 和最终一致性 AP 系统 Eureka。SOFARegistry 在数据存储层面采用了类似 Eureka 的最终一致性的过程，但是存储内容上和 Eureka 在每个节点存储相同内容特性不同，采用每个节点上的内容按照一致性 Hash 数据分片来达到数据容量无限水平扩展能力。\n服务端发现和客户端发现 抛开数据存储的一致性，我们从服务发现的实现维度考虑服务注册中心的分类，业界也按照服务地址选择发生主体和负载均衡策略实现主体分为客户端服务发现和服务端服务发现。\n 客户端服务发现：即由客户端负责决定可用的服务实例的\u0026amp;quot;位置\u0026amp;quot;以及与其相关的负载均衡策略，就是服务发现的地址列表在客户端缓存后由客户端自己根据负载均衡策略进行选址完成最终调用，地址列表定期进行刷新或服务端主动通知变更。最主要的缺点是需要有客户端实现，对于各种异构系统不同语言不同结构的实现必须要进行对应的客户端开发，不够灵活，成本较高。   服务端服务发现：在服务端引入了专门的负载均衡层，将客户端与服务发现相关的逻辑搬离到了负载均衡层来做。客户端所有的请求只会通过负载均衡模块，其并不需要知会微服务实例在哪里，地址是多少。负载均衡模块会查询服务注册中心，并将客户端的请求路由到相关可用的微服务实例上。这样可以解决大量不同实现应用对客户端的依赖，只要对服务端的负载均衡模块发请求就可以了，由负载均衡层获取服务发现的地址列表并最终确定目标地址进行调用。   SOFARegistry 服务发现模式：以客户端服务发现模式为主。这样的模式实现比较直接，因为在同一个公司内部实践面对的绝大多数应用基本上都是同一个语言实现的，客户端实现也只需要确定一套，每个客户端通过业务内嵌依赖方式部署，并且可以根据业务需求进行定制负载均衡策略进行选址调用。当然也会遇到特殊的异构系统，这个随着微服务架构 RPC 调用等通信能力下沉到 Mesh 执行也得到解决，可以在 Mesh 层进行特定的服务注册中心客户端嵌入，选择路由都在这里统一进行，对不同语言实现的系统进行无感知。  服务发现的推、拉模型 服务发现最重要的过程是获取服务发布方地址列表的过程，这个过程可以分为两种实现模式：客户端主动获取的拉模式和服务端主动变更通知的推送模式：\n 拉模式主要是在客户端按照订阅关系发起主动拉取过程。客户端在首次订阅可以进行一次相关服务 ID 的服务列表查询，并拉取到本地缓存，后续通过长轮询定期进行服务端服务 ID 的版本变更检测，如果有新版本变更则及时拉取更新本地缓存达到和服务端一致。这种模式在服务端可以不进行订阅关系的存储，只需要存储和更新服务发布数据。由客户端主动发起的数据获取过程，对于客户端实现较重，需要主动获取和定时轮训，服务端只需要关注服务注册信息的变更和健康情况及时更新内存。这个过程由于存在轮训周期，对于时效性要求不高的情况比较适用。   推模式主要是从服务端发起的主动变更推送。这个模式主要数据压力集中在服务端，对于服务注册数据的变更和提供方，节点每一次变更情况都需要及时准确的推送到客户端，更新客户端缓存。这个数据推送量较大，在数据发布频繁变更的过程，对于大量订阅方的大量数据推送频繁执行，数据压力巨大，但是数据变更信息及时，对于每次变更都准确反映到客户端。   **SOFARegistry 服务发现模式采用的是推拉结合方式。**客户端订阅信息发布到服务端时可以进行一次地址列表查询，获取到全量数据，并且把对应的服务 ID 版本信息存储在 Session 回话层，后续如果服务端发布数据变更，通过服务 ID 版本变更通知回话层 Session，Session 因为存储客户端订阅关系，了解哪些客户端需要这个服务信息，再根据版本号大小决定是否需要推送给这个版本较旧的订阅者，客户端也通过版本比较确定是否更新本次推送的结果覆盖内存。此外，为了避免某次变更通知获取失败，定期还会进行版本号差异比较，定期去拉取版本低的订阅者所需的数据进行推送保证数据最终一致。  SOFARegistry 服务发现模式 数据分层 前面的文章介绍过 SOFARegistry 内部进行了数据分层，在服务注册中心的服务端因为每个存储节点对应的客户端的链接数据量有限，必须进行特殊的一层划分用于专门收敛无限扩充的客户端连接，然后在透传相应的请求到存储层，这一层是一个无数据状态的代理层，我们称之为 Session 层。\n此外，Session 还承载了服务数据的订阅关系，因为 SOFARegistry 的服务发现需要较高的时效性，对外表现为主动推送变更到客户端，所以推送的主体实现也集中在 Session 层，内部的推拉结合主要是通过 Data 存储层的数据版本变更推送到所有 Session 节点，各个 Session 节点根据存储的订阅关系和首次订阅获取的数据版本信息进行比对，最终确定推送给那些服务消费方客户端。\n触发服务推送的场景 直观上服务推送既然是主动的，必然发生在主动获取服务时刻和服务提供方变更时刻：\n 主动获取：服务订阅信息注册到服务端时，需要查询所有的服务提供方地址，并且需要将查询结果推送到客户端。这个主动查询并且拉取的过程，推送端是一个固定的客户端订阅方，不涉及服务 ID 版本信息判定，直接获取列表 …","date":1563433200,"description":"本文为《剖析 | SOFARegistry 框架》第二篇，本篇作者尚彧，来自蚂蚁金服。","dir":"blog/sofa-registry-service-discovery-optimization/","fuzzywordcount":5100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"f99d259a0c323df2ddaaea719da2f93c","permalink":"/blog/sofa-registry-service-discovery-optimization/","publishdate":"2019-07-18T15:00:00+08:00","readingtime":11,"relpermalink":"/blog/sofa-registry-service-discovery-optimization/","summary":"SOFAStack Scalable Open Financial Architecture Stack 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 SOFARegistry 是蚂蚁金服开","tags":["SOFARegistry","剖析 | SOFARegistry 框架","SOFALab"],"title":"蚂蚁金服服务注册中心 SOFARegistry 解析 | 服务发现优化之路","type":"blog","url":"/blog/sofa-registry-service-discovery-optimization/","wordcount":5056},{"author":"隐秀","categories":"SOFAStack","content":" KubeCon China 2019 大会上， Serverless 应用服务正式亮相，在 SOFAStack 工作坊吸引了百余名参与者同场体验。\n 市场观察 当我们回顾云计算的发展历程，会看到基础架构经历了从物理机到虚拟机，从虚拟机再到容器的演进过程。在这大势之下，应用架构也在同步演进，从单体过渡到多层，再到当下的微服务。在变化的背后，有一股持续的动力，它来自于三个不变的追求：提高资源利用率，优化开发运维体验，以及更好地支持业务发展。\n目前， Serverless 已成为云原生社区关注的重点之一，它的发展也不例外。相比容器技术，Serverless 可以将资源管理的粒度更加细化，使开发者更快上手云原生，并且倡导事件驱动模型支持业务发展。从而帮助用户解决了资源管理复杂、低频业务资源占用等问题；实现面向资源使用，以取代面向资源分配的模式。根据 CNCF 在2018年底基于 2400 人的一份统计报告，已有 38% 的组织正在使用 Serverless 技术，相比 2017 同期增长了 22%。(数据来源：CNCF Survey)\n 图片来源：Gartner Report: China Summary Translation Evolution of Server Computing - VMs to Containers to Serverless - Which to Use When\n 目前市场上，云厂商提供了多种 Serverless 产品和解决方案，大致可划分为：\n 函数计算服务：如 AWS Lambda，特点是以代码片段为单位运行，并对代码风格有一定要求。 面向应用的 Serverless 服务：如 Knative，特点是基于容器服务，并提供了从代码包到镜像的构建能力。 容器托管服务：如 AWS Fargate，特点是以容器镜像为单元运行，但用户仍需感知容器。  从社区来看，CNCF 云原生基金会正通过 Serverless 工作组协调社区讨论并促进规范和标准的形成，工作组产出了 Serverless 白皮书和全景图等重要内容。其中，全景图将目前的生态划分为了平台层，框架层，工具链层和安全层这四个模块。\n 图片来源：https://landscape.cncf.io/\n 落地挑战 在交流过程中，我们发现 Serverless 很好地解决了客户的一些诉求：包括通过 0-1-0 的伸缩能力来提高资源时用率，降低成本；支持代码包出发，从而让客户无感化实现云原生，历史应用无需经过容器化改造；支持灵活的触发器配置，引导用户对应用进行事件驱动的改造，从而适应业务的高速发展等。这些优势，使得 Serverless 在小程序开发的场景下大放异彩。\n同时，对于在企业级应用的生产环境落地 Serverless，各方也有了很多探索和突破。在本周刚结束的 KubeCon China 2019 大会上，Serverless 工作组会议也以此为话题展开了讨论。目前的核心挑战可归纳为：\n平台可迁移\n目前众多平台都推出了自己的 Serverless 标准，包括代码格式、框架和运维工具等，用户既面临较高的学习成本和选择压力，也担心无法在平台之间灵活迁移 Serverless 应用。\n0-M-N 性能\n线上应用对控制请求延迟有严格的要求，因此，用户需要谨慎地验证 Serverless 0-1 冷启动速度、M-N 扩容速度以及稳定性都达到了生产要求。\n调试和监控\n用户对底层资源无感知，只能借助平台能力对应用进行调试和监控，用户需要平台提供强大的日志功能进行排错，和多维度的监控功能时刻了解应用状态。\n事件源集成\n采用 Serverless 架构后，应用往往进行更细粒度的拆分，并通过事件串联。因此用户希望平台能集成大多数通用的事件源，并支持自定义事件，使得触发机制更加灵活。\n工作流支持\n完成某个业务，往往涉及多个 Serverless 应用之间的配合，当数目较多时，用户希望可以用工作流工具来进行统一编排和状态查看，提高效率。\n蚂蚁金服实践 SOFAStack 致力于通过产品技术解决云上客户实际痛点，沉淀蚂蚁金服技术实践，帮助用户以高效、低成本的方式迁移到云原生架构。Serverless 应用服务（Serverless Application Service，简称 SOFA SAS）是一款源自蚂蚁金服实践的一站式 Serverless 平台。SAS 基于 SOFAStack CAFE 云应用引擎 （Cloud Application Fabric Engine 简称 CAFE），CAFE 的容器服务已经通过了 CNCF 的一致性认证，是一个标准的 Kubernetes。\nServerless 应用服务产品在兼容标准 Knative 同时，融入了源自蚂蚁金服实践的应用全生命周期管理能力，提供了 Serverless 引擎管理、应用与服务管理、版本管理与流控、根据业务请求或事件触发较快的 0-M-N-0 自动伸缩、计量、日志及监控等配套能力。同时结合金融云上客户实际痛点，产品独居匠心的提供独占版与共享版两种形态，以及传统代码包、容器镜像与纯函数三种研发模式，以解决用户的不同需求，降低客户准入门槛。\n 一键部署：用户可以通过代码包或容器镜像的方式一键部署应用并在任意时刻测试执行。 引擎管理：SAS 提供了丰富的引擎全生命周期管理、诊断、监测等能力，为独占版客户赋能 Serverless 引擎数据面的全方位管理与运维运营能力。 服务及版本：SAS 提供应用管理、应用服务管理以及版本管理。版本可以采用容器镜像方式部署也可以采用传统VM发布模式下的代码包部署，很多情况下用户代码无需修改也无需编写维护 Dockerfile 即可迁移。 0-M-N：SAS 提供 0-M-N-M-0 的 Serverelss 快速伸缩能力，支持事件触发或流量触发的 0-M，多种指标的 M-N（如 QPS、CPU、MEM 等等） 日志监控计量：产品内置了日志、监控、计量等配套设施能力，帮助用户进行调试和应用状态监控。 流量控制：基于 SOFAMesh，SAS提供基本流控能力，后续会与服务网格进一步深度集成提供大规模多维跨地域及混合云的流控能力。 触发器管理：产品支持基于常见周期以及秒级精度的cron表达式触发器，可关联并触发无服务器应用，后续将支持更多 IaaS、PaaS 管控型与数据型事件。   性能简析：横轴为完全在同一时刻触发冷启的Java应用个数，纵轴为冷启应用的平均与最小耗时。随着压力增大，50个Java应用同一时刻调度加冷启平均耗时2.5秒左右，100个Java应用同一时刻调度冷启平均耗时3-4秒，最短耗时1.5到2秒。\n  性能简析：Pooling 快弹慢缩时序算法，池容量和实际单位时间申请量关系可做到如图所示（蓝色为实际申请量，绿色为池容量）\n 目前产品已顺利支撑生产环境小程序 Serverless 模式。同时通过 0-M-N-M-0 的能力在很大程度上降低了小程序的运营成本。在行业客户领域，某保险公司决定近期迁移部分日结前置和长尾应用到 Serverless 产品平台，这也是我们产品又一个重要突破。未来，我们致力于将 SAS 打造成为一个 …","date":1562828400,"description":"KubeCon China 2019 大会上， Serverless 应用服务正式亮相，在 SOFAStack 工作坊吸引了百余名参与者同场体验。","dir":"blog/serverless-market-challenge/","fuzzywordcount":2600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"e2a95cbe3e0343e3908f17bea5a55d70","permalink":"/blog/serverless-market-challenge/","publishdate":"2019-07-11T15:00:00+08:00","readingtime":6,"relpermalink":"/blog/serverless-market-challenge/","summary":"KubeCon China 2019 大会上， Serverless 应用服务正式亮相，在 SOFAStack 工作坊吸引了百余名参与者同场体验。 市场观察 当我们回顾云计算的发展历程，会看到基础架构经历了从物理机到虚","tags":["SOFAStack","Serverless"],"title":"Serverless 市场观察和落地挑战","type":"blog","url":"/blog/serverless-market-challenge/","wordcount":2538},{"author":"SOFAStack","categories":"SOFAStack","content":" 2019 年 6 月 25 日，全球知名开源组织云原生计算基金会 CNCF 宣布，蚂蚁金服正式成为 CNCF 黄金会员，蚂蚁金服表示将持续加大对开源项目的支持，包括 Kubernetes，ServiceMesh，Serverless，安全容器等方向，并发挥自己的力量。SOFAStack 作为蚂蚁金服重要的开源项目，最近也与 CNCF 有故事发生。\n 近期，CNCF 发布了最新版本的 Cloud Native Landscape，蚂蚁金服金融级分布式架构 SOFAStack 中有 3 个项目被纳入，分别是 Service Mesh 数据平面代理 SOFAMosn、分布式链路跟踪系统 SOFATracer 和 RPC 服务框架 SOFARPC。\nCNCF \u0026amp;amp; CNCF Cloud Native Landscape CNCF(Cloud Native Computing Foundation)，是由 Google 牵头创立的云原生计算开源软件基金会。它致力于云原生(Cloud Native)技术的普及和可持续发展。2016 年 11 月，CNCF 开始维护 Cloud Native Landscape，汇总流行热门的云原生技术与工具，并加以分类，为企业构建云原生体系提供参考，在云生态研发、运维领域具有广泛影响力。\nSOFAStack \u0026amp;amp; CNCF Cloud Native Landscape 蚂蚁金服金融级分布式架构 SOFAStack 中的 3 个项目加入这次最新版本的 Cloud Native Landscape ，分别是 Service Mesh 数据平面代理 SOFAMosn、分布式链路跟踪系统 **SOFATracer ** 和 RPC 服务框架 SOFARPC。\nSOFAMosn Star 一下✨： https://github.com/sofastack/sofa-mosn\nSOFAMosn(Modular Observable Smart Network)，是一款采用 GoLang 开发的 Service Mesh 数据平面代理， 功能和定位类似 Envoy ，旨在提供分布式，模块化，可观察，智能化的代理能力。 SOFAMosn 支持 Envoy 和 Istio 的 API，可以和 Istio 集成，在 SOFAMesh 中，我们使用 SOFAMosn 替代 Envoy。 SOFAMosn 初始版本由蚂蚁金服和阿里大文娱 UC 事业部携手贡献，期待社区一起来参与后续开发，共建一个开源精品项目。\nSOFARPC Star 一下✨： https://github.com/sofastack/sofa-rpc\nSOFARPC 是蚂蚁金服开源的一款基于 Java 实现的 RPC 服务框架，为应用之间提供远程服务调用能力，具有高可伸缩性，高容错性，目前蚂蚁金服所有业务相互间的 RPC 调用都是采用 SOFARPC。SOFARPC 为用户提供了负载均衡，流量转发，链路追踪，链路数据透传，故障剔除等功能。\nSOFARPC 还支持不同的协议，目前包括Bolt， RESTful ， Dubbo ， H2C 协议进行通信。其中 Bolt 是蚂蚁金融服务集团开放的基于 Netty 开发的网络通信框架。\nSOFATracer Star 一下✨： https://github.com/sofastack/sofa-tracer\nSOFATracer 是蚂蚁金服开发的基于 OpenTracing 规范 的分布式链路跟踪系统，其核心理念就是通过一个全局的 TraceId 将分布在各个服务节点上的同一次请求串联起来。通过统一的 TraceId 将调用链路中的各种网络调用情况以日志的方式记录下来同时也提供远程汇报到 Zipkin 进行展示的能力，以此达到透视化网络调用的目的。\nSOFAStack 开源家族 SOFAStack™（Scalable Open Financial Architecture Stack）是用于快速构建金融级分布式架构的一套中间件，也是在金融场景里锤炼出来的最佳实践。\n图为 SOFAStack 开源全景图，其中橙色部分为 SOFAStack 包含的开源组件，白色部分为兼容或集成开源社区其它优秀的开源产品\n特别感谢 SOFAStack 开源社区的每一个你 2018 年 4 月 19 日正式宣布逐步开源 SOFAStack，开源的策略是 Open Core，也就是把核心的接口和实现都开源出来，内部保留老的兼容代码。 到现在为止差不多 1 年 2 个月的时间，已经开源了十几个项目，累计超过 25,600 Star，120 多位贡献者， 以及 30 多家生产用户，近期认证了两位社区 Committer，再次感谢开发者和企业的信任和认可，因为你们，SOFAStack 社区才能会更好。\n","date":1562749200,"description":"Service Mesh 数据平面代理 SOFAMosn、分布式链路跟踪系统 SOFATracer 和 RPC 服务框架 SOFARPC 加入 CNCF 云原生全景图","dir":"blog/sofastack-projects-joined-cncf-landscape/","fuzzywordcount":1300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"219e8daac9b49b95c7d5afd94d9ee791","permalink":"/blog/sofastack-projects-joined-cncf-landscape/","publishdate":"2019-07-10T17:00:00+08:00","readingtime":3,"relpermalink":"/blog/sofastack-projects-joined-cncf-landscape/","summary":"2019 年 6 月 25 日，全球知名开源组织云原生计算基金会 CNCF 宣布，蚂蚁金服正式成为 CNCF 黄金会员，蚂蚁金服表示将持续加大对开源项目的支持，包括 Kuberne","tags":["SOFAStack","CNCF","开源"],"title":"蚂蚁金服 3 个项目进入 CNCF 云原生全景图 | 开源","type":"blog","url":"/blog/sofastack-projects-joined-cncf-landscape/","wordcount":1278},{"author":"力鲲","categories":"SOFAJRaft","content":" SOFAStack Scalable Open Financial Architecture Stack 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。\n 本文为《剖析 | SOFAJRaft 实现原理》第四篇，本篇作者力鲲，来自蚂蚁金服。《剖析 | SOFAJRaft 实现原理》系列由 SOFA 团队和源码爱好者们出品，项目代号：SOFA:JRaftLab/，目前领取已经完成，感谢大家的参与。\nSOFAJRaft 是一个基于 Raft 一致性算法的生产级高性能 Java 实现，支持 MULTI-RAFT-GROUP，适用于高负载低延迟的场景。\nSOFAJRaft ：https://github.com/sofastack/sofa-jraft\n前言 在 Raft 算法中，选举是很重要的一部分，所谓选举也就是在多个节点中选出一个 Leader 节点，由他来对外提供写服务 （以及默认情况下的读服务）。\n在剖析源码时，对选举机制的理解经常会遇到两极分化的情况，对于了解 Raft 算法基本原理的同学，阅读源码就是品味实现之巧妙的过程，而对初体验的同学，却会陷入丈二和尚的窘境，仿佛坠入云里雾里。\n为了提升文章的可读性，我还是希望花一部分篇幅讲清楚选举机制的基本原理，以便后面集中注意力于代码实现。下面是一段图文比喻，帮助理解的同时也让整篇文章不至于过早陷入细节的讨论。\n问题1：选举要解决什么 一个分布式集群可以看成是由多条战船组成的一支舰队，各船之间通过旗语来保持信息交流。这样的一支舰队中，各船既不会互相完全隔离，但也没法像陆地上那样保持非常密切的联系，天气、海况、船距、船只战损情况导致船舰之间的联系存在但不可靠。\n舰队作为一个统一的作战集群，需要有统一的共识、步调一致的命令，这些都要依赖于旗舰指挥。各舰船要服从于旗舰发出的指令，当旗舰不能继续工作后，需要有别的战舰接替旗舰的角色。\n图1 - 所有船有责任随时准备接替旗舰\n如何在舰队中，选出一艘得到大家认可的旗舰，这就是 SOFAJRaft 中选举要解决的问题。\n问题2：何时可以发起选举 何时可以发起选举？换句话说，触发选举的标准是什么？这个标准必须对所有战舰一致，这样就能够在标准得到满足时，所有舰船公平的参与竞选。在 SOFAJRaft 中，触发标准就是通信超时，当旗舰在规定的一段时间内没有与 Follower 舰船进行通信时，Follower 就可以认为旗舰已经不能正常担任旗舰的职责，则 Follower 可以去尝试接替旗舰的角色。这段通信超时被称为 Election Timeout （简称 ET）， Follower 接替旗舰的尝试也就是发起选举请求。\n图2 - ET 触发其他船竞选旗舰\n问题3：何时真正发起选举 在选举中，只有当舰队中超过一半的船都同意，发起选举的船才能够成为旗舰，否则就只能开始一轮新的选举。所以如果 Follower 采取尽快发起选举的策略，试图尽早为舰队选出可用的旗舰，就可能引发一个潜在的风险：可能多艘船几乎同时发起选举，结果其中任何一支船都没能获得超过半数选票，导致这一轮选举无果，然后失败的 Follower 们再一次几乎同时发起选举，又一次失败，再选举 again，再失败 again ···\n图3 - 同时发起选举，选票被瓜分\n为避免这种情况，我们采用随机的选举触发时间，当 Follower 发现旗舰失联之后，会选择等待一段随机的时间 Random(0, ET) ，如果等待期间没有选出旗舰，则 Follower 再发起选举。\n图4 - 随机等待时间\n问题4：哪些候选者值得选票 SOFAJRaft 的选举中包含了对两个属性的判断：LogIndex 和 Term，这是整个选举算法的核心部分，也是容易让人产生困惑的地方，因此我们做一下解释：\n Term：我们会对舰队中旗舰的历史进行编号，比如舰队的第1任旗舰、第2任旗舰，这个数字我们就用 Term 来表示。由于舰队中同时最多只能有一艘舰船担任旗舰，所以每一个 Term 只归属于一艘舰船，显然 Term 是单调递增的。 LogIndex：每任旗舰在职期间都会发布一些指令（称其为“旗舰令”，类比“总统令”），这些旗舰令当然也是要编号归档的，这个编号我们用 Term 和 LogIndex 两个维度来标识，表示“第 Term 任旗舰发布的第 LogIndex 号旗舰令”。不同于现实中的总统令，我们的旗舰令中的 LogIndex 是一直递增的，不会因为旗舰的更迭而从头开始计算。  图5 - 总统令 Vs 旗舰令，LogIndex 稍有区别\n所有的舰船都尽可能保存了过去从旗舰接收到的旗舰令，所以我们选举的标准就是哪艘船保存了最完整的旗舰令，那他就最有资格接任旗舰。具体来说，参与投票的船 V 不会对下面两种候选者 C 投票：一种是 lastTermC \u0026amp;lt; lastTermV；另一种是 (lastTermV == lastTermC) \u0026amp;amp;\u0026amp;amp; (lastLogIndexV \u0026amp;gt; lastLogIndexC)。\n稍作解释，第一种情况说明候选者 C 最后一次通信过的旗舰已经不是最新的旗舰了，至少比 V 更滞后，所以它所知道的旗舰令也不可能比 V 更完整。第二种情况说明，虽然 C 和 V 都与同一个旗舰有过通信，但是候选者 C 从旗舰处获得的旗舰令不如 V 完整 (lastLogIndexV \u0026amp;gt; lastLogIndexC)，所以 V 不会投票给它。\n图6 - Follower 船 b 拒绝了船 c 而投票给船 a，船 a 旗舰令有一个空白框表示“第 Term 任旗舰”没有发布过任何旗舰令\n问题5：如何避免不够格的候选者“捣乱” 如上一小节所说，SOFAJRaft 将 LogIndex 和 Term 作为选举的评选标准，所以当一艘船发起选举之前，会自增 Term 然后填到选举请求里发给其他船只 （可能是一段很复杂的旗语），表示自己竞选“第 Term + 1 任”旗舰。这里要先说明一个机制，它被用来保证各船只的 Term 同步递增：当参与投票的 Follower 船收到这个投票请求后，如果发现自己的 Term 比投票请求里的小，就会自觉更新自己的 Term 向候选者看齐，这样能够很方便的将 Term 递增的信息同步到整个舰队中。\n图7 - Follower 船根据投票请求更新自己的 Term\n但是这种机制也带来一个麻烦，如果一艘船因为自己的原因没有看到旗舰发出的旗语，他就会自以为是的试图竞选成为新的旗舰，虽然不断发起选举且一直未能当选（因为旗舰和其他船都正常通信），但是它却通过自己的投票请求实际抬升了全局的 Term，这在 SOFAJRaft 算法中会迫使旗舰 stepdown （从旗舰的位置上退下来）。\n图8 - 自以为是的捣乱者，迫使旗舰 stepdown\n所以我们需要一种机制阻止这种“捣乱”，这就是预投票 (pre-vote) 环节。候选者在发起投票之前，先发起预投票，如果没有得到半数以上节点的反馈，则候选者就会识趣的放弃参选，也就不会抬升全局的 Term。\n图9 - Pre-vote …","date":1562742000,"description":"本文为《剖析 | SOFAJRaft 实现原理》第四篇，本篇作者力鲲，来自蚂蚁金服","dir":"blog/sofa-jraft-election-mechanism/","fuzzywordcount":3200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"e40fefafd980ac2308a3ba6f3fda9cdd","permalink":"/blog/sofa-jraft-election-mechanism/","publishdate":"2019-07-10T15:00:00+08:00","readingtime":7,"relpermalink":"/blog/sofa-jraft-election-mechanism/","summary":"SOFAStack Scalable Open Financial Architecture Stack 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文为《剖析 |","tags":["SOFAJRaft","SOFALab","剖析 | SOFAJRaft 实现原理"],"title":"SOFAJRaft 选举机制剖析 | SOFAJRaft 实现原理","type":"blog","url":"/blog/sofa-jraft-election-mechanism/","wordcount":3152},{"author":"SOFAStack","categories":"SOFAStack","content":" 本文根据 KubeCon China 2019 同场活动 SOFAStack Cloud Native Workshop 内容整理，文末包含文档、PPT 地址，欢迎试用和提出建议。\n 2019 年 6 月 25 日，在 KubeCon China 2019，全球知名开源组织云原生计算基金会 CNCF 宣布，蚂蚁金服正式成为 CNCF 黄金会员，蚂蚁金服表示将持续加大对开源项目的支持，包括 Kubernetes，Service Mesh，Serverless，安全容器等方向，并发挥自己的力量。\n在本次大会，蚂蚁金服也与数百名云原生爱好者用五个小时搭建了一个云原生的电商平台，具体怎么做？希望本文能提供一些思路。\n近二十年技术发展：从集中式架构到云原生架构 过去的十几年里，技术发生了翻天覆地的变化，先来简单回顾下：在二十一世纪初，大部分企业的应用还处于集中式架构。这个阶段企业开始做一些信息化的建设工作，典型的一些技术例如集群部署（Tomcat 集群、Weblogic 集群）来保证系统的高可用，以及采购 IOE（IBM，Oracle，EMC）等这些商业化的软硬件产品，通过更高的配置、更好的性能等方式来抗住业务的增长。\n慢慢的，随着公司规模的扩大，集中式架构已经不足以再支撑复杂的业务系统，很多企业开始做一些系统拆分的改造，典型的技术例如 SOA 化。当系统拆分后，就不再需要使用之前昂贵的小型机去部署服务，慢慢的虚拟机的部署方式变成了主流。同样的，服务化后数据库和存储也不再必须采用商业化软硬件的解决方案，企业转为一些开源的解决方案，例如把 Oracle 换成了 MySQL。\n系统的拆分虽然可以带来很多好处，例如使业务内聚，系统之间松耦合，方便快速迭代等。但是随之带来的问题也很明显，例如拆分后系统越来越多，系统间的交互也会变得更加复杂，调用链路变长可能引起性能问题，分布式后数据存储等数据一致性也有不少挑战，还有服务化后带来资源分配、隔离等问题。这时候一些虚拟化和容器化的技术开始涌现，典型技术就是 OpenStack 和 Docker，OpenStack 帮助我们解决了 IaaS 层的建设与管理问题，而 Docker 给了我们资源隔离的最佳实践，但这些并没有解决掉运维复杂的一些问题。\n而近几年，新的云原生的一些技术产品和理念开始出现，例如 Kubernetes、Service Mesh、Serverless 等，这些可以解决应用部署、运维复杂的一些实际问题。\n技术发展下的蚂蚁金服 蚂蚁金服从 2007 年开始从集中式架构走向分布式架构。我们把过去十多年的技术演进过程中自主研发的一套金融级分布式架构沉淀成为 SOFAStack™（Scalable Open Financial Architecture Stack）。\n从 2007 年到 2012 年，蚂蚁金服完成所有业务系统的模块化、服务化改造。通过 TCC 模式解决了服务化、数据拆分等带来的数据一致性的问题，通过注册中心解决了服务单点的问题。\n在完成服务化改造后，随着服务集群的增大，系统的伸缩性遇到了瓶颈，另外为了满足金融级的属性，蚂蚁金服对系统可用性、数据一致性提出了更高的要求。蚂蚁金服从 2013 年开始摸索出了一套单元化的思想，并基于此，推出了同城双活、异地多活、弹性调度等能力，保证业务不停机，数据不丢失。\n再之后随着国内互联网金融的崛起、蚂蚁金服的国际化，蚂蚁金服也将自己的能力和技术开放出来，在金融云上以云产品的形式存在，开发者可以基于此快速搭建金融级能力的分布式系统，同时我们也将内部的一些实践开源出来。\n从 2017 年开始，我们注意到云原生的理念正在快速发展，面对云原生带来的机会和改变，蚂蚁金服的策略是积极拥抱云原生。 因为云原生带来的思想和理念刚好可以用来解决蚂蚁金服内部遇到的一些场景和问题。\n例如 Service Mesh 可以解决中间件等基础能力下层的问题，Serverless 可以解决研发效能的问题，可以让业务开发更专注于业务。这些新的技术和理念蚂蚁金服都会在内部探索并在生产落地，最近我们在深圳 GIAC 首次分享了大规模落地的实践总结，蚂蚁金服 Service Mesh 落地实践与挑战 | GIAC 实录。同时，我们也会将这些云原生落地实践开源出来，并和社区一起共同推进和建设金融级的云原生标准。\nSOFAStack 开源版本： **2018 年 4 月 19 日正式宣布逐步开源 SOFAStack，开源的策略是 Open Core，也就是把核心的接口和实现都开源出来，内部保留老的兼容代码。**到现在为止差不多 1 年 2 个月的时间，已经开源了十几个项目，累计超过 25,600 Star，120 多位贡献者， 以及 30 多家生产用户，近期也认证了两位社区 Committer，这里想再次感谢开发者和企业的信任和认可，我们将持续优化和扩大开源版图。\n我们看下这张图，这里可以看到 SOFAStack 体系下开源了很多微服务相关的技术组件，例如 SOFABoot、SOFARPC 等，我们也和社区其它优秀的开源产品进行了兼容或者集成，利用这些组件可以快速的搭建出金融级分布式架构系统。开源的源码可以在这张图下面的 Github 地址上找到。本次的 Workshop 我们就会利用到开源的一些技术组件。\nSOFAStack 云产品： 上图是云上 SOFAStack 的架构图，我们可以看到 SOFAStack 商业化对外输出的是完整的解决方案。支撑解决方案的就是本次要体验的分布式中间件和云应用引擎等等能力。除此之外还有完善的研发效能平台服务以及技术风险防控平台。关于这部分内容，在本次下午场会有更详细的介绍和体验。\nLet\u0026amp;rsquo;s get started! 刚聊了这么多，大家是不是想动手试试了呢？本次 Demo 将带领大家综合利用开源版本的 SOFAStack 和云上产品，五小时实现一个在线电商平台。\n下面简单介绍下本次 Workshop 的内容，如下图：\n上午\n 构建基础电商平台（书店） ，并改造为微服务架构； 基于 SOFABoot 动态模块能力实时的电商平台（书店）增加智能推荐的能力； 用分布式事务 Seata 来解决微服务拆分后的分布式事务的问题，保证购买和余额的数据一致性；  下午\n 通过 Serverless 快速上云，利用 SOFA SAS 发布书店到云环境上，根据流量自动扩缩容； 通过 Service Mesh 的方式来实现精度灰度和流控的能力；  这是提到的是在线书店的系统架构图，最上面是部署好的一些基础设施，包括注册中心 SOFARegistry，服务管控台 SOFADashboard，监控度量 SOFALookout 等，我们已经提前准备好了这部分内容。\n下面就是业务的内容。为了方便，我们不再做前后端分类部署，本次大家只需要操作 2 个应用：\n左边是网页系统和库存系统，提供库存操作服务，右边是账务系统，提供余额相关服务，当用户的请求进来时，库存系统需要通过 RPC 调到账务系统。\n另外库存服务和余额服务分别对应的是独立的数据库，这个后面会用分布式事务 Seata 去解决分布式事务的问题。\nSOFAStack …","date":1562742000,"description":"本文根据 KubeCon China 2019 同场活动 SOFAStack Cloud Native Workshop 内容整理，文末包含文档、PPT 地址，欢迎试用和提出建议。","dir":"blog/sofastack-cloud-native-workshop-show/","fuzzywordcount":2700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"bed45f24a92c60ca5b141952abdc2049","permalink":"/blog/sofastack-cloud-native-workshop-show/","publishdate":"2019-07-10T15:00:00+08:00","readingtime":6,"relpermalink":"/blog/sofastack-cloud-native-workshop-show/","summary":"本文根据 KubeCon China 2019 同场活动 SOFAStack Cloud Native Workshop 内容整理，文末包含文档、PPT 地址，欢迎试用和提出建议。 2019 年 6 月 25 日，在 KubeCon China 2019，全球知名开源组织云原生计","tags":["分布式事务","SOFABoot","Service Mesh","开源","Seata"],"title":"五小时构建云原生电商平台 | KubeCon SOFAStack Workshop 详解","type":"blog","url":"/blog/sofastack-cloud-native-workshop-show/","wordcount":2654},{"author":"潘潘","categories":"SOFAChannel","content":"概要  活动主题：SOFAChannel#7：扩展 Kubernetes 实现金融级云原生发布部署 - 自定义资源 CAFEDeployment 的背景、实现和演进 活动时间：7 月 18 日周四晚 7 点 活动形式：线上直播 直播视频回顾 直播回顾文章  介绍 | SOFAChannel \u0026amp;lt;SOFA:Channel/\u0026amp;gt; 有趣实用的分布式架构频道：前沿技术、直播 Coding、观点“抬杠”，多种形式。\n\u0026amp;lt;SOFA:Channel/\u0026amp;gt; 将作为 SOFA 所有在线内容的承载，包含直播/音视频教程，集中体现 SOFAStack 的能力全景图。\n| SOFAChannel#7：扩展 Kubernetes 实现金融级云原生发布部署 - 自定义资源 CAFEDeployment 的背景、实现和演进 在 6 月 KubeCon 大会期间，蚂蚁金服正式宣布加入了 CNCF 成为黄金会员，同时 SOFAStack-CAFE 云应用引擎产品也通过了 K8S 一致性认证，旨在向广大金融机构提供云原生的可落地路径。\n为满足金融级云原生发布部署、变更管控场景对于可灰度、可监控、可应急的需求，SOFAStack 产品研发团队在 Kubernetes 基础上实现了自定义资源 CAFEDeployment ，它能够通过可靠而灵活的分发、风险控制的部署策略以及高性能的原地升级更新扩展部署能力。它尤其消除了金融服务行业所面临的技术障碍，使用户能够专心发展核心业务。\n与 Kubernetes 原生工作负载对象 Deployment 所提供的简洁轻量的滚动发布相比，CAFEDeployment 旨在满足金融场景对分批发布、多活容灾、原地升级等方面的诉求。\n7 月 18 日周四晚 7 点，将邀请 蚂蚁金服 SOFAStack-CAFE 云应用引擎 容器应用服务研发负责人 枫晟 为大家分享《扩展 Kubernetes 实现金融级云原生发布部署 - 自定义资源 CAFEDeployment 的背景、实现和演进》。\n在此次分享中，将介绍对此 Kubernetes 扩展能力的相关观点主张、产品探索和实际演示。\n| 加入 SOFA 钉钉互动群 欢迎加入直播互动钉钉群：23195297（搜索群号加入即可）\n| 点击即可报名 https://tech.antfin.com/community/live/737\n议程 19:00-19:05 主持人开场 SOFAGirl 主持人\n19:05-20:00 扩展 Kubernetes 实现金融级云原生发布部署 - 自定义资源 CAFEDeployment 的背景、实现和演进 枫晟 蚂蚁金服 SOFAStack-CAFE 云应用引擎 容器应用服务研发负责人\n本期分享大纲：  Kubernetes Deployment 发展历史与现状 Kubernetes Deployment 在互联网金融云场景下的问题与挑战 CafeDeployment 适配互联网金融发布的工作负载 CafeDeployment 的运行机制 CafeDeployment 功能演示  嘉宾  SOFAGirl 主持人 枫晟 蚂蚁金服 SOFAStack-CAFE 云应用引擎 容器应用服务研发负责人  ","date":1562573400,"description":"7 月 18 日周四晚 7 点，线上直播第 7 期。","dir":"activities/sofa-channel-7/","fuzzywordcount":900,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"51c929733c988190de480a3a0dc5e735","permalink":"/activities/sofa-channel-7/","publishdate":"2019-07-08T16:10:00+08:00","readingtime":2,"relpermalink":"/activities/sofa-channel-7/","summary":"概要 活动主题：SOFAChannel#7：扩展 Kubernetes 实现金融级云原生发布部署 - 自定义资源 CAFEDeployment 的背景、实现和演进 活动时间：7 月 18 日周四晚 7 点 活动形式","tags":["SOFAChannel","CAFEDeployment"],"title":"SOFAChannel#7：扩展 Kubernetes 实现金融级云原生发布部署 - 自定义资源 CAFEDeployment 的背景、实现和演进","type":"activities","url":"/activities/sofa-channel-7/","wordcount":813},{"author":"SOFAStack","categories":"SOFAStack","content":" 2019 年 6 月 25 日，全球知名开源组织云原生计算基金会 CNCF 宣布，蚂蚁金服正式成为 CNCF 黄金会员，蚂蚁金服表示将持续加大对开源项目的支持，包括 Kubernetes，ServiceMesh，Serverless，安全容器等方向，并发挥自己的力量。SOFAStack 作为蚂蚁金服重要的开源项目，最近也与 CNCF 有故事发生。\n 近期，CNCF 发布了最新版本的 Cloud Native Landscape，蚂蚁金服金融级分布式架构 SOFAStack 中有 3 个项目被纳入，分别是 Service Mesh 数据平面代理 SOFAMosn、分布式链路跟踪系统 SOFATracer 和 RPC 服务框架 SOFARPC。\nCNCF \u0026amp;amp; CNCF Cloud Native Landscape CNCF(Cloud Native Computing Foundation)，是由 Google 牵头创立的云原生计算开源软件基金会。它致力于云原生(Cloud Native)技术的普及和可持续发展。2016 年 11 月，CNCF 开始维护 Cloud Native Landscape，汇总流行热门的云原生技术与工具，并加以分类，为企业构建云原生体系提供参考，在云生态研发、运维领域具有广泛影响力。\nSOFAStack \u0026amp;amp; CNCF Cloud Native Landscape 蚂蚁金服金融级分布式架构 SOFAStack 中的 3 个项目加入这次最新版本的 Cloud Native Landscape，分别是 Service Mesh 数据平面代理 SOFAMosn 、分布式链路跟踪系统 SOFATracer 和 RPC 服务框架 SOFARPC。\nSOFAMosn Star 一下✨：https://github.com/sofastack/sofa-mosn\nSOFAMosn(Modular Observable Smart Network)，是一款采用 GoLang 开发的 Service Mesh 数据平面代理， 功能和定位类似 Envoy ，旨在提供分布式，模块化，可观察，智能化的代理能力。 SOFAMosn 支持 Envoy 和 Istio 的 API，可以和 Istio 集成，在 SOFAMesh 中，我们使用 SOFAMosn 替代 Envoy。 SOFAMosn 初始版本由蚂蚁金服和阿里大文娱 UC 事业部携手贡献，期待社区一起来参与后续开发，共建一个开源精品项目。\nSOFARPC Star 一下✨：https://github.com/sofastack/sofa-rpc\nSOFARPC 是蚂蚁金服开源的一款基于 Java 实现的 RPC 服务框架，为应用之间提供远程服务调用能力，具有高可伸缩性，高容错性，目前蚂蚁金服所有业务相互间的 RPC 调用都是采用 SOFARPC。SOFARPC 为用户提供了负载均衡，流量转发，链路追踪，链路数据透传，故障剔除等功能。\nSOFARPC 还支持不同的协议，目前包括Bolt， RESTful ， Dubbo ， H2C 协议进行通信。其中 Bolt 是蚂蚁金融服务集团开放的基于 Netty 开发的网络通信框架。\nSOFATracer Star 一下✨：https://github.com/sofastack/sofa-tracer\nSOFATracer 是蚂蚁金服开发的基于 OpenTracing 规范 的分布式链路跟踪系统，其核心理念就是通过一个全局的 TraceId 将分布在各个服务节点上的同一次请求串联起来。通过统一的 TraceId 将调用链路中的各种网络调用情况以日志的方式记录下来同时也提供远程汇报到 Zipkin 进行展示的能力，以此达到透视化网络调用的目的。\nSOFAStack 开源家族 SOFAStack™（Scalable Open Financial Architecture Stack）是用于快速构建金融级分布式架构的一套中间件，也是在金融场景里锤炼出来的最佳实践。\n图为 SOFAStack 开源全景图，其中橙色部分为 SOFAStack 包含的开源组件，白色部分为兼容或集成开源社区其它优秀的开源产品\n特别感谢 SOFAStack 开源社区的每一个你 **2018 年 4 月 19 日正式宣布逐步开源 SOFAStack，开源的策略是 Open Core，也就是把核心的接口和实现都开源出来，内部保留老的兼容代码。**到现在为止差不多 1 年 2 个月的时间，已经开源了十几个项目，累计超过 25,600 Star，120 多位贡献者， 以及 30 多家生产用户，近期认证了两位社区 Committer，再次感谢开发者和企业的信任和认可，因为你们，SOFAStack 社区才能会更好。\n文中涉及的相关链接：\n SOFAMosn：https://github.com/sofastack/sofa-mosn SOFARPC：https://github.com/sofastack/sofa-rpc SOFATracer：https://github.com/sofastack/sofa-tracer SOFAMesh：https://github.com/sofastack/sofa-mesh  ","date":1562569200,"description":"近期，CNCF 发布了最新版本的 Cloud Native Landscape，蚂蚁金服金融级分布式架构 SOFAStack 中有 3 个项目被纳入。","dir":"blog/sofastack-cncf-cloud-native-landscape/","fuzzywordcount":1600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"7146cdd7e74b9901a8ac20cb3e80cf6e","permalink":"/blog/sofastack-cncf-cloud-native-landscape/","publishdate":"2019-07-08T15:00:00+08:00","readingtime":4,"relpermalink":"/blog/sofastack-cncf-cloud-native-landscape/","summary":"2019 年 6 月 25 日，全球知名开源组织云原生计算基金会 CNCF 宣布，蚂蚁金服正式成为 CNCF 黄金会员，蚂蚁金服表示将持续加大对开源项目的支持，包括 Kuberne","tags":["SOFAStack"],"title":"蚂蚁金服 3 个项目进入 CNCF 云原生全景图 | 开源","type":"blog","url":"/blog/sofastack-cncf-cloud-native-landscape/","wordcount":1592},{"author":"SOFAStack","categories":"SOFAStack","content":"2019 年 7 月 3 日，在 2019 云计算开源产业大会上，蚂蚁金服自主研发的金融级分布式架构 SOFAStack（Scalable Open Financial Architecture Stack）荣获 OSCAR 尖峰开源技术创新奖（自主研发）。云计算开源产业大会由中国信息通信研究院主办，是中国云计算开源领域最权威和专业的行业盛会。\n本次大会上，中国信息通信研究院还发布了《混合云白皮书（2019年）》，该白皮书梳理了混合云的最新发展现状、关键能力、应用案例和技术发展趋势。基于完全自主研发的 SOFAStack 金融级分布式架构的网商银行三地五中心异地多活部署方案被作为典型应用案例入选其中。\n完全自主研发的金融级分布式架构 SOFAStack SOFAStack 是蚂蚁金服完全自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，如微服务研发框架、RPC 框架、服务注册中心、分布式定时任务、限流/熔断框架、动态配置推送、分布式链路追踪、Metrics 监控度量、分布式高可用消息队列、分布式事务框架和分布式数据库代理层等。\n据了解，经过数代架构演进和“双十一”考验的 SOFAStack，已于 2018 年 4 月正式对外开源，仅一年时间，SOFAStack 所有相关的开源代码，累计获得 16,000+ 个 Star，并有 110+ 个代码贡献者参与其中。\nSOFAStack 助力客户数字化转型 作为一套分布式架构的完整的解决方案，SOFAStack 在真实的金融场景里锤炼出不少最佳实践。\n2017 年 10 月，SOFAStack 与南京银行共同打造出“鑫云+”互金开放平台。该平台具备高性能承载、敏捷开发、强数据一致性和容灾能力等特性，从而使得南京银行互金核心系统在贷款交易处理能力、成本控制和对接效率都得到了极大的提升。南京银行与互联网平台合作开展线上业务仅一年时间，业务量就已经达到了过去十年传统线下消费金融业务的总和。南京银行“鑫云+”平台上线后，业务快速增长，贷款交易处理量增长了数倍。\n据介绍，SOFAStack 还帮助中国人保健康打造行业领先的互联网保险云核心业务系统，助力网商银行成为中国第一家将核心系统架构在金融云上的银行。\nSOFAStack 引领开源技术创新 2019 年 6 月 25 日，蚂蚁金服正式成为 CNCF 云原生计算基金会黄金会员，SOFAStack 云应用引擎产品 CAFE 已通过 CNCF 一致性认证，积极拥抱云原生的同时，满足严苛金融业务场景需求、保障金融技术风险。\n蚂蚁金服是金融级云原生的首倡者，主张金融级的云原生容器产品必须拥有稳定性与高可用保障、无限弹性扩展、运行时安全的能力，这些理念也集中体现在蚂蚁金服的金融级分布式开源项目 SOFAStack 里。\n蚂蚁金服一直积极参与开源社区共建。截至目前，蚂蚁金服已经有 400 多个开源项目。除了 SOFAStack 系列，Ant Design、SQLFlow、EggJS、Seata（与阿里巴巴共建）等也成为社区热门。\n蚂蚁金服金融科技产品技术总监杨冰表示：“开源是一种可以使客户和上下游产业共同参与和发展的可行模式，是个共赢的模式。在贡献蚂蚁金服的技术沉淀给社区的同时，也期待社区、合作伙伴甚至客户，都能够一起参与共建，形成行业标准和最佳实践。只有开放才能求同存异，共同发展。”\n","date":1562223600,"description":"在 2019 云计算开源产业大会上，蚂蚁金服自主研发的金融级分布式架构 SOFAStack（Scalable Open Financial Architecture Stack）荣获 OSCAR 尖峰开源技术创新奖（自主研发）。","dir":"blog/sofastack-2019-oscar/","fuzzywordcount":1300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"21da7fc5e118681336c84d2dc46fe6bb","permalink":"/blog/sofastack-2019-oscar/","publishdate":"2019-07-04T15:00:00+08:00","readingtime":3,"relpermalink":"/blog/sofastack-2019-oscar/","summary":"2019 年 7 月 3 日，在 2019 云计算开源产业大会上，蚂蚁金服自主研发的金融级分布式架构 SOFAStack（Scalable Open Financial Architecture Stack）荣获 OSCAR 尖峰开","tags":["SOFAStack"],"title":"蚂蚁金服 SOFAStack 荣获云计算开源产业大会尖峰开源技术创新奖","type":"blog","url":"/blog/sofastack-2019-oscar/","wordcount":1223},{"author":"绍辉","categories":"Seata","content":"获取本次分享完整 PPT：下载地址\n本文整理自蚂蚁金服技术专家、分布式事务 Seata 发起者之一张森（花名：绍辉）在 GIAC 全球互联网架构大会的分享。详细讲解了在分布式架构演进中，蚂蚁金服面对的跨服务、跨数据库的业务数据一致性问题以及应对措施，并分享了分布式事务 Seata 的 AT、TCC、Saga 和 XA 四种模式。\nSeata：https://github.com/seata/seata\n一、自研分布式事务解决数据一致性问题 1.1 分布式事务问题产生原因 1.1.1 数据库的水平拆分 蚂蚁金服的业务数据库起初是单库单表，但随着业务数据规模的快速发展，数据量越来越大，单库单表逐渐成为瓶颈。所以我们对数据库进行了水平拆分，将原单库单表拆分成数据库分片。\n如下图所示，分库分表之后，原来在一个数据库上就能完成的写操作，可能就会跨多个数据库，这就产生了跨数据库事务问题。\n1.1.2 业务服务化拆分 在业务发展初期，“一块大饼”的单业务系统架构，能满足基本的业务需求。但是随着业务的快速发展，系统的访问量和业务复杂程度都在快速增长，单系统架构逐渐成为业务发展瓶颈，解决业务系统的高耦合、可伸缩问题的需求越来越强烈。\n如下图所示，蚂蚁金服按照面向服务（SOA）的架构的设计原则，将单业务系统拆分成多个业务系统，降低了各系统之间的耦合度，使不同的业务系统专注于自身业务，更有利于业务的发展和系统容量的伸缩。\n业务系统按照服务拆分之后，一个完整的业务往往需要调用多个服务，如何保证多个服务间的数据一致性成为一个难题。\n1.2 蚂蚁金服遇到的数据一致性问题 在数据库水平拆分、服务垂直拆分之后，一个业务操作通常要跨多个数据库、服务才能完成。在分布式网络环境下，我们无法保障所有服务、数据库都百分百可用，一定会出现部分服务、数据库执行成功，另一部分执行失败的问题。\n当出现部分业务操作成功、部分业务操作失败时，业务数据就会出现不一致。以金融业务中比较常见的“转账”场景为例：\n如下图所示，在支付宝的“转账”操作中，要分别完成 4 个动作：\n 创建交易订单； 创建支付订单； A 账户扣钱； B 账户加钱；  而完成以上操作要分别访问 3 个服务和 4 个数据库。\n在分布式环境下，肯定会出现部分操作成功、部分操作失败的问题，比如：A 账户的钱扣了，但是 B 账户的钱没加上，这就造成了资金损失，影响资金安全。\n在金融业务场景下，我们必须保证“转账”的原子性，要么所有操作全部成功，要么全部失败，不允许出现部分成功部分失败的现象。\n为了解决跨数据库、跨服务的业务数据一致性问题，蚂蚁金服自主研发了分布式事务中间件。\n从 2007 年开始做分布式事务并支持双十一，至今已经有 12 年。\n2013 年，蚂蚁金服开始做单元化改造，分布式事务也开始支持 LDC、异地多活和高可用容灾，解决了机房故障情况下服务快速恢复的问题。\n2014 年，蚂蚁金服分布式事务中间件 DTX(Distributed Transaction-eXtended)开始通过蚂蚁金融云对外输出，我们发展了一大批的外部用户。在发展外部客户的过程中，外部客户表示愿意牺牲一部分性能（无蚂蚁的业务规模）以换取接入便利性和无侵入性。所以在 2015 年，我们开始做无侵入的事务解决方案：FMT 模式和 XA 模式。\n蚂蚁金服分布式事务（Distributed Transaction-eXtended，简称 DTX）链接：\nhttps://tech.antfin.com/products/DTX\n二、投入开源社区，共建开源分布式事务 Seata  2.1 分布式事务 Seata 介绍 Seata（Simple Extensible Autonomous Transaction Architecture，简单可扩展自治事务框架）是 2019 年 1 月份蚂蚁金服和阿里巴巴共同开源的分布式事务解决方案。Seata 开源半年左右，目前已经有接近一万 star，社区非常活跃。我们热忱欢迎大家参与到 Seata 社区建设中，一同将 Seata 打造成开源分布式事务标杆产品。\nSeata：https://github.com/seata/seata\n2.2 分布式事务 Seata 产品模块 如下图所示，Seata 中有三大模块，分别是 TM、RM 和 TC。 其中 TM 和 RM 是作为 Seata 的客户端与业务系统集成在一起，TC 作为 Seata 的服务端独立部署。\n在 Seata 中，分布式事务的执行流程：\n TM 开启分布式事务（TM 向 TC 注册全局事务记录）； 按业务场景，编排数据库、服务等事务内资源（RM 向 TC 汇报资源准备状态 ）； TM 结束分布式事务，事务一阶段结束（TM 通知 TC 提交/回滚分布式事务）； TC 汇总事务信息，决定分布式事务是提交还是回滚； TC 通知所有 RM 提交/回滚 资源，事务二阶段结束。  2.3 分布式事务 Seata 解决方案 Seata 会有 4 种分布式事务解决方案，分别是 AT 模式、TCC 模式、Saga 模式和 XA 模式。\n2.3.1 AT 模式 今年 1 月份，Seata 开源了 AT 模式。AT 模式是一种无侵入的分布式事务解决方案。在 AT 模式下，用户只需关注自己的“业务 SQL”，用户的 “业务 SQL” 作为一阶段，Seata 框架会自动生成事务的二阶段提交和回滚操作。\nAT 模式如何做到对业务的无侵入 ：  一阶段：  在一阶段，Seata 会拦截“业务 SQL”，首先解析 SQL 语义，找到“业务 SQL”要更新的业务数据，在业务数据被更新前，将其保存成“before image”，然后执行“业务 SQL”更新业务数据，在业务数据更新之后，再将其保存成“after image”，最后生成行锁。以上操作全部在一个数据库事务内完成，这样保证了一阶段操作的原子性。\n 二阶段提交：  二阶段如果是提交的话，因为“业务 SQL”在一阶段已经提交至数据库， 所以 Seata 框架只需将一阶段保存的快照数据和行锁删掉，完成数据清理即可。\n 二阶段回滚：  二阶段如果是回滚的话，Seata 就需要回滚一阶段已经执行的“业务 SQL”，还原业务数据。回滚方式便是用“before image”还原业务数据；但在还原前要首先要校验脏写，对比“数据库当前业务数据”和 “after image”，如果两份数据完全一致就说明没有脏写，可以还原业务数据，如果不一致就说明有脏写，出现脏写就需要转人工处理。\nAT 模式的一阶段、二阶段提交和回滚均由 Seata 框架自动生成，用户只需编写“业务 SQL”，便能轻松接入分布式事务，AT 模式是一种对业务无任何侵入的分布式事务解决方案。\n2.3.2 TCC 模式 2019 年 3 月份，Seata 开源了 TCC 模式，该模式由蚂蚁金服贡献。TCC 模式需要用户根据自己的业务场景实现 Try、Confirm 和 Cancel 三个操作；事务发起方在一阶段 执行 Try 方式，在二阶段提交执行 Confirm 方法，二阶段回滚执行 Cancel 方法。\nTCC 三个方法描述：\n Try：资 …","date":1562050800,"description":"本文整理自蚂蚁金服技术专家、分布式事务 Seata 发起者之一张森（花名：绍辉）在 GIAC 全球互联网架构大会的分享。","dir":"blog/seata-distributed-transaction-deep-dive/","fuzzywordcount":5800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"d87c4d85b8c16bfc24a0b9bea52b604d","permalink":"/blog/seata-distributed-transaction-deep-dive/","publishdate":"2019-07-02T15:00:00+08:00","readingtime":12,"relpermalink":"/blog/seata-distributed-transaction-deep-dive/","summary":"获取本次分享完整 PPT：下载地址 本文整理自蚂蚁金服技术专家、分布式事务 Seata 发起者之一张森（花名：绍辉）在 GIAC 全球互联网架构大会的分享。详细讲解了","tags":["分布式事务","实践","开源","Seata"],"title":"Seata 分布式事务实践和开源详解 | GIAC 实录","type":"blog","url":"/blog/seata-distributed-transaction-deep-dive/","wordcount":5775},{"author":"米麒麟","categories":"SOFAJRaft","content":" SOFAStack Scalable Open Financial Architecture Stack 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。\n 本文为《剖析 | SOFAJRaft 实现原理》第三篇，本篇作者米麒麟，来自陆金所。《剖析 | SOFAJRaft 实现原理》系列由 SOFA 团队和源码爱好者们出品，项目代号：SOFA:JRaftLab/，目前领取已经完成，感谢大家的参与。\nSOFAJRaft 是一个基于 Raft 一致性算法的生产级高性能 Java 实现，支持 MULTI-RAFT-GROUP，适用于高负载低延迟的场景。\nSOFAJRaft ：https://github.com/sofastack/sofa-jraft\n前言 线性一致读是在分布式系统中实现 Java volatile 语义，当客户端向集群发起写操作的请求并且获得成功响应之后，该写操作的结果要对所有后来的读请求可见。实现线性一致读常规手段是走 Raft 协议，将读请求同样按照 Log 处理，通过日志复制和状态机执行获取读结果返回给客户端，SOFAJRaft 采用 ReadIndex 替代走 Raft 状态机的方案。本文将围绕 Raft Log Read，ReadIndex Read 以及 Lease Read 等方面剖析线性一致读原理，阐述 SOFAJRaft 如何使用 ReadIndex 和 Lease Read 实现线性一致读：\n 什么是线性一致读？共识算法只能保证多个节点对某个对象的状态是一致的，以 Raft 为例只能保证不同节点对 Raft Log 达成一致，那么 Log 后面的状态机的一致性呢？ 基于 ReadIndex 和 Lease Read 方式 SOFAJRaft 如何实现高效的线性一致读？  线性一致读 什么是线性一致读? 所谓线性一致读，一个简单的例子是在 t1 的时刻我们写入了一个值，那么在 t1 之后，我们一定能读到这个值，不可能读到 t1 之前的旧值(想想 Java 中的 volatile 关键字，即线性一致读就是在分布式系统中实现 Java volatile 语义)。简而言之是需要在分布式环境中实现 Java volatile 语义效果，即当 Client 向集群发起写操作的请求并且获得成功响应之后，该写操作的结果要对所有后来的读请求可见。和 volatile 的区别在于 volatile 是实现线程之间的可见，而 SOFAJRaft 需要实现 Server 之间的可见。\n如上图 Client A、B、C、D 均符合线性一致读，其中 D 看起来是 Stale Read，其实并不是，D 请求横跨 3 个阶段，而 Read 可能发生在任意时刻，所以读到 1 或 2 都行。\nRaft Log read 实现线性一致读最常规的办法是走 Raft 协议，将读请求同样按照 Log 处理，通过 Log 复制和状态机执行来获取读结果，然后再把读取的结果返回给 Client。因为 Raft 本来就是一个为了实现分布式环境下线性一致性的算法，所以通过 Raft 非常方便的实现线性 Read，也就是将任何的读请求走一次 Raft Log，等此 Log 提交之后在 apply 的时候从状态机里面读取值，一定能够保证这个读取到的值是满足线性要求的。\n当然，因为每次 Read 都需要走 Raft 流程，Raft Log 存储、复制带来刷盘开销、存储开销、网络开销，走 Raft Log不仅仅有日志落盘的开销，还有日志复制的网络开销，另外还有一堆的 Raft “读日志” 造成的磁盘占用开销，导致 Read 操作性能是非常低效的，所以在读操作很多的场景下对性能影响很大，在读比重很大的系统中是无法被接受的，通常都不会使用。\n在 Raft 里面，节点有三个状态：Leader，Candidate 和 Follower，任何 Raft 的写入操作都必须经过 Leader，只有 Leader 将对应的 Raft Log 复制到 Majority 的节点上面认为此次写入是成功的。所以如果当前 Leader 能确定一定是 Leader，那么能够直接在此 Leader 上面读取数据，因为对于 Leader 来说，如果确认一个 Log 已经提交到大多数节点，在 t1 的时候 apply 写入到状态机，那么在 t1 后的 Read 就一定能读取到这个新写入的数据。\n那么如何确认 Leader 在处理这次 Read 的时候一定是 Leader 呢？在 Raft 论文里面，提到两种方法：\n ReadIndex Read Lease Read  ReadIndex Read 第一种是 ReadIndex Read，当 Leader 需要处理 Read 请求时，Leader 与过半机器交换心跳信息确定自己仍然是 Leader 后可提供线性一致读：\n Leader 将自己当前 Log 的 commitIndex 记录到一个 Local 变量 ReadIndex 里面； 接着向 Followers 节点发起一轮 Heartbeat，如果半数以上节点返回对应的 Heartbeat Response，那么 Leader就能够确定现在自己仍然是 Leader； Leader 等待自己的 StateMachine 状态机执行，至少应用到 ReadIndex 记录的 Log，直到 applyIndex 超过 ReadIndex，这样就能够安全提供 Linearizable Read，也不必管读的时刻是否 Leader 已飘走； Leader 执行 Read 请求，将结果返回给 Client。  使用 ReadIndex Read 提供 Follower Read 的功能，很容易在 Followers 节点上面提供线性一致读，Follower 收到 Read 请求之后：\n Follower 节点向 Leader 请求最新的 ReadIndex； Leader 仍然走一遍之前的流程，执行上面前 3 步的过程(确定自己真的是 Leader)，并且返回 ReadIndex 给 Follower； Follower 等待当前的状态机的 applyIndex 超过 ReadIndex； Follower 执行 Read 请求，将结果返回给 Client。  不同于通过 Raft Log 的 Read，ReadIndex Read 使用 Heartbeat 方式来让 Leader 确认自己是 Leader，省去 Raft Log 流程。相比较于走 Raft Log 方式，ReadIndex Read 省去磁盘的开销，能够大幅度提升吞吐量。虽然仍然会有网络开销，但是 Heartbeat 本来就很小，所以性能还是非常好的。\nLease Read 虽然 ReadIndex Read 比原来的 Raft Log Read 快很多，但毕竟还是存在 Heartbeat 网络开销，所以考虑做更进一步的优化。Raft 论文里面提及一种通过 Clock + Heartbeat 的 Lease Read 优 …","date":1562050800,"description":"本文为《剖析 | SOFAJRaft 实现原理》第三篇，本篇作者米麒麟，来自陆金所。","dir":"blog/sofa-jraft-linear-consistent-read-implementation/","fuzzywordcount":4800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"cfa43268e0ca8424ff44bd4397f720b3","permalink":"/blog/sofa-jraft-linear-consistent-read-implementation/","publishdate":"2019-07-02T15:00:00+08:00","readingtime":10,"relpermalink":"/blog/sofa-jraft-linear-consistent-read-implementation/","summary":"SOFAStack Scalable Open Financial Architecture Stack 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文为《剖析 |","tags":["SOFAJRaft","SOFALab","剖析 | SOFAJRaft 实现原理"],"title":"SOFAJRaft 线性一致读实现剖析 | SOFAJRaft 实现原理","type":"blog","url":"/blog/sofa-jraft-linear-consistent-read-implementation/","wordcount":4732},{"author":"响风","categories":"SOFALookout","content":" SOFA:Channel/，有趣实用的分布式架构频道。 本文根据 SOFAChannel#6 直播分享整理，主题：轻量级监控分析系统 SOFALookout 原理讲解和功能演示。 回顾视频以及 PPT 查看地址见文末。 欢迎加入直播互动钉钉群：23195297，不错过每场直播。\n 大家好，我是响风，来自蚂蚁金服， 现在是 SOFALookout 的开源负责人。本期 SOFAChannel 我给大家带来主题是《轻量级监控分析系统 SOFALookout 原理讲解和功能演示》的分享。本期的讲解内容如下将从以下四个部分展开：\n 监控预警基本概念介绍 SOFALookout 的客户端使用（包括系统设计简介与实现） SOFALookout 的服务端使用（包括系统设计简介与实现） SOFALookout 发展规划  欢迎大家 Star 我，SOFALookout：https://github.com/sofastack/sofa-lookout\n1 监控预警基本概念介绍 1.1 什么是 SOFALookout 现在我们开始第一部分，先介绍一些基本概念。6 月初，SOFALookout 服务端开源，具体内容可以查看相关文章：蚂蚁金服轻量级监控分析系统 SOFALookout 服务端开源，SOFALookout 客户端在之前也已经开源。目前整个系统是真正地可以玩转起来的，这里先介绍一下 SOFALookout。\nSOFALookout 是蚂蚁金服开源的一款解决系统的度量和监控问题的轻量级中间件服务。开源版本只提供对 Metrics 的处理部分：涵盖 Metrics 数据的产生，也就是 Metrics 的埋点、收集、加工、存储与查询等一系列服务。\n1.2 Metrics 的前置知识 介绍一些 Metrics 的前置知识：\n第一是时序数据，比较正式的解释是“基于稳定频率持续产生的一系列指标监测数据”。简单说横轴是时间，纵轴是数值的情况下，第一印象可以做成走势图的数据通常就是时序数据。比如 2009 年到 2018 年每年双十一天猫的成交额，就构成了时序数据。\n第二是标签（Tag），它用于表明指标项监测针对的具体对象。还是以刚才的成交额为例子，其实我们要监测的指标是“成交额”，但是“成交额”并没有标明要监测的对象，即谁的成交额，哪个省的成交额，也就是缺少“定语”。标签的作用就相当于是“定语”。比如“天猫的 浙江省的 成交额”，在代码中通常会有键值对来描述，比如 type=\u0026amp;ldquo;天猫\u0026amp;rdquo;，province=\u0026amp;ldquo;浙江\u0026amp;rdquo;。\n第三是时序数据库，即专门为存查时序数据而设计的数据管理系统。主要有以下几个特点：\n 写多读少 数据多维度，无 schema，需要多维度查询或聚合 通常无删除和更新操作， 或受限  以下是一些常见的开源时序数据库，由于篇幅关系，就不一一介绍了。\n Graphite InfluxDB OpenTSDB Prometheus  1.3 传统 Metrics 和 Metrics 2.0 的对比 下面再来看一下传统 Metrics 和 Metrics 2.0 的对比。\n1.3.1 传统 Metrics 传统 Metrics 是我对它的称呼，简单来说它只有 Name 和 Value，没有显式的 Tags 概念。比如 \u0026amp;ldquo;temperature = 29\u0026amp;rdquo;，温度=29，当然这里都省略了时间戳。这个表达式并没有指出监测对象，传统 Metrics 的做法是，将监测对象的信息编码到 Name 里，因此可能就变成了 \u0026amp;ldquo;temperature.hangzhou=29\u0026amp;rdquo;。这里是有一些隐式的 Tags 信息的，只是被编码到 Name 里了。\n这种做法很快会导致一个问题，我们来看下一个例子： shanghai.host1.foo.exporter.bar 。 只看这个名字的话几乎很难知道这个 Metrics 统计的是什么。这是因为它并没有把字段对应的 Key 编码到名字里，所以在缺少一些上下文的情况下，我们很难读懂它的含义。\n另外，字段的顺序也是很重要的，不能写错，这是因为编码到 Name 里的只有 Tag 的 Value，Key 不在里面，于是又有了另外一种编码方式：zone.shanghai.host.host1.app.foo.counters.exporter.bar 。这种方式将 Tag 的 Key 也编码在Name 里。但带来的问题也很明显：Name 越来越长。\n我们再看下一个例子： login.success.h5，它想表达来自 H5 平台登录成功的次数。假设我们还有其他平台，比如安卓、IOS，我们想求所有平台的总登录成功次数，那么就需要做一个聚合操作。通常时序数据库会提供型号来匹配所有值。\n其实上面这些都是旧版本 Graphite 的例子, 不过它在 2017 年底的版本支持了 Tags 概念，所以已经不能拿新版来当反面教材了。\n这是 Dropwizard 客户端的一个简单 Demo，它是一个很流行的 Metrics 埋点客户端，但是只能支持传统 Metrics 的概念。\nMetricRegistry registry = new MetricRegistry(); Counter h5Counter = registry.counter(\u0026amp;#34;login.success.h5\u0026amp;#34;); h5Counter.inc(); 1.3.2 Metrics 2.0 我们再来看 Metrics 2.0，其实 Metrics 2.0 也就只是多了 Tags 的概念，这里同样省略了 Timestamp。\n这是 OpenTSDB 风格的数据描述。\n{ \u0026amp;#34;metric\u0026amp;#34;: \u0026amp;#34;login.counter\u0026amp;#34;, \u0026amp;#34;tags\u0026amp;#34;: { \u0026amp;#34;result\u0026amp;#34;: \u0026amp;#34;success\u0026amp;#34;, \u0026amp;#34;platform\u0026amp;#34;: \u0026amp;#34;h5\u0026amp;#34; }, \u0026amp;#34;timestamp\u0026amp;#34;: 1560597254000, \u0026amp;#34;value\u0026amp;#34;: 100 } 这是 Prometheus 的描述方式。\ntemperature{city=\u0026amp;#34;hangzhou\u0026amp;#34;}=29 这是对应的 lookout-client 的埋点代码。\nRegistry registry = …; Id loginCounter = registry.createId(\u0026amp;#34;login.counter\u0026amp;#34;); Id id = loginCounter.withTags( \u0026amp;#34;result\u0026amp;#34;, \u0026amp;#34;success\u0026amp;#34;, \u0026amp;#34;platform\u0026amp;#34;, \u0026amp;#34;ios\u0026amp;#34; ); registry.counter(reqId).increment(); 可以看到它们都显式支持了 Metrics 2.0 的概念。\n这里我们花了点时间强调传统 Metrics 与 Metrics 2.0版本的区别，主要是想强调合理使用 Name …","date":1561705200,"description":"本文根据 SOFAChannel#6 直播分享整理，主题：轻量级监控分析系统 SOFALookout 原理讲解和功能演示。","dir":"blog/sofa-channel-6-retrospect/","fuzzywordcount":4200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"27fcb53174efd0b72fcee578993cae38","permalink":"/blog/sofa-channel-6-retrospect/","publishdate":"2019-06-28T15:00:00+08:00","readingtime":9,"relpermalink":"/blog/sofa-channel-6-retrospect/","summary":"SOFA:Channel/，有趣实用的分布式架构频道。 本文根据 SOFAChannel#6 直播分享整理，主题：轻量级监控分析系统 SOFALookout 原理讲解和功能演示。 回顾视频以及 PPT 查","tags":["SOFALookout","SOFAChannel"],"title":"蚂蚁金服轻量级监控分析系统解析 | SOFAChannel#6 直播整理","type":"blog","url":"/blog/sofa-channel-6-retrospect/","wordcount":4165},{"author":"卓与","categories":"SOFAStack","content":"本文整理自 GIAC（GLOBAL INTERNET ARCHITECTURE CONFERENCE）全球互联网架构大会，蚂蚁金服平台数据技术事业群技术专家石建伟（花名：卓与）的分享。分享基于 Service Mesh 的理念，结合蚂蚁金服内部实际场景，将中间件、数据层、安全层等能力从应用中剥离出来后下沉至独立的 Sidecar SOFAMosn 中，结合 Kubernetes 运维体系，提供应用无感知的情况下升级基础设施层能力的案例。\n本次分享将从以如下次序展开进行：\n蚂蚁金服当前的服务化现状 在看蚂蚁金服的服务化架构之前我们先从一个简单的服务化调用示例说起，下图是 SOFARPC 基本原理：\n我们从上图可以看出，构建一个服务化框架需要有服务注册中心，有服务定义，调用方和服务提供方使用相同的服务定义来互相通讯。通过服务注册中心，调用方可以直接订阅到服务提供方的地址，采用点对点的方式直接发起请求。客户端内可实现服务发现、路由寻址、负载均衡、限流熔断等能力来增强服务通讯能力。通过我们开源的 SOFARPC、SOFARegistry、SOFABoot，用户已经可以直接构建起微服务体系，助力业务发展。\n蚂蚁金服发展至今，双 11 系统需要应对的交易洪峰逐年递增：\n每秒 26.5 万笔交易是 2017 年双 11 的峰值数据，这个数据背后有非常复杂的架构支持，LDC 单元化架构是蚂蚁金服沉淀多年的核心架构，依靠这个架构实现每年峰值交易量飞速增长下系统依然能平滑渡过。我们来简要看下 LDC 架构：\n上图摘自 金融级分布式架构 中的 素描单元化 一文，这里不详细展开。LDC 的单元化架构给应用的服务化带来更多的规范与抽象，服务路由中需要考虑单元间的调用，跨机房调用等更多场景。这里主要希望表达的是 LDC 架构给 RPC 调用带来更高的复杂度。\n服务化痛点 中间件版本升级 在上面介绍背景时，有介绍到目前 LDC 架构下服务调用的复杂度，这些复杂度目前是直接体现在应用的代码中。对于业务同学来讲，一个应用的关注重点是如何实现业务逻辑，至于高可用、容灾等能力更多是整体架构层面会考虑的点。应用内通过引入 RPC 的 jar 包即可获得 LDC 架构下服务调用各种能力的支撑，带来便利的同时也可以看到这种模式的缺点：\n应用内除业务逻辑之外，由中间件的 SDK 引入大量外部依赖，来完成服务发现、路由寻址、负载均衡、限流熔断、序列化、通讯等能力，每个组件的引入都可能带来稳定性风险，以及更高的升级成本。\n根据目前 SOFARPC 在内部的版本举例，服务发现依赖 SOFARegistry 的客户端做 IDC 内的服务发现，依赖 Antvip 做跨 IDC 的服务发现，ZoneClient 集成 LDC 架构的单元化信息，路由寻址需要根据请求的入参计算目前 Zone 然后确定调用目标，限流熔断依赖 Guardian 组件，通讯协议与序列化协议相对稳定，变更较少。仅为了完成服务调用，应用需要额外引入 7+ 客户端包。\n每年双 11 需要涉及到架构调整时：比如支持弹性架构，需要做很多中间件客户端的版本升级来支撑更优的架构，对于业务同学来讲，这些升级是很耗费精力的，拿 200 个核心应用举例，每个应用升级中间件版本经过研发、测试、再到部署预发、灰度、生产等环境需要 5个人日的话，200 个核心应用中间件升级需要耗费 1000 人日，如果这部分时间可以节省出来，每年架构升级可以节约大量人力资源。\n跨语言通讯 蚂蚁金服发展至今，内部业务百花齐放，搜索推荐、人工智能、安全等各种业务使用到的技术栈非常多样化，跨语言的服务通讯能力也十分重要。早在几年前，Java 之外规模最大的就是 NodeJS 应用，为了让 Java 和 NodeJS 应用之间可以复用蚂蚁金服内部的各种中间件和基础设施，前端团队使用 NodeJS 逐步重写了各种中间件客户端，让整个 NodeJS 和 Java 体系可以完美互通。\n中间件 SDK 跨语言重写与维护成本极高，随着语言种类的增多，跨语言通讯的诉求也越来越多。\nJava, NodeJS, Go, Python, C++ 等，5+ 语言，中间件 SDK 全部重写成本极高。这些问题不得不激励我们寻找更优的解法。\n解决痛点 SDK 能力下沉 依然以上述 RPC SDK 举例，SDK 中的能力我们可以根据稳定性与不可剥离等特性来看，哪些是可以从应用中抽出来的，尽量把 SDK 做薄，做的足够稳定无需变更，那么升级成本将不复存在。\nRPC SDK 中的服务发现、路由寻址、限流熔断等特性，是更易于变更的，我们将这部分能力下沉至独立的 Sidecar 中，可以复用这部分能力，让多语言的 SDK 只实现最基本的序列化与通讯协议，而这些能力是很轻量且易于实现的。这里的 Sidecar 我们是希望它作为独立进程存在，和业务应用的进程剥离，并和业务应用的升级解耦开来，实现业务和基础设施并行发展，互不干扰的愿景。\n除了 RPC 通讯，我们还可以下沉消息、数据源等能力至 Sidecar 中，业务应用可以越来越薄，SDK 实现成本也降低到可接受的程度，基础设施层与业务剥离，双方均可独立演进。\n落地架构 整体架构 不同于开源的 Istio 体系，蚂蚁金服内部版 Service Mesh 落地优先考虑数据面的实现与落地，控制面在逐步建设中，整体的架构上看，我们使用数据面直接和内部的各种中间件服务端对接，来完成 RPC、消息等能力的下沉，给业务应用减负。由上图可以看出，我们将不同的 Sidecar 与业务应用编排在同一个 Pod 中，App 与 Mosn 直接通讯，Mosn 来负责目标接口的服务发现、路由寻址，并且由 Mosn 内置的安全模块来做应用间调用的加密鉴权。通过 DBMesh 的 Sidecar 来实现数据层的下沉，App 不在需要与多个数据源建立连接，只需要连接本 Pod 内的 DBMesh 即可完成数据层调用，数据库的用户名、密码、分库分表规则等均不再需要关心。\n图中名词解析：\nConfigServer：配置中心，负责各种元数据配置、动态开关等。\nRegistry：服务注册中心，负责 IDC 内服务发现。\nAntVip：类 DNS 解析的产品，可通过域名解析一组目标地址，用于跨 IDC 服务发现。\nMQ：消息中心服务端，用于收发消息。\n落地数据 目前这套架构已经在支付核心链路中做试点，618 大促 Mesh 化应用对比无 Mesh 化应用 CPU 损耗增长 1.7%，单笔交易整体耗时增长 5ms。CPU 增长是由于多出一个进程，请求增加一条之后，RT 会有稳定的小幅增长，但这些成本相比于整体架构带来的红利，微乎其微，并且针对整个数据面的持续优化是有望逐步减少资源占用，提升资源利用率。\n降低打扰度 中间件能力下沉在架构上看是可行的，实际落地如何做到无打扰的在奔跑的火车上换轮子，低打扰是一个非常重要的考量点。借助于 Kubernetes 的优秀实践，将业务容器与 Sidecar 容器编排在同一个 Pod 中是比较合理的架构，Sidecar 与业务容器互不干扰，互相升级均可做到双方无感。\n我们为了让业务应用升级尽可能如丝般顺滑，主要做了如 …","date":1561359600,"description":"本文整理自 GIAC（GLOBAL INTERNET ARCHITECTURE CONFERENCE）全球互联网架构大会，蚂蚁金服平台数据技术事业群技术专家石建伟（花名：卓与）的分享。","dir":"blog/service-mesh-giac-2019/","fuzzywordcount":4600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"7cfc7c8a7b735c31418186aae0ca99a2","permalink":"/blog/service-mesh-giac-2019/","publishdate":"2019-06-24T15:00:00+08:00","readingtime":10,"relpermalink":"/blog/service-mesh-giac-2019/","summary":"本文整理自 GIAC（GLOBAL INTERNET ARCHITECTURE CONFERENCE）全球互联网架构大会，蚂蚁金服平台数据技术事业群技术专家石建伟（花名：卓与）的分享。","tags":["SOFAStack","Service mesh"],"title":"蚂蚁金服 Service Mesh 落地实践与挑战 | GIAC 实录","type":"blog","url":"/blog/service-mesh-giac-2019/","wordcount":4572},{"author":"雾渊","categories":"SOFAArk","content":" 本文来自 SOFAArk 用户—溢米教育投稿，分享其内部使用 SOFAArk 组件后极大提高内部推荐系统的开发效率和稳定性的案例。感谢溢米教育对 SOFAStack 的支持，同时也欢迎更多用户投稿 Join us。\nSOFAArk 是一款基于 Java 实现的轻量级类隔离容器，主要提供类隔离和应用(模块)合并部署能力，由蚂蚁金服开源贡献。\n写在前面 **个性化推荐，**相信大家都不陌生，简单来说就是根据每个人的偏好经过模型计算推荐出适合的东西，这些东西可以是视频、商品、文章、电影等。经过互联网这几年的发展，个性化推荐已经无处不在，不管是电商、教育、游戏、金融行业，推荐系统对业务的提升都有着非常重要的帮助。溢米教育作为一家互联网教育平台，近几年推荐业务发展非常迅速，技术团队也在持续的进行能力提升。业务快速增长的同时，亟需一个高效率、高稳定的推荐系统来支持推荐场景。\n本文是根据我们内部推荐平台效率与稳定性建设的实际经验整理，介绍了溢米教育推荐系统的改造优化。在整个过程中我们基于公司架构做了分析，确认了技术选型和改造方案，最终选择基于 SOFAStack 社区开源的 SOFAArk 组件开发框架，极大的提升了我们推荐系统的开发效率和稳定性。希望能给有同样困扰的技术团队参考。\n背景 一次完整的个性化推荐，通常包括召回、过滤、排序等步骤。虽然步骤不多，但是涉及到的逻辑是非常多的，包括 abtest、用户画像、物品画像、离线数据、在线数据、模型系统、字段补全等等。个性化推荐极为依赖场景定制化，不同的场景对应不同的处理逻辑。\n我们可以想象，把这一堆处理逻辑都放在一个系统里面，应用会变得十分臃肿和复杂，随着业务系统不断的迭代更新，逐渐会变得难以维护，开发效率和系统稳定性都会面临不小的挑战。不幸的是，随着溢米业务快速发展，内部的推荐平台已经变得 “过劳肥”。不管是迭代效率、性能、稳定性都遇到了瓶颈，比如：\n  **发布耗时：**算法团队一个人跟进一条业务线，导致业务迭代频繁、应用发布非常频繁，由于系统本身复杂性，这么一个庞然大物发布一次非常慢，降低了工程师效率；\n  **系统臃肿：**所有模块统一维护，包含了存储、算法、业务等，几乎每次迭代都是只增不减，降低了系统可维护性；\n  **覆盖风险：**多个团队共同维护一份代码，分支上容易存在冲突，合并代码存在覆盖风险，降低了团队合作效率；\n  **版本不一致：**不同业务团队使用的 jar 包版本不一致，每次升级一个 jar 包都会引起很多问题，导致各个团队在开发期间都要花费不少精力解决依赖冲突；\n  基于上述背景，溢米推荐平台不得不进行应用瘦身和系统改造，从而提升平台的开发效率和稳定性。然而在实际的改造过程中，我们不难发现这两者其实是互相冲突的。为了提高稳定性，我们肯定要做到流程上的把控，比如测试、灰度、发布等流程的规范，这势必会影响业务迭代效率；反过来如果要提升效率，那么在流程上肯定会有一定的舍弃，随之而来的是稳定性的潜在风险。 但是人总是需要梦想驱动的，每个工程师都希望能用一种架构或者方案，同时解决很多通用的问题，节约成本，提升效率， 让设计人员能够不至于疲于奔命， 解放生产力来完成更多有创新有挑战的工作。\n调研 效率和稳定性并非一定是二选一，在进行推荐平台升级改造之前，我们梳理了溢米内部影响业务效率和系统稳定性的主要因素。\n    开发效率 系统稳定     影响因素 业务复杂度+开发复杂度 业务变更：代码变更+数据变更    业务迭代流程+开发流程 非业务变更：配置变更+代码变更    业务变更+服务变更上线 流量变化    稳定性流程 硬件故障    关于开发效率，从上面可以看出来除了开发部分是依赖平台所能提供的便利和开发者个人技术能力之外，其余大部分都是流程上的把控。这些流程上的把控一是为了保障业务迭代的正确性，二是为了提升业务迭代带来的线上服务稳定性，但是简单的流程不足以把控住这些点，而过度复杂的流程会很大程度上影响业务迭代效率，所以我们需要思考并且寻求一种平衡，比如如何降低业务开发复杂度？如何提升平台提供的便利？如何在不影响稳定性的情况下简化业务迭代和维护流程？\n关于稳定性，我列举几个在溢米内部遇到的几个类似案例：\n 推荐服务性能优化上线，功能性测试没有问题，但是没有经过压测导致高峰期服务能力下降，最终导致整个服务不可用，而上游由于没有做好服务治理也受影响变成了服务不可用； 推荐服务所依赖的某个数据源或者 RPC 响应从 10ms 突然增长到 100ms，从而导致推荐服务主要线程池耗尽，最终导致服务不可用； 上游压测或者流量推广或者爬虫导致流量激增，但是推荐服务没有做好限流导致服务被打垮而不可用； 推荐系统依赖业务系统提供的RPC服务进行过滤，由于此RPC服务变更导致响应变慢，而推荐服务没有区分强弱依赖导致整体服务超时； 某个业务由于排期时间紧张，测试周期太短，上线后导致其它业务异常；  结合这些案例和上文总结的系统稳定性影响因素，可以发现除了硬件故障是不可控之外，其余几点基本都是因为变更而引起的。那么如何不受变更影响而提升稳定性呢？上面我们介绍过最主要也是最有效的是变更流程控制，通过测试、灰度、发布流程规范，其余也可以通过技术手段来控制，比如性能优化、服务治理、业务隔离、强弱依赖区分、多机房容灾、扩容等等。\n针对以上开发效率和稳定性分析，最开始确定如下了改造目标：\n 场景模块化  系统瘦身，拆分模块，提高系统可维护性 模块复用，提升开发效率   模块开发时隔离  各模块单独迭代开发，解决之前统一迭代开发的代码冲突问题 各模块单独测试，提升测试效率   模块运行时隔离  模块运行时类隔离，解决模块间包冲突问题 模块间有明确的服务边界，一定程度的故障隔离   模块动态可插拔  动态升级，秒级发布回滚    改造 为了满足改造目标，我们初步确认了三个选择：\n 采用自定义 SPI 的 ServiceLoader 动态加载实现； 采用自定义 Classloader 实现； 寻求开源软件支持。  基于资源成本、时间成本的考虑，我们选择了寻求开源支持，蚂蚁金服开源其分布式架构吸引了我们的关注，经过技术判断，我们最终决定使用 SOFAStack 社区开源的 SOFAArk 组件开发框架。\nSOFAArk 定义了一套相对简单的类加载模型、特殊的打包格式、统一的编程界面、事件机制、易扩展的插件机制等，从而提供了一套较为规范化的插件化、组件化的开发方案。更多内容可以参考官方文档：\nSOFA JVM 服务： https://www.sofastack.tech/sofa-boot/docs/sofa-ark-ark-jvm\nSOFAArk 官方文档： https://www.sofastack.tech/sofa-boot/docs/sofa-ark-readme\nSOFAArk 源码： https://github.com/sofastack/sofa-ark\n通过 SOFAArk+SOFABoot 的组合，我们将应用进行拆分，分为宿主应用+数据模块+业务模块：\n **主应用：**负责整个容器的状态保持； **数据模块：**负责数据通信， …","date":1560409200,"description":"本文来自 SOFAArk 用户—溢米教育投稿，分享其内部使用 SOFAArk 组件后极大提高内部推荐系统的开发效率和稳定性的案例。","dir":"blog/sofastack-user-yimi/","fuzzywordcount":3400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"967e9a815b24a3b000d5ecd90c59b8fb","permalink":"/blog/sofastack-user-yimi/","publishdate":"2019-06-13T15:00:00+08:00","readingtime":7,"relpermalink":"/blog/sofastack-user-yimi/","summary":"本文来自 SOFAArk 用户—溢米教育投稿，分享其内部使用 SOFAArk 组件后极大提高内部推荐系统的开发效率和稳定性的案例。感谢溢米教育对 SOFAStack 的支持，同时也欢迎更多用户","tags":["SOFAArk"],"title":"溢米教育推荐平台的效率与稳定性建设 | SOFAStack 用户说","type":"blog","url":"/blog/sofastack-user-yimi/","wordcount":3335},{"author":"潘潘","categories":"SOFAChannel","content":"概要  活动主题：SOFAChannel#6：轻量级监控分析系统 SOFALookout 原理讲解和功能演示 活动时间：6 月 12 日周四晚 7 点 活动形式：线上直播 直播视频回顾 直播回顾文章  介绍 | SOFAChannel \u0026amp;lt;SOFA:Channel/\u0026amp;gt; 有趣实用的分布式架构频道：前沿技术、直播 Coding、观点“抬杠”，多种形式。\n\u0026amp;lt;SOFA:Channel/\u0026amp;gt; 将作为 SOFA 所有在线内容的承载，包含直播/音视频教程，集中体现 SOFAStack 的能力全景图。\n| SOFAChannel#6：轻量级监控分析系统 SOFALookout 原理讲解和功能演示 6 月 27 日周四晚 7 点，将邀请 蚂蚁金服 SOFALookout 开源负责人 响风 为大家分享，通过对多个模块的剖析，详解 SOFALookout 服务端以及客户端，带你了解 SOFALookout 具体是如何支持主流 Metrics协议的数据收集、存储、查询计算和可视化的。欢迎报名参加~\nSOFALookout 是蚂蚁金服开源的一款解决系统的度量和监控问题的轻量级中间件服务，提供的服务包括：Metrics 的埋点、收集、加工、存储与查询等。该开源项目包括了两个独立部分，分别是客户端与服务器端服务。\n本期分享大纲：\n 监控预警基本概念介绍 SOFALookout 客户端使用 Gateway - 多协议数据收集与处理的设计与实现 Server - PromQL 与多种存储层的设计与实现 SOFALookout 发展路线  | 加入 SOFA 钉钉互动群 欢迎加入直播互动钉钉群：23195297（搜索群号加入即可）\n| 点击即可报名 https://tech.antfin.com/community/live/687\n议程 19:00-19:05 主持人开场 SOFAGirl 主持人\n19:05-20:00 轻量级监控分析系统 SOFALookout 原理讲解和功能演示 响风 蚂蚁金服轻量级监控分析系统 SOFALookout 开源负责人\n本期分享大纲：  监控预警基本概念介绍 SOFALookout 客户端使用 Gateway - 多协议数据收集与处理的设计与实现 Server - PromQL 与多种存储层的设计与实现 SOFALookout 发展路线  嘉宾  SOFAGirl 主持人 响风 蚂蚁金服轻量级监控分析系统 SOFALookout 开源负责人  ","date":1560312000,"description":"6 月 12 日周四晚 7 点，线上直播第 6 期。","dir":"activities/sofa-channel-6/","fuzzywordcount":700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"29a5673d4608770bbe7598954fcecc78","permalink":"/activities/sofa-channel-6/","publishdate":"2019-06-12T12:00:00+08:00","readingtime":2,"relpermalink":"/activities/sofa-channel-6/","summary":"概要 活动主题：SOFAChannel#6：轻量级监控分析系统 SOFALookout 原理讲解和功能演示 活动时间：6 月 12 日周四晚 7 点 活动形式：线上直播 直播视频回顾 直","tags":["SOFAChannel","SOFALookout"],"title":"SOFAChannel#6：轻量级监控分析系统 SOFALookout 原理讲解和功能演示","type":"activities","url":"/activities/sofa-channel-6/","wordcount":637},{"author":"卿祤、 首仁","categories":"SOFAStack","content":" 由蚂蚁金服主办的 SOFAStack Cloud Native Workshop 将在 6月24日于 KubeCon + CloudNativeCon + Open Source Summit China 大会的同场活动中进行，欢迎报名参与，更多信息可见此链接。 欢迎加入 SOFA 钉钉互动群（钉钉搜索群号）：23195297\n 楔子 为支撑业务高速发展并积极拥抱主流技术，我们从 2017 年开始探索并构建以Kubernetes为核心的云原生应用 PaaS 平台。在 2018 年，我们已在网商银行顺利落地了 K8S 容器引擎，并顺利支撑了 2018 年双十一。2019 年伊始，国泰产险作为互金行业的典型代表，正基于 SOFAStack 容器应用服务和监控分析产品探索云原生架构转型。时至今日，已完成了关键业务 SOFABoot 应用的容器化改造，在开发、测试乃至灰度生产环境践行云原生的运维实践。\n这将是一系列技术分享文章的开端，基于在实际金融机构和场景中落地的云原生产品项目经验，我们希望和大家一起分享从中获得的洞察和总结，探讨我们的产品观点、技术实现，并非常期待大家的建议和指点，欢迎一起交流共创。\n云原生容器产品的金融机构落地挑战 从去年开始，云原生、Kubernetes、容器这些关键字逐渐从社区走向金融科技圈，越来越多的金融机构客户开始向我们咨询，云原生技术是什么，能够给企业带来什么价值，对现有业务有什么影响？落地的路径可能会是哪些？\n我们的观点是，金融场景下的云原生，绝对不止是 12Factors，亦不止是 CNCF TOC 所定义的 5 大件，我们不仅要提供标准、通过一致性认证的 Kubernetes 产品，还需要满足更多金融场景需求，创造实际业务价值。\n经过很长一段时间的产品研发实践、深挖内外容器平台落地诉求，金融客户的关注点可能包括但不限于以下几点：\n 业务采用了云原生能否节省资源，提升工程效率？ 发现问题后如何做到快速止损，甚至线上零故障？ 如何在云原生下做到业务同城双活甚至异地多活的高可用容灾能力？ 能否和现有业务能无缝集成，如何做平滑升级？ 采用了云原生平台能否保证和现有云上一致的安全性？ 云原生能否支撑大规模分布式系统的架构？ \u0026amp;hellip;  而基于以上实际场景下的落地挑战，我们对自身容器平台产品的设计和实施，提出了以下六大关键价值主张：\n云原生容器产品的价值主张 一 使用 Immutable Infrastructure 的思想进行设计 在 PaaS 平台中，核心是应用。在之前的经典运维体系中，要对应用打一个全量快照不是件容易的事情，但在云原生世界中，会方便许多。从描述流量接入层的 Service 到描述应用配置和代码包的 Pod template，这些已是 kubernetes 的标准 Resources。\n为了解决应用管理需求，我们定义了一个 CafeAppService 对象，用于整体描述上述内容，并通过 Revision 对象属性作版本控制（和 Knative 中的 Revision 类似）。用户每次的修改都是一个 Revision，发布一个应用本质上是发布该应用的一个 Revision，故可做到快速的弹性扩缩容，并且可以方便回滚到之前发布成功过的 Revision。相比之前基于包的经典发布运维体系，效率有极大提升。\n二 可审计和无损应用发布的能力 发布变更是 PaaS 平台提供的重要能力。对于金融客户来说，每次发布必须要有据可查，而且要保证安全无损。这里，我们将蚂蚁的安全生产理念融入其中，在产品层面上提供“可灰度，可回滚（应急），可监控”的能力。\n为了做到上述能力，我们提供了发布单的概念，并定义了一个原生的 CRD：CafeDeployment。接下来逐一介绍。\n发布单 主要两个用途：做应用发布的审查记录，用于统计分析，故障复盘回顾等；协调多个应用的发布顺序，这是由于金融业务对系统的可靠性要求高，尤其在涉及资金的主链路，另外，不少系统由于业务原因，存在依赖关系，必须做有序发布。\nCafeDeployment 在这里只做简单介绍，后续会有专题介绍。该 CRD 拥有三种能力：\n 原地升级（InplaceSet）:升级过程中 Pod 的 IP 保持不变，可和经典的运维监控体系做无缝集成。 替换升级（ReplicaSet）:和社区版本的 ReplicaSet 能力保持一致。 有状态应用（StatefulSet）:和社区版本的 StatefulSet 能力保持一致。  除此之外，相比社区的 deployment，还具备 beta 验证，自定义分组策略，分组暂停，引流验证（配合 ServiceMesh）的能力。\n三 具有高可用容灾能力的工作负载 金融业由于监管的要求对系统可用性和容灾能力具有很高的要求。从应用的生命周期来看，最主要有两个状态：发布态 和 运行态。\n对于发布态，由于存在 Pod 上下线的过程，线上有抖动不可避免，要做的是尽可能的降低抖动幅度以及降低系统报错率。kubernetes 的 deployment 在发布一个 pod 时，pod 里容器的 kill 和对应 endpoint 的销毁是异步的，这就意味着可能出现 pod 里应用容器已经 kill 了，但仍然会有流量打到该 Pod，导致出现报错，甚至故障。为了防止这种情况，我们采用 finalizer 的机制，保证在南北流量和东西流量（7 层协议）都切断的情况下才对 Pod 进行更新。\n同时，还通过 CafeDeployment 里的灰度发布策略，保证发布态时线上系统的水位不会过低，防止出现流量过载，造成系统异常。\n对于运行态，要考虑以下几个方面：Pod 异常退出后的重新上线，Node 故障后的 Pod 的迁移，机房级故障后系统仍然可用。对于第一点，Kubernetes 本身已经有了较好的机制；第二点，我们做了增强，使用自定义的 NodeLifecycle Controller 结合更加详细的监控信息来判断Node是否出现故障，然后做 Pod 迁移；第三点，从 Scheduler 方面进行保障，CafeDeployment 可以定义相应的高可用拓扑结构，以同城双活为例，在创建 Pod 时，调度器会根据定义好的拓扑信息尽量将 Pod 均分到不同的可用区，达到同城双活的状态。\n四 一致的验证授权体验 蚂蚁金服 PaaS 平台在近 4 年的时间里，已经有了一套完整的 IAM 体系，并且许多客户已经基于此定义了许多的角色，用做安全防护。我们从两方面来提供一致性的体验：\n首先，在产品上的操作上提供和原先一样的验证授权机制。只要客户将 K8S 内预先定义好的角色或者权限分配相应的用户或用户组，那该用户或者属于该用户组的用户就能在产品上做相应的操作。\n其次，IAM 的权限和角色与 Kubernetes 的 RBAC 做映射。根据用户在 IAM 所具备的角色，在 Kubernetes 集群中创建相应的 ClusterRole，并生成访问 Kubernetes 集群的 token，创建 ClusterRoleBinding 与 token 绑定。这样用户使用 kubectl 操作集群时也可以具备相同的权限，保证权限的 …","date":1559890800,"description":"这将是一系列技术分享文章的开端，基于在实际金融机构和场景中落地的云原生产品项目经验，我们希望和大家一起分享从中获得的洞察和总结，探讨我们的产品观点、技术实现，并非常期待大家的建议和指点，欢迎一起交流共创。","dir":"blog/sofa-financial-cloud-native-exploration/","fuzzywordcount":3900,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"9c93781d7d4b980b1990e4655445d4bf","permalink":"/blog/sofa-financial-cloud-native-exploration/","publishdate":"2019-06-07T15:00:00+08:00","readingtime":8,"relpermalink":"/blog/sofa-financial-cloud-native-exploration/","summary":"由蚂蚁金服主办的 SOFAStack Cloud Native Workshop 将在 6月24日于 KubeCon + CloudNativeCon + Open Source Summit China 大会的同场活动中进行，欢迎报名参与，更多信息可见此链接。 欢迎加入 SOFA 钉钉互动群（钉钉搜","tags":["SOFAStack"],"title":"金融级云原生探索实践系列 - 开篇","type":"blog","url":"/blog/sofa-financial-cloud-native-exploration/","wordcount":3890},{"author":"墨睿","categories":"SOFALookout","content":" SOFAStack Scalable Open Financial Architecture Stack 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 SOFALookout 是在 SOFAStack 体系内研发开源的一款解决系统的度量和监控问题的轻量级中间件服务。本文给大家介绍下 SOFALookout 服务器端主要提供的特性以及使用方式。 SOFALookout：https://github.com/sofastack/sofa-lookout\n 前言 容器，K8S，微服务，Mesh 以及 Serverless 这些新技术方向正在根本的变革我们运行软件的方式。我们构建的系统更加分布式化，另外由于容器，系统的生命周期更加短，变得易逝。针对这些变化，SOFALookout 希望提供一套轻量级解决方案。之前 SOFALookout 已经开源客户端的能力。今天，SOFALookout 服务器端 Metrics 部分的代码终于正式开源啦！本文给大家介绍下 SOFALookout 服务器端的主要特性以及使用方法。\n什么是 SOFALookout SOFALookout 是蚂蚁金服开源的一款解决系统的度量和监控问题的轻量级中间件服务。它提供的服务包括：Metrics 的埋点、收集、加工、存储与查询等。该开源项目包括了两个独立部分，分别是客户端与服务器端服务。\nSOFALookout 目标是打造一套轻量级 Observability 实时工具平台，帮助用户解决基础设施、应用和服务等的监控和分析的问题。SOFALookout（目前已开源部分） 是一个利用多维度的 metrics 对目标系统进行度量和监控的项目。SOFALookout 的多维度 metrics 参考 Metrics2.0 标准。\nSOFALookout ：https://github.com/sofastack/sofa-lookout\nSOFALookout 安装文档：https://www.sofastack.tech/sofa-lookout/docs/quickstart-metrics-server\n SOFALookout 服务器端的主要特性:\n 适配社区主要 Metrics 数据源协议写入（比如: Prometheus，Metricbeat 等）； 数据的存储支持扩展，暂时开源版默认支持 Elasticsearch， 并且透明和自动化了相关运维操作； 遵循 Prometheus 查询 API 的标准以及支持 PromQL，并进行了适当改进； 自带数据查询的控制台，并支持 Grafana 进行数据可视化； 使用简单，支持单一进程运行整个服务器端模块。  随着 SOFALookout （metrics）服务器端代码开源，metrics 数据的处理已经形成闭环。后续我们将会进一步开源 Trace 和 Event 相关的服务能力，敬请期待。\nSOFALookout 项目结构 服务器端代码分别包括两部分：Gateway 模块和 Server 模块。如下图所示（展示了 SOFALookout 源码项目的模块概要结构）\n├── boot ├── client ├── gateway └── server 项目中的 boot 模块作用是方便集成和运行服务端的模块，既可以单独运行 Gateway 和 Server 的服务，也可以借助 SOFAArk 完成（Gateway 和 Server）的 All in One 的合并为单一进程运行。\nSOFALookout 工作机制 下图完整展示了 SOFALookout 如何从 metrics 数据采集、上报、存储到最终展示的完整流程路径。\n目前 SOFALookout 支持灵活的 metrics 数据存储选型。但开源版本我们暂时只支持了 Elasticsearch 作为存储的方案（后续可能继续支持 Cassandra,InfluxDB\u0026amp;hellip;），其他存储地适配我们希望更多同学能参与共建和支持。优先支持 Elasticsearch 是因为我们考虑到了 ELK 解决方案在业界已经广泛使用，尤其是日志数据。\n为了开箱即用，同时考虑到不熟悉 Elasticsearch 的同学的使用，SOFALookout已经内置了关于 metrics 数据存储的自动化运维工具，可以免除大家自己建 Index，和日常维护 ES Index 的麻烦，更多细节后续单独讲解。\n本次新增开源模块 一、SOFALookout Gateway 模块 SOFALookout Gateway 轻量的数据管道，它提供丰富的协议接入支持，包括自有SDK（SOFALookout Client）上报协议，还支持 Prometheus 的数据协议（推模式和拉模式），Metricbeat 协议（版本是6），OpenTSDB 写入协议。每种数据来源对应于一个 Importer 的概念。\nSOFALookout Gateway 对于远程（推模式）上报提供本地硬盘缓冲的支持。Gateway 总体设计是围绕数据加工的Pipeline 形式，包括前置后置的数据过滤器方便进行开发者数据加工。 另外 Gateway 可以支持自定义 Exporter，默认提供了 Elasticsearch Exporter，Standard Exporter(用于 Gateway 间数据中继)，开发者也可以自定义其他存储的 或 Kafka 等各式各样 Exporter。\n二、SOFALookout Server 模块 SOFALookout Server 兼容和增强了 Prometheus 的数据及元数据查询的 RESTful API。同样对应 PromQL 我们也基本实现了兼容和增强（不包括 Alert 相关语法），SOFALookout 的 promQL 相关解析逻辑是从 Prometheus 移植而来，做了一些优化和改进， 感谢 Prometheus 开源了如此易用和强大的 golang 版本的 QL 实现。\n为了方便方便开发者做数据探索和试验，我们也提供了自有 Web-UI 的支持，能够满足基本功能使用。\n我们还是推荐大家使用 Grafana 进行数据展示。Grafana 集成 SOFALookout 很简单，只需要选择 Prometheus 作为数据源协议即可（SOFALookout默认查询端口也是: 9090）。下图展示 Grafana 新增数据源配置：\n近期计划 下图是近期的 Roadmap：\n非常欢迎更多同学参与 SOFALookout 共建，尤其是支持更多的 Metrics 存储库。\n","date":1559804400,"description":"本文给大家介绍下 SOFALookout 服务器端主要提供的特性以及使用方式。","dir":"blog/sofa-lookout-server-open-source/","fuzzywordcount":2000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"d80fe27f8652b6e8a8da8d712a90a027","permalink":"/blog/sofa-lookout-server-open-source/","publishdate":"2019-06-06T15:00:00+08:00","readingtime":4,"relpermalink":"/blog/sofa-lookout-server-open-source/","summary":"SOFAStack Scalable Open Financial Architecture Stack 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 SOFALookout 是在 SOFAStack 体系内","tags":["SOFALookout"],"title":"轻量级监控分析系统 SOFALookout 服务端开源","type":"blog","url":"/blog/sofa-lookout-server-open-source/","wordcount":1970},{"author":"Jimmy Song","categories":null,"content":"SOFAStack Cloud Native Workshop hosted by Ant Financial (KubeCon China 2019 Co-Located Event)  Date: Monday, 24 June, 2019 Time: 9:00 – 16:00 Location: Shanghai Expo Centre Room 616 Registration Fees: Complimentary Register here: https://www.lfasiallc.com/events/kubecon-cloudnativecon-china-2019/co-located-events/#sofastack-cloud-native-workshop Note: This event is hands-on, please bring your personal computer. The language of communication in this workshop is Chinese.  SOFAStack (Scalable Open Financial Architecture Stack) is a financial-grade distributed architecture independently developed and open sourced by Ant Financial. It contains the components required to build a financial-grade cloud native architecture. It is a best practice tempered in financial scenarios. SOFAStack official website: https://www.sofastack.tech/\nAttendees can get:\n Rapidly build microservices based on SOFAStack Best Practices for Distributed Transactions in Financial Scenarios Cloud native deployment experience based on Kubernetes Service Mesh basic usage scenario experience on the cloud Get started on Serverless apps Easily build applications on the cloud based on Serverless  How to Register: Pre-registration is required. To register for SOFAStack Cloud Native Workshop, add it on during your KubeCon + CloudNativeCon + Open Source Summit registration. You can get KubeCon half price tickets with KCCN19COMATF coupon code!\nFor questions regarding this event, please reach out to jingchao.sjc@antfin.com.\nEvent details 9:00 - 9:20 Opening speech SOFAStack Cloud Native\n9:20 - 10:10 Quickly build microservices with SOFAStack by Jie Cao\nBuilding a microservices application based on the SOFAStack. Through this workshop, you can learn how to report application monitoring data, service link data, and publish and subscribe services in the SOFAStack.\n10:15 - 11:05 SOFABoot dynamic module practice by Guolei Song\nIn this workshop, you can implement the combined deployment and dynamic module push capabilities provided by SOFAArk based on the ARK control capabilities of SOFADashboard.\n11:10 - 12:00 Using Seata to guarantee the consistency of payment by Long Chen\nUnder the microservice architecture, the distributed transaction problem is an industry problem. Through this workshop, you can understand the background of distributed transaction problems under distributed architecture, as well as common distributed transaction solutions and experience on how to use the open source distributed transaction framework - Seata\u0026amp;rsquo;s AT mode, TCC mode to solve the ultimate consistency of the business data.\n12:00 - 13:00 Lunch time\n13:00 - 13:30 Cloud Native exlporation and practice in Ant Fnancial by Renjie Yu\n13:30 - 14:40 Migrating to cloud based on Serverless by Yitao Dong\nAs one of the pioneering technologies of cloud technology, Serverless architecture allows you to further improve resource utilization and focus on business development. Through our workshop, you can experience new product …","date":1559643600,"description":"","dir":"activities/sofastack-cloud-native-workshop/","fuzzywordcount":600,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"57c6b0262af34c2010179000834d8363","permalink":"/en/activities/sofastack-cloud-native-workshop/","publishdate":"2019-06-04T10:20:00Z","readingtime":3,"relpermalink":"/en/activities/sofastack-cloud-native-workshop/","summary":"SOFAStack Cloud Native Workshop hosted by Ant Financial (KubeCon China 2019 Co-Located Event)  Date: Monday, 24 June, 2019 Time: 9:00 – 16:00 Location: Shanghai Expo Centre Room 616 Registration Fees: Complimentary Register here: https://www.lfasiallc.com/events/kubecon-cloudnativecon-china-2019/co-located-events/#sofastack-cloud-native-workshop Note: This event is hands-on, please bring your personal computer. The language of communication in this workshop is Chinese.  SOFAStack (Scalable Open Financial Architecture Stack) is a financial-grade distributed architecture independently developed and open sourced by Ant Financial.","tags":["KubeCon","Workshop","Cloud Native"],"title":"KubeCon China 2019 Co-Located Event SOFAStack Cloud Native Workshop","type":"activities","url":"/en/activities/sofastack-cloud-native-workshop/","wordcount":515},{"author":"宋净超","categories":null,"content":"蚂蚁金服 SOFAStack 云原生工作坊（KubeCon China 2019 同场活动）  日期：2019年6月24日，星期一 时间：9:00 – 16:00 地点：上海世博中心 616 房间 注册费：免费 注册地址：https://www.lfasiallc.com/events/kubecon-cloudnativecon-china-2019/co-located-events/#sofastack-cloud-native-workshop 备注：本次活动为动手实践，请携带个人电脑。本沙龙沟通语言为中文。  SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发并开源的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。SOFAStack 官方网站：https://www.sofastack.tech/\n参加此次 Meetup 您将获得：\n 基于 SOFAStack 快速构建微服务 金融场景下的分布式事务最佳实践 基于 Kubernetes 的云原生部署体验 云上的 Service Mesh 基本使用场景体验 基于 Serverless 轻松构建云上应用  如何注册：此活动须提前注册。请将 SOFAStack Cloud Native Workshop 添加到您 KubeCon + CloudNativeCon + Open Source Summit 的注册表里。您可以使用 KCCN19COMATF 折扣码获取 KubeCon 半价门票！\n如果对此活动有任何疑问，请发送邮件至 jingchao.sjc@antfin.com。\n活动详情 9:00 - 9:20 开场演讲 SOFAStack 云原生开源体系介绍 by 余淮\n9:20 - 10:10 使用 SOFAStack 快速构建微服务 by 玄北\n基于 SOFA 技术栈构建微服务应用。通过本 workshop ，您可以了解在 SOFA 体系中如何上报应用监控数据、服务链路数据以及发布及订阅服务。\n10:15 - 11:05 SOFABoot 动态模块实践 by 卫恒\n在本 workshop 中，您可以基于 SOFADashboard 的 ARK 管控能力来实现 SOFAArk 提供的合并部署和动态模块推送的功能。\n11:10 - 12:00 使用 Seata 保障支付一致性 by 屹远\n微服务架构下，分布式事务问题是一个业界难题。通过本workshop，您可以了解到分布式架构下，分布式事务问题产生的背景，以及常见的分布式事务解决方案；并亲身体验到如何使用开源分布式事务框架Seata的AT模式、TCC模式解决业务数据的最终一致性问题。\n12:00 - 13:00 午餐时间\n13:00 - 13:30 蚂蚁金服的云原生探索与实践 by 首仁\n13:30 - 14:40 通过 Serverless 快速上云 by 隐秀\n作为云原生技术前进方向之一，Serverless 架构让您进一步提高资源利用率，更专注于业务研发。通过我们的 workshop，您可以体验到快速创建 Serveless 应用、根据业务请求秒级 0-1-N 自动伸缩、通过日志查看器快速排错、按时间触发应用等产品新功能。\n14:50 - 16:00 使用 CloudMesh 轻松实践 Service Mesh by 敖小剑\nService Mesh 将服务间通信能力下沉到基础设施，让应用解耦并轻量化。但 Service Mesh 本身的复杂度依然存在，CloudMesh 通过将 Service Mesh 托管在云上，使得您可以轻松的实践 Service Mesh 技术。通过我们的 workshop，您可以快速部署应用到 CloudMesh ，对服务进行访问，通过监控查看流量，体验服务治理、Sidecar管理和对服务的新版本进行灰度发布等实用功能。\n","date":1559643600,"description":"","dir":"activities/sofastack-cloud-native-workshop/","fuzzywordcount":1200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"57c6b0262af34c2010179000834d8363","permalink":"/activities/sofastack-cloud-native-workshop/","publishdate":"2019-06-04T10:20:00Z","readingtime":3,"relpermalink":"/activities/sofastack-cloud-native-workshop/","summary":"蚂蚁金服 SOFAStack 云原生工作坊（KubeCon China 2019 同场活动） 日期：2019年6月24日，星期一 时间：9:00 – 16:00 地点：上海世博中心 616 房间 注册费：免费","tags":["KubeCon","Workshop","Cloud Native"],"title":"KubeCon 上海同场活动 SOFAStack Cloud Native Workshop","type":"activities","url":"/activities/sofastack-cloud-native-workshop/","wordcount":1134},{"author":"卫恒","categories":"SOFAMeetup","content":"作者：卫恒（宋国磊），SOFATracer 以及 SOFADashboard 开源负责人。\n本文根据 5月26日 SOFA Meetup#2上海站 《使用 SOFAStack 快速构建微服务》主题分享整理，着重分享如何使用 SOFADashboard 来管控 SOFAArk ，对于 SOFAArk 中的一些基础概念和知识不过多涉及；建议大家在阅读之前，先了解下 SOFAArk 的相关基本知识。\n现场回顾视频以及 PPT 见文末链接。\n前言 SOFAArk 是一款基于 Java 实现的轻量级类隔离容器，主要提供类隔离和应用（模块）合并部署能力，由蚂蚁金服开源贡献。SOFAArk 在 0.6.0 版本 提供了非常丰富的功能特性，其中最核心的当属多应用（模块）合并部署这个能力。SOFAArk 本身提供了多种方式来支持多应用（模块）合并部署 ，包括基于命令行的管控，基于 API 的管控等。本篇将结合 SOFA 开源的管控端组件 SOFADashboard，来实现 SOFAArk 提供的合并部署和动态模块推送的功能。\n案例工程地址\n背景 复杂项目通常需要跨团队协作开发，各自负责不同的组件，而众所周知，协调跨团队合作开发会遇到不少问题；比如各自技术栈不统一导致的依赖冲突，又比如往同一个 Git 仓库提交代码常常导致 merge 冲突。因此，如果能让每个团队将负责的功能组件当成一个个单独的应用开发，运行时合并部署，通过统一的编程界面交互，那么将极大的提升开发效率及应用可扩展性。SOFAArk 提出了一种特殊的包结构 \u0026amp;ndash; Ark Biz，用户可以使用 Maven 插件将应用打包成 Biz，允许多 Biz 在 SOFAArk 容器之上合并部署，并通过统一的编程界面交互。\n案例模型 本篇所演示案例是上图的一个简化版，从整体上可以体现 SOFAArk多应用合并部署的能力。主要包括已经几个工程：\n sofa-dashboard-ark-hostapp : 宿主应用 sofa-dashboard-ark-facade : 提供接口 API sofa-dashboard-ark-provider ：提供接口 API 的具体实现，将发布一个 JVM 服务  sofa-dashboard-ark-hostapp 和 sofa-dashboard-ark-provider 均作为 SOFAArk 中的 ark-biz 存在；sofa-dashboard-ark-hostapp 作为宿主应用对外提供服务。\n上图的模型中，在宿主应用不重启的情况下，实现 provider 模块的动态替换，从而实现版本升级。\n 在宿主应用启动时，provider 1.0.0 以静态合并部署方式“寄宿”到宿主应用中，这部分实际上与 SOFADashboard 管控是没有什么关系的，为了案例效果，在下面的案例中，关于静态合并部署的操作也会涉及到。\n 最终的工程结构图如下：\n环境准备 本文需要启动 SOFADashboard 服务端，具体请参考 : Quick Start ；其他基础设施环境如 Zookeeper 、Mysql 等需提前准备。\n工程构建 本篇将通过 step by step 的方式来构建整个工程，为大家在实际的应用过程中提供一种简单的思路，同时也帮助大家更好的理解 SOFAArk 中的一些点。\nsofa-dashboard-ark-facade 基础 API 提供模块，不需要依赖任何其他二方或者三方 JAR，这里仅提供一个接口。\npublic interface SofaJvmService { String test(); } sofa-dashboard-ark-provider 这个模块是 JVM 服务的提供方，也是后面需要在宿主应用中进行替换演示的模块包，这个模块本身也是一个 Web 应用。这里就来一步步分解下，如何将一个普通的 SpringBoot 工程改造成一个 ark-biz 工程。\n1、新建一个 SpringBoot 工程 新建 SpringBoot 工程推荐的方式有两种，一种是在 https://start.spring.io/ 进行下载，另外一种是基于 IDEA 的 Spring 插件来生成；此处不在过多描述过程。\n2、工程基本能力实现  引入 sofa-dashboard-ark-facade 依赖，先将需要提供的 JVM 服务实现：  @SofaService @Service public class SofaJvmServiceImpl implements SofaJvmService { @Override public String test() { return \u0026amp;#34;first version biz\u0026amp;#34;; } }  NOTE: SofaService 的作用是将一个 Bean 发布成一个 JVM 服务， 所以这里需要加上 Spring 提供的 @Service 注解将 SofaJvmServiceImpl 标注为一个 Bean。\n  配置文件：  spring.application.name=biz-ark-test server.port=8800 logging.path=./logs 3、配置打包插件，将应用打包成 ark-biz  根据官方文档，可以使用 sofa-ark-maven-plugin 插件将一个普通的工程打包成一个 ark biz 包。这里直接给出本篇中工程的配置：\n\u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;0.6.0\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;executions\u0026amp;gt; \u0026amp;lt;execution\u0026amp;gt; \u0026amp;lt;!--goal executed to generate executable-ark-jar --\u0026amp;gt; \u0026amp;lt;goals\u0026amp;gt; \u0026amp;lt;goal\u0026amp;gt;repackage\u0026amp;lt;/goal\u0026amp;gt; \u0026amp;lt;/goals\u0026amp;gt; \u0026amp;lt;!--ark-biz 包的打包配置 --\u0026amp;gt; \u0026amp;lt;configuration\u0026amp;gt; \u0026amp;lt;!--是否打包、安装和发布 ark biz，详细参考 Ark Biz 文档，默认为false--\u0026amp;gt; \u0026amp;lt;attach\u0026amp;gt;true\u0026amp;lt;/attach\u0026amp;gt; \u0026amp;lt;!--ark 包和 ark biz 的打包存放目录，默认为工程 build 目录--\u0026amp;gt; \u0026amp;lt;outputDirectory\u0026amp;gt;target\u0026amp;lt;/outputDirectory\u0026amp;gt; \u0026amp;lt;!--default none--\u0026amp;gt; \u0026amp;lt;arkClassifier\u0026amp;gt;executable-ark\u0026amp;lt;/arkClassifier\u0026amp;gt; \u0026amp;lt;!-- ark-biz 包的启动优先级，值越小，优先级越高--\u0026amp;gt; …","date":1559286000,"description":"本文根据 5月26日 SOFA Meetup#2上海站 《使用 SOFAStack 快速构建微服务》主题分享整理，着重分享如何使用 SOFADashboard 来管控 SOFAArk ，对于 SOFAArk 中的一些基础概念和知识不过多涉及。","dir":"blog/sofa-meetup-2-2-retrospect/","fuzzywordcount":3700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"61a156b1a9f1a80f555200bfea5a20b6","permalink":"/blog/sofa-meetup-2-2-retrospect/","publishdate":"2019-05-31T15:00:00+08:00","readingtime":8,"relpermalink":"/blog/sofa-meetup-2-2-retrospect/","summary":"作者：卫恒（宋国磊），SOFATracer 以及 SOFADashboard 开源负责人。 本文根据 5月26日 SOFA Meetup#2上海站 《使用 SOFAStack 快速构建微服务》主题分享整理，","tags":["SOFAMeetup","SOFAArk","SOFADashboard"],"title":"基于 SOFAArk 和 SOFADashboard 实现动态模块管控 | Meetup#2 回顾","type":"blog","url":"/blog/sofa-meetup-2-2-retrospect/","wordcount":3608},{"author":"玄北","categories":"SOFAStack","content":"本文作者：玄北（曹杰），蚂蚁金服 SOFAStack 开源组核心成员。\n本文根据 5月26日 SOFA Meetup#2 上海站 《当 Spring Cloud 遇上 SOFAStack》主题分享整理，主要来聊聊 spring-cloud-antfin 包含的主要特性及如何使用 SOFAStack 和 SpringCloud 快读构建微服务系统。\n现场回顾视频以及 PPT 见文末链接。\n概念 Spring Cloud 是 Spring 社区开源的一套微服务开发框架，帮助开发人员快速构建分布式应用，Spring Cloud 的官网介绍如下：\n Spring Cloud provides tools for developers to quickly build some of the common patterns in distributed systems (e.g. configuration management, service discovery, circuit breakers, intelligent routing, micro-proxy, control bus, one-time tokens, global locks, leadership election, distributed sessions, cluster state).\n 蚂蚁金服从 2007 年开始在公司内部使用 SOFAStack 框架，2014 年基于 Spring Boot 研发了 SOFABoot，2016 年将 SOFAStack 在公有云输出，2018 年 4 月，蚂蚁金服宣布开源 SOFAStack。SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服开源的，用于快速构建金融级分布式架构的一套中间件，也是在金融场景里锤炼出来的最佳实践。SOFAStack ：https://github.com/sofastack\nSOFAStack 包含以下主要特性：\n 全面：覆盖多种场景，让用户更加专注于业务开发； 可靠：经历过大规模场景的锤炼，特别是严苛的金融场景； 丰富：包含构建金融级云原生架构所需的各个组件，满足用户场景的现状和未来需求； 开放：兼容开源生态，组件可插拔， SOFAStack 组件与其它开源组件可相互集成或替换。  SOFAStack 开源全景图涵盖了微服务领域的各个方面，同时也积极和业界流行的开源组件结合，包括阿里巴巴集团开源的 Nacos、Sentinel 等，为用户提供更加广泛地选择。\nSOFAStack 开源已经超过一年，Spring Cloud 作为当下流行的微服务框架，社区用户以及公司内部用户迫切希望能够将这两个优秀的框架进行整合，将 SOFAStack 中间件适配 Spring Cloud 规范也就产生了我们今天的主角——spring-cloud-antfin。\nspring-cloud-antfin 全景图 Spring 官网提供了一份 Spring Cloud 的架构图：\n从 Spring Cloud 的架构图可以看到，Spring Cloud 框架涵盖了分布式应用开发的方方面面，包括：\n API 网关  熔断与限流 服务发现 分布式配置 分布式链路  spring-cloud-antfin 是 Spring Cloud 微服务规范的 antfin 实现，同样的，我们也有一份 spring-cloud-antfin 全景图，涵盖了蚂蚁金服所有中间件：\n与 Spring Cloud 全景图不同，在 spring-cloud-antfin 中每种分布式组件都有具体的蚂蚁中间件实现：\n API 网关：SOFAGateway 熔断与限流：Guardian 服务发现：SOFARegistry 分布式配置：DRM 分布式链路：SOFATracer  在 spring-cloud-antfin 适配 Spring Cloud 的过程中，我们发现 Spring Cloud 制定的规范并不完整，对于一些 Spring Cloud 规范并未涵盖的方面，spring-cloud-antfin 进行了扩展。\n扩展 Spring Cloud 虽然 Spring Cloud 定义了很多微服务规范，但是在具体业务开发过程中，我们发现 Spring Cloud 还有很多不足，例如 Spring Cloud 对以下能力没有进行规范化：\n 属性级别动态配置 事务消息 Big Table 分布式事务  属性级别动态配置 Spring Cloud 的动态配置基于 RefreshScope 接口，默认 RefreshScope 会对整个 Bean 进行刷新，而且实现自动刷新需要配合 spring-cloud-bus，我们认为与 Apollo、Nacos 等属性级别刷新相比，这个是明显的退步，所以 spring-cloud-antfin 定义一个 DynamicConfig 注解，对于打有这个注解的 Bean，spring-cloud-antfin 支持属性级别动态配置：\n@Target({ ElementType.TYPE }) @Retention(RetentionPolicy.RUNTIME) public @interface DynamicConfig { } 事务消息 spring-cloud-stream 默认不支持事务消息，但是在金融级场景中事务消息是必不可少的，所以 spring-cloud-antfin 扩展了 spring-cloud-stream 的定义，对事务消息进行了支持：\n MQ 支持事务：对于使用 MQ 本身就支持事务消息的，spring-cloud-antfin 会在 MessageHeaders 中增加 Transcation 相关属性，以此支持事务消息； MQ 不支持事务：对于使用 MQ 本身不支持事务的，spring-cloud-antfin 支持用本地事件表的模式支持事务消息。   消息发送端在同一个本地事务中记录业务数据和消息事件； 事件恢复服务定时从事件表中恢复未发布成功的事件，重新发布成功后删除记录的事件。  通过事件恢复服务的不停执行，我们保证了本地事件和消息发送到 Message Broker 必定同时成功或者同时失败。\nBig Table 一些 SOFAStack 的使用者，一套代码会在多种技术栈使用，当使用开源技术栈时，Big Table 的实现会使用 HBase，在使用商业技术栈时，Big Table 会使用阿里云的 TableStore，为了让用户实现不修改代码在不同技术栈使用，spring-cloud-antfin 会定义一套统一接口，然后让用户针对 spring-cloud-antfin 的接口进行编程，这样在替换底层实现时用户代码不需要修改：\npublic interface BigTableService { Result get(Get get) throws StoreException; Result[] get(List\u0026amp;lt;Get\u0026amp;gt; get) …","date":1559113200,"description":"本文根据 5月26日 SOFA Meetup#2 上海站 《当 Spring Cloud 遇上 SOFAStack》主题分享整理。","dir":"blog/sofa-meetup-2-1-retrospect/","fuzzywordcount":3000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"ffc229811fe6c3065b010a9730e6d895","permalink":"/blog/sofa-meetup-2-1-retrospect/","publishdate":"2019-05-29T15:00:00+08:00","readingtime":6,"relpermalink":"/blog/sofa-meetup-2-1-retrospect/","summary":"本文作者：玄北（曹杰），蚂蚁金服 SOFAStack 开源组核心成员。 本文根据 5月26日 SOFA Meetup#2 上海站 《当 Spring Cloud 遇上 SOFAStack》主题分享整理，主要来聊聊 spring-cloud-antfin 包含","tags":["SOFAStack","SOFAMeetup"],"title":"当 Spring Cloud 遇上 SOFAStack | Meetup#2 回顾","type":"blog","url":"/blog/sofa-meetup-2-1-retrospect/","wordcount":2934},{"author":"敖小剑","categories":"Service Mesh","content":"前言 本文内容整理自5月25日在 Kubernetes \u0026amp;amp; Cloud Native Meetup 上海站发表的主题演讲，主要介绍了 ServiceMesh 最新的产品动态，分析其发展趋势和未来走向；结合蚂蚁金服的上云实践，阐述在云原生背景下 Service Mesh 的核心价值，以及对云原生落地的关键作用。\n内容主要有三个部分：\n Service Mesh 产品动态：介绍最近半年 Service Mesh 的产品动态，包括开源项目和云厂商推出的云上服务 Service Mesh 发展趋势：根据最近的产品动态，总结 Service Mesh 的发展趋势，推断未来的走向 Service Mesh 与云原生：结合云原生，更好的理解 Service Mesh 的价值和作用  Service Mesh 产品动态 Istio1.1 发布 Istio 是目前 Service Mesh 社区最引人注目的开源项目，在今年的3月份发布了期待已久的 Istio 1.1 版本，我们来看看 Istio 最近几个版本的发布情况：\n 2018年6月1日，Istio 发布了 0.8 版本，这是 Istio 历史上第一个 LTS 版本，也是 Istio 历史上变动最大的一个版本； 2018年7月31日，Istio 发布了 1.0 版本，号称 \u0026amp;ldquo;Product Ready\u0026amp;rdquo;； 然后就是漫长的等待，Istio 1.0 系列以每个月一个小版本的方式一路发布了 1.0.1 到 1.0.6，然后才开始 1.1.0 snapshot 1 到 6，再 1.1.0-rc 1 到 6，终于在 2019年3月20日 发布了 1.1 版本，号称 \u0026amp;ldquo;Enterprise Ready\u0026amp;rdquo;。  从 Istio 1.0 到 Istio 1.1，中间的时间跨度高达9个月！我们来看看经过这漫长的开发时间才发布的 Istio 1.1 版本带来了哪些新的东西：\n图中标红的部分，涉及到 Istio 的架构调整，下面将详细介绍 Istio 1.1 版本中带来的架构变化。\nIstio 1.1 架构变化 下图是 Istio 1.0 和 Istio 1.1 的架构图对比：\nIstio 1.1 的第一个架构变化来自 Galley：在 Istio 1.1 的架构图中增加了 Galley 组件。但是实际上在 Istio 1.0 版本中 Gallay 组件就已经存在，只是当时 Galley 的功能非常简单，只是做配置更新之后的验证（Validation），在 Istio 1.0 的架构图中都没有出现。而在 Istio 1.1 版本之后，Galley 的定位发生了巨大的变化：Galley开始分担 Pilot/Mixer 的职责。\n在 Istio 1.1 版本之前的设计中，Istio 的三大组件 Pilot/Mixer/Citadel 都需要访问 Kubernetes 的 API Server，以获取服务注册信息和配置信息，包括 Kubernetes 原生资源如 service/deployment/pod 等，还有 Istio 的自定义资源（数量多达50多个的 CRD） 。这个设计导致 Istio 的各个组件都不得不和 Kubernetes 的 API Server产生强绑定，不仅仅代码大量冗余，而且在测试中也因为需要和 Kubernetes 的 API Server 交互导致 Pilot/Mixer 模块测试困难。\n为了解决这个问题，在 Istio 1.1 之后，访问 Kubernetes 的 API Server 的工作将逐渐交给 Galley 组件，而其他组件如 Pilot/Mixer 就会和 Kubernetes 解耦。\n这个工作还在进行中，目前 Istio 的 CRD 已经修改为由 Galley 读取，而 K8s 的原生资源（Service / Deployment / Pod等），暂时还是由 Pilot 读取。\n为了方便在各个组件中同步数据，Istio 引入了MCP（Mesh Configuration Protocol）协议。在 Istio 1.1 版本中，Pilot 通过 MCP 协议从 Galley 同步数据。MCP 是受 xDS v2 协议（准确说是 aDS）的启发而制定的新协议，用于在Istio 各模块之间同步数据。\nIstio 1.1 的第二个架构变化来自于 Mixer，在 Istio 1.1 版本中，推荐使用 Out-of-Process Adapter，即进程外适配器。Istio 预计下一个版本将弃用 In-Proxy Adapter，目前所有的 Adapter 都将改为 Out-of-Process adapter。\n什么是 In-Proxy Adapter？下图是 Mixer 的架构图，在 Istio 的设计中，Mixer 是一个独立进程，Proxy 通过远程调用来和 Mixer 交互。而 Mixer 的实现了 Adapter 模式，定义了 Adapter API，然后内建了数量非常多的各种Adapter。这些 Adatper 的代码存放在 Mixer 代码中，运行时也在 Mixer 的进程内，因此称为 In-Process Adapter。\nIn-Process Adapter 的问题在于所有的 Adapter 的实现都和 Mixer 直接绑定，包括代码和运行时。因此当 Adapter 需要更新时就需要更新整个 Mixer，任意一个 Adapter 的实现出现问题也会影响整个 Mixer，而且数量众多的 Adapter 也带来了数量众多的CRD。为此，Istio 1.1 版本中通过引入 Out-of-Process Adapter 来解决这个问题。\nOut-of-Process Adapter 以独立进程的方式运行在 Mixer 进程之外，因此 Out-of-Process Adapter 的开发/部署和配置都可以独立于 Mixer，从而将 Mixer 从 Adaper 的实现细节中解脱出来。\n但是，Out-of-Process Adapter 的引入，会导致新的性能问题：原来 Mixer 和 In-Process Adapter 之间是方法调用，现在改成 Out-of-Process Adapter 之后就变成远程调用了。而 Mixer 一直以来都是 Istio 架构设计中最大的争议，之前 Proxy 和 Mixer 之间的远程调用，已经造成非常大的性能瓶颈，而引入 Out-of-Process Adapter 之后远程调用会从一次会变成多次（每个配置生效的 Out-of-Process Adapter 就意味着一次远程调用），这会让性能雪上加霜。\n总结 Out-of-Process Adapter 的引入：架构更加的优雅，性能更加的糟糕。\n在 Istio 1.1 为了架构而不顾性能的同时，Istio 内部也有其他的声音传出，如正在规划中的 Mixer v2。这个规划最重要的决策就是放弃 Mixer 独立进程的想法，改为将 Mixer 的功能合并到 Envoy 中，从而避免 Envoy  …","date":1559026800,"description":"本文内容整理自5月25日在 Kubernetes \u0026 Cloud Native Meetup 上海站发表的主题演讲。","dir":"blog/service-mesh-development-trend-1/","fuzzywordcount":8400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"8756e6985e0df28a5150ebd3af0e48c5","permalink":"/blog/service-mesh-development-trend-1/","publishdate":"2019-05-28T15:00:00+08:00","readingtime":17,"relpermalink":"/blog/service-mesh-development-trend-1/","summary":"前言 本文内容整理自5月25日在 Kubernetes \u0026amp; Cloud Native Meetup 上海站发表的主题演讲，主要介绍了 ServiceMesh 最新的产品动态，分析其发展趋势和未来走向；结合蚂蚁金服的上云实践，","tags":["Service Mesh"],"title":"Service Mesh 发展趋势：云原生中流砥柱","type":"blog","url":"/blog/service-mesh-development-trend-1/","wordcount":8379},{"author":"米麒麟","categories":"SOFAJRaft","content":" SOFAStack Scalable Open Financial Architecture Stack 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。\n 本文为《剖析 | SOFAJRaft 实现原理》第二篇，本篇作者米麒麟，来自陆金所。《剖析 | SOFAJRaft 实现原理》系列由 SOFA 团队和源码爱好者们出品，项目代号：SOFA:JRaftLab/，目前领取已经完成，感谢大家的参与。\nSOFAJRaft 是一个基于 Raft 一致性算法的生产级高性能 Java 实现，支持 MULTI-RAFT-GROUP，适用于高负载低延迟的场景。\nSOFAJRaft ：https://github.com/sofastack/sofa-jraft\n前言 SOFAJRaft-RheaKV 是基于 SOFAJRaft 和 RocksDB 实现的嵌入式、分布式、高可用、强一致的 KV 存储类库，SOFAJRaft 是基于 Raft 一致性算法的生产级高性能 Java 实现，支持 Multi-Raft-Group。SOFAJRaft-RheaKV 集群主要包括三个核心组件：PD，Store 和 Region。本文将围绕 SOFAJRaft-RheaKV 架构设计，存储概览，核心模块，使用场景以及基于 Raft 实现等方面剖析 SOFAJRaft-RheaKV 基于 SOFAJRaft 实现原理，阐述如何使用 Raft 协议支持 KV 存储类库功能特性：\n SOFAJRaft-RheaKV 基础架构如何设计？核心组件负责哪些功能？模块内部处理流程是怎样？ 基于 SOFAJRaft 如何使用 Raft 实现 SOFAJRaft-RheaKV 强一致性和自驱动等特性？   SOFAJRaft-RheaKV 概览 SOFAJRaft-RheaKV 是一个轻量级的分布式的嵌入式的 KV 存储 Library， RheaKV 包含在 SOFAJRaft 项目里，是 SOFAJRaft 的子模块。SOFAJRaft-RheaKV 定位是嵌入式 jar 包方式嵌入到应用中，涵盖以下功能特性：\n 强一致性，基于 Multi-Raft 分布式一致性协议保证数据可靠性和一致性； 自驱动，自诊断，自优化，自决策，自恢复； 可监控基于节点自动上报到 PD 的元信息和状态信息； 基本 API get/put/delete 和跨分区 scan/batch put，distributed lock 等。  架构设计 SOFAJRaft-RheaKV 存储类库主要包括 PD，Store 和 Region 三个核心组件，支持轻量级的状态/元信息存储以及集群同步，分布式锁服务使用场景：\n PD 是全局的中心总控节点，负责整个集群的调度管理，维护 RegionRouteTable 路由表。一个 PDServer 管理多个集群，集群之间基于 clusterId 隔离；PD Server 需要单独部署，很多场景其实并不需要自管理，RheaKV 也支持不启用 PD，不需要自管理的集群可不启用 PD，设置 PlacementDriverOptions 的 fake选项为 true 即可。 Store 是集群中的一个物理存储节点，一个 Store 包含一个或多个 Region。 Region 是最小的 KV 数据单元，可理解为一个数据分区或者分片，每个 Region 都有一个左闭右开的区间 [startKey, endKey)，能够根据请求流量/负载/数据量大小等指标自动分裂以及自动副本搬迁。Region 有多个副本 Replication 构建 Raft Groups 存储在不同的 Store 节点，通过 Raft 协议日志复制功能数据同步到同 Group 的全部节点。  存储设计 SOFAJRaft-RheaKV 存储层为可插拔设计，实现 RawKVStore 存储接口，目前 StoreEngine 存储引擎支持 MemoryDB 和 RocksDB 两种实现：\n MemoryRawKVStore：MemoryDB 基于 ConcurrentSkipListMap 实现，有更好的性能，但是单机存储容量受内存限制； RocksRawKVStore：RocksDB 在存储容量上只受磁盘限制，适合更大数据量的场景。  SOFAJRaft-RheaKV 存储引擎基于 MemoryDB 和 RocksDB 实现 KV 存储入口：\ncom.alipay.sofa.jraft.rhea.storage.RawKVStore com.alipay.sofa.jraft.rhea.storage.MemoryRawKVStore com.alipay.sofa.jraft.rhea.storage.RocksRawKVStore SOFAJRaft-RheaKV 数据强一致性依靠 SOFAJRaft 同步数据到其他副本 Replication, 每个数据变更都会落地为一条 Raft 日志, 通过 Raft 协议日志复制功能将数据安全可靠地同步到同 Raft Group 的全部节点里。\n核心设计 SOFAJRaft-RheaKV 核心模块包括 KV 模块[RheaKVStore 基于 RegionRouteTable 路由表使用 RaftRawKVStore 存储 KeyValue]，PD 模块[PlacementDriverServer 基于 StoreHeartbeat/RegionHeartbeat 心跳平衡节点分区 Leader 以及分裂]。\nKV 模块内部处理  RheaKVStore：最上层 User API，默认实现为 DefaultRheaKVStore， RheaKVStore 为纯异步实现，所以通常阻塞调用导致的客户端出现瓶颈，理论上不会在 RheaKV 上遭遇，DefaultRheaKVStore 实现包括请求路由、Request 分裂、Response 聚合以及失败重试等功能。 PlacementDriverClient：非必须，作为与 PlacementDriver Server 集群沟通的客户端，通过它获取集群完整信息包括但不仅限于\u0026amp;quot;请求路由表\u0026amp;quot;，对于无 PD 场景， RheaKV 提供 Fake PD Client。 RegionRouteTable：分片逻辑基于 RegionRouteTable 路由表结构，最适合的数据结构便是跳表或者二叉树(最接近匹配项查询)。作为本地路由表缓存组件，RegionRouteTable 根据 KV 请求的具体失败原因来决策是否从 PD Server 集群刷新数据，并且提供对单个 Key、多个 Key 列表以及 Key Range 进行计算返回对应的分区 ID。选择 Region 的 StartKey 作为 RegionRouteTable 的 Key ，主要取决于 Region Split 的方式，父 Region 分裂成两个子 Region 导致其中一个子 Region 的 StartKey …","date":1558681200,"description":"本文为《剖析 | SOFAJRaft 实现原理》第二篇，本篇作者米麒麟，来自陆金所。","dir":"blog/sofa-jraft-rheakv/","fuzzywordcount":5900,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"4d79102c8300ca628483bdba44c13049","permalink":"/blog/sofa-jraft-rheakv/","publishdate":"2019-05-24T15:00:00+08:00","readingtime":12,"relpermalink":"/blog/sofa-jraft-rheakv/","summary":"SOFAStack Scalable Open Financial Architecture Stack 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文为《剖析 |","tags":["SOFAJRaft","SOFALab","剖析 | SOFAJRaft 实现原理"],"title":"SOFAJRaft 实现原理 - SOFAJRaft-RheaKV 是如何使用 Raft 的","type":"blog","url":"/blog/sofa-jraft-rheakv/","wordcount":5815},{"author":"Linux 中国老王","categories":"SOFAStack","content":"— 本文转载自 Linux 中国老王\n蚂蚁金服的 SOFAStack 作为一个成功地将企业私有项目转化为开源核心模式的知名案例，我们之前对背后的思考和推动力做过专题分析，但是具体这件事是如何在蚂蚁金服内部发生的、是如何实操的，有很多读者向我们表示非常感兴趣，而我觉得这也是其它技术公司所正在探索和思考的方向。\n因此，上个月底，老王在参加上海举办的 KubeCon 2019 时，遇到了蚂蚁金服 SOFA 团队的余淮，他目前在蚂蚁金服中间件团队服务与框架组具体负责开发框架与 SOFAStack 的开源工作。于是，参会之余，我和余淮就 SOFA 开源的实操方面进行了深入的沟通，现将谈话所得整理给大家。\nSOFA 与开源 继去年开始开源 SOFAStack 以来，今年上半年他们又开源了分布式事务框架 Seata 和服务注册中心 SOFARegistry，之前我曾经向蚂蚁金服中间件负责人杨冰了解过为什么要将 SOFA 开源的背后思考，以及 SOFA 发展迭代的历程，详情可以看之前的文章《蚂蚁金服技术总监杨冰：金融科技公司为什么要拥抱开源？ 》进行了解。\n目前，SOFA 的架构已经发展到 SOFA 5 阶段，在今年 2 月，前任 SOFA 开源负责人鲁直还向我分享了 SOFA 5 中重点推进的方向，主要包括 Service Mesh 和 Serverless，以及分布式事务 Seata 的落地，具体内容见文章《蚂蚁金服开源负责人鲁直：不只是中间件，未来会开源更多》。\n作为一个成功的开源核心模式的项目，我非常关注 SOFA 开源的实操是如何进行的，是如何进行开源治理的，作为 SOFA 团队的老朋友，我们话题就直接从 SOFA 的开源治理聊起。\n以 SOFA 为例：公司内部软件的开源流程 余淮说，从 2015 年开始，蚂蚁金服开启了金融科技对外输出的战略，SOFAStack 也走出了蚂蚁金服，甚至跨越了国界，被更多金融机构与合作伙伴所使用，如天弘基金、信美互信、南京银行、PayTM、DANA 钱包等。\n在与合作伙伴以及客户的沟通、合作过程中，他们发现了 SOFAStack 的理念和能力也正是很多金融行业的企业所需要的。在蚂蚁金融科技对外输出的过程中，内部已经对 SOFAStack 进行了一定程度的代码重构，例如历史兼容逻辑的剥离等，但是并未能达到直接开源的标准。\n关于开源，内部一直有开源的讨论，到 2017 年双十一结束后正式决定开源。经过了一系列的准备，2018 年 4 月，完成了对 SOFA 项目的满足了开源改造的标准后，SOFAStack 马上宣布正式开源框架中部分重要组件。\n**SOFA 团队采用的开源策略叫「Open Core」，顾名思义就是要将接口层以及核心实现都开源，以可扩展化的方式来层层构建 SOFAStack 的能力，保证 SOFAStack 的内部版本和开源的版本采用的是同一个内核。**为此 SOFAStack 做了大量的改造和重构工作。\n在开源的具体考量上，余淮表示，SOFAStack 的开源改造基本上有三条原则，分别是高可扩展性、对内兼容历史版本、对外兼容业界标准。\n以 SOFARPC 重构为例，大概经历了这样的过程：\n 首先需要将 SOFARPC 进行了一次核心接口和模型抽象，然后增加了扩展点机制和事件总线机制，所有的对内对外实现都基于这些核心接口和模型去扩展，并且保证这些扩展能力都是平等的、可选的； 接着将核心的处理逻辑实现迁移到这套接口和模型上来，保证 SOFARPC 能力完整可用； 然后需要将 SOFARPC 里一些对接内部系统的、兼容历史逻辑的代码做成内部扩展，并进行全量测试验证，确保和已有线上的历史方案的兼容，发布上线； 最后会调研业界的一些开源标准方案和实现，并对其进行兼容，例如 SOFARPC 不仅对接自己的 SOFARegistry 的实现，还兼容了 Zookeeper、Etcd、Nacos 等业界优秀的注册中心方案。  虽然上面重构过程听上去没那么复杂，但是在实际过程中还是非常考验团队的技术能力的，特别是在抽象核心接口和模型的时候，为了做到既兼容内部又兼容外部，这需要进行大量的调研工作，才能做好这层较为通用抽象。其次在对内逻辑兼容的时候，由于内部的历史负担还是比较重的，为了能让重构的代码安全上线，团队也做了很多事情。\n还是举 SOFARPC 的例子，蚂蚁金服内部的服务路由过程比开源是要复杂很多的，特别是配合蚂蚁金服特有的单元化部署以及异地多活的能力，有时候需要多层路由才能找到目标地址。为了验证重构后逻辑的正确性，除了在开源代码里有单元测试用例外，SOFA 团队在内部也构建了一套非常完善的集成框架，专门用来测试已有逻辑的兼容性及正确性。\n基于 Open Core 这套思想建设 SOFAStack 以后，其实对开发同学的工作量来不会变少，反而可能是增多的。这是因为在写代码的同时，需要更多的考虑内部外部的使用情况，对代码质量也提出了更高的要求，开发流程会变得更加复杂。\n例如，内部新增一个特性，在以前可能直接修改代码经过测试就发布上线了，但现在的话会去思考这其中哪些能力是通用的，把这些能力抽象一下放到开源版本里去，然后开源版测试后发布，这个时候内部版本在基于这个开源版进行扩展，再经过测试后发布上线。\n虽然开发同学工作变多了，但是这样的话可以让 SOFAStack 的核心代码被更多的开发者 Review，在更多的系统中运行，在更多的场景下进行验证，对 SOFAStack 的品质保证有非常大的帮助。\n此外在开源进度上，余淮表示， SOFAStack 并不追求开源全部内部的组件，而是会根据产品的特性和开源准备的情况有选择的开源。\n例如 SOFAStack 下的分库分表组件，因为产品特性和 OB 等内部结合紧密就暂时不会开源。金融级分布式架构下未开源部分能力，SOFAStack 会和与业界其它优秀的开源项目做集成，保证整个金融级分布式架构功能的完整性和多样性。\n所以对于 SOFAStack 来说，并不只有自己开源的产品，而更多关注的是，和整个社区里所有开源优秀的产品一起，打造一套快速构建金融级分布式架构的套件。\n开源项目管理 开源一个项目，作为背后推动的公司事实上要付出相当多的人力和资金成本，同时，也不可避免的会涉及到审批流程。随着蚂蚁金服越来越多领域的项目开源，包括 SOFAStack，AI，区块链等，蚂蚁金服内部出台了相应的严格的审核机制，包括技术、合规、法务、安全等部门进行审核，同时还会考察项目开源对公司的意义，以及是否对社区有价值，在审核通过之后项目就会正式开源与大家见面了。\n蚂蚁金服对于开源文化是十分友好的，其内部的代码也大多都是公开在内网的 GitLab 仓库，经常会有业务团队对 SOFAStack 提交一些合并请求（拉取请求）来帮助项目的发展。\n同时，蚂蚁金服的工程师也普遍地拥抱开源，开源能够帮助项目产生更多、更好的想法，同时也可以吸收来自社区的贡献，让项目本身能够做的更好，这是大家所喜闻乐见的。 SOFA 的社区治理 开源项目并不是开放源代码就是终点，事实上，这只是开始，之后持续不断的开源治理才是开源之路。而如何将一个开源项目从最开始的由开源项目背后的公司主导转 …","date":1558681200,"description":"SOFAStack 开源如何在蚂蚁金服内部发生、是如何实操的、如何运营，Lunix中国老王进行了采访和分析，欢迎阅读","dir":"blog/sofastack-linux-china/","fuzzywordcount":4000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"c1896b9b50b60432bb345d583a9be24a","permalink":"/blog/sofastack-linux-china/","publishdate":"2019-05-24T15:00:00+08:00","readingtime":8,"relpermalink":"/blog/sofastack-linux-china/","summary":"— 本文转载自 Linux 中国老王 蚂蚁金服的 SOFAStack 作为一个成功地将企业私有项目转化为开源核心模式的知名案例，我们之前对背后的思考和推动力做过专题分析，但是具","tags":["SOFAStack"],"title":"大公司开源怎么做？SOFAStack给出了一个很好的例子","type":"blog","url":"/blog/sofastack-linux-china/","wordcount":3970},{"author":"花肉","categories":"SOFAMeetup","content":"概要  活动主题：SOFA Meetup#2 上海站-使用 SOFAStack 快速构建微服务 活动时间：5 月 26 日周日下午 13 点 活动地点：上海市徐汇区田林路200号A7栋一楼 活动形式：线下活动 报名方式：https://tech.antfin.com/community/activities/576  活动介绍 蚂蚁金服 SOFAStack SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，历经蚂蚁金服超过十年的业务历练。SOFAStack 于 2018 年 4 月宣布开源，并逐步开源 SOFABoot、SOFARPC、SOFALookout、SOFATracer、SOFAMosn、SOFAMesh 等组件。\n欢迎 Star 我：https://github.com/sofastack\nSOFA Meetup#2 上海站-使用 SOFAStack 快速构建微服务 适合自身企业的技术架构才是最佳的方案，SOFAStack 提供了一套的金融级解决方案，提供多种场景下需要的多种组件。\n5 月 26 日，SOFAMeetup#2 上海站，SOFAStack 开源核心成员集体出动。本期我们将侧重于各个落地的实际场景进行架构解析。\n分布式事务 Seata 详解、与 Spring Cloud 生态的融合案例、使用 SOFAStack 快速构建微服务 Demo 实操、更有最新开源的《让 AI 像 SQL 一样简单 — SQLFlow Demo 》首秀，期待与你不见不散~\n建议：参会者可带上电脑，现场有 Demo 实操环节~\n加入 SOFA 钉钉互动群 欢迎加入直播互动钉钉群：23195297（搜索群号加入即可）\n点击即可报名 https://tech.antfin.com/community/activities/576\n议程    时间 环节 讲师     13:00 - 13:30 签到    13:30 - 14:15 《研发框架 SOFABoot 的特性及落地场景介绍》 蚂蚁金服 SOFABoot 负责人 善逝   14 :15 - 15:00 《谈注册中心 SOFARegistry 架构设计 》 蚂蚁金服 SOFARegistry 负责人 琪祥   15:00 - 15:05 茶歇休息    15:05 - 15:15 《SOFALab 社区共建分享》 SOFALab 杰出贡献者 米麒麟   15:15 - 16:00 《当 SpringCloud 遇上 SOFAStack》 蚂蚁金服 SOFAStack 开源组核心负责人 玄北   16:00 - 16:45 《分布式事务 Seata 实现原理及实践详解》 Seata Committer 绍辉   16:45 - 17:30 《使用 SOFAStack 快速构建微服务》SOFADashboard 演示 + SOFARegistry + SOFARPC + SOFAArk 蚂蚁金服 SOFADashboard 负责人 卫恒   17:30 - 17:45 《让 AI 像 SQL 一样简单 — SQLFlow Demo 演示》 蚂蚁金服深度学习引擎开源产品负责人 三平    ","date":1558437600,"description":"SOFA Meetup#2 上海站-使用 SOFAStack 快速构建微服务，5 月 26 日周日下午 13 点，上海市徐汇区田林路200号A7栋一楼。","dir":"activities/sofa-meetup-2/","fuzzywordcount":900,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"5765309cb693fc8cc45958ecab5a9c3b","permalink":"/activities/sofa-meetup-2/","publishdate":"2019-05-21T11:20:00Z","readingtime":2,"relpermalink":"/activities/sofa-meetup-2/","summary":"概要 活动主题：SOFA Meetup#2 上海站-使用 SOFAStack 快速构建微服务 活动时间：5 月 26 日周日下午 13 点 活动地点：上海市徐汇区田林路200号A7栋一楼 活动形式：线","tags":["SOFAMeetup","SOFAStack"],"title":"SOFA Meetup#2 上海站——使用 SOFAStack 快速构建微服务","type":"activities","url":"/activities/sofa-meetup-2/","wordcount":849},{"author":"SOFA 团队","categories":"SOFAStack","content":"SOFAStack 启用独立 Group ，社区更加开放 今日，SOFAStack 将启用独立 Group： https://github.com/sofastack\n感谢大家的一路支持，未来，我们继续相伴~\n背景：分布式架构 SOFAStack 开源历史 金融级分布式架构 SOFAStack 产生于蚂蚁金服内部需求，起初是为了解决高速发展下的业务问题。到 2019 年，已经历12年的业务锤炼，变成了一套成熟的金融级最佳实践。\nSOFAStack 的发展受益于开源社区的优秀产品，我们也决定结合我们的实践积累，把这些技术反馈给开源社区。\n2018 年 4 月，SOFAStack 宣布开源。这一年，SOFAStack 逐步开源 SOFABoot、SOFARPC、SOFALookout、SOFATracer、SOFABolt、SOFAMosn、SOFAMesh、SOFAJRaft、SOFAActs、SOFARegistry、SOFADashboard 等组件。2019 年 3 月，蚂蚁金服加入分布式事务Seata的社区共建中，并贡献其 TCC 模式。\nSOFAStack 未来也将持续开源，丰富生态。\nSOFA 开源全景图，涵盖了微服务领域的各个方面，同时也积极和业界流行的开源组件结合，包括阿里巴巴集团开源的 Nacos、Sentinel 等，为用户提供更加广泛地选择。\nSOFAStack 启用独立 Group 和邮件订阅列表 为了开源管理更加清晰，更社区化的运作，更中立的技术态度，开放给更多的开发者和企业参与，SOFAStack 将启用独立 Group：\n SOFAStack 项目地址： https://github.com/sofastack  原项目地址： https://github.com/alipay 继续可访问，会跳转到新的地址上。\n 邮件订阅列表  加入 SOFAStack 邮件组 https://groups.google.com/forum/#!forum/sofastack 获取邮件订阅。\n感谢大家的一路支持，未来，我们继续相伴~\n","date":1557990000,"description":"SOFAStack 将启用独立 Group，社区更加开放今日。感谢大家的一路支持，未来，我们继续相伴","dir":"blog/sofastack-independent-droup/","fuzzywordcount":700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"f25b8521e498ebce982a98b882f941b3","permalink":"/blog/sofastack-independent-droup/","publishdate":"2019-05-16T15:00:00+08:00","readingtime":2,"relpermalink":"/blog/sofastack-independent-droup/","summary":"SOFAStack 启用独立 Group ，社区更加开放 今日，SOFAStack 将启用独立 Group： https://github.com/sofastack 感谢大家的一路支持，未来，我们继续相伴~ 背景：分布式架构 SOFAStack 开源历史","tags":["SOFAStack"],"title":"持续技术开放 | SOFAStack 启用独立 Group","type":"blog","url":"/blog/sofastack-independent-droup/","wordcount":617},{"author":"SQLFlow","categories":"SQLFlow","content":"5 月 6 日，在 QCon 全球软件开发大会（北京站）2019 上，蚂蚁金服副 CTO 胡喜正式宣布开源机器学习工具 SQLFlow，他在演讲中表示：“未来三年，AI 能力会成为每一位技术人员的基本能力。我们希望通过开源 SQLFlow，降低人工智能应用的技术门槛，让技术人员调用 AI 像 SQL 一样简单。”\nSQLFlow 的目标是将 SQL 引擎和 AI 引擎连接起来，让用户仅需几行 SQL 代码就能描述整个应用或者产品背后的数据流和 AI 构造。其中所涉及的 SQL 引擎包括 MySQL、Oracle、Hive、SparkSQL、Flink 等支持用 SQL 或其某个变种语言描述数据，以及描述对数据的操作的系统。而这里所指的 AI 引擎包括 TensorFlow、PyTorch 等深度学习系统，也包括 XGBoost、LibLinear、LibSVM 等传统机器学习系统。\nSQLFlow 开源项目链接：https://sqlflow.org/sqlflow\n5 月 26 日，将在上海迎来 SQLFlow 线下首秀 —《让 AI 像 SQL 一样简单— SQLFlow Demo》，还有 SOFAStack 开源生态交流分享，点击链接，即可报名~期待你的到来~\nhttps://tech.antfin.com/community/activities/576\nSQLFlow 的研发团队认为，在 SQLFlow 和 AI 引擎之间存在一个很大的空隙——如何把数据变成 AI 模型需要的输入。谷歌开源的 TensorFlow 项目开了一个好头，TFX Data Transform 和 feature column API 都是意图填补这个空缺的项目。但是这个空缺很大，是各种 SQL 引擎和各种 AI 引擎的笛卡尔积，远不是 TensorFlow 的这两个子项目就足以填补的，需要一个开源社区才行。要填补好这个空缺，需要先让用户意识到其重要性，这也是蚂蚁金服开源 SQLFlow 的意图之一。\nSQLFlow 位于 AI 软件系统生态的最顶端，最接近用户，它也位于数据和数据流软件生态之上。\n其实，将 SQL 和 AI 连接起来这个想法并非 SQLFlow 原创。谷歌于 2018 年年中发布的 BigQueryML 同样旨在“让数据科学家和分析师只用 SQL 语言就可以实现流行的机器学习功能并执行预测分析”。除了 Google 的 BigQueryML，微软基于 SQL Server 的 AI 扩展，以及 Teradata 的 SQL for DL 同样旨在连接 SQL 和 AI，让人工智能的应用变得像 SQL 一样简单。而 SQLFlow 与上述各个系统最根本的差异在于：SQLFlow 是开源的，以上系统都不是。\n开发 SQLFlow 的初衷 蚂蚁金服和很多互联网公司一样，不同产品背后有很多功能都依赖于 AI，比如用户信用的评估就是一套预测模型。到目前为止，每一个这样的功能的实现，都依赖一个工程师团队开发多个子系统——读取数据库或者在线日志流、这两类数据的 join、各种数据筛选、数据到模型输入（常说的 features）的映射、训练模型、用训练好的模型来做预测。整个过程下来耗时往往以月计，如果加班加点放弃写 unit test 代码，可能缩短到以周记。\n以上问题正是 SQLFlow 系统希望替工程师们解决的问题。蚂蚁金服拥有数千数据分析师，他们日常工作用的就是 SQL 语言。虽然数据分析师在互联网行业往往不像用 Python、Java、C++ 的工程师那样醒目，但是在很多有面向商业伙伴的业务的公司里，比如 LinkedIn，他们的贡献和人数都能与工程师相匹敌。SQLFlow 最早的初衷，就是希望解决分析师既要操作数据又要使用 AI、往往需要在两个甚至更多的系统之间切换、工作效率低的窘境。\nSQLFlow 旨在大幅提升效率，让上述功能实现所花费的时间进一步缩短到能以日计，甚至以小时计的程度。\n要达到这样的效率，必须有一种效率极高的描述工作意图的方式。SQL 是一种典型的描述意图，而不描述过程的编程语言。用户可以说我要 join 两个表，但是不需要写循环和构造 hash map 来描述如何 join 两个表。这个特性使得 SQL 能极大地提升开发效率，这正是 SQLFlow 选择扩展 SQL 语法支持 AI 这条思路的原因。\n不过，高效率的背后是更大的工程技术挑战。SQLFlow 需要做到能根据用户的意图，自动生成达到意图的 Python、C++、Go 语言的程序。\nSQLFlow 的架构设计 设计目标 在连接 SQL 和 AI 应用这一方向上，业内已有相关工作。开发者可以使用像 DOT_PRODUCT 这样的运算符在 SQL 中编写简单的机器学习预测（或评分）算法。但是，从训练程序到 SQL 语句需要进行大量的模型参数复制粘贴的工作。目前在一些商业软件中，已经有部分专有 SQL 引擎提供了支持机器学习功能的扩展。\n Microsoft SQL Server：Microsoft SQL Server 支持机器学习服务，可以将 R 或 Python 编写的机器学习程序作为外部脚本运行。 Teradata SQL for DL：Teradata 也提供了 RESTful 服务，可以通过扩展的 SQL SELECT 语法调用。 Google BigQuery：Google BigQuery 通过引入 CREATE MODEL 语句让用 SQL 实现机器学习成为可能。  但上述已有的解决方案都无法解决蚂蚁金服团队的痛点，他们的目标是打造一个完全可扩展的解决方案。\n 这一解决方案应与许多 SQL 引擎都兼容，而不是只能兼容特定版本或类型的 SQL 引擎。 它应该支持复杂的机器学习模型，包括用于深度学习的 TensorFlow 和用于树模型的 XGBoost。 能够灵活地配置和运行前沿机器学习算法，包括指定特征交叉，无需在 SQL 语句中嵌入 Python 或 R 代码，以及完全集成超参数估计等。  应对上述挑战的关键在于打造一套 SQL 扩展语法。研发团队首先从仅支持 MySQL 和 TensorFlow 的原型开发开始，后续计划支持更多 SQL 引擎和机器学习工具包。\n从 SQL 到机器学习 SQLFlow 可以看作一个翻译器，它把扩展语法的 SQL 程序翻译成一个被称为 submitter 的程序，然后执行。 SQLFlow 提供一个抽象层，把各种 SQL 引擎抽象成一样的。SQLFlow 还提供一个可扩展的机制，使得大家可以插入各种翻译机制，得到基于不同 AI 引擎的 submitter 程序。\nSQLFlow 对 SQL 语法的扩展意图很简单：在 SELECT 语句后面，加上一个扩展语法的 TRAIN 从句，即可实现 AI 模型的训练。或者加上一个 PREDICT 从句即可实现用现有模型做预测。这样的设计大大简化了数据分析师的学习路径。\n此外，SQLFlow 也提供一些基本功能，可以供各种 submitter 翻译插件使用，用来根据数据的特点，推导如何自动地把数据转换成 features。这样用户就 …","date":1557903600,"description":"本文整理于 QCon 全球软件开发大会（北京站）2019 上，蚂蚁金服副 CTO 胡喜正式宣布开源机器学习工具 SQLFlow 的现场演讲。","dir":"blog/sqlflow-open-source/","fuzzywordcount":5200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"fcd6535619144aec695ee9afbf2fc36b","permalink":"/blog/sqlflow-open-source/","publishdate":"2019-05-15T15:00:00+08:00","readingtime":11,"relpermalink":"/blog/sqlflow-open-source/","summary":"5 月 6 日，在 QCon 全球软件开发大会（北京站）2019 上，蚂蚁金服副 CTO 胡喜正式宣布开源机器学习工具 SQLFlow，他在演讲中表示：“未来三年，AI","tags":["SQLFlow"],"title":"蚂蚁金服开源机器学习工具 SQLFlow，技术架构独家解读","type":"blog","url":"/blog/sqlflow-open-source/","wordcount":5106},{"author":"花肉","categories":"SOFAChannel","content":"概要 活动主题：SOFAChannel#5：给研发工程师的代码质量利器 —— 自动化测试框架 SOFAActs\n活动时间：5 月 16 日周四晚 7 点\n活动形式：线上直播\n报名方式：https://tech.antfin.com/activities/552\n介绍 | SOFAChannel\n\u0026amp;lt;SOFA:Channel/\u0026amp;gt; 有趣实用的分布式架构频道：前沿技术、直播 Coding、观点“抬杠”，多种形式。\n\u0026amp;lt;SOFA:Channel/\u0026amp;gt; 将作为 SOFA 所有在线内容的承载，包含直播/音视频教程，集中体现 SOFAStack 的能力全景图。\n| SOFAChannel#5：给研发工程师的代码质量利器 —— 自动化测试框架 SOFAActs\n如何自动生成测试用例？\n如何减少测试用例设计过程中的阻力？\n如何进行精细化校验以及用例的高效管理，从而保障代码质量，有效提高测试效率？\n\u0026amp;lt;SOFA:Channel/\u0026amp;gt; 线上直播第 5 期《给研发工程师的代码质量利器 —— 自动化测试框架 SOFAActs》报名开启！\n5 月 16 日周四晚 7 点，围绕蚂蚁金服的多年测试实践的积累与沉淀，自动化测试框架 SOFAActs 核心成员青勤将为大家带来精彩分享，不要错过哦。\nSOFAActs 是基于数据模型驱动测试引擎的的新一代测试框架，它的数据以 YAML 为载体，在此上构建基于数据模型的驱动引擎，适配 TestNg+SOFABoot 的测试上下文环境；支持高效、标准化构建用例，可视化编辑测试数据，精细化校验结果数据和自动清理 DB 数据，可以有效降低人工录入用例数据的成本，同时支持 API 重写提高测试代码的可扩展可复用性，提供特有注解提高测试代码编排的灵活性。\n| 加入 SOFA 钉钉互动群\n欢迎加入直播互动钉钉群：23127468（搜索群号加入即可）\n| 点击即可报名\nhttps://tech.antfin.com/activities/552\n议程 19:00-19:05 主持人开场\nSOFAGirl 主持人\n19:05-20:00 给研发工程师的代码质量利器 — 自动化测试框架 SOFAActs\n青勤 蚂蚁金服自动化测试框架 SOFAActs 核心成员\n本期分享大纲：\n 蚂蚁金服接口自动化测试理念 如何接入 SOFAActs 自动化测试框架 SOFAActs 自动化测试框架的基本使用  嘉宾  SOFAGirl 主持人 青勤 蚂蚁金服自动化测试框架 SOFAActs 核心成员  ","date":1557310800,"description":"5 月 16 日周四晚 7 点，线上直播。","dir":"activities/sofa-channel-5/","fuzzywordcount":800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"e000553c2c76f43ed8df5b8e56491a7b","permalink":"/activities/sofa-channel-5/","publishdate":"2019-05-08T10:20:00Z","readingtime":2,"relpermalink":"/activities/sofa-channel-5/","summary":"概要 活动主题：SOFAChannel#5：给研发工程师的代码质量利器 —— 自动化测试框架 SOFAActs 活动时间：5 月 16 日周四晚 7 点 活动形式：线上直播 报名方","tags":["SOFAChannel","SOFAActs"],"title":"SOFAChannel#5：给研发工程师的代码质量利器 —— 自动化测试框架 SOFAActs","type":"activities","url":"/activities/sofa-channel-5/","wordcount":733},{"author":"米麒麟","categories":"SOFAJRaft","content":" SOFAStack Scalable Open Financial Architecture Stack 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。\nSOFAJRaft 是一个基于 Raft 一致性算法的生产级高性能 Java 实现，支持 MULTI-RAFT-GROUP，适用于高负载低延迟的场景。\n本文为《剖析 | SOFAJRaft 实现原理》第一篇，本篇作者米麒麟，来自陆金所。《剖析 | SOFAJRaft 实现原理》系列由 SOFA 团队和源码爱好者们出品，项目代号：SOFA:JRaftLab/，文章尾部有参与方式，欢迎同样对源码热情的你加入。\nSOFAJRaft ：https://github.com/sofastack/sofa-jraft\n 前言 SOFAJRaft 是一个基于 Raft 一致性算法的生产级高性能 Java 实现，支持 MULTI-RAFT-GROUP，适用于高负载低延迟的场景。\nSOFAJRaft 存储模块分为：\n Log 存储记录 Raft 配置变更和用户提交任务日志； Meta 存储即元信息存储记录 Raft 实现的内部状态； Snapshot 存储用于存放用户的状态机 Snapshot 及元信息。  本文将围绕日志存储，元信息存储以及快照存储等方面剖析 SOFAJRaft 存储模块原理，阐述如何解决 Raft 协议存储问题以及存储模块实现：\n Raft 配置变更和用户提交任务日志如何存储？如何调用管理日志存储？ SOFAJRaft Server 节点 Node 是如何存储 Raft 内部配置？ Raft 状态机快照 Snapshot 机制如何实现？如何存储安装镜像？  日志存储 Log 存储，记录 Raft 配置变更和用户提交任务的日志，把日志从 Leader 复制到其他节点上面。\n LogStorage 是日志存储实现，默认实现基于 RocksDB 存储，通过 LogStorage 接口扩展自定义日志存储实现； LogManager 负责调用底层日志存储 LogStorage，针对日志存储调用进行缓存、批量提交、必要的检查和优化。  LogStorage 存储实现 LogStorage 日志存储实现，定义 Raft 分组节点 Node 的 Log 存储模块核心 API 接口包括：\n 返回日志里的首/末个日志索引； 按照日志索引获取 Log Entry 及其任期； 把单个/批量 Log Entry 添加到日志存储； 从 Log 存储头部/末尾删除日志； 删除所有现有日志，重置下任日志索引。  Log Index 提交到 Raft Group 中的任务序列化为日志存储，每条日志一个编号，在整个 Raft Group 内单调递增并复制到每个 Raft 节点。LogStorage 日志存储实现接口定义入口：\ncom.alipay.sofa.jraft.storage.LogStorage RocksDBLogStorage 基于 RocksDB 实现 Log Structured Merge Tree 简称 LSM ，把一颗大树拆分成 N 棵小树，数据首先写入内存，内存里构建一颗有序小树，随着小树越来越大，内存的小树 Flush 到磁盘，磁盘中的树定期做合并操作合并成一棵大树以优化读性能，通过把磁盘的随机写转化为顺序写提高写性能，RocksDB 就是基于 LSM-Tree 数据结构使用 C++ 编写的嵌入式 KV 存储引擎，其键值均允许使用二进制流。RocksDB 按顺序组织所有数据，通用操作包括 get(key), put(key), delete(Key) 以及 newIterator()。RocksDB 有三种基本的数据结构：memtable，sstfile 以及 logfile。memtable 是一种内存数据结构\u0026amp;ndash;所有写入请求都会进入 memtable，然后选择性进入 logfile。logfile 是一种有序写存储结构，当 memtable 被填满的时候被刷到 sstfile 文件并存储起来，然后相关的 logfile 在之后被安全地删除。sstfile 内的数据都是排序好的，以便于根据 key 快速搜索。\nLogStorage 默认实现 RocksDBLogStorage 是基于 RocksDB 存储日志，初始化日志存储 StorageFactory 根据 Raft节点日志存储路径和 Raft 内部实现是否调用 fsync 配置默认创建 RocksDBLogStorage 日志存储。基于 RocksDB 存储实现 RocksDBLogStorage 核心操作包括：\n init()：创建 RocksDB 配置选项调用 RocksDB#open() 方法构建 RocksDB 实例，添加 default 默认列族及其配置选项获取列族处理器，通过 newIterator() 生成 RocksDB 迭代器遍历 KeyValue 数据检查 Value 类型加载 Raft 配置变更到配置管理器 ConfigurationManager。RocksDB 引入列族 ColumnFamily 概念，所谓列族是指一系列 KeyValue 组成的数据集，RocksDB 读写操作需要指定列族，创建 RocksDB 默认构建命名为default 的列族。 shutdown()：首先关闭列族处理器以及 RocksDB 实例，其次遍历列族配置选项执行关闭操作，接着关闭RocksDB 配置选项，最后清除强引用以达到 Help GC 垃圾回收 RocksDB 实例及其配置选项对象。 getFirstLogIndex()：基于处理器 defaultHandle 和读选项 totalOrderReadOptions 方法构建 RocksDB 迭代器 RocksIterator，检查是否加载过日志里第一个日志索引，未加载需调用 seekToFirst() 方法获取缓存 RocksDB 存储日志数据的第一个日志索引。 getLastLogIndex()：基于处理器 defaultHandle 和读选项 totalOrderReadOptions 构建 RocksDB 迭代器 RocksIterator，调用 seekToLast() 方法返回 RocksDB 存储日志记录的最后一个日志索引。 getEntry(index)：基于处理器 defaultHandle 和指定日志索引调用 RocksDB#get() 操作返回 RocksDB 索引位置日志 LogEntry。 getTerm(index)：基于处理器 defaultHandle 和指定日志索引调用 RocksDB#get() 操作获取 RocksDB 索引位置日志并且返回其 LogEntry 的任期。 appendEntry(entry)：检查日志 LogEntry 类型是否为配置变更，配置变更类型调用 RocksDB#write() 方法执行批量写入，用户提交任务的日志基于处理器 defaultHandle 和 LogEntry …","date":1557066600,"description":"本文为《剖析 | SOFAJRaft 实现原理》第一篇，本篇作者米麒麟，来自陆金所。。","dir":"blog/sofa-jraft-algorithm-storage-module-deep-dive/","fuzzywordcount":6400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"b48c76bf76b0c77d11af1a6265c9b78b","permalink":"/blog/sofa-jraft-algorithm-storage-module-deep-dive/","publishdate":"2019-05-05T14:30:00Z","readingtime":13,"relpermalink":"/blog/sofa-jraft-algorithm-storage-module-deep-dive/","summary":"SOFAStack Scalable Open Financial Architecture Stack 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 SOFAJRaft 是一个基于 Raft","tags":["SOFAJRaft","SOFALab","剖析 | SOFAJRaft 实现原理"],"title":"SOFAJRaft 实现原理 - 生产级 Raft 算法库存储模块剖析","type":"blog","url":"/blog/sofa-jraft-algorithm-storage-module-deep-dive/","wordcount":6382},{"author":"卫恒","categories":"SOFADashboard","content":" SOFAStack Scalable Open Financial Architecture Stack 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 为了建设更完整的 SOFAStack 微服务体系，我们计划发起 SOFADashboard 项目，计划通过社区的方式共建，将其打造为一站式的 SOFAStack 管控平台。欢迎共建~ SOFADashboard：https://github.com/sofastack/sofa-dashboard  背景 从 2018 年 4 月 19 日宣布开源至今，SOFAStack 目前已经开源了包括 SOFABoot、 SOFARPC、SOFALookout、SOFATracer、SOFARegistry 等在内的一系列微服务相关的项目，并投入分布式事务 Seata 进行重要贡献。随着 SOFAStack 架构体系的不断丰富和完善，外部对于 SOFAStack 的管控平台的需求也愈加强烈。\n由于 SOFAStack 内部的管控平台依赖众多的内部基础设施，为了建设更完整的 SOFAStack 微服务体系，我们计划发起全新的 SOFADashboard 项目，计划通过社区的方式共建，将其打造为一站式的 SOFAStack 管控平台。\n能力大图 SOFADashboard 作为一站式 SOFAStack 管控台，希望对 SOFAStack 各个组件的使用等进行统一管理。为此我们为 SOFADashboard 规划一版能力图，包含了微服务里的一些能力点，例如应用信息管理、服务治理、配置管控、动态模块等等。见下图所示：\n每个能力点对应的实现我们都做了一层抽象。例如服务查看需要从注册中心获取数据，我们封装了一层服务列表获取接口，底层可以是从 Zookeeper 或者 SOFARegistry 等不同的注册中心实现读取服务列表。\n技术栈选择 为了最大限度的降低开发成本、部署成本及运维成本，SOFADashboard 会基于开源社区优秀的产品来进行开发构建。经过讨论，最终选择社区主流的前后端分离思路，具体的组件包括：\n Ant Design：基于 React封装的一套 Ant Design 的组件库，主要用于研发企业级中后台产品。从产品成熟度、社区活跃度、框架上手难易程度等各个方面均有很好的表现。 SOFABoot：蚂蚁金服开源的基于 Spring Boot 的研发框架，它在 Spring Boot 的基础上，提供了诸如 Readiness Check，类隔离，日志空间隔离等能力。在增强了 Spring Boot 的同时，SOFABoot 提供了让用户可以在 Spring Boot 中非常方便地使用 SOFA 中间件的能力。 MyBatis：Mybatis 相对于 JPA 来说，上手难度略低，JPA 更加倾向于结合 DDD 使用(业务越复杂，对于DDD 的需求越高)；对于简单的增删改查业务操作，Mybatis 相对来说更灵活和可控。  v1.0 发布 4 月 30 日，我们上传了第一个 SOFADashboard 版本，主要能力包括：应用信息、服务查看、动态模块管控等。\n目前演示地址：http://dashboard.dev.sofastack.tech:8000/ 详细设计图 基础依赖 从架构图中可以看到，目前 SOFADashboard 中的服务治理、SOFAArk 管控等需要依赖于 Zookeeper 和 MySQL；它们承担的解决如下：\n   外部依赖 作用 备注     Zookeeper 注册中心 SOFARPC 服务治理    配置推送 SOFAArk 管控   MySql 资源存储 注册的 ark-biz 信息，插件与应用的关联信息，插件版本信息等    应用面板 SOFADashboard 支持查看应用的 IP、端口、健康检查状态等基本信息，此功能依赖 SOFADashboard client。SOFADashboard client 用于向 SOFADashboard 服务端注册 IP、端口、健康检查状态等应用基本信息；SOFADashboard client 并非是直接通过 API 调用的方式将自身应用信息直接注册到 SOFADashboard 服务端 ，而是借助于 Zookeeper 来完成。\n客户端向 Zookeeper 中如上图所示的节点中写入数据，每一个 ip:port 节点代表一个应用实例，应用本身信息将写入当前节点的 data 中。\n如果一个应用需要将应用信息展示到 SOFADashboard 管控端，可以通过引入客户端依赖即可，具体使用参考 SOFADashboard client 快速开始 。\n服务治理 SOFADashboard 服务治理是对 SOFARPC 的服务进行管理，服务治理管控台部分，主要包括基于服务名查询和服务信息列表展示两个基础能力。在服务治理管控台界面，可以直观的看到当前服务的一些基本元数据信息：\n当点击 服务 ID 对应的超链接时，会进入到当前服务的详情页；服务提供者详情页中，可以看到当前服务所有的提供方信息列表，每个 item 行对应一个服务提供方实例，通过此界面可以快速查看服务的 providers 信息。\n服务消费者详情页中，可以看到当前服务所有的消费方信息列表。\nSOFAArk 管控 SOFAArk 本身提供了多种方式来支持多应用(模块)合并部署 ，包括基于命令行的管控，基于 API 的管控等；SOFAArk 管控是 SOFADashboard 针对 API 管控的一种实现。通过面向 Zookeeper 进行命令的推送和命令的解析执行。SOFAArk 管控主要包括以下功能：\n 插件注册  将 ark-biz 插件注册到 SOFADashboard，作为基础数据，统一管控。\n插件基本信息录入：\n插件列表：\n 关联应用  将 ark-biz 插件与宿主应用进行绑定，此关联信息在 SOFAArk 多应用（模块）合并部署中作为重要的基础信息存在。在后续的操作中，可以通过此关联关系查看到某个插件下挂载的应用信息。\n 插件详情  通过插件详情页，可以看下当前 ark-biz 插件下所有关联的宿主应用信息，以及宿主应用中的 ark-biz 状态信息，插件详情页中，可以查看所有关联此插件的应用中，插件的状态信息。\n 命令推送  命令推送是 SOFADashboard 中提供 SOFAArk 管控的核心能力，通过面向 Zookeeper 编程的方式，将指令信息传递给各个宿主应用中的 ark-biz 模块，ark-biz 在接收到相关指令之后再进行相应的行为，如安装、切换、卸载等。\n可以针对应用维度、IP 维度推送一些指令，比如 install、uninstall 等等，当这些命令被写入到 Zookeeper 的某个节点上时，所有监听此节点的宿主应用均会解析此指令，并进行相关的操作。\n基于 IP 维度推送如图例所示，每个应用实例表单默认会有对应的操作，可以通过展示的命令按钮操作当前实例行为：\n点击 安装按钮，延迟 1~1.5s 之后 界面将会刷新 …","date":1557039600,"description":"为了建设更完整的 SOFAStack 微服务体系，我们计划发起 SOFADashboard 项目，计划通过社区的方式共建，将其打造为一站式的 SOFAStack 管控平台。欢迎共建~","dir":"blog/sofa-dashboard-open-source/","fuzzywordcount":2700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"f9a78639fd427da4c3ea19d32e8420e7","permalink":"/blog/sofa-dashboard-open-source/","publishdate":"2019-05-05T15:00:00+08:00","readingtime":6,"relpermalink":"/blog/sofa-dashboard-open-source/","summary":"SOFAStack Scalable Open Financial Architecture Stack 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 为了建设更完整","tags":["SOFADashboard"],"title":"SOFADashboard 启动开源共建 | SOFAStack 一站式管控平台","type":"blog","url":"/blog/sofa-dashboard-open-source/","wordcount":2602},{"author":"老王","categories":"SOFAStack","content":"本文转自 Linux 中国\n谈话中，鲁直反问的“你为什么不开源？”这句话让我印象深刻。\u0026amp;ndash; 老王\n二月初春，在西子湖畔的细雨中，我拜访了蚂蚁金服中间件团队，和 SOFA 技术负责人鲁直做了一次深入交谈，更妙的是，鲁直也是负责 SOFA 开源事务推进的人，而这样一个切实践行开放核心模式的开源项目，也正是我非常感兴趣的。\n两个技术人的谈话，自然是朴实而直白的，话题主要围绕着 SOFA 和开源主题展开，希望也能一样引起同是技术人的你的共鸣。\n 人物介绍 受访者：鲁直，蚂蚁金服 SOFA 开源负责人。 采访者：老王，开源布道人，有 20 年互联网从业经历的技术老兵。\n 虽然我和鲁直在微信上已经联系很久了，但这还是第一次见面。交谈中，我了解到鲁直是 2009 年加入阿里巴巴工作，已经有十年了。刚开始是在 1688.COM 做业务系统，对中间件技术非常感兴趣，也会经常研究各种中间件的实现和功能。后来在 2013年时，为了更深入地学习研究中间件框架，转到了蚂蚁金服中间件团队，从那个时候开始就一直在做 SOFA。\n目前鲁直在 SOFA 的团队主要负责的工作包括几个部分。其中一个主要部分就是 SOFA 开源相关的工作。SOFA 的产品体系非常广，包括已经对外开源的部分、内部整个微服务体系，以及 SOFA 框架等等——而这些开源相关的工作主要是由鲁直负责推动的。\n当然，作为技术负责人，鲁直既要带技术团队也要做技术工作。谈及这一点，鲁直说：\n“我觉得做技术管理，跟普通的管理不太一样，因为技术管理最重要的一个点是除了管理之外，还要保持一定的技术判断力和敏锐度。对一些新技术，包括团队中遇到一些重大的技术问题，你都要有一些方向性的判断。虽然最后不一定是你具体解决的，但是在整个团队的技术攻坚和技术选型上，要一起确立方向。”\n我以前也做过十余年的技术管理，我很能够感受这种情况，重大问题技术负责人更要迎难而上。\nSOFA 5 落子 Service Mesh 就我了解的情况，现在 SOFA 已经发展到了 SOFA5 了。在 SOFA4 阶段，主要的任务是将开源体系捋清楚了，然后开始按步骤地开源；到现在发展到了 SOFA5。我想知道从 SOFA4 发展到 SOFA5，是什么让蚂蚁金服中间件团队判断 SOFA4 的阶段性目标已经达成，可以迈进到新的 SOFA5 阶段了呢？\n “从整个业界趋势上来讲，SOFA4 的架构相对来说还是偏传统一些，更多是对我们之前的技术框架的整理和梳理。在这个阶段，SOFA 的代码经过了非常多的优化和重构，才达到了对外开源的要求，从而 SOFA 走上了开源核心的模式，逐步分阶段的将各个部分进行了开源。”鲁直讲到，“但是，从我们对业界的整体判断上来说，未来无疑是云的时代，所以说要考虑怎么让所有的业务系统能够提供云的能力，比如说 Serverless。”\n接着这个话题，鲁直讲了他对云计算的理解：“一方面云计算肯定要为整个业务的发展提供更加方便的基础资源，可以不用去关心底层的基础设施。Serverless 字面的意思就是说‘无服务器’——我不用关心服务器怎么来的，不用关心基础设施，只要关心业务代码就可以了。那反过来对于云服务商来说，经过了这一层抽象，其资源利用率会更高，可以有更多的利润空间，这是一个双赢的局面。对于用户来讲，这种好处是实实在在的，可以更少关注基础设施，只关心代码就可以了。”\n  “我们希望在 SOFA5 的方向上，在这个新的迭代中，去让业务——包括让未来我们开源出来各种功能、各样服务模式——都更多地去关心自己的业务代码，而不用再过多地关心基础设施。”鲁直说。\n 在 SOFA5 中，一个重要的方向就是 Service Mesh 这个方向，这将是 SOFA5 中非常重要的特性。鲁直强调了其对 Service Mesh 技术的看好：“我认为 Service Mesh 是迈向未来往前走的非常关键的一步，让业务不用再关心基础设施。通过 Service Mesh，我们可以将很多技术能力直接放到基础设施里面，而业务可以不用感知到这一层。原来可能需要花几个小时或者更多的时间解决的基础设施问题，现在可以通过 Service Mesh 解决掉。”\n“目前我们我们已经在生产环境中应用了 Service Mesh。我们在这方面有非常大的决心，我们希望能够在今年，在更大的范围中去落地 Service Mesh。当前这个阶段更聚焦在这种技术的内部落地上，希望用好了，再给社区做更多的贡献。”\n Service Mesh 这个词最早是由开发 Linkerd 的 Buoyant 公司于 2016 年提出的，随着 Linkerd 的传入，Service Mesh 也进入国内技术社区的视野。Service Mesh 也被翻译为“服务网格”。Linkerd 则是业界第一个 Service Mesh。 Service Mesh 是一个基础设施层，用于处理服务间通信，负责实现请求的可靠传递。在实践中，服务网格通常实现为轻量级网络代理，通常与应用程序部署在一起，但是对应用程序透明。\nService Mesh 的部署模型，有两种情况： ◈ 对于一个简单请求，作为请求发起者的客户端应用实例，会首先用简单方式将请求发送到本地的 Service Mesh 实例。这是两个独立进程，它们之间是远程调用。Service Mesh 会完成完整的服务间调用流程，如服务发现负载均衡，最后将请求发送给目标服务。这就是 Sidecar，它在原有的客户端和服务端之间加多了一个代理。 ◈ 多个服务调用的情况，Service Mesh 出现在所有的服务的下面，这一层被称之为服务间通讯专用基础设施层。Service Mesh 会接管整个网络，把所有的请求在服务之间做转发。在这种情况下，上面的服务不再负责传递请求的具体逻辑，只负责完成业务处理。服务间通讯的环节就从应用里面剥离出来，呈现出一个抽象层。\n如果有大量的服务，Sidecar 之间的连接就会形成一个网络，这个就是服务网格名字的由来。\n “我们将以 Service Mesh 为跳板再往前走。”鲁直表示，“Serverless 更多的还是应该聚焦在其字面本身，其含义就是‘无服务器’，后面的技术都是为了让无服务器承载具体的业务。”\nServerless 这个概念虽然提出来已经有几年了，目前 AWS 在 Serverless 和 FaaS 方面处于比较前沿的位置，但是在国内，Serverless、FaaS 这些技术的发展还是相对比较滞后。\n鲁直指出，“我觉得 Serverless 想要成功，还是要从覆盖业务的整个广度上打开，否则可能还是停留在 FaaS 上，那场景就比较受限。”\n Service Mesh 将是微服务的下一个时代，关于它还在持续进行理论研究和实践探索。\n 鲁直说：“坦白来讲，我觉得 istio 的理念非常好，但是在整个工程设计上，如果放到蚂蚁金服这样体量较大的环境里面，可能跑起来还需要做一些工作。我们希望今年 Service Mesh 在蚂蚁金服有了更大规模落地之后，可以把我们在 Service Mesh 方面的一些实践经验用到产品环境的工程中去实践，然后贡献出去。目前更多的一些工作，是将整个体 …","date":1556607600,"description":"谈话中，鲁直反问的“你为什么不开源？”这句话让我印象深刻。-- 老王","dir":"blog/antfin-middleware-open-source-key-figure-luzhi/","fuzzywordcount":6000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"6779f59b05648131b0d635a71cd95d0d","permalink":"/blog/antfin-middleware-open-source-key-figure-luzhi/","publishdate":"2019-04-30T15:00:00+08:00","readingtime":12,"relpermalink":"/blog/antfin-middleware-open-source-key-figure-luzhi/","summary":"本文转自 Linux 中国 谈话中，鲁直反问的“你为什么不开源？”这句话让我印象深刻。\u0026ndash; 老王 二月初春，在西子湖畔的细雨中，我拜访了蚂蚁金服中间","tags":["SOFAStack"],"title":"对话鲁直：蚂蚁金服中间件的开源头羊 | 穿山甲专访","type":"blog","url":"/blog/antfin-middleware-open-source-key-figure-luzhi/","wordcount":5979},{"author":"力鲲","categories":"SOFAJRaft","content":" SOFAStack Scalable Open Financial Architecture Stack 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。\n本文根据 SOFA Meetup#1 北京站 现场分享整理，完整的分享 PPT 获取方式见文章底部。\n 前言 SOFAJRaft 是一个基于 Raft 一致性算法的生产级高性能 Java 实现，支持 MULTI-RAFT-GROUP，适用于高负载低延迟的场景。SOFAJRaft 是从百度的 braft 移植而来，做了一些优化和改进，感谢百度 braft 团队开源了如此优秀的 C++ Raft 实现。\nGitHub 地址：https://github.com/sofastack/sofa-jraft\n之前，我们有一篇介绍 SOFAJRaft 的文章，可在文末获得链接，延续这个内容，今天的演讲分为三部分，先简要介绍 Raft 算法，然后介绍 SOFAJRaft 的设计，最后说说它的优化。\n分享嘉宾：力鲲 蚂蚁金服 SOFAJRaft 核心成员\nRaft 共识算法 Raft 是一种共识算法，其特点是让多个参与者针对某一件事达成完全一致：一件事，一个结论。同时对已达成一致的结论，是不可推翻的。可以举一个银行账户的例子来解释共识算法：假如由一批服务器组成一个集群来维护银行账户系统，如果有一个 Client 向集群发出“存 100 元”的指令，那么当集群返回成功应答之后，Client 再向集群发起查询时，一定能够查到被存储成功的这 100 元钱，就算有机器出现不可用情况，这 100 元的账也不可篡改。这就是共识算法要达到的效果。\nRaft 算法和其他的共识算法相比，又有了如下几个不同的特性：\n Strong leader：Raft 集群中最多只能有一个 Leader，日志只能从 Leader 复制到 Follower 上； Leader election：Raft 算法采用随机选举超时时间触发选举来避免选票被瓜分的情况，保证选举的顺利完成； Membership changes：通过两阶段的方式应对集群内成员的加入或者退出情况，在此期间并不影响集群对外的服务。  共识算法有一个很典型的应用场景就是复制状态机。Client 向复制状态机发送一系列能够在状态机上执行的命令，共识算法负责将这些命令以 Log 的形式复制给其他的状态机，这样不同的状态机只要按照完全一样的顺序来执行这些命令，就能得到一样的输出结果。所以这就需要利用共识算法保证被复制日志的内容和顺序一致。\nLeader 选举 复制状态机集群在利用 Raft 算法保证一致性时，要做的第一件事情就是 Leader 选举。在讲 Leader 选举之前我们先要说一个重要的概念：Term。Term 用来将一个连续的时间轴在逻辑上切割成一个个区间，它的含义类似于“美国第 26 届总统”这个表述中的“26”。\n每一个 Term 期间集群要做的第一件事情就是选举 Leader。起初所有的 Server 都是 Follower 角色，如果 Follower 经过一段时间( election timeout )的等待却依然没有收到其他 Server 发来的消息时，Follower 就可以认为集群中没有可用的 Leader，遂开始准备发起选举。在发起选举的时候 Server 会从 Follower 角色转变成 Candidate，然后开始尝试竞选 Term + 1 届的 Leader，此时他会向其他的 Server 发送投票请求，当收到集群内多数机器同意其当选的应答之后，Candidate 成功当选 Leader。但是如下两种情况会让 Candidate 退回 (step down) 到 Follower，放弃竞选本届 Leader：\n  如果在 Candidate 等待 Servers 的投票结果期间收到了其他拥有更高 Term 的 Server 发来的投票请求；\n  如果在 Candidate 等待 Servers 的投票结果期间收到了其他拥有更高 Term 的 Server 发来的心跳；\n  当然了，当一个 Leader 发现有 Term 更高的 Leader 时也会退回到 Follower 状态。\n当选举 Leader 成功之后，整个集群就可以向外提供正常读写服务了，如图所示，集群由一个 Leader 两个 Follower 组成，Leader 负责处理 Client 发起的读写请求，同时还要跟 Follower 保持心跳或者把 Log 复制给 Follower。\nLog 复制 下面我们就详细说一下 Log 复制。我们之前已经说了 Log 就是 Client 发送给复制状态机的一系列命令。这里我们再举例解释一下 Log，比如我们的复制状态机要实现的是一个银行账户系统，那么这个 Log 就可以是 Client 发给账户系统的一条存钱的命令，比如“存 100 元钱”。\nLeader 与 Follower 之间的日志复制是共识算法运用于复制状态机的重要目的，在 Raft 算法中 Log 由 TermId、LogIndex、LogValue 这三要素构成，在这张图上每一个小格代表一个 Log。当 Leader 在向 Follower 复制 Log 的时候，Follower 还需要对收到的 Log 做检查，以确保这些 Log 能和本地已有的 Log 保持连续。我们之前说了，Raft 算法是要严格保证 Log 的连续性的，所以 Follower 会拒绝无法和本地已有 Log 保持连续的复制请求，那么这种情况下就需要走 Log 恢复的流程。总之，Log 复制的目的就是要让所有的 Server 上的 Log 无论在内容上还是在顺序上都要保持完全一致，这样才能保证所有状态机执行结果一致。\n目前已经有一些很优秀的对 Raft 的实现，比如 C++ 写的 braft，Go 写的 etcd，Rust 写的 TiKV。当然了，SOFAJRaft 并不是 Raft 算法的第一个 Java 实现，在我们之前已经有了很多项目。但是经过我们的评估，觉得目前还是没有一个 Raft 的 Java 实现库类能够满足蚂蚁生产环境的要求，这也是我们去写 SOFAJRaft 的主要原因。\nSOFAJRaft 介绍 接下来我们介绍 SOFAJRaft。 SOFAJRaft 是基于 Raft 算法的生产级高性能 Java 实现，支持 MULTI-RAFT-GROUP。从去年 3 月开发到今年 2 月完成，并在今年 3 月开源。应用场景有 Leader 选举、分布式锁服务、高可靠的元信息管理、分布式存储系统，目前使用案例有 RheaKV，这是 SOFAJRaft 中自带的一个分布式 KV 存储，还有今天开源的 SOFA 服务注册中心中的元信息管理模块也是用到了 SOFAJRaft，除此之外还有一些内部的项目也有使用，但是因为没有开源，所以就不再详述了。\n这张图就是 SOFAJRaft 的设计图，Node 代表了一个 SOFAJRaft Server 节点，这些方框代表他内部的各个模块，我们 …","date":1556202600,"description":"本文根据 SOFAChannel#4 直播分享整理，主题：SOFAJRaft 详解。","dir":"blog/sofa-jraft-deep-dive/","fuzzywordcount":5700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"f2d4559ece4184ef09b96899a1aeb900","permalink":"/blog/sofa-jraft-deep-dive/","publishdate":"2019-04-25T14:30:00Z","readingtime":12,"relpermalink":"/blog/sofa-jraft-deep-dive/","summary":"SOFAStack Scalable Open Financial Architecture Stack 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文根据 SOFA Meetup#1 北","tags":["SOFAJRaft","剖析 | SOFAJRaft 实现原理","SOFALab"],"title":"蚂蚁金服开源 SOFAJRaft 详解| 生产级高性能 Java 实现","type":"blog","url":"/blog/sofa-jraft-deep-dive/","wordcount":5688},{"author":"琪祥","categories":"SOFARegistry","content":" SOFAStack Scalable Open Financial Architecture Stack 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 SOFARegistry 是蚂蚁金服开源的具有承载海量服务注册和订阅能力的、高可用的服务注册中心，最早源自于淘宝的初版 ConfigServer，在支付宝/蚂蚁金服的业务发展驱动下，近十年间已经演进至第五代。 GitHub 地址：https://github.com/sofastack/sofa-registry \n 3 月 31 日，蚂蚁金服正式开源了内部演进了近 10 年的注册中心产品-SOFARegistry。先前的文章介绍了 SOFARegistry 的演进之路，而本文主要对 SOFARegistry 整体架构设计进行剖析，并着重介绍一些关键的设计特点，期望能帮助读者对 SOFARegistry 有更直接的认识。\n如有兴趣，也欢迎加入《剖析 | SOFARegistry 实现原理》系列的共建，认领列表见文末。\n服务注册中心是什么 不可免俗地，先介绍一下服务注册中心的概念。对此概念已经了解的读者，可选择跳过本节。\n如上图，服务注册中心最常见的应用场景是用于 RPC 调用的服务寻址，在 RPC 远程过程调用中，存在 2 个角色，一个服务发布者（Publisher）、另一个是服务订阅者（Subscriber）。Publisher 需要把服务注册到服务注册中心（Registry），发布的内容通常是该 Publisher 的 IP 地址、端口、调用方式 （协议、序列化方式）等。而 Subscriber 在第一次调用服务时，会通过 Registry 找到相应的服务的 IP 地址列表，通过负载均衡算法从 IP 列表中取一个服务提供者的服务器调用服务。同时 Subscriber 会将 Publisher 的服务列表数据缓存到本地，供后续使用。当 Subscriber 后续再调用 Publisher 时，优先使用缓存的地址列表，不需要再去请求Registry。\n如上图，Subscriber 还需要能感知到 Publisher 的动态变化。比如当有 Publisher 服务下线时， Registry 会将其摘除，随后 Subscriber 感知到新的服务地址列表后，不会再调用该已下线的 Publisher。同理，当有新的 Publisher 上线时，Subscriber 也会感知到这个新的 Publisher。\n初步认识 在理解了常见的服务注册中心的概念之后，我们来看看蚂蚁金服的 SOFARegistry 长什么样子。如上图，SOFARegistry 包含 4 个角色：\n Client  提供应用接入服务注册中心的基本 API 能力，应用系统通过依赖客户端 JAR 包，通过编程方式调用服务注册中心的服务订阅和服务发布能力。\nSessionServer  会话服务器，负责接受 Client 的服务发布和服务订阅请求，并作为一个中间层将写操作转发 DataServer 层。SessionServer 这一层可随业务机器数的规模的增长而扩容。\nDataServer  数据服务器，负责存储具体的服务数据，数据按 dataInfoId 进行一致性 Hash 分片存储，支持多副本备份，保证数据高可用。这一层可随服务数据量的规模的增长而扩容。\nMetaServer  元数据服务器，负责维护集群 SessionServer 和 DataServer 的一致列表，作为 SOFARegistry 集群内部的地址发现服务，在 SessionServer 或 DataServer 节点变更时可以通知到整个集群。\n产品特点 （图片改编自 https://luyiisme.github.io/2017/04/22/spring-cloud-service-discovery-products ）\n首先放一张常见的服务注册中心的特性对比，可以看出，在这些 Feature 方面，SOFARegistry 并不占任何优势。那么，我们为什么还开源这样的一个系统？SOFARegistry 开源的优势是什么？下面将着重介绍 SOFARegistry 的特点。\n支持海量数据 大部分的服务注册中心系统，每台服务器都是存储着全量的服务注册数据，服务器之间依靠一致性协议（如 Paxos/Raft/2PC 等）实现数据的复制，或者只保证最终一致性的异步数据复制。“每台服务器都存储着全量的服务注册数据”，在一般规模下是没问题的。但是在蚂蚁金服庞大的业务规模下，服务注册的数据总量早就超过了单台服务器的容量瓶颈。\nSOFARegistry 基于一致性 Hash 做了数据分片，每台 DataServer 只存储一部分的分片数据，随数据规模的增长，只要扩容 DataServer 服务器即可。这是相对服务发现领域的其他竞品来说最大的特点，详细介绍见后面《如何支持海量数据》一节。\n支持海量客户端 SOFARegistry 集群内部使用分层的架构，分别为连接会话层（SessionServer）和数据存储层（DataServer）。SessionServer 功能很纯粹，只负责跟 Client 打交道，SessionServer 之间没有任何通信或数据复制，所以随着业务规模（即 Client 数量）的增长，SessionServer 可以很轻量地扩容，不会对集群造成额外负担。\n相比之下，其他大多数的服务发现组件，如 eureka，每台服务器都存储着全量的数据，依靠 eurekaServer 之间的数据复制来传播到整个集群，所以每扩容 1 台 eurekaServer，集群内部相互复制的数据量就会增多一份。再如 Zookeeper 和 Etcd 等强一致性的系统，它们的复制协议（Zab/Raft）要求所有写操作被复制到大多数服务器后才能返回成功，那么增加服务器还会影响写操作的效率。\n秒级的服务上下线通知 对于服务的上下线变化，SOFARegistry 使用推送机制，快速地实现端到端的传达。详细介绍见后面《秒级服务上下线通知》一节。\n接下来，我将围绕这些特点，讲解 SOFARegistry 的关键架构设计原理。\n高可用 各个角色都有 failover 机制：\n MetaServer 集群部署，内部基于 Raft 协议选举和复制，只要不超过 1/2 节点宕机，就可以对外服务。 DataServer 集群部署，基于一致性 Hash 承担不同的数据分片，数据分片拥有多个副本，一个主副本和多个备副本。如果 DataServer 宕机，MetaServer 能感知，并通知所有 DataServer 和 SessionServer，数据分片可 failover 到其他副本，同时 DataServer 集群内部会进行分片数据的迁移。 SessionServer 集群部署，任何一台 SessionServer 宕机时 Client 会自动 failover 到其他 SessionServer，并且 Client 会拿到最新的 SessionServer 列表，后续不 …","date":1556175600,"description":"本文为《剖析 | SOFARegistry 框架》第一篇，本篇作者琪祥。","dir":"blog/sofa-registry-introduction/","fuzzywordcount":11100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"04394de7d7b0ecba5303baa6949a40d4","permalink":"/blog/sofa-registry-introduction/","publishdate":"2019-04-25T15:00:00+08:00","readingtime":23,"relpermalink":"/blog/sofa-registry-introduction/","summary":"SOFAStack Scalable Open Financial Architecture Stack 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 SOFARegistry 是蚂蚁金服开","tags":["SOFARegistry","剖析 | SOFARegistry 框架","SOFALab"],"title":"海量数据下的注册中心 - SOFARegistry 架构介绍","type":"blog","url":"/blog/sofa-registry-introduction/","wordcount":11069},{"author":"觉生","categories":"Seata","content":" SOFA:Channel/，有趣实用的分布式架构频道。 本文根据 SOFAChannel#4 直播分享整理，主题：分布式事务 Seata TCC 模式深度解析。 Seata：https://github.com/seata/seata 回顾视频以及 PPT 查看地址见文末。 欢迎加入直播互动钉钉群：23127468，不错过每场直播。\n 2019 年 3 月，蚂蚁金服加入分布式事务 Seata 的社区共建中，并贡献其 TCC 模式。本期是 SOFAChannel 第四期，主题：分布式事务 Seata TCC 模式深度解析，本文根据觉生的直播整理。\n大家晚上好，我是 Seata Committer 觉生，来自蚂蚁金服数据中间件团队。今天的内容主要分为以下四个部分：\n Seata TCC 模式的原理解析； 从 TCC 的业务模型与并发控制分享如何设计一个 TCC 接口，并且适配 TCC 模型； 如何控制异常； 性能优化，使得 TCC 模式能够满足更高的业务需求。  1、 Seata 的 TCC 模式 1.1 服务化拆分 下面我们就进入第一个主题，Seata 的 TCC 模式。蚂蚁金服早期是单系统架构，所有业务服务几乎都在少数几个系统中。随着业务的发展，业务越来越复杂，服务之间的耦合度也越来越高，故我们对系统进行了重构，服务按照功能进行解耦和垂直拆分。拆分之后所带来的问题就是一个业务活动原来只需要调用一个服务就能完成，现在需要调用多个服务才能完成，而网络、机器等不可靠，数据一致性的问题很容易出现，与可扩展性、高可用容灾等要求并肩成为金融 IT 架构支撑业务转型升级的最大挑战之一。\n从图中可以看到，从单系统到微服务转变，其实是一个资源横向扩展的过程，资源的横向扩展是指当单台机器达到资源性能瓶颈，无法满足业务增长需求时，就需要横向扩展资源，形成集群。通过横向扩展资源，提升非热点数据的并发性能，这对于大体量的互联网产品来说，是至关重要的。服务的拆分，也可以认为是资源的横向扩展，只不过方向不同而已。\n资源横向扩展可能沿着两个方向发展，包括业务拆分和数据分片：\n  业务拆分。根据功能对数据进行分组，并将不同的微服务分布在多个不同的数据库上，这实际上就是 SOA 架构下的服务化。业务拆分就是把业务逻辑从一个单系统拆分到多个微服务中。\n  数据分片。在微服务内部将数据拆分到多个数据库上，为横向扩展增加一个新的维度。数据分片就是把一个微服务下的单个 DB 拆分成多个 DB，具备一个 Sharding 的功能。通过这样的拆解，相当于一种资源的横向扩展，从而使得整个架构可以承载更高的吞吐。\n  横向扩展的两种方法可以同时进行运用：交易、支付与账务三个不同微服务可以存储在不同的数据库中。另外，每个微服务内根据其业务量可以再拆分到多个数据库中，各微服务可以相互独立地进行扩展。\nSeata 关注的就是微服务架构下的数据一致性问题，是一整套的分布式事务解决方案。Seata 框架包含两种模式，一种是 AT 模式。AT 模式主要从数据分片的角度，关注多 DB 访问的数据一致性，当然也包括多服务下的多 DB 数据访问一致性问题。\n另外一个就是 TCC 模式，TCC 模式主要关注业务拆分，在按照业务横向扩展资源时，解决微服务间调用的一致性问题，保证读资源访问的事务属性。\n今天我们主要讲的就是TCC模式。在讲 TCC 之前，我们先回顾一下 AT 模式，这样有助于我们理解后面的 TCC 模式。\n1.2. AT 模式 对于 AT 模式，之前其他同学已经分享过很多次，大家也应该比较熟悉了。AT 模式下，把每个数据库被当做是一个 Resource，Seata 里称为 DataSource Resource。业务通过 JDBC 标准接口访问数据库资源时，Seata 框架会对所有请求进行拦截，做一些操作。每个本地事务提交时，Seata RM（Resource Manager，资源管理器） 都会向 TC（Transaction Coordinator，事务协调器） 注册一个分支事务。当请求链路调用完成后，发起方通知 TC 提交或回滚分布式事务，进入二阶段调用流程。此时，TC 会根据之前注册的分支事务回调到对应参与者去执行对应资源的第二阶段。TC 是怎么找到分支事务与资源的对应关系呢？每个资源都有一个全局唯一的资源 ID，并且在初始化时用该 ID 向 TC 注册资源。在运行时，每个分支事务的注册都会带上其资源 ID。这样 TC 就能在二阶段调用时正确找到对应的资源。\n这就是我们的 AT 模式。简单总结一下，就是把每个数据库当做一个 Resource，在本地事务提交时会去注册一个分支事务。\n1.3 TCC 模式 那么对应到 TCC 模式里，也是一样的，Seata 框架把每组 TCC 接口当做一个 Resource，称为 TCC Resource。这套 TCC 接口可以是 RPC，也以是服务内 JVM 调用。在业务启动时，Seata 框架会自动扫描识别到 TCC 接口的调用方和发布方。如果是 RPC 的话，就是 sofa:reference、sofa:service、dubbo:reference、dubbo:service 等。\n扫描到 TCC 接口的调用方和发布方之后。如果是发布方，会在业务启动时向 TC 注册 TCC Resource，与DataSource Resource 一样，每个资源也会带有一个资源 ID。\n如果是调用方，Seata 框架会给调用方加上切面，与 AT 模式一样，在运行时，该切面会拦截所有对 TCC 接口的调用。每调用一次 Try 接口，切面会先向 TC 注册一个分支事务，然后才去执行原来的 RPC 调用。当请求链路调用完成后，TC 通过分支事务的资源ID回调到正确的参与者去执行对应 TCC 资源的 Confirm 或 Cancel 方法。\n在讲完了整个框架模型以后，大家可能会问 TCC 三个接口怎么实现。因为框架本身很简单，主要是扫描 TCC 接口，注册资源，拦截接口调用，注册分支事务，最后回调二阶段接口。最核心的实际上是 TCC 接口的实现逻辑。下面我将根据蚂蚁金服内部多年的实践来为大家分析怎么实现一个完备的 TCC 接口。\n2、 TCC 业务模型与并发控制 2.1 TCC 设计原则 从 TCC 模型的框架可以发现，TCC 模型的核心在于 TCC 接口的设计。用户在接入 TCC 时，大部分工作都集中在如何实现 TCC 服务上。下面我会分享蚂蚁金服内多年的 TCC 应用实践以及在 TCC 设计和实现过程中的注意事项。\n设计一套 TCC 接口最重要的是什么？主要有两点，**第一点，需要将操作分成两阶段完成。**TCC（Try-Confirm-Cancel）分布式事务模型相对于 XA 等传统模型，其特征在于它不依赖 RM 对分布式事务的支持，而是通过对业务逻辑的分解来实现分布式事务。\nTCC 模型认为对于业务系统中一个特定的业务逻辑 ，其对外提供服务时，必须接受一些不确定性，即对业务逻辑初步操作的调用仅是一个临时性操作，调用它的主业务服务保留了后续的取消权。如果主业务服务认为全局事务应该回滚，它会要求取消之前的临时性操作，这 …","date":1556089200,"description":"本文根据 SOFAChannel#4 直播分享整理，主题：分布式事务 Seata TCC 模式深度解析。","dir":"blog/sofa-channel-4-retrospect/","fuzzywordcount":10500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"75094c50f180bcd31d84bc687e4c93e0","permalink":"/blog/sofa-channel-4-retrospect/","publishdate":"2019-04-24T15:00:00+08:00","readingtime":21,"relpermalink":"/blog/sofa-channel-4-retrospect/","summary":"SOFA:Channel/，有趣实用的分布式架构频道。 本文根据 SOFAChannel#4 直播分享整理，主题：分布式事务 Seata TCC 模式深度解析。 Seata：https://","tags":["Seata","SOFAChannel"],"title":"分布式事务 Seata TCC 模式深度解析 | SOFAChannel#4 直播整理","type":"blog","url":"/blog/sofa-channel-4-retrospect/","wordcount":10491},{"author":"青勤","categories":"SOFAActs","content":" SOFA:Channel/，有趣实用的分布式架构频道。 本文根据 SOFAChannel#5 直播分享整理，主题：给研发工程师的代码质量利器 —— 自动化测试框架 SOFAActs。 回顾视频以及 PPT 查看地址见文末。 欢迎加入直播互动钉钉群：23195297，不错过每场直播。\n 大家晚上好，我是蚂蚁金服自动化测试框架 SOFAActs 开源核心成员青勤，目前从事测试技术相关的研发工作，今晚将由我来给大家分享交流自动化测试框架 SOFAActs 的基本原理和使用，今天的内容主要分为以下四个章节：\n 项目介绍 SOFAActs 接入 功能介绍与使用 升阶功能使用  欢迎大家 Star 我，SOFAActs：https://github.com/sofastack/sofa-acts\n1 项目介绍 在分享使用操作前，我将引导大家来熟悉下 SOFAActs 的项目背景、基本原理等。\n对于研发质量保障而言，金融系统和金融业务的多样性、复杂性同样也会在测试场景、测试验证和测试流程的复杂程度上得到充分体现。\n譬如，对于包含出参、RPC 调用、DB 变更和异常等多个测试验证点的用例而言，在研发和测试人员维护和验证用例场景的过程中，时常发生业务结果校验遗漏，对我们及早发现和纠错问题造成干扰，进而无法严格保障产品质量。这些问题对研发质量保障提出了很高的挑战，相应的自动化、精细化的白盒测试工具需求日益增长，这其中就包括 SOFAActs。\n为了解决上述痛点、满足精细化测试需要，在多年测试实践积累与沉淀下，我们研发了基于模型驱动的 SOFAActs 测试框架，它可以灵活、可扩展的提供一站式用例管理，标准化测试执行和精细化校验。目前 SOFAActs 测试框架逐渐成熟并在蚂蚁金服内部得到广泛应用。\n1.1 项目架构 介绍完背景，我们来看下 SOFAActs 的大体框架，SOFAActs 底层封装并集成适配 SOFABoot 等运行环境。\n在重要的引擎层，SOFAActs 封装了工具类和数据模型，并将测试模式的过程进行了标准化，提供通用测试能力和扩展点。对于有自动化测试经验的同学来讲，测试模式其实并不复杂，这其中有很多工作是可以抽象和固定的，SOFAActs 将这部分内容内聚到引擎层，封装成标准测试流程等，尤其是模型驱动和精细化校验等，从而释放精力，将更多关注点聚焦在待测目标上。\n引擎层之上，是 SOFAActs 提供的可视化用例管理功能，可以一站式的维护测试脚本、测试数据和数据模型，借助可视化编辑器可成倍提高用例管理等等操作效率，整体而言 SOFAActs 围绕模型驱动引擎和可视化编辑器，将测试代码的编写工作量极尽降低，目标聚焦在测试对象上。\n这里我们示例看下，SOFAActs 对测试代码和效率的优化。这里以 Credit 接口为例，业务处理开始之前会检查传参，构造上下文、随后发起业务处理，涉及对三张表的读取或变更，并在数据库事物结束之后，返回业务处理结果。\n针对这一业务逻辑，这里我们构造一个 Credit 接口的完整测试用例，在代码驱动测试时，它需要一下 9 个步骤，手动准备依赖数据、构造请求参数、执行业务逻辑、校验业务结果以及数据清理等等，人工介入成本居高，尤其当存在多个用例时，测试代码可复用性低，测试效率是难以得到有效提升。而与之对比，在模型驱动测试下，Credit 接口的 SOFAActs 测试脚本会对固有的测试模式进行封装，用例复杂度得到极大精简，众多用例数据可以得到高效的可视化管理。\n1.2 执行原理 在开始使用 SOFAActs 之前，我们来了解一下有关 SOFAActs 执行引擎的运作原理。SOFAActs 框架也提供了非常多的扩展点，如果需要个性化的定义，可以对每一个环节进行扩展。\n上文中已提到过 SOFAActs 执行引擎是对测试模式过程的封装，Setup 方法是引擎入口，用于加载初始化 SOFAActs 运行时的必需资源，如获取数据源。\n以下是主体测试过程：clear、prepare、execute、check 这 4 个方法依次负责环境清理、依赖准备、执行、结果校验等。这些内容是代码驱动测试时需要手写的测试代码和内容，每个测试脚本的完成意味着上面的过程会被我们重复一遍，于是 SOFAActs 将这部分内容进行了封装，实现了最通用基础的功能。\n右侧，我们对高频数据如方法入参、出参、异常和依赖DB数据进行了抽象，给出 SOFAActs 的模型，这是代码驱动转向模型驱动、精细化校验的基础。左侧的数据总线会贯穿每个用例的执行生命周期，即贯穿中间的主体测试过程，如果大家对框架封装的基础功能有自定义需要，可以通过数据总线对 SOFAActs 的对象、方法进行获取、重写，以便更灵活的控制框架行为。当然 SOFAActs 对这些内容作了较好的封装，覆盖了大部分的测试需求，无需大家过度关注。\n以上就是 SOFAActs 的执行原理，接下来我会给大家详细介绍 SOFAActs 的接入和使用。\n2 SOFAActs 接入 SOFAActs 分为两部分，其一是可视化编辑器，在 [SOFAStack 官网上 1 我们可以获取该编辑器的安装包，并通过 IDEA 的插件管理进行安装。其二是 SOFAActs 的基础 jar，它提供了 SOFAActs 用例运行的环境支持，在 test 模块 pom 中添加下列依赖即可，有关 test 模块或者多模块详细内容大家可以参考 [SOFAActs 的快速开始文档 1 。\n3 功能介绍和使用 下面，我们进入 SOFAActs 的功能介绍和使用章节，这部分我将分为三小节展开：一站式构建、SOFAActs 核心的模型驱动以及 SOFAActs 提供的精准校验。\n3.1 一站式构建 一站式构建中，SOFAActs 通过可视化编辑器为我们提供了便捷操作，以帮助一键配置初始化、构建测试脚本与模型，可视化管理用例数据等等。借助可视化编辑器，在整个过程中我们可以替换大部分手工编写代码的工作，进行一站式操作。\n一键初始化\n这里我们示例看下，如何操作一键初始化以及一键初始化做哪些内容。首先一键初始化框架只需要 3 个鼠标点击步骤。在 Package 视图下选中测试模块并右键选择 SOFAActs 功能，一键初始化，输入该应用的应用名称和工程编码格式。在一键初始化完成后，SOFAActs 将会在 test 模块写入 SOFAActs 配置文件，DB 连接配置文件，测试套件配置文件以及创建模型存储目录等。\nacts-config 配置文件是 SOFAActs 的核心配置，提供了测试环境切换、数据库连接切换、冒烟测试以及预跑反填等配置，来开关 SOFAActs 的相关功能；model 目录用于存放对象模型、数据模型，以便对模型进行统一管理；DB 配置文件指明了数据库连接信息，用于生成数据模型时自动填充表结构和模版数据。\n一键生成测试脚本\n在完成配置初始化操作后，我们可以开始第一个用例的编写，SOFAActs 提供了一键测试脚本生成功能。以待测的 getMessage 接口为例，在其方法定义上右键选择 SOFAActs 功能，生成测试用例，在弹出框中检查用例信息，修正无误后点击确定可以生成该接口的 …","date":1556089200,"description":"本文根据 SOFAChannel#5 直播分享整理，主题：给研发工程师的代码质量利器 —— 自动化测试框架 SOFAActs。","dir":"blog/sofa-channel-5-retrospect/","fuzzywordcount":5500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"1f088b226caf9430dc6aafb3f248316d","permalink":"/blog/sofa-channel-5-retrospect/","publishdate":"2019-04-24T15:00:00+08:00","readingtime":11,"relpermalink":"/blog/sofa-channel-5-retrospect/","summary":"SOFA:Channel/，有趣实用的分布式架构频道。 本文根据 SOFAChannel#5 直播分享整理，主题：给研发工程师的代码质量利器 —— 自动化测试框架 SOFAAc","tags":["SOFAActs","SOFAChannel"],"title":"给研发工程师的代码质量利器 | SOFAChannel#5 直播整理","type":"blog","url":"/blog/sofa-channel-5-retrospect/","wordcount":5492},{"author":"SOFAStack","categories":"SOFAStack","content":"Hey, SOFAer！有些话想对你说：\n“开源”二字代表的不仅仅是一个项目，更是代表了整个技术社区，代表了隐藏在背后的工程师们。\n很幸运，这一年遇到你们。\n生于蚂蚁金服，经历 12 年的业务锤炼，这是金融级分布式架构 SOFAStack。SOFAStack 的发展受益于开源社区的优秀产品，我们也决定结合我们的实践积累，把这些技术反馈给开源社区。\n于是，2018 年 4 月，SOFAStack 宣布开源，项目地址：https://github.com/alipay 。\n这一年，SOFAStack 逐步开源 SOFABoot、SOFARPC、SOFALookout、SOFATracer、SOFABolt、SOFAMosn、SOFAMesh、SOFAJRaft、SOFAActs、SOFARegistry 等组件。2019 年 3 月，蚂蚁金服加入分布式事务 Seata 的社区共建中，并贡献其 TCC 模式。\n这一年，我们获得了 14,000+ Star，超过 100 位贡献者参与，并有超过 30 家企业用户将 SOFAStack 应用在了生产环境上。\n这一年，SOFAStack 团队从电脑屏幕前，走到了开源社区里，与大家讨论并吸纳社区的建议。\n这一年，尝试了很多的“第一次”：第一次与大家编写 SOFALab 源码解析系列文章，第一次做 SOFAChannel 技术直播，第一次组织 SOFAMeetup，第一次在开源技术大会演讲。\n嘿，或许你见过我们紧张的样子。\n这一年，我们得到了太多来自社区的帮助，因为你们，SOFAStack 团队能一直享受“Make something people want”的乐趣。\n这一年，感谢有你。Hey, SOFAer~有些话想对你说：\n戳这里\n","date":1555333200,"description":"这一年，感谢有你。","dir":"blog/sofastack-anniversary-1/","fuzzywordcount":700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"82d2afd98352ab185691773fcd616233","permalink":"/blog/sofastack-anniversary-1/","publishdate":"2019-04-15T21:00:00+08:00","readingtime":2,"relpermalink":"/blog/sofastack-anniversary-1/","summary":"Hey, SOFAer！有些话想对你说： “开源”二字代表的不仅仅是一个项目，更是代表了整个技术社区，代表了隐藏在背后的工程师们。 很幸运，这一年遇到你","tags":["SOFAStack"],"title":"Hey, SOFAer！有些话想对你说：","type":"blog","url":"/blog/sofastack-anniversary-1/","wordcount":639},{"author":"李钊","categories":"Seata","content":"本文作者李钊，公众号「咖啡拿铁」作者，分布式事务 Seata 社区 Contributor。\n1.关于 Seata 在前不久，我写了一篇关于分布式事务中间件 Fescar 的解析，没过几天 Fescar 团队对其进行了品牌升级，取名为 Seata(Simpe Extensible Autonomous Transcaction Architecture)，而以前的 Fescar 的英文全称为 Fast \u0026amp;amp; EaSy Commit And Rollback。可以看见 Fescar 从名字上来看更加局限于 Commit 和 Rollback，而新的品牌名字 Seata 旨在打造一套一站式分布式事务解决方案。更换名字之后，我对其未来的发展更有信心。\n这里先大概回忆一下 Seata 的整个过程模型：\n TM：事务的发起者。用来告诉 TC，全局事务的开始，提交，回滚。 RM：具体的事务资源，每一个 RM 都会作为一个分支事务注册在 TC。 TC 事务的协调者。也可以看做是 Fescar-server，用于接收我们的事务的注册，提交和回滚。  在之前的文章中对整个角色有个大体的介绍，在这篇文章中我将重点介绍其中的核心角色 TC，也就是事务协调器。\n2.Transaction Coordinator 为什么之前一直强调 TC 是核心呢？那因为 TC 这个角色就好像上帝一样，管控着芸芸众生的 RM 和 TM。如果 TC 一旦不好使，那么 RM 和 TM 一旦出现小问题，那必定会乱的一塌糊涂。所以要想了解 Seata，那么必须要了解他的 TC。\n那么一个优秀的事务协调者应该具备哪些能力呢？我觉得应该有以下几个：\n 正确的协调：能正确的协调 RM 和 TM 接下来应该做什么，做错了应该怎么办，做对了应该怎么办。 高可用：事务协调器在分布式事务中很重要，如果不能保证高可用，那么他也没有存在的必要了。 高性能：事务协调器的性能一定要高，如果事务协调器性能有瓶颈，那么他所管理的 RM 和 TM 会经常遇到超时，从而引起回滚频繁。 高扩展性：这个特点是属于代码层面的，如果是一个优秀的框架，那么需要给使用方很多自定义扩展，比如服务注册/发现，读取配置等等。  下面我也将逐步阐述 Seata 是如何做到上面四点。\n2.1 Seata-Server 的设计 Seata-Server 整体的模块图如上所示：\n Coordinator Core：最下面的模块是事务协调器核心代码，主要用来处理事务协调的逻辑，如是否 Commit、Rollback 等协调活动。 Store：存储模块，用来将我们的数据持久化，防止重启或者宕机数据丢失。 Discover：服务注册/发现模块，用于将 Server 地址暴露给 Client。 Config：用来存储和查找服务端的配置。 Lock：锁模块，用于给 Seata 提供全局锁的功能。 Rpc：用于和其他端通信。 HA-Cluster：高可用集群，目前还没开源。为 Seata 提供可靠的高可用功能。  2.2 Discover 首先来讲讲比较基础的 Discover 模块，又称服务注册/发现模块。我们将 Seata-Server 启动之后，需要将自己的地址暴露给其他使用者，那么就需要这个模块帮忙。\n这个模块有个核心接口 RegistryService，如上图所示：\n register：服务端使用，进行服务注册。 unregister：服务端使用，一般在 JVM 关闭钩子，ShutdownHook 中调用。 subscribe：客户端使用，注册监听事件，用来监听地址的变化。 unsubscribe：客户端使用，取消注册监听事件。 lookup：客户端使用，根据 Key 查找服务地址列表。 close：都可以使用，用于关闭 Register 资源。  如果需要添加自己定义的服务注册/发现，那么实现这个接口即可。截止目前在社区的不断开发推动下，已经有四种服务注册/发现，分别是 redis、zk、nacos、eruka。下面简单介绍下 Nacos 的实现：\n2.2.1 register 接口 step1：校验地址是否合法；\nstep2：获取 Nacos 的 Name 实例，然后将地址注册到当前 Cluster 名称上面。\nunregister 接口类似，这里不做详解。\n2.2.2 lookup 接口 step1：获取当前 clusterName 名字；\nstep2：判断当前 Cluster 是否已经获取过了，如果获取过就从 Map 中取；\nstep3：从 Nacos 拿到地址数据，将其转换成我们所需要的；\nstep4：将我们事件变动的 Listener 注册到 Nacos。\n2.2.3 subscribe 接口 这个接口比较简单，具体分两步：\nstep1：将 Clstuer 和 Listener 添加进 Map 中；\nstep2：向 Nacos 注册。\n2.3 Config 配置模块也是一个比较基础，比较简单的模块。我们需要配置一些常用的参数比如：Netty 的 Select 线程数量，Work 线程数量，Session 允许最大为多少等等，当然这些参数在 Seata 中都有自己的默认设置。\n同样的在 Seata 中也提供了一个接口 Configuration，用来自定义我们需要的获取配置的地方：\n getInt/Long/Boolean/Config()：通过 DataId 来获取对应的值。 putConfig：用于添加配置。 removeConfig：删除一个配置。 add/remove/get ConfigListener：添加/删除/获取 配置监听器，一般用来监听配置的变更。  目前为止有四种方式获取 Config：File（文件获取）、Nacos、Apollo、ZK。在 Seata 中首先需要配置 registry.conf，来配置 conf 的类型。实现 conf 比较简单这里就不深入分析。\n2.4 Store 存储层的实现对于 Seata 是否高性能，是否可靠非常关键。\n如果存储层没有实现好，那么如果发生宕机，在 TC 中正在进行分布式事务处理的数据将会被丢失。既然使用了分布式事务，那么其肯定不能容忍丢失。如果存储层实现好了，但是其性能有很大问题，RM 可能会发生频繁回滚那么其完全无法应对高并发的场景。\n在 Seata 中默认提供了文件方式的存储，下面定义存储的数据为 Session，而 TM 创造的全局事务数据叫 GloabSession，RM 创造的分支事务叫 BranchSession，一个 GloabSession 可以拥有多个 BranchSession。我们的目的就是要将这么多 Session 存储下来。\n在 FileTransactionStoreManager#writeSession 代码中：\n上面的代码主要分为下面几步：\nstep1：生成一个 TransactionWriteFuture。\nstep2：将这个 futureRequest 丢进一个 LinkedBlockingQueue 中。为什么需要将所有数据都丢进队列中呢？当然这里其实也可以用锁来实现，在另 …","date":1554793200,"description":"在这篇文章，将重点介绍 Seata 其中的核心角色 TC，也就是事务协调器。","dir":"blog/seata-server-deep-analysis/","fuzzywordcount":6900,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"3354370f3ca29297c819c279994e0a0d","permalink":"/blog/seata-server-deep-analysis/","publishdate":"2019-04-09T15:00:00+08:00","readingtime":14,"relpermalink":"/blog/seata-server-deep-analysis/","summary":"本文作者李钊，公众号「咖啡拿铁」作者，分布式事务 Seata 社区 Contributor。 1.关于 Seata 在前不久，我写了一篇关于分布式事务中间件 Fescar 的解析，没","tags":["Seata"],"title":"深度剖析一站式分布式事务方案 Seata-Server","type":"blog","url":"/blog/seata-server-deep-analysis/","wordcount":6804},{"author":"潘潘","categories":"SOFAChannel","content":"概要  活动主题：SOFAChannel#4：分布式事务 Seata TCC 模式深度解析 活动时间：4 月 18 日周四晚 7 点 活动形式：线上直播 直播视频回顾 直播回顾文章  介绍 | SOFAChannel \u0026amp;lt;SOFA:Channel/\u0026amp;gt; 有趣实用的分布式架构频道：前沿技术、直播 Coding、观点“抬杠”，多种形式。\n\u0026amp;lt;SOFA:Channel/\u0026amp;gt; 将作为 SOFA 所有在线内容的承载，包含直播/音视频教程，集中体现 SOFAStack 的能力全景图。\n| SOFAChannel#4：分布式事务 Seata TCC 模式深度解析 4月初，分布式事务 Fescar 宣布进行品牌升级为 Seata，Seata 意为：Simple Extensible Autonomous Transaction Architecture，是一套一站式分布式事务解决方案。蚂蚁金服在 Seata 0.4.0 版本加入了 TCC 模式，后续也会持续输入。\n本期为 SOFAChannel 线上直播第 4 期，将邀请 蚂蚁金服 技术专家 \u0026amp;amp; Seata Committer 觉生 和大家一起探讨 《分布式事务 Seata TCC 模式深度解析》。\n本期分享大纲：\n TCC 模式基本原理解析 分布式事务并发控制解析 分布式事务空回滚与幂等解析 分布式事务防悬挂解析 分布式事务异步化解析  | 加入 SOFA 钉钉互动群 欢迎加入直播互动钉钉群：23195297（搜索群号加入即可）\n| 点击即可报名 https://tech.antfin.com/community/live/462\n议程 19:00-19:05 主持人开场 SOFAGirl 主持人\n19:05-20:00 分布式事务 Seata TCC 模式深度解析 觉生 蚂蚁金服 技术专家 / Seata Committer\n本期分享大纲：  TCC 模式基本原理解析 分布式事务并发控制解析 分布式事务空回滚与幂等解析 分布式事务防悬挂解析 分布式事务异步化解析  嘉宾  SOFAGirl 主持人 觉生 蚂蚁金服 技术专家 / Seata Committer  ","date":1554783000,"description":"4 月 18 日周四晚 7 点，线上直播第 4 期。","dir":"activities/sofa-channel-4/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"0e0d4d4a75723cc408567a65aab0c3df","permalink":"/activities/sofa-channel-4/","publishdate":"2019-04-09T12:10:00+08:00","readingtime":2,"relpermalink":"/activities/sofa-channel-4/","summary":"概要 活动主题：SOFAChannel#4：分布式事务 Seata TCC 模式深度解析 活动时间：4 月 18 日周四晚 7 点 活动形式：线上直播 直播视频回顾 直播回顾文章 介","tags":["SOFAChannel","Seata"],"title":"SOFAChannel#4：分布式事务 Seata TCC 模式深度解析","type":"activities","url":"/activities/sofa-channel-4/","wordcount":551},{"author":"绍辉","categories":"Seata","content":"上周，分布式事务 Fescar 宣布进行品牌升级：\nThanks, Fescar ❤️，\nHello, Seata 🚀。\nSeata 意为：Simple Extensible Autonomous Transaction Architecture，是一套一站式分布式事务解决方案。\n项目地址：https://github.com/seata/seata\n蚂蚁金服在 Seata 0.4.0 版本加入了 TCC 模式，后续也会持续输入。\n为了帮助大家理解，分布式事务开源负责人绍辉进行了一次线下分享，详细讲述了分布式事务在蚂蚁金服的发展，希望可以帮助大家理解分布式事务，以下为分享的文字整理版本。\n前言 今天的分享将从以下三个部分展开：分布式事务问题产生的背景、蚂蚁金服分布式事务以及分布式事务 Seata 的 Roadmap。\n分享嘉宾：绍辉 蚂蚁金服 分布式事务开源负责人\n1、分布式事务问题产生的背景 1.1、数据库的水平拆分 蚂蚁金服早期，业务量比较小，单库单表便能满足业务需求；但是随着业务的发展，单库单表数据库逐渐成为瓶颈。为了解决数据库的瓶颈问题，我们对数据库进行了水平拆分。拆分所带来的一个问题就是以前一个数据库上便能完成的写操作现在要跨多个数据库，由此带来了跨库事务问题。\n1.2、业务的服务化拆分 蚂蚁金服早期是单系统架构，所有业务服务几乎都在少数几个 APP 中。随着业务的发展，业务越来越复杂，服务之间的耦合度也越来越高，故我们对系统进行了重构，服务按照功能进行解耦和垂直拆分。拆分之后所带来的问题就是一个业务活动原来只需要调用一个服务就能完成，现在需要调用多个服务才能完成，由此产生了跨服务事务问题。\n1.3、转账案例说明数据一致性问题 数据库的水分拆分以及服务的垂直拆分，所带来的问题是一个业务活动通常要调用多个服务、访问多个数据库才能完成。\n以金融业务场景下的转账场景为例，转账服务要完成以下操作：\n 调用交易系统服务创建交易订单； 调用支付系统记录支付明细； 调用账务系统执行 A 扣钱； 调用账务系统执行 B 加钱。  以上 4 个操作要跨 3 个系统，访问 4 个数据库。而网络、数据库、机器等都具有不可靠性，我们很难保证以上 4 个操作能 100% 全部成功。\n在金融属性的业务中，不允许 A 账户的钱扣了，而 B 账户的钱没有加上的现象出现，所以我们必须想办法保证 1 ~ 4 这四个操作要么全部成功，要么全部失败；所以蚂蚁金服自主研发了分布式事务中间件，解决跨服务、跨数据库的数据一致性问题。\n2、蚂蚁金服分布式事务 2.1、分布式事务理论基础 在介绍蚂蚁金服的分布式事务中间件之前，先介绍一些分布式事务的理论背景。\n 2PC  两阶段提交协议（Two Phase Commitment Protocol）是分布式事务最基本的协议。在两阶段提交协议中，有一个事务管理器和多个资源管理器，事务管理器分两阶段协调资源管理器。在第一阶段，事务管理器询问所有资源管理器准备是否成功。如果所有资源均准备成功，那么在第二阶段事务管理器会要求所有资源管理器执行提交操作；如果任一资源管理器在第一阶段返回准备失败，那么事务管理器会要求所有资源管理器在第二阶段执行回滚操作。通过事务管理器的两阶段协调，最终所有资源管理器要么全部提交，要么全部回滚，最终状态都是一致的。\n TCC  资源管理器有很多实现方式，其中 TCC（Try-Confirm-Cancel）是资源管理器的一种服务化的实现。TCC 是一种比较成熟的分布式事务解决方案，可用于解决跨数据库、跨服务业务操作的数据一致性问题。TCC 其 Try、Confirm、Cancel 3 个方法均由业务编码实现，故 TCC 可以被称为是服务化的资源管理器。\nTCC 的 Try 操作作为一阶段，负责资源的检查和预留；Confirm 操作作为二阶段提交操作，执行真正的业务；Cancel 是二阶段回滚操作，执行预留资源的取消，使资源回到初始状态。\n如下图所示，用户实现 TCC 服务之后，该 TCC 服务将作为分布式事务的其中一个资源，参与到整个分布式事务中。事务管理器分两个阶段协调 TCC 服务，在第一阶段调用所有 TCC 服务的 Try 方法，在第二阶段执行所有 TCC 服务的 Confirm 或者 Cancel 方法，最终所有 TCC 服务要么全部都是提交的、要么全部都是回滚的。\n2.2、蚂蚁金服分布式产品介绍 蚂蚁金服从 2007 年开始做分布式事务，至今已经有 12 年历史。蚂蚁金服的分布式事务最初是采用 TCC 实现的，TCC 模式帮蚂蚁业务解决了各类金融核心场景下的数据一致性问题。\n2007 年我们开始支持双十一，为了满足双十一的高性能需求，我们对分布式事务做了一系列的性能优化。\n2013年，蚂蚁金服开始做单元化改造，分布式事务也开始支持 LDC、异地多活和高可用容灾，解决了机房故障情况下服务快速恢复的问题。\n2014年，蚂蚁金服分布式事务中间件开始通过蚂蚁金融云对外输出，我们发展了一大批的外部用户；在发展外部客户的过程中，外部客户表示愿意牺牲一部分性能（无蚂蚁的业务规模）以换取接入便利性和无侵入性。\n所以在 2015年，我们开始做无侵入的事务解决方案：FMT 模式和 XA 模式。\n蚂蚁金服分布式事务中间件经过长期演进，目前积累了 TCC、FMT 和 XA 三种模式，具有丰富的应用场景。下面分别介绍这三种模式。\n2.3、TCC 模式 蚂蚁金服的 TCC 模式和前面介绍 TCC 理论中提的 TCC 原理是一致的。不同的是，我们在整个分布式事务执行过程中，会去记录事务日志，一个分布式事务会产生一条主事务记录（对应发起方）和若干分支事务记录（对应 TCC 参与者）。记录事务日志的目的是，当分布式事务执行过程中出现异常中断时，事务恢复服务通过轮询事务日志，找出这个异常中断的事务，补偿执行该异常事务剩余未完成的动作，整个分布式事务的最终状态要么全部提交，要么全部回滚。\nTCC 设计规范和注意事项：\n用户在接入 TCC 时，大部分工作都集中在如何实现 TCC 服务上。经过蚂蚁金服多年的 TCC 应用实践，总结如下在 TCC 设计和实现过程中的注意事项：\n1、业务操作分两阶段完成： 接入 TCC 前，业务操作只需要一步就能完成。但是在接入 TCC 之后，需要考虑如何将其分成两个阶段完成：把资源的检查和预留放在一阶段的 Try 操作中进行，把真正的业务操作的执行放在二阶段的 Confirm 操作中进行。\n以下举例说明业务模式如何分成两阶段进行设计，举例场景：“账户 A 的余额中有 100 元，需要扣除其中 30 元”。\n在接入 TCC 之前，用户编写 SQL：“update 账户表 set 余额 = 余额 -20 where 账户 = A”，便能一步完成扣款操作。\n在接入 TCC 之后，就需要考虑如何将扣款操作分成两步完成：\n Try 操作：资源的检查和预留。  在扣款场景，Try 操作要做的事情就是先检查 A 账户余额是否足够，再冻结要扣款的 30 元（预留资源）；此阶段不会发生真正的扣款。\n Confirm 操作：执行真正业务的提交。  在扣款场景下，Confirm 阶段做 …","date":1554706800,"description":"本文根据 SOFAMeetup#1 分享整理，详细讲述了分布式事务在蚂蚁金服的发展。","dir":"blog/sofa-meetup-1-seata/","fuzzywordcount":5000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"fd2c8c1c6ee4231c6987a1d556ce4089","permalink":"/blog/sofa-meetup-1-seata/","publishdate":"2019-04-08T15:00:00+08:00","readingtime":10,"relpermalink":"/blog/sofa-meetup-1-seata/","summary":"上周，分布式事务 Fescar 宣布进行品牌升级： Thanks, Fescar ❤️， Hello, Seata 🚀。 Seata 意为：Simple Extensible Autonomous Transaction Architecture，是一套一站式分布式事务解决方案。 项","tags":["Seata","SOFAMeetup"],"title":"蚂蚁金服分布式事务开源以及实践 | SOFA 开源一周年献礼","type":"blog","url":"/blog/sofa-meetup-1-seata/","wordcount":4909},{"author":"力鲲","categories":"SOFAJRaft","content":" SOFAStack Scalable Open Financial Architecture Stack 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文根据 SOFA Meetup#1 北京站 现场分享整理，完整的分享视频回顾获取方式见文章底部。\n 前言 SOFAJRaft 是一个基于 Raft 一致性算法的生产级高性能 Java 实现，支持 MULTI-RAFT-GROUP，适用于高负载低延迟的场景。SOFAJRaft 是从百度的 braft 移植而来，做了一些优化和改进，感谢百度 braft 团队开源了如此优秀的 C++ Raft 实现。\nGitHub 地址：https://github.com/alipay/sofa-jraft\n之前，我们有一篇介绍 SOFAJRaft 的文章，可在文末获得链接，延续这个内容，今天的演讲分为三部分，先简要介绍 Raft 算法，然后介绍 SOFAJRaft 的设计，最后说说它的优化。\n分享嘉宾：力鲲 蚂蚁金服 SOFAJRaft 核心成员\nRaft 共识算法 Raft 是一种共识算法，其特点是让多个参与者针对某一件事达成完全一致：一件事，一个结论。同时对已达成一致的结论，是不可推翻的。可以举一个银行账户的例子来解释共识算法：假如由一批服务器组成一个集群来维护银行账户系统，如果有一个 Client 向集群发出“存 100 元”的指令，那么当集群返回成功应答之后，Client 再向集群发起查询时，一定能够查到被存储成功的这 100 元钱，就算有机器出现不可用情况，这 100 元的账也不可篡改。这就是共识算法要达到的效果。\nRaft 算法和其他的共识算法相比，又有了如下几个不同的特性：\n Strong leader：Raft 集群中最多只能有一个 Leader，日志只能从 Leader 复制到 Follower 上； Leader election：Raft 算法采用随机选举超时时间触发选举来避免选票被瓜分的情况，保证选举的顺利完成； Membership changes：通过两阶段的方式应对集群内成员的加入或者退出情况，在此期间并不影响集群对外的服务。  共识算法有一个很典型的应用场景就是复制状态机。Client 向复制状态机发送一系列能够在状态机上执行的命令，共识算法负责将这些命令以 Log 的形式复制给其他的状态机，这样不同的状态机只要按照完全一样的顺序来执行这些命令，就能得到一样的输出结果。所以这就需要利用共识算法保证被复制日志的内容和顺序一致。\nLeader 选举 复制状态机集群在利用 Raft 算法保证一致性时，要做的第一件事情就是 Leader 选举。在讲 Leader 选举之前我们先要说一个重要的概念：Term。Term 用来将一个连续的时间轴在逻辑上切割成一个个区间，它的含义类似于“美国第 26 届总统”这个表述中的“26”。\n每一个 Term 期间集群要做的第一件事情就是选举 Leader。起初所有的 Server 都是 Follower 角色，如果 Follower 经过一段时间( election timeout )的等待却依然没有收到其他 Server 发来的消息时，Follower 就可以认为集群中没有可用的 Leader，遂开始准备发起选举。在发起选举的时候 Server 会从 Follower 角色转变成 Candidate，然后开始尝试竞选 Term + 1 届的 Leader，此时他会向其他的 Server 发送投票请求，当收到集群内多数机器同意其当选的应答之后，Candidate 成功当选 Leader。但是如下两种情况会让 Candidate 退回 (step down) 到 Follower，放弃竞选本届 Leader：\n 如果在 Candidate 等待 Servers 的投票结果期间收到了其他拥有更高 Term 的 Server 发来的投票请求； 如果在 Candidate 等待 Servers 的投票结果期间收到了其他拥有更高 Term 的 Server 发来的心跳；  当然了，当一个 Leader 发现有 Term 更高的 Leader 时也会退回到 Follower 状态。\n当选举 Leader 成功之后，整个集群就可以向外提供正常读写服务了，如图所示，集群由一个 Leader 两个 Follower 组成，Leader 负责处理 Client 发起的读写请求，同时还要跟 Follower 保持心跳或者把 Log 复制给 Follower。\nLog 复制 下面我们就详细说一下 Log 复制。我们之前已经说了 Log 就是 Client 发送给复制状态机的一系列命令。这里我们再举例解释一下 Log，比如我们的复制状态机要实现的是一个银行账户系统，那么这个 Log 就可以是 Client 发给账户系统的一条存钱的命令，比如“存 100 元钱”。\nLeader 与 Follower 之间的日志复制是共识算法运用于复制状态机的重要目的，在 Raft 算法中 Log 由 TermId、LogIndex、LogValue 这三要素构成，在这张图上每一个小格代表一个 Log。当 Leader 在向 Follower 复制 Log 的时候，Follower 还需要对收到的 Log 做检查，以确保这些 Log 能和本地已有的 Log 保持连续。我们之前说了，Raft 算法是要严格保证 Log 的连续性的，所以 Follower 会拒绝无法和本地已有 Log 保持连续的复制请求，那么这种情况下就需要走 Log 恢复的流程。总之，Log 复制的目的就是要让所有的 Server 上的 Log 无论在内容上还是在顺序上都要保持完全一致，这样才能保证所有状态机执行结果一致。\n目前已经有一些很优秀的对 Raft 的实现，比如 C++ 写的 braft，Go 写的 etcd，Rust 写的 TiKV。当然了，SOFAJRaft 并不是 Raft 算法的第一个 Java 实现，在我们之前已经有了很多项目。但是经过我们的评估，觉得目前还是没有一个 Raft 的 Java 实现库类能够满足蚂蚁生产环境的要求，这也是我们去写 SOFAJRaft 的主要原因。\nSOFAJRaft 介绍 接下来我们介绍 SOFAJRaft。\nSOFAJRaft 是基于 Raft 算法的生产级高性能 Java 实现，支持 MULTI-RAFT-GROUP。从去年 3 月开发到今年 2 月完成，并在今年 3 月开源。应用场景有 Leader 选举、分布式锁服务、高可靠的元信息管理、分布式存储系统，目前使用案例有 RheaKV，这是 SOFAJRaft 中自带的一个分布式 KV 存储，还有今天开源的 SOFA 服务注册中心中的元信息管理模块也是用到了 SOFAJRaft，除此之外还有一些内部的项目也有使用，但是因为没有开源，所以就不再详述了。\n这张图就是 SOFAJRaft 的设计图，Node 代表了一个 SOFAJRaft Server 节点，这些方框代表他内部的各个模块，我们依然用之前的银行 …","date":1554188400,"description":"本文根据 SOFA Meetup#1 北京站 现场分享整理，完整的分享视频回顾获取方式见文章底部。","dir":"blog/sofa-meetup-1-jraft/","fuzzywordcount":5600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"614c6031770d98ed7d0c23c3276d72ef","permalink":"/blog/sofa-meetup-1-jraft/","publishdate":"2019-04-02T15:00:00+08:00","readingtime":11,"relpermalink":"/blog/sofa-meetup-1-jraft/","summary":"SOFAStack Scalable Open Financial Architecture Stack 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文根据 SOFA Meetup#1 北","tags":["SOFAJRaft","SOFAMeetup"],"title":"详解蚂蚁金服 SOFAJRaft | 生产级高性能 Java 实现","type":"blog","url":"/blog/sofa-meetup-1-jraft/","wordcount":5507},{"author":"张磊、心贵、临石、徙远、衷源、浔鸣","categories":"Kubernetes","content":"本文由张磊、心贵、临石、徙远、衷源、浔鸣等同学联合撰写。\nKubernetes 1.14.0 Release 已经于 3 月 25 日正式发布。相信你也已经注意到，相比于1.13 和 1.12 版本，这次发布包含的重要变非常多，其对应的 Release Note 的篇幅长度也创下了“新高”。\n面对这样一份“海量信息”的 Release Note，我们该如何从这份文档里进行高效的信息过滤和挖掘，帮助团队更精准、快速的梳理出这次发布最主要的技术脉络呢？\n在本篇文章中，我们将 1.14 的 Release Note 按照主题进行了重新归纳和梳理，按照类别对重要变更进行了技术剖析和讨论。希望这种“分类解读”的方式，能够帮助大家更好的理解 1.14 这个发布的核心内容。\nWindows Node 正式生产可用 随着1.14的发布，Kubernetes 对windows节点的生产级支持无疑是一个重要的里程碑。具体来说，1.14 版本针对 Windows 做了大量增强；\n Pod：Pod内支持 readiness 和 liveness 探针；支持进程隔离和 volume 共享的多容器 Pod；Pod 支持原生configmap 和 sercret；Pod 支持emptyDir；支持对 Pod 进行资源配额等；但是像优雅删除、Termination message、Privileged Containers、HugePages、Pod 驱逐策略等部分特性还未在 1.14 版本提供； Service：支持服务环境变量提供 DNS 解析；支持 NodePort、ClusterIP、LoadBalancer、Headless service；暂不支持 Pod 的 hostnetwork 模式； 常规 Workload controller：RS、deployment、statefulset、daemonset、job、cronjob 均支持 windows 容器； 除此之外，支持 Pod 和 container 维度的metrics、HPA、“kubectl exec”、调度抢占、resource quotas、CNI 网络支持等多种特性让 windows workload 更加云原生；由于 windows 的特殊兼容性，目前 host OS 的版本必须和容器镜像 OS 版本一致，1.14 版本支持 win server 2019；未来版本中会考虑使用 Hyper-V 隔离机制来解决版本兼容性问题。  而伴随着 Windows 容器的生态正在慢慢壮大，能够在生产级别支持 Windows 节点的容器服务开始见诸各大云厂商。阿里云容器服务（ACK）近期已经推出了 Windows Container 的支持，提供了 linux/windows 应用混合部署的统一管理能力。\n参见：Support for Windows Nodes is Graduating to Stable (#116 )\n本地持久化数据卷（Local PV） 正式可用 长期以来，能够让 Kubernetes 直接用宿主机的本地存储设备（比如：本地 SSD 硬盘）来提供持久化数据卷（即：Local PV 功能），一直是社区里非常强烈的一个诉求。这个原因很容易理解：相对于远程存储（网络存储），Local PV 在时延性、易用性、稳定性和费用上具有独特的优势，尤其是对于相关特性比较敏感的应用，如数据库应用和搜索引擎应用来说，有着重要的意义。\n而在 1.14 中，Local PV 终于正式宣布 GA，为云上的持久化存储选择增加了一种重要的的可能。\n不过，必须要明确的是， 选择使用 Local PV，也意味着用户必须自己承担一些潜在的风险，这包括：\n 目前社区的开源方案无法动态创建卷 调度器需要由额外的调度逻辑工作，以确保调度的节点可以分配出足够的磁盘容量 容错性差，如果 Pod 正在运行的宿主机宕机或者磁盘发生异常，那么它的持久化卷里的信息可能丢失  第一个问题，可以通过比如阿里云的 local-volume-provisioner 实现本地 SSD Nvme 实例自动创建数据卷来解决，但对于容错性和健壮性的问题，就是比较棘手的了。\n参见：Durable Local Storage Management is Now GA (#121)\nPod 优先级与抢占机制稳定可用 Kubernetes 里的任务优先级（priority）和抢占机制（preemption）的目的十分明确：保证高优先级的任务可以在需要的时候通过抢占低优先级任务的方式得到运行。\n这其中，优先级定义了一个 Pod 在集群中的重要程度，这个重要程度体现且仅体现在两个地方：\n 高优先级的Pod 在调度阶段更容易被优先调度（K8s 采用队列调度模型），注意这里并不保证高优先级 Pod 永远被优先调度，实际影响调度顺序的因素有很多； 在集群整体负载较高时，如果出现高优先级 Pod 无法被调度的情况（集群中没有满足条件的 Node 供 Pod 运行），K8s 会启动抢占机制，通过抢占已经运行的低优先级的 Pod 的方式，让高优先级的 Pod 可以运行起来。抢占机制便是在这里引入的。  抢占机制指当调度器发现某个Pod（如 Pod-A）无法在集群中找到合适的节点部署时（所有节点 Predicates 全部失败），会试图通过删除一些优先级低于 Pod-A 的 Pod 来“腾出空间”部署 Pod-A，这样 Pod-A 就可以被调度了。这样一个“看似简单”的需求在分布式环境中实施起来有很多细节，例如：如何决定删除哪个节点的哪些 Pod、如何保证为 Pod-A 腾出的空间不被其它 Pod 占用、如何保证 Pod-A 不被饿死（Starvation）、如何处理有亲和性需求的 Pod 调度约束、是否需要支持跨节点 Preemption 以支持某些特定的约束（例如某 Failure Domain 的反亲和约束）等等。\n参见：Pod Priority and Preemption in Kubernetes (#564) 你一定要知道什么是 Pod Ready++ 在 1.14 版本之前，Kubernetes 判断一个 Pod 是否 Ready，就是检查这个 Pod 的容器是否全部正常运行。但是这里有个问题，那就是容器或者说里面的主进程 Ready，并不一定意味着这个应用副本就一定是就绪的。为了确认 Pod 确实可以正常可用，我们希望给它增加一些外部指标（比如，该 Pod 需要的 Service，DNS，存储等服务全部就绪），来反应这个Pod是否“真正”Ready。\n这个特性，就是1.14 里一个叫做“Pod Readiness Gates”、也叫做 Pod Ready ++ 的特性。它为pod的“Ready 状态” 提供了一个非常强大的扩展点。需要注意的是，用户需要编写一个外部控制器（Controller）来为这个Pod Readiness Gates 字段对应的指标设置值。\n参见：Pod Ready++ (#580) Kubernetes 原生应用管理能力 1.14之后，Kubernetes 项目本身开始具备了 …","date":1553756400,"description":"在本篇文章中，我们将 1.14 的 Release Note 按照主题进行了重新归纳和梳理，按照类别对重要变更进行了技术剖析和讨论。希望这种“分类解读”的方式，能够帮助大家更好的理解 1.14 这个发布的核心内容。","dir":"blog/k8s-1.14-release-note/","fuzzywordcount":4100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"8dddcb73179e656ccebedbba2d4e9131","permalink":"/blog/k8s-1.14-release-note/","publishdate":"2019-03-28T15:00:00+08:00","readingtime":9,"relpermalink":"/blog/k8s-1.14-release-note/","summary":"本文由张磊、心贵、临石、徙远、衷源、浔鸣等同学联合撰写。 Kubernetes 1.14.0 Release 已经于 3 月 25 日正式发布。相信你也已经注意到，相比于1.13 和 1.12 版本，这次发布包","tags":["Kubernetes"],"title":"Kubernetes 1.14 发布了，Release Note 该怎么读？","type":"blog","url":"/blog/k8s-1.14-release-note/","wordcount":4010},{"author":"Yu Shuqiang","categories":"SOFATracer","content":" SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。\nSOFATracer 是一个用于分布式系统调用跟踪的组件，通过统一的 TraceId 将调用链路中的各种网络调用情况以日志的方式记录下来，以达到透视化网络调用的目的，这些链路数据可用于故障的快速发现，服务治理等。\n本文为《剖析 | SOFATracer 框架》最后一篇，本篇作者yushuqiang，来自小象生鲜。《剖析 | SOFATracer 框架》系列由 SOFA 团队和源码爱好者们出品，项目代号：[SOFA:TracerLab/]，目前领取已经完成，感谢大家的参与。\nSOFATracer：https://github.com/sofastack/sofa-tracer\n 前言 自 Google《Dapper，大规模分布式系统的跟踪系统》论文发表以来，开源 Tracer 系统如雨后春笋般相继面市，各显神通，但都是用于分布式系统调用跟踪的组件，通过统一的 traceId 将调用链路中的各种网络调用情况记录下来，以达到透视化网络调用的目的。本文介绍的 SOFATracer 是以日志的形式来记录的，这些日志可用于故障的快速定位，服务治理等。目前来看 SOFATracer 团队已经为我们搭建了一个完整的 Tracer 框架内核，包括数据模型、编码器、跨进程透传 traceId、采样、日志落盘与上报等核心机制，并提供了扩展 API 及基于开源组件实现的部分插件，为我们基于该框架打造自己的 Tracer 平台提供了极大便利。\n作为一个开源实现，SOFATracer 也尽可能提供大而全的插件实现，但由于多数公司都有自己配套的技术体系，完全依赖官方提供的插件可能无法满足自身的需要，因此如何基于 SOFATracer 自身 API 的组件埋点机制进行扩展，实现自己的插件是必须掌握的一项本领。\n本文将根据 SOFATracer 自身 AP I的扩展点及已提供的插件源码来分析下 SOFATracer 插件的埋点机制。\nSOFATracer 的插件埋点机制 对一个应用的跟踪要关注的无非就是 客户端-\u0026amp;gt;web 层-\u0026amp;gt;rpc 服务-\u0026amp;gt;dao 后端存储、cache 缓存、消息队列 mq 等这些基础组件。SOFATracer 插件的作用实际上也就是对不同组件进行埋点，以便基于这些组件采集应用的链路数据。\n不同组件有不同的应用场景和扩展点，因此对插件的实现也要因地制宜，SOFATracer 埋点方式一般是通过 Filter、Interceptor 机制实现的。\n组件扩展入口之 Filter or Interceptor SOFATracer 目前已实现的插件中，像 SpringMVC 插件是基于 Filter 进行埋点的，httpclient、resttemplate 等是基于 Interceptor 机制进行埋点的。在实现插件时，要根据不同插件的特性和扩展点来选择具体的埋点方式。正所谓条条大路通罗马，不管怎么实现埋点，都是依赖 SOFATracer 自身 API 的扩展机制来实现。\nAPI 扩展点之 AbstractTracer API SOFATracer 中所有的插件均需要实现自己的 Tracer 实例，如 SpringMVC 的 SpringMvcTracer 、HttpClient 的 HttpClientTracer 等。\n 基于 SOFATracer API 埋点方式插件扩展如下：  AbstractTracer 是 SOFATracer 用于插件扩展使用的一个抽象类，根据插件类型不同，又可以分为 clientTracer 和 serverTracer，分别对应于 AbstractClientTracer 和 AbstractServerTracer；再通过 AbstractClientTracer 和 AbstractServerTracer 衍生出具体的组件 Tracer 实现，比如上图中提到的 HttpClientTracer 、RestTemplateTracer 、SpringMvcTracer 等插件 Tracer 实现。\nAbstractTracer 这里先来看下 AbstractTracer 这个抽象类中具体提供了哪些抽象方法，也就是对于 AbstractClientTracer 和 AbstractServerTracer 需要分别扩展哪些能力。\n从上图 AbstractTracer 类提供的抽象方法来看，不管是 client 还是 server，在具体的 Tracer 插件实现中，都必须提供以下实现：\n DigestReporterLogName ：当前组件摘要日志的日志名称 DigestReporterRollingKey : 当前组件摘要日志的滚动策略 SpanEncoder：对摘要日志进行编码的编码器实现 AbstractSofaTracerStatisticReporter : 统计日志 reporter 类的实现类  基于 SOFATracer 自身 API 埋点最大的优势在于可以通过上面的这些参数来实现不同组件日志之间的隔离，上述需要实现的这些点是实现一个组件埋点常规的扩展点，是不可缺少的。\n上面分析了 SOFATracer API 的埋点机制，并且对于一些需要扩展的核心点进行了说明。SOFATracer 自身提供的内核非常简单，其基于自身 API 的埋点扩展机制为外部用户定制组件埋点提供了极大的便利。下面以 Thrift 扩展，具体分析如何实现一个组件埋点。\n PS : Thrift 是外部用户基于 SOFATracer API 扩展实现的，目前仅用于其公司内部使用，SOFATracer 官方组件中暂不支持，请知悉；后续会沟通作者提供 PR ，在此先表示感谢。\n Thrift 插件埋点分析 这里我们以 Thrift RPC 插件实现为例，分析如何实现一个埋点插件。\n1、实例工程的分包结构\n从上图插件的工程的包结构可以看出，整个插件实现比较简单，代码量不多，但从类的定义来看，直观的体现了SOFATracer 插件埋点机制所介绍的套路。下面将进行详细的分析与介绍。\n2、实现 Tracer 实例\nRpcThriftTracer 继承了 AbstractTracer 类，是对 clientTracer、serverTracer 的扩展。\n   AbstractTracer RpcThriftTracer     PS：如何确定一个组件是 client 端还是 server 端呢？就是看当前组件是请求的发起方还是请求的接受方，如果是请求发起方则一般是 client 端，如果是请求接收方则是 server 端。那么对于 RPC 来说，即是请求的发起方也是请求的接受方，因此这里实现了 AbstractTracer 类。\n 3、扩展点类实现\n   DigestReporterLogName RpcTracerLogEnum …","date":1553697000,"description":"本文为《剖析 | SOFATracer 框架》最后一篇，本篇作者 Yu Shuqiang，来自小象生鲜。","dir":"blog/sofa-tracer-event-tracing-deep-dive/","fuzzywordcount":4400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"35dc2221b95ec62fd2aa03fca6367554","permalink":"/blog/sofa-tracer-event-tracing-deep-dive/","publishdate":"2019-03-27T14:30:00Z","readingtime":9,"relpermalink":"/blog/sofa-tracer-event-tracing-deep-dive/","summary":"SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 SOFATracer 是一个用于分","tags":["SOFATracer","SOFALab","剖析 | SOFATracer 框架"],"title":"蚂蚁金服开源分布式链路跟踪组件 SOFATracer 埋点机制剖析","type":"blog","url":"/blog/sofa-tracer-event-tracing-deep-dive/","wordcount":4334},{"author":"尚彧","categories":"SOFARegistry","content":" SOFAStack\nScalable Open Financial Architecture Stack 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文根据 SOFA Meetup#1 北京站 现场分享整理，完整的分享 PPT 获取方式见文章底部。\n SOFAStack 开源一周年，继续补充开源大图 2018 年 4 月， 蚂蚁金服宣布开源 SOFAStack 金融级分布式架构。这一年的时间，感谢社区的信任和支持，目前已经累积超过一万的 Star 数目，超过 30 家企业用户。 2019 年 3 月 24 日，SOFA 在北京举办了首场 Meetup，我们有幸见到了关心SOFA 的朋友们。 此次，我们宣布开源蚂蚁金服注册中心 SOFARegistry 作为一周年的礼物之一，本文为根据现场分享整理的详细介绍。 SOFARegistry 是蚂蚁金服开源的具有承载海量服务注册和订阅能力的、高可用的服务注册中心，最早源自于淘宝的初版 ConfigServer，在支付宝/蚂蚁金服的业务发展驱动下，近十年间已经演进至第五代。\nGitHub 地址：https://github.com/sofastack/sofa-registry\n概念 注册中心在微服务架构中位置 服务发现，并非新鲜名词，在早期的 SOA 框架和现在主流的微服务框架中，每个服务实例都需要对外提供服务，同时也需要依赖外部服务。如何找到依赖的服务（即服务定位），最初我们思考了很多方式，比如直接在 Consumer 上配置所依赖的具体的服务地址列表，或者使用 LVS、F5 以及 DNS（域名指向所有后端服务的 IP）等负载均衡。\n但是以上方式都有明显的缺点，比如无法动态感知服务提供方节点变更的情况，另外基于负载均衡的话还需要考虑它的瓶颈问题。所以需要借助第三方的组件，即服务注册中心来提供服务注册和订阅服务，在服务提供方服务信息发生变化、或者节点上下线时，可以动态更新消费方的服务地址列表信息，最终解耦服务调用方和服务提供方。\n能力 服务注册中心的主要能力：\n 服务注册 服务订阅  演进 蚂蚁金服的服务注册中心，经历了 5 代技术架构演进，才最终形成了如今足以支撑蚂蚁海量服务注册订阅的，具有高可用、高扩展性和高时效性的架构。\n数据结构 SOFARegistry 的存储模型比较简单，主要基于 KV 存储两类数据，一类是订阅关系，体现为多个订阅方关心的 Topic（或服务键值）和他们的监听器列表，另一类是同一个 Topic（或服务键值）的发布者列表。基于观察者模式，在服务提供方发生变化时（比如服务提供方的节点上下线），会从订阅关系中寻找相应的订阅者，最终推送最新的服务列表给订阅者。\n存储扩展 主备模式  既然服务注册中心最主要能力之一是存储，那么就要思考：怎么存？存哪儿？存了会不会丢？ 怎么存，主要是由存什么数据来决定的，由于 SOFARegistry 所存储的数据结构比较简单( KV），因为并没有基于关系数据库；另外由于服务发现对变更推送的时效性要求高，但并没有很高的持久化要求(数据可以从服务提供方恢复)，所以最终我们决定自己实现存储能力。 SOFARegistry 的存储节点，最初是主备模式。  强一致集群 随着蚂蚁的服务数据量不断增长，我们将存储改为集群方式，每个存储节点的数据是一样的，每一次写入都保证所有节点写入成功后才算成功。这种模式的特点是每台服务器都存储了全量的服务数据，在当时数据规模比较小的情况下，尚可接受。\n这样的部署结构有两个问题：\n 首先，根据 CAP 原理，在分区容忍性（P）的前提下，为了保持强一致（C），必然牺牲高可用（A）为代价，比如 Zookeeper 是 CP 系统，它在内部选举期间是无法对外提供服务的，另外由于需要保证 C（顺序一致性），写的效率会有所牺牲。 其次，每个节点都存储全量的服务数据，随着业务的发展就有很大的瓶颈问题。  数据分片 如果要实现容量可无限扩展，需要把所有数据按照一定维度进行拆分，并存储到不同节点，当然还需要尽可能地保证数据存储的均匀分布。我们很自然地想到可以进行 Hash 取余，但简单的取余算法在节点数增减时会影响全局数据的分布，所以最终采用了一致性 Hash 算法（这个算法在业界很多场景已经被大量使用，具体不再进行介绍）。\n每个服务数据，经过一致性 Hash 算法计算后会存储到某个具体的 Data 上，整体形成环形的结构。理论上基于一致性 Hash 对数据进行分片，集群可以根据数据量进行无限地扩展。\n内部分层 连接承载 我们知道单机的 TCP 连接数是有限制的，业务应用不断的增多，为了避免单机连接数过多，我们需要将存储节点与业务应用数量成正比地扩容，而我们实际上希望存储节点的数量只跟数据量成正比。所以我们选择从存储节点上把承载连接职责的能力独立抽离出来成为新的一个角色，称之为 Session 节点，Session 节点负责承载来自业务应用的连接。这么一来，SOFARegistry 就由单个存储角色被分为了 Session 和 Data 两个角色，Session 承载连接，Data 承载数据，并且理论上 Session 和 Data 都支持无限扩展。\n如图，客户端直接和 Session 层建立连接，每个客户端只选择连接其中一个 Session 节点，所有原本直接到达 Data层的连接被收敛到 Session 层。Session 层只进行数据透传，不存储数据。客户端随机连接一台 Session 节点，当遇到 Session 不可用时重新选择新的 Session 节点进行重连即可。\n读写分离 分离出 Session 这一层负责承载连接，引起一个新的问题：数据到最终存储节点 Data 的路径变长了，整个集群结构也变的复杂了，怎么办呢？\n我们知道，服务注册中心的一个主要职责是将服务数据推送到客户端，推送需要依赖订阅关系，而这个订阅关系目前是存储到 Data 节点上。在 Data 上存储订阅关系，但是 Client 并没有直接和 Data 连接，那必须要在 Session 上保存映射后才确定推送目标，这样的映射关系占据了大量存储，并且还会随 Session 节点变化进行大量变更，会引起很多不一致问题。\n因此，我们后来决定，把订阅关系信息（Sub）直接存储在 Session 上，并且通过这个关系 Session 直接承担把数据变化推送给客户端的职责。而对于服务的发布信息（Pub）还是通过 Session 直接透传最终在 Data 存储节点上进行汇聚，即同一个服务 ID 的数据来自于不同的客户端和不同的 Session 最终在 Data 的一个节点存储。\n这样划分了 Sub 和 Pub 数据之后，通过订阅关系（Sub）进行推送的过程就有点类似于对服务数据读取的过程，服务发布进行存储的过程有点类似数据写的过程。数据读取的过程，如果有订阅关系就可以确定推送目标，迁移订阅关系数据到 Session，不会影响整个集群服务数据的状态，并且 Client 节点连接新的 Session 时，也会回放所有订阅关系，Session 就可以无状态的无 …","date":1553697000,"description":"此次，我们宣布开源蚂蚁金服注册中心 SOFARegistry 作为一周年的礼物之一，本文为根据现场分享整理的详细介绍。","dir":"blog/sofa-registry-deep-dive/","fuzzywordcount":4400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"86b3010d0f85f6711d60de29a244ed7e","permalink":"/blog/sofa-registry-deep-dive/","publishdate":"2019-03-27T14:30:00Z","readingtime":9,"relpermalink":"/blog/sofa-registry-deep-dive/","summary":"SOFAStack Scalable Open Financial Architecture Stack 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文根据 SOFA Meetup#1 北","tags":["SOFARegistry","SOFAMeetup"],"title":"蚂蚁金服开源服务注册中心 SOFARegistry | SOFA 开源一周年献礼","type":"blog","url":"/blog/sofa-registry-deep-dive/","wordcount":4313},{"author":"尚彧","categories":"SOFARegistry","content":" SOFAStack Scalable Open Financial Architecture Stack 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文根据 SOFA Meetup#1 北京站 现场分享整理，完整的分享 PPT 获取方式见文章底部。\n SOFAStack 开源一周年，继续补充开源大图 2018 年 4 月， 蚂蚁金服宣布开源 SOFAStack 金融级分布式架构。这一年的时间，感谢社区的信任和支持，目前已经累积超过一万的 Star 数目，超过 30 家企业用户。\n2019 年 3 月 24 日，SOFA 在北京举办了首场 Meetup，我们有幸见到了关心 SOFA 的朋友们。\n此次，我们宣布开源蚂蚁金服注册中心 SOFARegistry 作为一周年的礼物之一，本文为根据现场分享整理的详细介绍。\nSOFARegistry 是蚂蚁金服开源的具有承载海量服务注册和订阅能力的、高可用的服务注册中心，最早源自于淘宝的初版 ConfigServer，在支付宝/蚂蚁金服的业务发展驱动下，近十年间已经演进至第五代。\nGitHub 地址：https://github.com/alipay/sofa-registry 概念 注册中心在微服务架构中位置 服务发现，并非新鲜名词，在早期的 SOA 框架和现在主流的微服务框架中，每个服务实例都需要对外提供服务，同时也需要依赖外部服务。如何找到依赖的服务（即服务定位），最初我们思考了很多方式，比如直接在 Consumer 上配置所依赖的具体的服务地址列表，或者使用 LVS、F5 以及 DNS（域名指向所有后端服务的 IP）等负载均衡。\n但是以上方式都有明显的缺点，比如无法动态感知服务提供方节点变更的情况，另外基于负载均衡的话还需要考虑它的瓶颈问题。所以需要借助第三方的组件，即服务注册中心来提供服务注册和订阅服务，在服务提供方服务信息发生变化、或者节点上下线时，可以动态更新消费方的服务地址列表信息，最终解耦服务调用方和服务提供方。\n能力 服务注册中心的主要能力：\n 服务注册 服务订阅  演进 蚂蚁金服的服务注册中心，经历了 5 代技术架构演进，才最终形成了如今足以支撑蚂蚁海量服务注册订阅的，具有高可用、高扩展性和高时效性的架构。\n数据结构 SOFARegistry 的存储模型比较简单，主要基于 KV 存储两类数据，一类是订阅关系，体现为多个订阅方关心的 Topic（或服务键值）和他们的监听器列表，另一类是同一个 Topic（或服务键值）的发布者列表。基于观察者模式，在服务提供方发生变化时（比如服务提供方的节点上下线），会从订阅关系中寻找相应的订阅者，最终推送最新的服务列表给订阅者。\n存储扩展 主备模式  既然服务注册中心最主要能力之一是存储，那么就要思考：怎么存？存哪儿？存了会不会丢？ 怎么存，主要是由存什么数据来决定的，由于 SOFARegistry 所存储的数据结构比较简单( KV），因为并没有基于关系数据库；另外由于服务发现对变更推送的时效性要求高，但并没有很高的持久化要求(数据可以从服务提供方恢复)，所以最终我们决定自己实现存储能力。 SOFARegistry 的存储节点，最初是主备模式。  强一致集群 随着蚂蚁金服的服务数据量不断增长，我们将存储改为集群方式，每个存储节点的数据是一样的，每一次写入都保证所有节点写入成功后才算成功。这种模式的特点是每台服务器都存储了全量的服务数据，在当时数据规模比较小的情况下，尚可接受。\n这样的部署结构有两个问题：\n 首先，根据 CAP 原理，在分区容忍性（P）的前提下，为了保持强一致（C），必然牺牲高可用（A）为代价，比如 Zookeeper 是 CP 系统，它在内部选举期间是无法对外提供服务的，另外由于需要保证 C（顺序一致性），写的效率会有所牺牲。 其次，每个节点都存储全量的服务数据，随着业务的发展就有很大的瓶颈问题。  数据分片 如果要实现容量可无限扩展，需要把所有数据按照一定维度进行拆分，并存储到不同节点，当然还需要尽可能地保证数据存储的均匀分布。我们很自然地想到可以进行 Hash 取余，但简单的取余算法在节点数增减时会影响全局数据的分布，所以最终采用了一致性 Hash 算法（这个算法在业界很多场景已经被大量使用，具体不再进行介绍）。\n每个服务数据，经过一致性 Hash 算法计算后会存储到某个具体的 Data 上，整体形成环形的结构。理论上基于一致性 Hash 对数据进行分片，集群可以根据数据量进行无限地扩展。\n内部分层 连接承载 我们知道单机的 TCP 连接数是有限制的，业务应用不断的增多，为了避免单机连接数过多，我们需要将存储节点与业务应用数量成正比地扩容，而我们实际上希望存储节点的数量只跟数据量成正比。所以我们选择从存储节点上把承载连接职责的能力独立抽离出来成为新的一个角色，称之为 Session 节点，Session 节点负责承载来自业务应用的连接。这么一来，SOFARegistry 就由单个存储角色被分为了 Session 和 Data 两个角色，Session 承载连接，Data 承载数据，并且理论上 Session 和 Data 都支持无限扩展。\n如图，客户端直接和 Session 层建立连接，每个客户端只选择连接其中一个 Session 节点，所有原本直接到达 Data层的连接被收敛到 Session 层。Session 层只进行数据透传，不存储数据。客户端随机连接一台 Session 节点，当遇到 Session 不可用时重新选择新的 Session 节点进行重连即可。\n读写分离 分离出 Session 这一层负责承载连接，引起一个新的问题：数据到最终存储节点 Data 的路径变长了，整个集群结构也变的复杂了，怎么办呢？\n我们知道，服务注册中心的一个主要职责是将服务数据推送到客户端，推送需要依赖订阅关系，而这个订阅关系目前是存储到 Data 节点上。在 Data 上存储订阅关系，但是 Client 并没有直接和 Data 连接，那必须要在 Session 上保存映射后才确定推送目标，这样的映射关系占据了大量存储，并且还会随 Session 节点变化进行大量变更，会引起很多不一致问题。\n因此，我们后来决定，把订阅关系信息（Sub）直接存储在 Session 上，并且通过这个关系 Session 直接承担把数据变化推送给客户端的职责。而对于服务的发布信息（Pub）还是通过 Session 直接透传最终在 Data 存储节点上进行汇聚，即同一个服务 ID 的数据来自于不同的客户端和不同的 Session 最终在 Data 的一个节点存储。\n这样划分了 Sub 和 Pub 数据之后，通过订阅关系（Sub）进行推送的过程就有点类似于对服务数据读取的过程，服务发布进行存储的过程有点类似数据写的过程。数据读取的过程，如果有订阅关系就可以确定推送目标，迁移订阅关系数据到 Session，不会影响整个集群服务数据的状态，并且 Client 节点连接新的 Session 时，也会回放所有订阅关系，Session 就可以无状态的无 …","date":1553670000,"description":"本文根据 SOFA Meetup#1 北京站 现场分享整理，完整的分享 PPT 获取方式见文章底部。","dir":"blog/sofa-meetup-1-registry/","fuzzywordcount":4400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"0e3d1f0cf167e7afea39c2435ceefcfd","permalink":"/blog/sofa-meetup-1-registry/","publishdate":"2019-03-27T15:00:00+08:00","readingtime":9,"relpermalink":"/blog/sofa-meetup-1-registry/","summary":"SOFAStack Scalable Open Financial Architecture Stack 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文根据 SOFA Meetup#1 北","tags":["SOFARegistry","SOFAMeetup"],"title":"蚂蚁金服开源服务注册中心 SOFARegistry | SOFA 开源一周年献礼","type":"blog","url":"/blog/sofa-meetup-1-registry/","wordcount":4318},{"author":"蚂蚁金服团队","categories":"seata","content":"Fescar 0.4.0 版本发布了 TCC 模式，由蚂蚁金服团队贡献，欢迎大家试用。\nSample 地址：https://github.com/fescar-group/fescar-samples/tree/master/tcc\n文末也提供了项目后续的 Roadmap，欢迎关注。\n一、TCC 简介 在两阶段提交协议（2PC，Two Phase Commitment Protocol）中，资源管理器（RM, resource manager）需要提供“准备”、“提交”和“回滚” 3 个操作；而事务管理器（TM, transaction manager）分 2 阶段协调所有资源管理器，在第一阶段询问所有资源管理器“准备”是否成功，如果所有资源均“准备”成功则在第二阶段执行所有资源的“提交”操作，否则在第二阶段执行所有资源的“回滚”操作，保证所有资源的最终状态是一致的，要么全部提交要么全部回滚。\n资源管理器有很多实现方式，其中 TCC（Try-Confirm-Cancel）是资源管理器的一种服务化的实现；TCC 是一种比较成熟的分布式事务解决方案，可用于解决跨数据库、跨服务业务操作的数据一致性问题；TCC 其 Try、Confirm、Cancel 3 个方法均由业务编码实现，故 TCC 可以被称为是服务化的资源管理器。\nTCC 的 Try 操作作为一阶段，负责资源的检查和预留；Confirm 操作作为二阶段提交操作，执行真正的业务；Cancel 是二阶段回滚操作，执行预留资源的取消，使资源回到初始状态。\n如下图所示，用户实现 TCC 服务之后，该 TCC 服务将作为分布式事务的其中一个资源，参与到整个分布式事务中；事务管理器分 2 阶段协调 TCC 服务，在第一阶段调用所有 TCC 服务的 Try 方法，在第二阶段执行所有 TCC 服务的 Confirm 或者 Cancel 方法；最终所有 TCC 服务要么全部都是提交的，要么全部都是回滚的。\n二、TCC 设计 用户在接入 TCC 时，大部分工作都集中在如何实现 TCC 服务上，进过蚂蚁金服多年的 TCC 应用，总结如下主要的TCC 设计和实现主要事项：\n1、业务操作分两阶段完成 接入 TCC 前，业务操作只需要一步就能完成，但是在接入 TCC 之后，需要考虑如何将其分成 2 阶段完成，把资源的检查和预留放在一阶段的 Try 操作中进行，把真正的业务操作的执行放在二阶段的 Confirm 操作中进行。\n以下举例说明业务模式如何分成两阶段进行设计，举例场景：“账户A的余额中有 100 元，需要扣除其中 30 元”；\n在接入 TCC 之前，用户编写 SQL：“update 账户表 set 余额 = 余额 -20 where 账户 = A”，便能一步完成扣款操作。\n在接入 TCC 之后，就需要考虑如何将扣款操作分成 2 步完成：\n Try 操作：资源的检查和预留；  在扣款场景，Try 操作要做的事情就是先检查 A 账户余额是否足够，再冻结要扣款的 30 元（预留资源）；此阶段不会发生真正的扣款。\n Confirm 操作：执行真正业务的提交；  在扣款场景下，Confirm 阶段走的事情就是发生真正的扣款，把A账户中已经冻结的 30 元钱扣掉。\n Cancel 操作：预留资源的是否；  在扣款场景下，扣款取消，Cancel 操作执行的任务是释放 Try 操作冻结的 30 元钱，是 A 账户回到初始状态。\n2、并发控制 用户在实现 TCC 时，应当考虑并发性问题，将锁的粒度降到最低，以最大限度的提高分布式事务的并发性。\n以下还是以A账户扣款为例，“账户 A 上有 100 元，事务 T1 要扣除其中的 30 元，事务 T2 也要扣除 30 元，出现并发”。\n在一阶段 Try 操作中，分布式事务 T1 和分布式事务 T2 分别冻结资金的那一部分资金，相互之间无干扰；这样在分布式事务的二阶段，无论 T1 是提交还是回滚，都不会对 T2 产生影响，这样 T1 和 T2 在同一笔业务数据上并行执行。\n3、允许空回滚 如下图所示，事务协调器在调用 TCC 服务的一阶段 Try 操作时，可能会出现因为丢包而导致的网络超时，此时事务管理器会触发二阶段回滚，调用 TCC 服务的 Cancel 操作，而 Cancel 操作调用未出现超时。\nTCC 服务在未收到 Try 请求的情况下收到 Cancel 请求，这种场景被称为空回滚；空回滚在生产环境经常出现，用户在实现TCC服务时，应允许允许空回滚的执行，即收到空回滚时返回成功。\n4、防悬挂控制 如下图所示，事务协调器在调用 TCC 服务的一阶段 Try 操作时，可能会出现因网络拥堵而导致的超时，此时事务管理器会触发二阶段回滚，调用 TCC 服务的 Cancel 操作，Cancel 调用未超时；在此之后，拥堵在网络上的一阶段 Try 数据包被 TCC 服务收到，出现了二阶段 Cancel 请求比一阶段 Try 请求先执行的情况，此 TCC 服务在执行晚到的 Try 之后，将永远不会再收到二阶段的 Confirm 或者 Cancel ，造成 TCC 服务悬挂。\n用户在实现 TCC 服务时，要允许空回滚，但是要拒绝执行空回滚之后 Try 请求，要避免出现悬挂。\n5、幂等控制 无论是网络数据包重传，还是异常事务的补偿执行，都会导致 TCC 服务的 Try、Confirm 或者 Cancel 操作被重复执行；用户在实现 TCC 服务时，需要考虑幂等控制，即 Try、Confirm、Cancel 执行一次和执行多次的业务结果是一样的。\nRoadmap 当前已经发布到 0.4.0 版本，后续我们会发布 0.5 ~ 1.0 版本，继续对 AT、TCC 模式进行功能完善和和丰富，并解决服务端高可用问题，在 1.0 版本之后，本开源产品将达到生产环境使用的标准。\n","date":1553583600,"description":"Fescar 0.4.0 版本发布了 TCC 模式，由蚂蚁金服团队贡献，欢迎大家试用。","dir":"blog/seata-tcc-theory-design-realization/","fuzzywordcount":2000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"45ef8a72beefcd26f4f62e7bdb34671c","permalink":"/blog/seata-tcc-theory-design-realization/","publishdate":"2019-03-26T15:00:00+08:00","readingtime":4,"relpermalink":"/blog/seata-tcc-theory-design-realization/","summary":"Fescar 0.4.0 版本发布了 TCC 模式，由蚂蚁金服团队贡献，欢迎大家试用。 Sample 地址：https://github.com/fescar-group/fescar","tags":["seata"],"title":"TCC 理论及设计实现指南介绍","type":"blog","url":"/blog/seata-tcc-theory-design-realization/","wordcount":1971},{"author":"蚂蚁金服团队","categories":"seata","content":"Fescar 0.4.0 版本发布了 TCC 模式，由蚂蚁金服团队贡献，欢迎大家试用，文末也提供了项目后续的 Roadmap，欢迎关注。\n前言：基于 TCC 模型的应用场景 TCC 分布式事务模型直接作用于服务层。不与具体的服务框架耦合，与底层 RPC 协议无关，与底层存储介质无关，可以灵活选择业务资源的锁定粒度，减少资源锁持有时间，可扩展性好，可以说是为独立部署的 SOA 服务而设计的。\n一、TCC 模型优势 对于 TCC 分布式事务模型，笔者认为其在业务场景应用上，有两方面的意义。\n1.1 跨服务的分布式事务 服务的拆分，也可以认为是资源的横向扩展，只不过方向不同而已。\n横向扩展可能沿着两个方向发展：\n 功能扩展，根据功能对数据进行分组，并将不同的功能组分布在多个不同的数据库上，这实际上就是 SOA 架构下的服务化。 数据分片，在功能组内部将数据拆分到多个数据库上，为横向扩展增加一个新的维度。  下图简要阐释了横向数据扩展策略：\n横向扩展的两种方法可以同时进行运用：用户信息（Users）、产品信息（Products）与交易信息（Trans）三个不同功能组可以存储在不同的数据库中。另外，每个功能组内根据其业务量可以再拆分到多个数据库中，各功能组可以相互独立地进行扩展。\n因此，TCC 的其中一个作用就是在按照功能横向扩展资源时，保证多资源访问的事务属性。\n1.2 两阶段拆分 TCC 另一个作用就是把两阶段拆分成了两个独立的阶段，通过资源业务锁定的方式进行关联。资源业务锁定方式的好处在于，既不会阻塞其他事务在第一阶段对于相同资源的继续使用，也不会影响本事务第二阶段的正确执行。\n传统模型的并发事务：\nTCC 模型的并发事务：\n可以发现 TCC 模型进一步减少了资源锁的持有时间。同时，从理论上来说，只要业务允许，事务的第二阶段什么时候执行都可以，反正资源已经业务锁定，不会有其他事务动用该事务锁定的资源。\n这对业务有什么好处呢？拿支付宝的担保交易场景来说，简化情况下，只需要涉及两个服务，交易服务和账务服务。交易作为主业务服务，账务作为从业务服务，提供 Try、Commit、Cancel 接口：\n Try 接口扣除用户可用资金，转移到预冻结资金。预冻结资金就是业务锁定方案，每个事务第二阶段只能使用本事务的预冻结资金，在第一阶段执行结束后，其他并发事务也可以继续处理用户的可用资金。 Commit 接口扣除预冻结资金，增加中间账户可用资金（担保交易不能立即把钱打给商户，需要有一个中间账户来暂存）。  假设只有一个中间账户的情况下，每次调用支付服务的 Commit 接口，都会锁定中间账户，中间账户存在热点性能问题。 但是，在担保交易场景中，七天以后才需要将资金从中间账户划拨给商户，中间账户并不需要对外展示。因此，在执行完支付服务的第一阶段后，就可以认为本次交易的支付环节已经完成，并向用户和商户返回支付成功的结果，并不需要马上执行支付服务二阶段的 Commit 接口，等到低锋期时，再慢慢消化，异步地执行。\n可能部分读者认为担保交易比较特殊，其实直付交易（直接把钱打到商户账户的交易模式，Commit 接口扣除预冻结资金以后，不是转移到中间账务，而是直接转移到商户账户）也可以这样使用，只要提前告知商户，高峰期交易资金不是实时到账，但保证在一定时间之内结算完成，商户应该也是可以理解的。\n这就是 TCC 分布式事务模型的二阶段异步化功能，从业务服务的第一阶段执行成功，主业务服务就可以提交完成，然后再由框架异步的执行各从业务服务的第二阶段。\n二、通用型 TCC 解决方案 通用型 TCC 解决方案就是最典型的 TCC 分布式事务模型实现，所有从业务服务都需要参与到主业务服务的决策当中。\n适用场景 由于从业务服务是同步调用，其结果会影响到主业务服务的决策，因此通用型 TCC 分布式事务解决方案适用于执行时间确定且较短的业务，比如互联网金融企业最核心的三个服务：交易、支付、账务：\n当用户发起一笔交易时，首先访问交易服务，创建交易订单；然后交易服务调用支付服务为该交易创建支付订单，执行收款动作，最后支付服务调用账务服务记录账户流水和记账。\n为了保证三个服务一起完成一笔交易，要么同时成功，要么同时失败，可以使用通用型 TCC 解决方案，将这三个服务放在一个分布式事务中，交易作为主业务服务，支付作为从业务服务，账务作为支付服务的嵌套从业务服务，由 TCC 模型保证事务的原子性。\n支付服务的 Try 接口创建支付订单，开启嵌套分布式事务，并调用账务服务的 Try 接口；账务服务在 Try 接口中冻结买家资金。一阶段调用完成后，交易完成，提交本地事务，由 TCC 框架完成分布式事务各从业务服务二阶段的调用。\n支付服务二阶段先调用账务服务的 Confirm 接口，扣除买家冻结资金；增加卖家可用资金。调用成功后，支付服务修改支付订单为完成状态，完成支付。\n当支付和账务服务二阶段都调用完成后，整个分布式事务结束。\n三、异步确保型 TCC 解决方案 异步确保型 TCC 解决方案的直接从业务服务是可靠消息服务，而真正的从业务服务则通过消息服务解耦，作为消息服务的消费端，异步地执行。\n可靠消息服务需要提供 Try，Confirm，Cancel 三个接口。Try 接口预发送，只负责持久化存储消息数据；Confirm 接口确认发送，这时才开始真正的投递消息；Cancel 接口取消发送，删除消息数据。\n消息服务的消息数据独立存储，独立伸缩，降低从业务服务与消息系统间的耦合，在消息服务可靠的前提下，实现分布式事务的最终一致性。\n此解决方案虽然增加了消息服务的维护成本，但由于消息服务代替从业务服务实现了 TCC 接口，从业务服务不需要任何改造，接入成本非常低。\n适用场景 由于从业务服务消费消息是一个异步的过程，执行时间不确定，可能会导致不一致时间窗口增加。因此，异步确保性 TCC 分布式事务解决方案只适用于对最终一致性时间敏感度较低的一些被动型业务（从业务服务的处理结果不影响主业务服务的决策，只被动的接收主业务服务的决策结果）。比如会员注册服务和邮件发送服务：\n当用户注册会员成功，需要给用户发送一封邮件，告诉用户注册成功，并提示用户激活该会员。但要注意两点：\n 如果用户注册成功，一定要给用户发送一封邮件； 如果用户注册失败，一定不能给用户发送邮件。  因此，这同样需要会员服务和邮件服务保证原子性，要么都执行，要么都不执行。不一样的是，邮件服务只是一种被动型的业务，并不影响用户是否能够注册成功，它只需要在用户注册成功以后发送邮件给用户即可，邮件服务不需要参与到会员服务的活动决策中。\n对于此种业务场景，可以使用异步确保型TCC分布式事务解决方案，如下：\n由可靠消息服务来解耦会员和邮件服务，会员服务与消息服务组成 TCC 事务模型，保证事务原子性。然后通过消息服务的可靠特性，确保消息一定能够被邮件服务消费，从而使得会员与邮件服务在同一个分布式事务中。同时，邮件服务也不会影响会员服务的执行过程，只在会员服务执行成功后被动接收发送邮件的请求。\n四、补偿型 TCC 解决方案 补偿型 TCC 解决方案与通用型 TCC 解决方案的结构相似，其从业务服务也需要参与到主业 …","date":1553410800,"description":"Fescar 0.4.0 版本发布了 TCC 模式，由蚂蚁金服团队贡献，欢迎大家试用。","dir":"blog/seata-tcc-applicable-models-scenarios/","fuzzywordcount":4000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"fa8436ce2760fafb880427799a763f32","permalink":"/blog/seata-tcc-applicable-models-scenarios/","publishdate":"2019-03-24T15:00:00+08:00","readingtime":8,"relpermalink":"/blog/seata-tcc-applicable-models-scenarios/","summary":"Fescar 0.4.0 版本发布了 TCC 模式，由蚂蚁金服团队贡献，欢迎大家试用，文末也提供了项目后续的 Roadmap，欢迎关注。 前言：基于 TCC 模型的应用场景 TCC 分布式事","tags":["seata"],"title":"TCC 适用模型与适用场景分析","type":"blog","url":"/blog/seata-tcc-applicable-models-scenarios/","wordcount":3912},{"author":"善逝","categories":"SOFAArk","content":" SOFAStack Scalable** O**pen **F**inancial **A**rchitecture Stack 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。\n蚂蚁金服在 SOFAStack 体系内研发了一款基于 Java 实现的轻量级类隔离容器，主要提供类隔离和应用(模块)合并部署能力\u0026amp;ndash;SOFAArk。本篇文章为 SOFAArk 0.6.0 的新特性介绍。 GitHub 地址：https://github.com/alipay/sofa-ark\n 简介 在大型软件开发过程中，通常会推荐底层功能插件化、业务功能模块化的开发模式，以其达到低耦合、高内聚、功能复用的优点。基于此，SOFAArk 提供了一套较为规范化的插件化、模块化开发方案，产品能力主要包括：\n 定义插件开发规范，提供 Maven 打包工具，简单快速将多个二方包打包成插件（Ark Plugin，以下简称 Plugin）， 适用于将底层组件插件化输出，例如 RPC、富客户端等； 定义模块开发规范，提供 Maven 打包工具，简单快速将应用（Spring Boot/SOFABoot/普通 Java 应用）打包成模块 (Ark Biz，以下简称 Biz)，适用于将业务组件模块化输出，提升业务能力复用； 定义类加载模型，运行时 Plugin、Biz 之间均相互隔离，运行时由不同的 ClassLoader 加载，有效避免相互之间的包冲突，降低 Plugin 和 Biz 对运行环境的要求； 定义标准的编程界面，包括服务、事件、扩展点等机制，方便 Plugin、Biz 交互和扩展； 定义业务模块 (Biz) 生命周期，支持多 Biz 合并部署。开发阶段将多个 Biz 打包成 Executable Ark Jar 包(以下简称 Ark 包)，或者运行时使用 API 或配置中心(Zookeeper)动态地管理 Biz 安装和卸载，满足多应用合并部署及动态升级的需求。  基于以上能力，SOFAArk 可以帮助解决多应用(模块)合并部署、动态升级、依赖包冲突等场景问题。\n场景 场景一：合并部署 复杂项目通常需要跨团队协作开发，各自负责不同的组件。协调跨团队合作开发会遇到不少问题：比如各自技术栈不统一导致的依赖冲突、往同一个 Git 仓库提交代码常常导致 merge 冲突、组件功能相互依赖影响测试进度。因此，如果能让每个团队将负责的功能组件当成一个个单独的应用开发和测试，运行时合并部署，那么将有助于提升开发效率及应用可扩展性。\nSOFAArk 提出了一种特殊的包结构 \u0026amp;ndash; Ark Biz，用户可以使用 Maven 插件将应用打包成 Biz，允许多 Biz 在 SOFAArk 容器之上合并部署，并通过统一的编程界面交互，如下：\nBiz 对应用类型没有限制，可以是 Spring Boot/SOFABoot/Java 普通应用类型，Biz 之间采用统一的编程界面-SOFA JVM服务进行交互。发布和引用服务也非常简单，使用 API 或者 Spring 注解/XML 方式：\n合并部署的形式，分为两种 \u0026amp;ndash; 静态合并部署和动态合并部署。\n静态合并部署 在开发阶段，应用可以将其他应用打成的 Biz 包通过 Maven 依赖的方式引入，而当自身被打成 Ark 包时，会将引入的其他 Biz 包一并打入。通过 java -jar 启动 Ark 包时，则会根据优先级依次启动各 Biz，单个 Biz 使用独立的 BizClassLoader 加载，不需要考虑依赖包冲突问题，Biz 之间则通过 SOFA JVM 服务交互。\n动态合并部署 动态合并部署区别于静态合并部署最大的一点是，在运行时可以通过 API 或者配置中心（Zookeeper）来控制 Biz 的部署和卸载。动态合并部署的设计理念图如下：\n无论是静态抑或动态合并部署都有存在宿主应用 (master biz) 的概念，如果 Ark 包只打包了一个 Biz，则该 Biz 默认成为宿主应用；如果 Ark 包打包了多个 Biz 包，需要配置指定宿主应用。宿主 Biz 和其他 Biz 唯一不同在于，宿主 Biz 不允许被卸载。\n一般而言，宿主应用会作为流量入口的中台系统，具体的服务实现会放在不同的动态 Biz 中，供宿主应用调用。宿主应用可以使用 SOFAArk 提供的客户端 API 实现动态应用的部署和卸载。除了 API， SOFAArk 提供了 Config Plugin，用于对接配置中心（目前支持 Zookeeper），运行时接受动态配置；Config Plugin 会解析下发的配置，控制动态应用的部署和卸载。\n场景二：动态升级 SOFAArk 在蚂蚁内部也被用来解决动态升级的场景问题。有时候，因为业务迭代较快，应用依赖的某二方包需要频繁的变更，这将导致应用每次都因为升级二方包版本做变更发布，影响开发效率；而作为二方包的开发者，常常因为推动依赖方应用升级阻力较大，导致新特性无法按时上线，影响业务发展。\n为了加快创新业务的迭代速度，会将需要频繁变更的二方包打包成 Biz 包，供其他应用依赖。作为依赖方，不会直接在 Pom 文件（假设是使用 Maven 构建）定义 Biz 包版本，而是通过配置中心（例如 Zookeeper）下发配置。如此，当应用启动时，会拉取 Biz 版本配置信息，进而拉取正确版本的 Biz 包并启动。如此，当需要依赖方升级 Biz 版本时，只需要在配置中心重新推送配置即可。\n场景三：依赖隔离 日常使用 Java 开发，常常会遇到包依赖冲突的问题，尤其当应用变得臃肿庞大，包冲突的问题也会变得更加棘手，导致各种各样的报错，例如 LinkageError, NoSuchMethodError 等。实际开发中，可以采用多种方法来解决包冲突问题，比较常见的是类似 Spring Boot 的做法：统一管理应用所有依赖包的版本，保证这些三方包不存在依赖冲突。这种做法只能有效避免包冲突问题，不能根本上解决包冲突的问题。如果某个应用的确需要在运行时使用两个相互冲突的包，例如 protobuf2 和 protobuf3，那么类似 Spring Boot 的做法依然解决不了问题。\n为了彻底解决包冲突的问题，需要借助类隔离机制，使用不同的 ClassLoader 加载不同版本的三方依赖，进而隔离包冲突问题。 OSGi 作为业内最出名的类隔离框架，自然是可以被用于解决上述包冲突问题，但是 OSGi 框架门槛较高，功能繁杂。为了解决包冲突问题，引入 OSGi 框架，有牛刀杀鸡之嫌，反而使工程变得更加复杂，不利于开发。\nSOFAArk 采用轻量级的类隔离方案来解决日常经常遇到的包冲突问题，在蚂蚁金服内部服务于整个 SOFABoot 技术体系，弥补 Spring Boot 没有的类隔离能力。SOFAArk 提出了一种特殊的包结构 \u0026amp;ndash; Ark Plugin，在遇到包冲突时，用户可以使用 Maven 插件将若干冲突包打包成 Plugin，运行时由独立的 PluginClassLoader 加载，从而解决包冲 …","date":1553065200,"description":"本篇文章为 SOFAArk 0.6.0 的新特性介绍。","dir":"blog/sofa-ark-0.6.0/","fuzzywordcount":3500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"7a25cfa30d66586c83abafd947447de3","permalink":"/blog/sofa-ark-0.6.0/","publishdate":"2019-03-20T15:00:00+08:00","readingtime":7,"relpermalink":"/blog/sofa-ark-0.6.0/","summary":"SOFAStack Scalable** O**pen **F**inancial **A**rchitecture Stack 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 蚂蚁金服在 SOFAStack 体","tags":["SOFAArk"],"title":"蚂蚁金服 SOFAArk 0.6.0 新特性介绍 | 模块化开发容器","type":"blog","url":"/blog/sofa-ark-0.6.0/","wordcount":3490},{"author":"炎竹","categories":"SOFAActs","content":" SOFAStack Scalable Open Financial Architecture Stack 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。\n蚂蚁金服在 SOFAStack 体系内研发了基于模型驱动的自动化接口测试框架 SOFAACTS。 GitHub 地址：https://github.com/alipay/sofa-acts\n 背景 伴随着业务需求的爆发，蚂蚁金服金融级分布式架构质量测试活动变得复杂起来，表现在测试的业务场景复杂，诸如分布式事务处理流程场景、并发性、账户状态多样性、幂等性和兼容性等等。在原有的自动化测试框架下，测试流程编排极易出现测试数据冗余分散、可维护性差、人工编码成本高和测试验证点易遗漏的问题。\n如何解决上面的问题呢？\n蚂蚁金服在 SOFAStack 体系内研发了基于模型驱动的自动化接口测试框架 SOFAACTS。\nSOFAACTS 介绍 SOFAACTS 由 IDE 和测试引擎组成，下图为产品架构图：\n框架适配 TestNg+Spring 的测试上下文环境，以 YAML 为数据载体并在此上构建数据模型驱动，具有契合快速互联网发展和复杂分布式金融系统特点的优良特性：\n 模型驱动和标准执行引擎； 精细化校验和数据的自动回写； 具有灵活的可扩展性； 用例可视化维护。  1.模型驱动和标准化 在测试用例数据与测试代码分离的探索上，很多测试框架采用数据驱动的方式，但这也无法从容应对金融级的复杂业务场景。框架对用例数据进行了深度抽象，提出模型驱动理念，研发出基于模型的数据驱动和标准化执行引擎，实现了数据和代码的分离管理，同时对测试过程中的数据清理、数据准备、用例执行、结果校验阶段进行标准化，做到测试数据维护和测试代码的简洁优雅。用例执行时用户无需关注数据如何加载，结果和期望数据如何比对，只需要关注测试数据和执行结果。\n接下来，我们介绍如何使用 SOFAACTS 来高效率地完成一键生成数据模型生成和一键生成测试脚本。\n数据模型生成 首先进行数据模型的准备，以方便之后模版化地快速创建对象和表，按照如下方式来准备 DB 数据、接口请求参数和返回结果对象模型。\nDB 数据模型生成  任意测试代码中右击-\u0026amp;gt; SOFAACTS 功能-\u0026amp;gt;生成 DB 表结构模板；  选择生成的目标测试工程；  点击确认后选择并添加需要生成模型的表即可生成。  类对象模型生成  待构建模型的类定义的任意方法上右击-\u0026amp;gt; SOFAACTS 功能-\u0026amp;gt;模板生成，生成当前对象的模型；  生成完成后，我们可以在下图位置找到生成的数据对象模型；  按照上述步骤，这样我们就生成了接口对象模板。  现在，我们开始进行脚本一键生成：\n测试脚本生成 SOFAACTS IDE 提供测试脚本自动生成功能，无需手动编码。操作方式如下：\n 被测接口方法上点击，选择 SOFAACTS 功能\u0026amp;ndash;\u0026amp;gt;生成测试用例；  这时会弹出一个文本框，填写脚本生成的位置和编码格式，如下：  填写完成后，点击 OK 即可自动生成如下测试脚本，可以看出模型驱动生成的脚本精简而优雅。  原来数据驱动下的脚本是如下面图这样的，测试数据冗余分散，人工编码成本高维护性差。\n实践证明 SOFAACTS 用例的测试代码构建效率提高 80% ，测试数据精简到 1/case 数。\n2.精细化校验 在解决复杂业务场景下测试验证难、易遗漏等问题时，SOFAACTS 基于代码行为跟踪和分析理念，通过反射机制和日志解析实现结果数据的自动采集，以此做为场景用例校验的数据基线，并在持续集成时进行基线全量因子匹配来达到精细化验证。如下图：\n同时，为了提高自动采集后数据回填的效率，框架支持预校验数据的自动写入能力，进一步实现了数据的自动化精细校验。如下图：一键点击即可采集到校验数据基线，在蚂蚁内部实践中 ACTS 做到了结果校验效率提升至少 80%，场景验证 0 遗漏。\n3.灵活可扩展 框架为了应对各种特殊业务测试情况而不需要过多改动，设计上应用高内聚与低耦合原则，支持既可以复用框架底层代码又可以针对业务个性化情况做扩展的能力。整个框架提供了丰富的 API，测试执行过程每个方法、每个类以便测试执行过程的每个阶段（如下图）都能够在测试脚本里面被重新为其他方法或者被其他多态的子类替换，这样让框架变得更通用，既赋予了框架轻量性又增加了灵活性。\n自定义的 API 如下：\nAPI 的具体使用请详细学习产品使用手册。\n4.用例可视化维护 框架支持研发集成环境的一站式编辑，高效的用例脚本和数据维护，有效减少重复性的数据准备代码。如下图：\n总结 以上便是对 SOFAACTS 测试框架的基本介绍，还有诸多能力各位可以查阅我们详细的使用手册。\n目前，SOFAACTS 已经在蚂蚁金服大范围使用，分钟级用例编写 10 倍效能提升，累计用例个数 10w 以上，高频功能使用可达近 2000 次/日，并持续保持着旺盛的生命力。\n当前，代码已开源托管在 GitHub 上，欢迎关注，同时也欢迎业界爱好者共同创造更好的 SOFAACTS。\nGitHub 项目地址：https://github.com/alipay/sofa-acts\n相关链接  SOFAACTS ：https://github.com/alipay/sofa-acts API 产品使用手册：https://www.sofastack.tech/sofa-acts/docs/Usage-API SOFAACTS 详细使用手册：https://www.sofastack.tech/sofa-acts/docs/Home  招聘 蚂蚁金服金融核心测试技术团队持续寻找对测试自动化、智能风险管控等方向充满热情的小伙伴加入，有意者请联系 zhiqiang.li@antfin.com\n","date":1552546800,"description":"SOFAStack 体系，基于模型驱动的自动化接口测试框架 SOFAACTS。","dir":"blog/sofa-acts-automated-testing-framework/","fuzzywordcount":2100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"b76c650b1a69560fe38c8e4f237f6207","permalink":"/blog/sofa-acts-automated-testing-framework/","publishdate":"2019-03-14T15:00:00+08:00","readingtime":5,"relpermalink":"/blog/sofa-acts-automated-testing-framework/","summary":"SOFAStack Scalable Open Financial Architecture Stack 是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 蚂蚁金服在 SOFAStack 体","tags":["SOFAActs"],"title":"SOFAStack 开源自动化测试框架 SOFAACTS","type":"blog","url":"/blog/sofa-acts-automated-testing-framework/","wordcount":2096},{"author":"家纯","categories":"SOFAJRaft","content":" 什么是 SOFAJRaft？ SOFAJRaft 是一个基于 Raft 一致性算法的生产级高性能 Java 实现，支持 MULTI-RAFT-GROUP，适用于高负载低延迟的场景。 使用 SOFAJRaft 你可以专注于自己的业务领域，由 SOFAJRaft 负责处理所有与 Raft 相关的技术难题，并且 SOFAJRaft 非常易于使用，你可以通过几个示例在很短的时间内掌握它。 SOFAJRaft 是从百度的 braft 移植而来，做了一些优化和改进，感谢百度 braft 团队开源了如此优秀的 C++ Raft 实现。\n 基础知识：分布式共识算法 (Consensus Algorithm) 如何理解分布式共识?  多个参与者 针对 某一件事 达成完全 一致 ：一件事，一个结论 已达成一致的结论，不可推翻  有哪些分布式共识算法?  Paxos：被认为是分布式共识算法的根本，其他都是其变种，但是 Paxos 论文中只给出了单个提案的过程，并没有给出复制状态机中需要的 multi-paxos 的相关细节的描述，实现 Paxos 具有很高的工程复杂度（如多点可写，允许日志空洞等）。 Zab：被应用在 Zookeeper 中，业界使用广泛，但没有抽象成通用的 library。 Raft：以容易理解著称，业界也涌现出很多 Raft 实现，比如大名鼎鼎的 etcd, braft, tikv 等。  什么是 Raft？ Raft 是一种更易于理解的分布式共识算法，核心协议本质上还是师承 Paxos 的精髓，不同的是依靠 Raft 模块化的拆分以及更加简化的设计，Raft 协议相对更容易实现。\n模块化的拆分主要体现在：Raft 把一致性协议划分为 Leader 选举、MemberShip 变更、日志复制、Snapshot 等几个几乎完全解耦的模块。\n更加简化的设计则体现在：Raft 不允许类似 Paxos 中的乱序提交、简化系统中的角色状态（只有 Leader、Follower、Candidate 三种角色）、限制仅 Leader 可写入、使用随机化的超时时间来设计 Leader Election 等等。\n特点：Strong Leader  系统中必须存在且同一时刻只能有一个 Leader，只有 Leader 可以接受 Clients 发过来的请求； Leader 负责主动与所有 Followers 通信，负责将“提案”发送给所有 Followers，同时收集多数派的 Followers 应答； Leader 还需向所有 Followers 主动发送心跳维持领导地位(保持存在感)。  一句话总结 Strong Leader: \u0026amp;ldquo;你们不要 BB! 按我说的做，做完了向我汇报!\u0026amp;quot;。另外，身为 Leader 必须保持一直 BB(heartbeat) 的状态，否则就会有别人跳出来想要 BB 。\nRaft 中的基本概念 篇幅有限，这里只对 Raft 中的几个概念做一个简单介绍，详细请参考 Raft paper。\nRaft-node 的 3 种角色/状态  Follower：完全被动，不能发送任何请求，只接受并响应来自 Leader 和 Candidate 的 Message，每个节点启动后的初始状态一定是 Follower； Leader：处理所有来自客户端的请求，以及复制 Log 到所有 Followers； Candidate：用来竞选一个新 Leader （Candidate 由 Follower 触发超时而来）。  Message 的 3 种类型  RequestVote RPC：由 Candidate 发出，用于发送投票请求； AppendEntries (Heartbeat) RPC：由 Leader 发出，用于 Leader 向 Followers 复制日志条目，也会用作 Heartbeat （日志条目为空即为 Heartbeat）； InstallSnapshot RPC：由 Leader 发出，用于快照传输，虽然多数情况都是每个服务器独立创建快照，但是Leader 有时候必须发送快照给一些落后太多的 Follower，这通常发生在 Leader 已经丢弃了下一条要发给该Follower 的日志条目(Log Compaction 时清除掉了) 的情况下。  任期逻辑时钟  时间被划分为一个个任期 (term)，term id 按时间轴单调递增； 每一个任期的开始都是 Leader 选举，选举成功之后，Leader 在任期内管理整个集群，也就是 “选举 + 常规操作”； 每个任期最多一个 Leader，可能没有 Leader (spilt-vote 导致)。  本图出自《Raft: A Consensus Algorithm for Replicated Logs》\n什么是 SOFAJRaft？ SOFAJRaft 是一个基于 Raft 一致性算法的生产级高性能 Java 实现，支持 MULTI-RAFT-GROUP，适用于高负载低延迟的场景。 使用 SOFAJRaft 你可以专注于自己的业务领域，由 SOFAJRaft 负责处理所有与 Raft 相关的技术难题，并且 SOFAJRaft 非常易于使用，你可以通过几个示例在很短的时间内掌握它。\nSOFAJRaft 是从百度的 braft 移植而来，做了一些优化和改进，感谢百度 braft 团队开源了如此优秀的 C++ Raft 实现。\nSOFAJRaft 整体功能\u0026amp;amp;性能优化 功能支持   Leader election：Leader 选举，这个不多说，上面已介绍过 Raft 中的 Leader 机制。\n  Log replication and recovery：日志复制和日志恢复。\n   Log replication 就是要保证已经被 commit 的数据一定不会丢失，即一定要成功复制到多数派。 Log recovery 包含两个方面：  Current term 日志恢复：主要针对一些 Follower 节点重启加入集群或者是新增 Follower 节点后如何追日志； Prev term 日志恢复：主要针对 Leader 切换前后的日志一致性。    Snapshot and log compaction：定时生成 snapshot，实现 log compaction 加速启动和恢复，以及 InstallSnapshot 给 Followers 拷贝数据，如下图：  本图出自《In Search of an Understandable Consensus Algorithm》\n Membership change：用于集群线上配置变更，比如增加节点、删除节点、替换节点等。\n  Transfer leader：主动变更 leader，用于重启维护，leader 负载平衡等。\n  Symmetric network partition tolerance：对称网络分区容忍性。\n  如上图 S1 为当前 leader，网络分区造成 S2 不断增加本地 term，为了避免网络恢复后 S2 …","date":1552374000,"description":"本文为 SOFAJRaft 的基础解析，欢迎阅读~","dir":"blog/sofa-jraft-production-level-algorithm-library/","fuzzywordcount":6500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"a2e98969240f05af10554781f4ab81ef","permalink":"/blog/sofa-jraft-production-level-algorithm-library/","publishdate":"2019-03-12T15:00:00+08:00","readingtime":13,"relpermalink":"/blog/sofa-jraft-production-level-algorithm-library/","summary":"什么是 SOFAJRaft？ SOFAJRaft 是一个基于 Raft 一致性算法的生产级高性能 Java 实现，支持 MULTI-RAFT-GROUP，适用于高负载低延迟的场景。 使用","tags":["SOFAJRaft","SOFALab"],"title":"SOFAStack 开源 SOFAJRaft：生产级 Java Raft 算法库","type":"blog","url":"/blog/sofa-jraft-production-level-algorithm-library/","wordcount":6480},{"author":"Linux 中国 老王","categories":"SOFAStack","content":"我们选择将 SOFA 中间件框架逐步开源出来，在贡献给社区的同时，也期待社区、合作伙伴甚至客户，都能够一起参与共建，形成行业标准和最佳实践。\u0026amp;ndash; 蚂蚁金服总监杨冰\n引言 最近，我听到了一个消息，蚂蚁金服将会开源 SOFA最核心的两个组件——分布式事务框架和服务注册中心。\n熟悉中间件的朋友们都知道，这两个组件都是针对当前最火的微服务架构。其中，分布式事物框架是解决数据一致性问题的关键。服务注册中心则是服务治理的基础。在这两块开源后，SOFA 将成为一套真正完备的分布式解决方案。\n作为开源人士，我对此消息深感兴趣，因此联系到了蚂蚁金服中间件团队的杨冰总监，就此消息向他求证。机缘凑巧之下，杨冰花费了宝贵的时间，和我深入讲述了 SOFA 开源的思考，以及近期的规划。\n通过这次交谈，也让我看到了一个成功的商业公司是如何拥抱开源、并将开源作为其根本战略来撬动技术红利，支持其急速发展的业务需求的。\n以下是正文，我将它分享出来以飨读者。\n 如今，开源已经成为主流，可以说，整个信息产业已经从过去的闭源模式转换为现今的开源模式。各种开源公司纷纷创新不同的开源模式，其中以 RedHat、Google、Facebook 等公司所取得的成绩最为耀眼。\n2018 年的时候，我曾经参与“开源社”主持的《2018 中国开源年度报告》的撰写工作，并建立了一个数学分析模型，以此来对中国的互联网公司的开源项目分析其活跃度和健康度。让我既感意外，也不意外的是，阿里系的开源项目占据了活跃度排行榜前五的第一、第二和第四；甚至在前五十个项目中，阿里系的开源项目占据了超过一半的份额！我不意外的是，业界一直对阿里在开源方面的动作和力度颇有感受；意外的是，这种力度还是超乎了我的想象。这其中包括阿里巴巴集团和蚂蚁金服等都贡献了相当可观的开源项目。\n因此，这次遇到杨冰时，我就开源方面和他深入聊了几句，想了解一下蚂蚁金服是如何思考开源和践行开源的，是如何将开源与公司的商业价值有机地结合起来的。\n缘何开源 作为一家商业公司，宣称自己开源，甚至也形式上开源一些代码，其实已经是很常见的事情了。但是，真正能将开源与公司的技术演进相融合，并能有效地助推公司业务发展的，却并不太多。这件事其实并没有那么简单——远非只是上传到 GitHub 那么简单。\n根据业界的经验，在公司的技术产品开源方面，要将现有场景的代码开源，至少需要在已经运行稳定、结构清晰的现有代码基础上多付出 30% 的技术投入，对代码进行梳理、完善和通用化，才能做到初步的代码开源；而进一步要将这些开源代码维护下去，乃至于和公司业务线上的产品代码保持同步发展，多付出的技术成本还远远不止这些。作为一个互联网技术老兵，我对此深以为然。\n那么，蚂蚁金服是如何说服公司决策层在尚未看到开源回报的前景下，同意付出这么多的额外代价来支持开源的呢？推动开源的力量是因何而来的？\n“首先，开源是个共赢的模式，对于蚂蚁金服来说，开源可以扩大技术服务场景，为支付、金融等更多的客户提供服务，提升合作伙伴的效率。”杨冰说，“虽然，蚂蚁金服已经有很多的业务场景，也在很多场景下取得了超大规模的实践经验，但是，依然存在没有覆盖到的金融服务场景。而将技术开源出来，可以供更多的客户应用到其自身的场景下——这些场景有效的补充了蚂蚁金服的技术应用面，也为更完善的技术框架奠定了基础。因此，我们选择将 SOFA 中间件框架逐步开源出来，在贡献给社区的同时，也期待社区、合作伙伴甚至客户，都能够一起参与共建，形成行业标准和最佳实践。”\n“其次，对金融服务来说，监管和自主可控的要求更多，”杨冰接着谈到，“客户也希望可以对其所采用的技术有更多的掌控。”开源是一种可以使客户和上下游产业共同参与和发展的可行模式。\n“所以，其实并不是技术部门去说服公司决策层去开源，而是业务发展的自然选择，这也是一种合理的发展方向。”他总结道。这样的结果，其实是和当前流行的开源商业模式所暗合的。\n“另外，如你所说，确实在开源时，我们做了很大的改造。以可扩展化的方式来层层构建 SOFA 框架的能力，保证 SOFA 的内部版本和开源的版本采用的是同一个内核。在开源时，剥离了特定业务的逻辑，而保持了公司内部的业务线上的代码和开源代码的核心是一致的。这样，只要公司的业务在持续发展，开源的代码就会一直维护和演进下去。所以 SOFA 的内部版本就是在开源版本之上扩展了内部逻辑和历史版本的兼容逻辑。开源版本的核心逻辑，内外是一致的，并在蚂蚁金服的生产环境中被广泛使用，同时会随着蚂蚁金服自身业务诉求的驱动不断的演进。”杨冰补充道，“但这是值得的，在为开源代码做改进时，也是为公司自己的业务做改进，这是双赢且可持续发展的。”\n很多公司在初涉开源时，常常有疑虑，将核心技术开放出去，会不会导致竞争对手的技术提升，会不会造成更大的技术竞争压力？\n“事实上，我们在最初准备开源时，也有讨论过这个方面。技术要被更多人用、更多场景用，才会有发展。而开放的技术才能带来团队的发展，因为技术是动态发展的，作为开源的一方，事实上在技术上是相对领先的。开源和掌握是两码事，掌握和用好又是两码事，所以，因开源而带来的竞争，其实是助推整个开源体系的发展的，是良性的、有益的。”杨冰说，“而从社区和行业现状看，大家都在开放，封闭的技术体系会逐渐落后。只有开放才能求同存异，共同发展。”\n 花絮\n我问蚂蚁金服的朋友，在你们开源中有什么有趣的“段子”吗？可以讲来听听。\n我朋友过了几天后，给我发来了这样一段文字：\n“参与双十一的中间件团队的常态是什么呢？\n当晚，团队的常态大概就是喝着茶等零点高峰，高峰期过了之后，当然就是参与买买买啦。 我们很多的一些事情的初始想法都是来自于双十一当天的夜聊，似乎在经历了紧张的零点高峰之后，脑细胞特别活跃。\n对于基础设施团队来说，双十一算是一次大考的结束，考完成绩出来了，我们就想琢磨一些有挑战的事情，于是我们会天马行空地聊一聊对于下一年在技术上需要去做的事情。而在 2017 年的双十一当天，SOFA 的几个同学就围在一起聊了 SOFA 能不能开源？为什么要开源？开源和商业化之间的关系？开源后要做哪些事情等等，这个算是 SOFA 开源的第一次内部讨论。\n从这次内部讨论之后，经过了大约半年的准备时间，我们在 2018 年 4 月份正式宣布开源并一直在逐步开源的进程中。”\n他说，这就是他们憋了半天想出来的“段子”，哈哈哈，这群可爱的技术人啊。\n SOFA 的演进和开源之路 SOFA 中间件框架是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是一套分布式架构的完整的解决方案，也是在金融场景里锤炼出来的最佳实践。\nSOFA 开源全景图，涵盖了微服务领域的各个方面，同时也积极和业界流行的开源组件结合，包括阿里巴巴集团开源的Nacos、Sentinel等，为用户提供更加广泛地选择。\nSOFA 作为一个演进了几年的框架，也一定程度上代表了蚂蚁金服的技术体系的演变，并且现在形成了开源核心、开放式（组件式）开源的模式。SOFA 从 2018 年开始开源，但是我比较好奇 SOFA 开源之前的发展旅程是怎样的。\n杨冰说，“最早的时候，在蚂蚁金服还没有从淘宝分拆出来时，公司内使用过一个 …","date":1552287600,"description":"我们选择将 SOFA 中间件框架逐步开源出来，在贡献给社区的同时，也期待社区、合作伙伴甚至客户，都能够一起参与共建，形成行业标准和最佳实践。","dir":"blog/financial-technology-meet-open-source/","fuzzywordcount":6200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"620bf66a94dd1d8b872cb4cb90ca3028","permalink":"/blog/financial-technology-meet-open-source/","publishdate":"2019-03-11T15:00:00+08:00","readingtime":13,"relpermalink":"/blog/financial-technology-meet-open-source/","summary":"我们选择将 SOFA 中间件框架逐步开源出来，在贡献给社区的同时，也期待社区、合作伙伴甚至客户，都能够一起参与共建，形成行业标准和最佳实践。\u0026ndas","tags":["SOFAStack"],"title":"蚂蚁金服总监杨冰：金融科技公司为什么要拥抱开源？ | 穿山甲专访","type":"blog","url":"/blog/financial-technology-meet-open-source/","wordcount":6194},{"author":"潘潘","categories":"SOFAMeetup","content":"概要  活动主题：SOFA Meetup#1 北京站——服务注册中心、分布式事务重磅发布 活动时间：3 月 24 日周日下午 13 点 活动地点：北京中关村创业大街 氪空间 活动形式：线下活动 活动视频回顾：https://tech.antfin.com/community/activities/382  活动介绍 蚂蚁金服 SOFAStack SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁金服自主研发的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，历经蚂蚁金服超过十年的业务历练。SOFAStack 于 2018 年 4 月宣布开源，并逐步开源 SOFABoot、SOFARPC、SOFALookout、SOFATracer、SOFAMosn、SOFAMesh 等组件。 欢迎 Star 我：https://github.com/alipay\nSOFA Meetup#1 北京站-服务注册中心、分布式事务重磅发布 这次的 Meetup 是 SOFAStack 第一场线下活动，也是 SOFA 开源一周年的线下庆祝会。\n我们将带来重磅发布，继续补充 SOFAStack 的开源大图，届时除了 SOFA 团队的见面交流之外，也安排了周年的庆祝环节，期待与朋友们的见面。\n重磅发布：开源蚂蚁金服分布式事务 蚂蚁金服内部的分布式事务框架已经发展十多年，广泛用于解决各类复杂业务场景的数据一致性问题，同时经受大规模业务挑战，在高性能、高可用等方面也积累了丰富的实践经验。\n这次，将带来蚂蚁金服分布式事务十多年的技术总结分享，同时也会宣布开源版本。\n重磅发布：开源蚂蚁金服注册中心 SOFARegistry SOFARegistry 是蚂蚁金服开源的服务注册中心。\nSOFARegistry： https://github.com/alipay/sofa-registry\nSOFARegistry 最早源自于淘宝的初版 ConfigServer，在支付宝/蚂蚁金服的业务发展驱动下，近十年间已经演进至第五代。目前 SOFARegistry 不仅全面应用于蚂蚁金服的自有业务，还随着蚂蚁金融科技输出，助力广大合作伙伴，同时也兼容开源生态。SOFARegistry 最新一代内部版与商业版，均以开源版为基础内核，在其上开发内部特性插件。\n更多内容，到现场来看\n加入 SOFA 钉钉互动群 群号：23127468，使用钉钉搜索群号即可加入，获取一手开源技术干货。\n议程    时间 环节 嘉宾介绍     13:00 - 13:30  签到    13:40 - 14:20  《SOFAStack 开源这一年》 蚂蚁金服技术总监 杨冰   14:20 - 15:00 《SOFARegistry \u0026amp;ndash; 蚂蚁金服高性能服务注册中心开源》 蚂蚁金服服务注册中心开源负责人 尚彧   15:00 - 15:20 庆祝一周年环节    15:20 - 16:00  《SOFAFescar \u0026amp;ndash; 蚂蚁金服分布式事务开源以及实践》 蚂蚁金服分布式事务开源负责人 绍辉   16:00 - 16:40 《SOFAJRaft \u0026amp;ndash; 蚂蚁金服基于 RAFT 一致性算法的生产级高性能 Java 实现》 蚂蚁金服 SOFAJRaft 核心成员 力鲲   16:40 - 17:00  互动交流     ","date":1552277400,"description":"SOFA Meetup#1 北京站，3 月 24 日周日下午 13 点，北京中关村创业大街氪空间。","dir":"activities/sofa-meetup-1/","fuzzywordcount":1100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"dd713adb17a610bef8a0f6ed06cace55","permalink":"/activities/sofa-meetup-1/","publishdate":"2019-03-11T12:10:00+08:00","readingtime":3,"relpermalink":"/activities/sofa-meetup-1/","summary":"概要 活动主题：SOFA Meetup#1 北京站——服务注册中心、分布式事务重磅发布 活动时间：3 月 24 日周日下午 13 点 活动地点：北京中关村创业大街 氪空间 活动形式：","tags":["SOFAMeetup","SOFAStack"],"title":"SOFA Meetup#1 北京站——服务注册中心、分布式事务重磅发布","type":"activities","url":"/activities/sofa-meetup-1/","wordcount":1037},{"author":"SOFA 团队","categories":"SOFARPC","content":" SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。\nSOFA 文档: http://www.sofastack.tech/ SOFA: https://github.com/alipay\n 最新的 SOFARPC 5.5.1 已经发布啦，本文给大家介绍下 SOFARPC v5.5.x 系列主要提供的特性以及使用方式。\nSOFARPC 作为成熟的 RPC 框架，一直致力于给用户提供稳定可靠的 RPC 框架 以及最自主的选择权。SOFARPC 的插件扩展机制可以支持各类实现的可插拔实现。\nSOFARPC 5.5 主要给开发者们带来了服务发现的新选择：Nacos 的集成 与 服务容错对 Hystrix 的集成。\n服务注册 Nacos 新选择 Nacos 是阿里巴巴开源的一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。根据 Nacos 的 Roadmap，0.8.0 已具备生产使用的能力，截止笔者撰稿时间，Nacos 已发布 0.9.0，距离 1.0.0 越来越近了。\nSOFARPC 5.5.0 开始提供对 Nacos 的集成，以下介绍两种使用方式：\n1、SOFABoot 集成 Nacos SOFABoot 从 2.5.3 开始已集成 SOFARPC 对 Nacos 的配置支持，假如开发者本机已经根据 Nacos 快速开始安装并启动 Nacos Server。\n根据 RPC 的示例工程创建一个 SOFABoot 工程，SOFABoot 工程使用 2.5.3。\n$ git clone git@github.com:alipay/sofa-rpc-boot-projects.git $ git checkout 5.x 在 application.properties 中配置服务注册中心地址信息，就能够使用 Nacos 作为注册中心。\n$ vi sofa-boot-samples/src/main/resources/application.properties com.alipay.sofa.rpc.registry.address=nacos://127.0.0.1:8848 启动 RPC 服务端实例工程：\nrun com.alipay.sofa.rpc.samples.invoke.InvokeServerApplication 启动成功后即可在 Nacos 服务端看到服务注册信息：Nacos 服务列表 （注：如果用户自己部署了nacos 的服务端，可以通过这个地址访问）\n启动 RPC 客户端调用工程：\nrun com.alipay.sofa.rpc.samples.invoke.InvokeClientApplication 可以看到调用成功结果，分别代表同步、异步、回调调用成功：\nsync future callback client process:callback 2、SOFARPC 独立集成 Nacos SOFARPC 独立使用集成 Nacos 也很简单，只需要将注册中心地址设置为 Nacos 服务地址即可。\n引入 SOFARPC：\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-rpc-all\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;5.5.1\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; API 方式发布服务：\n# 构造服务注册中心配置 RegistryConfig registryConfig = new RegistryConfig() .setProtocol(\u0026amp;#34;nacos\u0026amp;#34;) .setSubscribe(true) .setAddress(\u0026amp;#34;127.0.0.1:8848\u0026amp;#34;) .setRegister(true); # 构造服务端口配置 ServerConfig serverConfig = new ServerConfig() .setProtocol(\u0026amp;#34;bolt\u0026amp;#34;) .setHost(\u0026amp;#34;0.0.0.0\u0026amp;#34;) .setPort(12200); # 构造服务发布者 ProviderConfig\u0026amp;lt;HelloService\u0026amp;gt; providerConfig = new ProviderConfig\u0026amp;lt;HelloService\u0026amp;gt;() .setInterfaceId(HelloService.class.getName()) .setRef(new HelloServiceImpl()) .setServer(serverConfig) .setRegister(true) .setRegistry(Lists.newArrayList(registryConfig)); providerConfig.export(); 即可发布服务至 Nacos Server。\n服务容错支持 Hystrix 在大规模的分布式系统中，一个完整的请求链路会跨越多个服务，其中每一个节点出现故障都将放大到全局，轻则造成执行逻辑崩溃，重则消耗掉所有资源拖垮整个系统。\nHystrix 是 Netflix 开源的容错组件，提供以下功能以解决该问题：\n 通过线程池或是信号量对资源进行隔离，避免依赖服务在故障时使用大量资源拖垮整个应用 使用熔断器模式（Circuit Breaker pattern）实现请求故障服务的快速失败（fail-fast），避免故障服务所造成的延时影响整体请求的延时 提供故障降级（Fallback）使用户可以编写优雅降级的策略，防止故障传递到上层 提供准实时的监控指标，使每一个依赖服务的请求结果和延时可观测  在 SOFARPC 中使用 Hystrix Hystrix 本身使用命令模式（Command pattern）实现了 API，我们在 SOFARPC 中对其进行了封装，只需要简单配置即可开启相关功能。\nHystrix 作为 SOFARPC 的可选模块默认不会进行加载，所以首先需要显式在项目中添加 Hystrix 依赖：\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.netflix.hystrix\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hystrix-core\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;1.5.12\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 然后通过开关选择开启全局的 Hystrix 支持，或是只对一部分 Consumer 开启：\n// 全局开启 RpcConfigs.putValue(HystrixConstants.SOFA_HYSTRIX_ENABLED, true); // 对特定 Consumer …","date":1551769200,"description":"最新的 SOFARPC 5.5.1 已经发布啦，本文给大家介绍下 SOFARPC v5.5.x 系列主要提供的特性以及使用方式。","dir":"blog/sofarpc-5.5.x-nacos-hystrix/","fuzzywordcount":2500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"c712254801354ae1b1bd22cd39b80ec2","permalink":"/blog/sofarpc-5.5.x-nacos-hystrix/","publishdate":"2019-03-05T15:00:00+08:00","readingtime":5,"relpermalink":"/blog/sofarpc-5.5.x-nacos-hystrix/","summary":"SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 SOFA 文档: http://www.sofastack.tech/ SOFA: https://github.com/alipay","tags":["SOFARPC"],"title":"SOFARPC 5.5.X 新版发布 | 集成 Nacos 与 Hystrix","type":"blog","url":"/blog/sofarpc-5.5.x-nacos-hystrix/","wordcount":2473},{"author":"花肉","categories":"SOFAChannel","content":"概要  活动主题：SOFAChannel#3：SOFARPC 性能优化（下）—— 手把手带你性能调优（含 Demo） 活动时间：2 月 28 日周四晚 7 点 活动形式：线上直播 直播视频回顾 直播回顾文章  介绍 SOFA:Channel/，有趣实用的分布式架构频道\n前沿技术、直播 Coding、观点“抬杠”，多种形式\nSOFA:Channel/ 将作为 SOFA 所有在线内容的承载，包含直播/音视频教程，集中体现 SOFAStack 的能力全景图。\n本期 SOFAChannel 为 SOFARPC 专场，分为上下两篇，将采用内容分享与 Demo 实际操作结合的形式进行。\n本期为上篇，下篇将在 2 月 28 日开展，记得关注哟~\n欢迎加入直播互动钉钉群：23127468（搜索群号加入即可）\n议程    SOFAChannel#2：SOFARPC 性能优化（上）—— 详解优化设计点 时间：2019-02-21      19:00-20:00 《SOFARPC 性能优化（上）—— 详解优化设计点》 蚂蚁金服 SOFA 团队 碧远    在业务规模大并发极高的情况下，RPC 对性能的追求就变得极为重要，任何一点小的优化都会累积提高业务整体性能。 本期手把手带你解读： 自定义通信协议使用有哪些注意细节？ SOFARPC 如何进行连接保持？ 在 IO 线程池中批量解包带来的性能提升有哪些？\n嘉宾 蚂蚁金服 SOFA 团队 碧远\n","date":1551349200,"description":"本次为下半场，2 月 28 日晚 7 点，线上直播。","dir":"activities/sofa-channel-3/","fuzzywordcount":500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"202f32cfe0c8a1c3aacbf435389a956f","permalink":"/activities/sofa-channel-3/","publishdate":"2019-02-28T10:20:00Z","readingtime":1,"relpermalink":"/activities/sofa-channel-3/","summary":"概要 活动主题：SOFAChannel#3：SOFARPC 性能优化（下）—— 手把手带你性能调优（含 Demo） 活动时间：2 月 28 日周四晚 7 点 活动形","tags":["SOFAChannel","SOFARPC"],"title":"SOFAChannel#3：SOFARPC 性能优化（下）—— 手把手带你性能调优（含 Demo）","type":"activities","url":"/activities/sofa-channel-3/","wordcount":477},{"author":"碧远","categories":"SOFARPC","content":" SOFA:Channel/，有趣实用的分布式架构频道。 本次是 SOFAChannel 第三期，SOFARPC 性能优化（下），进一步分享 SOFARPC 在性能上做的一些优化。 本期你将收获：\n 如何控制序列化和反序列化的时机； 如何通过线程池隔离，避免部分接口对整体性能的影响； 如何进行客户端权重调节，优化启动期和故障时的性能； 服务端 Server Fail Fast 支持，减少无效操作； 在 Netty 内存操作中，如何优化内存使用。  欢迎加入直播互动钉钉群：23127468，不错过每场直播。\n 大家好，今天是 SOFAChannel 第三期，欢迎大家观看。\n我是来自蚂蚁金服中间件的雷志远，花名碧远，目前负责 SOFARPC 框架的相关工作。在上一期直播中，给大家介绍了 SOFARPC 性能优化方面的关于自定义协议、Netty 参数优化、动态代理等的优化。\n 往期的直播回顾，可以在文末获取。\n本期互动中奖名单： @司马懿 @邓从宝 @雾渊，请文章下方回复进行礼品领取\n 今天我们会从序列化控制、内存操作优化、线程池隔离等方面来介绍剩余的部分。\n序列化优化 上次介绍了序列化方式的选择，这次主要介绍序列化和反序列化的时机、处理的位置以及这样的好处，如避免占用 IO 线程，影响 IO 性能等。\n上一节，我们介绍的 BOLT 协议的设计，回顾一下：\n可以看到有这三个地方不是通过原生类型直接写的：ClassName，Header，Content 。其余的，例如 RequestId 是直接写的，或者说跟具体请求对象无关的。所以在选择序列化和反序列化时机的时候，我们根据自己的需求，也精确的控制了协议以上三个部分的时机。\n对于序列化 serializeClazz 是最简单的：\nbyte[] clz = this.requestClass.getBytes(Configs.DEFAULT_CHARSET); 直接将字符串转换成 Byte 数组即可，跟具体的任何序列化方式，比如跟采用 Hessian 还是 Pb 都是无关的。\nserializeHeader 则是序列化 HeaderMap。这时候因为有了前面的 requestClass，就可以根据这个名字拿到SOFARPC 层或者用户自己注册的序列化器。然后进行序列化 Header，这个对应 SOFARPC 框架中的 SofaRpcSerialization 类。在这个类里，我们可以自由使用本次传输的对象，将一些必要信息提取到Header 中，并进行对应的编码。这里也不跟具体的序列化方式有关，是一个简单 Map 的序列化，写 key、写 value、写分隔符。有兴趣的同学可以直接看源码。\n源码链接：https://github.com/alipay/sofa-bolt/blob/531d1c0d872553d92fc55775565b3f7be8661afa/src/main/java/com/alipay/remoting/rpc/protocol/RpcRequestCommand.java#L66\nserializeContent 序列化业务对象的信息，这里 RPC 框架会根据本次用户配置的信息决定如何操作序列化对象，是调用 Hessian 还是调用 Pb 来序列化。\n至此，完成了序列化过程。可以看到，这些操作实际上都是在业务发起的线程里面的，在请求发送阶段，也就是在调用 Netty 的写接口之前，跟 IO 线程池还没什么关系，所以都会在业务线程里先做好序列化。\n对于反序列化 介绍完序列化，反序列化的时机就有一些差异，需要重点考虑。在服务端的请求接收阶段，我们有 IO 线程、业务线程两种线程池。为了最大程度的配合业务特性、保证整体吞吐，SOFABolt 设计了精细的开关来控制反序列化时机。\n具体选择逻辑如下：\n体现在代码的这个类中。\ncom.alipay.remoting.rpc.protocol.RpcRequestProcessor#process 从上图可以看到 反序列化 大致分成以下三种情况，适用于不同的场景。\n   IO 线程池动作 业务线程池 使用场景     反序列化 ClassName 反序列化 Header 和 Content 处理业务 一般 RPC 默认场景。IO 线程池识别出来当前是哪个类，调用用户注册的对应处理器   反序列化 ClassName 和 Header 仅反序列化 Content 和业务处理 希望根据 Header 中的信息，选择线程池，而不是直接注册的线程池   一次性反序列化 ClassName、Header 和 Content，并直接处理 没有逻辑 IO 密集型的业务    线程池隔离 经过前面的介绍，可以了解到，由于业务逻辑通常情况下在 SOFARPC 设置的一个默认线程池里面处理，这个线程池是公用的。也就是说， 对于一个应用，当他作为服务端时，所有的调用请求都会在这个线程池中处理。\n举个例子：如果应用 A 对外提供两个接口，S1 和 S2，由于 S2 接口的性能不足，可能是下游系统的拖累，会导致这个默认线程池一直被占用，无法空闲出来被其他请求使用。这会导致 S1 的处理能力受到影响，对外报错，线程池已满，导致整个业务链路不稳定，有时候 S1 的重要性可能比 S2 更高。\n因此，基于上面的设计，SOFARPC 框架允许在序列化的时候，根据用户对当前接口的线程池配置将接口和服务信息放到 Header 中，反序列化的时候，根据这个 Header 信息选择到用户自定义的线程池。这样，用户可以针对不同的服务接口配置不同的业务线程池，可以避免部分接口对整个性能的影响。在系统接口较多的时候，可以有效的提高整体的性能。\n内存操作优化 介绍完线程池隔离之后，我们介绍一下 Netty 内存操作的一些注意事项。在 Netty 内存操作中，如何尽量少的使用内存和避免垃圾回收，来优化性能。先看一些基础概念。\n内存基础 在 JVM 中内存可分为两大块，一个是堆内存，一个是直接内存。\n堆内存是 JVM 所管理的内存。所有的对象实例都要在堆上分配，垃圾收集器可以在堆上回收垃圾，有不同的运行条件和回收区域。\nJVM 使用 Native 函数在堆外分配内存。为什么要在堆外分配内存？主要因为在堆上的话， IO 操作会涉及到频繁的内存分配和销毁，这会导致 GC 频繁，对性能会有比较大的影响。\n注意：直接分配本身也并不见得性能有多好，所以还要有池的概念，减少频繁的分配。\n因此 JVM 中的直接内存，存在堆内存中的其实就是 DirectByteBuffer 类，它本身其实很小，真的内存是在堆外，通过 JVM 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。直接内存不会受到 Java 堆的限制，只受本机内存影响。当然可以设置最大大小。也并不是 Direct 就完全跟 Heap 没什么关系了，因为堆中的这个对象持有了堆外的地址，只有这个对象被回收了，直接内存才能释放。\n其中 DirectByteBuffer 经过几次 young gc 之后，会进入老年代。当老年代满了之后，会触发 Full GC。\n因为本身很小，很难占 …","date":1551337200,"description":"本文根据 SOFAChannel#3 直播分享整理，进一步分享 SOFARPC 在性能上做的一些优化。","dir":"blog/sofa-channel-3-retrospect/","fuzzywordcount":5800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"7a816fa5f942ce857c10ebb1c416482d","permalink":"/blog/sofa-channel-3-retrospect/","publishdate":"2019-02-28T15:00:00+08:00","readingtime":12,"relpermalink":"/blog/sofa-channel-3-retrospect/","summary":"SOFA:Channel/，有趣实用的分布式架构频道。 本次是 SOFAChannel 第三期，SOFARPC 性能优化（下），进一步分享 SOFARPC 在性能上做的一些优化。 本期你","tags":["SOFARPC","SOFAChannel"],"title":"SOFARPC 性能优化实践（下）| SOFAChannel#3 直播整理","type":"blog","url":"/blog/sofa-channel-3-retrospect/","wordcount":5775},{"author":"心贵","categories":"Kubernetes","content":" 此文章适合没有任何 Kubernetes/容器/Docker 经验的同学 —** 在不久的将来，你不懂如何操作 Kubernetes 接口，就等于现在的你不懂最普通的 Linux 命令。**此文章阅读耗时大概 15 分钟。\n 蚂蚁金服资源调度组致力于将 Kubernetes 落地到世界上最有价值的金融科技独角兽公司，欢迎联系作者微信： answer1991chen 咨询招聘事宜。\n文章 Markdown 源码位于 https://github.com/answer1991/articles/blob/master/Kubernetes-is-the-next-generation-os.md ，遵从 Apache License 2.0 开源协议。\n导言 此文章着重介绍如何在入门阶段使用 Kubernetes，以及要面向 Kubernetes 编程带来的优势，不会介绍复杂的 Kubernetes 架构、实现。因此此文章适合没有任何 Kubernetes/容器/Docker 经验的同学，对 Kubernetes 有了解的同学也可以从此文章里面获取一些灵感，可以更加酷炫的玩转 Kubernetes。\n希望在阅读完此文章之后，你可以从 “我需要一个 Linux VM 做开发、测试和部署”，变成 “我需要一个 Kubernetes 做开发、测试和部署”。\nKubernetes 是下一代操作系统 Kubernetes 是这几年非常热门的一个词汇，大概所有的软件工程师都已经听说过这个词。\n那么 Kubernetes 到底是什么呢？可能 Google 会告诉你很多，但是我想告诉你的是：Kubernetes 是下一代操作系统；一个 Kubernetes 集群是一个资源无限大(可扩容)的虚拟机。而且，Kubernetes 的接口是是声明式的，是天然面向分布式系统而设计的（下面会详细介绍）。\n说到这里，大家估计立刻就有疑问了。我想大概是这些：\n Q: 那么，Linux、Windows 要被淘汰了？\nA: 不会被淘汰，只是 Linux、Windows 是一个底层的单机操作系统。而我们这些普通的应用软件工程师将来都不会跟Linux 打交道了，都会使用 Kubernetes 这个更上层、同时功能也更强大的操作系统。\n Q: 那么，我不学 Kubernetes 可以吗？\nA: 不行！在未来不久的某一天，也许云厂商只卖 Kubernetes “虚拟机”了：阿里云不单独卖 ecs 了，亚马逊AWS，微软云，Google 云等各种云厂商都不卖 Linux 虚拟机了。如果你想买单机版的 Linux 虚拟机，他们都会一脸惊讶的问你，你买那么底层的、功能那么薄弱的计算机干什么？就像你现在从云厂商那里买不到一个还没有安装 Linux 的虚拟机一样。以后，云厂商交付的 “虚拟机” 必定是 “集群级别的虚拟机” ，而 “集群级别的虚拟机” 的操作系统就是 Kubernetes。\n在不久的将来，你不懂如何操作 Kubernetes 接口，就等于现在的你不懂最普通的 Linux 命令。\n Q: 那这样的话，我买不到 Linux 虚拟机，我连学习 Linux 的机会都没有了？\nA: 当然不是，有了 Kubernetes，你可以在 1秒内自己搞一个任何 Linux 发行版本的 “单机虚拟机” 出来。\n Q: Kubernetes 真的是一个操作系统？ Show me\u0026amp;hellip;.\nA:\n   功能/名词 单机 Linux Kubernetes 说明     Shell, CMD sh, bash kubectl kubectl 是 Kubernetes 的 shell 工具，有了 kubectl 你就可以连接并管理 Kubernetes 这个超级虚拟机了。   用户，登录 Linux User, Group, ssh 登录 kubeconfig 文件类似 Linux ssh 的 .key 文件，用户使用 kubeconfig 访问 Kubernetes 就自带了用户信息。Kubernetes 能根据用户限制权限，也能限制用户能使用的资源。kubectl 使用 kubeconfig 访问 Kubernetes 就好比使用 .ssh key 访问 Linux Kubernetes 集群管理员(或者自动化的申请系统)为用户颁发 kubeconfig 文件。   进程 进程 Pod Pod 就是 Kubernetes 这个 “超级虚拟机” 的进程。   管理进程 ps, kill kubectl get po, kubectl delete pod 发布、升级、管理 “进程”(或者说应用)   配置管理 登录各个 Linux VM，替换机器上的文件。 kubectl apply -f ./cm.yaml 使用 ConfigMap 管理应用的配置文件，一次提交，进程的每个实例自动生效新的配置。由于篇幅管理，使用 ConfigMap 配置应用（“进程”）启动参数不在此文章里面举例。   发布、管理、升级应用 在 Linux 上面发布一个应用，需要一顿疯狂的操作：先阅读如何发布、参数有什么、下载二进制包、搞定一些配置文件，然后运行应用。 kubectl apply -f ./my-app.yaml my-app.yaml 可能是应用提供商提供的、面向 Kubernetes 发布应用的“菜单”文件(为什么叫“菜单”我后面会介绍)。只要提交这个“菜单”，应用就部署好了。Kubernetes 让一切简单，而且，它是分布式，是天然容灾的。只要向 Kubernetes 提交 Deployment 这样的“资源”即可，下文有介绍。   限制应用资源 一顿疯狂的操作，把应用进程的 Cgroup 限制好。 发布应用时已经做了 Kubernetes 让一切简单。   分布式应用发布 在各个 Linux 虚拟机上面发布好应用，然后把他们组网。 发布应用时已经做了 还是那句话，Kubernetes 让一切简单。   分布式应用容灾 搞个监控，监控我们各个 Linux 虚拟机上面的应用是不是不健康了。不健康了的话，我们起床，来一次“一顿操作猛如虎”的故障恢复操作。 / 天然容灾，安心睡你的觉。   数据持久化，故障时数据迁移 “一顿操作猛如虎” 用 PV（持久化存储卷），容灾把应用的一个应用实例从 “节点一” 切换到了 “节点二”，都不用做任何数据迁移。新的应用实例起来就能使用老数据。 还是那句话，Kubernetes 让一切简单。我都不用关心这个事情。（由于篇幅管理，下文的例子中也不会涉及 PV 的例子）    “一顿操作猛如虎” 听起来很酷，但是你在做一些没必要的事情，同时你做了这些事情并不讨好你的老板，可能在因为你的失误操作引起更大的故障和问题。\n面向 Kubernetes 做最简单的操作，达到最佳的效果，才是更酷的事情。\n A: 行了行了，别说那么多了，我还是需要一个 Linux VM。\nQ: 好的，我给您一个 Kubernetes，然后给你一个 基础 OS Pod “菜单”文件，然后您自己就可以创建任何一个 Linux 发行版、任何一个 Linux …","date":1551078000,"description":"希望在阅读完此文章之后，你可以从 “我需要一个 Linux VM 做开发、测试和部署”，变成 “我需要一个 Kubernetes 做开发、测试和部署”。","dir":"blog/kubernetes-the-next-gen-os/","fuzzywordcount":8600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"09e6dbd10bffdeea13865fc45e3b3ee5","permalink":"/blog/kubernetes-the-next-gen-os/","publishdate":"2019-02-25T15:00:00+08:00","readingtime":18,"relpermalink":"/blog/kubernetes-the-next-gen-os/","summary":"此文章适合没有任何 Kubernetes/容器/Docker 经验的同学 —** 在不久的将来，你不懂如何操作 Kubernetes 接口，就等于现在的你不懂最普通的 Linux 命","tags":["Kubernetes"],"title":"Kubernetes 是下一代操作系统 | 面向 Kubernetes 编程","type":"blog","url":"/blog/kubernetes-the-next-gen-os/","wordcount":8599},{"author":"碧远","categories":"SOFARPC","content":" SOFA:Channel/，有趣实用的分布式架构频道。 本次是 SOFAChannel 第二期，主要分享 SOFARPC 在性能上做的一些优化，这个系列会分成上下两部分进行分享，今天是 SOFARPC 性能优化（上），也会对本次分享中的一些结论，提供部分代码 Demo，供大家了解验证。 欢迎加入直播互动钉钉群：23127468，不错过我们每场直播。\n 大家好，今天是我们 SOFAChannel 第二期。欢迎大家观看。\n我是来自蚂蚁金服中间件的雷志远，花名碧远，目前在负责 SOFARPC 框架相关工作。\n去年的时候，我们和外部的爱好者们一起，做了一个基于 SOFARPC 的源码解析系列，我同事已经发到群里了，大家可以保存，直播之后查看。\nSOFARPC 源码解析系列：（点击【剖析 | SOFARPC 框架】即可查看）\nhttps://www.sofastack.tech/blog/ 今年，基于源码解析的基础，我们来多讲讲实践，如何应用到大家的业务，来帮助大家解决实际问题。在直播过程中有相关的问题想提问，可以在钉钉群互动。\n前言 在上一期中，余淮分享了《从蚂蚁金服微服务实践谈起》。介绍了蚂蚁微服务的起源，以及之后服务化，单元化的情况。同时介绍了 SOFAStack 目前开源的情况。最后也分享了一下整个微服务中 SOFARPC 的设计与实现。\n本期，我们主要分享 SOFARPC 在性能上做的一些优化。这个系列会分成上下两部分进行分享，今天是 SOFARPC 性能优化（上），也会对本次分享中的一些结论，提供部分代码 Demo，供大家了解验证。\n我们先简要介绍一下 SOFARPC 的框架分层。这个在上次的分享中已经进行了介绍。\n下层是网络传输层，依次是协议，序列化，服务发现和 Filter 等。\nTransport 主要负责数据传输，可以是 Http2Transport，也可以是 BoltTransport，还有可能是其他。\nProtocol 层是协议，是 Rest 还是 Bolt ，或者是 Dubbo 。\nSerialization 是序列化，对于每种协议，可以是用不同的序列化方式，比如 hessian，pb，json 等。\nFilter 是通用的过滤器层，主要是为了留出一些扩展，完成一些其他扩展功能，比如 Tracer 的埋点等。\nRouter 是路由层，主要是做寻址，这里可能是 Zk，也可能是 LVS，也可能是直连。Cluster 是客户端集群方式的表示。\n自定义通讯协议使用 首先我想介绍一下自定义通讯协议。\n在说明自定义通讯协议之前，我先简单介绍一下通讯协议。在TCP之上，RPC框架通常还需要将请求和响应数据进行一定的封装，组装成 Packet，然后发送出去。这样，服务端收到之后，才能正确识别整个 TCP 发过来的字节流中，哪一部分是我们可以进行处理的一个完整单位。反之，客户端收到服务端的TCP 数据流也是如此。\n有了上面的共识之后，我们要回答下面两个问题：\n 为什么要自定义，不使用 Http2/Dubbo/Rest/Grpc？ 自定义之后，带来了什么好处呢？  Http2 虽然更为通用，但是一方面，出现较晚，迁移转换成本高，并且通用则意味着传输的辅助数据会变多，会有一些额外的信息需要传递或者判断。对于序列化反序列化的控制上，也不是很好扩展操作。\n而 Dubbo，协议简单强大。但是一些元信息需要解析，Header 中传输的数据太少，很多都需要依赖 body 中的数据反序列化完成后才能使用，头部的信息太少。\n而使用了自研的协议之后，Header 中可自定义传输更多的元信息，序列化方式，Server Fail Fast，服务端线程隔离等也都成为可能。甚至蚂蚁在 ServiceMesh 的场景下，Mesh 本身也能利用 Bolt 的协议，进行部分数据的读取，而不依赖具体的序列化实现。\n经过我们的实践，大致来看，目前给我们带来的好处主要有以下的能力：\n Server Fast 的支持 Header 和 Body 的分开序列化 Crc 校验的支持 版本的支持，预防未来可能出现的更好的设计方案 多种序列化方式的支持 安全认证，Mesh 路由  如果你要自己设计一个通讯协议。可以考虑使用 BOLT 协议，或者参考进行更好的设计和优化。\n关于 SOFABolt 相关的源码解析，也可以通过这个系列来了解。\nSOFABolt 源码解析系列：点击【剖析 | SOFABOLT 框架】即可查看） https://www.sofastack.tech/blog Netty 性能参数优化 在介绍了自定义通讯协议之后，也就是确定好了怎么封包解包之后，还需要确定传输层的开发。一个 RPC 框架从现在的情况来看，一般不太可能完全基于 JAVA 的 NIO 或者其他 IO 进行直接的开发，主要是一些 NIO 原生的问题和使用难度，而成熟的，目前可选的不多。基本上，大家都会基于 Netty 进行开发，HSF/Dubbo/Motan 等都是这样。\n直接使用是比较简单的。在 Netty 的 Bootstrap 的设置中，有一些可选的优化项，有必要跟大家分享一下。\n1. SO_REUSEPORT/SO_REUSEADDR - 端口复用(允许多个 socket 监听同一个IP+端口)\nSO_REUSEPORT 支持多个进程或者线程绑定到同一端口，提高服务器的接收链接的并发能力，由内核层面实现对端口数据的分发的负载均衡，在服务器 socket 上没有了锁的竞争。\n同时 SO_REUSEADDR也要打开，这样针对 time-wait 链接 ，可以确保 server 重启成功。在一些服务端启动很快的情况下，可以防止启动失败。\n2. TCP_FASTOPEN - 3次握手时也用来交换数据\n三次握手的过程中，当用户首次访问服务端时，发送 syn 包，server 根据客户端 IP 生成 cookie ，并与 syn+ack 一同发回客户端；客户端再次访问服务端时，在 syn 包携带 TCP cookie；如果服务端校验合法，则在用户回复 ack 前就可以直接发送数据；否则按照正常三次握手进行。也就是说，如果客户端中途断开，再建联的时候，会同时发送数据，会有一定的性能提升。\nTFO 提高性能的关键是省去了热请求的三次握手，这在小对象传输较多的移动应用场景中，能够极大提升性能。\nNetty 中仅在 Epoll 的时候可用 Linux特性，不能在 Mac/Windows 上使用，SOFARPC 未开启。\n3. TCP_NODELAY-关闭 (纳格) Nagle 算法，再小的包也发送，而不是等待\nTCP/IP 协议中针对 TCP 默认开启了 Nagle 算法。Nagle 算法通过减少需要传输的数据包个数，来优化网络。但是现在的环境下，网络带宽足够，需要进行关闭。这样，对于传输数据量小的场景，能很好的提高性能，不至于出现数据包等待。\n4. SO_KEEPALIVE –开启 TCP 层面的 Keep Alive 能力\n这个不多说，开启一下 TCP 层面的 Keep Alive 的能力。\n5. WRITE_BUFFER_WATER_MARK …","date":1551078000,"description":"本文根据 SOFAChannel#2 直播分享整理，主要分享 SOFARPC 在性能上做的一些优化。","dir":"blog/sofa-channel-2-retrospect/","fuzzywordcount":5100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"6751c882f7879a7dd9c9f49823410ffc","permalink":"/blog/sofa-channel-2-retrospect/","publishdate":"2019-02-25T15:00:00+08:00","readingtime":11,"relpermalink":"/blog/sofa-channel-2-retrospect/","summary":"SOFA:Channel/，有趣实用的分布式架构频道。 本次是 SOFAChannel 第二期，主要分享 SOFARPC 在性能上做的一些优化，这个系列会分成上下两部分进行分享，今天","tags":["SOFARPC","SOFAChannel"],"title":"SOFARPC 性能优化实践（上）| SOFAChannel#2 直播整理","type":"blog","url":"/blog/sofa-channel-2-retrospect/","wordcount":5080},{"author":"花肉","categories":"SOFAChannel","content":"概要  活动主题：SOFAChannel#2：SOFARPC 性能优化（上）—— 详解优化设计点 活动时间：2 月 21 日周四晚 7 点 活动形式：线上直播 直播视频回顾 直播回顾文章  介绍 SOFA:Channel/，有趣实用的分布式架构频道\n前沿技术、直播 Coding、观点“抬杠”，多种形式\nSOFA:Channel/ 将作为 SOFA 所有在线内容的承载，包含直播/音视频教程，集中体现 SOFAStack 的能力全景图。\n本期 SOFAChannel 为 SOFARPC 专场，分为上下两篇，将采用内容分享与 Demo 实际操作结合的形式进行。\n本期为上篇，下篇将在 2 月 28 日开展，记得关注哟~\n欢迎加入直播互动钉钉群：23127468（搜索群号加入即可）\n议程    SOFAChannel#2：SOFARPC 性能优化（上）—— 详解优化设计点 时间：2019-02-21      19:00-20:00 《SOFARPC 性能优化（上）—— 详解优化设计点》 蚂蚁金服 SOFA 团队 碧远    在业务规模大并发极高的情况下，RPC 对性能的追求就变得极为重要，任何一点小的优化都会累积提高业务整体性能。 本期手把手带你解读： 自定义通信协议使用有哪些注意细节？ SOFARPC 如何进行连接保持？ 在 IO 线程池中批量解包带来的性能提升有哪些？\n嘉宾 蚂蚁金服 SOFA 团队 碧远\n","date":1550744400,"description":"本次为上半场，2 月 21 日晚 7 点，线上直播。","dir":"activities/sofa-channel-2/","fuzzywordcount":500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"3140990819c0601c041bf5091405220b","permalink":"/activities/sofa-channel-2/","publishdate":"2019-02-21T10:20:00Z","readingtime":1,"relpermalink":"/activities/sofa-channel-2/","summary":"概要 活动主题：SOFAChannel#2：SOFARPC 性能优化（上）—— 详解优化设计点 活动时间：2 月 21 日周四晚 7 点 活动形式：线上直播 直播视","tags":["SOFAChannel","SOFARPC"],"title":"SOFAChannel#2：SOFARPC 性能优化（上）—— 详解优化设计点","type":"activities","url":"/activities/sofa-channel-2/","wordcount":468},{"author":"卫恒","categories":"SOFATracer","content":" SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。\nSOFATracer 是一个用于分布式系统调用跟踪的组件，通过统一的 TraceId 将调用链路中的各种网络调用情况以日志的方式记录下来，以达到透视化网络调用的目的，这些链路数据可用于故障的快速发现，服务治理等。\nSOFATracer：https://github.com/sofastack/sofa-tracer\n本文为《剖析 | SOFATracer 框架》第一篇。《剖析 | SOFATracer 框架》系列由 SOFA 团队和源码爱好者们出品，项目代号：SOFA:TracerLab/，目前领取已经完成，感谢大家的参与。\n 0、前言 在单体应用时代，我们不需要花费时间去关心调用链路这个东西。但是链路跟踪不仅仅是在分布式场景下才会有，即使是单体应用，同样也会存在调用链路。例如，我们把应用中的每个服务接口作为一个链路节点，那么从请求进来到返回响应，把这个过程中多历经的所有的方法接口串联起来，就能组成一条完整的链路，如下图所示：\n对于单体应用而言，如果访问一个资源没有成功，那么我们可以很快的锁定是哪一台机器，然后通过查询这台机器上的日志就能定位问题。\n但是在微服务体系架构下，这种方式会显得非常无力。对于一个稍具规模的应用来说，一次请求可能会跨越相当多的服务节点，在这种情况下，如果一个请求没有得到成功的响应，就不能确定到底是哪个节点出了问题。\n因此在面对这种复杂的大规模分布式集群来实现的服务体系来说，就需要一些可以帮助理解各个应用的线上调用行为、并可以分析远程调用的组件。\n基于上述背景，蚂蚁金服开源了基于 OpenTracing 规范实现的 SOFATracer 分布式链路跟踪组件，为实施大规模服务化体系架构场景下提供了链路跟踪的解决方案。\n在介绍 SOFATracer 之前，先来了解一下 Opentracing 规范。\n1、Opentracing 简介 首先来解释下 OpenTracing 是什么OpenTracing 致力于为分布式跟踪创建更标准化的API和工具，它由完整的API规范、实现该规范的框架、库以及项目文档组成。\nOpenTracing 提供了一套平台无关、厂商无关的 API，这样不同的组织或者开发人员就能够更加方便的添加或更换追踪系统的实现。 OpenTracing API 中的一些概念和术语，在不同的语言环境下都是共享的。\n1.1、数据模型 Opentracing 规范中，一条 trace 链路是由多个与之关联的 span 组成，一条链路整体可以看做是一张有向无环图，各个span之间的边缘关系被称之为“References”。下面是官方提供的示例：\n如果已时间轴维度来看的话，也可以表现为下面的形式(官方示例)：\n root span : 当前链路中的第一个 span ChildOf 和 FollowFrom 是目前被定义的两种 References 类型  ChildOf : 父级 span某种程度上取决于子span （子span的结果可能会对父span产生影响） FollowFrom : 父 Span不以任何方式依赖子 Span    但是为了简化 span 之间的这种依赖关系，在具体实现时通常会将具有嵌套关系的作为 ChildOf，平行执行的作为FollowFrom，比如：\na、ChildOf 示例\n在 methodA 中调用了 method B :\nmethodA(){ // spanA start  methodB(); } // spanA finish methodB(){ // spanB start } // spanB finish 产生的 span 在时间维度上展现的视角如下：\n这种关系一般会 表示为 SpanB ChildOf SpanA 。\nb、FollowFrom 示例\nmethod 方法中，methodA 执行之后 methodB 执行 :\nmethod(){ methodA(); methodB(); } 产生的 span 在时间维度上展现的视角如下：\n这种关系一般会 表示为 SpanB FollowFrom SpanA 。\n1.2、API Opentracing API 是对分布式链路中涉及到的一些列操作的高度抽象集合。Opentracing 中将所有核心的组件都声明为接口，例如 Tracer、Span、SpanContext、Format（高版本中还包括 Scope 和 ScopeManager）等。SOFATracer 使用的版本是 0.22.0 ，主要是对 Tracer、Span、SpanContext 三个概念模型的实现。下面就针对这三个组件结合 SOFATracer 来分析。\n1.3、SOFATracer 标准实现 下图为 SOFATracer 中对于这三个核心接口实现的类图结构：\n 由于篇幅原因，下面的介绍过程中一些点不会展开说明，有兴趣的同学可以自行官网查看完整的 OpenTracing-api 规范 （https://opentracing.io/specification/）。\n a、Tracer \u0026amp;amp; SofaTracer\nTracer 是一个简单、广义的接口，它的作用就是构建 span 和传输 span 。核心接口列表如下：\n   接口 描述     SpanBuilder buildSpan(String operationName) 根据指定的operationName构建一个新的span   void inject(SpanContext spanContext, Format format, C carrier); 将 spanContext 以 format 的格式注入到 carrier 中   SpanContext extract(Format format, C carrier); 以 format 的格式从carrier中解析出 SpanContext    SofaTracer 实现了 Tracer 接口，并扩展了采样、数据上报等能力。\nb、Span \u0026amp;amp; SofaTracerSpan\nSpan 是一个跨度单元，在实际的应用过程中，Span 就是一个完整的数据包，其包含的就是当前节点所需要上报的数据。核心接口列表如下：\n   接口 描述     SpanContext context() 从 span 中获取 SpanContext   void finish()/void finish(long finishMicros) 结束一个 span   void close() 关闭 span   Span setTag(String key, value) 设置 tags   Span log(long timestampMicroseconds, String event) 设置 log 事件   Span setOperationName(String operationName) 设 …","date":1550744400,"description":"本文为《剖析 | SOFATracer 框架》第一篇。","dir":"blog/sofa-tracer-overview/","fuzzywordcount":4200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"ff58d686746c53b81af210eaf17bb154","permalink":"/blog/sofa-tracer-overview/","publishdate":"2019-02-21T10:20:00Z","readingtime":9,"relpermalink":"/blog/sofa-tracer-overview/","summary":"SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 SOFATracer 是一个用于分","tags":["SOFATracer","SOFALab","剖析 | SOFATracer 框架"],"title":"蚂蚁金服分布式链路跟踪组件 SOFATracer 总览|剖析","type":"blog","url":"/blog/sofa-tracer-overview/","wordcount":4107},{"author":"卫恒","categories":"SOFATracer","content":" SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。\nSOFATracer 是一个用于分布式系统调用跟踪的组件，通过统一的 TraceId 将调用链路中的各种网络调用情况以日志的方式记录下来，以达到透视化网络调用的目的，这些链路数据可用于故障的快速发现，服务治理等。\n本文为《剖析 | SOFATracer 框架》第二篇。《剖析 | SOFATracer 框架》系列由 SOFA 团队和源码爱好者们出品，项目代号：SOFA:TracerLab/，目前领取已经完成，感谢大家的参与。\nSOFATracer：https://github.com/sofastack/sofa-tracer\n 0、前言 在《蚂蚁金服分布式链路跟踪组件 SOFATracer 总览|剖析》一文中已经对 SOFATracer 进行了概要性的介绍。从对 SOFATracer 的定义可以了解到，SOFATracer 作为一个分布式系统调用跟踪的组件，是通过统一的 TraceId 将调用链路中的各种网络调用情况以数据上报的方式记录下来，以达到透视化网络调用的目的。\n本篇将针对SOFATracer的数据上报方式进行详细分析，以帮助大家更好的理解 SOFATracer 在数据上报方面的扩展。\n1、Reporter 整体模型 本节将对 SOFATracer 的 Report 模型进行整体介绍，主要包括两个部分：\n Reporter 的接口设计及实现； 数据上报流程。  1.1、Reporter 的接口设计及实现 数据上报是 SofaTracer 基于 OpenTracing Tracer 接口扩展实现出来的功能；Reporter 实例作为 SofaTracer 的属性存在，在构造 SofaTracer 实例时，会初始化 Reporter 实例。\n1.1.1、Reporter 接口设计 Reporter 接口是 SOFATracer 中对于数据上报的顶层抽象，核心接口方法定义如下：\n//获取 Reporter 实例类型 String getReporterType(); //输出 span void report(SofaTracerSpan span); //关闭输出 span 的能力 void close(); Reporter 接口的设计中除了核心的上报功能外，还提供了获取 Reporter 类型的能力，这个是因为 SOFATracer 目前提供的埋点机制方案需要依赖这个实现。\n1.1.2、Reporter 接口实现 Reporter 的类体系结构如下：\nReporter 的实现类有两个，SofaTracerCompositeDigestReporterImpl 和 DiskReporterImpl ：\n SofaTracerCompositeDigestReporterImpl：组合摘要日志上报实现，上报时会遍历当前 SofaTracerCompositeDigestReporterImpl 中所有的 Reporter ，逐一执行 report 操作；可供外部用户扩展使用。 DiskReporterImpl：数据落磁盘的核心实现类，也是目前 SOFATracer 中默认使用的上报器。  1.2、数据上报流程分析 数据上报实际都是由不同的链路组件发起，关于插件扩展机制及埋点方式不是本篇范畴，就不展开了。这里直接来看数据上报的入口。\n在 Opentracing 规范中提到，Span#finish 方法是 span 生命周期的最后一个执行方法，也就意味着一个 span 跨度即将结束。那么当一个 span 即将结束时，也是当前 span 具有最完整状态的时候。所以在 SOFATracer 中，数据上报的入口就是 Span#finish 方法，这里贴一小段代码：\n//SofaTracerSpan#finish @Override public void finish(long endTime) { this.setEndTime(endTime); //关键记录:report span  this.sofaTracer.reportSpan(this); SpanExtensionFactory.logStoppedSpan(this); } 在 finish 方法中，通过 SofaTracer#reportSpan 将当前 span 进行了上报处理。以这个为入口，整个数据上报的调用链路如下图所示：\n整个上报调用流程其实并不是很难，这里留两个问题：\n 如何构造 clientRportor 和 serverReporter 的，依据是什么？ 摘要日志和统计日志是怎么落盘的？  第一个问题会在插件埋点解析篇中给出答案；第二个问题下面来看。\n2、日志落盘 前面已经提到，SOFATracer 本身提供了两种上报模式，一种是落到磁盘，另外一种是上报到zipkin。在实现细节上，SOFATracer 没有将这两种策略分开以提供独立的功能支持，而是将两种上报方式组合在了一起，然后再通过配置参数来控制是否进行具体的上报逻辑，具体参考下图：\n本节将来剖析下日志落盘的实现细节。日志落盘又分为摘要日志落盘 和 统计日志落盘；摘要日志是每一次调用均会落地磁盘的日志；统计日志是每隔一定时间间隔进行统计输出的日志。\n2.1、摘要日志落盘 摘要日志落盘是基于 Disruptor 高性能无锁循环队列实现的。SOFATracer 中，AsyncCommonDigestAppenderManager 类对 disruptor 进行了封装，用于处理外部组件的 Tracer 摘要日志打印。\n 关于 Disruptor 的原理及其自身的事件模型此处不展开分析，有兴趣的同学可以自行查阅相关资料。这里直接看下 SOFATracer 中是如何使用 Disruptor 的。\n 2.1.1、消息事件模型 SOFATracer 使用了两种不同的事件模型，一种是 SOFATracer 内部使用的 StringEvent，一种是外部扩展使用的SofaTacerSpanEvent。详见：SofaTracerSpanEvent \u0026amp;amp; StringEvent 。\n2.1.2、Consumer 消费者 Consumer 是 AsyncCommonDigestAppenderManager 的内部类；实现了 EventHandler 接口，这个 Consumer 作为消费者存在，监听事件，然后通过 TraceAppender 将 span 数据 flush 到磁盘。详见：AsyncCommonDigestAppenderManager\n2.1.3、Disruptor 的初始化  Disruptor 的构建：在 AsyncCommonDigestAppenderManager 的构造函数中完成的。  //构建disruptor，使用的是 ProducerType.MULTI //等待策略是 BlockingWaitStrategy，考虑到的是CPU的使用 …","date":1550744400,"description":"本文为《剖析 | SOFATracer 框架》第二篇。","dir":"blog/sofa-tracer-response-mechanism/","fuzzywordcount":5100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"350b5d9eacee1bc4b3b604236b247a3c","permalink":"/blog/sofa-tracer-response-mechanism/","publishdate":"2019-02-21T10:20:00Z","readingtime":11,"relpermalink":"/blog/sofa-tracer-response-mechanism/","summary":"SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 SOFATracer 是一个用于分","tags":["SOFATracer","SOFALab","剖析 | SOFATracer 框架"],"title":"蚂蚁金服分布式链路跟踪组件 SOFATracer 数据上报机制和源码剖析","type":"blog","url":"/blog/sofa-tracer-response-mechanism/","wordcount":5014},{"author":"米麒麟","categories":"SOFATracer","content":" SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。\nSOFATracer 是一个用于分布式系统调用跟踪的组件，通过统一的 TraceId 将调用链路中的各种网络调用情况以日志的方式记录下来，以达到透视化网络调用的目的，这些链路数据可用于故障的快速发现，服务治理等。\n本文为《剖析 | SOFATracer 框架》第四篇，本篇作者米麒麟，来自陆金所。《剖析 | SOFATracer 框架》系列由 SOFA 团队和源码爱好者们出品，项目代号：SOFA:TracerLab/**，**目前领取已经完成，感谢大家的参与。\nSOFATracer： https://github.com/sofastack/sofa-tracer\n 前言 由于分布式链路追踪涉及到调用的每个环节，而每个环节都会产生大量的数据，为了存储这种数据，可能需要大量的成本，另外在实际的生产过程中并非所有数据都是值得关注的，基于这些原因，SOFATracer 提供链路数据采样功能特性，一方面可以节约 I/O 磁盘空间，另一方面需要把无关数据直接过滤筛选。目前 SOFATracer 内置两种采样策略，一种是基于固定比率的采样，另一种是基于用户扩展实现的自定义采样。自定义采样模式将 SofaTracerSpan 实例作为采样计算的条件，用户可以基于此实现自行扩展自定义的采样规则。\n本篇文章主要介绍 SOFATracer 数据采样策略原理，通过剖析源码实现详细讲述采样规则算法。\nDapper 论文中的采样模型与策略 跟踪采样模型 每个请求都会利用到大量服务器高吞吐量的线上服务，这是对有效跟踪最主要的需求之一。这种情况需要生成大量的跟踪数据，并且他们对性能的影响是最敏感的。延迟和吞吐量带来的损失在把采样率调整到小于1/16之后就能全部在实验误差范围内。\n在实践中，我们发现即便采样率调整到 1/1024 仍然是有足够量的跟踪数据用来跟踪大量的服务。保持链路跟踪系统的性能损耗基线在一个非常低的水平是很重要的，因为它为那些应用提供了一个宽松的环境使用完整的 Annotation API 而无惧性能损失。使用较低的采样率还有额外好处，可以让持久化到硬盘中的跟踪数据在垃圾回收机制处理之前保留更长时间，这样为链路跟踪系统的收集组件提供更多灵活性。\n分布式链路跟踪系统中任何给定进程的消耗和每个进程单位时间的跟踪采样率成正比。然而，在较低的采样率和较低的传输负载下可能会导致错过重要事件，而想用较高的采样率就需要能接受的相应的性能损耗。我们在部署可变采样的过程中，参数化配置采样率时，不是使用一个统一的采样方案，而是使用一个采样期望率来标识单位时间内采样的追踪。这样一来，低流量低负载会自动提高采样率，而在高流量高负载的情况下会降低采样率，使损耗一直保持在控制之内。实际使用的采样率会随着跟踪本身记录下来，这有利于从跟踪数据里准确分析排查。\n跟踪采样策略 要真正做到应用级别的透明，我们需要把核心跟踪代码做的很轻巧，然后把它植入到那些无所不在的公共组件中，比如线程调用、控制流以及 RPC 库。使用自适应的采样率可以使链路跟踪系统变得可伸缩，并且降低性能损耗。链路跟踪系统的实现要求性能低损耗，尤其在生产环境中不能影响到核心业务的性能，也不可能每次请求都跟踪，所以要进行采样，每个应用和服务可以自己设置采样率。采样率应该是在每个应用自己的配置里设置的，这样每个应用可以动态调整，特别是应用刚上线时可以适当调高采样率。一般在系统峰值流量很大的情况下，只需要采样其中很小一部分请求，例如 1/1000 的采样率，即分布式跟踪系统只会在 1000 次请求中采样其中的某一次。\n在 Dapper 论文中强调了数据采样的重要性，如果将每条埋点数据都刷新到磁盘上会增大链路追踪框架对原有业务性能的影响。如果采样率太低，可能会导致一些重要数据的丢失。 论文中提到如果在高并发情况下 1/1024 的采样率是足够的，也不必担心重要事件数据的丢失。因为在高并发环境下，一个异常数据出现一次，那么就会出现1000次。 然而在并发量不是很多的系统，并且对数据极为敏感时需要让业务开发人员手动设置采样率。\n对于高吞吐量服务，积极采样并不妨碍最重要的分析。如果一个显著的操作在系统中出现一次，他就会出现上千次。低吞吐量服务可以负担得起跟踪每一个请求。这是促使我们下决心使用自适应采样率的原因。为了维持物质资源的需求和渐增的吞吐要求之间的灵活性，我们在收集系统自身上增加了额外的采样率支持。\n如果整个跟踪过程和收集系统只使用一个采样率参数确实会简单一些，但是这就不能应对快速调整在所有部署节点上的运行期采样率配置的这个要求。我们选择了运行期采样率，这样就可以优雅的去掉我们无法写入到仓库中的多余数据。我们还可以通过调节收集系统中的二级采样率系数来调整这个运行期采样率。Dapper 的管道维护变得更容易，因为我们可以通过修改二级采样率的配置，直接增加或减少全局覆盖率和写入速度。\nSOFATracer 的采样源码剖析 SOFATracer 提供链路数据采样功能特性，支持两种采样策略：基于固定采样率的采样模式和基于用户扩展实现的自定义采样模式。\n采样接口模型 SOFATracer 提供定义链路追踪数据采样模式接口 com.alipay.common.tracer.core.samplers.Sampler，此接口 sample 方法通过 SofaTracerSpan 实例参数作为采样计算基础条件决定链路是否采样，实现丰富的数据采样规则。SOFATracer 基于 com.alipay.common.tracer.core.samplers.SamplerFactory 生成的采样器执行链路数据采样基本流程：\n 构建链路追踪器，通过采样器工厂 SamplerFactory 根据自定义采样规则实现类全限定名配置生成指定策略采样器 Sampler，其中基于用户扩展实现的采样模式优先级高，默认采样策略为基于固定采样率的采样计算规则； Reporter 数据上报 reportSpan 或者链路跨度 SofaTracerSpan 启动调用采样器 sample 方法检查链路是否需要采样，获取采样状态 SamplingStatus 是否采样标识 isSampled。  采样器的初始化 上面分析到，采样策略实例是通过 SamplerFactory 来创建的，SamplerFactory 中提供了一个 getSampler 方法用于获取采样器： 从代码片段来看，用户自定义的采样策略将会优先被加载，如果在配置文件中没有找到自定义的 ruleClassName ，则构建默认的基于固定采样率的采样器。SamplerProperties 是采样相关的配置属性，默认提供的基于固定比率的采样率是 100%，即默认情况下，所有的 Span 数据都会被记录到日志文件中。关于具体配置，在下文案例中会有详细介绍。\n采样计算 采样是对于整条链路来说的，也就是说从 RootSpan 被创建开始，就已经决定了当前链路数据是否会 …","date":1550744400,"description":"本文为《剖析 | SOFATracer 框架》第四篇，本篇作者米麒麟，来自陆金所。","dir":"blog/sofa-tracer-sampling-tracking-deep-dive/","fuzzywordcount":4300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"552e5d7feb431d3ff658a0194ead7b8f","permalink":"/blog/sofa-tracer-sampling-tracking-deep-dive/","publishdate":"2019-02-21T10:20:00Z","readingtime":9,"relpermalink":"/blog/sofa-tracer-sampling-tracking-deep-dive/","summary":"SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 SOFATracer 是一个用于分","tags":["SOFATracer","SOFALab","剖析 | SOFATracer 框架"],"title":"蚂蚁金服开源分布式链路跟踪组件 SOFATracer 采样策略和源码剖析","type":"blog","url":"/blog/sofa-tracer-sampling-tracking-deep-dive/","wordcount":4228},{"author":"J. Queue","categories":"SOFATracer","content":" SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。\nSOFATracer 是一个用于分布式系统调用跟踪的组件，通过统一的 TraceId 将调用链路中的各种网络调用情况以日志的方式记录下来，以达到透视化网络调用的目的，这些链路数据可用于故障的快速发现，服务治理等。\n 本文为《剖析 | SOFATracer 框架》第三篇。《剖析 | SOFATracer 框架》系列由 SOFA 团队和源码爱好者们出品，项目代号：SOFA:TracerLab/**，**目前领取已经完成，感谢大家的参与。 SOFATracer：https://github.com/sofastack/sofa-tracer\nSOFATracer 是一个用于分布式系统调用跟踪的组件，其核心作用就是能够在分布式场景下将请求经过的各个的链路环节的相关数据记录下来，通过这些数据将各个调用链路相关的组件串联起来。\n在日常的开发中，我们除了跟踪链路外，可能还会遇到一些场景：\n例如在线压测，我们在已有的系统中，模拟一些请求（压测流量）对我们的系统进行压力测试，那么在整个链路中我们是如何让所有的系统都识别出当前的请求是压测流量而不是正式流量的呢？压测流量的标记又是如何在整个链路传递的呢？\n又例如我们已经有了链路数据分析能力，能够快速定位到某个请求是在 A 系统里出的问题，那么我们怎么从 A 系统的业务日志里找到当前请求对应的业务日志呢？\n带着这些问题，让我们先来看看 SOFATracer 的链路透传以及支持 SLF4J MDC 扩展能力。\nSOFATracer 链路透传原理 SOFATracer 的链路透传具体包括两个点：\n 跨进程的透传，即如何将链路数据从一个进程传递到下游进程中 线程中的透传  当前请求跨进程调用结束之后，当前如何恢复 tracer 上下文信息 如何实现跨线程的透传，如在当前线程中起一个异步线程的场景    跨进程链路透传原理 跨进程透传就是将上游系统的链路数据透传到下游系统中，以便于提取出全局的链路标记，如 TracerId 、采样标记等，来实现将服务串联起来并且保持传输过程中某些属性的一致性。SOFATracer 基于 Opentracing 规范实现，因此在链路透传部分，也是基于此规范；下面就先从 Opentracing 规范中的透传开始说起。\nOpentracing 中的定义 在 OT 原文有这么一段描述 传送门\n Programmers adding tracing support across process boundaries must understand the Tracer.Inject(...)and Tracer.Extract(...) capabilities of the OpenTracing specification. They are conceptually powerful, allowing the programmer to write correct_general cross-process propagation code without being bound to a particular OpenTracing implementation; that said, with great power comes great opportunity for confusion.\n 大概意思就是：如果开发者要给应用添加跨进程的追踪能力, 首先要理解 OpenTracing 规范中的 Tracer.Inject(...)和 Tracer.Extract(…)的功能。它们在概念抽象上非常强大，而且允许开发者编写正确的、通用的跨进程传输的代码，而不需要绑定到特定的 OpenTracing 实现上去。\n总的来说就是 Opentracing 的 Tracer 接口定义了跨进程的能力，但是就是没具体实现，不同的基于此规范实现的组件，需要遵循此规范来实现具体的透传逻辑，下面是 Tracer 接口定义的用于透传的两个方法：\n   接口 描述     void inject(SpanContext spanContext, Formatformat, C carrier); 把 spanContext 以指定的 format 的格式注入到 carrier 中   SpanContext extract(Format format, C carrier); 以指定的 format 的格式从 carrier 中解析出 SpanContext    进程透传实现分析 SOFATracer 的 Tracer 的实现类是 SofaTracer， UML 图如下：\n从图中可以看出 SofaTracer 除了有跨进程传输的能力，还扩展了数据上报的能力( Reporter )和采样能力( Sampler )。数据上报能力可以参考《SOFATracer 数据上报机制和源码分析|剖析》这篇文章；采样将在下一篇文章中进行剖析。\n跨进程透传的就是 SpanContext 的内容， carrier 为传输的载体， SpanContext 的实现类为 SofaTracerSpanContext， UML 图：\n跨进程透传处理流程 SOFATracer 中跨进程传输的总体流程如下图所示：\n透传原理的实质就是：调用方编码将指定内容传输到被调方， 被调方解码获取内容的过程。\n跨进程透传的方式有很多， 在这里以客户端向服务端发起 HTTP 请求的方式来演示跨进程传输， fork 代码， 打开 sample/tracer-sample-with-httpclient 示例工程运行 HttpClientDemoApplication ，打开 logs/tracelog/spring-mvc-stat.log 即可看到链路日志， 运行结果 ：\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2019-01-07 19:42:50.134\u0026amp;#34;,\u0026amp;#34;stat.key\u0026amp;#34;:{\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;GET\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;HttpClientDemo\u0026amp;#34;,\u0026amp;#34;request.url\u0026amp;#34;:\u0026amp;#34;http://localhost:8080/httpclient\u0026amp;#34;},\u0026amp;#34;count\u0026amp;#34;:1,\u0026amp;#34;total.cost.milliseconds\u0026amp;#34;:1563,\u0026amp;#34;success\u0026amp;#34;:\u0026amp;#34;true\u0026amp;#34;,\u0026amp;#34;load.test\u0026amp;#34;:\u0026amp;#34;F\u0026amp;#34;} {\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2019-01-07 …","date":1550744400,"description":"本文为《剖析 | SOFATracer 框架》第三篇。","dir":"blog/sofa-tracer-unvarnished-transmission-slf4j-mdc/","fuzzywordcount":6300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"82a08996dd671b01595748aa2d2fa748","permalink":"/blog/sofa-tracer-unvarnished-transmission-slf4j-mdc/","publishdate":"2019-02-21T10:20:00Z","readingtime":13,"relpermalink":"/blog/sofa-tracer-unvarnished-transmission-slf4j-mdc/","summary":"SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 SOFATracer 是一个用于分","tags":["SOFATracer","SOFALab","剖析 | SOFATracer 框架"],"title":"蚂蚁金服开源分布式链路跟踪组件 SOFATracer 链路透传原理与SLF4J MDC 的扩展能力剖析","type":"blog","url":"/blog/sofa-tracer-unvarnished-transmission-slf4j-mdc/","wordcount":6298},{"author":"卫恒","categories":"SOFABoot","content":" SOFABoot 是基于 Spring Boot 的一套研发框架。 在完全兼容 Spring Boot 的基础上，SOFABoot 还提供了启动期监控检查，上下文隔离，模块化开发，类隔离，日志空间隔离等等能力 SOFABoot 地址：https://github.com/alipay/sofa-boot 本文工程案例：https://github.com/glmapper/glmapper-sofa-extension\n 春节小长假还没感觉就过去了，对于“热爱工作”的我，也早早的回到了工作岗位；感受下假期中的我和上班时的我。\n 后面拿枪的就是\u0026amp;quot;逼着\u0026amp;quot;我写文章的五花肉，上次 SOFATracer 采样用的是刀，这次用了枪！\n 模块化与扩展点 言归正传，节前 SOFABoot 发布了 2.6.x 系列版本，新特性也是相当给力，这里简单罗列下新特性：\n 支持扩展和扩展点 在刷新上下文期间支持 spring bean 的并行初始化 支持使用注解方式发布 JVM 服务  之前的文章中有 @玄北 写过的模块化的文章( 传送门 : 剖析 | 详谈 SOFABoot 模块化原理 \u0026amp;amp; 基于 SOFABoot 进行模块化开发 )，这两篇文章中介绍了模块化的几种实现方案（PS：当然主要还是为了宣传一下 SOFABoot 提供的基于 Spring 上下文隔离的模块化能力）。SOFABoot 的模块隔离方案是为了解决传统的模块化方案模块化不彻底的问题，从 2.4.0 版本开始支持基于 Spring 上下文隔离的模块化能力，每个 SOFABoot 模块使用独立的 Spring 上下文，每个模块自包含，模块与模块之间通过 JVM Service 进行通信，从而避免模块间的紧耦合。\n在 Spring 上下文隔离的情况下，各个上下文之间的 bean 是互不可见；SOFABoot 中通过发布 JVM 服务的方式使得不同模块 bean 之间的访问得以实现。但是同时又带来了另外一个问题，如果一个模块以独立 jar 的方式对外提供 api ，那么对于其他依赖此模块的模块来说，就无法去改变这个模块中的 bean 实例行为。\n在实际的使用场景中，一个模块中的 bean 有时候需要开放一些入口，供另外一个模块扩展。SOFABoot 借鉴和使用了 Nuxeo Runtime 项目 以及 nuxeo 项目，并在上面扩展，与 Spring 融合，提供了扩展点的能力。\n本篇将针对 SOFABoot 2.6.x 版本中提供的扩展点进行简单尝试，结合官方文档提供的示例，一步一步实现我们自定义的一个扩展点功能（本文过于简单，可能会引起极度舒适，请备好被子和热水袋）。\n案例背景 这里先抛出一个例子，现在有一个三方 jar ，它定义了获取数据源接口的顶层抽象；不同的业务方如果依赖这个 jar，则需要自己提供一个数据源的实现，当然其本身提供了默认实现（假设是 mysql）。基于此我们大概能够想到的方式就是基于 SPI 来提供这种扩展能力，但是对于在 Spring 上下文隔离的情况下，业务方的 Spring 上下文是无法与引入 jar 的上下文共享 bean 的，这样自然也就无法实现对原有数据源实现的扩展。\n那么这里我们就可以选择使用 SOFABoot 扩展点来实现，这里有两个比较重要的概念，也是扩展点区别于 SPI 的主要特性：\n 可以在基于 Spring 上下文隔离的情况下实现扩展 扩展的是 Spring Bean   下面基于这两个点，来完成自定义扩展点的一个案例。在实现上述案例之前我们需要先构建一个基于 Spring 上下文隔离的模块化工程，然后再简单介绍下扩展点的基本使用方式。\n构建模块化工程 SOFABoot 开源版本中并没有给出扩展点相关的案例工程，只是在测试用例中进行了详细的测试，有兴趣的同学可以看下相关测试用例代码。实际上测试用例中也没有涉及到在模块化的场景下使用扩展点，测试用例都是基于同一个Spring 上下文来完成的。本篇文章将先搭建一个简单的模块化工程，然后基于此工程来实现扩展点的能力。\n本工程主要包括 4 个模块：\n glmapper-sofa-facade // JVM 服务发布与引用的 API 包 glmapper-sofa-provider // Annotation 方式发布 JVM 服务 glmapper-sofa-consumer // Annotation 方式引用 JVM 服务 glmapper-sofa-web // 启动包含 SOFABoot 模块的 SOFA Boot 应用  官方文档及案例 中给的比较复杂，包含了多种使用服务发布和引用的方式，这里我使用了最新提供的基于注解的方式来实现；获取本文工程案例。\n扩展点基本使用 在 SOFABoot 中使用扩展点能力，需要以下三个步骤：\n 定义提供扩展能力的 bean 定义扩展点 定义扩展并使用  这三步中前两步都是由服务提供方来完成，最后一步由具体的业务使用方式来定义。\n定义提供扩展能力的 bean 本案例工程中，是将 glmapper-sofa-provider 作为服务提供方，因此也在此模块下定义一个具有扩展能力的 bean 。\n定义这个接口的实现：\n在模块的 Spring 配置文件 resources/META-INF/service-provider.xml 中，我们把这个 bean 给配置起来：\n定义扩展点 在上面的 bean 中有一个字段 word ，在实际中，我们希望这个字段能够被其他的模块自定义进行覆盖，这里我们将其以扩展点的形式暴露出来。这里先定义一个类去描述这个扩展点：\n然后在模块的 Spring 配置文件 resources/META-INF/service-provider.xml 中定义扩展点：\n name：为扩展点的名字 ref：为扩展点所作用在的 bean object：为扩展点的贡献点具体的描述，这个描述是通过 XMap 的方式来进行的（XMap 的作用是将 Java 对象和 XML 文件进行映射，这里建议通过在网上搜索下 XMap 的文档来了解 XMap）  至此服务提供端已经暴露出了扩展点，那么在服务使用端，也就是需要扩展这个 bean 的使用方就可以扩展这个bean 了。\n定义扩展 上述已经将扩展点定义好了，此时我们就可以对这个 bean 进行扩展了。扩展是具体业务使用方来做的事，在本案例中，glmapper-sofa-web 模块作为使用服务使用方，因此在 resources/META-INF/spring/web-home.xml 下进行扩展定义：\n bean：为扩展所作用在的 bean point：为扩展点的名字 content 里面的内容为扩展的定义，会通过 XMap 将内容解析为：扩展点的贡献点具体的描述对象，在这里即为 com.glmapper.bridge.extension.ExtensionDescriptor 对象   需要注意一点，glmapper-sofa-web 模块不是一个 SOFABoot 模块，这里留坑。\n 编写一个 TestController 类，这里最先参考的 …","date":1550127600,"description":"本文根据 SOFAChannel#5 直播分享整理，主题：给研发工程师的代码质量利器 —— 自动化测试框架 SOFAActs。","dir":"blog/sofa-boot-extension-practice/","fuzzywordcount":3800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"4f05313f7adf5401f3b5f499b43bb928","permalink":"/blog/sofa-boot-extension-practice/","publishdate":"2019-02-14T15:00:00+08:00","readingtime":8,"relpermalink":"/blog/sofa-boot-extension-practice/","summary":"SOFABoot 是基于 Spring Boot 的一套研发框架。 在完全兼容 Spring Boot 的基础上，SOFABoot 还提供了启动期监控检查，上下文隔离，模块化开发，类隔离，日志空间隔离等等","tags":["SOFABoot"],"title":"SOFABoot 扩展点初体验 | SOFALab 实践系列","type":"blog","url":"/blog/sofa-boot-extension-practice/","wordcount":3779},{"author":"余淮","categories":"SOFAStack","content":" SOFA:Channel/，有趣实用的分布式架构频道。 SOFA:Channel/ 作为 SOFA 所有在线内容的承载，包含直播/音视频教程，集中体现 SOFAStack 的能力全景图。欢迎加入直播互动钉钉群：23127468（搜索群号加入即可）。\n 大家晚上好，今天是 SOFAChannel 第一次线上直播，感谢大家的收看。\n先自我介绍下，我是来自蚂蚁金服中间件的章耿，花名余淮，目前在负责应用框架与 SOFAStack 开源相关的工作。\n今天给大家的分享主要分为三部分，第一部分是蚂蚁金服服务化演进的简介，第二部分是SOFAStack开源的情况。这两部分之前的分享也提到过，我们讲快一点，第三部分会详细介绍下 SOFARPC 的一些设计和实现细节。\n分享过程中如果大家对技术点比较感兴趣，或者其他组件感兴趣，也欢迎留言，后面的直播会安排更多的相关分享。\n蚂蚁服务化架构演进简介 大家现在对蚂蚁金服技术的概念，听得比较多的应该是“余额宝”、“相互宝”、“蚂蚁森林”、“刷脸支付”，“扫描工具地铁”、“双十一”等等这些耳耳熟能详的产品和场景。\n这些产品的背后，是蚂蚁金融科技的一套核心技术，包括 “三地五中心异地多活架构”，“金融级分布式架构”、“国产金融级分布式数据库 OceanBase”，“智能风控”，“区块链” 等诸多黑科技。\n当然，蚂蚁金服的微服务架构体系像其它传统的企业一样，也不是一开始就这么高大上，也是随着业务的发展慢慢演进而来的。下面给大家简单介绍下演进的过程。\n这个支付宝最早的架构示意图，可以看到当时支付宝只是电商后台的一个支付系统，是一个单体应用，里面简单的分了几个业务模块，连的也是一个数据库。但随着业务规模的不断扩展，单系统架构已经无法满足业务需求。\n所以支付宝就对大系统进行了拆分，将原来的一个单体应用内部的多个模块变成了多个独立的子系统，这算是典型的 SOA 化的架构。\n最开始系统之间是使用 F5 的硬件负载设备来做系统间的负载均衡，但由于 F5 设备存在单点的问题，所以后面就在中间引入一个注册中心的组件。服务提供者去注册中心注册服务，服务消费者去注册中心订阅服务列表，服务消费者通过软负载方式通过 RPC 框架直接调用服务提供者。这在现在看来是一种非常显而易见的服务化架构，但当时 07 年就采用这样的架构还是算比较超前的。\n支付宝在做系统拆分的同时，对数据库也按子系统进行了垂直拆分。数据库的拆分就会引入分布式事务的问题，蚂蚁金服中间件就提供了基于 TCC 思想的分布式事务组件 DTX。\n业务还是不断扩展，系统也越来越多，当系统节点到一定数量的时候，单个物理机房已经无法承受。另外考虑到同城容灾的问题，支付宝就在同城再扩建另外一个机房，通过专线部署为一个内部网络，然后将应用部署上去。\n同城多机房会引入一个跨机房远程访问的问题，相比同机房调用，这个延迟损耗一定是更高的。远程访问主要包括两种：RPC 调用和数据库访问。为了解决 RPC 跨机房调用的问题，支付宝的工程师选择的方案是在每个机房都部署注册中心，同机房优先调用本机房服务的方式，也就变成图中的部署模式。但是数据库跨机房访问的问题，在这个阶段并没有解决。\n另外还存在的一个问题就是调用链路混乱以及数据库连接瓶颈的调用。例如这个图里，我们对数据进行了分片，然后图中的 user0 的请求进来后，随机转到 S2，再随机转到B0，在随机到C1，最终跟进数据分配落到了数据库 D0。可以看到这里的调用链路是随机的，而每一个核心层也需要跟所有的分库都建立长连接。\n为了解决上面的跨机房数据访问、数据库连接数瓶颈以及未来数据水平扩展的问题，蚂蚁的工程师们设计了一套单元化的架构，这是单元化的一个示意图。\n在没有单元化的时候，用户请求进入内部后，所有请求链路都是随机走的，例如图里的 S0 到 B1 到 C2 到 D0。首先蚂蚁的请求都是跟用户相关的，所以我们将数据按用户的维度进行水平分片，例如这张示意图我们将所有用户分为三组。然后我们将我们的应用也部署成三组独立的逻辑单元，每个逻辑单元的应用和数据都是独立的，相当于每个逻辑单元都处理1/3总量用户的数据。\n这个时候我们的三个不同终端的用户，不管是在PC端或者手机端或者扫二维码，当请求进入统一接入层的时候，接入层会按上面逻辑单元的分组规则，将用户请求转发到对应的逻辑单元，例如 user0 的请求转到 S0，后面的应用之间的调用、数据都只在逻辑单元 0 内。统一的 user1 只在逻辑单元 1，user2 也只到逻辑单元 2。\n我们把这种逻辑单元称之为 RegionZone。在实际的部署过程中，物理数据中心 IDC 和 逻辑单元的数量没有完全的对等关系。例如图中我们物理机房可以是两地三中心，而 RegionZone 则是分为五个。\n两地三中心是国家对金融机构的一个容灾指导方案，要求在同城或相近区域内 （ ≤ 200K M ）建立两个数据中心 : 一个为数据中心，负责日常生产运行 ; 另一个为灾难备份中心，负责在灾难发生后的应用系统运行。同时在异地（＞ 200KM ) 建立异地容灾中心。\n有了这套单元化的架构做指导思想，蚂蚁进行大规模的改造，包括应用改造、基础框架改造、数据中心的建设。\n机房建设完成后，同时蚂蚁金服将自己的用户分成了若干份，划了几个逻辑单元，分别部署进了不同的物理机房，同时完成大规模的数据迁移。\n从两地三中心到容灾能力更强大的三地五中心，我们只需要先进行第三个城市的机房建设，然后将部分 RegionZone 部署到第三个城市，最后再完成数据迁移和引流即可。\n每一个 RegionZone 在异地都有备份，当发生城市级的故障时，我们通过统一的管控中心将新的逻辑规则推送到统一接入层以及异地的备 RegionZone 时，就可以做到城市级的整体容灾切换。\n再后面基于单元化思想，蚂蚁工程师还建设了弹性 LDC 的能力，例如大型活动开始的时候，我们将动态的将大促相关应用调度到其它的临时机房（例如是云上的机房）去，然后将流量引入。例如图中实例将 10% 的流量引入了 ZoneX 中。等到活动结束，我们再将流量引回。\nSOFAStack 开源情况 从前面的服务化演进可以看到，蚂蚁的微服务架构面临的场景已经慢慢从简单的远程调用发展到要面临复杂的三地五中心异地多活场景，为了支持这些场景，蚂蚁中间件自研了一套中间件 SOFAStack。\nSOFAStack 中的 SOFA 其实是 Scalable Open Financial Architecture 的首字母缩写，它是用于快速构建金融级分布式架构的一套中间件，也是在金融场景里锤炼出来的最佳实践。\n这是我们内部的技术栈，可以看到微服务领域各个功能点我们都有对应的内部系统或者组件。包括有RPC框架、服务发现、动态配置、熔断限流，还有分布式事务，分库分表等一整套中间件。\n目前 SOFAStack 也在蚂蚁金融科技上进行了技术输出。我们对中间件产品进行了产品化，并在蚂蚁金融云上变成了云上的产品，并提供了诸多例如同城双活之类的解决方案。这个是商业的产品，大家有空可以看下。\n在去年的 4.19 号，SOFAStack 正式宣布开源，我们第一批主要开了SOFABoot …","date":1548680400,"description":"本文根据 SOFAChannel#1 直播分享整理，主题：从蚂蚁金服微服务实践谈起。","dir":"blog/sofa-channel-1-retrospect/","fuzzywordcount":6300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"c7997723a3859feb5f4f8fa454b6e00e","permalink":"/blog/sofa-channel-1-retrospect/","publishdate":"2019-01-28T21:00:00+08:00","readingtime":13,"relpermalink":"/blog/sofa-channel-1-retrospect/","summary":"SOFA:Channel/，有趣实用的分布式架构频道。 SOFA:Channel/ 作为 SOFA 所有在线内容的承载，包含直播/音视频教程，集中体现 SOFAStack 的能力全景图。欢迎加入直播","tags":["SOFAStack","SOFAChannel"],"title":"从蚂蚁金服微服务实践谈起 | SOFAChannel#1 直播整理","type":"blog","url":"/blog/sofa-channel-1-retrospect/","wordcount":6269},{"author":"花肉","categories":"SOFAChannel","content":" 活动主题：SOFAChannel#1——从蚂蚁金服微服务实践谈起 活动时间：1 月 17 日周四晚 7 点 活动形式：线上直播 直播视频回顾 直播回顾文章  介绍 \u0026amp;lt;SOFA:Channel/\u0026amp;gt;，有趣实用的分布式架构频道\n前沿技术、直播 Coding、观点“抬杠”，多种形式\n\u0026amp;lt;SOFA:Channel/\u0026amp;gt; 将作为 SOFA 所有在线内容的承载，包含直播/音视频教程，集中体现 SOFAStack 的能力全景图。\n欢迎加入直播互动钉钉群：23127468（搜索群号加入即可）\n议程 嘉宾 蚂蚁金服 SOFA 团队 余淮\n视频回顾地址 https://tech.antfin.com/community/live/148\n","date":1547720400,"description":"首次 SOFAChannel 线上直播，1 月 17 日晚 7 点等你。","dir":"activities/sofa-channel-1/","fuzzywordcount":300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"5c79d2fac126784ef412f107470b2924","permalink":"/activities/sofa-channel-1/","publishdate":"2019-01-17T10:20:00Z","readingtime":1,"relpermalink":"/activities/sofa-channel-1/","summary":"活动主题：SOFAChannel#1——从蚂蚁金服微服务实践谈起 活动时间：1 月 17 日周四晚 7 点 活动形式：线上直播 直播视频回顾 直播回顾文章 介绍 \u0026","tags":["SOFAChannel","SOFARPC"],"title":"SOFAChannel#1——从蚂蚁金服微服务实践谈起","type":"activities","url":"/activities/sofa-channel-1/","wordcount":216},{"author":"许文奇","categories":"SOFAStack","content":" 许文奇 蚂蚁金服高级技术专家，SOFAStack 商业化产品技术 Leader，多年分布式架构及中间件研发经验，负责过蚂蚁金服分布式架构在多家金融机构的咨询和落地 本文根据他在 2019 蚂蚁金服 ATEC（Ant Technology Exploration Conference）科技大会上海站的分享整理。\n 本次分享主要会从单体架构和微服务架构的对比开始，后面重点谈一下实施金融级分布式架构的常见三个问题。\n常用架构：单体式架构 目前很多金融机构的架构是典型的单体式架构，一般由反向代理服务器，数据库和应用组成，所有业务模块都打包在一个应用里面运行，一般为了高可用考虑，应用至少会部署两个节点。单体式架构在业务简单的时候有很多它自身的优点：\n 开发，测试简单 部署简单 扩容简单，只要给应用加机器就行  但同样，单体式架构也有很多缺点，尤其是业务规模变得复杂以后，缺点会非常突出：\n 编译慢，启动慢，代码冲突等各种问题，严重影响开发效率 性能扩展有局限性，一定规模后，单纯堆机器已经很难扩展性能了。  蚂蚁金服的架构：分布式架构 微服务架构是目前大家最关注的一种分布式架构。微服务架构除了在性能可扩展性上对比单体式架构有巨大优势，还有一个重要优势体现在复杂业务下的生产效率优势。\n只有在业务复杂度较低的时候，单体式架构的生产效率才能超过微服务架构，但随着业务复杂度上升，尤其过了临界点，单体架构下的生产效率是非常恐怖的急速下坠，而微服务架构生产效率有所下降，但下降趋势非常缓慢，且不会偏离原有生产效率太多，能很好的应对业务复杂性的增长。\n所以实施微服务架构最重要的一个意义是在业务复杂度较高的情况下提升生产效率，更快速的进行业务创新。\n实施金融级分布式架构最常见的三个挑战 基于微服务架构的巨大优势，很多金融机构、企业开始逐渐转型微服务架构，转型总是伴随着挑战，这里选了三个最常见的，最多用户关心的问题，聊聊蚂蚁金服的一些实践心得：\n 如何进行微服务架构拆分及治理？ 新的分布式架构如何兼容老系统？ 如何一步一步构建金融级容灾架构？  1、微服务架构拆分及治理 微服务拆分模式可以从微服务架构的扩展立方开始讲起，分为X轴，Y轴，Z轴三类拆分。\nX轴代表横向扩展模式。主要通过部署多份应用，负载均衡的方式来扩展性能，这个单体架构也可以做。当然，在微服务架构下，横向扩展模式的实现方式有别于单体架构。\n微服务架构做服务负载均衡不需要通过F5或者LVS集群这样的硬件设备，只需要通过注册中心就可以实现，这样带来的好处是降低了成本，不需要购买大量的硬件设备了；提高了性能，业务干路上少了一个单点风险；降低了维护成本。\n当然支持横向扩展模式还需要应用是无状态的，这个是微服务架构的基本要求，任何涉及状态的数据都应该保存在数据库，缓存或者其他一些存储介质中。更高的要求的话，应用应该要满足著名的12要素的要求。\nY轴代表功能分解模式。我们提倡业务系统在开发的时候就应该按照模块化进行开发，满足高内聚，低耦合的架构要求。为了更好支持模块化开发，以SOFAStack中间件的SOFABoot框架为例，框架支持模块隔离能力，不同的模块使用不同的Spring上下文，这样不同的模块之间就不能直接引用了，如果需要调用别的模块的接口，那么需要走SOFABoot框架规定的特别声明才可以办到。这样极大的规范了模块化开发，使得这些系统将来在进行拆分的时候，成本非常的低。\n关于功能分解，服务拆分，虽然没有一个标准答案告诉我们就该怎么做，但其实也有一些基本指导原则和实践：\n 按照业务领域进行拆解，而不是组织。所有拆分必须按照业务领域模型进行合理划分，因为实体组织不一定能和业务领域完全对应，且组织一般粒度较大，不能作为拆分细粒度微服务的参考。 从数据核心模型拆分开始先拆，而后再往上进行服务拆分。这个主要是进行拆分的一个重要次序问题。一般梳理数据核心模型比较容易，比如很容易梳理出哪些表，哪些数据属于交易，哪些表，哪些数据属于账务，然后按照业务垂直进行拆分。有些业务归属不那么明确的可以按照数据亲和性进行拆分。然后数据核心模型拆分好以后，再往上按照功能模块，所对应的场景，进行服务拆分。 单一职责。这个是微服务架构的一条金科玉律，要求微服务架构必须遵守。一个很主要的原因是为了避免微服务架构重新掉进单体架构的老问题里面。原来单体架构最大的问题就是任何的改动，都要导致整个应用重新的编译打包部署，还包括全量回归测试。试想一个微服务里面有太多的功能、职责，如果任意一个业务模块有需求，需要改动，必然导致该微服务的应用重新编译，打包部署和全量回归测试，频繁变动成本很高，研发效率也会降低。 注意拆分粒度，避免一开始拆得过细，循序渐进。关于拆分粒度，这个也是一个没有标准答案的问题。总的一个原则就是适用最好。任何一家公司的业务都是独一无二的，不存在一模一样业务的两家公司，所以别人的拆分，可以借鉴，但往往很难照抄。所以推荐拆分的时候，一开始不要拆得过细，按照业务发展的规律，循序渐进。举个例子，比如说红包业务，原来可能只是营销系统的一个模块，但如果公司的业务在红包这块发展得足够复杂，是可以考虑拆为单独的微服务，这一切取决于业务发展。 注意服务分级和分层，避免循环依赖。这个要求服务拆分的时候，充分注意到哪些是核心服务，哪些是非核心服务，不能出现核心服务强依赖非核心服务的情况，更不能出现循环依赖的情况。 考虑团队结构。最后微服务拆出来，肯定是要有对应团队去维护的，所以整个拆分的粒度，拆分的逻辑也要考虑团队结构的情况。  Z 轴代表数据分区模式。一般在数据库遇到性能瓶颈的时候，需要进行数据拆分，一般分为垂直拆分和水平拆分。垂直拆分一般就是按照业务划分来进行，比如以前账务和交易放在一个数据库，现在数据库有瓶颈了，那么就可以拆成账务和交易两个数据库，缓解数据库的性能瓶颈。当然，如果按照垂直拆分完毕以后，还是不能满足性能要求，这个时候就需要进行水平拆分了。\n关于水平拆分，也有一些重要的实践原则。在做数据库水平拆分的时候，最好一次性考虑未来十年，甚至二十年的业务的要求，要避免今天做了一个拆5张表的决定，过了两年，发现不行，还要继续拆成10张表，甚至20张表的情况。\n重新分片是个非常复杂的工作，尤其是线上还不允许停机的情况。另外关于确定如何拆多少库，多少表，也有一些实践。一般拆的数据库数量等于未来业务的峰值（TPS）除以单数据库的容量（TPS）。这里并不代表要一步到位，拆那么多实际物理库，一开始可借助SOFAStack分库分表中间件虚拟成逻辑库，只需要少量物理库，等到访问量上来后，再扩容物理库。拆的表的数量等于单表时间业务量乘以存储时长除以单标容量上限。记住表的数量一定要一步拆到位，避免过一两年还要折腾。\n做了数据拆分后，就会遇到分布式事务的问题，需要解决分布式事务的问题，这个也是金融行业区分与别的行业的最大不同。SOFAStack分布式事务中间件目前支持TCC和FMT两种模式（这里主要讨论实践，对于TCC和FMT两种模式的原理，这里不再赘述，有兴趣的可以参考之前的文章）。TCC模式虽然编码复杂，业务有侵入，难度较高，但胜在性能好，所以像核心系统里面的分布式事务都是用该方案。当然，因为复杂，所以实现中有些地方 …","date":1547535600,"description":"本次分享主要会从单体架构和微服务架构的对比开始，后面重点谈一下实施金融级分布式架构的常见三个问题。","dir":"blog/distributed-arch-in-the-enterprise/","fuzzywordcount":5500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"e2f9f404c5e859e21c65fb3c2f2f0324","permalink":"/blog/distributed-arch-in-the-enterprise/","publishdate":"2019-01-15T15:00:00+08:00","readingtime":11,"relpermalink":"/blog/distributed-arch-in-the-enterprise/","summary":"许文奇 蚂蚁金服高级技术专家，SOFAStack 商业化产品技术 Leader，多年分布式架构及中间件研发经验，负责过蚂蚁金服分布式架构在多家金融","tags":["SOFAStack"],"title":"企业实施分布式架构的挑战以及应对建议 | 上海 ATEC 科技大会实录","type":"blog","url":"/blog/distributed-arch-in-the-enterprise/","wordcount":5455},{"author":"崔秀龙","categories":"Service Mesh","content":" 崔秀龙，HPE 软件分析师，Kubernetes 权威指南作者之一，Kubernetes、Istio 项目成员。\n本文根据崔秀龙在 2019 广州 Service Mesh Meetup#5 分享整理，完整的分享 PPT 获取方式见文章底部。\n本文内容收录在崔秀龙的新书：《深入浅出 Istio - Service Mesh 快速入门与实践》的第十章，该书将于近期由博文视点出版发行，敬请关注。\n Service Mesh 概念在 Linkerd 落地之后，让一直漂浮在空中的微服务治理方案有了一个明确的落地点，给微服务架构的具体实现指出了一个清晰的方向，围绕这一概念逐步开始形成新的技术生态，在业界造成不少震动。这种震动对于企业 IT 转型工作带来的影响，甚至比容器化的影响更加深远。对于承担企业 IT 转型工作的企业服务行业来说，也自然首当其冲感觉到新概念带来的压力。\n企业服务行业和互联网行业相比，业务形态、技术积累和人员结构等方面都大相径庭，举几个常见的差异：\n 开发、运维、基础设施所属 人员结构、水平和年龄 资源使用率差别 架构和平台一致性 负载能力 \u0026amp;hellip;  目前进行 Service Mesh 布道的主力还是互联网行业的旗手们，一味追求跟进互联网同行们的进度和做法，颇有邯郸学步的风险。\n本文中将会针对目前 Service Mesh 方面的一些普遍问题和关注热点发表一些个人意见。并尝试提供一种 Istio 的试用思路，给乙方同行们提供参考。\nIstio 的功能 无需赘述，多数用户都很清楚，Istio 使用和应用共享网络栈的方式，利用 Iptables 劫持应用的网络流量，从而在不修改业务源码的情况下，完成一系列的功能：\n 监控服务质量 控制服务间的访问路由 应对服务故障 在服务间通信之间进行加密 访问控制和频率限制   分布式跟踪和业务紧密相关，无法做到无侵入。\n 这其中最大的优势就是无侵入，这意味着给试用流程留下了全身而退的机会，如果没有回滚的能力，上述种种能力都是空中楼阁。\nIstio 的问题  API 稳定性可能是最严重的一个问题。目前最成熟的功能组别应该是流量控制，其版本号也仅是 v1alpha3，一般来说，alpha 阶段的产品，代表着不提供向后兼容的承诺，流量控制 API 在从 v1alpha2 升级为 v1alpha3 的过程中，API 几乎全部改写，使得很多早期用户的精力投入付诸东流。核心功能尚且如此，遑论相对比较边缘的 Mixer、Citadel 以及 Galley 组件的相关内容。 发布节奏和发布质量的问题也相当严重。Istio并不算长的历史中，出现了多次版本撤回、大版本严重延期、发布质量低下无法使用以及 Bug 反复等状况，这无疑会让每次升级尝试都充满了不确定性，会很大的影响生产过程的连续性。 Mixer 是一个问题焦点，其数据模型较为复杂，并且集中了所有应用的流量于一点，虽然其中加入了各种缓存等技术来降低延迟，但是其独特地位决定了 Mixer 始终处于一个高风险的位置。同时其 API 结构稍显混乱，重构风险较大。 Pilot的性能方面也经常为人诟病，虽然经过几次升级，但是即使是 1.0 之后，还是出现了两次 Pilot 在集群中服务/Pod 过多的情况下会超量消耗资源的问题。 安全、物理机和虚拟机的支持以及网格边缘通信这三组功能，目前用户较少，质量尚不明确。 最后就是 Istio 的 Sidecar 注入模式，这种模式一定会增加服务间调用的网络延迟，在目前阶段这是一个痼疾，Sidecar 的固定延迟和 Mixer 的不确定行为相结合，有可能会产生严重后果。  这里提出的只是被反复提及，或者经常出现在 Issue 列表中的问题，由发布问题来看，面临的风险可能远不止这些。\nIstio 试用工作的理由和规划 试用 Istio，首先应该确定，该技术的采用，是否能够在可控的风险和投入下，得到有效的产出。\n 微服务模式的推进，必须要有相应的管理能力，Service Mesh 目前看来，是一个确定有效的方案，如果不是 Istio，也会有其它替代产品出现。 目前看来，Istio 是 Service Mesh 的标志性产品，有一定可能性成为事实标准。 提供了众多开箱即用的丰富特性，能够迅速进入 Service mesh。 最后是无侵入的优势：如果试用失败，可以退回，控制损失范围。  Istio 的多数功能，在无需对程序进行修改（分布式跟踪除外）的情况下，能对应用提供如此之多的功能支持，无疑是非常有吸引力的。Istio 的功能集，完全可以说是服务网格技术的典范。一旦确认现有环境有可能支持 Istio 的运行，并且在合理的投入下能够获得有效益的产出，那么这个试用就是有价值的。\n结合 Istio 的现状，以及多数企业的运行状态，个人浅见，Istio 的应用在现阶段只能小范围试探性地进行，在进行过程中要严格定义试用范围，严控各个流程。 按照个人经验，笔者将试用过程分为如下 4 个阶段。\n 范围定义：选择进入试用的服务，确定受影响的范围，并根据 Istio 项目现 状决定预备使用的 Istio 相关功能。围绕这些需要，制定试用需求。 方案部署：根据范围定义的决策，制定和执行相关的部署工作。其中包含 Istio 自身的部署和业务服务、后备服务的部署工作。 测试验证：根据既有业务目标对部署结果进行测试。 切换演练：防御措施，用于在业务失败时切回到原有的稳定环境。  Istio 的试用步骤 确定功能范围 在 Istio 中包含了非常多的功能点，从原则上来说，各种功能都是有其实际作用的。然而，Istio 作为一个新产品，本身也有很多不足，我们在 10.1 节中也提到了这些不足。\nIstio 提供的众多功能对每个公司或者项目，都会有不同价值。我们在采用一个新系统时，首先要考虑的就是性价比问题，这里的“价”代表着 Istio 带来的风险、对业务应用的影响，还包括可能出现的服务停机等问题。\n可以根据性价比，做出一个优先级别列表。在制定了优先级列表之后，就可以根据这一列表，结合项目的实际需求，按照效果明显、功能稳定、部署成本低、少改造或者不改造的标准来进行选择，最终确定待测试的功能点。\n在选定功能点之后，应该遵循目前已有的 Istio 文档，对各个功能点进行单项测试和验证，以确保其有效性。并通过官方 GitHub 的 Issue 列表及讨论组内容，了解现有功能是否存在待解决的问题，以及相关的注意事项等。\n选择试用业务 在试用功能点确定之后，就要选择用于试用的业务应用了。Istio 作为一个相对底层的系统，其部署和调试过程必然会对业务产生一定的影响，在运行阶段又有 Sidecar 和各个组件造成的损耗，如下所述：\n 所有网格之间的通信都要经过 Sidecar 的中转，会造成大约 10 毫秒的延迟。 Pilot 对集群规模敏感，集群中的服务数量、Pod 数量都可能对 Pilot 造成较大影响，也会影响到 Istio 各种规则向 Pod 的传输过程。 所有流量都会经由 Mixer 处理，也有造成瓶颈的可能。 安全功能设置不当同样会造成服务中断。  如上所述还只是个概要，对业务来说，对这些风险都是必须正视 …","date":1547103600,"description":"本文根据崔秀龙在 2019 广州 Service Mesh Meetup#5 分享整理，完整的分享 PPT 获取方式见文章底部。","dir":"blog/service-mesh-meetup-5-istio-retrospect/","fuzzywordcount":4100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"88553acdb286a68c44cc9bf390855f26","permalink":"/blog/service-mesh-meetup-5-istio-retrospect/","publishdate":"2019-01-10T15:00:00+08:00","readingtime":9,"relpermalink":"/blog/service-mesh-meetup-5-istio-retrospect/","summary":"崔秀龙，HPE 软件分析师，Kubernetes 权威指南作者之一，Kubernetes、Istio 项目成员。 本文根据崔秀龙在 2019 广州 Service Mesh Meetup#5 分享整","tags":["Service Mesh"],"title":"企业服务行业如何试水 Istio | Service Mesh Meetup 分享实录","type":"blog","url":"/blog/service-mesh-meetup-5-istio-retrospect/","wordcount":4050},{"author":"敖小剑","categories":"Serverless","content":" Knative 是Google 发起的 Serverless 项目，希望通过提供一套简单易用的 Serverless 开源方案，将 Serverless 标准化。 本文根据敖小剑在 2018 年上海 GIAC 演讲内容整理，PPT 获取地址：下载地址\n 前言 大家好，今天给大家来的演讲专题是“Knative：重新定义Serverless”, 我是来自蚂蚁金服中间件的敖小剑。\n这是我的个人资料，有兴趣的同学可以关注的我的个人技术博客网站 https://skyao.io\n这次演讲的内容将会有这些，首先给大家介绍一下 Knative 是什么，然后是 Knative 的主要组件，让大家对 Knative 有一个基本的了解。之后我会简单的对 Knative 做一些分析和探讨，以及介绍一下 Knative 后续的发展。希望本次的内容让大家能够对Knative有一个基本的认知。\n什么是 Knative？ Knative 是 Google 牵头发起的 Serverless 项目。\n这是Knative的项目定义，注意这句话里面几个关键字：Kubernetes，Serverless，Workload。\n这是最近几年 Google 做大型项目的常态：产品刚出来，阵营就已经很强大了，所谓先声夺人。\n是目前Knative项目的进展，可以看到这是一个非常新的项目，刚刚起步。\n 备注：这是截至2018-11-24演讲当天的情况，到2018年12月底，Knative已经发布了v0.2.2和v0.2.3两个bugfix版本。但也还只是 0.2 ……\n 我们来看一下，在Knative出来前， Serverless 领域已有的实现，包括云端提供的产品和各种开源项目。\n这幅图片摘自 The New Stack 的一个 Serverless 调查，我们忽略调查内容，仅仅看看这里列出来的 Serverless 产品的数量——感受是什么？好多Serverless项目，好多选择！\n那问题来了：到底该怎么选？\n这就是目前 Serverless 的问题：由于缺乏标准，市场呈现碎片化。不同厂商，不同项目，各不相同，因此无论怎么选择，都面临一个风险：供应商绑定！\n这段话来自 Knative 的官方介绍，Google 推出 Knative 的理由和动机。其中第一条和第二条针对的是当前 Serverless 市场碎片的现状。而第四条多云战略，则是针对供应商绑定的风险。\nGoogle 描述 Knative 的动机之一，是将云原生中三个领域的最佳实践结合起来。\n小结：\n当前 Serverless 市场产品众多导致碎片化严重，存在厂商绑定风险，而 Google 推出 Knative，希望能提供一套简单易用的 Serverless 方案，实现 Serverless 的标准化和规范化。\nKnative 的主要组件 第二部分，来介绍一下Knative的主要组件。\n前面提到，Google 推出 Knative ，试图将云原生中三个领域的最佳实践结合起来。反应到 Knative 产品中，就是这三大主要组件：Build，Serving，Eventing。\nKnative Build 组件，实现从代码到容器的目标。为什么不直接使用 dockfile 来完成这个事情？\nKnative Build 在实现时，是表现为 Kubernetes 的 CRD，通过 yaml 文件来定义构建过程。这里引入了很多概念如：Build，Builder，Step，Template，Source等。另外支持用 Service Account 做身份验证。\nKnative Serving 组件的职责是运行应用以对外提供服务，即提供服务、函数的运行时支撑。\n注意定义中的三个关键：\n Kubernetes-based：基于 k8s，也仅支持 k8s，好处是可以充分利用k8s平台的能力 scale-to-zero：serverless 最重要的卖点之一，当然要强调 request-driven compute：请求驱动的计算  值得注意的是，除了k8s之外，还有另外一个重要基础：istio！后面会详细聊这个。\nKnative Serving项目同样也提供了自己的中间件原语，以支持如图所示的几个重要特性。\nKnative中有大量的概念抽象，而在这之后的背景，说起来有些意思：Knative 觉得 kubernetes 和 istio 本身的概念非常多，多到难于理解和管理，因此 Knative 决定要自己提供更高一层的抽象。至于这个做法，会是釜底抽薪解决问题，还是雪上加霜让问题更麻烦……\nKnative的这些抽象都是基于 kubernetes 的 CRD 来实现，具体抽象概念有：Service、Route、Configuration 和 Revision。特别提醒的是，右边图中的 Service 是 Knative 中的 Service 概念，service.serving.knative.dev，而不是大家通常最熟悉的 k8s 的 service。\n对于 Knative Serving 组件，最重要的特性就是自动伸缩的能力。目前伸缩边界支持从0到无限，容许通过配置设置。\nKnative 目前是自己实现的 Autoscaler ，原来比较简单：Revision 对应的pod由 k8s deployment 管理，pod上的工作负载上报 metrics，汇总到 Autoscaler 分析判断做决策，在需要时修改 replicas 数量来实现自动伸缩（后面会再讲这块存在的问题）。\n当收缩到0，或者从0扩展到1时，情况会特别一些。Knative在这里提供了名为 Activator 的设计，如图所示：\n Istio Route 控制流量走向，正常情况下规则设置为将流量切到工作负载所在的pod 当没有流量，需要收缩到0时，规则修改为将流量切到 Activator ，如果一直没有流量，则什么都不发生。此时Autoscaler 通过 deployment 将 replicas 设置为0。 当新的流量到来时，流量被 Activator 接收，Activator 随即拉起 pod，在 pod 和工作负载准备好之后，再将流量转发过去  Knative Eventing 组件负责事件绑定和发送，同样提供多个抽象概念：Flow，Source，Bus，以帮助开发人员摆脱概念太多的负担（关于这一点，我保留意见）。\nBus 是对消息总线的抽象。\nSource 是事件数据源的抽象。\nKnative 在事件定义方面遵循了 Cloudevents 规范。\n小结：\n简单介绍了一下 Knative 中的三大组件，让大家对 Knative 的大体架构和功能有个基本的认知。这次就不再继续深入 Knative 的实现细节，以后有机会再展开。\nKnative分析和探讨 在第三部分，我们来分析探讨一下 Knative 的产品定位，顺便也聊一下为什么我们会看好 Knative。\n首先，最重要的一点是：Knative __不是__一个 Serverless 实现，而是一个 Serviceless 平台。\n也就是说，Knative 不是在现有市场上的20 …","date":1546498800,"description":"本文根据敖小剑在 2018 年上海 GIAC 演讲内容整理，文中有 PPT 获取地址。","dir":"blog/serverless-knative-giac/","fuzzywordcount":3800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"21d3b124a0863acf6481463647b92095","permalink":"/blog/serverless-knative-giac/","publishdate":"2019-01-03T15:00:00+08:00","readingtime":8,"relpermalink":"/blog/serverless-knative-giac/","summary":"Knative 是Google 发起的 Serverless 项目，希望通过提供一套简单易用的 Serverless 开源方案，将 Serverless 标准化。 本文根据敖小剑在 2018 年上海 GIAC 演讲内容整理，PPT 获取地址：下载","tags":["Serverless","Knative"],"title":"Knative：重新定义 Serverless | GIAC 实录","type":"blog","url":"/blog/serverless-knative-giac/","wordcount":3750},{"author":"余淮","categories":"SOFAStack","content":" 章耿，花名余淮，蚂蚁金服高级技术专家。 2007 年毕业后一直从事服务化相关的工作，最早在国家电网做电子商务平台 SOA 化的工作，之后在京东负责京东的服务化框架 JSF，目前在蚂蚁金服中间件服务与框架组负责应用框架及 SOFAStack 相关的工作。\n本文根据余淮在 2018 开源中国年终盛典的演讲内容整理，完整的分享 PPT 获取方式见文章底部。\n 本次分享主要分为三部分：  蚂蚁金服服务化架构演进 蚂蚁金服微服务体系 蚂蚁金服 SOFAStack 的开源情况  1、蚂蚁金服服务化架构演进 在开始讲架构演进之前，我们先来看一组数据。 这是历年来的双十一数据图，柱状是双十一的交易额，从最初到20亿到去年的1682亿，今年是2135亿。而这个橙色的折线则是支付宝双十一 0 点的交易峰值，去年是 26.5w笔每秒，今年更高。从这两组数据可以看出蚂蚁的业务每年都是在高速增长，那技术面临的压力更是在不断的增长。但是最近几年，峰值虽然越来越大，但是大家有个体感，就是大促的购物体验更好了，再也不像以前系统会被大促搞挂，系统反而越来越稳了。\n而支撑这些数字的背后，是蚂蚁金融科技的一些核心技术，我们可以看到有三地五中心多活架构，分布式数据库 OceanBase，金融级分布式架构 SOFAStack，还有更多的一些黑科技，例如 Zoloz 生物识别，蚂蚁区块链，第五代智能风控引擎。\n相信大家都听过一句话 “罗马不是一天建成的”。蚂蚁金服科技的技术也不是最早就设计成这样，和所有的大公司发展一样，目前这些技术架构也是随着业务发展、系统的壮大，一步一步演进而来的。\n下面给大家介绍下蚂蚁金服的演进。\n这个是支付宝最早的架构示意图，可以看到当时支付宝只是电商后台的一个支付系统，是一个单体应用，里面简单的分了几个业务模块，连的也是一个数据库。但随着业务规模的不断扩展，单系统架构已经无法满足业务需求。\n所以支付宝就对大系统进行了拆分，将原来的一个单体应用内部的多个模块变成了多个独立的子系统，这算是典型的 SOA 化的架构。最开始系统之间是使用 F5 的硬件负载设备来做系统间的负载均衡，但由于 F5 设备存在单点的问题，所以后面就在中间引入一个注册中心的组件。服务提供者去注册中心注册服务，服务消费者去注册中心订阅服务列表，服务消费者通过软负载方式通过 RPC 框架直接调用服务提供者。这在现在看来是一种非常显而易见的服务化架构，但当时 07 年就采用这样的架构还是算比较超前的。 支付宝在做系统拆分的同时，对数据库也按子系统进行了垂直拆分。数据库的拆分就会引入分布式事务的问题，蚂蚁金服中间件就提供了基于 TCC 思想的 分布式事务组件 DTX。\n业务还是不断扩展，系统也越来越多，当系统节点到一定数量的时候，单个物理机房已经无法承受。另外考虑到同城容灾的问题，支付宝就在同城再扩建另外一个机房，通过专线部署为一个内部网络，然后将应用部署上去。同城多机房会引入一个跨机房远程访问的问题，相比同机房调用，这个延迟损耗一定是更高的。远程访问主要包括两种：RPC 调用和数据库访问。为了解决 RPC 跨机房调用的问题，支付宝的工程师选择的方案是在每个机房都部署注册中心，同机房优先调用本机房服务的方式，也就变成图中的部署模式。但是数据库跨机房访问的问题，在这个阶段并没有解决。\n为了解决上面的跨机房数据访问、数据库连接数瓶颈以及未来数据水平扩展的问题，蚂蚁的工程师们设计了一套单元化的架构，这是单元化的一个示意图。在没有单元化的时候，用户请求进入内部后，所有请求链路都是随机走的，例如图里的 S0 到 B1 到 C2 到 D0。首先蚂蚁的请求都是跟用户相关的，所以我们将数据按用户的维度进行水平分片，例如这张示意图我们将所有用户分为三组。然后我们将我们的应用也部署成三组独立的逻辑单元，每个逻辑单元的应用和数据都是独立的，相当于每个逻辑单元都处理1/3总量用户的数据。\n这个时候我们的三个不同终端的用户，不管是在PC端或者手机端或者扫二维码，当请求进入统一接入层的时候，接入层会按上面逻辑单元的分组规则，将用户请求转发到对应的逻辑单元，例如 user0 的请求转到 S0，后面的应用之间的调用、数据都只在逻辑单元 0 内。统一的 user1 只在逻辑单元 1，user2 也只到逻辑单元 2。\n我们把这种逻辑单元称之为 RegionZone。在实际的部署过程中，物理数据中心 IDC 和 逻辑单元的数量没有完全的对等关系。例如图中我们物理机房可以是两地三中心，而 RegionZone 则是分为五个。\n两地三中心是国家对金融机构的一个容灾指导方案，要求在同城或相近区域内 （ ≤ 200K M ）建立两个数据中心 : 一个为数据中心，负责日常生产运行 ; 另一个为灾难备份中心，负责在灾难发生后的应用系统运行。同时在异地（＞ 200KM ) 建立异地容灾中心。\n有了这套单元化的架构做指导思想，蚂蚁进行大规模的改造，包括应用改造、基础框架改造、数据中心的建设。\n机房建设完成后，同时蚂蚁金服将自己的用户分成了若干份，划了几个逻辑单元，分别部署进了不同的物理机房，同时完成大规模的数据迁移。\n从两地三中心到容灾能力更强大的三地五中心，我们只需要先进行第三个城市的机房建设，然后将部分 RegionZone 部署到第三个城市，最后再完成数据迁移和引流即可。\n每一个 RegionZone 在异地都有备份，当发生城市级的故障时，我们通过统一的管控中心将新的逻辑规则推送到统一接入层以及异地的备 RegionZone 时，就可以做到城市级的整体容灾切换。\n再后面我们基于单元化的思想做了更多弹性调度等能力，这里就不展开了。\n2015 年 9 月蚂蚁金融云对外正式发布，在今年 9 月的云栖大会，蚂蚁金融云正式升级为蚂蚁金融科技，并宣布技术全面对外开放，其中就包括金融级分布式架构 SOFAStack，左上角就是网址，感兴趣的朋友可以看下：https://tech.antfin.com/sofa\n云上的 SOFAStack 继承了蚂蚁金服内部的能力，有三大特点，分别是开放（全栈开放、开源共建）、云原生（异地多活、无限扩展）、金融级（资金安全、无损容灾），下面是一些核心能力大家可以看下。这一切就使得蚂蚁金服的微服务体系不仅仅在蚂蚁内部玩得转，也需要适应云上例如云原生、多租户等更复杂的场景。\n2、蚂蚁微服务体系 讲到微服务，大家就会看到或者脑子就跳出各种各样的词，例如 RPC 框架、服务安全、路由寻址等等。 除了这些以外，其实还有更多的服务归属、服务测试、服务编排等更多概念。\n那蚂蚁内部围绕微服务体系，也建设了很多的组件和框架对应这些微服务的概念点。\n这是一张蚂蚁内部微服务体系的一张简图，只列了部分主要组件，这些组件都是自研的，部分已经开源。可以看到有配置中心 DRM、注册中心 SOFARegistry，应用开发框架 SOFABoot，应用里的 RPC 框架、分布式链路跟踪组件 Tracer、监控度量组件 Lookout 等微服务组件，应用旁边是我们的 SOFAMosn，也就是 ServiceMesh 里的数据平面 SideCar，会将 RPC 里的路由、限流、鉴权等一些能力集成到这个组件里，下 …","date":1545030000,"description":"本文根据余淮在 2018 开源中国年终盛典的演讲内容整理，完整的分享 PPT 获取方式见文章底部。","dir":"blog/sofastack-oschina-2018/","fuzzywordcount":6600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"e636d50f3f49170801c38118bf711adc","permalink":"/blog/sofastack-oschina-2018/","publishdate":"2018-12-17T15:00:00+08:00","readingtime":14,"relpermalink":"/blog/sofastack-oschina-2018/","summary":"章耿，花名余淮，蚂蚁金服高级技术专家。 2007 年毕业后一直从事服务化相关的工作，最早在国家电网做电子商务平台 SOA 化的工作，之后在京东负责京东的服务化","tags":["微服务","开源","实践"],"title":"蚂蚁金服微服务实践- 2018 开源中国年终盛典分享实录","type":"blog","url":"/blog/sofastack-oschina-2018/","wordcount":6552},{"author":"颜洄、丞一","categories":"SOFABolt","content":"1. 前言 为了让中间件开发者们将更多的精力投入到产品的功能特性上，而不是重复的写通信层框架，蚂蚁中间件团队设计并实现了SOFABolt。 Bolt 名字取自迪士尼动画-闪电狗，是一个基于 Netty 最佳实践的轻量、易用、高性能、易扩展的通信框架。蚂蚁中间件的同学这些年在微服务和消息中间件上解决了很多网络通信的问题，积累了很多经验，并将这些经验、解决方案沉淀到了SOFABolt这个项目中，希望能让更多需要使用网络通信的团队、开发者受益。目前SOFABolt已经运行在蚂蚁中间件的微服务 (SOFARPC)、消息中心、分布式事务、分布式开关、以及配置中心等众多产品上。\n2. 主要特性 SOFABolt核心功能包括三大块：\n 网络通信能力 协议框架 私有协议实现  网络通信能力 网络通信能力（remoting-core）可以理解为Netty的最佳实践，并额外进行了一些优化工作，包含：\n 基于Netty的高效的网络IO于线程模型的应用 链接管理（无锁建连、定时断连、自动重连） 通信模型（oneway、sync、callback、future） 超时控制 批量解包和批量提交处理 心跳于IDLE机制  协议框架 协议框架（protocol-skeleton）包含命令处理器、编解码器等，是底层通信能力之上，具体私有协议之下，连接通信能力和私有协议的中间层。网络通信层是SOFABolt对Netty的封装和功能增强，协议框架则是SOFABolt对网络请求处理流程的抽象，是用户可以不关心底层细节快速实现自己的处理器来完成网络请求的处理逻辑，是用户可以进行拓展来实现自定义的私有协议的基础，也是本篇文章分析的内容。\n私有协议实现 由于性能、安全性等等的原因，很多中间件都会采用私有协议进行通信。SOFABolt除了提供基础的通信能力、协议框架之外，还提供了默认的RPC协议的实现，这样它就是一个完整的通信框架，用户可以不关心协议而直接上手使用。本篇文章主要分析SOFABolt的协议框架的设计和实现，不展开对SOFABolt中的RPC协议实现做介绍。\n3. 协议框架 协议框架整体如下：\n Command：协议命令，通讯数据的顶层抽象。从交互的角度可以分为Request（请求）于Response（响应），从功能的角度，分为负载命令（交换业务数据）和控制命令（进行系统的管理、协调等）。 CommandEncoder/CommandDecoder：协议命令的编解码器，自定义协议实现的基础，编解码器完成对象和字节数组之间的相互转换。 CommandHandler：协议命令的处理器，命令处理入口，负责分发、处理命令。 CommandFactory：协议命令工厂类，负责创建协议命令对象。 HeartbeatTrigger：心跳的处理器，用户用户拓展特定的心跳机制的处理。 下面以SOFABolt中默认实现的RPC协议为例来介绍SOFABolt协议框架的实现。  3.1 请求的处理流程 一个请求处理流程大致如下：\n 通过CommandFactory构建请求对象 通过CommandEncoder对请求对象进行编码，写入到网络连接 服务端从连接中读取数据，通过CommandDecoder解析成请求对象 CommandHandler接收请求对象，进行分发和处理  CommandFactory是一个工厂类，比较简单，不展开介绍。编解码相关内容见《SOFABolt编解码机制》。下面介绍一下CommandHandler对请求的分发和处理。\n上面是SOFABolt中RpcHandler的代码片段，这段代码是命令处理的入口：\n 首先从连接的上下文中获取使用的协议的版本ProtocolCode 再根据ProtocolCode从ProtocolManager中获取具体的协议 之后从协议中获取CommandHandler，并构造请求的上下文信息和请求的对象（代码片段中的msg）提交处理  上面的处理逻辑中透露出一个信息：SOFABolt支持同时运行多个版本的协议，通过ProtocolCode来区分协议。这一点可以使得系统在做升级或重构时，需要同时支持新老系统不同协议时变得简单。\n上面是CommandHandler的代码片段，透露出的信息是SOFABolt支持批量提交请求，这在《SOFABolt编解码机制》一文中也有部分介绍。而具体的process流程如下：\n通过Command对象获取CommandCode，根据CommandCode获取对应的RemotingProcessor进行处理。 CommandCode是一个接口，只有一个返回short的value()方法，表示Command的具体类型，每个请求都需要有自己的CommandCode来标识自己的类型。框架通过一个Map来维护CommandCode和RemotingProcessor的关系，每个CommandCode需要有对应的RemotingProcessor进行处理，一个RemotingProcessor可以处理多个CommandCode的请求。\n再往下看一层，请求会被提交到RemotingProcessor中处理。上面是RpcRequestProcessor处理请求的代码片段，处理流程中会通过cmd.getRequestClass()来获取请求的对象的Class名称，再获取对应的UserProcess进行处理（具体处理不再上面的代码片段中）。 对用户来说，只需要实现自己的Command对象、实现自己的UserProcessor并注册到ProcessorManager中，就可以完成自己的网络通信。 以上是一个请求在SOFABolt的协议框架下的处理流程和核心代码的分析。\n3.2 协议框架的拓展机制 通过对请求处理流程的分析可以感受到SOFABolt的协议框架是支持多协议版本运行，能直接使用，也支持进行拓展来实现更丰富和定制化的功能。下面具体介绍SOFABolt的拓展机制。\n上图是RemotingCommand在处理过程中的路由示意图。第一层路由根据ProtocolCode进行，第二层路由根据CmdCode进行，第三层路由则根据RequestClass进行。用户可以在每一层进行扩展来实现自己的处理。 这种设计具有很好的拓展性和灵活性，ProtocolCode用于区分“大版本”的协议，适用于协议发生较大的变化的场景。CmdCode则标识请求类型，比如在RPC场景中CmdCode可能就两个：RPC_REQUEST、RPC_RESPONSE，而在消息场景中CmdCode可能会更丰富一些，比如有发送消息、批量发送消息、投递消息等等。RequestClass是Command上承载的数据的类型，用户根据不同的类名进行不同的业务逻辑的实行。\n实际应用中，以RPC的场景为例，用户更多的是去实现UserProcessor来完成不同的业务逻辑的处理。而在消息的场景中，因为消息承载的是二进制的数据，所以请求的数据类型是固定的，系统更多的是拓展CmdCode来执行不同类型的请求的处理，比如心跳请求的处理、写入消息的处理、批量写入消息的处理等等。SOFABolt协议框架的设计和实现，具备较好的可拓展性，使其能应用于蚂蚁 …","date":1544091600,"description":"本文是对蚂蚁金服开源通信框架 SOFABolt 的协议框架解析。","dir":"blog/sofa-bolt-framework-deep-dive/","fuzzywordcount":3900,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"67335ca275995497a5f28340cb13f45b","permalink":"/blog/sofa-bolt-framework-deep-dive/","publishdate":"2018-12-06T10:20:00Z","readingtime":8,"relpermalink":"/blog/sofa-bolt-framework-deep-dive/","summary":"1. 前言 为了让中间件开发者们将更多的精力投入到产品的功能特性上，而不是重复的写通信层框架，蚂蚁中间件团队设计并实现了SOFABolt。 Bolt 名字取","tags":["SOFABolt","SOFALab","剖析 | SOFABolt 框架"],"title":"蚂蚁金服开源通信框架 SOFABolt 协议框架解析","type":"blog","url":"/blog/sofa-bolt-framework-deep-dive/","wordcount":3889},{"author":"鲁道","categories":"SOFABolt","content":"前言 SOFABolt 是一款基于 Netty 最佳实践，通用、高效、稳定的通信框架。目前已经运用在了蚂蚁中间件的微服务，消息中心，分布式事务，分布式开关，配置中心等众多产品上。\n本文将重点分析 SOFABolt 的序列化机制。\n我们知道，但凡在网络中传输数据，都涉及到序列化以及反序列化。即将数据编码成字节，再把字节解码成数据的过程。\n例如在 RPC 框架中，一个重要的性能优化点是序列化机制的设计。即如何为服务消费者和和服务提供者提供灵活的，高性能的序列化器。\n这里说的序列化器，不仅仅是指“对象”的序列化器，例如 Hessian，Protostuff，JDK 原生这种“对象”级别的序列化器，而是指“协议”级别的序列化器，“对象”的序列化只是其中一部分。通常“协议”级别的序列化器包含更多的信息。\n下面我们将先从 SOFABolt 的设计及实现入手，进而分析 SOFABolt 详细的序列化与分序列化流程，最后介绍 SOFABolt 序列化扩展。\n设计及实现 一个优秀的网络通信框架，必然要有一个灵活的，高性能的序列化机制。那么，SOFABolt 序列化机制的设计目标是什么呢？具体又是如何设计的呢？\n首先说灵活，灵活指的是，框架的使用方（这里指的是网络通信框架的使用方，例如 RPC，消息中心等中间件）能够自定义自己的实现，即用户决定使用什么类型的序列化以及怎么序列化。\n再说高效，序列化和反序列化事实上是一个重量级的操作，阿里 HSF 作者毕玄在著名的 NFS-RPC框架优化过程（从37k到168k） 文章中提到，其优化 RPC 传输性能的第一步就是调整反序列化操作，从而将 TPS 从 37k 提升到 56k。之后又通过更换对象序列化器，又将 TPS 提升了将近 10k。由此可见，合理地设计序列化机制对性能的影响十分巨大。\n而 SOFABolt 和 HSF 有着亲密的血缘关系，不但有着 HSF 的高性能，甚至在某些地方，优化的更为彻底。\n我们现在可以看看 SOFABolt 序列化设计。\n接口设计 SOFABolt 设计了两个接口：\n Serializer 该接口定义 serialize 方法和 deserialize 方法，用于对象的序列化和反序列化。 CustomSerializer 该接口定义了很多方法，主要针对自定义协议中的 header 和 content 进行序列化和反序列化。同时提供上下文，以精细的控制时机。  同时，从框架设计的角度说，他们可以称之为 “核心域”， 他们也被对应的 “服务域” 进行管理。\n这里解释一下服务域和核心域，在框架设计里，通常会有“核心域”，“服务域”， “会话域” 这三部分组成。\n例如在 Spring 中，Bean 就是核心域，是核心领域模型，所有其他模型都向其靠拢；而 BeanFactory 是服务域，即服务“核心域”的模型，通常长期存在于系统中，且是单例；“会话域” 指的是一次会话产生的对象，会话结束则对象销毁，例如 Request，Response。\n在 SOFABolt 序列化机制中，Serializer 和 CustomSerializer 可以认为是核心域，同时，也有服务于他们的 “服务域”，即 SerializerManager 和 CustomSerializerManager。“会话域” RpcCommand 依赖 “服务域” 获取 “核心域” 实例。\nUML 设计图如下：\n其中红色部分就是 SOFABolt 序列化机制的核心接口，同时也是用户的扩展接口，他们被各自的 Manager 服务域进行管理，最后，会话域 RpcCommand 依赖着 Manager 以获取序列化组件。\n这两个接口的使用场景通常在数据被 协议编解码器 编码之前或解码之后，进行处理。\n例如在发送数据之前，协议编码器 根据通信协议（如 bolt 协议）进行编码，编码之前，用户需要将数据的具体内容进行序列化，协议编解码器 再进行更详细的编码。\n同样，协议解码器 在接收到 Socket 发送来的字节后，根据协议将字节解码成对象，但是，对象的内容还是字节，需要用户进行反序列化。\n一个比较简单的流程图就是这样的:\n上图中，假设场景是 Client 发送数据给 Server，那么，编解码器负责将字节流解码成 Command 对象，序列化器负责将 Command 对象里的内容反序列化成业务对象，从设计模式的角度看，这里是 GOF 中 “命令模式”和“职责链模式”的组合设计。\n看完了设计，再看看实现。\n接口实现 我们可以看看这两个接口的实现。\n Serializer  Serializer 接口在 SOFABolt 中已有默认实现，即 HessianSerializer，目前使用的是 hessian-3.3.0 版本。通过一个 SerializerManager 管理器进行管理。注意，这个管理器内部使用的是数组，而不是 Map，这在上文毕玄的文章也曾提到：通过使用数组替换成 Map，NFS-RPC 框架的 TPS 从 153k 提升到 160k。事实上，任何对性能非常敏感的框架，能用数组就绝不用 Map，例如 Netty 的 FastThreadLocal，也是如此。\n当然，Serializer 接口用户也是可以扩展的，例如使用 protostuff，FastJson，kryo 等，扩展后，通过 SerializerManager 可以将自己的序列化器添加到 SOFABolt 中。注意：这里的序列化 type 实际就是上面提到的数组的下标，所以不能和其他序列化器的下标有冲突。\n CustomSerializer  再说 CustomSerializer，这个接口也是有默认实现的，用户也可以选择自己实现，我们这里以 SOFARPC 为例。\nSOFARPC 在其扩展模块 sofa-rpc-remoting-bolt 中，通过实现 CustomSerializer 接口，自己实现了序列化 header，content。\n这里稍微扩展讲一下 header 和 content。实际上，header 和 content 类似 http 协议的消息头和消息体，header 和 content 中到底存放什么内容，取决于协议设计者。\n例如在 SOFARPC 的协议中，header 里存放的是一些扩展属性和元信息上下文。而 content 中存放的则是主要的一些信息，比如 request 对象，request 对象里就存放了 RPC 调用中常用信息了，例如参数，类型，方法名称。\n同时，CustomSerializer 接口定义的方法中，提供了 InvokeContext 上下文，例如是否泛化调用等信息，当进行序列化时，将是否泛型的信息放入上下文，反序列化时，再从上下文中取出该属性，即可正确处理泛化调用。\n注意，如果用户已经自己实现了 CustomSerializer 接口，那么 SOFABolt 的 SerializerManager 中设置的序列化器将不起作用！因为 SOFABolt 优先使用用户的序列化器。\n具体代码如下：\n行文至此，讨论的都是“灵活”这个设计，即用户既可以使用 SOFABolt  …","date":1544091600,"description":"SOFABolt 是一款基于 Netty 最佳实践，通用、高效、稳定的通信框架，本文将重点分析 SOFABolt 的序列化机制。","dir":"blog/sofa-bolt-serialization-deep-dive/","fuzzywordcount":4700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"2145bb681760cdf3d1953bf4ed75fa60","permalink":"/blog/sofa-bolt-serialization-deep-dive/","publishdate":"2018-12-06T10:20:00Z","readingtime":10,"relpermalink":"/blog/sofa-bolt-serialization-deep-dive/","summary":"前言 SOFABolt 是一款基于 Netty 最佳实践，通用、高效、稳定的通信框架。目前已经运用在了蚂蚁中间件的微服务，消息中心，分布式事务，分布式开关，配置中心等众多","tags":["SOFABolt","SOFALab","剖析 | SOFABolt 框架"],"title":"蚂蚁金服开源通信框架SOFABolt解析之序列化机制","type":"blog","url":"/blog/sofa-bolt-serialization-deep-dive/","wordcount":4634},{"author":"水寒","categories":"SOFABolt","content":"基础介绍 SOFABolt 是蚂蚁金融服务集团开发的一套基于 Netty 实现的网络通信框架。\n 为了让 Java 程序员能将更多的精力放在基于网络通信的业务逻辑实现上，而不是过多的纠结于网络底层 NIO 的实现以及处理难以调试的网络问题，Netty 应运而生。 为了让中间件开发者能将更多的精力放在产品功能特性实现上，而不是重复地一遍遍制造通信框架的轮子，SOFABolt 应运而生。  Bolt 名字取自迪士尼动画-闪电狗，是一个基于 Netty 最佳实践的轻量、易用、高性能、易扩展的通信框架。 这些年我们在微服务与消息中间件在网络通信上解决过很多问题，积累了很多经验，并持续的进行着优化和完善，我们希望能把总结出的解决方案沉淀到 SOFABolt 这个基础组件里，让更多的使用网络通信的场景能够统一受益。 目前该产品已经运用在了蚂蚁中间件的微服务 (SOFARPC)、消息中心、分布式事务、分布式开关、以及配置中心等众多产品上。\n前言 SOFABolt 提供了设计良好、使用便捷的编解码功能。本篇我们会依次介绍编解码的概念， TCP 粘包拆包问题，SOFABolt 私有通信协议的设计，以及SOFABolt 编解码原理，最后还会介绍一下相较于 Netty，我们做出的优化。欢迎大家与我们讨论交流。\n编解码介绍 每个网络应用程序都必须定义如何解析在两个节点之间来回传输的原始字节，以及如何将其和目标应用程序的数据格式做相互转换。在一个成熟的通信框架中，我们通常都会通过私有通信协议来描述这种定义，通过编解码技术将理论上的私有通信协议转化为实践。\n通过编解码技术，我们可以方便的做一些逻辑，例如双方可以方便的统一序列化与反序列化方式、解决 TCP 拆包粘包问题等。\n下面，我们先来看一下 TCP 粘包拆包问题的产生，然后分析 Netty 是如何解决粘包拆包问题的，最后分析 SOFABolt 是如何解决粘包拆包问题的。\nTCP 粘包拆包问题 如上图所示，三种拆包原因见黄色标签说明；两种粘包原因见蓝色标签说明。TCP 本身是面向流的，它无法从源源不断涌来的数据流中拆分出或者合并出有意义的信息，通常可以通过以下几种方式来解决： 基于分隔符协议：使用定义的字符来标记一个消息的结尾，在编码的时候我们在消息尾部添加指定的分隔符，在解码的时候根据分隔符来拆分或者合并消息。Netty 提供了两种基于分隔符协议的解码器 LineBasedFrameDecoder 和 DelimiterBasedFrameDecoder。LineBasedFrameDecoder 指定以 \\n 或者 \\r\\n 作为消息的分隔符；DelimiterBasedFrameDecoder 使用用户自定义的分隔符来标记消息的结尾。 基于定长消息协议：每一个消息在编码的时候都使用固定的长度，在解码的时候根据这个长度进行消息的拆分和合并。Netty 提供了 FixedLengthFrameDecoder 解码器来实现定长消息解码。 基于变长消息协议：每一个消息分为消息头和消息体两部分，在编码时，将消息体的长度设置到消息头部，在解码的时候，首先解析出消息头部的长度信息，之后拆分或合并出该长度的消息体。Netty 提供了 LengthFieldBasedFrameDecoder 来实现变长消息协议解码。 基于私有通信协议：Netty 提供了 MessageToByteEncoder 和 ByteToMessageDecoder 两个抽象类，这两个抽象类提供了基本的编解码模板。用户可以通过继承这两个类来实现自定义的编解码器。SOFABolt 通过继承 MessageToByteEncoder 实现了自定义的编码器，通过继承修改版的 ByteToMessageDecoder 来实现了解码器。对于处理 TCP 粘包拆包问题，SOFABolt 实际上也是使用变长消息协议，SOFABolt 的私有通信协议将消息体分为三部分 className、header、body，在消息头对应的提供了 classLen、headerLen、bodyContent 分别标识三部分的长度，之后就可以基于这三个长度信息进行消息的拆分和合并。  对于一个成熟的 rpc 框架或者通信框架来讲，编解码器不仅仅是要处理粘包拆包问题，还要实现一些特有的需求，所以必须制定一些私有通信协议，下面来看一下 SOFABolt 的私有通信协议的设计。\nSOFABolt 私有通信协议的设计  以下分析以 SOFABolt 1.5.1 版本为例。SOFABolt 定义了两种协议 RpcProtocol 和 RpcProtocolV2。针对这两种协议，提供了两组不同的编解码器。\n RpcProtocol 协议定义 请求命令（协议头长度：22 byte）  ProtocolCode ：这个字段是必须的。因为需要根据 ProtocolCode 来进入不同的核心编解码器。该字段可以在想换协议的时候，方便的进行更换。 RequestType ：请求类型，request / response / oneway 三者之一。oneway 之所以需要单独设置，是因为在处理响应时，需要做特殊判断，来控制响应是否回传。 CommandCode ：请求命令类型，request / response / heartbeat 三者之一。 CommandVersion ：请求命令版本号。该字段用来区分请求命令的不同版本。如果修改 Command 版本，不修改协议，那么就是纯粹代码重构的需求；除此情况，Command 的版本升级，往往会同步做协议的升级。 RequestId ：请求 ID，该字段主要用于异步请求时，保留请求存根使用，便于响应回来时触发回调。另外，在日志打印与问题调试时，也需要该字段。 Codec ：序列化器。该字段用于保存在做业务的序列化时，使用的是哪种序列化器。通信框架不限定序列化方式，可以方便的扩展。 Timeout ：超时字段，客户端发起请求时，所设置的超时时间。 ClassLen ：业务请求类名长度 HeaderLen ：业务请求头长度 ContentLen ：业务请求体长度 ClassName ：业务请求类名。需要注意类名传输的时候，务必指定字符集，不要依赖系统的默认字符集。曾经线上的机器，因为运维误操作，默认的字符集被修改，导致字符的传输出现编解码问题。而我们的通信框架指定了默认字符集，因此躲过一劫。 HeaderContent ：业务请求头 BodyContent ：业务请求体  响应命令（协议头长度：20 byte）  ResponseStatus ：响应码。从字段精简的角度，我们不可能每次响应都带上完整的异常栈给客户端排查问题，因此，我们会定义一些响应码，通过编号进行网络传输，方便客户端定位问题。  RpcProtocolV2 协议定义 请求命令（协议头长度：24 byte）  ProtocolVersion ：确定了某一种通信协议后，我们还需要考虑协议的微小调整需求，因此需要增加一个 version 的字段，方便在协议上追加新的字段 Switch ：协议开关，用于一些协议级别的开关控制，比如 CRC 校验，安全 …","date":1544091600,"description":"本篇我们会依次介绍编解码的概念， TCP 粘包拆包问题，SOFABolt 私有通信协议的设计，以及SOFABolt 编解码原理，最后还会介绍一下相较于 Netty，我们做出的优化。","dir":"blog/sofa-bolt-codec-deep-dive/","fuzzywordcount":4000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"9383bfa0b8c9975e3d4b2ed4bc01a593","permalink":"/blog/sofa-bolt-codec-deep-dive/","publishdate":"2018-12-06T10:20:00Z","readingtime":8,"relpermalink":"/blog/sofa-bolt-codec-deep-dive/","summary":"基础介绍 SOFABolt 是蚂蚁金融服务集团开发的一套基于 Netty 实现的网络通信框架。 为了让 Java 程序员能将更多的精力放在基于网络通信的业务逻辑实现上，而不是过多的纠","tags":["SOFABolt","SOFALab","剖析 | SOFABolt 框架"],"title":"蚂蚁金服开源通信框架SOFABolt解析之编解码机制","type":"blog","url":"/blog/sofa-bolt-codec-deep-dive/","wordcount":3909},{"author":"胡萝卜、丞一","categories":"SOFABolt","content":"前言 SOFABolt 是一个基于 Netty 最佳实践的轻量、易用、高性能、易扩展的通信框架。目前已经运用在了蚂蚁中间件的微服务，消息中心，分布式事务，分布式开关，配置中心等众多产品上。\n本文将分析SOFABolt的超时控制和心跳机制。\n超时 在程序中，超时一般指的是程序在特定的等待时间内没有得到响应，网络通信问题、程序BUG等等都会引起超时。系统引入超时机制往往是为了解决资源的问题，比如一个同步RPC请求，在网络不稳定的情况下可能一直无法得到响应，那么请求线程将一直等待结果而无法执行其它任务，最终导致所有线程资源耗尽。超时机制正是为了解决这样的问题，在特定的等待时间之后触发一个“超时事件”来释放资源。\n在一个网络通信框架中，超时问题无处不在，连接的建立、数据的读写都可能遇到超时问题。并且网络通信框架作为分布式系统的底层组件，需要管理大量的连接，如何建立一个高效的超时处理机制就成为了一个问题。\n时间轮（TimeWheel） 在网络通信框架中动辄管理上万的连接，每个连接上都有很多的超时任务，如果每个超时任务都启动一个java.util.Timer，不仅低效而且会占用大量的资源。George Varghese 和 Tony Lauck在1996年发表了一篇论文：《Hashed and Hierarchical Timing Wheels: EfficientData Structures for Implementing a Timer Facility》来高效的管理和维护大量的定时任务。\n时间轮其实就是一种环形的数据结构，可以理解为时钟，每个格子代表一段时间，每次指针跳动一格就表示一段时间的流逝（就像时钟分为60格，秒针没跳动一格代表一秒钟）。时间轮每一格上都是一个链表，表示对应时间对应的超时任务，每次指针跳动到对应的格子上则执行链表中的超时任务。时间轮只需要一个线程执行指针的“跳动”来触发超时任务，且超时任务的插入和取消都是O(1)的操作，显然比java.util.Timer的方式要高效的多。\nSOFABolt的超时控制机制 如上图所示，SOFABolt中支持四中调用方式：\n oneway：不关心调用结果，所以不需要等待响应，那么就没有超时 sync：同步调用，在调用线程中等待响应 future：异步调用，返回future，由用户从future中获取结果 callback：异步调用，异步执行用户的callback 在oneway调用中，因为并不关心响应结果，所以没有超时的概念。下面具体介绍SOFABolt中同步调用（sync）和异步调用（future\\callback）的超时机制实现。  同步调用的超时控制实现 同步调用中，每一次调用都会阻塞调用线程等待服务端的响应，这种场景下同一时刻产生最大的超时任务取决于调用线程的数量。线程资源是非常昂贵的，用户的线程数是相对可控的，所以这种场景下，SOFABolt使用简单的java.util.concurrent.CountDownLatch来实现超时任务的触发。\nSOFABolt同步调用的代码如上，核心逻辑是：\n 创建InvokeFuture 在Netty的ChannelFuture中添加Listener，在写入操作失败的情况下通过future.putResponse方法修改Future状态（正常服务端响应也是通过future.putResponse来改变InvokeFuture的状态的，这个流程不展开说明） 写入出现异常的情况下也是通过future.putResponse方法修改Future状态 通过future.waitResponse来执行等待响应 其中和超时相关的是future.waitResponse的调用，InvokeFuture内部通过java.util.concurrent.CountDownLatch来实现超时触发。  java.util.concurrent.CountDownLatch#await(timeout, timeoutUnit) 方法实现了等待一段时间的逻辑，并且通过countDown方法来提前中断等待，SOFABolt中InvokeFuture通过构建new CountDownLatch(1)的实例，并将await和countDown方法包装为awaitResponse和putResponse来实现同步调用的超时控制。\n异步调用的超时控制实现 相对于同步调用，异步调用并不会阻塞调用线程，那么超时任务的数量并不受限于线程对的数量，用户可能通过一个线程来触发量大的请求，从而产生大量的定时任务。那么我们需要一个机制来管理大量的定时任务，并且作为系统底层的通信框架，需要保证这个机制尽量少的占用资源。上文已经提到TimeWheel是一个非常适合于这种场景的数据结构。\nNetty中实现了TimeWheel数据结构：io.netty.util.HashedWheelTimer，SOFABolt异步调用的超时控制直接依赖于Netty的io.netty.util.HashedWheelTimer实现。\nFuture模式和Callback模式在超时控制机制上一致的，下面以Callback为例分析异步调用的超时控制机制。\nSOFABolt异步调用的代码如上，核心逻辑是：\n 创建InvokeFuture 创建Timeout实例，Timeout实例的run方法中通过future.putResponse来修改InvokeFuture的状态 在Netty的ChannelFuture中添加Listener，在写入操作失败的情况下通过future.cancelTimeout来取消超时任务，通过future.putResponse来修改InvokeFuture的状态 在写入异常的情况下同样通过future.cancelTimeout来取消超时任务，通过future.putResponse来修改InvokeFuture的状态 在异步调用的实现中，通过Timeout来触发超时任务，相当于同步调用中的java.util.concurrent.CountDownLatch#await(timeout, timeoutUnit)。Future#cancelTimeout()方法则是调用了Timeout的cancel来取消超时任务，相当于同步调用中通过 java.util.concurrent.CountDownLatch#countDown() 来提前结束超时任务。具体超时任务的管理则全部委托给了Netty的Timer实现。 另外值得注意的一点是SOFABolt在使用Netty的Timer时采用了单例的模式，因为一般情况下使用一个Timer管理所有的超时任务即可，这样可以节省系统的开销。  Fail-Fast机制 以上关于SOFABolt的超时机制介绍都是关于SOFABolt客户端如何完成高效的超时任务管理的，其实在SOFABolt的服务端同样针对超时的场景做了优化。\n客户端为了应对没有响应的情况，增加了超时机制，那么就可能存在服务端返回一个响应但是客户端在收到这个响应之前已经认为请求超时了，移除了相关的请求上下文，那么这个响应对客户端来说就没有意义了。 …","date":1544091600,"description":"本篇我们会依次介绍编解码的概念， TCP 粘包拆包问题，SOFABolt 私有通信协议的设计，以及SOFABolt 编解码原理，最后还会介绍一下相较于 Netty，我们做出的优化。","dir":"blog/sofa-bolt-timeout-and-heart-beat-deep-dive/","fuzzywordcount":4400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"8f3ab1ecc952a0fc5ea40576e8b57471","permalink":"/blog/sofa-bolt-timeout-and-heart-beat-deep-dive/","publishdate":"2018-12-06T10:20:00Z","readingtime":9,"relpermalink":"/blog/sofa-bolt-timeout-and-heart-beat-deep-dive/","summary":"前言 SOFABolt 是一个基于 Netty 最佳实践的轻量、易用、高性能、易扩展的通信框架。目前已经运用在了蚂蚁中间件的微服务，消息中心，分布式事务，分布式开关，配置","tags":["SOFABolt","SOFALab","剖析 | SOFABolt 框架"],"title":"蚂蚁金服开源通信框架SOFABolt解析之超时控制机制及心跳机制","type":"blog","url":"/blog/sofa-bolt-timeout-and-heart-beat-deep-dive/","wordcount":4303},{"author":"任展","categories":"SOFABolt","content":"前言 SOFABolt 是一款基于 Netty 最佳实践，通用、高效、稳定的通信框架。目前已经运用在了蚂蚁中间件的微服务，消息中心，分布式事务，分布式开关，配置中心等众多产品上。\n本文将重点分析 SOFABolt 的连接管理功能。\n我们知道，一次 tcp 请求大致分为三个步骤：建立连接、通信、关闭连接。每次建立新连接都会经历三次握手，中间包含三次网络传输，对于高并发的系统，这是一笔不小的负担；关闭连接同样如此。为了减少每次网络调用请求的开销，对连接进行管理、复用，可以极大的提高系统的性能。\n下面我们将介绍 SOFABolt 在连接管理的实现，包括连接生命周期管理、定时断连及自动重连等。\n设计抽象 首先我们将会介绍 SOFABolt 对连接的封装抽象。\n连接封装 SOFABolt 中定义了一个基础的连接类 \u0026amp;ndash; Connection:\n省去 AtributeKey 类型定义以及 Log 配置，以上是Connection中所有的成员变量。包括几个方面:\n 连接：Channel、Url 版本：protocolCode、version 调用：invokeFutureMap 附着：attributes 引用：referenceCount、id2PoolKey、poolKeys  这里提一下 protocolCode 和 version，版本信息会被携带至对端，用于连接的协商。总的来说，通过对于 Channel 的包装，Connection 提供了丰富的上下文及引用信息，是 SOFABolt 连接管理的直接对象。\n连接事件 SOFABolt 定义了连接事件和事件监听器用于处理连接对象。ConnectionEventType 定义了三种事件类型：CONNECT, CLOSE 和 EXCEPTION. 针对不同的连接事件类型，我们可以通过事件监听器 \u0026amp;ndash; ConnectionEventListener 来进行处理，下面来看一下 ConnectionEventListener 类：\n监听器定义了两个方法 onEvent 和 addConnectionEventProcessor, 分别是触发事件和添加事件处理器。整个监听器采用一个 HashMap 来存储事件类型及其对应的处理器集合。在触发相关连接事件后，会遍历处理器集合并调用处理器执行。\nSOFABolt 的连接管理集中在 ConnectionEventHandler 中处理，他继承了 ChannelDuplexHandler，是标准的用来处理Connection连接对象并进行日志打印的一个处理器。先来看一下成员组成：\n其中连接事件监听器上文已经提及，剩下的几个成员从名称上也通俗易懂，先简单介绍一下，后续会详细地展开：\n 连接管理器：管理连接对象，包括创建、添加、删除、检查是否可用等等 连接事件监听器：监听连接事件的触发，然后执行对应的逻辑 连接事件执行器：包装后的线程池，用于异步触发连接事件监听器来处理对应的连接事件，值得一提的是，这个线程池只有一个线程。 重连管理器：顾名思义，管理重连的Url对象以及执行重连任务 全局开关：全局的设置，比如是否需要管理连接对象、是否需要执行重连任务等等  代码中方法都比较简单，大部分的处理逻辑围绕 Connection 对象展开，主要是维护有关本 Channel 对象的 Connection 对象的生命周期(包括connect、close等事件)。下面着重分析两个方法：\nhannelInactive 方法是在连接断开前触发的方法，在 SOFABolt 里的处理逻辑中，会根据globalSwitch 中 CONN_RECONNECT_SWITCH 的开关状态来判定是否开启重连的任务。除此之外，会在最后触发该 Connection 对象的 CLOSE 事件。这个触发事件是在异步线程中执行的，也就是上文提到的连接事件执行器。\n另一个是 userEventTriggered 方法， 用来触发自定义的用户事件，通过查看本方法的调用位置，可以得知，该方法是在连接建立的最初被触发的，一个简单的例子可以在RpcServer类中找到：\n在连接建立触发 fireUserEventTriggered 方法后，我们就开始执行对应此方法中的逻辑，也可以看到，在判定是 CONNECT 事件后，通过attr得到绑定在Channel的Connection对象，然后就同 channelInactive 方法一样，触发 CONNECT 事件异步执行对应的处理器逻辑。\n连接管理 下面来介绍 ConnectionManager，SOFABolt 提供了默认的实现类 DefaultConnectionManager类。顾名思义，主要负责连接对象的管理：\n 通过工厂创建 Connection 连接对象 通过注入的选择策略进行 Connection 连接的选择 管理创建和添加的 Connection 对象和 ConnectionPool 连接池对象（包括检查 Connection 对象、维护 ConnectionPool 的健壮性） 控制 Connection 对象的心跳打开与关闭  创建连接 ConnectionFactory 用于创建连接对象，SOFABolt 提供了两个实现类： DefaultConnectionFactory 和 RpcConnectionFactory。这个工厂类执行了客户端所有 Connection 对象的创建工作，代码也比较简单：\n注意到了吗，在创建完毕 Connection 对象后，执行了 fireUserEventTriggered 方法，这样就保证了每一个 Connection 对象在创建之后都会去触发 CONNECT 事件。\n选择连接 ConnectionSelectStrategy 选择策略的默认实现是随机策略 RandomSelectStrategy, 在执行选择连接时大致分为两步：\n 在开启CONN_MONITOR_SWITCH监控时，会从该连接池所有的连接中做一个简单的filter操作，把CONN_SERVICE_STATUS为ON的连接挑选出来，作为选择池。如果没有开启监控，那么选择池就是连接池。 执行挑选策略，获取选择池中的一个连接。  管理连接和连接池 管理连接和连接池是 ConnectionManager 最主要的作用，用来进行连接和连接池的生命周期管理，包括添加、删除、检查健康、恢复连接数等功能。下面先看一个在添加中常见的方法，用来获取一个连接池对象或者创建一个，限于篇幅，这里不贴代码，有兴趣的同学可以在 GitHub 上查看源码。在执行创建连接池对象时，会有两种逻辑:\n 返回空的连接池 返回一个初始化过的连接池(有一定的连接数)  这两种逻辑其实对应的是两种需求，第一个对应连接已经创建好然后放入连接池的流程，第二个则是对应通过 Url 来创建一个连接池并且在连接池中做新建连接的流程。那么对于第二种情况，由于建立连接需要耗时且有可能抛出异常，所以 ConnectionManager 允许重试两次。\n下面来说说对于连接和连接池的维护方面的功能，大概包含以下几个方面\n 检查单个连接的可用性  …","date":1544091600,"description":"本文将重点分析 SOFABolt 的连接管理功能。","dir":"blog/sofa-blot-connection-management-deep-dive/","fuzzywordcount":3500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"99733a6333604b8aeb8ada37d5705d36","permalink":"/blog/sofa-blot-connection-management-deep-dive/","publishdate":"2018-12-06T10:20:00Z","readingtime":7,"relpermalink":"/blog/sofa-blot-connection-management-deep-dive/","summary":"前言 SOFABolt 是一款基于 Netty 最佳实践，通用、高效、稳定的通信框架。目前已经运用在了蚂蚁中间件的微服务，消息中心，分布式事务，分布式开关，配置中心等众多","tags":["SOFABolt","SOFALab","剖析 | SOFABolt 框架"],"title":"蚂蚁金服开源通信框架SOFABolt解析之连接管理剖析","type":"blog","url":"/blog/sofa-blot-connection-management-deep-dive/","wordcount":3490},{"author":"奕杉","categories":"Service Mesh","content":" 朵晓东，花名奕杉，蚂蚁金服高级技术专家。专注企业云计算技术及产品，蚂蚁金融云 PaaS 创始团队核心成员，Antstack 网络产品负责人。开源爱好者，Apache Kylin 创始团队核心成员；SOFAMesh 创始团队核心成员，SOFAMosn 项目负责人。 本文根据晓东在 GIAC 上海站的演讲内容整理，完整的分享 PPT 获取方式见文章底部。\n 大家好，我是蚂蚁金服系统部的高级技术专家奕杉，今天分享的内容是: 《蚂蚁金服在 ServiceMesh 推进落地过程中对新型网络代理的思考和实践》\n内容结构： 主要的分享顺序：\n 背景概述 架构设计及功能特性 技术案例 总结展望  1、背景、概览 ServiceMesh 作为云原生之上的服务网格技术在今年引起了业界的广泛关注，首先我们来看一下目前 ServiceMesh 数据平面的一些方案。\n最为大家熟知的是老牌七层代理 Nginx 和 ISTIO 原生的数据平面 Envoy。Nginx 早已在国内外广泛使用，近两年积极探索 K8S、ServiceMesh 微服务场景，并推出了与 ISTIO 集成的微服务解决方案，试图扩展其场景边界，拿下新的领域，从单纯的7层流量代理到云原生时代的智能数据平面转型。但目前看 “NgMesh”研发不够活跃，已知的使用方也不多。Envoy 作为 Google 和 Lyft联合开发的 ISTIO 原生数据平面产品，近两年借助 ServiceMesh 微服务场景快速打开了市场，并在一些互联网公司推广使用，同时引入了一批开发者进行 API 网关等功能网关的开发，发展势头非常好。\n其次 LINKERD 是基于 Rust 的一种高性能数据平面，但其发展空间受到了 Envoy 挤压，业界使用的公司也比较有限。\n蚂蚁金服基于自身诉求自研了基于 Golang 的数据平面 SOFAMosn（后简称MOSN），并在蚂蚁、UC 等公司落地使用。 同时对业界开源，提供了一种新的数据平面产品选择。\n此外国内的华为、新浪等公司都基于自身场景提出了数据平面方案并先后进行了开源，数据平面竞争已经从独霸业界的基于 Nginx 二开方案逐步转变为目前的多样化产品同场竞技的局面。\n为什么众多大厂纷纷投入研发数据平面呢？\n我个人认为新生技术栈、云原生、微服务快速发展等契机对数据平面提出了场景多样化、功能服务化、云原生亲和等多重挑战。\n以往从未像现在这样对数据平面提出过如此多的要求：\n 数据平面需要执行部署运维中的流量切换； 需要提供云亲和的细粒度流量调度功能； 需要提供微服务亲和的服务发现、路由组网特性； 需要以云原生的方式感知资源； 需要支撑服务粒度、高度自定义的压测、故障测试、线上灰度流量管理； 需要提供链路级、服务级的安全隔离保护，需要支持多种语言、多种协议的转换分发能力； 需要能享受系统层面、硬件层面的红利； 需要为复杂的运维架构（如蚂蚁的 LDC 等）提供可扩展的流量调拨能力等等； 当然根据每个公司的业务场景可能还有其他的因素。  最后，如何要将这些能力都汇聚在统一的数据平面产品上，弥合南北向、东西向数据平面由于技术栈、团队等差异带来的鸿沟，变成了另一个更为复杂的问题。这里所提到的问题中任何一点扩展开来都可以是一个丰富独立的 Topic，受限于篇幅本次分享只能介绍我们在解决这些问题中的一小部分思考和实践。\n2、SOFAMesh 架构 \u0026amp;amp; 重点特性 首先，蚂蚁已经将基于 ISTIO 的 ServiceMesh 方案 \u0026amp;ldquo;SOFAMesh\u0026amp;rdquo; 开源，在控制面我们选择克隆 ISTIO 官方版本并研发符合蚂蚁需求的控制面，在数据面我们选择使用 Golang 研发数据平面 MOSN，目前已经支持了微服务场景所需的大量常用功能。\n这里我根据 ISTIO 的 Task 文档总结了目前 SOFAMesh 支持的一些能力，如：透明拦截适配，细粒度的流控，故障注入，双向链路加密等。对于一些暂时存疑的功能，如 Mixer Check 等，暂时没有支持。目前 SOFAMesh 已在 UC 生产环境落地使用，满足了 Sidecar、Ingress、Egress 多种场景的使用需求。在这里附上 SOFAMesh，SOFAMosn 的 Github 地址，也欢迎大家使用交流。\nSOFAMesh: https://github.com/alipay/sofa-mesh SOFAMosn: https://github.com/alipay/sofa-mosn\n再来看看蚂蚁内部，由于目前蚂蚁生产环境尚未大量铺开K8S，并且已经存在一套完善的管控技术体系，加上目前ISTIO 的性能和稳定性还不满足大规模微服务场景等原因，我们暂时没有选择直接升级到 ISTIO，而是通过优先落地Sidecar 的方式来赢得 ServiceMesh 解决方案带来的红利。在蚂蚁内部，MOSN 接管了SOFABoot 应用，代理了服务发现、路由/负载均衡、通信等工作，构成了微服务网格，通过自有的中间件及管控平面进行微服务的管理、治理。同时，我们积极的推进 MOSN 与 SOFA中间件，网络接入层，安全防护及监控体系的整合，以提供更统一更强大的数据平面。\n接下来我将介绍 MOSN 支持多协议的方案。\n为了在内部快速落地试错，我们首先支持了内部使用最广泛的 SOFARPC 协议，并对其进行了深度优化。随后我们根据 UC Mesh 化推进遇到的普遍问题提出了 XProtocol 方案，以在不解包的场景下提供路由能力。最后我们深度改造了三方 HTTP/1.1 实现及官方 HTTP/2.0 实现。到目前为止，MOSN 已提供了多种协议的支持。同时 MOSN 提供了两种自定义协议的能力支持使用者通过扩展的方式自定义协议实现，满足需要解包、不需要解包的协议扩展需求。\n除协议之外，性能是大家比较关心的另一个问题。为了提供满足生产要求的7层转发性能，我们在 IO、协议、内存、协程、网络处理等方面进行了优化，从目前通过 SOFARPC 通信应用的上线情况来看可以满足生产使用要求，在案例分析中我将展示一些性能数据，后续我们也将继续推进性能优化，以达到更好的性能。\n在安全能力上，SOFAMesh 支持 mTLS，并在蚂蚁内部集成蚂蚁内部的 KMS 完成了 mTLS 落地，同时 RBAC 功能在研发中，此外WAF、流量镜像能功能也在规划中。\n在蚂蚁内部基于 MOSN 的网关产品正在研发中，将会在稳定验证后开源。网关场景相对于 Sidecar 场景有一些特性需求，比如说一般会 Hold 住大量长链接，比如说会根据请求内容动态选择后端应用，由于网关可能代理了不同的后端应用，就会需要动态选择后端协议。此外还有一些网关类的通用能力需求，如签名，授权，限流等。\n为了能基于开源版建设蚂蚁内部的 Sidecar 及网关产品，我们充分考虑了开源版 MOSN 的扩展性，在路由、后端管理、TLS、网络、流处理等各方面提供了扩展性支持。对于其他使用 MOSN 的场景，也可以通过类似的方式来满足自身业务定制需求。\n为了更清晰的展示 MOSN 功能特性，这里将 MOSN 0.4.0 的功能特性通过表格的方式展示出来。可以 …","date":1543906800,"description":"本文根据晓东在 GIAC 上海站的演讲内容整理，完整的分享 PPT 获取方式见文章底部。","dir":"blog/service-mesh-giac-2018/","fuzzywordcount":7200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"71d6ede37fa4f1d1e6c99fbd37ff2f52","permalink":"/blog/service-mesh-giac-2018/","publishdate":"2018-12-04T15:00:00+08:00","readingtime":15,"relpermalink":"/blog/service-mesh-giac-2018/","summary":"朵晓东，花名奕杉，蚂蚁金服高级技术专家。专注企业云计算技术及产品，蚂蚁金融云 PaaS 创始团队核心成员，Antstack 网络产品负责人。开源爱好者，","tags":["Service Mesh"],"title":"蚂蚁金服 Service Mesh 新型网络代理的思考与实践","type":"blog","url":"/blog/service-mesh-giac-2018/","wordcount":7130},{"author":"敖小剑","categories":"Service Mesh","content":" 敖小剑，蚂蚁金服高级技术专家，十六年软件开发经验，微服务专家，Service Mesh 布道师，Servicemesher 社区联合创始人。 龙轼，阿里巴巴技术专家、前京东 Hadoop 负责人、Hadoop 代码贡献者、现负责UC 基于 Kubernetes 自研的 PaaS 平台整体的稳定性。 本文根据他们在 Service Mesher Meetup 上海站的演讲内容整理，完整的分享 PPT 获取方式见文章底部。\n 大家好，今天给大家带来的演讲主题是《蚂蚁金服 Service Mesh 渐进式迁移方案》，给大家介绍一下我们蚂蚁金服主站的 Service Mesh 迁移方案，在稍后的内容中我会给大家解释什么是“渐进式”。今天的演讲方式有些特殊，将会是两位讲师合作。我是敖小剑，来自蚂蚁金服中间件团队，另外一位讲师 龙轼 ，来自 UC 基础研发部。\nService Mesh 演进路线 今天的内容将会有四块主要内容：\n Service Mesh演进路线：介绍蚂蚁金服计划在主站落地Service Mesh的方案，由于涉及到大量的存量应用和超大规模，又要保证迁移过程的平滑，因此我们的落地方案相比社区方案要复杂的多。 实现平滑迁移的关键：介绍在整个迁移方案中，为了实现平滑迁移的几个关键做法，然后今天我们将详细展开其他的一个关键点：DNS寻址方案。 DNS寻址方案的演进：详细介绍Kubernetes/Istio/SOFAMesh一路演进过来的DNS寻址方式 DNS寻址方案的后续规划：介绍我们在DNS寻址方案上的后续规划。  前两块内容将由我来为大家介绍，后两块内容将由我的同事 龙轼 为大家介绍。\n在展开内容之前，先看一下背景，Service Mesh在蚂蚁金服主站落地的背景：\n 目标：需要满足我们对长期目标的认可，具体指服务间通讯走Service Mesh，而且是Istio这种带完整的控制平面的Service Mesh形态，基础设施要构建在k8s之上，而应用的形态要向微服务靠拢。 现状：而现实是存在很多挑战，首先还有很多应用没有实现微服务化，而且我们的k8s普及程度也不够，还有非常多的应用没有运行在kubernets之上。Istio的成熟程度也稍显不足，不够稳定，更大的挑战的是Istio目前无法原生支持我们蚂蚁金服的规模，我们还在试图对Istio进行改进和扩展。最后，在落地时必须考虑的非常现实的一点：现有系统中为数众多的应用不可能一夜之间全部迁移。 关键需求：因此在落地实施时，非常重要的需求是：要实现平滑迁移。简单说，微服务 + Service Mesh + kubernetes 是我们的目标，但是如何从现有体系出发，向目标平稳和坚实的迈进，必须给出可行的实践指导。  今天演讲的内容，要给大家介绍的就是，在这样的背景下，我们蚂蚁金服选择的Service Mesh主站落地演进方案。这个方案预期会在2019年初全面铺开。\n主站落地方案的实施原则，这是我们在过去半年的实践中，总结归纳出来的行为指导：\n 符合远期规划：一定要有清晰的长期目标，明确的知道未来的大方向。避免走弯路，避免浪费投资，理想状态是计划中的每一步都可以为下一步奠定坚实的基础。即使因为某些原因不得已妥协或绕行，也应该清晰的知道后面应该如何回归，谢绝中途推倒重来——代价太高，无法承受。 循序渐进：认清现实，如此之大的变革，一定是需要分步进行，不要心存一步登天的幻想，现实可行的方式是小步快跑。将整个过程拆解为若干个大步骤，每一步的工作量和复杂度都控制在一个可以接受的范围内，以保证每一步都简单方便，切实可行。 有可操作性：在操作层面上，要有足够的弹性，即每个步骤中的工作内容，都应该是可以分批进行。以步步为营的方式，逐步扩大战果，杜绝一刀切。  在接下来的演进路线中，大家将会体会到这三个原则在实际落地时的指导作用。\n这个图的信息量有点大，描述的是 Service Mesh 和 k8s 落地可能的多种演进路线。\n我们先从最下面开始看，这是当前蚂蚁金服主站大多数应用的现状：即应用\u0026amp;quot;部署在非k8s上\u0026amp;quot;，应用也\u0026amp;quot;不是Service Mesh形态\u0026amp;quot;。 然后看最上面，这是我们期望的蚂蚁金服主站未来的应用终极形态：应用\u0026amp;quot;部署在k8s上\u0026amp;quot;，应用也迁移到了\u0026amp;quot;Service Mesh形态\u0026amp;quot;。\n这里有个特别的地方，我们将Service Mesh形态细分为两种模式：\n Sidecar模式：只有Sidecar，没有控制平面，和外部系统的各种集成都是在Sidecar中直接进行。这是第一代的Service Mesh，Linkerd/Envoy都是如此，华为基于ServiceComb演进而来的mesher，新浪微博的Mesh，包括我们蚂蚁金服基于MOSN开发的用于取代多语言客户端的Mesh方案。 Istio模式：有完善的控制平面，可以提供强大的控制能力，而且从数据平面分离，这是第二代的Service Mesh，典型如Istio和Conkduit/Linkerd 2.0。  之所以将Service Mesh形态细分，是因为我们有着这样一个特殊背景：目前的原生Istio无法支撑我们蚂蚁金服的规模，因此在改进完善Istio之前，我们不得不暂时在Sidecar模式下短暂停留。另外一个原因就是考虑到存量应用的迁移，多一个Sidecar模式作为中间缓冲，会让整个迁移过程平滑很多。\n现在我们来介绍图中展示的四条演进路线：\n 左边的路线1，思路是先将应用迁移k8s部署，再迁移到Service Mesh形态。这条路线的最大好处，是过程中每个阶段的绝大多数投资都将最终得以保留，因为符合k8s+service mesh的远期目标。 右边的路线2，思路是跳过k8s，先迁移到Service Mesh形态，一路演进到Istio模式，然后最后迁移到k8s。 中间的路线3，直接一步到位，这个路线是Istio默认的方式，或者说Istio根本没有考虑过迁移的问题，默认客户已经有完善的k8s，然后将改造好的应用直接部署在Istio上。这个路线对于蚂蚁金服主站的复杂场景，当然是不现实的。（补充：只是对蚂蚁金服主站不合适，对于大多数公司，规模不是那么巨大，也没有历史负担，也有k8s基础，完全可行。） 还有一条特别的路线4，走位飘忽，先和路线2一样迁移到Sidecar模式，然后走回路线1，上k8s，再在有k8s支持的情况下继续演进到Istio模式。  下面我们来详细分析各条演进路线的优劣和实施条件。\n演进路线2，和路线1的核心差别，在于：是先上k8s，还是先上Service Mesh。而且路线2是在非k8s条件下一路演进Service Mesh到我们期望的终极形态Istio模式，这意味着过程中和最终目标有非常大的偏移。\n演进路线2的好处，在于第一步非常的自然：\n 没有k8s的限制，因此不依赖基础设施，实施方便。毕竟，k8s普及度是个大问题； 在原有的侵入式框架的客户端SDK基础上，通过包裹一个proxy，重用原有SDK的能力，可以非常快速的得到一个基本可用的Sidecar； 除了多一个proxy外，没有引入太多的新概念和新思想，符合现有开发 …","date":1543474800,"description":"本文根据敖小剑、龙轼在 Service Mesher Meetup 上海站的演讲内容整理，完整的分享 PPT 获取方式见文章底部。","dir":"blog/service-mesh-meetup-5-retrospect/","fuzzywordcount":10300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"5031be4287bf1a7d7921bf5133ea414c","permalink":"/blog/service-mesh-meetup-5-retrospect/","publishdate":"2018-11-29T15:00:00+08:00","readingtime":21,"relpermalink":"/blog/service-mesh-meetup-5-retrospect/","summary":"敖小剑，蚂蚁金服高级技术专家，十六年软件开发经验，微服务专家，Service Mesh 布道师，Servicemesher 社区联合创始人。 龙轼，阿里巴","tags":["Service Mesh"],"title":"Service Mesh 渐进式迁移方案 | Service Mesh Meetup 实录","type":"blog","url":"/blog/service-mesh-meetup-5-retrospect/","wordcount":10251},{"author":"鲁直","categories":"SOFAMesh","content":" 本文作者：黄挺，蚂蚁金服高级技术专家，蚂蚁金服分布式架构 SOFA 的开源负责人。目前在蚂蚁金服中间件团队负责应用框架与服务化相关的工作。 本文根据黄挺在 CNUTCon 全球运维大会的主题分享整理，完整的分享 PPT 获取方式见文章底部。\n 大家好，我是来自于蚂蚁金服的黄挺，花名鲁直，目前在蚂蚁金服负责微服务团队，也是 SOFA 开源的负责人。来到这个场子的朋友们肯定都知道，Service Mesh 在过去一两年之中迅速成长为社区中非常热门的话题，几乎所有的大会中，都多多少少有一些关于 Service Mesh 的话题。在一个月之前，我的同事敖小剑老师在上海的 QCon 中也分享了蚂蚁金服在 Service Mesh 上的探索，包括在前面的场次中，来自华为的巨震老师也分享了华为在 Service Mesh 上的一些思考。在今天的分享中，我不会去花太多时间介绍什么是 Service Mesh，更多地聚焦在蚂蚁金服将 Service Mesh 用在解决多语言的问题上的一些实践，希望在场的各位可以从这些实践中有所收获。\n这个是我今天介绍的主要的内容，首先，我会大家简单介绍一下多语言在蚂蚁金服发展的一些情况，铺垫一下背景，交代各个语言在蚂蚁金服的使用情况，并且之前在多语言通信上面遇到了哪些问题。\n然后，我会给大家简单介绍下 SOFAMesh，SOFAMesh 是蚂蚁金服产出的 Service Mesh 的解决方案。\n接着我会介绍我们在 SOFAMesh 之上架构的多语言通信的方案以及在这个方案的实施过程中遇到的一些技术要点。\n蚂蚁金服多语言发展 不知道在场的同学有没有听说过 SOFA，SOFA 是蚂蚁金服大约 10 年前开始研发的一套分布式中间件，包括了微服务体系，分布式事务，消息中间件，数据访问代理等等组件，这套组件一直以来都是完全用 Java 来构建的，因此基于 SOFA 构建的 SOFA 应用也都是用 Java 写的，在蚂蚁金服，目前大概有接近 2000 个 SOFA 应用，顺带提一下，这套 SOFA 中间件目前已经部分开源在 Github 上面。从这个数据我们也可以显而易见地得出以下的结论，Java 在蚂蚁金服，至少在在线的应用上，占据了绝对主导的地位。\n随着无线技术的发展以及 NodeJS 技术的兴起，在 2013 年，蚂蚁金服开始引入了 NodeJS，研发了 EggJS，目前也已经在 Github 上开源，在蚂蚁金服，我们主要将 EggJS 作为服务于无线以及 PC 的 BFF 层来使用，后端的所有的微服务还都是用基于 Java 的 SOFA 来研发，EggJS 要调用后端的 SOFA 服务，并且对 PC 和无线端提供接口，必然就要遵守 Java 世界的 SOFA 之前定下的种种“规矩”，事实上，蚂蚁金服的 NodeJS 团队完全用 EggJS 适配了所有的 SOFA 中间件的客户端，保证在 EggJS 上，也可以使用所有的 SOFA 中间件，可以和之前基于 Java 研发的 SOFA 应用进行通信。但是，由于 Java 在蚂蚁中间件上的主导地位，导致 SOFA 中间件的某些特性的实现，完全依赖于 Java 特有的语言特性，因此，NodeJS 团队在追赶 SOFA 中间件的过程中，也非常的痛苦，在后面的例子中，我会有一些具体的例子，大家看了之后肯定会感同身受。\n再到最近几年，随着 AI 的兴起，在蚂蚁金服也越来越多地出现 CPP，Python 等系统，而由于 CPP 和 Python 等等语言，在蚂蚁金服并没有一个独立的基础设施团队去研发对应的中间件，因此，他们和基于 Java 的 SOFA 应用的互通就降级成了直接采用 HTTP 来通信，这种方式虽然也可以 Work，但是在通信基础之上的服务调用的能力却完全没有，和原本的 SOFA 的基础设施也完全没法连接在一起。\n基于以上的一些现状，可以看到我们在发展过程中的主要的两个问题，一个是基础设施上的重复投入的消耗，很多 SOFA 中间件的特性，除了用 Java 写了一遍之外，还得用 NodeJS 再写一遍。另一个是以 Java 为中心，以 Java 为中心其实在只有 Java 作为开发语言的时候并没有什么问题，但是当其他的语言需要和你进行通信的时候，就会出现巨大的问题，事实上，很多框架上的特性的研发同学在不经意之间，就直接就用了 Java 的语言特有的特性去进行研发，这种惯性和隐性的思维会对其他语言造成巨大的壁垒。\n基于以上的问题，我们希望能够产出一个方案，一方面，可以尽量做到一次实现，到处可用。另一方面，需要能够保证语言的中立性，最好是能够天然地就可以让框架或者中间件的研发的同学去在做架构设计以及编码的时候，考虑到需要支持多语言。\nSOFAMesh 其实在这之前，我们已经尝试在数据访问层去解决类似的多语言适配的问题，蚂蚁金服有一个 OceanBase 的数据库，当各个语言需要访问 OceanBase 数据库的时候，采用的就是一个本地的 Proxy，这个 Proxy 会负责 Fail Over，容灾等等场景，而对各个语言只要保证 SQL 上的兼容就可以了，这让我们意识到，Proxy 的模式可能是解决多语言的一个方式，然后，在业界就出现了 Service Mesh，如果只是从技术上讲，Service Mesh 的 Sidecar 本质上也就是一个 Proxy，只是每一个服务实例都加上一个 Sidecar，这些 Sidecar 组成了一个网络，在加上一个控制平面，大家把他叫做 Service Mesh。通过 Service Mesh，我们可以将大量原来需要在语言库中实现的特性下沉到 Sidecar 中，从而达到一次实现，到处可用的效果；另外，因为 Sidecar 本身不以 Library 的形式集成到特定语言实现的服务中，因此也就不会说某些关键特性采用特定语言的特性来实现，可以保证良好的中立性。\n看起来 Service Mesh 似乎是一个非常完美的解决方案，但是如果我们探寻一下 Service Mesh 的本质的话，就会发现 Service Mesh 并非完美解决方案，这种不完美主要是体现在 Service Mesh 本质上是一种抽象，它抽象了什么东西，它把原来的服务调用中的一些高可用的能力全部抽象到了基础设施层。在这张 PPT 中，我放了三张图片，都是一棵树，从左到右，越来越抽象，从图中也可以非常直观地看出来，从右到左，细节越来越丰富。不管是什么东西，抽象就意味着细节的丢失，丢失了细节，就意味着在能力上会有所欠缺，所以，在 Service Mesh 的方案下，虽然看起来我们可以通过将能力下层到基础设施层，但是一旦下层下去，某些方面的能力就会受损。\n因此，我们希望能够演化出这样一套多语言通信的方案，它能够以 Service Mesh 为基础，但是我们也会做适当地妥协去弥补因为上了 Service Mesh 之后的一些能力的缺失。首先我们希望有一个语言中立的高效的通信协议，每个语言都能够非常简单地理解这个协议，这个是在一个跨语言的 RPC 通信中避免不了的，无论是否采用 Service Mesh。然后， …","date":1542870000,"description":"本文根据黄挺在 CNUTCon 全球运维大会的主题分享整理，完整的分享 PPT 获取方式见文章底部。。","dir":"blog/sofa-mesh-cnutcon-2018/","fuzzywordcount":7000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"5a750edaa8c6a9759fd5e3533dd3fa4d","permalink":"/blog/sofa-mesh-cnutcon-2018/","publishdate":"2018-11-22T15:00:00+08:00","readingtime":14,"relpermalink":"/blog/sofa-mesh-cnutcon-2018/","summary":"本文作者：黄挺，蚂蚁金服高级技术专家，蚂蚁金服分布式架构 SOFA 的开源负责人。目前在蚂蚁金服中间件团队负责应用框架与服务化相关的工作。 本文根据黄挺","tags":["SOFAMesh"],"title":"蚂蚁金服 SOFAMesh 在多语言上的探索实践","type":"blog","url":"/blog/sofa-mesh-cnutcon-2018/","wordcount":6910},{"author":"明不二","categories":"SOFARPC","content":" SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文为《剖析 | SOFARPC 框架》最后一篇，作者明不二，就职于华为。 《剖析 | SOFARPC 框架》系列由 SOFA 团队和源码爱好者们出品， 项目代号：SOFA:RPCLab/，官方目录目前已经全部完成，感谢所有参与的源码爱好者！\n 前言 在应用服务化架构中，RPC 框架是非常重要的基础组件。而在 RPC 框架当中，序列化（以及反序列化）又是必不可少的一环。因为序列化的性能对整体框架性能有比较大的影响，之前的文章中，我们已经详细剖析了 SOFARPC 各个核心功能模块的实现原理，想必大家已经很清楚 RPC 的调用流程。\n在整个 RPC 调用流程当中，序列化及反序列化起到了承上启下的作用。序列化时，RPC客户端把待调用的方法和参数对象转换为网络上可传输的字节序列，为进一步的编解码提供原料。反序列化时，把从网络上接收到且已经解码了的字节序列转换成对象，便于 RPC 服务端调用。\n本文将从序列化概述、序列化协议特性、序列化使用方法分类、SOFARPC 序列化的设计及实现、几种序列化协议对比等方面介绍及对比序列化及其在 SOFARPC 中的应用。\n序列化概述 RPC 调用通过网络传输相关的调用方法及参数，在这个网络传输过程中，内存中的对象是无法直接传输的，只有二进制字节才能在网络上传输。而为了实现调用对象在网络上的传输，必须通过序列化实现对象 -\u0026amp;gt; 字节的过程，以及反序列化实现字节 -\u0026amp;gt; 对象的过程。在网络协议模型中，序列化属于应用层协议的一部分。\n如下列定义：\n序列化：将数据结构或者对象转换成二进制串的过程。\n反序列化：将序列化过程中生成的二进制串转换成数据结构或者对象的过程。\n在上述定义中，二进制字节数组专指 Java 语言中的 byte[]。\n序列化协议特性 每种序列化协议都有其优点和缺点，在对一个序列化协议进行衡量评判时，通常由如下一些指标可以参考：\n   指标 说明 重要性     通用性 是否跨平台，社区如何 中高   可读 序列化格式是否可读 中低   易用性 是否简单易用 中高   性能 序列化后的大小和压缩 CPU消耗 中高   可扩展性 是在允许字段修改 高   安全性 是否存在一些无法修复的漏洞 高    以下逐个来详细说明：\n通用性 在通用性上，主要考察该序列化协议是否支持跨平台、跨语言的使用，同时兼顾考察业界的流行度及社区的活跃性。\n可读/易用性 在可读、易用性上面，主要考察该序列化协议序列化之后是否人眼可读，如 XML 和 JSON 就是人眼可读的序列化框架，这会大大提高调试的效率。同时，需要考察序列化框架所提供的 API 是否容易学习、调用。当然，在远程调用 的场景下，可读性不是一个重要因素。或者说，我们更多希望不可读。来保证一定的安全性。\n性能 性能指标，主要考虑序列化框架的时间复杂度和空间复杂度。\n序列化之后的数据一般都是用于存储或者网络传输，空间占用大小决定了传输的效率。序列化通常情况下要在原有的数据上加上描述字段，如果这个过程中引入的额外开销过大，则在大规模分布式系统中，很可能会造成巨大的额外空间开销。\n同时，为了提高系统的性能，是否耗费 CPU，解析和反解析二进制串的时间也是一个非常重要的指标。\n可扩展性 主要考虑当系统准备升级，需要对实体的属性进行变更，此时序列化协议能否快速支持，并且不会对原有的系统造成影响。如作为服务提供方的 API 接口入参中，增加了一个字段，是否一定要强制所有的客户端进行升级。这个会涉及到线上兼容性的问题。一般我们要求新增字段，在客户端尚未使用的情况下，不应该有序列化问题。\n安全性 需要考察序列化协议是否支持跨局域网之间的安全访问。是否存在一些安全漏洞。可以通过构造一些字节数组，使得服务端反序列化的时候，触发某些安全漏洞，执行一些系统调用，或者越权操作。\n序列化使用方式分类 按照序列化的使用方式，可以分为自描述型序列化以及基于中间格式型序列化。\n自描述型 所谓的自描述型，即在序列化的字节流里有着完整的对象类型信息和属性信息，可以在不依赖任何外界描述信息的前提下，只要拿到这个二进制流，就可以直接还原出原始对象。\n类似的系列化产品有：hessian、JSON、XML 等。\n例如，有如下一个对象 Person，Java 语言定义如下：\npackage com.sofa.test.Person; public class Person { private int age = 15; private String name = “sofa”; } 则使用 hessian 序列化后的字节流如下：\nM**com.sofa.test.PersonS**nameS**sofaS**ageI**b3 b2 b1 b0 z\n上面的*和b3 b2 b1 b0都表示不可打印的二进制。从上面内容可以看出，按照相应规定就能从二进制串中反序列化出对象来。因为这里面已经描述了类型，类型的字段名，以及对应的值，这样就可以直接反序列化了。\n基于中间描述型 一般这种类型的序列化主要用于跨语言当中，比如 Protobuf以及 thrift 等等。在使用时都需要事先定义一个中间格式的文件（IDL 文件），然后根据不同语言的生成工具生成一个相应语言的可序列化类。以下是一个简单的 Proto的描述文件\nmessage SofaApp{ string appName = 1; repeated string authList = 2; repeated string serviceList = 3; } 然后当需要反序列化时，根据 IDL 文件及逆行相应的反序列化即可。格式是这样\n其中，图中的用户定义编号就是前面 proto中对每个字段定义的编号。\nSOFARPC 序列化的设计与实现 SOFARPC 支持及将要支持的序列化协议有：hessian、Protobuf、Json。\n序列化接口定义 在目前的 SOFARPC 5.4 分支中，已经支持的序列化协议有 hessian 和 Protobuf。两个序列化实现类继承了 AbstractSerializer 抽象类，该抽象类又实现了如下的 Serializer 接口：\n/** * 序列化器接口 * * @author \u0026amp;lt;a href=mailto:zhanggeng.zg@antfin.com\u0026amp;gt;GengZhang\u0026amp;lt;/a\u0026amp;gt; */ @Extensible(coded = true) @Unstable public interface Serializer { /** * 序列化 * * @param object 对象 * @param context 上下文 * @return 序列化后的对象 * @throws SofaRpcException 序列化异常 */ public AbstractByteBuf encode(Object object, Map\u0026amp;lt;String, …","date":1541055600,"description":"本文为《剖析 | SOFARPC 框架》最后一篇，作者明不二，就职于华为。","dir":"blog/sofa-rpc-serialization-comparison/","fuzzywordcount":3300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"f0a5fd044fa69071a7251518ea7d69f6","permalink":"/blog/sofa-rpc-serialization-comparison/","publishdate":"2018-11-01T15:00:00+08:00","readingtime":7,"relpermalink":"/blog/sofa-rpc-serialization-comparison/","summary":"SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文为《剖析 |","tags":["SOFARPC","剖析 | SOFARPC 框架","SOFALab"],"title":"【剖析 | SOFARPC 框架】之 SOFARPC 序列化比较","type":"blog","url":"/blog/sofa-rpc-serialization-comparison/","wordcount":3236},{"author":"鸥波","categories":"SOFARPC","content":" SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文为《剖析 | SOFARPC 框架》第十二篇，作者鸥波。 《剖析 | SOFARPC 框架》系列由 SOFA 团队和源码爱好者们出品， 项目代号：SOFA:RPCLab/，官方目录目前已经全部认领完毕。\n 前言 随着 TIOBE 10月份的编程语言排行 的发布，C++重回第三的位置，新兴的 Swift 和 Go 表现出强劲的上升趋势。与此同时，虽然目前 Java 的领头位置尚未出现有力挑战，我们希望能够在基础设施的建设上预留跨语言的可扩展设计。同时，跨语言的挑战也是工程实际面临的现状，蚂蚁内部如 AI、IoT，算法等缺少 JVM 原生支持的领域，往往不可避免地需要涉及到跨语言调用的问题。\n本文将为大家介绍 基于 SOFARPC 的微服务应用在面临跨语言调用时的方案和实现。\n总体设计 经过前面几篇对 SOFARPC 的 BOLT 协议和序列化这些的介绍，相信大家已经对 RPC 有了一些自己的理解，提到跨语言，我们会首先想到其他语言调用 Java，Java 调用其他语言，那么这里的跨，体现在代码上，到底跨在哪里？\n从跨语言的实现上来说，主要解决两个方面的问题：\n  跨语言的通讯协议和序列化协议\n  跨语言服务发现\n  另外从跨语言的落地来说，还得解决一个平滑兼容的问题。\n业界常见的做法是一般是通过 DNS 和 HTTP 来解决跨语言的问题，但是在内部已经有完善技术栈体系的情况下，直接切换一个新的方案显然是不合适的，所以蚂蚁内部是在已有的技术体系基础上进行改进。\n蚂蚁内部使用的通讯协议是Bolt，序列化协议是Hessian。我们知道，服务端和客户端在请求和返回之间携带的结构化的业务数据，需要在传输到达对端后，被本地的语言能够易于解析消费。由于语言本身特性的差异，同一对象的在序列化和反序列化的转换后，结构可能有差异，但是需要保证其转换操作是可逆的。以上这点Hessian做的不是很好，其跨语言的兼容性不能满足跨语言的需求，所以另外一个可行的方案就是就是选择其它基于 IDL 的序列化协议，例如Protobuf。\n现成的服务注册中心一般都有一些多语言解决方案，像Zookeeper、SOFARegistry、Consul、etcd等都有多语言客户端，所以服务发现这块问题不算太大。\n例如下面就是一个基于注册中心 + Bolt 协议 + Protobuf 序列化的设计图。\n通讯协议和序列化协议 通讯协议只要跨语言各方约定清楚，大家安装约定实现即可，而序列化协议则需要较多的考量。\n序列化的协议选择列出一些考虑要点：\n  是否采用具备自我描述能力的序列化方案，如不需要借助一些 schema 或者接口描述文件。\n  是否为语言无关的，包括脚本语言在内。\n  是否压缩比例足够小，满足网络传输场景的要求。\n  是否序列化和反序列化的性能均足够优秀。\n  是否向前/向后兼容，能够处理传输对象的新增属性在服务端和客户端版本不一致的情况。\n  是否支持加密、签名、压缩以及扩展的上下文。\n  JSON Over HTTP 首先，说到跨语言，序列化支持，肯定有同学会问，为什么不直接通过 Http的Json来搞定呢？\n虽然得益于JSON和HTTP在各个语言的广泛支持，在多语言场景下改造支持非常便捷，能够低成本的解决网络通讯和序列化的问题。服务发现的过程则可以使用最简单的固定URL（协议+域名+端口+路径）的形式，负载均衡依赖于F5或者LVS等实现。\n但是这个方案的有明显的局限性：\n  HTTP 作为无状态的应用层协议，在性能上相比基于传输层协议（TCP）的方案处于劣势。HTTP/1.1后可以通过设置keep-alive使用长连接，可以一定程度上规避建立连接的时间损耗；然而最大的问题是，客户端线程采用了 request-response 的模式，在发送了 request 之后被阻塞，直到拿到 response 之后才能继续发送。这一问题直到 HTTP/2.0 才被解决。\n  JSON 是基于明文的序列化，较二进制的序列化方案，其序列化的结果可读性强，但是压缩率和性能仍有差距，这种对于互联网高并发业务场景下，意味着硬件成本的提升。\n  对于网络变化的响应。订阅端处理不够强大。\n  Hessian Over BOLT 在否决了上一个方案后，我们继续看，蚂蚁内部，最开始的时候，SOFARPC 还没有支持 Protobuf 作为序列化方式，当时为了跨语言，NodeJs的同学已经在此基础上，用 js 重写了一个 hessian 的版本，完成了序列化。也已经在线上平稳运行。但是当我们要扩展给其他语言的时候，重写 hessian 的成本太高。而且 Java语言提供的接口和参数信息，其他语言也需要自己理解一遍，对应地转换成自己的语言对象。因此该方案在特定场景下是可行的。但不具备推广至其他语言的优势。\nNode的实现版本可以参考：https://github.com/alipay/sofa-rpc-node\nProtobuf Over BOLT Protobuf 基于IDL，本身具备平台无关、跨语言的特性，是一个理想的序列化方案。但是需要先编写proto文件，结构化地描述传输的业务对象，并生成中间代码。\n由于要重点介绍一下这种方案，因此再次回顾一下SOFABolt的协议规范部分，便于后面的解释。\nRequest command protocol for v1 0 1 2 4 6 8 10 12 14 16 +-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+ |proto| type| cmdcode |ver2 | requestId |codec| timeout | classLen | +-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+ |headerLen | contentLen | ... ... | +-----------+-----------+-----------+ + | className + header + content bytes | + + | ... ... | +-----------------------------------------------------------------------------------------------+ codec: code for codec 序列化,hessian 是1,pb 是11,java 是2 Response command protocol for v1 0 1 2 3 4 6 8 10 12 14 16 …","date":1540969200,"description":"本文为《剖析 | SOFARPC 框架》第十二篇，作者鸥波。","dir":"blog/sofa-rpc-cross-language-support/","fuzzywordcount":3800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"28621f1b90e6ce8edf1b3e446fa5be23","permalink":"/blog/sofa-rpc-cross-language-support/","publishdate":"2018-10-31T15:00:00+08:00","readingtime":8,"relpermalink":"/blog/sofa-rpc-cross-language-support/","summary":"SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文为《剖析 |","tags":["SOFARPC","剖析 | SOFARPC 框架","SOFALab"],"title":"【剖析 | SOFARPC 框架】之SOFARPC 跨语言支持剖析","type":"blog","url":"/blog/sofa-rpc-cross-language-support/","wordcount":3741},{"author":"敏古","categories":"SOFARPC","content":" SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文为《剖析 | SOFARPC 框架》第十一篇，作者敏古。 《剖析 | SOFARPC 框架》系列由 SOFA 团队和源码爱好者们出品， 项目代号：SOFA:RPCLab/，官方目录目前已经全部认领完毕。 SOFARPC：https://github.com/sofastack/sofa-rpc\n 1、前言 在 SOFABoot 环境下，SOFARPC 提供三种方式给开发人员发布和引用 RPC 服务：\n  XML 方式（配置）\n  Annotation 方式（注解）\n  编程 API 方式（动态）\n  编程 API 方式与Spring 的 ApplicationContextAware 类似。XML的方式依赖于在xml中引入 SOFA 命名空间，利用 Bean 的生命周期管理，进行 Bean 的注入。相比这两种方式，通过 Annotation 方式发布 JVM 服务更加灵活方便，只需要在实现类上加 @SofaService、@SofaRefernce 注解即可进行服务的发布和引用。本文针对 SOFARPC 在注解的支持和使用分原理、源码两部分进行一一介绍。\n2、原理介绍 2.1、注解是什么 注解又称为元数据，可以对代码中添加信息，这是一种形式化的方法，可以在稍后的某个时刻非常方便地使用这些数据。这个时刻可能是编译时，也可能是运行时。\n注解是JDK1.5版本开始引入的一个特性，用于对代码进行说明，可以对包、类、接口、字段、方法参数、局部变量等进行注解。注解的本质就是一个继承了 Annotation 接口的接口。一个注解准确意义上来说，只不过是一种特殊的注释而已，如果没有解析它的代码，它可能连注释都不如。\n一般常用的注解可以分为三类：\n  Java自带的标准注解，包括@Override（标明重写某个方法）、@Deprecated（标明某个类或方法过时）和@SuppressWarnings（标明要忽略的警告）。\n  元注解，元注解是用于定义注解的注解。\n  自定义注解，可以根据自己的需求定义注解。\n  2.2、元注解 元注解是用于修饰注解的注解，通常用在注解的定义上。JAVA 中有以下几个元注解：\n @Target：注解的作用目标，也就是指明，你的注解到底是用来修饰方法的？修饰类的？还是用来修饰字段属性的，有以下几种类型：   ElementType.TYPE：允许被修饰的注解作用在类、接口和枚举上 ElementType.FIELD：允许作用在属性字段上 ElementType.METHOD：允许作用在方法上 ElementType.PARAMETER：允许作用在方法参数上 ElementType.CONSTRUCTOR：允许作用在构造器上 ElementType.LOCAL_VARIABLE：允许作用在本地局部变量上 ElementType.ANNOTATION_TYPE：允许作用在注解上 ElementType.PACKAGE：允许作用在包上  @Retention：指定了被修饰的注解的生命周期，分以下三种类型：   RetentionPolicy.SOURCE：该注解只保留在一个源文件当中，当编译器将源文件编译成class文件时，它不会将源文件中定义的注解保留在class文件中。 RetentionPolicy.CLASS：该注解只保留在一个class文件当中，当加载class文件到内存时，虚拟机会将注解去掉，从而在程序中不能访问。 RetentionPolicy.RUNTIME：该注解在程序运行期间都会存在内存当中。此时，我们可以通过反射来获得定义在某个类上的所有注解。   @Documented：当我们执行 JavaDoc 文档打包时会被保存进 doc 文档，反之将在打包时丢弃。\n  @Inherited：解修饰的注解是具有可继承性的，也就说我们的注解修饰了一个类，而该类的子类将自动继承父类的该注解。\n  以 @Override 为例子：\n当编译器检测到某个方法被修饰了 @Override 注解，编译器就会检查当前方法的方法签名是否真正重写了父类的某个方法，也就是比较父类中是否具有一个同样的方法签名。\n@Override 仅被编译器可知，编译器在对 java 文件进行编译成字节码的过程中，一旦检测到某个方法上被修饰了该注解，就会去匹对父类中是否具有一个同样方法签名的函数，否则不能通过编译。\n2.3、注解解析方式 解析一个类或者方法的注解通常有两种形式，一种是编译期直接的扫描，一种是运行期反射。\n2.3.1、编译器的扫描 指的是编译器在对 java 代码编译字节码的过程中会检测到某个类或者方法被一些注解修饰，这时它就会对于这些注解进行某些处理。典型的就是注解 @Override，一旦编译器检测到某个方法被修饰了 @Override 注解，编译器就会检查当前方法的方法签名是否真正重写了父类的某个方法，也就是比较父类中是否具有一个同样的方法签名。\n这一种情况只适用于那些编译器已经熟知的注解类，比如 JDK 内置的几个注解，而你自定义的注解，编译器是不知道你这个注解的作用的，\n2.3.1、运行期反射 首先对虚拟机的几个注解相关的属性表进行介绍，先大体了解注解在字节码文件中是如何存储的。虚拟机规范定义了一系列和注解相关的属性表，也就是说，无论是字段、方法或是类本身，如果被注解修饰了，就可以被写进字节码文件。属性表有以下几种：\n RuntimeVisibleAnnotations：运行时可见的注解 RuntimeInVisibleAnnotations：运行时不可见的注解 RuntimeVisibleParameterAnnotations：运行时可见的方法参数注解 RuntimeInVisibleParameterAnnotations：运行时不可见的方法参数注解 AnnotationDefault：注解类元素的默认值  java.lang.reflect.AnnotatedElement 接口是所有程序元素（Class、Method和Constructor）的父接口，程序通过反射获取了某个类的 AnnotatedElemen t对象之后，利用 Java 的反射机获取程序代码中的注解，然后根据预先设定的处理规则解析处理相关注解以达到主机本身设定的功能目标。\n本质上来说，反射机制就是注解使用的核心，程序可以调用该对象的以下方法来访问 Annotation信息：\n getAnnotation：返回指定的注解 isAnnotationPresent：判定当前元素是否被指定注解修饰 getAnnotations：返回所有的注解 getDeclaredAnnotation：返回本元素的指定注解 getDeclaredAnnotations：返回本元素的所有注解，不包含父类继承而来的  3、源码解析 3.1、 …","date":1540450800,"description":"本文为《剖析 | SOFARPC 框架》第十一篇，作者敏古。","dir":"blog/sofa-rpc-annotation-support/","fuzzywordcount":4400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"e68884b2feaf90e26f191de0ef49e945","permalink":"/blog/sofa-rpc-annotation-support/","publishdate":"2018-10-25T15:00:00+08:00","readingtime":9,"relpermalink":"/blog/sofa-rpc-annotation-support/","summary":"SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文为《剖析 |","tags":["SOFARPC","剖析 | SOFARPC 框架","SOFALab"],"title":"【剖析 | SOFARPC 框架】系列之 SOFARPC 注解支持剖析","type":"blog","url":"/blog/sofa-rpc-annotation-support/","wordcount":4360},{"author":"敖小剑","categories":"SOFAMesh","content":"背景 在Istio和Envoy中，对通讯协议的支持，主要体现在HTTP/1.1和HTTP/2上，这两个是Istio/Envoy中的一等公民。而基于HTTP/1.1的REST和基于HTTP/2的gRPC，一个是目前社区最主流的通讯协议，一个是未来的主流，google的宠儿，CNCF御用的RPC方案，这两个组成了目前Istio和Envoy（乃至CNCF所有项目）的黄金组合。\n而我们SOFAMesh，在第一时间就遇到和Istio/Envoy不同的情况，我们需要支持REST和gRPC之外的众多协议：\n SOFARPC：这是蚂蚁金服大量使用的RPC协议(已开源) HSF RPC：这是阿里集团内部大量使用的RPC协议(未开源) Dubbo RPC: 这是社区广泛使用的RPC协议(已开源) 其他私有协议：在过去几个月间，我们收到需求，期望在SOFAMesh上运行其他TCP协议，部分是私有协议  为此，我们需要考虑在SOFAMesh和SOFAMosn中增加这些通讯协议的支持，尤其是要可以让我们的客户非常方便的扩展支持各种私有TCP协议：\n实现分析 我们来大体看一下，在SOFAMesh/Istio中要新增一个通讯协议需要有哪些工作：\n protocol decoder：负责解析协议，读取协议字段 protocol encoder：负责生成请求报文，注意通常会有改动，比如修改某些header 在pilot中需要为新协议生成 Virtual Host 等配置，有 inbound 和 outbound 两份，分别下发到Sidecar 在Sidecar中，根据下发的 Virtual Host 等配置，进行请求匹配，以决定请求该转发到何处   备注：实际下发的配置不止 Virtual Host 配置，为了简单起见，我们仅以 Virtual Host 为例做讲解。\n 其中，protocol encoder和protocol decoder是容易理解的，对于新的通讯协议肯定需要有协议编解码层面的工作必须要完成，这块有工作量是很自然的。\n我们来看看第三块的工作量是什么，inbound 和 outbound 的Virtual Host配置示例如下：\noutbound 配置中，注意 domains 字段是各种域名和ClusterIP，而 routes 中，match是通过prefix来匹配。我们结合HTTP/1.1，domains字段是用来和请求的Host header进行域名匹配的，比如 Host: istio-telemetry，这决定了哪些请求是要转发到 istio-telemetry 这个服务的。routes的match用来进行路由匹配的，通过HTTP请求的path进行匹配。\ninbound 配置类似，只是inbound更简单，domains匹配*就可以。\n从上面的例子中可以看到，Istio和Envoy的设计有非常浓重的HTTP协议的味道，各种语义都是和HTTP直接相关。而当我们进行TCP协议的转发时，就需要将请求的协议字段进行映射，映射到HTTP的相应语义。\n比如，最基本的Destination，原始语义是请求的目的地，在前面的文章中我们指出过这是请求转发最关键的字段。在HTTP协议中，通常是通过Host header和Path表示，对于REST而言还有重要的Method字段。\n下面的格式是其他各种协议对这个Destination原始语义的实际实现方式：\n   协议 实现     原始语义 请求的目的地(Destination)   HTTP/1.1 Host header，Method，Path   HTTP/2 Header帧中的伪header :authority，:path和:method   Bolt协议 header map中key为”service”的字段   HSF协议 协议头中的服务接口名和服务方法名   Dubbo协议 data字段（payload）中的path/method    这些通讯协议在下发规则和进行请求匹配时，就需要进行协调：\n 定义好 Virtual Host 配置中的 domains 字段和 route 中的 match 用到的字段在当前通讯协议中的实际语义 在 protocol encoder 中读取请求的协议字段，和上面的字段对应 然后进行请求路由规则匹配（参照HTTP/1.1中的domain和route match的匹配）  而这些都是需要以代码的方式进行实现，以满足新通讯协议的要求。正规的做法，是每次新增一个通讯协议就将上述的工作内容重复一遍。这会直接导致大量的高度类似的重复代码。\nx-protocol的实现 在上述需要在协议扩展时修改的四个内容中，有一块是特别的：生成 Virtual Host 配置的工作是在Pilot中实现的，而其他三个是在Sidecar （Envoy或MOSN）中。考虑到 protocol encoder 和 protocol decoder 的工作是必不可少的，必然会修改Sidecar来增加实现代码，因此简化开发的第一个想法就是：能不能做到不修改Pilot？\n基本思路就是固定好原始语义，避免每个通讯协议都映射一遍。从前面我们列出来的各个协议的映射情况看，对于RPC协议而言，一般目的地信息都是服务名(有些是接口名)+方法名居多，因此可以考虑直接将服务名和方法名固定下来：\n RPC协议在 Virtual Host 配置中就固定为服务名对应 domains 字段，方法名对应 route 中的 match 用到的字段，这样只要修改一次然后各个RPC协议公用此配置，以后就不用再重复修改Pilot。 protocol encoder 在解析通讯协议完成之后，就直接将协议中对应服务名和方法名的字段提取出来，后面的匹配处理过程就可以公用一套通用实现，这样路由匹配这块也可以不用在重复开发。  因此，在x-protocol中，如果需要引入一个新的通讯协议，需要的工作内容只有必不可少的protocol encoder 和 protocol decoder，和实现以下几个接口：\n总结 X-protocol 在支持新通讯协议上的做法并无新奇之处，只是由于需求特殊有众多通讯协议需要支持，在开发时发现大量重复工作，因此我们选择了一条可以让后面更舒服一点的道路。\n目前这个方案在SOFAMesh中采用，我们将进一步检验实际效果，也会和合作的小伙伴时验证，看他们在自行扩展新协议时是否足够理想。这个方案理论上应该可以同样适用于Istio、Envoy体系，随着社区对Istio的接受程度的提高，在Istio上支持各种TCP通讯协议的需求会越来越多，有理由相信Istio后续可能也会出现类似的方案。毕竟，每次都改一大堆类似的东西，不是一个好做法。\n系列文章  SOFAMesh中的多协议通用解决方案x-protocol介绍系列（1）——DNS通用寻址方案 SOFAMesh中的多协议通用解决方案x-protocol介绍系列（2）——快速解码转发  ","date":1539500400,"description":"在本系列文章中，我们将详解Service Mesh中的多协议解决方案x-protocol，本文介绍的是TCP协议扩展。","dir":"blog/sofa-mesh-x-protocol-tcp-protocol-extension/","fuzzywordcount":2500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"2c2876e9ae6a7a2b374b0d04cc42e6a4","permalink":"/blog/sofa-mesh-x-protocol-tcp-protocol-extension/","publishdate":"2018-10-14T15:00:00+08:00","readingtime":5,"relpermalink":"/blog/sofa-mesh-x-protocol-tcp-protocol-extension/","summary":"背景 在Istio和Envoy中，对通讯协议的支持，主要体现在HTTP/1.1和HTTP/2上，这两个是Istio/Envoy中的一等公民。而","tags":["SOFAMesh"],"title":"SOFAMesh中的多协议通用解决方案x-protocol介绍系列（3）——TCP协议扩展","type":"blog","url":"/blog/sofa-mesh-x-protocol-tcp-protocol-extension/","wordcount":2488},{"author":"敖小剑","categories":"SOFAMesh","content":"前言 在Istio和Envoy中，对通讯协议的支持，主要体现在HTTP/1.1和HTTP/2上，而我们SOFAMesh，则需要支持以下几个RPC协议：\n SOFARPC：这是蚂蚁金服大量使用的RPC协议（已开源） HSF RPC：这是阿里集团内部大量使用的RPC协议（未开源） Dubbo RPC: 这是社区广泛使用的RPC协议（已开源）  更适合的平衡点：性能和功能 对于服务间通讯解决方案，性能永远是一个值得关注的点。而SOFAMesh在项目启动时就明确要求在性能上要有更高的追求，为此，我们不得不在Istio标准实现之外寻求可以获取更高性能的方式，比如支持各种RPC协议。\n期间有两个发现：\n Istio在处理所有的请求转发如REST/gRPC时，会解码整个请求的header信息，拿到各种数据，提取为Attribute，然后以此为基础，提供各种丰富的功能，典型如Content Based Routing。 而在测试中，我们发现：解码请求协议的header部分，对CPU消耗较大，直接影响性能。  因此，我们有了一个很简单的想法：是不是可以在转发时，不开启部分功能，以此换取转发过程中的更少更快的解码消耗？毕竟，不是每个服务都需要用到Content Based Routing这样的高级特性，大部分服务只使用 Version Based Routing，尤其是使用RPC通讯协议的服务，没有HTTP那么表现力丰富的header，对Content Based Routing的需求要低很多。\n此外，对于部分对性能有极高追求的服务，不开启高级特性而换取更高的性能，也是一种满足性能要求的折中方案。考虑到系统中总存在个别服务对性能非常敏感，我们觉得Service Mesh提供一种性能可以接近直连的方案会是一个有益的补充。为了满足这些特例而不至于因此整体否决Service Mesh方案，我们需要在Service Mesh的大框架下提供一个折中方案。\n请求转发 在我们进一步深入前，我们先来探讨一下实现请求转发的技术细节。\n有一个关键问题：当Envoy/SOFA MOSN这样的代理程序，接收到来自客户端的TCP请求时，需要获得哪些信息，才可以正确的转发请求到上游的服务器端？\n最关键的信息：destination 首先，毫无疑问的，必须拿到destination/目的地，也就是客户端请求必须通过某种方式明确的告之代理该请求的destination，这样代理程序才能根据这个destionation去找到正确的目标服务器，然后才有后续的连接目标服务器和转发请求等操作。\nDestination信息的表述形式可能有：\n1. IP地址\n可能是服务器端实例实际工作的IP地址和端口，也可能是某种转发机制，如Nginx/HAProxy等反向代理的地址或者Kubernetes中的ClusterIP。\n举例：“192.168.1.1:8080”是实际IP地址和端口，“10.2.0.100:80”是ngxin反向代理地址，“172.168.1.105:80”是Kubernetes的ClusterIP。\n2. 目标服务的标识符\n可用于名字查找，如服务名，可能带有各种前缀后缀。然后通过名字查找/服务发现等方式，得到地址列表（通常是IP地址+端口形式）。\n举例：“userservice”是标准服务名， “com.alipay/userservice”是加了域名前缀的服务名， “service.default.svc.cluster.local”是k8s下完整的全限定名。\nDestination信息在请求报文中的携带方式有：\n1. 通过通讯协议传递\n这是最常见的形式，标准做法是通过header头，典型如HTTP/1.1下一般使用 host header，举例如“Host: userservice”。HTTP/2下，类似的使用“:authority” header。\n对于非HTTP协议，通常也会有类似的设计，通过协议中某些字段来承载目标地址信息，只是不同协议中这个字段的名字各有不同。如SOFARPC，HSF等。\n有些通讯协议，可能会将这个信息存放在payload中，比如后面我们会介绍到的dubbo协议，导致需要反序列化payload之后才能拿到这个重要信息。\n2. 通过TCP协议传递\n这是一种非常特殊的方式，通过在TCP option传递，上一节中我们介绍Istio DNS寻址时已经详细介绍过了。\nTCP拆包 如何从请求的通讯协议中获取destination？这涉及到具体通讯协议的解码，其中第一个要解决的问题就是如何在连续的TCP报文中将每个请求内容拆分开，这里就涉及到经典的TCP沾包、拆包问题。\n转发请求时，由于涉及到负载均衡，我们需要将请求发送给多个服务器端实例。因此，有一个非常明确的要求：就是必须以单个请求为单位进行转发。即单个请求必须完整的转发给某台服务器端实例，负载均衡需要以请求为单位，不能将一个请求的多个报文包分别转发到不同的服务器端实例。所以，拆包是请求转发的必备基础。\n由于篇幅和主题限制，我们不在这里展开TCP沾包、拆包的原理。后面针对每个具体的通讯协议进行分析时再具体看各个协议的解决方案。\n多路复用的关键参数：RequestId RequestId用来关联request和对应的response，请求报文中携带一个唯一的id值，应答报文中原值返回，以便在处理response时可以找到对应的request。当然在不同协议中，这个参数的名字可能不同（如streamid等）。\n严格说，RequestId对于请求转发是可选的，也有很多通讯协议不提供支持，比如经典的HTTP1.1就没有支持。但是如果有这个参数，则可以实现多路复用，从而可以大幅度提高TCP连接的使用效率，避免出现大量连接。稍微新一点的通讯协议，基本都会原生支持这个特性，比如SOFARPC、Dubbo、HSF，还有HTTP/2就直接內建了多路复用的支持。\nHTTP/1.1不支持多路复用（http1.1有提过支持幂等方法的pipeline机制但是未能普及），用的是经典的ping-pong模式：在请求发送之后，必须独占当前连接，等待服务器端给出这个请求的应答，然后才能释放连接。因此HTTP/1.1下，并发多个请求就必须采用多连接，为了提升性能通常会使用长连接+连接池的设计。而如果有了requestid和多路复用的支持，客户端和Mesh之间理论上就可以只用一条连接（实践中可能会选择建立多条）来支持并发请求：\n而Mesh与服务器（也可能是对端的Mesh）之间，也同样可以受益于多路复用技术，来自不同客户端而去往同一个目的地的请求可以混杂在同一条连接上发送。通过RequestId的关联，Mesh可以正确将reponse发送到请求来自的客户端。\n由于篇幅和主题限制，我们不在这里展开多路复用的原理。后面针对每个具体的通讯协议进行分析时再具体看各个协议的支持情况。\n请求转发参数总结 上面的分析中，我们可以总结到，对于Sidecar，要正确转发请求：\n 必须获取到destination信息，得到转发的目的地，才能进行服务发现类的寻址 必须要能够正确的拆包，然后以请求为单位进行转发， …","date":1539154800,"description":"在本系列文章中，我们将详解Service Mesh中的多协议解决方案x-protocol，本文介绍的是快速解码转发方案。","dir":"blog/sofa-mesh-x-protocol-rapid-decode-forward/","fuzzywordcount":6900,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"37ad5c3f997c173a4ceb60cc9dfd0532","permalink":"/blog/sofa-mesh-x-protocol-rapid-decode-forward/","publishdate":"2018-10-10T15:00:00+08:00","readingtime":14,"relpermalink":"/blog/sofa-mesh-x-protocol-rapid-decode-forward/","summary":"前言 在Istio和Envoy中，对通讯协议的支持，主要体现在HTTP/1.1和HTTP/2上，而我们SOFAMesh，则需要支持以下几个RP","tags":["SOFAMesh"],"title":"SOFAMesh中的多协议通用解决方案x-protocol介绍系列（2）——快速解码转发","type":"blog","url":"/blog/sofa-mesh-x-protocol-rapid-decode-forward/","wordcount":6856},{"author":"米麒麟","categories":"SOFARPC","content":" SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文为《剖析 | SOFARPC 框架》第九篇，作者米麒麟，目前就职于陆金所。 《剖析 | SOFARPC 框架》系列由 SOFA 团队和源码爱好者们出品， 项目代号：SOFA:RPCLab/，官方目录目前已经全部认领完毕，文末提供了已完成的文章目录。\n 前言 众所周知，在微服务架构下面，当应用需要进行新功能升级发布，或者异常关闭重启的时候，我们会对应用的进程进行关闭，而在关闭之前，我们希望做一些诸如关闭数据库连接，等待处理任务完成等操作，这个就涉及到我们本文中的优雅关闭功能。假如应用没有支持优雅停机，则会带来譬如数据丢失，交易中断、文件损坏以及服务未下线等情况。\n微服务的优雅停机需要遵循\u0026amp;quot;注销发布服务 → 通知注销服务 → 更新服务清单 → 开启请求屏蔽 → 调用销毁业务服务 → 检查所有请求是否完成 → 超时强制停机\u0026amp;quot;应用服务停机流程。\nSOFARPC 提供服务端/客户端优雅关闭功能特性，用来解决 kill PID，应用意外自动退出譬如 System.exit() 退出 JVM，使用脚本或命令方式停止应用等使用场景，避免服务版本迭代上线人工干预的工作量，提高微服务架构的服务高可靠性。\n本文将从进程的优雅关闭，SOFARPC 应用服务优雅关闭流程，Netty 的优雅停机等方面出发详细剖析 。\n进程优雅关闭 Kill 结束进程 在 Linux上，kill 命令发送指定的信号到相应进程，不指定信号则默认发送 SIGTERM(15) 终止指定进程。如果无法终止，可以发送 SIGKILL(9) 来强制结束进程。kill 命令信号共有64个信号值，其中常用的是：\n2(SIGINT：中断，Ctrl+C)。\n15(SIGTERM：终止，默认值)。\n9(SIGKILL：强制终止)。\n这里我们重点说一下15和9的情况。\nkill PID/kill -15 PID 命令系统发送 SIGTERM 进程信号给响应的应用程序，当应用程序接收到 SIGTERM 信号，可以进行释放相应资源后再停止，此时程序可能仍然继续运行。\n而kill -9 PID 命令没有给进程遗留善后处理的条件。应用程序将会被直接终止。\n对微服务应用而言其效果等同于突然断电，强行终止可能会导致如下几方面问题：\n  缓存数据尚未持久化到磁盘，导致数据丢失；\n  文件写操作正在进行未更新完成，突然退出进程导致文件损坏；\n  线程消息队列尚有接收到的请求消息，未能及时处理，导致请求消息丢失；\n  数据库事务提交，服务端提供给客户端请求响应，消息尚在通信线程发送队列，进程强制退出导致客户端无法接收到响应，此时发起超时重试带来重复更新。\n  所以支持优雅关闭的前提是关闭的时候，不能被直接 通过发送信号为9的 Kill 来强制结束。当然，其实我们也可以对外统一暴露应用程序管理的 API 来进行控制。本文暂时不做讨论。\nJava 优雅关闭 当应用程序收到信号为15的关闭命令时，可以进行相应的响应，Java 程序的优雅停机通常通过注册 JDK 的 ShutdownHook 来实现，当应用系统接收到退出指令，首先 JVM 标记系统当前处于退出状态，不再接收新的消息，然后逐步处理推积的消息，接着调用资源回收接口进行资源销毁，例如内存清理、对象销毁等，最后各线程退出业务逻辑执行。\n优雅停机需要超时控制机制，即到达超时时间仍然尚未完成退出前资源回收等操作，则通过停机脚本调用kill-9 PID命令强制退出进程。\n其中 JVM 优雅关闭的流程主要的阶段如下图所示：\n如图所示，Java进程优雅退出流程包括如下五个步骤：\n  应用进程启动，初始化 Signal 实例；\n  根据操作系统类型，获取指定进程信号；\n  实现 SignalHandler 接口，实例化并注册到 Signal，当 Java 进程接收到譬如 kill -12 或者 Ctrl+C 命令信号回调其 handle() 方法；\n  SignalHandler 的 handle 回调接口初始化 ShutdownHook 线程，并将其注册到 Runtime 的 ShutdownHook。\n  Java 进程接收到终止进程信号，调用 Runtime 的exit() 方法退出 JVM 虚拟机，自动检测用户是否注册ShutdownHook 任务，如果有则触发 ShutdownHook 线程执行自定义资源释放等操作。\n  SOFARPC 优雅关闭 在进程可以进行优雅关闭后，SOFARPC 如何实现优雅关闭呢？首先 SOFARPC 对于所有可以被优雅关闭的资源设计com.alipay.sofa.rpc.base.Destroyable接口，通过向 JVM 的 ShutdownHook 注册来对这些可被销毁的资源进行优雅关闭，支持销毁前和销毁后操作。\n这里包括两部分：\n  作为服务端注册 JDK 的 ShutdownHook 执行取消服务注册、关闭服务端口等动作实现；\n  作为客户端通过实现 DestroyHook 接口逐步处理正在调用的请求关闭服务调用。\n  总体设计 运行时上下文注册 JDK 的 ShutdownHook 执行销毁 SOFARPC 运行相关环境实现类似发布平台/用户执行kill PID 优雅停机。运行时上下文 RpcRuntimeContext 静态初始化块注册 ShutdownHook 函数：\nstatic { ... // 增加jvm关闭事件  if (RpcConfigs.getOrDefaultValue(RpcOptions.JVM_SHUTDOWN_HOOK, true)) { Runtime.getRuntime().addShutdownHook(new Thread(new Runnable() { @Override public void run() { if (LOGGER.isWarnEnabled()) { LOGGER.warn(\u0026amp;#34;SOFA RPC Framework catch JVM shutdown event, Run shutdown hook now.\u0026amp;#34;); } destroy(false); } }, \u0026amp;#34;SOFA-RPC-ShutdownHook\u0026amp;#34;)); } } 注册本身很简单，重要的是 destroy 方法实际上做的事情非常多。按照先后顺序，大致包含如下几个部分。\nRpcRuntimeContext 销毁服务优雅关闭完整流程：\n  设置 RPC 框架运行状态修改为正在关闭，表示当前线程不再处理 RPC 服务请求；\n  遍历运行时上下文关闭资源的销毁钩子，进行注册销毁器清理资源前期准备工作；\n  获取发布的服务配置反注册服务提供者，向指定注册中心批量执行取消服务注册；\n  检查当前服务端连接和队列任务，先把队列任务处理完毕，再缓慢关闭启动端口；\n  关闭发布的服务，到注册中心取消服务发布，取消将处理器注册到服务 …","date":1539154800,"description":"本文为《剖析 | SOFARPC 框架》第九篇，作者米麒麟，目前就职于陆金所。","dir":"blog/sofa-rpc-graceful-exit/","fuzzywordcount":4000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"6a1f6847a5ecf97e90a3a06c36f39246","permalink":"/blog/sofa-rpc-graceful-exit/","publishdate":"2018-10-10T15:00:00+08:00","readingtime":8,"relpermalink":"/blog/sofa-rpc-graceful-exit/","summary":"SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文为《剖析 |","tags":["SOFARPC","剖析 | SOFARPC 框架","SOFALab"],"title":"【剖析 | SOFARPC 框架】之 SOFARPC 优雅关闭剖析","type":"blog","url":"/blog/sofa-rpc-graceful-exit/","wordcount":3970},{"author":"明不二","categories":"SOFARPC","content":" SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文为《剖析 | SOFARPC 框架》第十篇，作者明不二，就职于华为。 《剖析 | SOFARPC 框架》系列由 SOFA 团队和源码爱好者们出品， 项目代号：SOFA:RPCLab/，官方目录目前已经全部认领完毕。\n 前言 RPC 框架需要创造一种调用远程服务如同调用本地般的体验，因此在实现一个基于 RPC 框架的微服务架构的系统时，服务消费者（客户端）往往只需要知道服务端提供了哪些接口和方法，并不需要知道服务具体由哪些 IP 在提供。RPC 框架本身的服务发现和路由寻址功能解决了如何知道目标地址的问题，该过程对于 RPC 客户端调用方来说应该是完全透明的。\n在这个过程中，RPC 框架需要接入注册中心来完成服务发现和路由寻址的功能。同时，在应用大规模请求时，微服务系统还需要对请求服务集群化，同时通过负载均衡来达到降低访问压力的效果。\n本文我们会先介绍一下注册中心，然后介绍一下 SOFRPC 中的几种路由，最后会介绍一下负载均衡的几种比较。\n注册中心支持 首先我们简要介绍一下注册中心的原理。\n服务端推送地址给注册中心，注册中心将地址进行合并后，推送给客户端。\n其中，注册中心的场景依赖于各类注册中心的实现。在这里，SOFARPC 提供了注册中心的抽象类 Registry，该抽象类提供了注册中心的配置、启动、注册、反注册、订阅等方法。客户端在接入过程中，可以通过配置来激活 Zookeeper、Consul、local 等注册中心注册进启动类中，当请求到来时，可以通过注册中心进行相应的路由。\n注册中心的抽象类如下：\n在这个接口的基础上，目前内置实现了几种注册中心，包括即将合并的。\nLocal注册中心(Local) Local 注册中心是 SOFARPC 自己实现的一个本地注册中心，该注册中心的实现主要由类 LocalRegistry提供，可以调用其 register(ProviderConfig config) 方法实现服务的注册，主要是文件的读写。\n实现原理很简单，通过在本地注册文件来保存服务的发布和订阅信息。\nZookeeper注册中心(Zookeeper) Zookeeper 接入 SOFARPC 的实现类为 ZookeeperRegistry。目前是 SOFARPC 中默认的注册中心实现。也是大多数情况下，可以方便使用的。\nZookeeper 是一个分布式协调服务，用于维护配置信息、命名、提供分布式同步功能以及提供组服务等。Zookeeper 提供了服务注册与发现的解决方案，提供了简单的 API，可以让集成者简洁调用。\n当要发布一个 SOFARPC 服务时，首先需要在 zookeeper 中注册服务提供者的相关信息，包括：该服务接口隶属于哪个系统、服务的 IP 以及端口号、服务的请求 URL 和服务的权重等等。zookeeper 在这个过程中，注意负责对 SOFARPC 中的服务信息进行中心存储，同时负责把服务注册信息的更新及时通知到服务消费者。\n作为服务调用者，SOFARPC 调用端在调用时，若走的路由链路中有注册中心，则会从注册中心中获取到服务注册的相关信息，然后在调用时会根据负载均衡策略来发送请求。\nConsul注册中心(Consul) Consul 注册中心与 SOFARPC 之间的对接主要依赖于 ConsulRegistry类。\n该注册中心在功能表现上与 zookeeper 看起来一致。对比起 Zookeeper 来，Consul 支持多数据中心，同时支持 http 和 dns 等接口，有着多语言的能力。\n其他注册中心 目前已经在开发中的有 Nacos，SOFAMesh 等。也可以根据自己的场景，进行方便的扩展。\n路由设计 路由原理和设计 在阅读本部分之前，请大家注意：路由是为了选中一组地址。\nSOFARPC 通过对各类注册中心的支持，实现了服务发现、路由寻址的功能。访问客户端时，请求的路由可以由以下一些实现类实现：DirectUrlRouter、RegistryRouter、CustomRouter，上述三个路由实现类分别对应了直接地址路由（不需要经过注册中心直接路由直连到某个地址）、注册中心路由、以及客户自定义路由等。路由从 AddressHolder 获取到地址，同时通过各种负载均衡算法进行负载均衡，请求到相应的系统接口。\n首先我们看一下整个路由寻址过程的阶段。\n这 SOFARPC 中，路由可以分为地址直连路由、注册中心路由以及客户定制化路由。这以上三个路由均扩展了 Router 抽象类。服务路由的抽象类代码如下：\n这里的核心代码是 route 这个方法，将本次请求的信息，和服务列表进行计算。当客户端请求到达 Router 时，会根据请求的参数信息从 Router 和连接管理器中获取请求地址，通过调用 route(SofaRequest request, List\u0026amp;lt;ProviderInfo\u0026amp;gt; providerInfos) 方法达到路由寻址的目的。\n其中，路由并不是一个非此即彼的过程，这些可选的路由是由用户和系统的配置，被构造成一个路由链来执行的。这样。就可以有一些兜底的逻辑，如指定了 IP 地址，那我们就直接路由到这个地址，如果没有，就进行注册中心的路由等等。\n直连(DirectUrlRouter) 直接路由是比较简单的，因为有专门的配置，所以地址列表这些都是可以很方便地进行识别，在客户端配置时，可通过如下方式配置：\nConsumerConfig\u0026amp;lt;HelloService\u0026amp;gt; consumer = new ConsumerConfig\u0026amp;lt;HelloService\u0026amp;gt;() .setInterfaceId(HelloService.class.getName()) .setRegistry(registryConfig) .setDirectUrl(\u0026amp;#34;bolt://127.0.0.1:12201\u0026amp;#34;); 直接地址路由扩展了 Router 抽象类的实现，在重写的 route 方法中，直接获取配置好的直接路由地址。当请求到来时，直接从地址管理列表中，拿到对应的地址，就实现了直接地址路由的功能。\n注册中心(RegistryRouter) 注册中心路由同样扩展了 Router 抽象方法，这个 Router是大多数情况下使用最多的路由，主要是从本应用使用的注册中心中获取对应的地址，并进行路由寻址等。后面我们会介绍目前注册中心的几个内置实现。\n自定义(CustomRouter) 客户定制化路由可以配置客户自己所定制的路由实现，可以参考直接地址路由或者注册中心路由的实现，扩展 Router 类即可。\n这里的使用场景：\n一种是对于某些用户来说，在注册中心的场景下，用户认为所有的地址并不是等价的。会对地址进行人为拆分，使用方保存了自己的的所有服务提供方地址（或者是通过某种方法查询），然后重写路由定制逻辑，通过方法级别进行地址的选择。\n另一种是，用 …","date":1539154800,"description":"本文为《剖析 | SOFARPC 框架》第十篇，作者明不二，就职于华为。","dir":"blog/sofa-rpc-routing-implementation/","fuzzywordcount":3800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"dc2f04fd097731619e17f7da6a24ae6a","permalink":"/blog/sofa-rpc-routing-implementation/","publishdate":"2018-10-10T15:00:00+08:00","readingtime":8,"relpermalink":"/blog/sofa-rpc-routing-implementation/","summary":"SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文为《剖析 |","tags":["SOFARPC","剖析 | SOFARPC 框架","SOFALab"],"title":"【剖析 | SOFARPC 框架】之 SOFARPC 路由实现剖析","type":"blog","url":"/blog/sofa-rpc-routing-implementation/","wordcount":3769},{"author":"敖小剑","categories":"SOFAMesh","content":" 本文是SOFAMesh中的多协议通用解决方案x-protocol介绍系列文章之一。\n 前言 在2018年上半年，蚂蚁金服决定基于 Istio 订制自己的 ServiceMesh 解决方案，在6月底对外公布了 SOFAMesh，详情请见之前的文章: 大规模微服务架构下的Service Mesh探索之路 。\n在 SOFAMesh 的开发过程中，针对遇到的实际问题，我们给出了一套名为 x-protocol 的解决方案，定位是云原生、高性能、低侵入性的通用 Service Mesh 落地方案，依托 Kubernetes 基座，利用其原生的服务注册和服务发现机制，支持各种私有 RPC 协议低成本、易扩展的接入，快速享受 Service Mesh 所带来的红利。\n具体解决的问题包括：\n 多通讯协议支持问题，减少开发工作量，简单快捷的接入新协议 尽量提升性能，提供更灵活的性能与功能的平衡点选择，满足特定高性能场景 兼容现有SOA体系，提供通过接口进行访问的方式，实现不修改业务代码也能顺利接入 Service Mesh 支持单进程多服务的传统SOA程序，可以在微服务改造之前，先受益于 Service Mesh 带来的强大功能  在本系列文章中，我们将对此进行详细的讲解，首先是“DNS通用寻址方案”。\n背景和需求 SOA的服务模型 在SOFAMesh计划支持的RPC框架中，SOFARPC、HSF、Dubbo都是一脉相承的SOA体系，也都支持经典的SOA服务模型，通常称为”单进程多服务”，或者叫做”单进程多接口”。（备注：由于服务一词使用过于频繁，下文都统一称为接口以便区分）\nSOA标准的服务注册，服务发现和调用流程如下：\n 在单个SOA应用进程内，存在多个接口 服务注册时，以接口为单位进行多次独立的服务注册 当客户端进行调用时，按照接口进行服务发现，然后发起调用  当我们试图将这些SOA架构的应用搬迁到ServiceMesh时，就会遇到服务模型的问题：微服务是单服务模型，也就是一个进程里面只承载一个服务。以Kubernetes的服务注册为例，在单进程单服务的模型下，服务名和应用名可以视为一体，Kubernetes的自动服务注册会将应用名作为服务注册的标示。\n这就直接导致了SOA模型和微服务模型的不匹配问题：\n SOA以接口为单位做服务注册和服务发现，而微服务下是服务名 SOA是”单进程多接口”，而微服务是”单进程单服务”  一步接一步的需求   先上车后补票\n最理想的做法当然是先进行微服务改造，实现微服务拆分。但是考虑到现有应用数量众多，我们可能更愿意在大规模微服务改造之前，先想办法让这些应用可以运行在ServiceMesh下，提前受益于Service Mesh带来的强大功能。因此，我们需要找到一个合适的方案，让ServiceMesh支持没有做微服务改造依然是”单进程多接口”形式的传统SOA应用，所谓”先上车后补票”。\n  不修改代码\n考虑到原有的SOA应用，相互之间错综复杂的调用关系，最好不要修改代码，即保持客户端依然通过接口名来访问的方式。当然，SOA架构的客户端SDK可能要进行改动，将原有的通过接口名进行服务发现再自行负载均衡进行远程调用的方式，精简为标准的Servicemesh调用（即走Sidecar），因此修改SDK依赖包和重新打包应用是不可避免。\n  支持带特殊字符的接口名\nKubernetes的服务注册，Service名是不能携带”.“号的。而SOA架构下，接口名有时出于管理方便，有可能是加了域名前缀，如”com.alipay.demo.interface-2”。为了实现不修改原有代码，就只能想办法支持这种带特殊字符的接口名。\n  参考Kubernetes和Istio 在进一步讨论解决方案之前，我们先来看一下kubernetes和Istio中的标准请求寻址方式。\n 备注：过程稍显复杂，涉及到Kubernetes/Istio的一些底层细节。但是了解这个过程对后续的理解非常重要，也可以帮助大家了解Kubernetes和Kubernetes的工作原理，强烈推荐阅读。\n Kubernetes下的DNS寻址方式 在Kubernetes下，如图所示，假定我们部署了一个名为userservice的应用，有三个实例，分别在三个pod中。则应用部署之后，Kubernetes会为这个应用分配ClusterIP和域名，并在DNS中生成一条DNS记录，将域名映射到ClusterIP：\n当部署在Kubernetes下的某个充当客户端的应用发起请求时，如图中的HTTP GET请求，目标URL地址为 http://userservice/id/1000221。请求的寻址方式和过程如下：\n 首先进行域名解析，分别尝试解析”userservice”/“userservie.default.svc.cluster.local”等域名，得到ClusterIP 然后客户端发出请求的报文，目标地址为ClusterIP，源地址为当前客户端所在的pod IP（简单起见，端口先忽略） 请求报文随即被kube-proxy拦截，kube-proxy根据ClusterIP，拿到ClusterIP对应的多个实际服务实例所在的pod ip，取其中一个，修改目标地址为这个pod IP 请求报文最终就被发送到服务实例所在的pod IP  应答回来的方式类似，userservice发出的应答报文会被kube-proxy拦截并修改为发送到客户端所在的pod IP。\n我们详细看一下请求和应答全称的四个请求包的具体内容（简单起见继续忽略端口）：\n重点关注请求和应答报文的源地址和目标地址：\n 客户端发出的请求，为”客户端到ClusterIP” kube-proxy拦截到请求后，将请求修改为”客户端到服务器端” 服务器端收到请求时，表现为”客户端到服务器端”，ClusterIP被kube-proxy屏蔽 服务器端发送应答，因为收到的请求看似来自客户端，因此应答报文为”服务器端到客户端” 应答报文被kube-proxy拦截，将应答修改为”ClusterIP到服务器端” 客户端收到应答，表现为”ClusterIP到服务器端”，服务器端IP被kube-proxy屏蔽  kube-proxy在客户端和服务器端之间拦截并修改请求和应答的报文，联通两者，但各自屏蔽了一些信息：\n 在客户端看来它是在和ClusterIP交互，userservice的具体服务器端实例对客户端是无感知的 在服务器端看来，客户端是直接在和它交互，ClusterIP的存在对服务器端是无感知的  更深入一步，看kube-proxy在两个拦截和修改报文中的逻辑处理关系，即kube-proxy是如何在收到应答时正确的找回原有的ClusterIP：\n 在拦截并修改请求报文之后，kube-proxy会保存报文修改的5元组对应关系（5元组指源IP地址，源端口，协议，目的地IP地址，目的地端口） 在收到应答报文后，根据应答报文中的5元组，在保存的5元组对应关系中，找到对应信息，得到原有的ClusterIP和端口，然后修改应答报文  总结，通过上述Kubernetes下的寻址方式，客户端只需发送带简单寻址信息的请求（ …","date":1538982000,"description":"在本系列文章中，我们将详解Service Mesh中的多协议解决方案x-protocol，首先介绍的是DNS通用寻址方案。","dir":"blog/sofa-mesh-x-protocol-common-address-solution/","fuzzywordcount":5900,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"6429061afc56c5832c17b541943498e6","permalink":"/blog/sofa-mesh-x-protocol-common-address-solution/","publishdate":"2018-10-08T15:00:00+08:00","readingtime":12,"relpermalink":"/blog/sofa-mesh-x-protocol-common-address-solution/","summary":"本文是SOFAMesh中的多协议通用解决方案x-protocol介绍系列文章之一。 前言 在2018年上半年，蚂蚁金服决定基于 Istio 订制自己的 ServiceMesh 解决","tags":["SOFAMesh"],"title":"SOFAMesh中的多协议通用解决方案x-protocol介绍系列（1）——DNS通用寻址方案","type":"blog","url":"/blog/sofa-mesh-x-protocol-common-address-solution/","wordcount":5813},{"author":"水寒","categories":"SOFARPC","content":" SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文为《剖析 | SOFARPC 框架》第八篇，作者水寒，目前就职于网易。 《剖析 | SOFARPC 框架》系列由 SOFA 团队和源码爱好者们出品， 项目代号：SOFA:RPCLab/，官方目录目前已经全部认领完毕，文末提供了已完成的文章目录。\n 前言 在本系列之前的文章中，我们已经介绍了同步，异步，泛化调用等，也介绍了链路追踪的能力，本篇，我们将介绍一下 SOFARPC 中另一种内置的数据透传的能力。会依次介绍，数据透传的概念， SOFARPC 的设计原理，以及各种不同调用方式下的透传使用和详细说明，最后， 还会比较一下和 SOFATracer 的区别。欢迎大家与我们讨论交流。\n数据透传介绍 首先，我们介绍一下数据透传的概念，我们知道，在 RPC调用中，数据的传递，是通过接口方法参数来传递的，需要接口方定义好一些参数允许传递才可以，在一些场景下，我们希望，能够更通用的传递一些参数，比如一些标识性的信息。业务方可能希望，在每一次调用请求中都能够传递一些自定义的信息到下游。甚至也希望下游能够将一些数据传递回来。\n而数据透传功能，就是指数据不需要以作为方法参数的形式在调用链路中进行传递，而是直接存储到调用上下文中，之后通过 RPC 的内置对象，进行传递，调用双端可从上下文中获取数据而不需要去关注数据的传输过程。\nSOFARPC 提供的数据透传支持请求数据透传（客户端向服务端）和响应数据透传（服务端向客户端）。\nSOFARPC 设计原理 这里主要是介绍一下，实现的核心原理，更加具体的每种调用方式的透传，在后文中都会详细介绍。\n  用户通过 SOFARPC 提供的 API 进行数据传递设置\n  SOFARPC 在调用传输前，将透传的数据进行打包获取\n  进行正常的序列化和反序列化\n  SOFARPC 在反序列化时将用户设置的透传数据写回 Context\n  服务端用户即可进行获取使用\n  不同调用方式的透传 我们知道，SOFARPC 目前支持四种调用模式，如果没有阅读过之前文章的同学，可以阅读一下 SOFARPC 同步异步实现剖析，请求透传数据的原理都是一样的，服务端设置响应透传数据的原理也是一样的，只是客户端获取响应透传数据的方式有所不同（后三种模式只介绍客户端获取响应透传数据的原理）。因此我们会介绍下不同调用方式的透传细节，并介绍其使用方式，方便大家理解。以下为了方便说明，我们会使用如下的接口示例：\n接口服务 public interface HelloService { String sayHello(String string); } 服务实现 public class HelloServiceImpl implements HelloService { @Override public String sayHello(String string) { // 获取请求透传数据并打印 System.out.println(\u0026amp;quot;service receive reqBag -\u0026amp;gt; \u0026amp;quot; + RpcInvokeContext.getContext().getRequestBaggage(\u0026amp;quot;req_bag\u0026amp;quot;)); // 设置响应透传数据到当前线程的上下文中 RpcInvokeContext.getContext().putResponseBaggage(\u0026amp;quot;resp_bag\u0026amp;quot;, \u0026amp;quot;s2c\u0026amp;quot;); return \u0026amp;quot;hello \u0026amp;quot; + string + \u0026amp;quot; ！\u0026amp;quot;; } } 后续的所有调用模式都使用HelloServiceImpl这个服务实现。(示例代码在 SOFARPC 的 测试 case 中都要对应的示例，大家可以对应阅读。)\n对用户可见的操作 API 只有一个就是 RpcInvokeContext，在 SOFABoot 和 SOFARPC 下都适用，当然如果你了解 SOFARPC 的 Filter 机制，也可以通过扩展这个来实现。\nsync 调用下的透传 使用示例 原理剖析 请求透传数据  客户端首先在 main 线程（图中的user thread）中设置请求透传数据到其调用上下文RpcInvokeContext.requestBaggage属性中，之后在调用过程中从requestBaggage中取出请求透传数据并设置到SofaRequest.requestProps属性中； 服务端接收到请求SofaRequest对象后，在其调用链中的 ProviderBaggageFilter#invoke 方法中会先从SofaRequest.requestProps中取出请求透传数据并设置到当前服务端线程的调用上下文RpcInvokeContext.requestBaggage属性中，最后业务代码就可以从调用上下文中获取请求透传数据了。  响应透传数据  服务端设置响应透传数据到其调用上下文RpcInvokeContext.responseBaggage属性中，之后在ProviderBaggageFilter#invoke 方法中先从responseBaggage中取出响应透传数据并设置到SofaResponse.responseProps属性中； 客户端main线程被唤醒后，先从SofaResponse.responseProps中获取响应透传数据，之后将响应透传数据设置到其调用上下文RpcInvokeContext.responseBaggage中，最后业务代码就可以从调用上下文中获取响应透传数据了。  oneway 调用下的透传 使用示例 原理剖析 在 oneway 模式下，客户端不接受服务端响应，也不会获取响应透传数据。\nfuture 调用下的透传 使用示例 原理剖析 客户端获取响应透传数据 future 模式在 SOFARPC 内部会被转化为 callback 的方式进行调用，在 callback 对象中会存储main线程的调用上下文；当客户端接收到响应时，会执行该 callback 对象的回调函数，在其回调函数中，对于响应透传数据，会做如下操作：\n  从SofaResponse.responseProps中获取响应透传数据\n  从 callback 对象中获取 main 线程的调用上下文\n  设置响应透传数据到 main 线程的调用上下文\n  将 main 线程上下文拷贝到当前的回调线程中\n  实际上，第三步与第四步在 SOFARPC 源码中顺序相反，本文这样解读是为了更容易理解。这样无论是 future 模式（从 main 线程的调用上下文获取响应透传数据）还是 callback 模式（从回调线程的调用上下文获取响应透传数据），都可以顺利的获取到响应透传数据。\ncallback 调用下的透传 使用示例 原理剖析 与 future 模式原理一样，只是最终业务代码中是从回调线程而 …","date":1538550000,"description":"本文为《剖析 | SOFARPC 框架》第八篇，作者水寒，目前就职于网易。","dir":"blog/sofa-rpc-data-transmission/","fuzzywordcount":2600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"a26f5f1db99edadf48c406492ccdcaf8","permalink":"/blog/sofa-rpc-data-transmission/","publishdate":"2018-10-03T15:00:00+08:00","readingtime":6,"relpermalink":"/blog/sofa-rpc-data-transmission/","summary":"SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文为《剖析 |","tags":["SOFARPC","剖析 | SOFARPC 框架","SOFALab"],"title":"【剖析 | SOFARPC 框架】之 SOFARPC 数据透传剖析","type":"blog","url":"/blog/sofa-rpc-data-transmission/","wordcount":2528},{"author":"莫那·鲁道","categories":"SOFARPC","content":" SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文为《剖析 | SOFARPC 框架》第七篇，作者莫那·鲁道 ，来自 E签宝。 《剖析 | SOFARPC 框架》系列由 SOFA 团队和源码爱好者们出品， 项目代号：SOFA:RPCLab/，官方目录目前已经全部认领完毕。\n 前言 我们知道，在 RPC 调用中，客户端需要加载服务端提供的接口定义类，但是，很多情况下，这个并不总是可行的，于是，衍生了泛化调用的需求，一个成熟的，功能完善的 RPC 框架一般都会支持泛化调用，那么什么是泛化调用呢？SOFA RPC 又是如何支持泛化调用的？同时又是如何实现的？ 和其他的 RPC 泛化调用又有何不同？有何优势？我们将在本文一一解答这些问题。\n泛化调用介绍 当客户端因为某种原因无法得到服务提供方的接口 jar 包时，或者是客户端是一个比较通用的系统，并不想依赖每个服务提供方提供的 facade接口，但是又需要进行调用，那么此时就需要进行泛化调用。\n例如：\n 当分布式系统由多个语言开发，假设是 Node Js ，同时 Node Js 需要调用 Java 语言的 RPC 服务，那么，我们就需要在两者之间架设适配层，让适配层处理 Node Js 的请求后再转发给 Java 的 RPC 服务。 一些中间系统的功能，比如某些内部网关，需要以一个统一的方式实现对其他下游系统的调用（非 SPI的情况），逐个依赖下游的包显然是不可能的。 一些流量回放类的线上系统，可以将数据采集拦截，之后，通过泛化调用回放，而不需要依赖全站的应用。  那么这种情况下，肯定不能包含所有接口的 jar 文件，否则就太臃肿了。实际上也是不现实的，总不能每增加一个服务端，就增加一个 jar 包依赖，然后应用进行发布重启。\n这个时候就可以使用泛化调用，将相应的请求包装成泛化调用，就能够实现不依赖接口 jar 包，多语言调用 RPC 服务，避免重复开发。\nSOFA RPC 的泛化调用使用 SOFA RPC 的官方文档十分详细，在官方 wiki 泛化调用 中，已有详细介绍。同时，在源码中的 example 模块中，也有现成的 demo 可以跑起来，读者可以自己 clone 源码阅读，这里我们简要说明一下使用方式，以便大家有一个直观的了解。\n接口定义 总的来说，泛化调用有 2 个 API，包含 5 个方法，其中， 2 个方法已经废弃，也就是说，有 3 个主要方法。分别是：\n/** * 泛化调用 * @return 正常类型（不能是GenericObject类型） */ Object $invoke(String methodName, String[] argTypes, Object[] args); /** * 支持参数类型无法在类加载器加载情况的泛化调用 * @return 除了JDK等内置类型，其它对象是GenericObject类型 */ Object $genericInvoke(String methodName, String[] argTypes, Object[] args); /** * 支持参数类型无法在类加载器加载情况的泛化调用 * @return 返回指定的T类型返回对象 */ \u0026amp;lt;T\u0026amp;gt; T $genericInvoke(String methodName, String[] argTypes, Object[] args, Class\u0026amp;lt;T\u0026amp;gt; clazz);  $invoke 该方法使用场景：用户知道参数类型和返回值类型，那么就可以使用该方法。 $genericInvoke 该方法是个重载方法，重载一的使用场景是：如果你的应用不知道接口的参数类型和返回值类型，这个时候，你就需要使用 GenericObject 类，来包装返回值和参数。 $genericInvoke 重载二的使用场景是：如果应用不知道接口参数类型，但是知道接口返回值的类型，那么就不需要使用 GenericObject 作为返回值了。  基本上，已经覆盖了常用的集中场景，可以说功能相当全面。\n泛化使用 由于篇幅有限，这里就不贴使用 demo 了，感兴趣的可以通过链接查看官方的 demo 或者源码，包含 SOFARPC 的 API 使用方式和 SOFABoot 的使用方式：\n demo wiki 地址：用户手册-\u0026amp;gt;基本特性-\u0026amp;gt;泛化调用 源码地址：示例源码  SOFARPC 泛化调用的设计与实现 接下来我们重点来介绍 SOFARPC 是如何实现泛化调用的。\n框架调用设计 简单来说，泛化调用的关键就是对象表示和序列化，SOFARPC 提供了 GenericObject 等对象来表示参数对象或者返回值对象，而将 GenericObject 对象序列化成目标对象，或者将返回值反序列化成 GenericObject 对象，是 SOFARPC 实现泛化的关键。\n这里我们先来看一下 SOFARPC 泛化调用的流程图，有助于后面理解泛化实现。\n我们来说一下这个图：\n 泛化 API 调用时，会加载泛化过滤器，作用是做一些参数转换，同时设置序列化工厂类型。 SOFARPC 在使用 SOFABolt 进行网络调用前，会创建 context 上下文并传递给 SOFABolt，上下文中包含着序列化工厂类型信息，这个信息将决定使用何种序列化器，同时这个上下文将流转于整个调用期间。 在 SOFABolt 正式发送数据之前，会将 GenericObject 对象序列化成普通对象的字节流，这样，服务提供方就不必关心是否为泛化调用，从图中可见，提供方不用对泛化调用做任何改变 —— 这是 SOFARPC 泛化区别于其他 RPC 泛化的关键。 当提供方成功接收请求后，使用普通序列化器即可反序列化数据，只需要正常调用并返回即可。 当消费者的 SOFABolt 接收到响应数据后，便根据 context 的序列化类型，对返回值做反序列化，即将普通的字节流反序列化成 GenericObject 对象 —— 因为客户端有可能不知道返回值的 Class 类型。 最终，泛化 API 即可得到 GenericObject 类型的返回值。  从上面的流程可以看出，序列化器在泛化调用中，占了极大的篇幅和作用。而 SOFARPC 针对泛化调用，对 hessian3 进行了改造，使其支持泛化调用所需要的序列化功能。SOFA-Hessian的改动可以参考这里。\nHessian 泛化实现 SOFA-Hessian 在 hessian 的包中加入了 com.alipay.hessian.generic 包，此包的作用就是处理泛化调用，重写的关键是实现或继承 SerializerFactory 类和 Serializer、Deserializer 等接口。在这里，设计了一下几个类，来描述对应的类型信息，同时实现这几个类的序列化和反序列化。对应关系如下：\n我们以 GenericObjectSerializer 为例， …","date":1537945200,"description":" 本文为《剖析 | SOFARPC 框架》第七篇，作者莫那·鲁道 ，来自 E签宝。","dir":"blog/sofa-rpc-generalized-call-implementation/","fuzzywordcount":3300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"de327dfe502c28ef0f926f17b29a6c80","permalink":"/blog/sofa-rpc-generalized-call-implementation/","publishdate":"2018-09-26T15:00:00+08:00","readingtime":7,"relpermalink":"/blog/sofa-rpc-generalized-call-implementation/","summary":"SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文为《剖析 |","tags":["SOFARPC","剖析 | SOFARPC 框架","SOFALab"],"title":"【剖析 | SOFARPC 框架】之 SOFARPC 泛化调用实现剖析","type":"blog","url":"/blog/sofa-rpc-generalized-call-implementation/","wordcount":3219},{"author":"畅为","categories":"SOFARPC","content":" SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文为《剖析 | SOFARPC 框架》第六篇，作者畅为。 《剖析 | SOFARPC 框架》系列由 SOFA 团队和源码爱好者们出品， 项目代号：SOFA:RPCLab/，官方目录目前已经全部认领完毕。\n 一. 前言 对于金融业务而言每个环节都涉及到大量的资金操作，若因为网络、硬件等原因导致系统不稳定性，不仅影响用户体验，更重要的是可能会引起资损问题，因此系统可用性至关重要。在微服务分布式架构中提高系统可用性的常见方案是 集群（冗余）。 集群方式将一个服务部署在多个机器上，通过硬负载或软负载实现服务的均衡负载，虽然可以有效避免单点问题，但是仍然避免不了某些场景单机故障引起服务调用失败的问题。\nSOFARPC 提供了自动单机故障剔除能力，能够自动监控 RPC 调用的情况，对故障节点进行权重降级，并在节点恢复健康时进行权重恢复，提高系统可用性。本文将从以下几个方面进行剖析：\n  单机故障和服务降级介绍\n  SOFARPC 单机故障剔除原理\n  二. 单机故障和服务降级 在分布式架构中常见可用性方案的是 集群（冗余），即将一个服务部署在多个机器上，通过硬负载或软负载实现服务的均衡负载。硬件负载因每次请求都需要经过硬件负载，承担所有的访问压力，当集群规模增加、流量增多，硬件负载可能因无法支撑所有流量而导致系统不可用。\n软负载则提供注册中心，并将负载能力转移到服务调用方( Consumer )，注册中心只有在 Consumer 首次订阅或服务发生变化时才会发生交互，避免了并发访问下的单点问题。下图是基于软负载的服务调用：\n虽然软负载可以避免单点问题，但可能存在以下场景导致服务不可用：\n  Provider 出现单点故障或宕机，与 Consumer 的长连接已断开，但注册中心尚未摘除或未及时通知Consumer。\n  Consumer 和 Provider的长连接还在，注册中心未下发摘除，但服务器端由于某些原因，例如长时间的 Full GC, 硬件故障（后文中为避免重复，统一描述为机器假死）等场景，处于假死状态。\n  这两种场景都是服务端出现故障，但由于长连接还保留等原因注册中心未摘除服务，导致服务调用失败。针对第一种情况 Consumer 不应调用出现故障的 Provider，否则会引起部分服务不可用；针对第二种情况，这个 Consumer 应该不调用或少调用该 Provider，可以通过权重的方式来进行控制。目前 SOFARPC 5.3.0 以上的版本支持 RPC 单机故障剔除能力。SOFARPC 通过服务权重控制方式来减少异常服务的调用，将更多流量打到正常服务机器上，提高服务可用性。\n2.1 SOFARPC故障剔除 vs 注册中心故障剔除 SOFARPC 的故障剔除与注册中心故障服务剔除不同，它们从不同的维度来完成故障剔除提高服务可用性。主要两方面的区别：\n  故障剔除的时机\n  故障剔除的细粒度\n  故障剔除的时机 SOFARPC 的故障剔除与注册中心故障服务剔除不同，它们从不同的维度来完成故障剔除提高服务可用性。注册中心服务管理关注 Provider 与注册中心的心跳或长连接。如果 Provider 出现心跳异常或长连接不存在，则及时将服务从注册中心剔除，并告知 Consumer 移除本地缓存的故障 Provider 信息。Comsumer 在负载均衡选择时则不考虑被剔除的 Provider，如图所示：\n而 SOFARPC 单机故障剔除针对的场景不同，针对的是注册中心还未剔除的服务，这些服务与 Consumer 仍然保持长连接，但由于机器假死，不能提供正常服务。 如下图所示：\n故障剔除的细粒度 注册中心剔除的是粒度是针对单机上的某个服务进程，属于进程级别。一旦这个进程和注册中心断开连接或心跳无感应，则将其从注册中心剔除。\nSOFARPC 故障剔除并控制精度会更精细一些，会细致到进程对外暴露的服务，如部署在某个机器上的交易系统对外提供的交易查询服务 TransQueryService. 管理的维度是 IP + 服务， 这里的服务特指进程中的服务接口。\n2.2 服务权重降级 vs 服务降级 服务降级是当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务和页面有策略的降级，以此释放服务器资源以保证核心任务的正常运行。这里的降级级别是整个系统服务，而不是针对接口级别。\nSOFARPC 的服务降级，是指当某些个别机器因为存在机器假死，导致处于假死状态，导致一些服务接口响应异常，通过 SOFARPC 的故障剔除和服务权重降级来减少对这些异常机器接口的访问，而将更多的流量打到正常的机器上。 这里针对的维度主要还是 IP + 服务维度，如部署在 xxx 机器上交易系统对外提供的 TransQueryService 服务。\n三. 原理解析 通常一个服务有多个服务提供者，其中部分提供者可能由于机器假死等导致长连接还存活但是程序已经无法正常响应 。 故障剔除功能会将这部分异常的服务提供者进行降级，使得客户端的请求更多地指向健康节点。当异常节点的表现正常后，故障剔除功能会对该节点进行恢复，使得客户端请求逐渐将流量分发到该节点。\nSOFARPC 5.3.0 以上支持故障剔除的功能，故障剔除功能采用自动化监控和降级，因此可以减少人工干预，提供系统可用率。SOFARPC 剔除的维度是服务 + Ip 级别。为了支持单机故障剔除能力，SOFARPC 提供了以下几个方面的设计：\n  入口设计: 进行RPC调用的时候，增加一个信息统计的传递入口。SOFARPC 采用无缝插入设计，在不破坏开放封闭原则前提下引入单机故障剔除能力。\n  信息收集器 : 维护和管理从入口传进来的统计信息。\n  计算策略 : 主要是根据度量结果，判断是否需要执行降级或者恢复服务。如果命中降级规则，则触发降级行为。如果命中恢复规则，则触发恢复行为。\n  度量策略 : 负责按一定维度对调用信息做度量，判断服务正常或异常。\n  降级策略 : 如果服务异常，需要进行降级处理，降级策略指定了处理逻辑，比如按打印日志或降低服务权重。\n  恢复策略 ：当一个异常服务恢复正常时，如何恢复该服务，例如提高服务权重等。\n  3.1 整体结构和入口 《SOFARPC 链路追踪剖析》中已介绍 SOFARPC 的 内核设计和总线设计，和链路追踪功能一样，SOFARPC 单机故障剔除能力也是基于内核设计和总线设计，做到可插拔、零侵入。\nSOFARPC 单机故障剔除模块是 FaultToleranceModule， 通过 SOFARPC 的 SPI 机制完成模块的自动化加载，以完成该功能的插入。 FaultToleranceModule 模块包含了两个重要部分：\n  subscriber 事件订阅器 。 通过订阅事件总线 EventBus 的事件，以零侵入方式完成 RPC 调用的统计和信息收集。\n  regulator 调节器 。 根据收集的 RPC 调用信息，完成服务调用 …","date":1537167600,"description":"本文为《剖析 | SOFARPC 框架》第六篇，作者畅为。","dir":"blog/sofa-rpc-single-machine-fault-culling/","fuzzywordcount":5300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"3171526788b6f17e3ffa37512918729f","permalink":"/blog/sofa-rpc-single-machine-fault-culling/","publishdate":"2018-09-17T15:00:00+08:00","readingtime":11,"relpermalink":"/blog/sofa-rpc-single-machine-fault-culling/","summary":"SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文为《剖析 |","tags":["SOFARPC","剖析 | SOFARPC 框架","SOFALab"],"title":"【剖析 | SOFARPC 框架】之 SOFARPC 单机故障剔除剖析","type":"blog","url":"/blog/sofa-rpc-single-machine-fault-culling/","wordcount":5279},{"author":"SOFARPCLab","categories":"SOFARPC","content":" SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文为《剖析 | SOFARPC 框架》第五篇。 《剖析 | SOFARPC 框架》系列由 SOFA 团队和源码爱好者们出品。\n 前言 上一篇，我们介绍了 SOFARPC 同步异步的实现，本文我们将会介绍 SOFARPC 中的线程模型。\n本文会从同步异步，阻塞非阻塞开始讲起，进而探讨常见的线程模型设计，之后，我们会介绍下 SOFABolt 中对 Netty 的模型使用，最后 SOFARPC 在一次调用过程中各个步骤执行的线程。\n几种常见的 IO 模型 首先介绍一下 Linux 的几种 IO 模型，以进程从 Socket 中读取数据为例。实际上，进程最终是通过 recvfrom 系统调用来读取数据。这个时候，系统内核在收到之后，根据 IO 模型的不同，处理是不同的。\n注意，图下的红色部分表示阻塞时间。\n阻塞 I/O 阻塞 I/O(blocking I/O) 模型是最流行，最简单易用的 I/O 模型，默认情况下，所有套接字和文件描述符就是阻塞的。阻塞 I/O 将使请求进程阻塞，直到请求完成或出错。\n非阻塞 I/O 非阻塞 I/O(nonblocking I/O)的含义：如果 I/O 操作会导致请求进程休眠，则不要把它挂起，也就是不会让出 CPU，而是返回一个错误告诉它（可能是 EWOULDBLOCK 或者 EAGAIN）。\nI/O 复用 I/O 多路复用(I/O multiplexing)会用到 select 或者 poll 或者 epoll 函数，这几个函数也会使进程阻塞，但是和阻塞 I/O 所不同的的，函数可以同时阻塞多个 I/O 操作。而且可以同时对多个读操作，多个写操作的 I/O 函数进行检测，直到有数据可读或可写时，才真正调用 I/O 操作函数。\n信号驱动式 I/O 信号驱动 I/O(signal-driver I/O)使用信号，让内核在描述符就绪时发送 SIGIO 信号通知我们进行处理，这时候我们就可以开始真正的读了。\n异步 I/O 异步 I/O(asynchronous I/O)由 POSIX 规范定义，包含一系列以 aio 开头的接口。一般地说，这些函数的工作机制是：告知内核启动某个操作，并让内核在整个操作（包括将数据从内核空间拷贝到用户空间）完成后通知我们。\n这种模型与信号驱动模型的主要区别是：信号驱动 I/O 是由内核通知我们何时可以启动一个 I/O 操作，而异步 I/O 模型是由内核通知我们 I/O 操作何时完成。\n汇总 综上，我们给出一个大家比较熟知的比较图。方便理解。\nJAVA BIO \u0026amp;amp; NIO 在了解了内核层面上这几个线程模型之后，我们要给大家介绍下 JAVA BIO 和 JAVA NIO。\nJAVA BIO 首先我们给大家看一个直接使用 JAVA BIO 写得一个服务端。\n传统的BIO里面socket.read()，如果TCP RecvBuffer里没有数据，调用会一直阻塞，直到收到数据，返回读到的数据。\nJAVA NIO 对于 NIO，如果 TCP 的 buffer 中有数据，就把数据从网卡读到内存，并且返回给用户；反之则直接返回0，永远不会阻塞。下面是一段比较典型的 NIO 的处理代码。\n在我们可以将 JAVA NIO 和多路复用结合起来。这里也是最简单的 Reactor 模式：注册所有感兴趣的事件处理器，单线程轮询选择就绪事件，执行事件处理器。\n这里简单比较了一下以前的 BIO 和现在的 NIO，新的 NIO 给我们带来了如下的好处。\n  事件驱动模型\n  单线程处理多任务\n  非阻塞 I/O，I/O 读写不再阻塞，而是返回 0\n  基于快的传输，比基于流的传输更高效\n  更高级的 IO 函数，零拷贝\n  允许 IO 多路复用\n  Reactor 线程模型 前面说了，我们有了 JAVA NIO ，可以用多路复用。有些同学可能会问，不能直接使用吗？答案是可以直接使用，\n但是技术层面上的问题虽然解决了，在工程层面，实现一个高效没有问题的架构依然很难，而且这种多路复用，对编程思维有比较大的挑战，所以，工程层面还不够。因此，有了 Reactor 编程模型\n一般情况下，I/O 复用机制需要事件分发器，以上这个分发事件的模型太简单了。实际使用起来会有一些性能问题。目前比较流行的是 Reactor 和 Proactor，本文不介绍 Proactor 模型，有兴趣的同学可以自己学习。\n标准/典型的 Reactor 中定义了三个角色：\n而一个标准的操作流程则是：\n  步骤1：等待事件到来（Reactor 负责）。\n  步骤2：将读就绪事件分发给用户定义的处理器（Reactor 负责）。\n  步骤3：读数据（用户处理器负责）。\n  步骤4：处理数据（用户处理器负责）。\n  在这个标准之下，Reactor 有几种演进模式可以选择。注意 Reactor 重点描述的是 IO 部分的操作，包括两部分，连接建立和 IO 读写。\n单线程模型 Reactor 单线程模型指的是所有的 IO 操作都在同一个NIO 线程上面完成，NIO 线程的职责如下：\n  作为 NIO 服务端，接收客户端的 TCP 连接；\n  作为 NIO 客户端，向服务端发起 TCP 连接；\n  读取通信对端的请求或者应答消息；\n  向通信对端发送消息请求或者应答消息。\n  这是最基本的单 Reactor 单线程模型。其中 Reactor 线程，负责多路分离套接字，有新连接到来触发 connect 事件之后，交由 Acceptor 进行处理，有 IO 读写事件之后交给 hanlder 处理。\nAcceptor 主要任务就是构建 handler，在获取到和 client 相关的 SocketChannel 之后 ，绑定到相应的 handler上，对应的 SocketChannel 有读写事件之后，基于 reactor 分发，hanlder 就可以处理了（所有的 IO 事件都绑定到 selector 上，由 Reactor 分发）。\n该模型 适用于处理器链中业务处理组件能快速完成的场景。不过，这种单线程模型不能充分利用多核资源，所以实际使用的不多。\n多线程模型 Reactor 多线程模型与单线程模型最大的区别就是将 IO 操作和非 IO 操作做了分离。效率提高。\nReactor 多线程模型的特点：\n  有专门一个 NIO 线程-Acceptor 线程用于监听服务端，主要接收客户端的 TCP 连接请求；\n  网络 IO 操作-读、写等由一个单独的 NIO 线程池负责，线程池可以采用标准的 JDK 线程池实现，它包含一个任务队列和 N 个可用的线程，由这些 NIO 线程负责消息的解码、处理和编码；\n  主从多线程模型 这个也是目前大部分 RPC 框架，或者服务端处理的主要选择。\nReactor 主从多线程模型的特点：\n服务端用于接收客户端连接的不再是个1个单独的 NIO 线程，而是一个独立的 NIO 线程池。\n主要的工作 …","date":1536735600,"description":"本文为《剖析 | SOFARPC 框架》第五篇。","dir":"blog/sofa-rpc-threading-model/","fuzzywordcount":3500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"fbde29dd299a8163dafa9d571d1714e8","permalink":"/blog/sofa-rpc-threading-model/","publishdate":"2018-09-12T15:00:00+08:00","readingtime":7,"relpermalink":"/blog/sofa-rpc-threading-model/","summary":"SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文为《剖析 |","tags":["SOFARPC","剖析 | SOFARPC 框架","SOFALab"],"title":"【剖析 | SOFARPC 框架】之 SOFARPC 线程模型剖析","type":"blog","url":"/blog/sofa-rpc-threading-model/","wordcount":3410},{"author":"SOFARPCLab","categories":"SOFARPC","content":" SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文为《剖析 | SOFARPC 框架》第四篇。 《剖析 | SOFARPC 框架》系列由 SOFA 团队和源码爱好者们出品。\n 前言 这一篇，我们为大家带来了开发过程中，最常接触到的同步异步调用解析。本文会介绍下同步异步的使用场景，以及 SOFARPC 中的代码实现机制，为了方便大家理解和阅读代码。不会过多的设计代码实现细节，更多的还是希望大家从中有所收获，并能够独立阅读核心代码。\n原理剖析 SOFARPC 以基于 Netty 实现的网络通信框架 SOFABolt 用作远程通信框架，使用者不用关心如何实现私有协议的细节，直接使用内置 RPC 通信协议，启动客户端与服务端，同时注册用户请求处理器即可完成远程调用：\nSOFARPC 服务调用提供同步 Sync、异步 Future、回调 Callback 以及单向 Oneway 四种调用类型。\n这里我们先提供一张整体的图，后面每个方式原理介绍的时候，我会进行更加详细的解释。读者可以重点阅读以下部分的图示，根据阻塞时间的长短，会有不同的标识。\nSync 同步调用 同步调用是指的客户端发起调用后，当前线程会被阻塞，直到等待服务端返回结果或者出现了超时异常，再进行后续的操作，是绝大多数 RPC 的默认调用方式，无需进行任何设置即可。\n这种调用方式，当前线程发起调用后阻塞请求线程,需要在指定的超时时间内等到响应结果才能完成本次调用。如果超时时间内没有得到响应结果，那么抛出超时异常。Sync 同步调用模式最常用，注意要根据对端的处理能力合理设置超时时间。\n如上图所示，这里主要是描述了客户端的处理逻辑，其中客户端线程和 RPC 内部部分处理并不在一个线程里。所以这里客户端线程包含其中一部分操作，后文的图中也是类似。其中红色的树状框表示客户端的线程阻塞。\n可以看到，客户端在代码片段2中，发起 RPC 调用，那么除非本次 RPC 彻底完成，或者 RPC 在指定时间内抛出超时异常，否则红框一直阻塞，代码片段3没有机会执行。\nFuture 异步调用 客户端发起调用后不会同步等待服务端的结果，而是获取到 RPC框架给到的一个 Future 对象，调用过程不会阻塞线程，然后继续执行后面的业务逻辑。服务端返回响应结果被 RPC 缓存，当客户端需要响应结果的时候需要主动获取结果，获取结果的过程阻塞线程。\n如上图所示，代码片段2发起 RPC 调用后，RPC 框架会立刻返回一个 Future 对象。给到代码片段2，代码片段2可以选择等待结果，或者也可以继续执行代码片段3，等代码片段3执行完成后，再获取 Future 中的值。\nCallback 回调调用 客户端提前设置回调实现类，在发起调用后不会等待结果，但是注意此时是通过上下文或者其他方式向 RPC 框架注册了一个 Callback 对象，结果处理是在新的线程里执行。RPC在获取到服务端的结果后会自动执行该回调实现。\n如图所示，客户端代码段2发起 RPC 调用后，并不关心结果，此时也不会有结果。只是将自己的一个 Callback 对象传递给 RPC 框架，RPC 框架发起调用后，立即返回。之后自己等待调用结果，在有了调用结果，或者超过业务配置的超时时间后，将响应结果或者超时的异常，进行 callback 的回调。一般的，一个 callback 的结果需要包含两个部分\npublic interface InvokeCallback { /** * Response received. * * @param result */ public void onResponse(final Object result); /** * Exception caught. * * @param e */ public void onException(final Throwable e); } 如果是正常返回，则 RPC 框架回调用户传入 callback 对象的 onResponse 方法，如果是框架层的异常，比如超时，那么会调用 onException 方法。\nOneway 单向调用 客户端发送请求后不会等待服务端返回的结果，并且会忽略服务端的处理结果，\n当前线程发起调用后，用户并不关心调用结果，只要请求已经发出就完成本次调用。单向调用不关心响应结果，请求线程不会被阻塞，使用 Oneway 调用需要注意控制调用节奏防止压垮接收方。注意 Oneway 调用不保证成功，而且发起方无法知道调用结果。因此通常用于可以重试，或者定时通知类的场景，调用过程是有可能因为网络问题、机器故障等原因导致请求失败，业务场景需要能接受这样的异常场景才能够使用。\n调用方式比较    调用方式 优点 不足 使用场景     Sync 简单 同步阻塞 大部分场景   Oneway 简单，不阻塞 无结果 不需要结果，业务不需要保证调用成功的场景   Future 异步，可获取结果 需要再次调用 get 方法获取结果 同线程内多次 RPC 调用。且没有先后关系   Callback 异步，不需要手动获取结果 使用稍微复杂。且不能在当前代码段直接操作结果 当前不关心结果。但是最终依赖结果做一些其他事情的场景    源码剖析 下面我们以 SOFARPC 中的 BOLT 协议为基础，介绍一些 RPC 框架下面的代码层面的设计。主要介绍代码结构和相互的调用关系。\n对 BOLT 的包装主要在\ncom.alipay.sofa.rpc.transport.bolt.BoltClientTransport 业务方并不直接使用 BOLT 定义的一些类型，而是使用 RPC 定义的一些类型。这些类型被适配到 BOLT 的类型上，使得 RPC 框架对用户提供了统一的 API，和底层是否采用 BOLT 不强相关。\nSync 同步调用 SOFARPC 中的的同步调用是由 Bolt 通信框架来实现的。核心代码实现在\ncom.alipay.remoting.BaseRemoting#invokeSync com.alipay.remoting.rpc.protocol.RpcResponseProcessor#doProcess 使用时无需特殊配置。\nFuture 异步调用 使用 Future 异步调用 SOFABoot 配置服务引用需要设置\n\u0026amp;lt;sofa:global-attrs type=\u0026amp;#34;future\u0026amp;#34;/\u0026amp;gt; 元素的 type 属性声明调用方式为 future：\n如上设置为 Future 调用的方式。客户端获取响应结果有两种方式：\n1.通过 SofaResponseFuture 直接获取结果。第一个参数是获取结果的超时时间，第二个参数表示是否清除线程上下文中的结果。\nString result =(String)SofaResponseFuture.getResponse(timeout,true); 2.获取原生 Futrue，该种方式获取JDK …","date":1536130800,"description":"本文为《剖析 | SOFARPC 框架》第四篇。","dir":"blog/sofa-rpc-synchronous-asynchronous-implementation/","fuzzywordcount":3600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"d7ab7dabc882ef32b491dc6ce551fc39","permalink":"/blog/sofa-rpc-synchronous-asynchronous-implementation/","publishdate":"2018-09-05T15:00:00+08:00","readingtime":8,"relpermalink":"/blog/sofa-rpc-synchronous-asynchronous-implementation/","summary":"SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文为《剖析 |","tags":["SOFARPC","剖析 | SOFARPC 框架","SOFALab"],"title":"【剖析 | SOFARPC 框架】之 SOFARPC 同步异步实现剖析","type":"blog","url":"/blog/sofa-rpc-synchronous-asynchronous-implementation/","wordcount":3596},{"author":"SOFARPCLab","categories":"SOFARPC","content":" SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文为《剖析 | SOFARPC 框架》第三篇，本篇由米麒麟/碧远共同出品。 《剖析 | SOFARPC 框架》系列由 SOFA 团队和源码爱好者们出品。\n 前言 在 RPC 调用过程中，我们经常会和多个服务端进行远程调用，如果在每次调用的时候，都进行 TCP 连接，会对 RPC 的性能有比较大的影响，因此，实际的场景中，我们经常要对连接进行管理和保持。\nSOFARPC 应用心跳包以及断线重连实现,结合系统 tcp-keepalive 机制，来实现对 RPC 连接的管理和保持。\n连接管理 首先我们将会介绍连接管理相关的一些背景知识。\n长连接和短连接 短连接，一般是指客户端向服务端发起连接请求。连接建立后，发送数据，接收服务端数据返回，然后触发连接断开，下次再重新重复以上过程。\n长连接，则是在建立连接后，发送数据，接收数据，但是不主动断开，并且主动通过心跳等机制来维持这个连接可用，当再次有数据发送请求时，不需要进行建立连接的过程。\n一般的，长连接多用于数据发送频繁，点对点的通讯，因为每个 TCP 连接都需要进行握手，这是需要时间的，在一些跨城，或者长距离的情况下，如果每个操作都是先连接，再发送数据的话，那么业务处理速度会降低很多，所以每个操作完后都不断开，再次处理时直接发送数据包即可，节省再次建立连接的过程。\n但是，客户端不主动断开，并不是说连接就不会断。因为系统设置原因，网络原因，网络设备防火墙，都可能导致连接断开。因此我们需要实现对长连接的管理。\nTCP 层 keep-alive tcp 的 keep-alive 是什么 tcp-keepalive，顾名思义，它可以尽量让 TCP 连接“活着”，或者让一些对方无响应的 TCP 连接断开，\n使用场景主要是：\n  一些特定环境，比如两个机器之间有防火墙，防火墙能维持的连接有限，可能会自动断开长期无活动的 TCP 连接。\n  还有就是客户端，断电重启，卡死等等，都会导致 TCP 连接无法释放。\n  这会导致：\n一旦有热数据需要传递，若此时连接已经被中介设备断开，应用程序没有及时感知的话，那么就会导致在一个无效的数据链路层面发送业务数据，结果就是发送失败。\n无论是因为客户端意外断电、死机、崩溃、重启，还是中间路由网络无故断开、NAT 超时等，服务器端要做到快速感知失败，减少无效链接操作。\n而 tcp-keepalive 机制可以在连接无活动一段时间后，发送一个空 ack，使 TCP 连接不会被防火墙关闭。\n默认值 tcp-keepalive，操作系统内核支持，但是不默认开启,应用需要自行开启，开启之后有三个参数会生效，来决定一个 keepalive 的行为。\nnet.ipv4.tcp_keepalive_time = 7200 net.ipv4.tcp_keepalive_probes = 9 net.ipv4.tcp_keepalive_intvl = 75 可以通过如下命令查看系统 tcp-keepalive 参数配置。\nsysctl -a | grep keepalive cat /proc/sys/net/ipv4/tcp_keepalive_time sysctl net.ipv4.tcp_keepalive_time 系统默认值可以通过这个查看。\ntcp_keepalive_time，在 TCP 保活打开的情况下，最后一次数据交换到 TCP 发送第一个保活探测包的间隔，即允许的持续空闲时长，或者说每次正常发送心跳的周期，默认值为 7200s（2h）。 tcp_keepalive_probes 在 tcp_keepalive_time 之后，没有接收到对方确认，继续发送保活探测包次数，默认值为 9（次）。 tcp_keepalive_intvl，在 tcp_keepalive_time 之后，没有接收到对方确认，继续发送保活探测包的发送频率，默认值为 75s。\n这个不够直观，直接看下面这个图的说明：\n如何使用 应用层，以 Java 的 Netty 为例，服务端和客户端设置即可。\nServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 100) .childOption(ChannelOption.SO_KEEPALIVE, true) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer\u0026amp;lt;SocketChannel\u0026amp;gt;() { @Override public void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast( new EchoServerHandler()); } }); // Start the server.  ChannelFuture f = b.bind(port).sync(); // Wait until the server socket is closed.  f.channel().closeFuture().sync(); 就是这里面的ChannelOption.SO_KEEPALIVE, true 对应即可打开.\n目前 bolt 中也是默认打开的.\n.childOption(ChannelOption.SO_KEEPALIVE, Boolean.parseBoolean(System.getProperty(Configs.TCP_SO_KEEPALIVE, \u0026amp;#34;true\u0026amp;#34;))); Java 程序只能做到设置 SO_KEEPALIVE 选项，至于 TCP_KEEPCNT，TCP_KEEPIDLE，TCP_KEEPINTVL 等参数配置，只能依赖于 sysctl 配置，系统进行读取。\n检查 查看 tcp 连接 tcp_keepalive 状态\n我们可以用 netstat -no|grep keepalive 命令来查看当前哪些 tcp 连接开启了 tcp keepalive. 应用层 keep-alive 应用层 keep-alive 方案，一般叫做心跳包，跟 tcp-keepalive 类似，心跳包就是用来及时监测是否断线的一种机制，通过每间隔一定时间发送心跳数据，来检测对方是否连接，是属于应用程序协议的一部分。\n心跳是什么 心跳想要实现的和 tcp keep-alive 是一样的。\n由于连接丢失时，TCP 不会立即通知应用程序。比如说，客户端程序断线了，服务端的 TCP 连接不会检测到断线，而是一直处于连接状态。这就带来了很大的麻烦，明明客户 …","date":1535526000,"description":"本文为《剖析 | SOFARPC 框架》第三篇，本篇由米麒麟/碧远共同出品。","dir":"blog/sofa-rpc-connection-management-heartbeat-analysis/","fuzzywordcount":4300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"2f911034e6bec76b8b0496b7f06e10b7","permalink":"/blog/sofa-rpc-connection-management-heartbeat-analysis/","publishdate":"2018-08-29T15:00:00+08:00","readingtime":9,"relpermalink":"/blog/sofa-rpc-connection-management-heartbeat-analysis/","summary":"SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文为《剖析 |","tags":["SOFARPC","剖析 | SOFARPC 框架","SOFALab"],"title":"【剖析 | SOFARPC 框架】之SOFARPC 连接管理与心跳剖析","type":"blog","url":"/blog/sofa-rpc-connection-management-heartbeat-analysis/","wordcount":4225},{"author":"SOFARPCLab","categories":"SOFARPC","content":" SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文为《剖析 | SOFARPC 框架》第二篇，本篇由畅为/碧远/卓与共同出品。 《剖析 | SOFARPC 框架》系列由 SOFA 团队和源码爱好者们出品。\n 一. 前言 微服务已经被广泛应用在工业界，微服务带来易于团队并行开发、独立部署、模块化管理等诸多优点。然而微服务将原单体拆分多个模块独立部署，各模块之间链接变得错综复杂，在大规模分布式系统中这种复杂链路给维护带来了诸多困难。 如果对整个微服务架构不能了然于胸，便很难理清各模块之间的调用关系。 例如修改一个服务接口，对哪些服务造成影响不能快速定位。\nSOFARPC 在5.4.0 以后提供了**链路追踪技术，**可以有效协助开发运营人员进行故障诊断、容量预估、性能瓶颈定位以及调用链路梳理。\n如思维导图所示，本文将从以下几个方面介绍目前已经开源的 SOFARPC 的链路追踪技术：\n二. 什么是链路追踪技术 链路追踪技术主要是收集、存储、分析分布式系统中的调用事件数据，协助开发运营人员进行故障诊断、容量预估、性能瓶颈定位以及调用链路梳理。 链路追踪技术包含了数据埋点、收集、存储、分析等相关技术，是一套技术体系。 大部分的链路追踪框架都是参考 google链路追踪系统Dapper 的一篇设计论文（《Dapper, a Large-Scale Distributed Systems Tracing Infrastructure》 ），SOFARPC 的SOFATracer 的设计灵感也是来自这篇著名论文。\n以大规模分布式电商系统为例，用户下单购买某款产品时后端需要调用各系统或子模块进行协作，共同完成一个用户请求。 如下图所示，用户的下单行为涉及到了A、B、C、D、E、F 6个系统的协同工作，这些系统都是以集群形式部署。整个链路中最长的链路调用是3层，如 A-\u0026amp;gt; C -\u0026amp;gt; E 或 A -\u0026amp;gt; C -\u0026amp;gt; F。\n模块的增多加大了系统出错的概率，一旦因某系统/模块出错导致整个请求调用出错，在缺乏链路追踪的条件下很难定位具体出错的模块，只能通过日志搜索定位。 在实际生产环境下比较关注一个请求中的各个模块的耗时情况、连续调用情况、出错的节点等信息。 为了解决上述问题，Dapper提供了一套解决方案。整个方案分为数据收集、存储和分析几个部分。分布式追踪技术会记录一个请求中各模块的调用信息；并通过一个处理集群把所有机器上的日志增量地收集到集群当中进行处理，将同一个请求的日志串联；最后可视化显示调用情况。\n常用的数据收集方式为埋点，通过在公共组件如RPC等注入代码，收集服务调用的相关信息。目前大部分链路调用系统如Dapper、鹰眼、Spring Cloud Sleuth 都在用这种模式。同样SOFARPC 作为一个公共的通讯框架，在金融业务领域被广泛应用，因此适合作为埋点，这样无需业务端自行埋点，可做到对业务代码的无侵入性。\nDapper 将一个调用过程构建成一棵调用树(称为Tracer)，Tracer树中的每个节点表示链路调用中的一个模块或系统。 通过一个全局唯一的 traceId 来标识一个请求调用链。 并定义了span，span表示一个系统的调用，一个span 包含以下阶段：\n  Start: 发起调用\n  cleint send(cs): 客户端发送请求\n  Server Recv(sr)：服务端收到请求\n  Server Send(ss): 服务端发送响应\n  Client Recv(cr) : 客户端收到服务端响应\n  End： 整个链路完成\n  每个span 包含两个重要的信息 span id(当前模块的span id) 和 span parent ID(上一个调用模块的span id)，通过这两个信息可以定位一个span 在调用链的位置。 通过以上信息我们可以定义用户下单过程的调用链：\nSOFARPC中的链路追踪技术主要是作为埋点部分，因此对于链路追踪系统的收集和分析部分本文不做详述，想要深入了解的可参看参考资料内容。链路追踪可以提供我们以下功能:\n  服务耗时、瓶颈分析 ：分析每个服务的耗时情况，可以针对耗时长的服务进行优化，提高服务性能。\n  可视化错误：快速定位服务链路中出错的环境，便于排查和定位问题。一般链路追踪中间件都提供了ZipKin 页面支持。\n  链路优化: 对于调用比较频繁的服务，可以针对这些服务实施一些优化措施。\n  调用链路梳理：通过可视化界面，对整个调用链路有个清晰的认识。\n  在设计分布式链路框架时需要考虑一下几个问题：\n  低损耗、高性能: 追踪系统对在线服务的影响应该做到足够小，不影响线上服务性能。\n  应用透明: 对于业务开发人员来说，应不需要知道有跟踪系统这回事的。\n  可扩展性：虽则业务规则增大、集群增多，监控系统都应该能完全把控住这种快速变化。\n  **数据采样设计：**如果每条日志都记录，在高并发情况下对系统有一定的损耗。但收集数据太少可能对统计结果有所影响，所以应合理设计采样比例。\n  三. SOFARPC 链路追踪设计原理 SOFARPC 作为一个基础的通讯中间件，对服务调用有很强的感知能力，容易获取链路追踪所需的服务调用信息。因此很多链路追踪系统都会选择RPC 作为埋点对象，通过对RPC中间件的埋点可以轻松做到对用户的无感知、透明化。 SOFARPC在5.4.0 以后开始支持分布式链路追踪，其技术实现主要依赖于所集成的SOFATracer。\nSOFARPC 不仅提供了埋点信息采集的能力, 还支持数据上报zipkin。 通过SOFARPC + SOFATracer + zipKin 可以快速搭建一套完整的链路追踪系统，包括埋点、收集、分析展示等。 收集和分析主要是借用zipKin的能力，本文重点讲SOFARPC中的数据埋点设计。SOFARPC自身具备的微内核设计和可拓展性，使得在SOFARPC在不破坏开放封闭原则的前提下，比较轻松地集合SOFATracer。该部分主要从以下几个方面讨论SOFARPC的链路追踪设计思路：\n  可插拔设计。 SOFARPC采用了微内核设计，使得很容易扩展，增加新功能。\n  总线设计。为数据埋点做提供一种无侵入的扩展方式。\n  调用trace和span\n  数据采样设计\n  异步刷新机制\n  耗时计算：链路调用的耗时统计等信息获取。\n  埋点数据透传，各模块之间的链路调用数据的透传机制。\n  异步线程的链路调用。在异步多线程环境下如何保证traceId和spanId的有序性。\n  链路调用日志数据的文件存储结构\n  3.1 可插拔设计 SOFARPC自身具备的微内核设计和可拓展性，使得在SOFARPC在不破坏开放封闭原则的前提下，比较轻松地集合SOFATracer。SOFARPC 采用了自己实现的一套SPI机制， 通过该SPI机制动态去加载其他模块、过滤器、协议等，实现灵活拓展。SOFARPC 为了集成SOFATracer也采用了这套机制，做到可插 …","date":1534921200,"description":"本文为《剖析 | SOFARPC 框架》第二篇，本篇由畅为/碧远/卓与共同出品。","dir":"blog/sofa-rpc-link-tracking/","fuzzywordcount":6500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"09e24cfad0d59d40a509e893f26c59ef","permalink":"/blog/sofa-rpc-link-tracking/","publishdate":"2018-08-22T15:00:00+08:00","readingtime":13,"relpermalink":"/blog/sofa-rpc-link-tracking/","summary":"SOFA Scalable Open Financial Architecture 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。 本文为《剖析 |","tags":["SOFARPC","剖析 | SOFARPC 框架","SOFALab"],"title":"【剖析 | SOFARPC 框架】之 SOFARPC 链路追踪剖析","type":"blog","url":"/blog/sofa-rpc-link-tracking/","wordcount":6488},{"author":"碧远","categories":"SOFARPC","content":"前言 RPC 框架作为分布式技术的基石，在分布式和微服务环境下，扮演着非常重要的角色。\n在蚂蚁金服的分布式技术体系下，我们大量的技术产品（非网关类产品），都需要在内网，进行节点间通信。底层通信框架，已经在蚂蚁自研的 BOLT中的进行了实践，BOLT 提供了优秀的通信协议与通信框架，在 BOLT 的基础上，我们研发了自己的 RPC 框架，提供了负载均衡，流量转发，链路追踪，链路数据透传，故障剔除等基础能力，本文将从以下几个方面介绍目前已经开源的 SOFARPC 框架。\n RPC 是什么 通用 RPC 框架原理 SOFARPC 框架设计  RPC是什么 RPC 这个概念术语在上世纪 80 年代由 Bruce Jay Nelson 提出，在 Nelson 的论文 \u0026amp;ldquo;Implementing Remote Procedure Calls\u0026amp;rdquo; 中他提到了几点：\n 简单：RPC 概念的语义清晰,简单，方便建立分布式计算。 高效：在使用方看来,十分简单而且高效。 通用：通用,适用于各种不同的远程通信调用。  这里面Nelson提出了一个 RPC框架应该包含的几个部分。\n User User-stub RPC-Runtime Server-stub Server  如下图示，为了和现在我们通用的术语一致，我将 User 改成 Client 了。\n当 Client 想发起一个远程调用时，实际是通过本地调用 Client-stub，而 Client-stub 负责将调用的接口、方法和参数通过约定的协议规范进行编码并通过本地的 RPC-Runtime 实例传输到远端的实例。远端 RPC-Runtime 实例收到请求后交给 Server-stub 进行解码后发起本地端调用，在 Java中可以认为就是反射调用,调用结果再返回给 Client 端。\n从上文可以看到，一个典型的 RPC 调用过程还是相对简单的。但是实际上，一个真正的 RPC 框架要做的远不止这些。\n通用 RPC 框架原理 相信对 RPC 框架有过一定了解，或者使用过 RPC 产品的同学，在看到了图上之后，会产生几个疑问：\n1.Stub 怎么出现？\n2.怎么打包参数？\n3.怎么传输?\n4.怎么知道目标地址?\n5.怎么发布一个 RPC 服务?\n在解释这些问题之前，这里我画了一张目前通用的 RPC 框架的一个流程图：\n其中：\n1.创建代理解决了 Stub 的问题。\n2.序列化和网络协议编码解决了打包的问题。\n3.服务发现与路由寻址解决了如何知道目标地址的问题。\n4.如何发布一个服务，Registry 来解决。\nBolt，Netty 等解决了网络传输的问题。  当然 SOFARPC 的功能不止这些,在解决了这些问题之后，根据业务的需求和实际的线上情况，我们也开发了熔断,限流,故障剔除,数据透传等能力，下面我会来介绍 SOFARPC 的框架设计。\nSOFARPC框架设计 SOFARPC RoadMap 首先介绍下目前 SOFARPC 的现状和一些正在做的事情。\n欢迎对相关功能和 feature 有兴趣的同学，一起参与开发~\nSOFARPC 结构设计 原理大家清楚之后，为了方便大家尽快上手开发使用，我先从目前的 RPC 框架结构来简单介绍。\n其中 core和 core-impl 是核心的功能，包含 API 和一些扩展机制，extension-impl 中，则包含了不同的实现和扩展，比如对 http，rest，对 metrics，以及其他注册中心的集成和扩展。\n如 bootstrap 中对协议的支持，remoting 中对网络传输的支持，registry 中对注册中心的支持等。\n在此基础上，由于 RPC 框架涉及服务端和客户端，我会结合 SOFARPC 的处理流程，详细介绍下客户端和服务端的处理。\n客户端调用流程 当使用方对服务进行了引用配置之后：\n1.RPC 生成 Proxy，作为用户可以操作的入口。\n2.向服务中心订阅这个 RPC 的地址信息。\n3.使用方发起调用，经过路由，负载均衡，各类 Filter 发起调用。\n服务端处理流程 在服务端看来,通过 TCP 监听端口后：\n1.接到 RPC 请求后，进行解码和反序列化。\n2.选择线程池，进行分发。\n3.经过 Filter，进行反射调用。\n4.将结果序列化，编码,进行写回。\n可扩展的机制 从上面的流程中，可以看到，每个部分基本都有多种实现可选，这得益于RPC的扩展机制。\n为了对 RPC 各个环节的都有充足的可扩展性，提供 SPI 的能力，所以内部的实现和第三方实现都是绝对平等的。\n相比原生 SPI，我们实现了更强大的功能\n  按需加载\n  可以有别名\n  可以有优先级进行排序和覆盖\n  可以控制是否单例\n  可以在某些场景下使用编码\n  可以指定扩展配置位置\n  可以排斥其他扩展点\n  我们实现了一套自己的 SPI 机制。整个流程如下：\n在启动加载阶段，RPC 会根据对应的配置，加载需要调用方法ExtensionLoader(Class\u0026amp;lt;T\u0026amp;gt; interfaceClass, ExtensionLoaderListener\u0026amp;lt;T\u0026amp;gt; listener) 逻辑如下：\n  首先读取rpc-config-default.json和rpc-config.json，找到扩展描述文件存放的文件夹：extension.load.path属性。\n  找到接口类对应的扩展描述文件的文件名（默认就是接口名，也可以自己指定）。\n  循环加载这个文件下的扩展描述文件，按行读取。（同一个接口的同一个别名对应唯一的一个实现类，可以重复，允许覆盖。）\n  保存扩展实现类的alias和实现类的对应关系。\n  如果 ExtensionLoaderListener 不为空，则通知 Listener。\n  最终，将会构造出各个不同的 Filter，Invoker 等等。\n其中我们首先设计了一个扩展，代表这个类或者接口是可扩展的，默认单例、不需要编码。\n@Documented @Retention(RetentionPolicy.RUNTIME) @Target({ ElementType.TYPE }) public @interface Extensible { /** * 指定自定义扩展文件名称，默认就是全类名 * * @return 自定义扩展文件名称 */ String file() default \u0026amp;#34;\u0026amp;#34;; /** * 扩展类是否使用单例，默认使用 * * @return 是否使用单例 */ boolean singleton() default true; /** * 扩展类是否需要编码，默认不需要 * * @return 是否需要编码 */ boolean coded() default false; } 同时，针对具体的扩展实现，定义一个扩展注解\n@Documented @Retention(RetentionPolicy.RUNTIME) @Target({ ElementType.TYPE }) public @interface Extension { /** * …","date":1533193200,"description":"本文为  剖析 SOFARPC 框架第一篇。","dir":"blog/sofa-rpc-framework-overall-extension/","fuzzywordcount":2700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"d83b816009377f7f93fcd1edf63c534d","permalink":"/blog/sofa-rpc-framework-overall-extension/","publishdate":"2018-08-02T15:00:00+08:00","readingtime":6,"relpermalink":"/blog/sofa-rpc-framework-overall-extension/","summary":"前言 RPC 框架作为分布式技术的基石，在分布式和微服务环境下，扮演着非常重要的角色。 在蚂蚁金服的分布式技术体系下，我们大量的技术产品（非网关类产品","tags":["SOFARPC","剖析 | SOFARPC 框架","SOFALab"],"title":"【剖析 | SOFARPC 框架】之总体设计与扩展机制","type":"blog","url":"/blog/sofa-rpc-framework-overall-extension/","wordcount":2629},{"author":"鲁直","categories":"SOFABoot","content":"无论是什么样的业务系统，多多少少都会去做一些模块化的划分，或横或纵，各种姿势，但是这些姿势真地能帮你划分出良好的模块吗？帮你在模块之间做到高内聚，低耦合吗？模块化对于服务化又有什么样的影响？本来将分析常见的几种模块化方案的利弊，并且介绍蚂蚁金服开源的框架 SOFA 在模块化中发挥的作用。\n传统模块化的陷阱 在一个简单的 Spring/SpringBoot 的系统中，我们常常见到一个系统中的模块会按照如下的方式进行分层，如下图中的左边部分所示，一个系统就简单地分为 Web 层、Service 层、DAL 层。\n当这个系统承载的业务变多了之后，系统可能演化成上图中右边的这种方式。在上图的右边的部分中，一个系统承载了两个业务，一个是 Cashier（收银台），另一个是 Pay（支付），这两个业务可能会有一些依赖的关系，Cashier 需要调用 Pay 提供的能力去做支付。\n但是在这种模块化的方案里面，Spring 的上下文依然是同一个，类也没有任何做隔离，这就意味着，Pay Service 这个模块里面的任何的一个 Bean，都可以被 Cashier Service 这个模块所依赖。极端的情况下，可能会出现下面这种情况：\nCashier Service 错误地调用了 Pay Service 中的一个内部的 Bean，造成了两个模块之间的紧耦合。\n这种传统的模块化的问题在于模块化地不彻底。虽然在研发的时候，通过划分模块，把特定职责的类放到特定的模块里面去，达到了类的「物理位置」的内聚。但是在运行时，由于没有做任何隔离的手段，作为一个模块的开发者，并没有办法清楚地知道对方模块提供的对外的接口到底是什么，哪些 Bean 我是可以直接注入来用的，哪些 Bean 是你的内部的 Bean，我是不能用的。长此以往，模块和模块之间的耦合就会越来越严重，原来的模块的划分形同虚设。当系统越来越大，最后需要做服务化拆分的时候，就需要花费非常大的精力去梳理模块和模块之间的关系。\nOSGi 模块化 提到模块化，不得不提 OSGi，虽然 OSGi 没有成为 Java 官方的模块化的标准，但是由于 Java 在 Java 9 之前，一直没有官方的模块化的标准，所以 OSGi 已经是事实上的标准。\nOSGi 为模块化主要做了两个事情：\n OSGi 的类隔离 OSGi 的声明式服务  下面就给读者们简单地解释一下 OSGi 的这两个方面。\nOSGi 的类隔离 OSGi 通过扩展 Java 的 ClassLoader 机制，将模块和模块之间的类完全隔离开来，当一个模块需要引用另一个模块的类的时候，通过在模块中的 MANIFEST.MF 文件中声明类的导出和导入来解决，如下图所示：\n通过这种方式，可以控制一个模块特定的类才可以被另一个模块所访问，达到了一定程度地模块的隔离。\n但是，光光通过类的导出导入来解决类的引用问题还不够，还需要去解决实例的引用的问题，我们往往希望能够直接使用对方模块提供的某一个类的实例，而不是自己去 new 一个实例出来，所以 OSGi 还提供了声明式服务的方式，让一个模块可以引用到另一个模块提供的服务。\nOSGi 的声明式服务 OSGi 的声明式服务正是为了解决这个实例引用的问题，我们可以在一个 OSGi 的模块（Bundle）中去添加一个 XML 配置文件去声明一个服务，如下面的代码所示：\n\u0026amp;lt;?xml version=\u0026amp;#34;1.0\u0026amp;#34; encoding=\u0026amp;#34;UTF-8\u0026amp;#34;?\u0026amp;gt; \u0026amp;lt;scr:component xmlns:scr=\u0026amp;#34;http://www.osgi.org/xmlns/scr/v1.1.0\u0026amp;#34; name=\u0026amp;#34;ITodoService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;implementation class=\u0026amp;#34;com.example.e4.rcp.todo.service.internal.MyTodoServiceImpl\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;service\u0026amp;gt; \u0026amp;lt;provide interface=\u0026amp;#34;com.example.e4.rcp.todo.model.ITodoService\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/service\u0026amp;gt; \u0026amp;lt;/scr:component\u0026amp;gt; 也可以同样的通过 XML 配置文件去引用一个其他的模块声明的服务：\n\u0026amp;lt;?xml version=\u0026amp;#34;1.0\u0026amp;#34; encoding=\u0026amp;#34;UTF-8\u0026amp;#34;?\u0026amp;gt; \u0026amp;lt;scr:component xmlns:scr=\u0026amp;#34;http://www.osgi.org/xmlns/scr/v1.1.0\u0026amp;#34; name=\u0026amp;#34;XXXService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;reference name=\u0026amp;#34;ITodoService\u0026amp;#34; interface=\u0026amp;#34;com.example.e4.rcp.todo.model.ITodoService\u0026amp;#34; bind=\u0026amp;#34;setITodoService\u0026amp;#34; cardinality=\u0026amp;#34;0..1\u0026amp;#34; unbind=\u0026amp;#34;unsetITodoService\u0026amp;#34; policy=\u0026amp;#34;dynamic\u0026amp;#34; /\u0026amp;gt; \u0026amp;lt;implementation class=\u0026amp;#34;com.example.e4.rcp.todo.service.internal.XXXServiceImpl\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/scr:component\u0026amp;gt; 通过声明式服务的方式，我们就可以直接在一个 OSGi 的 Bundle 中使用另一个 Bundle 中提供的服务实例了。\nOSGi 的模块化的问题 OSGi 通过类隔离的机制解决了模块之间的类隔离的问题，然后通过声明式服务的方式解决了模块之间的服务调用的问题，看起来已经完美的解决了我们在传统的模块化中遇到的问题，通过这两个机制，模块和模块之间的边界变得清晰了起来。\n但是在实践的过程中，OSGi 的模块化却面临着一个非常严峻的问题，这个就是就是 OSGi 的类隔离带来的复杂性，OSGi 把每一个模块都通过独立的 ClassLoader 去加载，这样在开发模块的时候，研发的同学就必须非常清楚地去定义哪些类应该导出，哪些类应该导入，一旦少导出，或者导出错误，就会出现各种各样的错误，比如 LinkageError，NoSuchMethodError 等等，而要解决这些错误，要求研发同学清楚地理解 OSGi 的整个类加载体系，以及 Java 的整个类加载体系，这对普通的研发同学来说实在是一个太高的要求。所以这种方式在实施成本非常高，OSGi 并不是非常适合于业务研发。\nSOFA 模块化 为了解决传统的模块化方案模块化不彻底的问题，以及 OSGi 的彻底的模块化带来的复杂性的问题，SOFA 在早期就开始引入了一种折衷的模块化的方案。\nSOFA 模块化的整体的示意图如下：\nSOFA 模块化的方案，给每一个模块都提供了一个单独的 Spring 的上下文， …","date":1532520754,"description":"本来将分析常见的几种模块化方案的利弊，并且介绍蚂蚁金服开源的框架 SOFA 在模块化中发挥的作用。","dir":"blog/sofastack-modular-isolation/","fuzzywordcount":2700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"796c3ab365dd1191a7777c4dbf9d0a1b","permalink":"/blog/sofastack-modular-isolation/","publishdate":"2018-07-25T12:12:34Z","readingtime":6,"relpermalink":"/blog/sofastack-modular-isolation/","summary":"无论是什么样的业务系统，多多少少都会去做一些模块化的划分，或横或纵，各种姿势，但是这些姿势真地能帮你划分出良好的模块吗？帮你在模块之间做到高","tags":["SOFABoot"],"title":"蚂蚁金服的业务系统模块化之模块化隔离方案","type":"blog","url":"/blog/sofastack-modular-isolation/","wordcount":2688},{"author":"玄北","categories":"SOFABoot","content":"SOFABoot 是蚂蚁金服中间件团队开源的基于 Spring Boot 的一个开发框架，SOFABoot 从 2.4.0 版本开始支持基于 Spring 上下文隔离的模块化开发能力，SOFABoot 模块除了包括 Java 代码外，还会包含 Spring 配置文件，每个 SOFABoot 模块都是独立的 Spring 上下文。\n1. 背景 为了更好的理解 SOFABoot 模块化开发的概念，我们来区分几个常见的模块化形式：\n 基于代码组织上的模块化：这是最常见的形式，在开发期，将不同功能的代码放在不同 Java 工程下，在编译期被打进不同 jar 包，在运行期，所有 Java 类都在一个 classpath 下且使用同一个 Spring 上下文，没做任何隔离； 基于 Spring 上下文隔离的模块化：使用 Spring 上下文来做不同功能模块的隔离，在开发期和编译期，代码和配置也会分在不同 Java 工程中，但在运行期，不同的 Spring Bean 相互不可见，IoC 只在同一个上下文内部发生，但是所有的 Java 类还是在一个 ClassLoader 下； 基于 ClassLoader 隔离的模块化：借用 ClassLoader 来做隔离，每个模块都有独立的 ClassLoader，模块与模块之间的 classpath 不同，SOFAArk 就是这种模块化的实践方式。  以上三种模块化形式的隔离化程度逐次递进，但模块化就像一把双刃剑，在降低模块间耦合的同时也给模块间交互增加了成本，本文介绍第二种模块化形式 —— 基于 Spring 上下文隔离的模块化。\n与基于代码组织上的模块化相比，每个 SOFABoot 模块不仅仅包括 Java 代码，还会包含 Spring 配置文件，这种全新的包组织方式大大降低了用户接入成本，用户只需要简单的引入 Jar 包即可，由 SOFABoot 框架负责刷新模块上下文，无需在原来 Spring 配置文件中新增任何 Bean 定义，简化了接入流程，降低了出错几率。\n每个 SOFABoot 模块的 Spring 上下文都是隔离的。在 Spring 开发中，保证 Spring BeanId 不冲突是 Spring 运行的基础，这个限制在应用规模较小时很容易解决，只需用户在定义 BeanId 时稍加注意即可。但是随着系统规模越来越大，一个系统的开发往往涉及多个团队，保证每个业务定义 BeanId 不重复的成本也越来越高。在 SOFABoot 中，每个 SOFABoot 模块使用独立的 Spring 上下文，避免了不同 SOFABoot 模块间 BeanId 冲突，有效降低企业级多模块开发时团队间的沟通成本。\n2. 基本原理 在介绍 SOFABoot 模块化开发使用之前，我们简单了解下其背后的实现原理。下图是应用运行时的逻辑视图：\nSOFABoot 模块是模块化开发的最小单元，每个 SOFABoot 模块是一个独立的 Spring 上下文，在 SOFABoot 模块中我们可以定义Bean、发布 RPC 服务、连接数据库等等。\n由于上下文隔离，模块与模块之间的 Bean 无法通过 @Autowired 依赖注入，我们提供了 JVM Service/Reference 的方式进行模块间通信。SOFABoot 提供了两种形式的服务发布和引用，用于解决不同级别的模块间调用问题：\n JVM 服务发布和引用：解决一个 SOFABoot 应用内部各个 SOFABoot 模块之间的调用问题 RPC 服务发布和引用：解决多个 SOFABoot 应用之间的远程调用问题  Spring Boot 应用在调用 SpringApplication.run 时会创建一个 Spring Context，我们把它叫做 Root Application Context，它是每个 SOFABoot 模块创建的 Spring Context 的 Parent。这样设计的目的是为了保证每个 SOFABoot 模块的 Spring Context 都能发现 Root Application Context 中创建的 Bean，这样当应用新增 Starter 时，不仅 Root Application Context 能够使用 Starter 中新增的 Bean，每个 SOFABoot 模块的 Spring Context 也能使用这些 Bean。\n下面我们来演示如何开发一个简单的 SOFABoot 模块。\n3. 编写 SOFABoot 模块 3.1 新建工程 DEMO 工程地址\n运行需要 JDK 6 及以上、 Maven 3.2.5 以上。\n首先我们在 IDE 里新建一个普通 Maven 工程，并创建两个普通的 Maven 模块：\n service-facade: 定义服务接口 service-provide: 演示新建 SOFABoot 模块并发布 JVM 服务  3.2 定义服务接口 service-facade 模块包含用于演示 SOFABoot 模块发布与引用服务接口:\npublic interface SampleService { String message(); } 3.3 定义 SOFABoot 模块 service-provider 是一个 SOFABoot 模块，它会发布一个 JVM 服务供其他模块使用。首先需要为 service-provider 模块增加 sofa-module.properties 文件，将其定义为 SOFABoot 模块，sofa-module.properties 文件放置在 resources 目录:\nModule-Name=com.alipay.sofa.service-provider 3.4 发布服务 SOFABoot 支持三种形式的服务发布，分别是： XML 方式、Annotation 方式以及 API 编码方式，这里演示的是 XML 方式发布服务。\n首先增加 SampleServiceImpl 类，实现 SampleService 接口：\npublic class SampleServiceImpl implements SampleService { private String message; public String message() { return message; } public String getMessage() { return message; } public void setMessage(String message) { this.message = message; } } 增加 META-INF/spring/service-provide.xml 文件，将 SampleServiceImpl 发布为 JVM 服务:\n\u0026amp;lt;?xml version=\u0026amp;#34;1.0\u0026amp;#34; encoding=\u0026amp;#34;UTF-8\u0026amp;#34;?\u0026amp;gt; \u0026amp;lt;beans xmlns=\u0026amp;#34;http://www.springframework.org/schema/beans\u0026amp;#34; …","date":1532175154,"description":"本文是对蚂蚁金服开源的 SOFABoot 模块化开发的介绍。","dir":"blog/sofa-boot-modular-development/","fuzzywordcount":2300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"12a378e9b4d93d3dd89e79964b63d186","permalink":"/blog/sofa-boot-modular-development/","publishdate":"2018-07-21T12:12:34Z","readingtime":5,"relpermalink":"/blog/sofa-boot-modular-development/","summary":"SOFABoot 是蚂蚁金服中间件团队开源的基于 Spring Boot 的一个开发框架，SOFABoot 从 2.4.0 版本开始支持基于 Spring 上下文隔离的模块化开发能力，SOFABoot 模块除","tags":["SOFABoot"],"title":"基于 SOFABoot 进行模块化开发","type":"blog","url":"/blog/sofa-boot-modular-development/","wordcount":2209},{"author":"善逝","categories":"SOFABoot","content":"SOFABoot 是蚂蚁金服中间件团队开源的基于 Spring Boot 的一个开发框架，其在 Spring Boot 基础能力之上，增加了类隔离能力，以更好地解决随着工程应用变得臃肿庞大后带来的包冲突问题。类隔离能力天生带来模块化能力，同样给协作开发带来便利。\nSOFABoot 的类隔离能力借助单独的组件 SOFAArk 实现，遵循 Spring Boot 依赖即服务的思想，只要工程中引入了 SOFAArk 组件依赖，类隔离能力即生效。\n在上一篇文章 《在 Spring Boot 中集成 SOFABoot 类隔离能力》中，我们详细介绍了 SOFABoot 类隔离能力的使用背景及其使用方式。本文将介绍 SOFABoot 类隔离组件 SOFAArk 的实现原理。\n理解 SOFAArk 三要素 SOFAArk 类隔离框架定义了三个概念，Ark Container，Ark Plugin，Ark Biz。\n在介绍这三个主角之前，我们先来介绍另一个管家：Ark 包。我们都知道一个标准的 Spring Boot 应用可以借助 Spring 官方提供的打包插件：\n\u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/plugin\u0026amp;gt; 将应用打包成一个可执行 FatJar。相对应的，Ark 包则是 SOFABoot 官方提供的打包插件：\n\u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/plugin\u0026amp;gt; 将应用打包成一个具有类隔离能力的可执行 FatJar，称之为 Ark 包。下图是粗略地对比两者的目录结构差别：\n可以看到 Ark 包作为应用部署包的分发格式，它包含有 Ark Container，Ark Plugin 和 Ark Biz 三种格式模块。这里我们不对 Ark 包或者其他格式模块的目录结构作分析，感兴趣的同学可以点开文末附上的相关链接。我们重点介绍这三个角色的功能。\n Ark Container: Ark 容器，是组件 SOFAArk 的核心，运行 Ark 包时，Ark 容器会最先启动，负责应用运行时的管理，主要包括构建 Ark Plugin 和 Ark Biz 的类导入导出关系表、启动并初始化 Ark Plugin 和 Ark Biz、管理 Ark Plugin 服务的发布和引用等等。 Ark Plugin: SOFAArk 定义的一种模块格式，由若干个 Jar 包组成的一个 FatJar，开发人员可以借助官方提供的 maven 打包插件将若干 Jar 包打包成一个 Ark Plugin 供应用依赖。运行时，由独立的类加载器加载，因此有隔离需求的 Jar 包建议打包成 Ark Plugin 供应用依赖。 Ark Biz: SOFAArk 定义的一种模块格式，是应用及其依赖的所有三方包组成的一个 FatJar，需要注意的是，Ark Biz 不会包含应用依赖的 Ark Plugin。运行时，Ark Biz由独立的类加载器加载，借助类导入导出关系表，Ark Biz 可以使用 Ark Plugin 的导出类和资源。  SOFAArk 运行时隔离 根据上一节的描述可以知道 SOFABoot 类隔离关键是理解 SOFAArk 定义的三个概念，Ark Container，Ark Plugin 和 Ark Biz。下图表示的是应用启动后，运行时 Ark Container，Ark Plugin，Ark Biz 的逻辑分层图：\n我们将先以 Ark Plugin 入手来介绍 SOFABoot 类隔离的实现原理。\nArk Plugin 隔离 开发者借助 SOFABoot 官方提供的插件：\n\u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-plugin-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/plugin\u0026amp;gt; 可以将 Java 模块打包成一个 Ark Plugin，这里我们不讨论该打包插件的配置参数和使用方式，感兴趣的同学可以点开文末附上的相关链接以及学习 SOFABoot 类隔离能力使用篇。只需要知道，Ark Plugin 主要包含元信息有：插件启动器、导出类、导入类、导出资源、导入资源、优先级等，这些元信息保存在 Ark Plugin 中的 META-INF/MANIFEST.MF 中，一份典型的 MANIFEST.MF 文件样式如下：\nManifest-Version: 1.0 groupId: com.alipay.sofa artifactId: sample-ark-plugin version: 0.3.0-SNAPSHOT priority: 1000 pluginName: sample-ark-plugin activator: com.alipay.sofa.ark.sample.activator.SamplePluginActivator import-packages: import-classes: import-resources: export-packages: com.alipay.sofa.ark.sample.common.*,com.alipay.sofa.ark.sample export-classes: com.alipay.sofa.ark.sample.facade.SamplePluginService export-resources: Sample_Resource_Exported 在上面我们提到，运行 Ark 包时，类隔离容器 Ark Container 会最先启动，然后 Ark Container 会接管整个应用的启动过程。针对 Ark Plugin 处理逻辑如下：\n 首先解析 Ark 包中引入的所有 Ark Plugin，读取插件元信息，构建类/资源导入导出关系索引表。 提前生成所有插件类加载器，每个 Ark Plugin 都使用独立的类加载器，管理插件类加载逻辑，借助第一步生成的类导入导出关系表，突破 Java 原生的双亲委派模型，可以委托其他插件加载所需类，构建一个类 OSGi 的网状类加载模型。 根据插件优先级，依次调用插件启动器。在插件启动器中，插件开发者可以向容器注册服务以方便其他插件引用，也可以引用其他插件发布的服务，及插件启动所需的初始化操作。  需要明确一点，为了让类加载模型足够简单，Ark 容器在启动任何插件前，会把所有的插件类加载器提前构建完毕。Ark Plugin 可以相互委托加载，插件优先级只是影响插件的启动顺序， …","date":1528107154,"description":"本文将介绍 SOFABoot 类隔离组件 SOFAArk 的实现原理。","dir":"blog/sofa-boot-class-isolation-deep-dive/","fuzzywordcount":3600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"84c324f1230d57a0c4009566de91bb3c","permalink":"/blog/sofa-boot-class-isolation-deep-dive/","publishdate":"2018-06-04T10:12:34Z","readingtime":8,"relpermalink":"/blog/sofa-boot-class-isolation-deep-dive/","summary":"SOFABoot 是蚂蚁金服中间件团队开源的基于 Spring Boot 的一个开发框架，其在 Spring Boot 基础能力之上，增加了类隔离能力，以更好地解决随着工程应用变得臃肿庞大后带来的包冲","tags":["SOFAArk","SOFABoot"],"title":"SOFABoot 类隔离原理剖析","type":"blog","url":"/blog/sofa-boot-class-isolation-deep-dive/","wordcount":3540},{"author":"余淮","categories":"SOFAStack","content":"蚂蚁金服自主研发的分布式中间件（Scalable Open Financial Architecture，以下简称 SOFA 中间件），包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，是一套分布式架构的完整的解决方案，也是在金融场景里锤炼出来的最佳实践。\n一个多月前，蚂蚁金服开源了 SOFABoot 和 SOFARPC 两个组件，受到了社区的热烈欢迎，也收到了很多社区的反馈，其中就有提到目前开源的组件太少。\n本次 SOFA 中间件将继续开源微服务体系下的几个组件：包括分布式链路追踪（SOFATracer）客户端、Metrics监控度量（SOFALookout）客户端、SOFARPC 的 Nodejs 版实现。同时还开源了 SOFABoot 下的模块化开发框架，以及 SOFARPC 的 HTTP/2 能力等。\n下面将逐一进行简单介绍。\nSOFATracer SOFATracer 是一个用于分布式系统调用跟踪的中间件，通过统一的 traceId 将调用链路中的各种网络调用信息以日志或者上报的方式记录下来，以达到透视化网络调用的目的。这些日志可用于故障的快速发现，数据统计，服务治理等。为了解决在实施大规模微服务架构时的链路跟踪问题，SOFATracer 基于 OpenTracing（http://opentracing.io） 规范并扩展其能力，包括基于 Disruptor 高性能无锁循环队列的异步落地磁盘的日志打印能力，自定义日志格式，日志自清除和滚动能力，基于 SLF4J MDC 的扩展能力，统一的配置能力等。同时 SOFATracer 也对接了开源生态，可以选择将 Tracer 数据对接到 Zipkin 等开源产品。\nSOFATracer 的 Github 的地址是：https://github.com/sofastack/sofa-tracer ，欢迎大家使用反馈、贡献代码。（请将网址复制至浏览器中打开即可查看，下同。）\nSOFALookout SOFALookout 是一个利用多维度的 Metrics 对目标系统进行度量和监控的中间件。Lookout 的多维度 Metrics 参考 Metrics 2.0（http://metrics20.org/spec） 标准，提供一整套 Metrics 的处理，包括数据埋点、收集、加工、存储与查询等。SOFALookout 包括客户端与服务器端服务两部分，本次先开源客户端部分，服务端部分代码在整理中。 SOFALookout 客户端提供了一套 Metrics API 标准，通过它可以方便地对 Java 应用的 Metrics 进行埋点统计。为了方便使用，SOFALookout 客户端默认提供一些扩展模块，它们提供 JVM，OS 等基本 Metrics 信息的统计，遵循该扩展机制，我们可以自定义或集成更多的 Metrics 数据。另外，SOFALookout 客户端除了支持向 SOFALookout 服务端上报数据外，还支持与社区主流的相关产品，包括 Dropwizard,（SpringBoot）Actuator 以及 Prometheus 等进行集成和数据适配。\nSOFALookout 的 Github 的地址是：https://github.com/sofastack/sofa-lookout ，欢迎大家使用反馈、贡献代码。（请将网址复制至浏览器中打开即可查看，下同。）\nEggjs 集成 每种语言都有自己最擅长的领域，跨语言友好性对于分布式架构也是非常重要的。在蚂蚁内部还有一套 Nodejs 版本的 SOFA 中间件的实现，包含了绝大部分 Java 版本的功能，并将它们集成到已经开源的企业级 Nodejs 框架 Eggjs（https://eggjs.org） 中，形成了一套完整的 Web MVC 和 BFF (Backend For Frontend) 解决方案。这套架构目前广泛应用于蚂蚁的 Web 开发和多端适配等场景，让各岗位有了更清晰的职责划分，服务端（一般是 Java）提供基于领域模型的 RPC 接口，前端调用接口拿到数据后进行剪裁和格式化，并实现人机交互。领域模型与页面数据是两种思维模式，通过分层可以很好地解耦，让彼此更专业高效。后面我们也会陆续开源 SOFA 中间件的 Nodejs 版本实现，本期会先放出 SOFARPC 相关的两个模块：\nSOFARPC Node 的 Github 的地址是：https://github.com/sofastack/sofa-rpc-node ， SOFABolt Node 的 Github 的地址是：https://github.com/sofastack/sofa-bolt-node ， 欢迎大家使用反馈、贡献代码。（请将网址复制至浏览器中打开即可查看，下同。）\nSOFABoot 在最新的 SOFABoot 2.4.0 版本中，SOFABoot 新增加了基于 Spring 上下文隔离的模块化开发能力。在企业级应用场景，随着应用系统模块的增多，每个业务模块之间的耦合也会越来越严重，业务模块的自测更加复杂，团队之间的沟通成本增加。模块化开发是该问题的有效解决方案，但是 Spring Boot 默认不支持模块化开发，所有 Bean 共用一个 Spring 上下文。为此，SOFABoot 提出 SOFABoot 模块的概念，每个业务团队专注于开发自己的 SOFABoot 应用模块，模块自包含模块的代码和配置，拥有独立的 Spring 上下文，便于开发及自测，减少团队间的沟通成本。SOFABoot 模块间通信使用 JVM 服务进行通信，避免模块之间的耦合；如果远程服务在本地其它本地模块中存在，可优先调本地提高性能。同时 SOFABoot 提供了模块并行启动及 Bean 异步初始化能力，大幅提高应用启动速度。\nSOFABoot 的 Github 的地址是：https://github.com/sofastack/sofa-boot ，欢迎大家使用反馈、贡献代码。（请将网址复制至浏览器中打开即可查看，下同。）\nSOFARPC 在最新的 SOFARPC 5.4.0 版本中，SOFARPC 基于事件扩展机制，集成了 SOFATracer 和 SOFALookout 两个微服务体系产品，完善了自身的服务监控度量以及分布式跟踪功能。用户可以通过 SOFATracer 对接到 Zipkin 查看服务调用跟踪信息，也可以通过 SOFALookout 对接到 Prometheus 查看服务度量信息。新版本的 SOFARPC 中还增加了 HTTP/1.1 和 HTTP/2 协议的支持，在跨语言等场景下可以快速通过标准的 HTTP 协议进行通信。SOFARPC 也与 Eggjs 进行了打通了 Bolt 协议，方面用户在 Java 和 Nodejs 之间高效通信。\nSOFARPC 的 Github 的地址 …","date":1527761554,"description":"本次 SOFA 中间件将继续开源微服务体系下的几个组件：包括分布式链路追踪（SOFATracer）客户端、Metrics监控度量（SOFALookout）客户端、SOFARPC 的 Nodejs 版实现。同时还开源了 SOFABoot 下的模块化开发框架，以及 SOFARPC 的 HTTP/2 能力等。","dir":"blog/sofastack-open-source-doubles/","fuzzywordcount":3000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"00f2a1c85bfe83bf9f25ef1af9c44366","permalink":"/blog/sofastack-open-source-doubles/","publishdate":"2018-05-31T10:12:34Z","readingtime":6,"relpermalink":"/blog/sofastack-open-source-doubles/","summary":"蚂蚁金服自主研发的分布式中间件（Scalable Open Financial Architecture，以下简称 SOFA 中间件），包含了构建金融级云原生架构所需的各个组件，","tags":["SOFAStack"],"title":"蚂蚁金服分布式中间件开源第二弹：丰富微服务架构体系","type":"blog","url":"/blog/sofastack-open-source-doubles/","wordcount":2957},{"author":"善逝","categories":"SOFABoot","content":"SOFABoot 是蚂蚁金服中间件团队开源的基于 Spring Boot 的一个开发框架，其在 Spring Boot 基础能力之上，增加了类隔离能力。蚂蚁金服内部丰富的实践场景表明，类隔离能力对解决类冲突、版本管控有其特殊的优势。\nSOFABoot 的类隔离能力由单独的组件 SOFAArk 实现，相比业界遵循 OSGi（https://www.osgi.org/） 规范的 Equinox 或者 Felix，SOFAArk 专注于类隔离，简化了类加载模型，是一款更加轻量的类隔离框架。\n本文将介绍 SOFABoot 类隔离能力的背景及其使用方式。\n1. 背景 在 Java 世界中，依赖的 JAR 包之间相互冲突永远是一个痛，Spring Boot 采用统一的依赖管理机制规避了大部分依赖冲突问题。理想很美好，现实却很骨感，作为蚂蚁金服这类大体量的公司，各业务线纷繁复杂、基础服务组件繁多，很难做到对所有 JAR 包做统一管控，尤其涉及到多个跨团队模块组件相互依赖时，因为各自技术栈历史包袱的存在，难以有效统一冲突包版本。\n假设如下场景，工程需要引入两个三方组件：A 和 B，组件 A 需要依赖 Hessian 3，组件 B 需要依赖 Hessian 4，因为 Hessian 3 和 Hessian 4 是不兼容的。作为开发者，遇到这种包冲突问题，如果不借助类隔离框架，只能耗费精力升级到统一版本。\n为了彻底解决类似的包冲突问题，我们需要借助类隔离机制，使用不同的类加载器加载冲突的三方依赖包，进而做到在同一个应用运行时共存。\n基于此背景，SOFABoot 提供了一个轻量级的类隔离框架，也是本文的主角，SOFAArk。\n2. 基本原理 在介绍 SOFAArk 类隔离框架使用之前，我们简单了解下其背后的实现原理。正如前文中描述，SOFAArk 是通过独立的类加载器加载相互冲突的三方依赖包，从而做到隔离包冲突。那么我们不禁要问，SOFAArk 是如何区分应用中哪些依赖包是需要单独的类加载器加载呢？原因是 Ark Plugin，它是 SOFAArk 框架定义的一种特殊的 JAR 包文件格式，SOFAArk 框架会自动识别 Ark Plugin 这种特殊依赖。\n何为 Ark Plugin ? Ark Plugin 本质上是一个 FatJar，借助 SOFABoot 官方提供的 maven 打包插件，开发者可以把若干普通的 JAR 包打包成 Ark Plugin 供应用依赖或者把普通的 Java 模块改造成 Ark Plugin。通常来说，如果把一个普通 JAR 打包成 Ark Plugin，那么该 JAR 包依赖的其他三方包也会被打入同一个 Ark Plugin，默认情况下 SOFABoot 官方打包插件会自动把间接依赖也打入到 Ark Plugin。\n应用使用添加 maven 依赖的方式引入 Ark Plugin，运行时，SOFAArk 框架会自动识别应用的三方依赖包中是否含有 Ark Plugin，进而使用单独的类加载器加载。为了更加直观，下图是应用运行时逻辑分层图：\n可以看到，在应用运行时，SOFAArk 容器处于最底层，负责启动应用。应用依赖的所有 Ark Plugin 处于中间层，每个 Ark Plugin 都由 SOFAArk 容器使用独立的类加载器加载，相互隔离。应用业务代码及其他非 Ark Plugin 的普通三方依赖包，为了描述简单，统称为 Ark Biz，它运行在最上层，需要依赖中间层的 Ark Plugin。\n一个标准 Ark Plugin 会包含一些配置文件，主要包含导出类和导入类配置。导出类即把 Ark Plugin 中的类导出给 Ark Biz 和其他 Ark Plugin 可见。默认情况下，所有 Ark Plugin 的导出类对于 Ark Biz 来说都是可见的，即 Ark Biz 可以使用 Ark Plugin 的导出类。对于 Ark Plugin 来说，如果需要使用其他 Ark Plugin 的导出类，必须声明为自身的导入类。关于 Ark Plugin 详细说明可以参考文末相关链接。\n下面我们来演示如何开发一个简单的 Ark Plugin。\n3. Java 模块改造成 Ark Plugin 3.1 新建工程 Demo 工程参见：https://github.com/QilongZhang/ark-plugin-demo\n运行需要 JDK 6 及以上、 Maven 3.2.5 以上。\n首先我们在 IDE 里新建一个普通 Maven 工程，并创建三个普通的 Java 模块。以前文描述的 Hessian 冲突为例，在演示工程中定义了三个模快：\n pojo-module: 定义了一个简单的 PoJo 类 SamplePoJo，并设置为导出类，打包成 pojo-ark-plugin 。 hessian3-module：定义了一个服务类 Hessian3Service，实现了简单的序列化和反序列逻辑，使用的版本是 Hessian 3，并导入了 SamplePoJo，打包成 hessian3-ark-plugin 。 hessian4-module：定义了一个服务类 Hessian4Service，和 Hessian3Service 功能类似，使用的版本是 Hessian 4，并导入了 SamplePoJo，打包成 hessian4-ark-plugin 。  该用例是为了演示如何将普通的 Java 模块及其三方依赖包打包成 Ark Plugin，以 hessian3-module 模块为例来讲解打包流程。\n3.2 编写服务类 在 hessian3-module 中，提供了一个简单的序列化和反序列化功能类 Hessian3Service：\npackage com.alipay.sofa.demo.hessian3; import com.caucho.hessian.io.HessianInput; import com.caucho.hessian.io.HessianOutput; import java.io.ByteArrayInputStream; import java.io.ByteArrayOutputStream; import java.io.IOException; /** * @author qilong.zql */ public class Hessian3Service { public byte[] serialize(Object obj) throws IOException { if(obj==null) throw new NullPointerException(); ByteArrayOutputStream os = new ByteArrayOutputStream(); HessianOutput ho = new HessianOutput(os); ho.writeObject(obj); return os.toByteArray(); } public Object deserialize(byte[] by) throws …","date":1526465554,"description":"本文将介绍 SOFABoot 类隔离能力的背景及其使用方式。","dir":"blog/spring-boot-sofa-boot-class-isolation-integration/","fuzzywordcount":3600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"c22dd2791732b32177419ff678b34546","permalink":"/blog/spring-boot-sofa-boot-class-isolation-integration/","publishdate":"2018-05-16T10:12:34Z","readingtime":8,"relpermalink":"/blog/spring-boot-sofa-boot-class-isolation-integration/","summary":"SOFABoot 是蚂蚁金服中间件团队开源的基于 Spring Boot 的一个开发框架，其在 Spring Boot 基础能力之上，增加了类隔离能力。蚂蚁金服内部丰富的实践场景表明，类隔离能力对解决","tags":["SOFABoot","SpringBoot","SOFAArk"],"title":"在 Spring Boot 中集成 SOFABoot 类隔离能力","type":"blog","url":"/blog/spring-boot-sofa-boot-class-isolation-integration/","wordcount":3524},{"author":"绍辉","categories":"Seata","content":"上周，分布式事务 Fescar 宣布进行品牌升级：Thanks, Fescar ❤️，Hello, Seata 🚀。\nSeata 意为：Simple Extensible Autonomous Transaction Architecture，是一套一站式分布式事务解决方案。项目地址：https://github.com/seata/seata\n蚂蚁金服在 Seata 0.4.0 版本加入了 TCC 模式，后续也会持续输入。\n为了帮助大家理解，分布式事务开源负责人绍辉进行了一次线下分享，详细讲述了分布式事务在蚂蚁金服的发展，希望可以帮助大家理解分布式事务，以下为分享的文字整理版本。\n前言 今天的分享将从以下三个部分展开：分布式事务问题产生的背景、蚂蚁金服分布式事务以及分布式事务 Seata 的 Roadmap。\n分享嘉宾：绍辉 蚂蚁金服 分布式事务开源负责人\n1、分布式事务问题产生的背景 1.1、数据库的水平拆分 蚂蚁金服早期，业务量比较小，单库单表便能满足业务需求；但是随着业务的发展，单库单表数据库逐渐成为瓶颈。为了解决数据库的瓶颈问题，我们对数据库进行了水平拆分。拆分所带来的一个问题就是以前一个数据库上便能完成的写操作现在要跨多个数据库，由此带来了跨库事务问题。\n1.2、业务的服务化拆分 蚂蚁金服早期是单系统架构，所有业务服务几乎都在少数几个 APP 中。随着业务的发展，业务越来越复杂，服务之间的耦合度也越来越高，故我们对系统进行了重构，服务按照功能进行解耦和垂直拆分。拆分之后所带来的问题就是一个业务活动原来只需要调用一个服务就能完成，现在需要调用多个服务才能完成，由此产生了跨服务事务问题。\n1.3、转账案例说明数据一致性问题 数据库的水分拆分以及服务的垂直拆分，所带来的问题是一个业务活动通常要调用多个服务、访问多个数据库才能完成。\n以金融业务场景下的转账场景为例，转账服务要完成以下操作：\n 调用交易系统服务创建交易订单； 调用支付系统记录支付明细； 调用账务系统执行 A 扣钱； 调用账务系统执行 B 加钱。  以上 4 个操作要跨 3 个系统，访问 4 个数据库。而网络、数据库、机器等都具有不可靠性，我们很难保证以上 4 个操作能 100% 全部成功。\n在金融属性的业务中，不允许 A 账户的钱扣了，而 B 账户的钱没有加上的现象出现，所以我们必须想办法保证 1 ~ 4 这四个操作要么全部成功，要么全部失败；所以蚂蚁金服自主研发了分布式事务中间件，解决跨服务、跨数据库的数据一致性问题。\n2、蚂蚁金服分布式事务 2.1、分布式事务理论基础 在介绍蚂蚁金服的分布式事务中间件之前，先介绍一些分布式事务的理论背景。\n 2PC  两阶段提交协议（Two Phase Commitment Protocol）是分布式事务最基本的协议。在两阶段提交协议中，有一个事务管理器和多个资源管理器，事务管理器分两阶段协调资源管理器。在第一阶段，事务管理器询问所有资源管理器准备是否成功。如果所有资源均准备成功，那么在第二阶段事务管理器会要求所有资源管理器执行提交操作；如果任一资源管理器在第一阶段返回准备失败，那么事务管理器会要求所有资源管理器在第二阶段执行回滚操作。通过事务管理器的两阶段协调，最终所有资源管理器要么全部提交，要么全部回滚，最终状态都是一致的。\n TCC  资源管理器有很多实现方式，其中 TCC（Try-Confirm-Cancel）是资源管理器的一种服务化的实现。TCC 是一种比较成熟的分布式事务解决方案，可用于解决跨数据库、跨服务业务操作的数据一致性问题。TCC 其 Try、Confirm、Cancel 3 个方法均由业务编码实现，故 TCC 可以被称为是服务化的资源管理器。\nTCC 的 Try 操作作为一阶段，负责资源的检查和预留；Confirm 操作作为二阶段提交操作，执行真正的业务；Cancel 是二阶段回滚操作，执行预留资源的取消，使资源回到初始状态。\n如下图所示，用户实现 TCC 服务之后，该 TCC 服务将作为分布式事务的其中一个资源，参与到整个分布式事务中。事务管理器分两个阶段协调 TCC 服务，在第一阶段调用所有 TCC 服务的 Try 方法，在第二阶段执行所有 TCC 服务的 Confirm 或者 Cancel 方法，最终所有 TCC 服务要么全部都是提交的、要么全部都是回滚的。\n2.2、蚂蚁金服分布式产品介绍 蚂蚁金服从 2007 年开始做分布式事务，至今已经有 12 年历史。蚂蚁金服的分布式事务最初是采用 TCC 实现的，TCC 模式帮蚂蚁业务解决了各类金融核心场景下的数据一致性问题。\n2007 年我们开始支持双十一，为了满足双十一的高性能需求，我们对分布式事务做了一系列的性能优化。\n2013年，蚂蚁金服开始做单元化改造，分布式事务也开始支持 LDC、异地多活和高可用容灾，解决了机房故障情况下服务快速恢复的问题。\n2014年，蚂蚁金服分布式事务中间件开始通过蚂蚁金融云对外输出，我们发展了一大批的外部用户；在发展外部客户的过程中，外部客户表示愿意牺牲一部分性能（无蚂蚁的业务规模）以换取接入便利性和无侵入性。\n所以在 2015年，我们开始做无侵入的事务解决方案：FMT 模式和 XA 模式。\n蚂蚁金服分布式事务中间件经过长期演进，目前积累了 TCC、FMT 和 XA 三种模式，具有丰富的应用场景。下面分别介绍这三种模式。\n2.3、TCC 模式 蚂蚁金服的 TCC 模式和前面介绍 TCC 理论中提的 TCC 原理是一致的。不同的是，我们在整个分布式事务执行过程中，会去记录事务日志，一个分布式事务会产生一条主事务记录（对应发起方）和若干分支事务记录（对应 TCC 参与者）。记录事务日志的目的是，当分布式事务执行过程中出现异常中断时，事务恢复服务通过轮询事务日志，找出这个异常中断的事务，补偿执行该异常事务剩余未完成的动作，整个分布式事务的最终状态要么全部提交，要么全部回滚。\nTCC 设计规范和注意事项：\n用户在接入 TCC 时，大部分工作都集中在如何实现 TCC 服务上。经过蚂蚁金服多年的 TCC 应用实践，总结如下在 TCC 设计和实现过程中的注意事项：\n1、业务操作分两阶段完成： 接入 TCC 前，业务操作只需要一步就能完成。但是在接入 TCC 之后，需要考虑如何将其分成两个阶段完成：把资源的检查和预留放在一阶段的 Try 操作中进行，把真正的业务操作的执行放在二阶段的 Confirm 操作中进行。\n以下举例说明业务模式如何分成两阶段进行设计，举例场景：“账户 A 的余额中有 100 元，需要扣除其中 30 元”。\n在接入 TCC 之前，用户编写 SQL：“update 账户表 set 余额 = 余额 -20 where 账户 = A”，便能一步完成扣款操作。\n在接入 TCC 之后，就需要考虑如何将扣款操作分成两步完成：\n Try 操作：资源的检查和预留。  在扣款场景，Try 操作要做的事情就是先检查 A 账户余额是否足够，再冻结要扣款的 30 元（预留资源）；此阶段不会发生真正的扣款。\n Confirm 操作：执行真正业务的提交。  在扣款场景下，Confirm 阶段做的事情 …","date":1526465554,"description":"上周，分布式事务 Fescar 宣布进行品牌升级：Thanks, Fescar ❤️，Hello, Seata 🚀。","dir":"blog/seata-distributed-transaction-open-source/","fuzzywordcount":5000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"acb90bbbf0e7ec7dfb8c797bbd94efee","permalink":"/blog/seata-distributed-transaction-open-source/","publishdate":"2018-05-16T10:12:34Z","readingtime":10,"relpermalink":"/blog/seata-distributed-transaction-open-source/","summary":"上周，分布式事务 Fescar 宣布进行品牌升级：Thanks, Fescar ❤️，Hello, Seata 🚀。 Seata 意为：Simple Extensible Autonomous Transaction Architecture，是一套一站式","tags":["Seata"],"title":"蚂蚁金服分布式事务开源以及实践 | SOFA 开源一周年献礼","type":"blog","url":"/blog/seata-distributed-transaction-open-source/","wordcount":4977},{"author":"鲁直","categories":"SOFABoot","content":"SOFABoot 是蚂蚁金服中间件团队开源的基于 Spring Boot 的一个开发框架，其在 Spring Boot 的健康检查的基础上，加上了 Readiness Check 的能力，以更好地适应大规模金融级的服务化场景，防止在应用启动有问题的情况下让外部流量进入应用。在本文中，我们将通过 Kubernetes 来演示 SOFABoot 的 Readiness Check 的能力，主要涉及到两个部分的能力的演示：\n SOFABoot 的 Readiness Check 失败之后，SOFABoot 不会将发布的 RPC 服务的地址注册到 ZooKeeper 上面，防止 RPC 的流量进入。 Kubernetes 通过 http://localhost:8080/health/readiness 访问到 SOFABoot 的 Readiness 检查的结果之后，不会将 Pod 挂到对应的 Service 之上，防止 Kubernetes 上的流量进入。  准备一个 Kubernetes 的环境 为了演示在 Kubernetes 中使用 SOFABoot 的 Readiness Check 的能力，首先需要准备好一个 Kubernetes 的环境，在这个例子中，我们直接选择在本机安装一个 minikube，minikube 是 Kubernetes 为了方便研发人员在自己的研发机器上尝试 Kubernetes 而准备的一个工具，对于学习 Kubernetes 的使用非常方便。关于如何在本机安装 minikube，大家参考这个官方的安装教程即可。\n安装完成以后，大家可以直接终端中使用 minikube start来启动 minikube。\n需要注意的是，由于国内网络环境的问题，直接用 minikube start可能会无法启动 minikube，如果遇到无法启动 minikube 的问题，可以尝试加上代理的设置，大家可以参考以下的命令来设置代理服务器的地址：minikube start --docker-env HTTP_PROXY=http://xxx.xxx.xxx.xxx:6152 --docker-env HTTPS_PROXY=http://xxx.xxx.xxx.xxx:6152 在 Kubernetes 上安装一个 ZooKeeper 在准备好了 Kubernetes 的环境之后，我们接下来需要在 Kubernetes 上安装一个 ZooKeeper 作为 SOFARPC 的服务自动发现的组件。首先我们需要有一个 ZooKeeper 的 Deployment：\napiVersion: apps/v1beta1 kind: Deployment metadata: name: zookeeper-deployment labels: app: zookeeper spec: replicas: 1 selector: matchLabels: app: zookeeper template: metadata: labels: app: zookeeper spec: containers: - name: zookeeper image: zookeeper imagePullPolicy: IfNotPresent ports: - containerPort: 2181 这个 Deployment 会部署一个 ZooKeeper 的实例，并且将 2181 端口暴露出来。\n有了这个 YAML 文件之后，我们再部署一个 Service 来作为 ZooKeeper 的负载均衡，这样我们在应用中就可以直接通过域名来访问，而不用 IP 来访问 ZooKeeper 了。这个 Service 的 Yaml 文件如下：\napiVersion: v1 kind: Service metadata: name: zookeeper-service spec: selector: app: zookeeper ports: - protocol: TCP port: 2181 targetPort: 2181 这个 Service 直接将 2181 端口映射到 ZooKeeper 的 2181 端口上，这样，我们就可以在应用中直接通过 zookeeper-service:2181 来访问了。\n准备一个 SOFABoot 的应用 在前面的两步都 OK 之后，我们需要准备好一个 SOFABoot 的应用，并且在这个应用中发布一个 SOFARPC 的服务。首先，我们需要从 start.spring.io 上生成一个工程，例如 GroupId 设置为 com.alipay.sofa，ArtifactId 设置为 rpcserver。生成好了之后，接下来，我们需要把 SOFABoot 的依赖加上，将 pom.xml 中的 parent 修改成：\u0026amp;lt;parent\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofaboot-dependencies\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.3.1\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/parent\u0026amp;gt; 然后，增加一个 SOFARPC 的 Starter 的依赖：\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;rpc-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 接着，在 application.properties 里面加上我们的配置，包括应用名和 ZooKeeper 的地址：\n# Application Name spring.application.name=SOFABoot Demo # ZooKeeper 的地址 com.alipay.sofa.rpc.registry.address=zookeeper://127.0.0.1:2181 上面的事情准备好之后，我们可以在应用中发布一个服务，首先，我们需要分别声明好一个接口和一个实现：\npackage com.alipay.sofa.rpcserver; public interface SampleService { String hello(); } package com.alipay.sofa.rpcserver; public class SampleServiceImpl implements SampleService { @Override public String hello() { return \u0026amp;#34;Hello\u0026amp;#34;; } } 接下来，将这个接口和实现发布成一个 SOFARPC 的服务，我们可以新建一个 src/main/resources/spring/rpc-server.xml 的文件：\n\u0026amp;lt;?xml …","date":1525428754,"description":"在本文中，我们将通过 Kubernetes 来演示 SOFABoot 的 Readiness Check 的能力。","dir":"blog/sofa-boot-readiness-check-in-kubernetes/","fuzzywordcount":2800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"4018d6494df0e7ecde1c4911610fc89c","permalink":"/blog/sofa-boot-readiness-check-in-kubernetes/","publishdate":"2018-05-04T10:12:34Z","readingtime":6,"relpermalink":"/blog/sofa-boot-readiness-check-in-kubernetes/","summary":"SOFABoot 是蚂蚁金服中间件团队开源的基于 Spring Boot 的一个开发框架，其在 Spring Boot 的健康检查的基础上，加上了 Readiness Check 的能力，以更好地适应大规模金融级的服务化场景，防止","tags":["SOFABoot","Kubernetes"],"title":"在 Kubernetes 中使用 SOFABoot 的 Readiness Check 能力","type":"blog","url":"/blog/sofa-boot-readiness-check-in-kubernetes/","wordcount":2756},{"author":"余淮","categories":"SOFARPC","content":"SOFARPC 是近期蚂蚁金服开源的一个高可扩展性、高性能、生产级的 Java RPC 框架。在蚂蚁金服 SOFARPC 已经经历了十多年及五代版本的发展。SOFARPC 致力于简化应用之间的 RPC 调用，为应用提供方便透明、稳定高效的点对点远程服务调用方案。为了用户和开发者方便的进行功能扩展，SOFARPC 提供了丰富的模型抽象和可扩展接口，包括过滤器、路由、负载均衡等等。\nSOFARPC 可以集成多种注册中心实现，其中一种就是常用的 ZooKeeper。\nZooKeeper 作为一个开源的分布式应用协调系统，已经用到了许多分布式项目中，用来完成统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等工作。\n本文将介绍 SOFARPC 是使用 ZooKeeper 作为注册中心的用法。\n1. ZooKeeper 注册中心安装 这里介绍下 Zookeeper 单机模式两种安装方式，集群模式请参考下其他文档。\n1.1 基于压缩包安装 第一步：去官网下载 http://zookeeper.apache.org/releases.html#download 例如目前最新版是 v3.4.11，我们下载压缩包zookeeper-3.4.11.tar.gz，然后解压到文件夹下，例如 /home/admin/zookeeper-3.4.11。\n第二步：设置配置文件，可以直接从样例复制一份。\n$ cd /home/admin/zookeeper-3.4.11 $ cp conf/zoo_sample.cfg conf/zoo.cfg 第三步：到 Zookeeper 安装目录下直接启动Zookeeper。\n$ cd /home/admin/zookeeper-3.4.11 $ sh bin/zkServer.sh start ZooKeeper JMX enabled by default Using config: /Users/zhanggeng/dev/zookeeper/bin/../conf/zoo.cfg -n Starting zookeeper ... STARTED 第四步：我们使用四字命令检查下。\n$ echo stat | nc 127.0.0.1 2181 Zookeeper version: 3.4.11-37e277162d567b55a07d1755f0b31c32e93c01a0, built on 11/01/2017 18:06 GMT ... 第五步：如果需要查看数据，直接运行 zkCli.sh，连接后执行 ls /即可。\n$ sh bin/zkCli.sh Connecting to localhost:2181 ...... WatchedEvent state:SyncConnected type:None path:null [zk: localhost:2181(CONNECTED) 0] ls / [zookeeper] 1.2 基于 Docker 安装 如果您已安装了 Docker，那么可以选择使用镜像启动 Zookeeper。\n$ docker image pull zookeeper:3.4.11 $ docker run -i -t --name my_zookeeper -p2181:2181 -d zookeeper:3.4.11 我们查看下启动日志：\n$ docker logs -f my_zookeeper ZooKeeper JMX enabled by default Using config: /conf/zoo.cfg 2018-04-16 07:38:59,373 [myid:] - INFO [main:QuorumPeerConfig@136] - Reading configuration from: /conf/zoo.cfg ...... 2018-04-16 07:23:41,187 [myid:] - INFO [main:NIOServerCnxnFactory@89] - binding to port 0.0.0.0/0.0.0.0:2181 可以看到端口已经启动并发布，我们使用四字命令检查下。\n$ echo stat | nc 127.0.0.1 2181 Zookeeper version: 3.4.11-37e277162d567b55a07d1755f0b31c32e93c01a0, built on 11/01/2017 18:06 GMT ... 我们可以查看启动的容器运行状态、关闭、重启，参考命令如下：\n$ docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 30b13a744254 zookeeper:3.4.11 \u0026amp;#34;/docker-entrypoin...\u0026amp;#34; 23 hours ago Up 42 seconds 2888/tcp, 0.0.0.0:2181-\u0026amp;gt;2181/tcp, 3888/tcp my_zookeeper ## 关闭重启的话 $ docker container stop 30b13a744254 $ docker container start 30b13a744254 如果需要使用 ZooKeeper 客户端查看查看数据，参考命令如下：\n$ docker exec -it 30b13a744254 zkCli.sh Connecting to localhost:2181 ...... WatchedEvent state:SyncConnected type:None path:null [zk: localhost:2181(CONNECTED) 0] ls / [zookeeper] 2. SOFARPC 集成 Zookeeper 注册中心 Demo 工程参见: sofa-rpc-zookeeper-demo\n2.1 新建工程 运行需要 JDK 6 及以上、 Maven 3.2.5 以上。\n首先我们在 IDE 里新建一个普通 Maven 工程，然后在 pom.xml 中引入如下 RPC 和 Zookeeper 相关依赖：\n\u0026amp;lt;dependencies\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-rpc-all\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;5.3.1\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.apache.curator\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;curator-recipes\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.9.1\u0026amp;lt;/version\u0026amp;gt; …","date":1524737554,"description":"本文是 SOFARPC 集成 Zookeeper 的介绍。","dir":"blog/sofa-rpc-zookeeper-integriation/","fuzzywordcount":2400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"34d9ac266c4b2a95cc924705212d2eb0","permalink":"/blog/sofa-rpc-zookeeper-integriation/","publishdate":"2018-04-26T10:12:34Z","readingtime":5,"relpermalink":"/blog/sofa-rpc-zookeeper-integriation/","summary":"SOFARPC 是近期蚂蚁金服开源的一个高可扩展性、高性能、生产级的 Java RPC 框架。在蚂蚁金服 SOFARPC 已经经历了十多年及五代版本的发展。SOFARPC 致力于简化应用之","tags":["SOFARPC"],"title":"SOFARPC 集成 Zookeeper 注册中心","type":"blog","url":"/blog/sofa-rpc-zookeeper-integriation/","wordcount":2367},{"author":"蚂蚁中间件","categories":"SOFAStack","content":"我们很高兴地宣布，今天蚂蚁金服启动分布式中间件（Scalable Open Financial Architecture，以下简称 SOFA 中间件）的开源计划！\nSOFA 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics监控度量，分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，是一套分布式架构的完整的解决方案，也是在金融场景里锤炼出来的最佳实践。\n蚂蚁金服期望通过逐步向社区开源 SOFA 中各个组件，来帮助更多机构和合作伙伴完成金融分布式转型，帮助大家更加快速构建稳定的金融级云原生的架构，也期望 SOFA 在蚂蚁体系之外的更大场景下去应用，来进一步锻造改进这套体系，使其更加完善和稳固，并具备更多金融级的属性。所以我们也非常欢迎社区的伙伴和各行业的伙伴能够参与共同探讨、交流和共建。\nWhy（为什么要做） SOFA 中间件在蚂蚁内部经历了十年的发展和四代架构的演进，被广泛应用在包括支付，借贷，信用，基金，保险等全金融场景，支撑着蚂蚁平稳度过历次双十一，双十二，新春红包等大考，创造了25.6 w/s 的交易记录，并还在不断刷新这个记录。\n从 2015 年开始，蚂蚁金服开启了金融科技对外输出的战略，SOFA 也走出了蚂蚁，甚至跨越了国界，被更多金融机构与合作伙伴所使用，如天弘基金，信美互信，南京银行，PayTM、DANA钱包等。\n在与合作伙伴以及客户的沟通、合作过程中，我们发现了 SOFA 的理念和能力也正是很多金融行业的企业所需要的，大家或多或少正在规划或者已经在做类似的东西，但缺乏像蚂蚁金服这么大的流量来提供考验，也缺乏专业团队的长期投入，更缺乏丰富的金融场景和严苛的业务压力来驱动技术持续发展。\n随着近几年蚂蚁金服在生态构建上不断完善，以及不断地有更多的公司加入到蚂蚁金服的金融生态中，我们也发现了整个金融生态地复杂性和多样性，SOFA 中间件也需要在更多地场景下被打磨、被完善、被增强。因此，我们选择将 SOFA 逐步开源出来，在贡献给社区的同时，也期待社区、合作伙伴甚至客户，都能够一起参与共建，形成行业标准和最佳实践。\nHow（怎么做） 为了让 SOFA 能够开源出来，我们投入了大量的重构工作，以可扩展化的方式来层层构建 SOFA 的能力，保证 SOFA 的内部版本和开源的版本采用的是同一个内核。所以 SOFA 的内部版本就是在开源版本之上扩展了内部逻辑和历史版本的兼容逻辑。开源版本的核心逻辑，内外是一致的，并在蚂蚁金服的生产环境中被广泛使用的，同时会随着蚂蚁自身业务诉求的驱动，不断的演进。\n开源社区有非常多优秀的技术和丰富的生态，为了更好的能融入和对接现有技术体系，尊重并遵守一些社区标准，SOFA 在设计过程中就充分考虑了兼容性和架构分层，充分兼容适配社区标准，实现组件化、可扩展、可替换。\n所有的 SOFA 中间件中的组件组合起来可以发挥更大的能力，但是每一个组件都是可以被替换的，比如用户可以选择用 Dubbo 来替换 SOFARPC，或者跟 SOFARPC 对接互通；可以选择 Zookeeper 来作为服务注册发现，也可以选择 SOFA 的服务注册中心来做服务发现；分布式链路追踪组件遵守 OpenTracing 的规范，可以直接和 Zipkin 进行对接等等；Metrics组件会遵循 Metrics2.0 标准，适配 Prometheus 体系等等。\nWhat（要做什么） 本次 SOFA 中间件开源的内容包含了 SOFABoot 和 SOFARPC 两个组件。\nSOFABoot 是蚂蚁金服基于 Spring Boot 构建一个研发框架，整体架构上类似于蚂蚁金服之前开源的Egg框架，遵守微内核，可插拔的理念，我们以标准 Spring Boot Starter的方式，扩展了很多企业级特性，以解决大规模团队开发云原生微服务系统中会遇到的问题，如类隔离，ReadinessCheck，日志隔离等等能力，后续会开放更多内部实践过的特性，如 Spring 上下文隔离，合并部署，动态模块，Tracing、Metrics、Streaming、测试框架等。\n同时，蚂蚁的很多技术团队和阿里的技术团队也开放了很多类库和组件，我们都会提供原生的集成能力和 Demo，方便大家更好的整合使用。SOFABoot 100% 兼容 Spring Boot，和 Spring Boot 并非是替代的关系，所有 Spring Boot 中的能力也都可以在 SOFABoot 中使用。\nSOFABoot 的 Github 的地址是：https://github.com/sofastack/sofa-boot ，欢迎大家使用反馈、贡献代码。\nSOFARPC 是一个高效，可靠，可扩展的 RPC 的框架，是蚂蚁金服服务化架构的基石。SOFARPC 最早源于阿里内部的 HSF，经过了蚂蚁金服内部多年的发展，在协议，网络，路由，可扩展性等层面都进行了大量的改造和优化的工作，适配了更多金融级的场景。\nSOFARPC 在蚂蚁金服内部是被所有在线应用的使用的服务调用框架，截止 2017 年双十一，SOFARPC 已经被蚂蚁 2000 多个系统所使用，生产环境发布的服务数量超过了 23000 个。\nSOFARPC 提供了多协议的支持，包括在蚂蚁金服内部被广泛采用，并且高度优化的 Bolt 协议，以及 REST，Dubbo，gRPC 等等主流的协议；也针对内部网关，测试等等场景提供了泛化调用能力；为了解决超大规模流量的预热的问题，提供了服务预热的能力；用户也可以根据 SOFARPC 的扩展机制扩展自己需要的能力。\n在后续的版本中，SOFARPC 将会加上分布式链路追踪，Metrics，更多的服务注册中心的支持，CRC 校验等等能力。\nSOFARPC 的 Github 的地址是：https://github.com/sofastack/sofa-rpc ，欢迎大家使用反馈、贡献代码。\n除了以上的两个 SOFA 中间件中的组件，在接下来，我们将会陆续开源 SOFA 中间件中的其他的组件，目前这些组件正在进行一定程度地重构中，为开源做准备，敬请大家期待~\n附本文中提到的链接：\n Egg：http://eggjs.org SOFABoot：https://github.com/sofastack/sofa-boot SOFARPC：https://github.com/sofastack/sofa-rpc SOFABolt：https://github.com/sofastack/sofa-bolt  彩蛋 最后，我们也为对 SOFA 中间件感兴趣的小伙伴们准备了一个微信交流群，欢迎感兴趣的同学扫描下方二维码联系加群小助手加入我们 SOFA 交流群哦。👇\n","date":1524147739,"description":"我们很高兴地宣布，今天蚂蚁金服启动分布式中间件（Scalable Open Financial Architecture，以下简称 SOFA 中间件）的开源计划！","dir":"blog/announcing-sofastack-open-source/","fuzzywordcount":2500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"6019b0e0f6e4c9569640bcdb51b5a157","permalink":"/blog/announcing-sofastack-open-source/","publishdate":"2018-04-19T14:22:19Z","readingtime":5,"relpermalink":"/blog/announcing-sofastack-open-source/","summary":"我们很高兴地宣布，今天蚂蚁金服启动分布式中间件（Scalable Open Financial Architecture，以下简称 SOFA 中间件）的开源计划！ SOFA 是蚂蚁金服自主","tags":["开源"],"title":"蚂蚁金服启动分布式中间件开源计划，用于快速构建金融级云原生架构","type":"blog","url":"/blog/announcing-sofastack-open-source/","wordcount":2479},{"author":"程立","categories":"SOFAStack","content":"声明：本文发表于《金融电子化杂志》2016年12期，经授权转发，系作者原创，经谢绝个人、媒体、公众号或网站未经授权转载，违者追究其法律责任。\n移动互联网、大数据与云计算作为新的基础设施，催生了新的互联网经济，也正在推动各行各业的升级。在过去十多年中，金融服务飞速发展，移动支付支撑了零售业线上线下的变革，基于大数据的信贷服务支持了无数小微企业的创业创新，老百姓可以随时随地享受曾经高门槛的理财、保险等金融服务。以普惠服务为目标、数据与技术驱动、新型信用体系为基础的新金融已经成为新经济的基石。\n伴随着蚂蚁金服在新金融领域的探索，蚂蚁金服技术团队也在金融技术与架构领域不断开拓。从 2005 年每秒处理 1 笔交易到 2015 年双十一每秒处理 8.59 万笔交易，从单一的支付到覆盖微贷、理财、保险、信用、银行等，通过十多年的探索与实践，我们形成了一套包含金融级分布式交易、分布式大数据分析与决策等在内的完整架构与技术体系。\n在本文中，我们将与大家交流金融级分布式交易相关的实践与体会。\n金融级系统的关键目标 如果将建造系统比作盖楼的话，建一个常规的系统要先立稳四根柱子：高可用、安全、性能、成本。但要建一个移动互联网时代的金融级大厦，除了上述四根柱子需要更加牢固，还需要加上两根柱子：资金安全与数据质量。这六根柱子，是我们在架构蚂蚁金服的每一个系统时的首要目标。\n具体来说，我们对一个金融级系统有以下关键目标：\n高可用：具备 99.99% 以上的高可用性。系统能够容忍各种软硬件设施的故障，可以在服务不中断的情况下进行升级，在严苛的应用场景下保证承诺的服务质量，容忍各种人为失误。对于关键系统，还需要具备异地容灾能力。\n安全：具备多层次检测、感知与防御各类安全攻击的能力。系统有能力实时、精细地分析系统行为与数据流发现异常，必要时可以快速调集资源阻断大规模、有组织的攻击。\n性能：对于实时交易业务，要求极快的响应时间与极高并发能力。对于批量业务，要求极大的吞吐量。尤其重要的是，系统必须具备很强的可伸缩性与弹性，在需要时可以快速调集资源应对突发的业务量。\n成本：在满足高可用、安全与性能的前提下，成本是一个重要约束。我们将单笔交易的平均处理成本（月交易总笔数/月成本）、以及峰值交易的处理成本（每提升 1000 交易 TPS 需要追加的成本）作为两个关键指标去持续优化。除了必须在基础软硬件与系统关键链路上做极致的优化外，灵活的资源调度与按需伸缩能力是优化成本的关键。\n资金安全：这是金融级系统与常规系统的一个关键差异。要做到资金处理绝对不出差错，需要交易与数据具备强一致性，需要在任何故障场景数据不丢不错，需要具备准实时的交易资金核对能力，需要在异常场景下有精细化熔断与快速恢复能力。\n数据质量：数据质量是金融服务质量的基础。数据从采集、生成、流转、存储、计算、使用需要经历很多环节，要确保经过这么多环节后，数据依然是准确、完整和及时的，需要系统具备全链路的数据质量管控与治理能力。\n金融交易系统是否可以走分布式路线？如何基于分布式的思想与技术达到以上 6 个关键目标？接下来，我们就以蚂蚁金服的实践为基础，分享对这个问题的观点。\n分布式金融交易架构与技术 1 强一致的微服务：微交易架构 微服务是一种广泛应用的分布式架构。通过将系统分解为单一职责、高内聚、松耦合、独立部署、自主运行的“微“服务，可以极大提升系统的灵活性与扩展能力。但由于每一个微服务是自包含的数据与计算单元，当一个有严格一致性要求的交易，被分布在很多节点上执行时，如何保证数据与服务处理达到金融级的强一致性，成为一个难题。尽管可以用支持分布式事务的数据库或数据中间件来保证数据分布时的一致性，但解决不了当服务分布时的一致性问题。由于分布式事务对资源加锁的时间长、粒度大，也制约了系统的可伸缩性与高可用性。\n为了解决这个难题，我们提出一种使微服务具备强一致性的微交易架构。在这种架构中，涉及到交易操作的微服务具备事务属性。一个微交易提供三种操作TCC（Try-Confirm-Cancel），其中 Try 操作负责业务检查与资源预留，Confirm 操作负责实际操作，Cancel 操作负责释放预留的资源。一次完整的交易由一系列微交易的 Try 操作组成，如果所有的 Try 操作都成功，最终由微交易框架来统一Confirm，否则统一 Cancel，从而实现了类似经典两阶段提交协议（2PC）的强一致性。但不同于 2PC，微交易架构力求高效与可伸缩。TCC 三个操作都是基于本地事务的短事务，Try 操作只预留必须的业务资源，比如一笔交易涉及10元钱，仅预留账户中的 10 元钱，而不是锁定整个账户，TCC 协议在提交时，也没有单独的 Prepare 阶段，将提交协议的成本降到最低。\n从 2008 年初上线至今，微交易架构已经应用到蚂蚁金服的各种金融业务场景，经历过历次大促高峰考验，证明这套架构与技术的可行性。\n2 金融级分布式数据库: OceanBase 目前，主要商业数据库本质上是单机系统，其容量、性能和可靠性均依赖于单个或少量高性能服务器与高可靠存储的组合，成本高昂且扩展困难。尽管通过运用微交易架构，可以将对数据操作的压力分拆多个数据库，解决了水平可扩展的问题，但数据库本身的性能、成本与可靠性依然是一个难点。因此，阿里巴巴与蚂蚁金服从 2010 年起，开始研发专门的金融级分布式数据库 OceanBase。\nOceanBase 在以下几个方面，对传统数据库架构进行了突破：\n高性能：数据库的一个显著特征是总数量比较大，但每天变化(增删改)的数据只是总数据量的很小一部分。因此 OceanBase 将数据划分为基线数据和修改增量。基线数据即数据库在某个时间点的一个快照，存放在每台 OceanBase 服务器的硬盘中，修改增量即快照点之后的增删改数据，相对比较小，通常存放在每台 OceanBase 服务器的内存中。通过这种方式，使得增删改操作基本都在内存中进行，从而获得接近内存数据库的事务处理性能；\n强一致：经典的主库+备库方式的数据库，很难兼具高可用与强一致能力。为了解决这个问题，OceanBase 使用多数据副本（\u0026amp;gt;=3）投票协议，对于每个写事务，OceanBase 只有在事务日志（redo log）到达超过半数服务器后，才应答客户。这样当少数服务器（例如 3 台中的 1 台，或者 5 台中的 2 台）异常时，剩下的服务器至少有一台有事务日志，保证了数据库不因为少数服务器故障而导致数据丢失；\n高可用：关键业务的数据库必须达到 99.999% 的可用性，服务器故障、机房或网络故障都不能导致数据库不可用。OceanBase 通常由分布于多个机房（3 个或以上）的机群组成，每个机群有完整数据，其中一个机群作为主库对外提供读写服务，其余机群作为备库，接收主库的事务日志和回放日志。当主库故障时，剩下的机群会立刻自动发起投票选举，选出新的主库，新主库从其他机群获得可能存在的最新事务日志并回放，完成后对外提供服务。\n目前 OceanBase 已经稳定支撑了支付宝的核心交易、支付与账务，支撑了网商银行的核心系统，经历了多次“双十一”的考验，形成了跨机房、跨区域部署的高可用架构，并在日常运行、应急演 …","date":1520578800,"description":"本文发表于《金融电子化杂志》2016年12期，经授权转发，系作者原创。","dir":"blog/technical-financial-distributed-trading/","fuzzywordcount":4900,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"e6da780e4d5f611c48ac55795531fb2c","permalink":"/blog/technical-financial-distributed-trading/","publishdate":"2018-03-09T15:00:00+08:00","readingtime":10,"relpermalink":"/blog/technical-financial-distributed-trading/","summary":"声明：本文发表于《金融电子化杂志》2016年12期，经授权转发，系作者原创，经谢绝个人、媒体、公众号或网站未经授权转载，违者追究其法律责任。","tags":["SOFAStack"],"title":"金融级分布式交易的技术路径","type":"blog","url":"/blog/technical-financial-distributed-trading/","wordcount":4822},{"author":null,"categories":null,"content":"Novel features: Replicated state machines 1. Replicated state machines are implemented based on logs.  Each server stores a log. Each log entry contains a command. The state machine executes commands in order.  2. Consensus algorithms for practical systems typically have the following properties:  They ensure safety. They are highly available. They do not depend on the time sequence to ensure log consistency. A command can be completed as soon as a majority of the cluster has responded to a single round of remote procedure calls (RPCs).  Drawbacks of Paxos  Paxos is exceptionally difficult to understand. Paxos does not provide a good foundation for building practical implementations.  Raft design principles  Concept decomposition  Leader election Log replication Membership changes   Raft reduces the number of states to simplify the state space.  Raft does not allow log holes and restricts the possibilities of log inconsistency. Raft uses randomized timers to simplify the leader election.    Raft consistency algorithm State  Persistent state on all servers (updated on stable storage before responding to RPCs):\n   currentTerm The latest term that the server gets (initialized to 0 on initial boot, increasing monotonically)     votedFor The candidateId that has received votes in the current term (or null if none).   Log[] Log entries. Each entry contains a command for the state machine, and the term when the entry was received by the leader.    Volatile state on all servers:\n   commitIndex The index of the highest log entry known to be committed.     lastApplied The index of the highest log entry applied to the state machine.    Volatile state on leaders:\n   nextIndex[] The index of the next log entry to be sent to each follower.     matchIndex[] The index of the highest log entry known to have been replicated on each follower.    AppendEntries RPC (log replication) Called by the leader to replicate log entries or used as heartbeats.\n Arguments:\n   term leader\u0026amp;rsquo;s term     leaderId The leader\u0026amp;rsquo;s ID that can be used to redirect clients to the leader.   prevLogIndex The index of the preceding log entry.   prevLogTerm The term of the prevLogIndex entry.   entries[] The log entries to be stored (empty for heartbeat, and the leader may send more than one for efficiency).   leaderCommit The leader\u0026amp;rsquo;s commitIndex (for committed log entries).    Results:\n   term The currentTerm for the leader to update.     success True if the follower contains log entries matching prevLogIndex and prevLogTerm.    Receiver implementation:\n Reject the log entry and return false if term \u0026amp;lt; currentTerm. Reject the log entry and return false if the log does not contain an entry at prevLogIndex whose term matches prevLogTerm. If an existing entry conflicts with a new one (same index but different terms), delete the existing entry and all that follow it. Append any new entries that do not exist in the log. If leaderCommit \u0026amp;gt; commitIndex, set commitIndex = …","date":-62135596800,"description":"","dir":"projects/sofa-jraft/raft-introduction/","fuzzywordcount":2500,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"b811e803d23b40da67657798801f8b51","permalink":"/en/projects/sofa-jraft/raft-introduction/","publishdate":"0001-01-01T00:00:00Z","readingtime":12,"relpermalink":"/en/projects/sofa-jraft/raft-introduction/","summary":"Novel features: Replicated state machines 1. Replicated state machines are implemented based on logs.  Each server stores a log. Each log entry contains a command. The state machine executes commands in order.  2. Consensus algorithms for practical systems typically have the following properties:  They ensure safety. They are highly available. They do not depend on the time sequence to ensure log consistency. A command can be completed as soon as a majority of the cluster has responded to a single round of remote procedure calls (RPCs).","tags":null,"title":"'Introduction to the Raft algorithm'","type":"projects","url":"/en/projects/sofa-jraft/raft-introduction/","wordcount":2499},{"author":null,"categories":null,"content":"Open ACTS IDE In the Packages view, right click the function name annotated by @Test, and choose ACTS Function \u0026amp;gt; Edit Test Case as shown in the following figure.\nWrite test data Prepare request parameters Prepare correct request parameter data for the request parameters (type, order, and quantity) of the tested method. The parameters are divided into simple and complex types. Simple parameters include parameter types String, Date, Integer, Float, Double, Long, Short, and Byte (including their corresponding basic types, such as int and float). Complex parameters include parameter types List, Map, Set, custom class, Java defined class, and their nested expressions.\nSimple request parameters Right click Request Parameters, choose Select Model, and click Simple Type in the pop-up to select simple parameters.\nAfter importing simple request parameters, enter their values directly in the field as shown in the preceding figure. Parameters listed top down are the first, second, and third parameters of the tested method. You can right click a parameter to adjust its order.\nComplex parameters As shown in Figure 27, you need to generate request parameter models for the AccountTransRequest class and the BusinessActionContext class. Generally, class models of the tested method\u0026amp;rsquo;s request parameters and responses are automatically generated along with the test script. You can open ACTS IDE to edit class models of request parameters as shown in Figure 28.\nList Map See example 2 (the Set type is similar). In Figure 32, request parameters of the method shown in sample 2 is the Map\u0026amp;lt;String, Object\u0026amp;gt; type. Objects do not belong to a specific type. If you want to set an object as a complex one, edit the YAML file. For example, if you want to set an object as the AccountTransResult class, edit the YAML file as follows:\nenum Example code:\n You can edit the values in ACTS IDE as follows:   If an enum type class is nested in another class, set the value of the enum type to DEBIT in the CSV model of the class.\n  Figure 37 shows the test case data in the YAML file.\n  interestRecoverTypeEnum: !!com.alipay.fc.loancore.common.util.enums.InterestRecoverTypeEnum \u0026amp;#39;ALL\u0026amp;#39; You can override the prepare method, and use the ActsRuntimeContext method to quickly get and set test case request parameters. See Figure 38.\n Get all request parameters: List getInputParams() Get request parameters by position: Object getInputParamByPos(int i) Add request parameters for the test case: void addInputParam(Object obj)  Prepare database data - single column database As shown in Figure 39, right click Database Preparation, select the desired database model for insertion (ensure that this database model has been generated). The database preparation model is inserted when you click OK after performing steps 1 and 2. As shown in Figure 41, you can edit the data to be inserted into the database.\nSelect a column and click Copy. You can use this method to copy multiple columns and then …","date":-62135596800,"description":"","dir":"projects/sofa-acts/usage-ide/","fuzzywordcount":1500,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"697e7e6d35a2e058f3ca8b0a72032690","permalink":"/en/projects/sofa-acts/usage-ide/","publishdate":"0001-01-01T00:00:00Z","readingtime":7,"relpermalink":"/en/projects/sofa-acts/usage-ide/","summary":"Open ACTS IDE In the Packages view, right click the function name annotated by @Test, and choose ACTS Function \u0026gt; Edit Test Case as shown in the following figure.\nWrite test data Prepare request parameters Prepare correct request parameter data for the request parameters (type, order, and quantity) of the tested method. The parameters are divided into simple and complex types. Simple parameters include parameter types String, Date, Integer, Float, Double, Long, Short, and Byte (including their corresponding basic types, such as int and float).","tags":null,"title":"All-in-one editor","type":"projects","url":"/en/projects/sofa-acts/usage-ide/","wordcount":1489},{"author":null,"categories":null,"content":"Introduction To understand the usage mode of Jarslink2.0, you need to have a certain understanding of the SOFAArk framework and the packaging of Ark packages and Ark Biz packages.\nTo ensure the consistency of reading, here is a rough description of the packaging logic of the application\u0026amp;rsquo;s use of Jarslink2.0. The official recommendation is to jump to the above-mentioned link to obtain the necessary background knowledge.\nJarslink2.0 requires an application type of Spring Boot or SOFABoot. Before introducing new modes of application packaging, let\u0026amp;rsquo;s see why it is necessary for Spring Boot/SOFABoot applications to introduce new packaging modes after using Jarslink2.0.\nBackground At runtime, Jarslink2.0 works as an Ark Plugin of the SOFAArk framework, which must be introduced for the use of Jarslink2.0. The Jarslink2.0 plugin will not be loaded and started until the SOFAArk container is started. As we know, when official Spring Boot projects use plugins:\n\u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/plugin\u0026amp;gt; An executable FatJar will be packaged, which contains all the dependencies, configurations, and other resources required by the running application. The FatJar entry method is the main method of the Spring Boot application. The packaging logic of a SOFABoot project is the same as that of a Spring Boot project.\nAfter the application introduces Jarslink2.0, which needs to depend on the SOFAArk framework, the FatJar that is packaged by a new packaging mode needs to contain a SOFAArk container. The FatJar entry method also needs to be replaced by the SOFAArk container startup method, because the startup of SOFAArk takes precedence over the execution of the FatJar. The SOFAArk container starts all the Ark Plugins in turn before finally starting the application. Therefore, a new packaging mode is needed, and SOFAArk provides a packaging plugin.\n\u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/plugin\u0026amp;gt; responsible for packaging Spring Boot/SOFABoot applications into an executable FatJar called Ark package.\nPackaging Type In the previous section, we have described why the use of Jarslink 2.0 needs to introduce a packaging mode that is different from the official Spring Boot packaging mode, and brought out the first packaging type—Ark package. Now let\u0026amp;rsquo;s summarize the features of Ark package:\n Ark package is an executable FatJar package format customized by the SOFAArk framework, the details of which are available in Reference Documents. The Ark package contains all the configurations, dependencies, and other resources required by the running application. Its packaging logic is similar to that of Spring Boot, and it also contains the Ark Plugin and the SOFAArk framework on which the application depends. The SOFAArk framework does not need to be introduced into the …","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-jarslink-jarslink-repackage/","fuzzywordcount":800,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"a9cb3c5d3fa32c5f6c476d9ed80c80cb","permalink":"/en/projects/sofa-boot/sofa-jarslink-jarslink-repackage/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/en/projects/sofa-boot/sofa-jarslink-jarslink-repackage/","summary":"Introduction To understand the usage mode of Jarslink2.0, you need to have a certain understanding of the SOFAArk framework and the packaging of Ark packages and Ark Biz packages.\nTo ensure the consistency of reading, here is a rough description of the packaging logic of the application\u0026rsquo;s use of Jarslink2.0. The official recommendation is to jump to the above-mentioned link to obtain the necessary background knowledge.\nJarslink2.0 requires an application type of Spring Boot or SOFABoot.","tags":null,"title":"Application packaging","type":"projects","url":"/en/projects/sofa-boot/sofa-jarslink-jarslink-repackage/","wordcount":749},{"author":null,"categories":null,"content":" RheaKV: an embedded, distributed, highly available, and strongly consistent KV storage class library that is implemented based on JRaft and RocksDB. AntQ Streams QCoordinator: uses JRaft to implement elections and meta information storage in the Coordinator cluster. Metadata management module of SOFARegistry: an IP address registration. The data held by all nodes must be consistent, and the normal data storage must not be affected when a minority of nodes fail. AntQ NameServer leader election  ","date":-62135596800,"description":"","dir":"projects/sofa-jraft/user-stories/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"b233be7d9eed33645945293e637e28ea","permalink":"/en/projects/sofa-jraft/user-stories/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-jraft/user-stories/","summary":"RheaKV: an embedded, distributed, highly available, and strongly consistent KV storage class library that is implemented based on JRaft and RocksDB. AntQ Streams QCoordinator: uses JRaft to implement elections and meta information storage in the Coordinator cluster. Metadata management module of SOFARegistry: an IP address registration. The data held by all nodes must be consistent, and the normal data storage must not be affected when a minority of nodes fail.","tags":null,"title":"Application scenarios","type":"projects","url":"/en/projects/sofa-jraft/user-stories/","wordcount":74},{"author":null,"categories":null,"content":"﻿## Architecture diagram Jarslink 2.0 is an Ark plugin and needs to depend on the SOFAArk container at runtime. Jarslink 2.0 is in the middle layer between the applications and the containers at runtime. Boundary interaction mode:\n   Application boundaries: Jarslink 2.0 configures export classes that can be directly used by the applications. Such classes are loaded by Jarslink at runtime.    Container boundaries: The Ark plugin can interact with the SOFAArk container by using the exposed extension points and services. Jarslink expanded the BizDeployer implementation and referenced BizManagerService and BizFactoryService container services.    Module division The implementation classes of each module appear only in their own modules and are generally not cross-dependent. Required cross-dependencies will be moved into the core module. Detailed module descriptions can be found in the following table:\n   Module name Sub-module name Description Dependency relationship     bom  Dependent on version control None   core common Common module with log classes None   core spi SPI module, defining basic interfaces and commands None   core-impl runtime Jarslink runtime management, processing commands Core   integration  Ark plugin packaging module, implementing SOFAArk container service extension point and referencing container services All    ","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-jarslink-structure/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"fa09c01de689002edbd0bea7f68fe66e","permalink":"/en/projects/sofa-boot/sofa-jarslink-structure/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-boot/sofa-jarslink-structure/","summary":"﻿## Architecture diagram Jarslink 2.0 is an Ark plugin and needs to depend on the SOFAArk container at runtime. Jarslink 2.0 is in the middle layer between the applications and the containers at runtime. Boundary interaction mode:\n   Application boundaries: Jarslink 2.0 configures export classes that can be directly used by the applications. Such classes are loaded by Jarslink at runtime.    Container boundaries: The Ark plugin can interact with the SOFAArk container by using the exposed extension points and services.","tags":null,"title":"Architecture","type":"projects","url":"/en/projects/sofa-boot/sofa-jarslink-structure/","wordcount":184},{"author":null,"categories":null,"content":"","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-ark-biz/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"d7f80ce6a00d914546e642c887d23a01","permalink":"/en/projects/sofa-boot/sofa-ark-ark-biz/","publishdate":"0001-01-01T00:00:00Z","readingtime":0,"relpermalink":"/en/projects/sofa-boot/sofa-ark-ark-biz/","summary":"","tags":null,"title":"Ark Biz","type":"projects","url":"/en/projects/sofa-boot/sofa-ark-ark-biz/","wordcount":0},{"author":null,"categories":null,"content":"简介 本小节将介绍 Ark Biz 目录结构，以及如何使用官方插件 sofa-ark-maven-plugin 打包并发布 Ark Biz。\nArk Biz 包和 Ark 包 都是使用 Maven 插件 sofa-ark-maven-plugin 打包生成；工程应用在配置该插件时，默认情况下只会打包发布 Ark 包， 只有在配置参数 attach 为 true 时，才会打包发布 Ark Biz：\n\u0026amp;lt;build\u0026amp;gt; \u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${sofa.ark.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;executions\u0026amp;gt; \u0026amp;lt;execution\u0026amp;gt; \u0026amp;lt;id\u0026amp;gt;default-cli\u0026amp;lt;/id\u0026amp;gt; \u0026amp;lt;goals\u0026amp;gt; \u0026amp;lt;goal\u0026amp;gt;repackage\u0026amp;lt;/goal\u0026amp;gt; \u0026amp;lt;/goals\u0026amp;gt; \u0026amp;lt;/excution\u0026amp;gt; \u0026amp;lt;/executions\u0026amp;gt; \u0026amp;lt;configuration\u0026amp;gt; \u0026amp;lt;attach\u0026amp;gt;false\u0026amp;lt;/attach\u0026amp;gt; \u0026amp;lt;/configuration\u0026amp;gt; \u0026amp;lt;/plugin\u0026amp;gt; \u0026amp;lt;/build\u0026amp;gt; 那 Ark Biz 和 Ark 包 有什么区别呢？ 简单来说，Ark Biz 是工程应用所有资源的组织单元，它包含了应用启动所需的所有资源，详细可参考下文描述的 Ark Biz 目录格式；而工程应用打出来的 Ark 包，是一个通过 java -jar 启动，运行在 SOFAArk 容器的 Fat Jar，不仅包含应用工程对应的 Ark Biz，也包含 Ark Container，以及应用依赖的 Ark Plugin；\n通常情况，只需要发布 Ark 包 即可，但是 SOFAArk 是支持运行多个 Ark Biz的，因此如果开发者希望自己应用的 Ark Biz 包能够被其他应用直接当成 Jar 包依赖，进而运行在同一个 SOFAArk 容器之上，那么就需要打包发布 Ark Biz 包；\nArk-Biz 典型目录结构 . ├── META-INF │ ├── MANIFEST.MF │ ├── maven │ │ └── me.qlong.tech │ │ └── sofa-boot-demo3-web │ │ ├── pom.properties │ │ └── pom.xml │ └── sofa-boot-demo3 │ └── sofa-boot-demo3-web.xml ├── com │ └── alipay │ └── sofa │ └── ark │ └── biz │ └── mark ├── config │ ├── application-dev.properties │ ├── application-test.properties │ └── application.properties ├── lib │ ├── spring-beans-4.3.4.RELEASE.jar │ ├── spring-boot-1.4.2.RELEASE.jar │ ├── spring-boot-autoconfigure-1.4.2.RELEASE.jar │ ├── spring-boot-devtools-1.4.2.RELEASE.jar │ ├── spring-boot-starter-1.4.2.RELEASE.jar │ ├── spring-boot-starter-logging-1.4.2.RELEASE.jar │ ├── spring-boot-starter-tomcat-1.4.2.RELEASE.jar │ ├── spring-boot-starter-web-1.4.2.RELEASE.jar │ ├── spring-context-4.3.4.RELEASE.jar │ ├── spring-core-4.3.4.RELEASE.jar │ ├── spring-expression-4.3.4.RELEASE.jar │ ├── spring-web-4.3.4.RELEASE.jar │ ├── ... │ ├── ... │ ├── ... │ └── velocity-1.7.jar ├── logback-spring.xml ├── me │ └── qlong │ └── tech │ └── SOFABootWebSpringApplication.class └── static └── index.html 上述目录结构相关文件和目录说明如下：\n普通的 Java 工程或者 Spring Boot Core/Web 工程都可以打包成 Ark Biz；Ark Biz 没有固定的目录格式，它只是在原来 Jar 包结构基础上新增两个目录文件：\n  com/alipay/sofa/ark/biz/mark : 标记文件，标记该 Jar 包是 sofa-ark-maven-plugin 打包生成的 Ark Biz 文件；\n  lib/ : lib 目录存放工程应用的三方依赖，\n  ","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-ark-biz/","fuzzywordcount":800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"d7f80ce6a00d914546e642c887d23a01","permalink":"/projects/sofa-boot/sofa-ark-ark-biz/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-boot/sofa-ark-ark-biz/","summary":"简介 本小节将介绍 Ark Biz 目录结构，以及如何使用官方插件 sofa-ark-maven-plugin 打包并发布 Ark Biz。 Ark Biz 包和 Ark 包 都是使用 Maven 插件 sofa-ark-maven-plugin 打包生成；工程应用在配置该插件时，默认情","tags":null,"title":"Ark Biz","type":"projects","url":"/projects/sofa-boot/sofa-ark-ark-biz/","wordcount":700},{"author":null,"categories":null,"content":"SOFAArk 合并部署时，除了宿主应用，其他 Biz 允许运行时动态部署和卸载。Biz 的状态如下：\n unresolved: 未注册，此时 Biz 包未被运行时解析 resolved: Biz 包解析完成，且已注册，此时 Biz 包还没有安装或者安装中 activated: Biz 包启动完成，且处于激活状态，可以对外提供服务 deactivated: Biz 包启动完成，但出于未激活状态，模块多个版本时，只有一个版本出于激活状态(注意这个状态只对 JVM 服务生效，对 RPC 等其他中间件无效) broken: Biz 包启动失败后状态  目前 SOFAArk 提供了三种方式操作 Biz:\n 编程 API Zookeeper 动态配置 Telnet 指令  本质上，后两种都是通过编程 API 操作 Biz，所以在这里详细描述通过编程 API 控制 Biz 的生命周期。SOFAArk 提供客户端 ArkClient 操作 Biz, 主要包含三条指令：\n install: 安装 Biz，虽然有多个重载方法，本质是接受 bizFile 文件作为入参 uninstall: 卸载 Biz，运行时 Biz 是由 bizName 和 bizVersion 唯一确定的，因此需要这两个入参 switch: 激活 Biz，SOFAArk 运行部署多个相同名称不同版本的 Biz，但是运行时只有一个 Biz 被激活（JVM 服务对外可用）；当使用 switch 指令激活其他版本时，当前处于激活状态的 Biz 将切换到钝化，同样也需要 bizName 和 bizVersion 作为入参  注意：部署相同名称不同版本 Biz 时，如果已有激活的版本，后续部署的其他版本 Biz 将自动处于钝化状态\n安装 Biz 以 Spring Boot/SOFABoot 为例，应用(模块)安装包含以下流程：\n 解析模块   SOFAArk 容器会解析文件流，读取 Biz 配置，创建 BizClassLoader 等，生成 Biz 运行时模型\n  注册模块   注册解析后的 Biz 模型，设置状态为 resolved\n  启动模块   执行 Biz 的入口方法，完成上下文的刷新，如果报错则对外抛出异常\n  健康检查   启动完成，此时 Biz 还没有切换至下一个状态，将会执行应用健康检查，健康检查参考 SOFABoot 文档，健康检查失败则抛出异常，如果应用没有引入 SOFABoot 健康检查依赖，则跳过\n  切换状态   健康检查成功，会切换 Biz 状态；如果不存在其他版本 Biz 处于激活状态，则切换状态至 Activated，否则切换状态至 DeActivated\n 注意：启动模块时抛出异常，均导致 Biz 启动失败，可以查看 sofa-ark/common-error.log 日志\n卸载 Biz 应用（模块）卸载包含以下流程：\n 切换 Biz 状态至少 deactivated   钝化 Biz, 防止流量进入正在卸载的 Biz\n  关闭 ApplicationContext   关闭 Biz 的 Spring 上下文，如果用户需要自定义卸载操作，可以监听 ContextClosedEvent 事件\n  注销 JVM 服务   SOFAArk 运行时注销 Biz 发布的 JVM 服务\n  发送卸载事件   通知所有 Ark Plugin 和 Ark Biz，正在卸载某个 Biz\n  清楚缓存   SOFAArk 运行时注销所有和该 Biz 相关的缓存\n  切换 Biz 状态为 unresolved   Biz 执行完所有卸载操作时，将状态置为 unresolved\n 卸载面临的挑战 卸载 Biz 最大的挑战在于 ClassLoader 的卸载，如果 ClassLoader 没有卸载干净，极有可能会导致 metaspace OOM. JDK 对 Class 的回收条件非常苛刻，包含：\n 该类所有实例都已经回收 加载该类的 ClassLoader 已经回收 该类对应的 java.lang.Class 对象已经没有在任何地方被引用，无法在任何地方通过反射访问该类的方法  每个 Biz 都由独立的 BizClassLoader 加载，只要该 Biz 的加载的类或对象或 ClassLoader 被其他 Biz 或 Plugin 引用，则会导致 Biz 无法卸载成功\n激活 Biz 激活指令用于设置 Biz 状态为 Activated，如果此时已有其他版本 Biz 处于激活状态，则先设置其为 Deactivated，再激活指定的 Biz 为 Activated. 激活状态是相对 JVM 服务而言，只有被激活的 Biz，其发布的 JVM 服务才能被其他 Biz 引用\n","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-biz-lifecycle/","fuzzywordcount":1200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"090ee6596c6808339fa3233139903040","permalink":"/projects/sofa-boot/sofa-ark-biz-lifecycle/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/sofa-boot/sofa-ark-biz-lifecycle/","summary":"SOFAArk 合并部署时，除了宿主应用，其他 Biz 允许运行时动态部署和卸载。Biz 的状态如下： unresolved: 未注册，此时 Biz 包未被运行时解析 resolved: Biz 包解析完成，且已注册，此时","tags":null,"title":"Ark Biz 生命周期","type":"projects","url":"/projects/sofa-boot/sofa-ark-biz-lifecycle/","wordcount":1184},{"author":null,"categories":null,"content":"Ark container class loading mechanism The plugins and business modules are managed in the Ark container. The following figure describes the class loading mechanism:\nClass loading mechanism of Ark container Each Ark plugin has a separate classloader which loads a class in the following order:\n If byte codes generated by reflection are loaded, the system will throw a ClassNotFoundException to terminate the loading process. This primarily comes from our engineering practice: to avoid long time searches for the classes that can never be found. Search for the already loaded classes Search for classes in the JDK, which mainly consists of two parts: 1) the classes to be loaded by ExtClassloader; 2) the classes that are provided by the JDK but fail to be loaded from the ExtClassloader. When running locally, however, these classes will be added to the SystemClassloader\u0026amp;rsquo;s classpath or they might be put into some third-party toolkits such as sun.tools.attach.BsdVirtualMachine in tool.jar at the same time. This part also comes from our engineering practice, avoiding errors caused by loading a class more than once. See if the class is an interface from Sofa Ark, such as com.alipay.sofa.Ark.spi.service.PluginActivator. If so, the class will be delegated to the classloader of the Ark container responsible for loading. See if it is located in the plugin import (including import-classes and import-package). If so, the loading will be delegated to the plugin classloader that will export it. Load in the plugin\u0026amp;rsquo;s own classpath If the above steps have failed, it will try to load the class in SymtemClassloader to deal with the situation that the agent is used.  If the class fails to be loaded with all the above steps, the ClassNotFoundException will be thrown.\nArk business class loading mechanism Each Ark business has a separate classloader. Its class loading mechanism is basically consistent with that of Ark plugin, except for the step 5:\nFor Ark business, no import configuration is provided. Instead, it defaults to importing all classes exported by plug-ins. To deal with some particular business scenarios, however, we do provide the Deny-import configuration so that we can exclude the classes exported by some plugins.\nClass loading mechanism of Ark plugin resources The Ark plugin supports importing and exporting resources. To achieve this, we need to configure the corresponding import and export settings in sofa-Ark-plugin-maven-plugin. There are two ways to search for resources when using ClassLoader: ClassLoader.getResource(String) or ClassLoader.getResources(String);\n  ClassLoader.getResource(String): When an Ark Plugin is searching for a single resource, it will delegate the Ark Plugin that will export the resource to load the class first. If multiple plugins export the resource at the same time, then the plugin with higher priority will export the resource first. If the loading fails or no other Ark Plugin has exported the resource, it will have a …","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-classloader/","fuzzywordcount":600,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"5803b870aae47885c37e4bbb02cb0a06","permalink":"/en/projects/sofa-boot/sofa-ark-classloader/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/en/projects/sofa-boot/sofa-ark-classloader/","summary":"Ark container class loading mechanism The plugins and business modules are managed in the Ark container. The following figure describes the class loading mechanism:\nClass loading mechanism of Ark container Each Ark plugin has a separate classloader which loads a class in the following order:\n If byte codes generated by reflection are loaded, the system will throw a ClassNotFoundException to terminate the loading process. This primarily comes from our engineering practice: to avoid long time searches for the classes that can never be found.","tags":null,"title":"Ark container class loading mechanism","type":"projects","url":"/en/projects/sofa-boot/sofa-ark-classloader/","wordcount":549},{"author":null,"categories":null,"content":"Starting an Ark plug-in Ark provides the interface for starting a plug-in com.alipay.sofa.ark.spi.service.PluginActivator. The definition of the interface is as follows:\npublic interface PluginActivator { /** * Start Plugin * @param context plugin context * @throws ArkException */ void start(PluginContext context) throws ArkException; /** * Stop Plugin * @param context * @throws ArkException */ void stop(PluginContext context) throws ArkException; } Once a plug-in implements this interface, and the activator attribute is configured in MANIFEST.MF, the plug-in will use the start method when it starts and the stop method when it stops.\nArk plug-in communication Ark plug-ins communicate using services. The interfaces used by the publishing and reference services are provided in the input parameter type com.alipay.sofa.ark.spi.model.PluginContext of the preceding method of starting an interface.\n/** * Publish Plugin Service * @param ifClass service interface * @param implObject service implement object * @param \u0026amp;lt;T\u0026amp;gt; * @return */ \u0026amp;lt;T\u0026amp;gt; ServiceReference\u0026amp;lt;T\u0026amp;gt; publishService(Class\u0026amp;lt;T\u0026amp;gt; ifClass, T implObject); /** * Get Service publish by plugin, when there are multiple services, return the highest priority plugin service * @param ifClass service interface * @param \u0026amp;lt;T\u0026amp;gt; * @return service reference */ \u0026amp;lt;T\u0026amp;gt; ServiceReference\u0026amp;lt;T\u0026amp;gt; referenceService(Class\u0026amp;lt;T\u0026amp;gt; ifClass); /** * Get Service publish by one specific plugin * @param ifClass service interface * @param \u0026amp;lt;T\u0026amp;gt; * @param pluginName the name of the plugin which publish the service * @return service reference */ \u0026amp;lt;T\u0026amp;gt; ServiceReference\u0026amp;lt;T\u0026amp;gt; referenceService(Class\u0026amp;lt;T\u0026amp;gt; ifClass, String pluginName); /** * Get Service List publish by plugin * @param ifClass service interface * @param \u0026amp;lt;T\u0026amp;gt; * @return */ \u0026amp;lt;T\u0026amp;gt; List\u0026amp;lt;ServiceReference\u0026amp;lt;T\u0026amp;gt;\u0026amp;gt; referenceServices(Class\u0026amp;lt;T\u0026amp;gt; ifClass); A plug-in service is interface-specific. For one interface, the following descriptions are true:\n Only one service can be published for each plug-in. When more than one service is published, the reference of the previously published service will be returned. If you use referenceService to reference a single service when multiple plug-ins have published services, which service is returned depends on whether pluginName is specified:  When not specified, the service with the highest priority is returned. When specified, the service published by the plugin with the specified name is returned.    The returned service reference ServiceReference is defined as follows:\npublic interface ServiceReference\u0026amp;lt;T\u0026amp;gt; { /** * get Service Object * @return service */ T getService(); /** * get Service Metadata * @return */ ServiceMetadata getServiceMetadata(); } public interface ServiceMetadata { /** * get Service Unique Name * @return service name */ String getServiceName(); /** * get Service Interface Class * @return interface class */ Class\u0026amp;lt;?\u0026amp;gt; getInterfaceClass(); /** * get …","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-plugin/","fuzzywordcount":500,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"b552fc51eb84cc0fa4c26860bd316490","permalink":"/en/projects/sofa-boot/sofa-ark-plugin/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/en/projects/sofa-boot/sofa-ark-plugin/","summary":"Starting an Ark plug-in Ark provides the interface for starting a plug-in com.alipay.sofa.ark.spi.service.PluginActivator. The definition of the interface is as follows:\npublic interface PluginActivator { /** * Start Plugin * @param context plugin context * @throws ArkException */ void start(PluginContext context) throws ArkException; /** * Stop Plugin * @param context * @throws ArkException */ void stop(PluginContext context) throws ArkException; } Once a plug-in implements this interface, and the activator attribute is configured in MANIFEST.","tags":null,"title":"Ark container plugin mechanism","type":"projects","url":"/en/projects/sofa-boot/sofa-ark-plugin/","wordcount":468},{"author":null,"categories":null,"content":"Ark container start process The startup process of the Ark container is illustrated as follows:\nArkService Ark Service is a service in the Ark container. The underlying layer uses Guice to manage the service. The service is provided with the lifecycle interface com.alipay.sofa.ark.spi.service.ArkService\npublic interface ArkService { /** * Ark Service init * @throws ArkException */ void init() throws ArkException; /** * Ark Service dispose * @throws ArkException */ void dispose() throws ArkException; } After the service implements the preceding lifecycle interface, the Ark Service container invokes the interface when it starts and stops.\nPipeline service Pipeline is also a service registered in the Ark Service container. The service itself has no order or priority. The service is assembled in the Pipeline while the entire Ark container starts.\nArchive parsing At the very beginning of Pipeline, the running fatjar will be resolved into the models required for runtime, including the Ark plug-in model and the Ark business model, which are registered to the PluginManagerService and the BizManagerService in the Ark Service.\nDeploy the Ark plug-in Get all the Ark plug-ins from the PluginManagerService in the order of their priorities:\n ClassloaderService prepares for the map mapping of plug-in export class PluginDeployService starts com.alipay.sofa.Ark.spi.service.PluginActivator  Start the Ark business Get all the Ark business from the BizManagerService, and execute the entry main function provided by the business configuration in the Main-Class attribute of MANIFEST.MF.\n","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-startup/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"ad60e803febd20607686a1b4ea98efc3","permalink":"/en/projects/sofa-boot/sofa-ark-startup/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-boot/sofa-ark-startup/","summary":"Ark container start process The startup process of the Ark container is illustrated as follows:\nArkService Ark Service is a service in the Ark container. The underlying layer uses Guice to manage the service. The service is provided with the lifecycle interface com.alipay.sofa.ark.spi.service.ArkService\npublic interface ArkService { /** * Ark Service init * @throws ArkException */ void init() throws ArkException; /** * Ark Service dispose * @throws ArkException */ void dispose() throws ArkException; } After the service implements the preceding lifecycle interface, the Ark Service container invokes the interface when it starts and stops.","tags":null,"title":"Ark container startup process","type":"projects","url":"/en/projects/sofa-boot/sofa-ark-startup/","wordcount":231},{"author":null,"categories":null,"content":"﻿This section will introduce the directory structure of standard Ark package and how to use the maven plugin of sofa-Ark-maven-plugin to package and release an Ark package.\nMaven plugin The officially provided Maven plugin sofa-Ark-maven-plugin can package common Java projects or Spring Boot projects into standard-format Ark packages. Based on [Fat Jar] (https://docs.spring.io/spring-boot/docs/current/reference/html/executable-jar.html#executable-jar-jar-file-structure) technology, we can directly start an Ark package with the java -jar command. The Maven plugin coordinates are:\n\u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${sofa.ark.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/plugin\u0026amp;gt; Goals The sofa-Ark-maven-plugin plugin provides goal: repackage, which can package the project into an executable Ark package, it can be configured as follows:\n\u0026amp;lt;build\u0026amp;gt; \u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${sofa.ark.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;executions\u0026amp;gt; \u0026amp;lt;execution\u0026amp;gt; \u0026amp;lt;id\u0026amp;gt;default-cli\u0026amp;lt;/id\u0026amp;gt; \u0026amp;lt;goals\u0026amp;gt; \u0026amp;lt;goal\u0026amp;gt;repackage\u0026amp;lt;/goal\u0026amp;gt; \u0026amp;lt;/goals\u0026amp;gt; \u0026amp;lt;/excution\u0026amp;gt; \u0026amp;lt;/executions\u0026amp;gt; \u0026amp;lt;configuration\u0026amp;gt; \u0026amp;lt;!-- Configuration information --\u0026amp;gt; \u0026amp;lt;/configuration\u0026amp;gt; \u0026amp;lt;/plugin\u0026amp;gt; \u0026amp;lt;/build\u0026amp;gt; Complete configuration template Complete sofa-Ark-maven-plugin configuration template is as follows:\n\u0026amp;lt;plugins\u0026amp;gt; \u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;0.1.0\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;executions\u0026amp;gt; \u0026amp;lt;execution\u0026amp;gt; \u0026amp;lt;id\u0026amp;gt;default-cli\u0026amp;lt;/id\u0026amp;gt; \u0026amp;lt;goals\u0026amp;gt; \u0026amp;lt;goal\u0026amp;gt;repackage\u0026amp;lt;/goal\u0026amp;gt; \u0026amp;lt;/goals\u0026amp;gt; \u0026amp;lt;configuration\u0026amp;gt; \u0026amp;lt;!--The default packaging storage directory for Ark package and Ark biz is the project build directory--\u0026amp;gt; \u0026amp;lt;outputDirectory\u0026amp;gt;../target\u0026amp;lt;/outputDirectory\u0026amp;gt; \u0026amp;lt;!--The name of the generated Ark package file is ${artifactId} by default--\u0026amp;gt; \u0026amp;lt;finalName\u0026amp;gt;demo-ark\u0026amp;lt;/finalName\u0026amp;gt; \u0026amp;lt;!--Whether to skip execution of goal:repackage (false by default)--\u0026amp;gt; \u0026amp;lt;skip\u0026amp;gt;false\u0026amp;lt;/skip\u0026amp;gt; \u0026amp;lt;!--Whether to package, install, and release Ark biz (false by default). Refer to the Ark Biz file for details --\u0026amp;gt; \u0026amp;lt;attach\u0026amp;gt;true\u0026amp;lt;/attach\u0026amp;gt; \u0026amp;lt;!--Set the classifier of Ark package, which is null by default--\u0026amp;gt; \u0026amp;lt;arkClassifier\u0026amp;gt;ark-classifier\u0026amp;lt;/arkClassifier\u0026amp;gt; \u0026amp;lt;!-- Set the classifier of Ark biz, which is Ark-biz by default --\u0026amp;gt; \u0026amp;lt;bizClassifier\u0026amp;gt;ark-biz-classifier\u0026amp;lt;/bizClassifier\u0026amp;gt; \u0026amp;lt;!--Exclude the specified package dependency when packaging the Ark biz. The format is: ${groupId:artifactId} or ${groupId:artifactId:classifier}--\u0026amp;gt; \u0026amp;lt;excludes\u0026amp;gt; \u0026amp;lt;exclude\u0026amp;gt;org.apache.commons:commons-lang3\u0026amp;lt;/exclude\u0026amp;gt; \u0026amp;lt;/excludes\u0026amp;gt; \u0026amp;lt;!--Exclude the package dependency that is the same as the specified groupId …","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-ark-jar/","fuzzywordcount":1400,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"c2a9b8ad142f15b9ee82d7d9d8237850","permalink":"/en/projects/sofa-boot/sofa-ark-ark-jar/","publishdate":"0001-01-01T00:00:00Z","readingtime":7,"relpermalink":"/en/projects/sofa-boot/sofa-ark-ark-jar/","summary":"﻿This section will introduce the directory structure of standard Ark package and how to use the maven plugin of sofa-Ark-maven-plugin to package and release an Ark package.\nMaven plugin The officially provided Maven plugin sofa-Ark-maven-plugin can package common Java projects or Spring Boot projects into standard-format Ark packages. Based on [Fat Jar] (https://docs.spring.io/spring-boot/docs/current/reference/html/executable-jar.html#executable-jar-jar-file-structure) technology, we can directly start an Ark package with the java -jar command. The Maven plugin coordinates are:","tags":null,"title":"Ark JAR package","type":"projects","url":"/en/projects/sofa-boot/sofa-ark-ark-jar/","wordcount":1316},{"author":null,"categories":null,"content":"﻿This section will introduce the standard specifications and directory structure of Ark Plugin and how to use the maven plugin of sofa-ark-plugin-maven-plugin to package and release it.\nPlugin Specifications A standard Ark Plugin should meet the following specifications:\n  The plugin should have a name (default is ${artifactId}). At runtime, duplicate names are not allowed. In other words, the name will be used as the unique ID of Ark Plugin;\n  A plugin must be configured with a priority (default is 1,000): the lower the number, the higher the priority;\n  A plugin should be configured with no more than one entry class activator, a portal for the container startup plugin used to implement the com.alipay.sofa.ark.spi.service.PluginActivator interface class in a uniform way. The plugin with higher priority will start up first;\n  Import classes support both package and class levels. They are loaded first from other plugins;\n  Export classes support package and class levels. Plugins with higher priority will be exported first;\n  Support importing resources from the classpath (wildcard is not supported). Specified resources will be searched for from other plugins first;\n  Support exporting resources from the classpath (wildcard is not supported); resources with higher priority will be exported first;\n  Maven plugins The officially provided Maven plugin sofa-ark-plugin-maven-plugin can package projects into a standard-format Ark Plugin. The coordinates of Maven plugin are:\n\u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-plugin-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${sofa.ark.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/plugin\u0026amp;gt; Goals The sofa-ark-plugin-maven-plugin plugin provides goal: ark-plugin, which can be used to package the project into a standard-format Ark Plugin. Configurations are as follows:\n\u0026amp;lt;build\u0026amp;gt; \u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-plugin-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${sofa.ark.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;executions\u0026amp;gt; \u0026amp;lt;execution\u0026amp;gt; \u0026amp;lt;id\u0026amp;gt;default-cli\u0026amp;lt;/id\u0026amp;gt; \u0026amp;lt;goals\u0026amp;gt; \u0026amp;lt;goal\u0026amp;gt;ark-plugin\u0026amp;lt;/goal\u0026amp;gt; \u0026amp;lt;/goals\u0026amp;gt; \u0026amp;lt;/excution\u0026amp;gt; \u0026amp;lt;/executions\u0026amp;gt; \u0026amp;lt;configuration\u0026amp;gt; \u0026amp;lt;!-- Configuration information --\u0026amp;gt; \u0026amp;lt;/configuration\u0026amp;gt; \u0026amp;lt;/plugin\u0026amp;gt; \u0026amp;lt;/build\u0026amp;gt; Complete configuration template The complete configuration template of the sofa-ark-plugin-maven-plugin plugin is shown as follows:\n\u0026amp;lt;plugins\u0026amp;gt; \u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-plugin-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${sofa.ark.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;executions\u0026amp;gt; \u0026amp;lt;execution\u0026amp;gt; \u0026amp;lt;id\u0026amp;gt;default-cli\u0026amp;lt;/id\u0026amp;gt; \u0026amp;lt;goals\u0026amp;gt; \u0026amp;lt;goal\u0026amp;gt;ark-plugin\u0026amp;lt;/goal\u0026amp;gt; \u0026amp;lt;/goals\u0026amp;gt; \u0026amp;lt;configuration\u0026amp;gt; \u0026amp;lt;!-- Specify the directory to package ${pluginName}.ark.plugin (${project. build. directory} is the default location) --\u0026amp;gt; …","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-ark-plugin/","fuzzywordcount":1300,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"684dc1caa0f834eec498905f95913f83","permalink":"/en/projects/sofa-boot/sofa-ark-ark-plugin/","publishdate":"0001-01-01T00:00:00Z","readingtime":6,"relpermalink":"/en/projects/sofa-boot/sofa-ark-ark-plugin/","summary":"﻿This section will introduce the standard specifications and directory structure of Ark Plugin and how to use the maven plugin of sofa-ark-plugin-maven-plugin to package and release it.\nPlugin Specifications A standard Ark Plugin should meet the following specifications:\n  The plugin should have a name (default is ${artifactId}). At runtime, duplicate names are not allowed. In other words, the name will be used as the unique ID of Ark Plugin;","tags":null,"title":"Ark Plugin","type":"projects","url":"/en/projects/sofa-boot/sofa-ark-ark-plugin/","wordcount":1240},{"author":null,"categories":null,"content":"本小节将介绍 Ark Plugin 的标准规范和目录结构，以及如何使用官方插件 sofa-ark-plugin-maven-plugin 打包发布 Ark Plugin。\n插件规范 标准的 Ark Plugin 需要满足以下规范：\n  插件必须配置插件名，默认为 ${artifactId} ；运行时，不允许存在同名的插件，可以认为它是 Ark Plugin 的唯一 ID;\n  插件必须配置优先级，默认为1000，数字越低表示优先级越高；\n  插件最多配置一个入口类 activator ，它是容器启动插件的入口，统一实现 com.alipay.sofa.ark.spi.service.PluginActivator 接口类；优先级高的插件优先启动；\n  导入类支持 package 和 class 两个级别；导入类优先从其他的插件加载；\n  导出类支持 package 和 class 两个级别；优先级高的插件优先导出；\n  支持导入 classpath 中资源，不支持通配符；优先从其他插件中查找指定资源；\n  支持导出 classpath 中资源，不支持通配符；优先级高的插件优先导出；\n  Maven 插件 官方提供 Maven 插件 sofa-ark-plugin-maven-plugin 可以将工程打包成标准格式的 Ark Plugin ； Maven 插件坐标为：\n\u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-plugin-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${demo.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/plugin\u0026amp;gt; Goals sofa-ark-plugin-maven-plugin 插件提供 goal: ark-plugin，可以将工程打包成标准格式的 Ark Plugin, 如下配置：\n\u0026amp;lt;build\u0026amp;gt; \u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-plugin-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${sofa.ark.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;executions\u0026amp;gt; \u0026amp;lt;execution\u0026amp;gt; \u0026amp;lt;id\u0026amp;gt;default-cli\u0026amp;lt;/id\u0026amp;gt; \u0026amp;lt;goals\u0026amp;gt; \u0026amp;lt;goal\u0026amp;gt;ark-plugin\u0026amp;lt;/goal\u0026amp;gt; \u0026amp;lt;/goals\u0026amp;gt; \u0026amp;lt;/execution\u0026amp;gt; \u0026amp;lt;/executions\u0026amp;gt; \u0026amp;lt;configuration\u0026amp;gt; \u0026amp;lt;!-- 配置信息 --\u0026amp;gt; \u0026amp;lt;/configuration\u0026amp;gt; \u0026amp;lt;/plugin\u0026amp;gt; \u0026amp;lt;/build\u0026amp;gt; 完整配置模板 完整的 sofa-ark-plugin-maven-plugin 插件配置模板如下：\n\u0026amp;lt;plugins\u0026amp;gt; \u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-plugin-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${sofa.ark.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;executions\u0026amp;gt; \u0026amp;lt;execution\u0026amp;gt; \u0026amp;lt;id\u0026amp;gt;default-cli\u0026amp;lt;/id\u0026amp;gt; \u0026amp;lt;goals\u0026amp;gt; \u0026amp;lt;goal\u0026amp;gt;ark-plugin\u0026amp;lt;/goal\u0026amp;gt; \u0026amp;lt;/goals\u0026amp;gt; \u0026amp;lt;configuration\u0026amp;gt; \u0026amp;lt;!-- 指定打包的 ${pluginName}.ark.plugin 存放目录; 默认放在 ${project.build.directory} --\u0026amp;gt; \u0026amp;lt;outputDirectory\u0026amp;gt;./\u0026amp;lt;/outputDirectory\u0026amp;gt; \u0026amp;lt;!-- 是否把 ark plugin 安装、发布到仓库，默认为true --\u0026amp;gt; \u0026amp;lt;attach\u0026amp;gt;true\u0026amp;lt;/attach\u0026amp;gt; \u0026amp;lt;!-- ark plugin 最多仅能指定一个 com.alipay.sofa.ark.spi.service.PluginActivator 接口实现类 --\u0026amp;gt; \u0026amp;lt;activator\u0026amp;gt;com.alipay.sofa.ark.service.impl.SampleActivator\u0026amp;lt;/activator\u0026amp;gt; \u0026amp;lt;!-- 配置优先级，数字越小，优先级越高，优先启动，优先导出类，默认1000 --\u0026amp;gt; \u0026amp;lt;priority\u0026amp;gt;2000\u0026amp;lt;/priority\u0026amp;gt; \u0026amp;lt;!-- 配置插件的名字，务必配置对，运行时，是插件的唯一标识 ID。比如 sofa-rpc 插件，可以配置为 sofa-rpc; 默认为 ${artifactId} --\u0026amp;gt; \u0026amp;lt;pluginName\u0026amp;gt;${ark.plugin.name}\u0026amp;lt;/pluginName\u0026amp;gt; \u0026amp;lt;!--设置 ark plugin 的 classifier, 默认为空, 如非必要，建议不用设置--\u0026amp;gt; \u0026amp;lt;classifier\u0026amp;gt;ark-plugin\u0026amp;lt;/classifier\u0026amp;gt; \u0026amp;lt;!-- 配置导入类、资源 --\u0026amp;gt; \u0026amp;lt;imported\u0026amp;gt; \u0026amp;lt;!-- 配置需要优先从其他 ark plugin 加载的 package --\u0026amp;gt; \u0026amp;lt;packages\u0026amp;gt; \u0026amp;lt;package\u0026amp;gt;javax.servlet\u0026amp;lt;/package\u0026amp;gt; \u0026amp;lt;package\u0026amp;gt;org.springframework.*\u0026amp;lt;/package\u0026amp;gt; \u0026amp;lt;/packages\u0026amp;gt; \u0026amp;lt;!-- 配置需要优先从其他 ark plugin 加载的 class --\u0026amp;gt; \u0026amp;lt;classes\u0026amp;gt; \u0026amp;lt;class\u0026amp;gt;com.alipay.sofa.rpc.config.ProviderConfig\u0026amp;lt;/class\u0026amp;gt; \u0026amp;lt;/classes\u0026amp;gt; \u0026amp;lt;!-- 配置需要优先从其他 ark plugin 加载的资源 --\u0026amp;gt; \u0026amp;lt;resources\u0026amp;gt; \u0026amp;lt;resource\u0026amp;gt;META-INF/spring/bean.xml\u0026amp;lt;/resource\u0026amp;gt;\u0026amp;gt; \u0026amp;lt;/resources\u0026amp;gt; \u0026amp;lt;/imported\u0026amp;gt; …","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-ark-plugin/","fuzzywordcount":2000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"684dc1caa0f834eec498905f95913f83","permalink":"/projects/sofa-boot/sofa-ark-ark-plugin/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/projects/sofa-boot/sofa-ark-ark-plugin/","summary":"本小节将介绍 Ark Plugin 的标准规范和目录结构，以及如何使用官方插件 sofa-ark-plugin-maven-plugin 打包发布 Ark Plugin。 插件规范 标准的 Ark Plugin 需要满足以下规范： 插件必须配置插件名，","tags":null,"title":"Ark Plugin","type":"projects","url":"/projects/sofa-boot/sofa-ark-ark-plugin/","wordcount":1935},{"author":null,"categories":null,"content":"使用 Ark 事件处理机制 SOFAArk 从 1.1.0 版本开始提供了全新的事件模型，囊括了 SOFAArk 中 biz 和 plugin 的各个生命周期；该版本提供的事件模型参考了 Spring 中的生命周期事件模型。本篇文档将描述如何使用 SOFAArk 的事件机制。\n事件概览 biz 生命周期事件    事件名 描述     AfterBizStartupEvent biz 启动之后发送的事件   AfterBizStopEvent biz 停止之后发送的事件   AfterBizSwitchEvent biz 切换之后发送的事件   BeforeBizStartupEvent biz 启动之前发送的事件   BeforeBizStopEvent biz 停止之前发送的事件   BeforeBizSwitchEvent biz 切换之前发送的事件    plugin 生命周期事件    事件名 描述     AfterPluginStartupEvent plugin 启动之后发送的事件   AfterPluginStopEvent plugin 停止之后发送的事件   BeforePluginStartupEvent plugin 启动之前发送的事件   BeforePluginStopEvent plugin 停止之前发送的事件    容器级别生命周期事件    事件名 描述     AfterFinishDeployEvent 执行完 DeployStage 阶段之后发送的事件   AfterFinishStartupEvent 执行完 Ark 容器启动之后发送的事件    事件监听 监听指定类型的事件 上述提到的各个阶段的事件，我们可以通过编写 EventHandler 来处理，例如，希望监听类型为 BeforeBizStartupEvent 的事件，则可以通过以下方式实现监听：\n@Component public class EventHandlerSample implements EventHandler\u0026amp;lt;BeforeBizStartupEvent\u0026amp;gt; { private static final Logger LOGGER = LoggerFactory.getLogger(\u0026amp;#34;EVENT-HANDLER-LOGGER\u0026amp;#34;); @Override public int getPriority() { return 0; } @Override public void handleEvent(BeforeBizStartupEvent event) { Biz source = event.getSource(); LOGGER.info(\u0026amp;#34;begin to startup biz, current biz is: {}\u0026amp;#34;,source.getIdentity()); } }  日志目录：target/test/logs/host-app/event-handler.log 日志输出： 2019-11-28 15:18:33,248 INFO EVENT-HANDLER-LOGGER - begin to startup biz, current biz is: provider1:2.0.0, bizState: resolved\n 在此基础上，在提供其他几个 event 的处理器：\n AfterBizStartupEvent  @Component public class AfterBizStartupEventHandler implements EventHandler\u0026amp;lt;AfterBizStartupEvent\u0026amp;gt; { private static final Logger LOGGER = LoggerFactory.getLogger(\u0026amp;#34;EVENT-HANDLER-LOGGER\u0026amp;#34;); @Override public void handleEvent(AfterBizStartupEvent event) { Biz source = event.getSource(); LOGGER.info(\u0026amp;#34;after startup biz, current biz is: {}, bizState: {}\u0026amp;#34;,source.getIdentity(),source.getBizState() ); } @Override public int getPriority() { return 0; } } 分别启动 基座 -\u0026amp;gt; 安装 ark-provider 模块 -\u0026amp;gt; 卸载 ark-provider 模块 ，然后看到日志输出如下：\n2019-11-28 15:31:42,325 INFO EVENT-HANDLER-LOGGER - after startup biz, current biz is: host-app:2.0.0, bizState: resolved 2019-11-28 15:36:23,956 INFO EVENT-HANDLER-LOGGER - begin to startup biz, current biz is: provider1:2.0.0, bizState: resolved 2019-11-28 15:36:27,216 INFO EVENT-HANDLER-LOGGER - after startup biz, current biz is: provider1:2.0.0, bizState: resolved 2019-11-28 15:53:38,225 INFO EVENT-HANDLER-LOGGER - before stop biz, current biz is: provider1:2.0.0, bizState: deactivated 2019-11-28 15:53:38,233 INFO EVENT-HANDLER-LOGGER - after biz stop, current biz is: provider1:2.0.0, bizState: unresolved 监听不指定类型的事件 某些情况下，如果期望监听所有 biz 或者 plugin 生命周期事件，可以使用以下方式：\n@Component public class AbstractArkEventHandler implements EventHandler\u0026amp;lt;AbstractArkEvent\u0026amp;gt; { @Override public int getPriority() { return 0; } @Override public void handleEvent(AbstractArkEvent event) { System.out.println(\u0026amp;#34;------------ current event topic: \u0026amp;#34; + event.getTopic()); } }  为了区分输出，可以 sout 输出 …","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-ark-event/","fuzzywordcount":1100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"b0f233742572536edc8a517cf7547269","permalink":"/projects/sofa-boot/sofa-ark-ark-event/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/sofa-boot/sofa-ark-ark-event/","summary":"使用 Ark 事件处理机制 SOFAArk 从 1.1.0 版本开始提供了全新的事件模型，囊括了 SOFAArk 中 biz 和 plugin 的各个生命周期；该版本提供的事件模型参考了 Spring 中的生命周期事件模型。本篇","tags":null,"title":"Ark 事件机制","type":"projects","url":"/projects/sofa-boot/sofa-ark-ark-event/","wordcount":1075},{"author":null,"categories":null,"content":"本小节将介绍标准 Ark 包 的目录结构，以及如何使用官方插件 sofa-ark-maven-plugin 打包并发布 Ark 包。\nMaven 插件 官方提供 Maven 插件 sofa-ark-maven-plugin 可以将普通 Java 工程或者 Spring Boot 工程打包成标准格式 Ark 包 ；基于 Fat Jar 技术，使用 java -jar 命令可以直接启动 Ark 包 。 Maven 插件坐标为：\n\u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${sofa.ark.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/plugin\u0026amp;gt; Goals sofa-ark-maven-plugin 插件提供 goal: repackage， 可以将工程打包成可执行的 Ark 包，如下配置：\n\u0026amp;lt;build\u0026amp;gt; \u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${sofa.ark.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;executions\u0026amp;gt; \u0026amp;lt;execution\u0026amp;gt; \u0026amp;lt;id\u0026amp;gt;default-cli\u0026amp;lt;/id\u0026amp;gt; \u0026amp;lt;goals\u0026amp;gt; \u0026amp;lt;goal\u0026amp;gt;repackage\u0026amp;lt;/goal\u0026amp;gt; \u0026amp;lt;/goals\u0026amp;gt; \u0026amp;lt;/excution\u0026amp;gt; \u0026amp;lt;/executions\u0026amp;gt; \u0026amp;lt;configuration\u0026amp;gt; \u0026amp;lt;!-- 配置信息 --\u0026amp;gt; \u0026amp;lt;/configuration\u0026amp;gt; \u0026amp;lt;/plugin\u0026amp;gt; \u0026amp;lt;/build\u0026amp;gt; 完整配置模板 完整的 sofa-ark-maven-plguin 插件配置模板如下：\n\u0026amp;lt;plugins\u0026amp;gt; \u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${sofa.ark.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;executions\u0026amp;gt; \u0026amp;lt;execution\u0026amp;gt; \u0026amp;lt;id\u0026amp;gt;default-cli\u0026amp;lt;/id\u0026amp;gt; \u0026amp;lt;goals\u0026amp;gt; \u0026amp;lt;goal\u0026amp;gt;repackage\u0026amp;lt;/goal\u0026amp;gt; \u0026amp;lt;/goals\u0026amp;gt; \u0026amp;lt;configuration\u0026amp;gt; \u0026amp;lt;!--ark 包和 ark biz 的打包存放目录，默认为工程 build 目录--\u0026amp;gt; \u0026amp;lt;outputDirectory\u0026amp;gt;./target\u0026amp;lt;/outputDirectory\u0026amp;gt; \u0026amp;lt;!--设置应用的根目录，用于读取 ${base.dir}/conf/ark/bootstrap.application 配置文件，默认为 ${project.basedir}--\u0026amp;gt; \u0026amp;lt;baseDir\u0026amp;gt;./\u0026amp;lt;/baseDir\u0026amp;gt; \u0026amp;lt;!--生成 ark 包文件名称，默认为 ${artifactId}--\u0026amp;gt; \u0026amp;lt;finalName\u0026amp;gt;demo-ark\u0026amp;lt;/finalName\u0026amp;gt; \u0026amp;lt;!--是否跳过执行 goal:repackage，默认为false--\u0026amp;gt; \u0026amp;lt;skip\u0026amp;gt;false\u0026amp;lt;/skip\u0026amp;gt; \u0026amp;lt;!--是否打包、安装和发布 ark biz，详细参考 Ark Biz 文档，默认为false--\u0026amp;gt; \u0026amp;lt;attach\u0026amp;gt;true\u0026amp;lt;/attach\u0026amp;gt; \u0026amp;lt;!--设置 ark 包的 classifier，默认为空--\u0026amp;gt; \u0026amp;lt;arkClassifier\u0026amp;gt;ark\u0026amp;lt;/arkClassifier\u0026amp;gt; \u0026amp;lt;!--设置 ark biz 的 classifier，默认为 ark-biz--\u0026amp;gt; \u0026amp;lt;bizClassifier\u0026amp;gt;ark-biz\u0026amp;lt;/bizClassifier\u0026amp;gt; \u0026amp;lt;!--设置 ark biz 的 biz name，默认为 ${artifactId}--\u0026amp;gt; \u0026amp;lt;bizName\u0026amp;gt;demo-ark\u0026amp;lt;/bizName\u0026amp;gt; \u0026amp;lt;!--设置 ark biz 的 biz version，默认为 ${artifactId}--\u0026amp;gt; \u0026amp;lt;bizVersion\u0026amp;gt;0.0.1\u0026amp;lt;/bizVersion\u0026amp;gt; \u0026amp;lt;!--设置 ark biz 的 启动优先级，值越小优先级越高，${artifactId}--\u0026amp;gt; \u0026amp;lt;priority\u0026amp;gt;100\u0026amp;lt;/priority\u0026amp;gt; \u0026amp;lt;!--设置 ark biz 的启动入口，默认会搜索被打 org.springframework.boot.autoconfigure.SpringBootApplication 注解且含有 main 方法的入口类--\u0026amp;gt; \u0026amp;lt;mainClass\u0026amp;gt;com.alipay.sofa.xx.xx.MainEntry\u0026amp;lt;/mainClass\u0026amp;gt; \u0026amp;lt;!--设置是否将 scope=provided 的依赖打包，默认为 false--\u0026amp;gt; \u0026amp;lt;packageProvided\u0026amp;gt;false\u0026amp;lt;/packageProvided\u0026amp;gt; \u0026amp;lt;!--设置是否生成 Biz 包，默认为true--\u0026amp;gt; \u0026amp;lt;keepArkBizJar\u0026amp;gt;true\u0026amp;lt;/keepArkBizJar\u0026amp;gt; \u0026amp;lt;!--针对 Web 应用，设置 context path，默认为 /--\u0026amp;gt; \u0026amp;lt;webContextPath\u0026amp;gt;/\u0026amp;lt;/webContextPath\u0026amp;gt; \u0026amp;lt;!--打包 ark biz 时，排除指定的包依赖；格式为: ${groupId:artifactId} 或者 ${groupId:artifactId:classifier}--\u0026amp;gt; \u0026amp;lt;excludes\u0026amp;gt; \u0026amp;lt;exclude\u0026amp;gt;org.apache.commons:commons-lang3\u0026amp;lt;/exclude\u0026amp;gt; \u0026amp;lt;/excludes\u0026amp;gt; \u0026amp;lt;!--打包 ark biz 时，排除和指定 groupId 相同的包依赖--\u0026amp;gt; …","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-ark-jar/","fuzzywordcount":1700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"c2a9b8ad142f15b9ee82d7d9d8237850","permalink":"/projects/sofa-boot/sofa-ark-ark-jar/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/projects/sofa-boot/sofa-ark-ark-jar/","summary":"本小节将介绍标准 Ark 包 的目录结构，以及如何使用官方插件 sofa-ark-maven-plugin 打包并发布 Ark 包。 Maven 插件 官方提供 Maven 插件 sofa-ark-maven-plugin 可以将普通 Java 工程或者 Spring Boot 工程打包成标准格式 Ark 包 ；","tags":null,"title":"Ark 包","type":"projects","url":"/projects/sofa-boot/sofa-ark-ark-jar/","wordcount":1624},{"author":null,"categories":null,"content":"Ark 应用的整体启动流程如下图所述：\n当用 java -jar 启动 Ark 包 或者 在 IDE 中通过 SofaArkBootstrap.launch 启动 Ark 应用时，相应 Launcher 入口会负责启动应用，其中会反射调用 ArkContainer 的入口，初始化 ArkService ，然后依次执行 pipeline，来完成整个 Ark 应用的启动。\nArkService Ark Serivce 是 Ark 容器中的服务，底层使用 Guice 对服务进行管理。同时针对服务，提供了生命周期接口 com.alipay.sofa.ark.spi.service.ArkService\npublic interface ArkService { /** * Ark Service init * @throws ArkException */ void init() throws ArkException; /** * Ark Service dispose * @throws ArkException */ void dispose() throws ArkException; } 当服务实现了上述接口时，在 Ark Serivce 容器启动时和停止时会调用相应的生命周期接口\nPipeline 服务 Pipeline 也是注册在 Ark Service 容器中的一个服务，服务本身是没有顺序和优先级的，在 Pipeline 中会对服务进行一些组装，同时完成整个 Ark 容器的启动\nArchive 解析 在 Pipeline 的最开始，会将运行的 fatjar 进行解析，解析成运行时需要的模型，主要包括 Ark 插件模型和 Ark 业务模型，并将这些模型注册到 Ark Service 中的 PluginManagerService 以及 BizManagerService 中\n初始化环境 设置一些运行时需要的默认参数，比如设置 log4j.ignoreTCL 为 true 让 log4j/log4j2 初始化是日志不要从 ThreadContextClassloader 中寻找配置文件(背景)\n注册容器服务 在 Ark 容器中会发布一些服务供其它的插件来使用，比如 BizDeployer 来让 SOFAArk 官方插件 sofa-jarslink 来完成 biz 的动态加载/卸载等\n部署 Ark 插件 从 PluginManagerService 中获取到所有的 Ark 插件，并按照插件优先级顺序：\n ClassloaderService 准备插件 export 类的 map 映射 PluginDeployService 启动插件的 com.alipay.sofa.ark.spi.service.PluginActivator  启动 Ark 业务 从 BizManagerService 中获取到所有的 Ark 业务，并执行业务配置在 MANIFEST.MF 属性 Main-Class 中提供的入口 main 函数\n","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-startup/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"ad60e803febd20607686a1b4ea98efc3","permalink":"/projects/sofa-boot/sofa-ark-startup/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-boot/sofa-ark-startup/","summary":"Ark 应用的整体启动流程如下图所述： 当用 java -jar 启动 Ark 包 或者 在 IDE 中通过 SofaArkBootstrap.launch 启动 Ark 应用时，相应 Launcher 入口会负责启动应用，其中会反射调用 ArkContainer 的入口，初始化 ArkService ，然","tags":null,"title":"Ark 容器启动流程","type":"projects","url":"/projects/sofa-boot/sofa-ark-startup/","wordcount":521},{"author":null,"categories":null,"content":"Ark 插件启动 Ark 中提供了插件启动的接口 com.alipay.sofa.ark.spi.service.PluginActivator ，其定义如下：\npublic interface PluginActivator { /** * Start Plugin * @param context plugin context * @throws ArkException */ void start(PluginContext context) throws ArkException; /** * Stop Plugin * @param context * @throws ArkException */ void stop(PluginContext context) throws ArkException; } 插件只需要实现此接口，并在 MANIFEST.MF 中配置 activator 属性，就会在启动时执行 start 方法，停止时执行 stop 方法\nArk 插件通信 Ark 之间的通信是通过服务来完成的， 在上述启动接口方法的入参类型 com.alipay.sofa.ark.spi.model.PluginContext 中提供了发布服务和引用服务的接口\n/** * Publish Plugin Service * @param ifClass service interface * @param implObject service implement object * @param \u0026amp;lt;T\u0026amp;gt; * @return */ \u0026amp;lt;T\u0026amp;gt; ServiceReference\u0026amp;lt;T\u0026amp;gt; publishService(Class\u0026amp;lt;T\u0026amp;gt; ifClass, T implObject); /** * Get Service publish by plugin, when there are multiple services, return the highest priority plugin service * @param ifClass service interface * @param \u0026amp;lt;T\u0026amp;gt; * @return service reference */ \u0026amp;lt;T\u0026amp;gt; ServiceReference\u0026amp;lt;T\u0026amp;gt; referenceService(Class\u0026amp;lt;T\u0026amp;gt; ifClass); /** * Get Service publish by one specific plugin * @param ifClass service interface * @param \u0026amp;lt;T\u0026amp;gt; * @param pluginName the name of the plugin which publish the service * @return service reference */ \u0026amp;lt;T\u0026amp;gt; ServiceReference\u0026amp;lt;T\u0026amp;gt; referenceService(Class\u0026amp;lt;T\u0026amp;gt; ifClass, String pluginName); /** * Get Service List publish by plugin * @param ifClass service interface * @param \u0026amp;lt;T\u0026amp;gt; * @return */ \u0026amp;lt;T\u0026amp;gt; List\u0026amp;lt;ServiceReference\u0026amp;lt;T\u0026amp;gt;\u0026amp;gt; referenceServices(Class\u0026amp;lt;T\u0026amp;gt; ifClass); 插件服务是以接口为粒度的，针对同一个接口：\n 每一个插件只允许发布一个服务，重复发布则会直接返回已经发布服务的引用 当多有个插件发布服务时，若通过 referenceService 引用单个服务  当不指定 pluginName 时，则返回优先级最高的服务 当指定 pluginName 时，则返回该插件发布的服务    返回的服务引用 ServiceReference 定义如下:\npublic interface ServiceReference\u0026amp;lt;T\u0026amp;gt; { /** * get Service Object * @return service */ T getService(); /** * get Service Metadata * @return */ ServiceMetadata getServiceMetadata(); } public interface ServiceMetadata { /** * get Service Unique Name * @return service name */ String getServiceName(); /** * get Service Interface Class * @return interface class */ Class\u0026amp;lt;?\u0026amp;gt; getInterfaceClass(); /** * get ServiceProvider * @return */ ServiceProvider getServiceProvider(); } 其中通过\n getService() 可以获取到服务的实体 (也即发布服务时的 implObject) getServiceMetadata() 可以获取到服务的元数据信息，包括  服务名：即服务的接口名 服务接口 服务的提供方：包括提供方名字(插件名等)、提供方优先级(插件优先级)    ","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-plugin/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"b552fc51eb84cc0fa4c26860bd316490","permalink":"/projects/sofa-boot/sofa-ark-plugin/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-boot/sofa-ark-plugin/","summary":"Ark 插件启动 Ark 中提供了插件启动的接口 com.alipay.sofa.ark.spi.service.PluginActivator ，其定义如下： public interface PluginActivator { /** * Start Plugin * @param context plugin context * @throws ArkException */ void start(PluginContext context) throws ArkException; /** * Stop Plugin * @param context * @throws ArkException */ void stop(PluginContext context) throws ArkException; } 插件只需要实","tags":null,"title":"Ark 容器插件机制","type":"projects","url":"/projects/sofa-boot/sofa-ark-plugin/","wordcount":565},{"author":null,"categories":null,"content":"Ark 容器类加载机制 Ark 容器中会管理插件和业务，整体的类加载机制可见如下图描述：\nArk 插件类加载机制 每个 Ark 插件都拥有一个独立的类加载器，其类加载的顺序如下：\n 如果是加载反射生成的字节码，那么会直接抛出 ClassNotFoundException，终止类加载。这一部分主要是来源于我们的工程实践，避免一定找不到的类查找路径过长 查找已经被加载过的类 查找 JDK 中的类，这一块主要包含两部分：第一部分是 ExtClassloader 负责加载的类；第二部分是 JDK 提供的类但从 ExtClassloader 中加载不到，但在本地运行时会被加入到 SystemClassloader 的 classpath 中，同时这些类可能会被放到一些三方工具包中，典型的如 tool.jar 中 sun.tools.attach.BsdVirtualMachine,这一部分也主要来源于我们的工程实践，避免类被加载超过一次，从而引发报错 看类是否是由 Sofa Ark 提供的接口类，典型的如: com.alipay.sofa.ark.spi.service.PluginActivator, 如果是，则类会委托给 Ark 容器的类加载器加载 看是否在插件的 import 中(包括 import-classes 和 import-package)， 如果在，则会委托给导出该类的插件类加载器加载 在插件自身的 classpath 中加载 如果上述都失败了，则会尝试在 SymtemClassloader 中加载，这一步主要是为了解决使用 agent 时的情形  如果上述的步骤都加载失败了，则抛出 ClassNotFoundException\nArk 业务类加载机制 每个 Ark 业务都拥有一个独立的类加载器， Ark 业务类加载机制基本上与 Ark 插件保持一致，在上述的7步中，主要是第5步不一样：\n对于 Ark 业务而言，并没有提供 import 的配置，而是认为默认 import 所有插件 export 出来的类；但为了一些特殊的业务场景，我们提供了 Deny-import 的配置让业务可以排除掉某些插件导出的类\nArk 插件资源加载机制 Ark 插件支持导入导出资源，需要在 sofa-ark-plugin-maven-plugin 配置相关的导入导出配置；在使用 ClassLoader 加载资源时，存在两种方式查找资源，ClassLoader.getResource(String) 和 ClassLoader.getResources(String)；\n  ClassLoader.getResource(String): Ark Plugin 在查找单个资源时，会优先委托导出该资源的 Ark Plugin 加载，如果有多个插件同时导出，则优先级高的插件优先导出；如果加载失败或者没有其他 Ark Plugin 导出，则尝试在本 Ark Plugin 查找加载；\n  ClassLoader.getResources(String): Ark Plugin 在查找多个资源时，会从所有导出该资源的 Ark Plugin 加载，同时也会从本 Ark Plugin 加载资源；\n  Ark 业务资源加载机制 默认情况下，Ark Biz 会优先加载 Ark Plugin 导出的资源；如果开发者希望只在工程应用内部查找，则可以通过 sofa-ark-maven-plugin 配置 denyImportResources；如此，Ark Biz 不会从 Ark Plugin 查找该资源，只会在 Ark Biz 内部查找。\n","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-classloader/","fuzzywordcount":1000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"5803b870aae47885c37e4bbb02cb0a06","permalink":"/projects/sofa-boot/sofa-ark-classloader/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-boot/sofa-ark-classloader/","summary":"Ark 容器类加载机制 Ark 容器中会管理插件和业务，整体的类加载机制可见如下图描述： Ark 插件类加载机制 每个 Ark 插件都拥有一个独立的类加载器，其类加载的顺序","tags":null,"title":"Ark 容器类加载机制","type":"projects","url":"/projects/sofa-boot/sofa-ark-classloader/","wordcount":974},{"author":null,"categories":null,"content":"Ark 容器和 Ark Plugin 在运行时由不同的类加载器加载，不能使用常规的 ServiceLoader 提供 SPI 扩展，SOFAArk 自定义扩展点 SPI 机制， Ark Plugin 实现 SPI 机制，考虑到 Biz 卸载问题，Ark Biz 暂时不支持该 SPI 机制，只适用于 Ark Plugin 之间。\n声明扩展接口 使用注解 @Extensible 声明扩展接口，注解定义如下：\n@Target({ ElementType.TYPE }) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface Extensible { /** * return specify extensible file name, default value is the * full name of interface. */ String file() default \u0026amp;#34;\u0026amp;#34;; /** * return whether this a singleton, with a single, shared instance * returned on all calls, default value is true. */ boolean singleton() default true; }  file 用于声明 SPI 扩展文件名，默认为接口全类名 singleton 用于声明加载扩展类是否为单例模式  声明扩展实现 使用注解 @Extension 声明扩展实现，注解定义如下：\n@Target({ ElementType.TYPE }) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface Extension { /** * extension name */ String value(); /** * extension order, Higher values are interpreted as lower priority. * As a consequence, the object with the lowest value has the highest * priority. */ int order() default 100; }  value 用于定义扩展实现名称，例如不同的插件扩展同一个接口，可能会取不同的名字。 order 用于决定具体扩展实现的生效顺序  运行时，对于同一个接口的扩展实现生效规则如下：\n 规则一：名称相同的扩展实现，只会返回优先级高的扩展实现类，order 数字越小，优先级越高 规则二：名称不相同的扩展实现，则返回一个对应的 List 列表，每个名称返回优先级最高的扩展实现  加载 SPI 实现类 正常情况下，我们使用 ServiceLoader 加载 SPI 接口实现；SOFAArk 提供了工具类 ArkServiceLoader 用于加载扩展实现，工具类定义了两个简单的方法：\npublic class ArkServiceLoader { private static ExtensionLoaderService extensionLoaderService; // 方法一  public static \u0026amp;lt;T\u0026amp;gt; T loadExtension(Class\u0026amp;lt;T\u0026amp;gt; interfaceType, String extensionName) { return extensionLoaderService.getExtensionContributor(interfaceType, extensionName); } // 方法二  public static \u0026amp;lt;T\u0026amp;gt; List\u0026amp;lt;T\u0026amp;gt; loadExtension(Class\u0026amp;lt;T\u0026amp;gt; interfaceType) { return extensionLoaderService.getExtensionContributor(interfaceType); } }  方法一：用于加载指定接口和名称的扩展实现，返回单个结果。参考上述规则一 方法二：用于加载指定接口的扩展实现，返回列表结果。参考上述规则二  需要注意下，定义 SPI 接口的插件需要导出该接口，负责实现 SPI 接口的插件需要导入该接口。另外 SOFAArk 容器本身也会定义部分用于插件扩展实现的 SPI 接口，例如 ClassLoaderHook\n为什么不支持 Biz 的 SPI 扩展实现加载 考虑到 Biz 会动态的安装和卸载，如果支持 Biz 的扩展实现加载，生命周期容易引起混乱，暂时不考虑支持。如果确实存在 Ark Plugin 需要主动触发 Ark Biz 的逻辑调用，可以通过 SOFAArk 内部事件机制。\nSOFAArk 默认扩展点 SOFAArk 容器目前提供了唯一一个扩展点 ClassLoaderHook，用于其他插件提供扩展实现，自定义类/资源加载逻辑。ClassLoaderHooker 接口定义如下，用于扩展 BizClassLoader 和 PluginClassLoader 类(资源）加载逻辑：\n@Extensible public interface ClassLoaderHook\u0026amp;lt;T\u0026amp;gt; { Class\u0026amp;lt;?\u0026amp;gt; preFindClass(String name, ClassLoaderService classLoaderService, T t) throws ClassNotFoundException; Class\u0026amp;lt;?\u0026amp;gt; postFindClass(String name, ClassLoaderService classLoaderService, T t) throws ClassNotFoundException; URL preFindResource(String name, ClassLoaderService classLoaderService, T t); URL postFindResource(String name, ClassLoaderService classLoaderService, T t); Enumeration\u0026amp;lt;URL\u0026amp;gt; preFindResources(String name, ClassLoaderService classLoaderService, T t) throws IOException; Enumeration\u0026amp;lt;URL\u0026amp;gt; postFindResources(String name, ClassLoaderService classLoaderService, T t) throws IOException; } 通过在插件中扩展该 SPI 接口实现，可以自定义 PluginClassLoader 和 BizClassLoader 的类/资源的加载逻辑。 …","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-ark-extension/","fuzzywordcount":2000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"685e049f442cde4f3f51fefad5453dae","permalink":"/projects/sofa-boot/sofa-ark-ark-extension/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/projects/sofa-boot/sofa-ark-ark-extension/","summary":"Ark 容器和 Ark Plugin 在运行时由不同的类加载器加载，不能使用常规的 ServiceLoader 提供 SPI 扩展，SOFAArk 自定义扩展点 SPI 机制， Ark Plugin 实现 SPI 机制，考虑到 Biz 卸载问题，A","tags":null,"title":"Ark 扩展机制","type":"projects","url":"/projects/sofa-boot/sofa-ark-ark-extension/","wordcount":1923},{"author":null,"categories":null,"content":"SOFAArk 容器使用了 logback 日志实现，并集成了 sofa-common-tools，日志相关配置可以参考 配置文档, 这里介绍 SOFAArk 三个日志文件：\n sofa-ark/common-default.log   sofa-ark 默认日志，打印 SOFAArk 启动日志等，大概内容如下：\n 2019-03-12 15:08:55,758 INFO main - Begin to start ArkServiceContainer 2019-03-12 15:08:56,290 INFO main - Init Service: com.alipay.sofa.ark.container.session.StandardTelnetServerImpl 2019-03-12 15:08:56,311 INFO main - Listening on port: 1234 2019-03-12 15:08:56,313 INFO main - Init Service: com.alipay.sofa.ark.container.service.plugin.PluginDeployServiceImpl 2019-03-12 15:08:56,313 INFO main - Init Service: com.alipay.sofa.ark.container.service.biz.BizDeployServiceImpl 2019-03-12 15:08:56,313 INFO main - Init Service: com.alipay.sofa.ark.container.service.classloader.ClassLoaderServiceImpl 2019-03-12 15:08:56,317 INFO main - Finish to start ArkServiceContainer 2019-03-12 15:08:56,338 INFO main - Start to process pipeline stage: com.alipay.sofa.ark.container.pipeline.HandleArchiveStage 2019-03-12 15:08:56,349 INFO main - Finish to process pipeline stage: com.alipay.sofa.ark.container.pipeline.HandleArchiveStage 2019-03-12 15:08:56,349 INFO main - Start to process pipeline stage: com.alipay.sofa.ark.container.pipeline.RegisterServiceStage 2019-03-12 15:08:56,354 INFO main - Service: com.alipay.sofa.ark.spi.service.biz.BizManagerService publish by: ServiceProvider{provider=\u0026amp;#39;Ark Container\u0026amp;#39;, order=-2147483648} succeed 2019-03-12 15:08:56,354 INFO main - Service: com.alipay.sofa.ark.spi.service.biz.BizFactoryService publish by: ServiceProvider{provider=\u0026amp;#39;Ark Container\u0026amp;#39;, order=-2147483648} succeed 2019-03-12 15:08:56,355 INFO main - Service: com.alipay.sofa.ark.spi.service.plugin.PluginManagerService publish by: ServiceProvider{provider=\u0026amp;#39;Ark Container\u0026amp;#39;, order=-2147483648} succeed 2019-03-12 15:08:56,356 INFO main - Service: com.alipay.sofa.ark.spi.service.plugin.PluginFactoryService publish by: ServiceProvider{provider=\u0026amp;#39;Ark Container\u0026amp;#39;, order=-2147483648} succeed 2019-03-12 15:08:56,356 INFO main - Service: com.alipay.sofa.ark.spi.service.event.EventAdminService publish by: ServiceProvider{provider=\u0026amp;#39;Ark Container\u0026amp;#39;, order=-2147483648} succeed 2019-03-12 15:08:56,357 INFO main - Service: com.alipay.sofa.ark.spi.service.registry.RegistryService publish by: ServiceProvider{provider=\u0026amp;#39;Ark Container\u0026amp;#39;, order=-2147483648} succeed 2019-03-12 15:08:56,360 INFO main - Inject {field= bizManagerService} of {service= ServiceMetadata{service=\u0026amp;#39;com.alipay.sofa.ark.spi.service.biz.BizDeployer\u0026amp;#39;, provider=\u0026amp;#39;ServiceProvider{provider=\u0026amp;#39;Ark Container\u0026amp;#39;, order=100}\u0026amp;#39;}} success!  sofa-ark/common-error.log   sofa-ark 错误日志，打印 SOFAArk 容器运行时错误日志，例如 biz 启动失败日志等：\n 2019-03-12 16:38:41,873 ERROR main - Start biz: Startup In IDE meet error java.lang.reflect.InvocationTargetException: null at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at …","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-ark-log/","fuzzywordcount":700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"a514225510e53e9bf7173734c1f878e1","permalink":"/projects/sofa-boot/sofa-ark-ark-log/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-boot/sofa-ark-ark-log/","summary":"SOFAArk 容器使用了 logback 日志实现，并集成了 sofa-common-tools，日志相关配置可以参考 配置文档, 这里介绍 SOFAArk 三个日志文件： sofa-ark/common-default.log sofa-ark 默认日志，打印","tags":null,"title":"Ark 日志","type":"projects","url":"/projects/sofa-boot/sofa-ark-ark-log/","wordcount":664},{"author":null,"categories":null,"content":"SOFAArk 定义了两种服务类型，用于解决应用和插件，应用和应用之间的通信问题，下面分别介绍这两种服务类型：\n插件服务 SOFAArk 允许在 Plugin 通过 PluginContext 发布和引用服务，也可以使用注解 @ArkInject 引用服务。为了方便开发高级特性，SOFAArk 容器默认将内部功能组件发布成了服务，包括 Biz 管理，Plugin 管理，事件管理，服务注册管理。目前不允许 Biz 发布服务，只能引用插件服务。下面介绍如何发布和引用插件服务，以及 SOFAArk 容器默认发布的服务。\n发布服务 每个 Plugin 都可以定义唯一的插件入口，需要实现 PluginActivator 接口并在打包插件配置中声明，先看下接口定义：\npublic interface PluginActivator { /** * Start Plugin * @param context plugin context * @throws ArkRuntimeException */ void start(PluginContext context); /** * Stop Plugin * @param context * @throws ArkRuntimeException */ void stop(PluginContext context); } SOFAArk 容器在启动插件时，会调用插件启动入口(如果有)，因此如果插件实现方需要发布插件服务供其他插件或者 Biz 调用，可以使用入参 PluginContext 发布服务，PluginContext 提供了两个方法发布服务：\n/** * Publish Plugin Service * @param ifClass service interface * @param implObject service implement object * @param \u0026amp;lt;T\u0026amp;gt; * @return */ \u0026amp;lt;T\u0026amp;gt; ServiceReference\u0026amp;lt;T\u0026amp;gt; publishService(Class\u0026amp;lt;T\u0026amp;gt; ifClass, T implObject); /** * Publish Plugin Service * @param ifClass service interface * @param implObject service implement object * @param uniqueId service implementation id * @param \u0026amp;lt;T\u0026amp;gt; * @return */ \u0026amp;lt;T\u0026amp;gt; ServiceReference\u0026amp;lt;T\u0026amp;gt; publishService(Class\u0026amp;lt;T\u0026amp;gt; ifClass, T implObject, String uniqueId); 这两个方法的区别在于是否指定 uniqueId，因为同一个接口，可能会有多个服务实现，因此需要使用 uniqueId 区别，同样在引用端也需要指定 uniqueId. 默认 uniqueId 为空\n引用服务 SOFAArk 提供了两种方式引用插件服务，在插件内部，可以直接使用 PluginContext 引用服务，PluginContext 提供了两个简单的方法引用服务：\n/** * Get Service publish by plugin, when there are multiple services, return the highest priority plugin service * @param ifClass service interface * @param \u0026amp;lt;T\u0026amp;gt; * @return service reference */ \u0026amp;lt;T\u0026amp;gt; ServiceReference\u0026amp;lt;T\u0026amp;gt; referenceService(Class\u0026amp;lt;T\u0026amp;gt; ifClass); /** * Get Service publish by one specific plugin * @param ifClass service interface * @param \u0026amp;lt;T\u0026amp;gt; * @param uniqueId service implementation * @return service reference */ \u0026amp;lt;T\u0026amp;gt; ServiceReference\u0026amp;lt;T\u0026amp;gt; referenceService(Class\u0026amp;lt;T\u0026amp;gt; ifClass, String uniqueId); 在 Biz 内部，如果是 Spring Boot/SOFABoot 应用，可以直接使用注解 @ArkInject 引用服务，注解声明如下：\n@java.lang.annotation.Target(ElementType.FIELD) @java.lang.annotation.Retention(java.lang.annotation.RetentionPolicy.RUNTIME) @java.lang.annotation.Documented public @interface ArkInject { /** * ark service interface * @return */ Class\u0026amp;lt;?\u0026amp;gt; interfaceType() default void.class; /** * ark service uniqueId * * @return return reference unique-id */ String uniqueId() default \u0026amp;#34;\u0026amp;#34;; } SOFAArk 提供集成 Spring Boot/SOFABoot 功能，在 Field 上打上 @ArkInject，指定接口类型和 uniqueId 即可完成自动注入。为了更加方便的使用，如果没有指定 interfacetType 类型，默认使用被打注解的 Field 类型。\n在插件内部，有时候也可以使用 @ArkInject 引用服务，即插件在发布某个服务时，服务内部可以直接使用 @ArkInject 引用服务；需要注意的是，被引用的服务如果是其他插件发布的，则必须满足其他插件优先当前插件启动。\n默认服务 前面提到，为了方便 Plugin 和 Biz 开发高级特性，SOFAArk 将内部功能组件发布成服务，包括：\n BizManageService   Biz 管理器，管理、查询 Biz 信息\n  BizFactoryService   Biz 解析器，解析 Biz 文件\n  PluginManagerService   Plugin 管理器，管理、查询 Plugin 信息\n  PluginFactoryService   Plugin 解析器，解析 Plugin 文件\n  EventAdminService   SOFAArk 事件管理器，管理事件监听器以及发布事件\n  RegistryService   插件服务管理器，真 …","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-ark-service/","fuzzywordcount":1200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"81b7e697b890139c03831cdb648e094b","permalink":"/projects/sofa-boot/sofa-ark-ark-service/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/sofa-boot/sofa-ark-ark-service/","summary":"SOFAArk 定义了两种服务类型，用于解决应用和插件，应用和应用之间的通信问题，下面分别介绍这两种服务类型： 插件服务 SOFAArk 允许在 Plugin 通过 PluginContext 发布和引用服务，也可","tags":null,"title":"Ark 服务机制","type":"projects","url":"/projects/sofa-boot/sofa-ark-ark-service/","wordcount":1182},{"author":null,"categories":null,"content":"在 Ark 服务机制 中，我们详细介绍了如何引用和发布插件服务，主要是解决 Plugin 和 Biz 的通信问题；为了解决 Biz 之间的通信问题，SOFAArk 引入了 SOFABoot 提供的 SofaService/SofaReference 编程界面；下面介绍其使用方法。\n引入依赖 引入 runtime-sofa-boot-plugin 依赖，如果应用基于 Spring Boot 1.x 开发，推荐使用 v2.6.1 版本；如果应用基于 Spring Boot 2.x 开发，推荐使用 v3.1.3 版本；\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;runtime-sofa-boot-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${sofa.boot.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 发布和引用 JVM 服务 SOFAArk 引入了 SOFABoot 提供的 SofaService/SofaReference JVM 服务概念(参考文档)，为了方便文档统一，重复其介绍。\nSOFABoot 提供三种方式给开发人员发布和引用 JVM 服务\n XML 方式 Annotation 方式 编程 API 方式  XML 方式 服务发布 首先需要定义一个 Bean：\n\u0026amp;lt;bean id=\u0026amp;#34;sampleService\u0026amp;#34; class=\u0026amp;#34;com.alipay.sofa.runtime.test.service.SampleServiceImpl\u0026amp;#34;\u0026amp;gt; 然后通过 SOFA 提供的 Spring 扩展标签来将上面的 Bean 发布成一个 SOFA JVM 服务。\n\u0026amp;lt;sofa:service interface=\u0026amp;#34;com.alipay.sofa.runtime.test.service.SampleService\u0026amp;#34; ref=\u0026amp;#34;sampleService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.jvm/\u0026amp;gt; \u0026amp;lt;/sofa:service\u0026amp;gt; 上面的配置中的 interface 指的是需要发布成服务的接口，ref 指向的是需要发布成 JVM 服务的 Bean，至此，我们就已经完成了一个 JVM 服务的发布。\n服务引用 使用 SOFA 提供的 Spring 扩展标签引用服务:\n\u0026amp;lt;sofa:reference interface=\u0026amp;#34;com.alipay.sofa.runtime.test.service.SampleService\u0026amp;#34; id=\u0026amp;#34;sampleServiceRef\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.jvm/\u0026amp;gt; \u0026amp;lt;/sofa:service\u0026amp;gt; 上面的配置中的 interface 是服务的接口，需要和发布服务时配置的 interface 一致。id 属性的含义同 Spring BeanId。上面的配置会生成一个 id 为 sampleServiceRef 的 Spring Bean，你可以将 sampleServiceRef 这个 Bean 注入到当前 SOFABoot 模块 Spring 上下文的任意地方。\n service/reference 标签还支持 RPC 服务发布，相关文档: RPC 服务发布与引用\n Annotation 方式  警告\n如果一个服务已经被加上了 @SofaService 的注解，它就不能再用 XML 的方式去发布服务了，选择一种方式发布服务，而不是两种混用。\n 除了通过 XML 方式发布 JVM 服务和引用之外，SOFABoot 还提供了 Annotation 的方式来发布和引用 JVM 服务。通过 Annotation 方式发布 JVM 服务，只需要在实现类上加一个 @SofaService 注解即可，如下：\n@SofaService public class SampleImpl implements SampleInterface { public void test() { } }  提示\n@SofaService 的作用是将一个 Bean 发布成一个 JVM 服务，这意味着虽然你可以不用再写 \u0026amp;lt;sofa:service/\u0026amp;gt; 的配置，但是还是需要事先将 @SofaService 所注解的类配置成一个 Spring Bean。\n 在使用 XML 配置 \u0026amp;lt;sofa:service/\u0026amp;gt; 的时候，我们配置了一个 interface 属性，但是在使用 @SofaService 注解的时候，却没有看到有配置服务接口的地方。这是因为当被 @SofaService 注解的类只有一个接口的时候，框架会直接采用这个接口作为服务的接口。当被 @SofaService 注解的类实现了多个接口时，可以设置 @SofaService 的 interfaceType 字段来指定服务接口，比如下面这样：\n@SofaService(interfaceType=SampleInterface.class) public class SampleImpl implements SampleInterface, Serializable { public void test() { } } 和 @SofaService 对应，Sofa 提供了 @SofaReference 来引用一个 JVM 服务。假设我们需要在一个 Spring Bean 中使用 SampleJvmService 这个 JVM 服务，那么只需要在字段上加上一个 @SofaReference 的注解即可：\npublic class SampleServiceRef { @SofaReference private SampleService sampleService; } 和 @SofaService 类似，我们也没有在 @SofaReference 上指定服务接口，这是因为 @SofaReference 在不指定服务接口的时候，会采用被注解字段的类型作为服务接口，你也可以通过设定 @SofaReference 的 interfaceType 属性来指定：\npublic class SampleServiceRef { @SofaReference(interfaceType=SampleService.class) private SampleService sampleService; } 使用 @SofaService 注解发布服务时，需要在实现类上打上 @SofaService 注解；在 Spring Boot 使用 Bean Method 创建 Bean 时，会导致 @Bean 和 @SofaService 分散在两处，而且无法对同一个实现类使用不同的 unique id。因此自 SOFABoot v2.6.0 及 v3.1.0 版本 …","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-ark-jvm/","fuzzywordcount":2500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"1bf80b24428da0f91edc6af7b63f6047","permalink":"/projects/sofa-boot/sofa-ark-ark-jvm/","publishdate":"0001-01-01T00:00:00Z","readingtime":5,"relpermalink":"/projects/sofa-boot/sofa-ark-ark-jvm/","summary":"在 Ark 服务机制 中，我们详细介绍了如何引用和发布插件服务，主要是解决 Plugin 和 Biz 的通信问题；为了解决 Biz 之间的通信问题，SOFAArk 引入了 SOFABoot 提供的 SofaService/SofaReference 编","tags":null,"title":"Ark 服务通信","type":"projects","url":"/projects/sofa-boot/sofa-ark-ark-jvm/","wordcount":2436},{"author":null,"categories":null,"content":"Use java.lang.Runnable in thread If you start a thread via java.lang.Runnable in the code or use a thread pool to process some businesses asynchronously, SOFATracer log context needs to be passed from the parent thread to the child thread. com.alipay.common.tracer.core.async.SofaTracerRunnable provided by SOFATracer is reponsible for completing this operation by default. You can use it as follows:\nThread thread = new Thread(new SofaTracerRunnable(new Runnable() { @Override public void run() { //do something your business code  } })); thread.start(); Use java.util.concurrent.Callable in thread If you start a thread via java.util.concurrent.Callable in the code or use a thread pool to process some businesses asynchronously, SOFATracer log context needs to be passed from the parent thread to the child thread. com.alipay.common.tracer.core.async.SofaTracerCallable provided by SOFATracer is reponsible for completing this operation by default. You can use it as follows:\nExecutorService executor = Executors.newCachedThreadPool(); SofaTracerCallable\u0026amp;lt;Object\u0026amp;gt; sofaTracerSpanSofaTracerCallable = new SofaTracerCallable\u0026amp;lt;Object\u0026amp;gt;(new Callable\u0026amp;lt;Object\u0026amp;gt;() { @Override public Object call() throws Exception { return new Object(); } }); Future\u0026amp;lt;Object\u0026amp;gt; futureResult = executor.submit(sofaTracerSpanSofaTracerCallable); //do something in current thread  Thread.sleep(1000); //another thread execute success and get result  Object objectReturn = futureResult.get(); This example assumes that the object type returned by java.util.concurrent.Callable is java.lang.Object. You can replace it with the expected type based on actual situation.\nSOFATracer support for thread pool and asynchronous call scenarios Asynchronous  Asynchronous invocation, in RPC calls, for example,each time the rpc call request goes out, it will not wait until the result is returned before initiating the next call. There is a time difference here, before the callback of the previous rpc call comes back, another new one begin. At this time, the TracerContext in the current thread is not cleaned up, the spanId will be incremented, and the tracerId is the same.\n For the above situation, when the SOFATracer is processed for the asynchronous situation, it will not wait for the callback to execute, and then the cr phase will be cleaned up. Instead, the current thread\u0026amp;rsquo;s tracerContext context will be cleaned up in advance to ensure the correctness of the link.\nThread Pool For now, whether it\u0026amp;rsquo;s SOFARPC or Dubbo\u0026amp;rsquo;s trace implementation, the situation is the same when using single-thread or thread pools:\n Synchronous call. A thread in the thread pool is allocated to handle the RPC request. This does not cause the next RPC request to take the tracerContext data of the previous request by mistake Asynchronous calls, since the asynchronous callback is not in the callback to clean up the context, but in advance, there is no dirty data problem. callback, which is essentially an …","date":-62135596800,"description":"","dir":"projects/sofa-tracer/async/","fuzzywordcount":500,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"e755346c441115663c101638667fe4c0","permalink":"/en/projects/sofa-tracer/async/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/en/projects/sofa-tracer/async/","summary":"Use java.lang.Runnable in thread If you start a thread via java.lang.Runnable in the code or use a thread pool to process some businesses asynchronously, SOFATracer log context needs to be passed from the parent thread to the child thread. com.alipay.common.tracer.core.async.SofaTracerRunnable provided by SOFATracer is reponsible for completing this operation by default. You can use it as follows:\nThread thread = new Thread(new SofaTracerRunnable(new Runnable() { @Override public void run() { //do something your business code  } })); thread.","tags":null,"title":"Asynchronous thread processing","type":"projects","url":"/en/projects/sofa-tracer/async/","wordcount":436},{"author":null,"categories":null,"content":"﻿## Model\nApplications Jarslink manages the life cycle of multiple applications. During runtime dynamic deployment, it usually converts a Jar file entity into an abstract model Biz.\n Biz: abstract model of the application at runtime  Instruction Currently, Jarslink supports the telnet protocol and accepts the entered instructions. In the future, it will also support instruction execution through APIs. Acceptable instruction types:\n InstallCommand: install the application UninstallCommand: uninstall the application CheckCommand: check the application state SwitchCommand: switch the application state  Service The Jarslink plugin has expanded the SOFAArk container\u0026amp;rsquo;s services of BizDeployer and CommandProvider and referenced the SOFAArk container\u0026amp;rsquo;s exposed services of BizManagerService and BizFactoryService.\n BizDeployer is the application deployment extension point provided by the SOFAArk container, and it is used to control the Biz startup in the Ark package. Jarslink has registered its own implementation with the SOFAArk container. CommandProvider is the command processing extension point provided by the SOFAArk container, and it is used to process the commands received by the SOFAArk container through a telnet link. BizManagerService is the Biz manager exposed by the SOFAArk container, and it is used for registration, deregistration, and other operations. BizFactoryService is the Biz generator exposed by the SOFAArk container, and it is used to abstract static Biz package files into runtime Biz models.  ","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-jarslink-model/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"991cb277d50874fa27095b920ac9b736","permalink":"/en/projects/sofa-boot/sofa-jarslink-model/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-boot/sofa-jarslink-model/","summary":"﻿## Model\nApplications Jarslink manages the life cycle of multiple applications. During runtime dynamic deployment, it usually converts a Jar file entity into an abstract model Biz.\n Biz: abstract model of the application at runtime  Instruction Currently, Jarslink supports the telnet protocol and accepts the entered instructions. In the future, it will also support instruction execution through APIs. Acceptable instruction types:\n InstallCommand: install the application UninstallCommand: uninstall the application CheckCommand: check the application state SwitchCommand: switch the application state  Service The Jarslink plugin has expanded the SOFAArk container\u0026rsquo;s services of BizDeployer and CommandProvider and referenced the SOFAArk container\u0026rsquo;s exposed services of BizManagerService and BizFactoryService.","tags":null,"title":"Basic model","type":"projects","url":"/en/projects/sofa-boot/sofa-jarslink-model/","wordcount":212},{"author":null,"categories":null,"content":"Messages All messages are internally passed through SofaRequest and SofaResponse.\nTo convert to other protocols, you need to transform the messages to the objects that are to be actually transferred when calling and receiving requests.\nThe modules that can write SofaRequest and SofaResponse are as follows:\n Invoker Filter ServerHandler Serialization  The modules that can only read message bodies are as follows:\n Cluster Router LoadBalance  Logs The log initialization is based on the extension mechanism. Since the log loading should be done earliest, there is a separate key in rpc-config.json.\n{ / / Log implementation is done earlier than configuration loading, so it cannot adapt to the extension mechanism \u0026amp;#34;logger.impl\u0026amp;#34;: \u0026amp;#34;com.alipay.sofa.rpc.log.MiddlewareLoggerImpl\u0026amp;#34; } Configuration items RPC configuration for users The user configuration includes port configuration (although the fields for setting port in the objects have been opened, SOFA gets those fields from the configuration file by default), thread pool size configuration, and other configurations.\n Load the configuration via SofaConfigs and call ExternalConfigLoader to read external properties. Get the configuration through the API provided by SofaConfigs. All the internally configured keys are in the SofaOptions class. Priority: System.property \u0026amp;gt; sofa-config.properties (one for each application) \u0026amp;gt; rpc-config.properties.  RPC framework configuration The configuration of the framework itself, such as default serialization and default timeout. In the future, SOFARPC may support the configuration for multiple ClassLoaders.\n Load the configuration file via RpcConfigs. Get and listen to data changes via the API provided by RpcConfigs All internally configured keys are in the RpcOptions class Priority: System.property \u0026amp;gt; custom rpc-config.json (There may be multiple custom configuration files which are sorted in certain order) \u0026amp;gt; rpc-config-default.json.  Constants   The global basic constants are in RpcConstants. For example:  Calling method (sync/oneway) Protocol (bolt/grpc/rest); serialization (hessian/java/protobuf) Context key    If the extension implements its own constants, you need to maintain the constants yourself. For example:\n The constants of BOLT protocol  SERIALIZE_CODE_HESSIAN = 1 PROTOCOL_TR = 13   The constants related with DSR Configuration Center  The keys specific for DSR Configuration Center, such as _WEIGHT and _CONNECTTIMEOUT      Address  The address information of provider is placed in the ProviderInfo class. The value of ProviderInfo is mainly divided into three parts:  Fields, which are generally required items, such as IP, port and status. Static fields, such as application name. Dynamic fields, such as warm-up weight.   Field enumerations are maintained in the ProviderInfoAttrs class.  ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/common-model/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"b2cc3f7ed134408d6adc25e418e1978b","permalink":"/en/projects/sofa-rpc/common-model/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-rpc/common-model/","summary":"Messages All messages are internally passed through SofaRequest and SofaResponse.\nTo convert to other protocols, you need to transform the messages to the objects that are to be actually transferred when calling and receiving requests.\nThe modules that can write SofaRequest and SofaResponse are as follows:\n Invoker Filter ServerHandler Serialization  The modules that can only read message bodies are as follows:\n Cluster Router LoadBalance  Logs The log initialization is based on the extension mechanism.","tags":null,"title":"Basic model","type":"projects","url":"/en/projects/sofa-rpc/common-model/","wordcount":386},{"author":null,"categories":null,"content":"Publish Service To use SOFARPC to publish a Bolt-protocol service, you only need to add a Binding named bolt. The ways to add Bolt Binding are as follows:\nXML To publish a Bolt service using XML, simply add the \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; tag to the \u0026amp;lt;sofa:service\u0026amp;gt; tag:\n\u0026amp;lt;sofa:service ref=\u0026amp;#34;sampleService\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofa.rpc.sample.SampleService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt/\u0026amp;gt; \u0026amp;lt;/sofa:service\u0026amp;gt; Annotation To publish a Bolt service using Annotation, you only need to set the bindingType of @SofaServiceBinding to bolt:\n@Service @SofaService(bindings = {@SofaServiceBinding(bindingType = \u0026amp;#34;bolt\u0026amp;#34;)}) Public class SampleServiceImpl implements SampleService { } API in Spring environment To publish a Bolt-protocol service in Spring or Spring Boot environment, just add BoltBindingParam to ServiceParam:\nServiceParam serviceParam = new ServiceParam(); serviceParam.setInterfaceType(SampleService.class); // Set the service interface serviceParam.setInstance(new SampleServiceImpl()); // Set the implementation of the service interface  List\u0026amp;lt;BindingParam\u0026amp;gt; params = new ArrayList\u0026amp;lt;BindingParam\u0026amp;gt;(); BindingParam serviceBindingParam = new BoltBindingParam(); Params.add(serviceBindingParam); serviceParam.setBindingParams(params); API in non-Spring environment To provide the Bolt-protocol service using the bare API of SOFARPC in a non-Spring environment, just set the ServerConfig whose protocol is Bolt to the corresponding ProviderConfig:\nRegistryConfig registryConfig = new RegistryConfig() .setProtocol(\u0026amp;#34;zookeeper\u0026amp;#34;) .setAddress(\u0026amp;#34;127.0.0.1:2181\u0026amp;#34;); // Create a new ServerConfig with Bolt protocol ServerConfig serverConfig = new ServerConfig() .setPort(8803) .setProtocol(\u0026amp;#34;bolt\u0026amp;#34;); ProviderConfig\u0026amp;lt;SampleService\u0026amp;gt; providerConfig = new ProviderConfig\u0026amp;lt;SampleService\u0026amp;gt;() .setInterfaceId(SampleService.class.getName()) .setRef(new SampleServiceImpl()) .setServer(serverConfig) // Set ServerConfig to ProviderConfig to indicate that the protocol published by this service is Bolt.  .setRegistry(registryConfig); providerConfig.export(); Reference Service To reference a Bolt-protocol service using SOFARPC, just add a Binding named bolt. The ways to use Bolt Binding are as follows:\nXML To reference a Bolt-protocol service using XML, simply add the \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; tag to the \u0026amp;lt;sofa:reference\u0026amp;gt; tag:\n\u0026amp;lt;sofa:reference id=\u0026amp;#34;sampleService\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofa.rpc.sample.SampleService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt/\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt; Annotation To reference a Bolt-protocol service using Annotation, just set the bindingType of @SofaReferenceBinding to bolt:\n@SofaReference(binding = @SofaReferenceBinding(bindingType = \u0026amp;#34;bolt\u0026amp;#34;)) Private SampleService sampleService; API in Spring environment To reference a Bolt-protocol service in a Spring or Spring Boot environment, simply add a BoltBindingParam to ReferenceParam:\nReferenceClient referenceClient = …","date":-62135596800,"description":"","dir":"projects/sofa-rpc/bolt-usage/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"dd929c0a3cd2f4620ddf0d30d98ba85d","permalink":"/en/projects/sofa-rpc/bolt-usage/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-rpc/bolt-usage/","summary":"Publish Service To use SOFARPC to publish a Bolt-protocol service, you only need to add a Binding named bolt. The ways to add Bolt Binding are as follows:\nXML To publish a Bolt service using XML, simply add the \u0026lt;sofa:binding.bolt\u0026gt; tag to the \u0026lt;sofa:service\u0026gt; tag:\n\u0026lt;sofa:service ref=\u0026#34;sampleService\u0026#34; interface=\u0026#34;com.alipay.sofa.rpc.sample.SampleService\u0026#34;\u0026gt; \u0026lt;sofa:binding.bolt/\u0026gt; \u0026lt;/sofa:service\u0026gt; Annotation To publish a Bolt service using Annotation, you only need to set the bindingType of @SofaServiceBinding to bolt:\n@Service @SofaService(bindings = {@SofaServiceBinding(bindingType = \u0026#34;bolt\u0026#34;)}) Public class SampleServiceImpl implements SampleService { } API in Spring environment To publish a Bolt-protocol service in Spring or Spring Boot environment, just add BoltBindingParam to ServiceParam:","tags":null,"title":"Basic usage of Bolt protocol","type":"projects","url":"/en/projects/sofa-rpc/bolt-usage/","wordcount":364},{"author":null,"categories":null,"content":"In SOFARPC, to use different communication protocols, it is only required to use different Bindings. If you need to use the Dubbo protocol, just set Binding to Dubbo. The following shows an example using Annotation. For other usage methods, refer to Basic usage of Bolt protocol.\nPublish Service To publish a Dubbo service, just set the bindingType of @SofaServiceBinding to dubbo:\n@Service @SofaService(bindings = {@SofaServiceBinding(bindingType = \u0026amp;#34;dubbo\u0026amp;#34;)}) public class SampleServiceImpl implements SampleService { } Reference Service To reference a Dubbo service, just set the bindingType of @SofaReferenceBinding to dubbo:\n@SofaReference(binding = @SofaReferenceBinding(bindingType = \u0026amp;#34;dubbo\u0026amp;#34;), jvmFirst = false) private SampleService sampleService; Set the Group of Dubbo Service In the SOFARPC program model, there is no field called Group, but there is a model of uniqueId, which can be directly mapped to the Group in Dubbo model. For example, the following code is to publish a service whose Group is groupDemo:\n@Service @SofaService(bindings = {@SofaServiceBinding(bindingType = \u0026amp;#34;dubbo\u0026amp;#34;)}, uniqueId = \u0026amp;#34;groupDemo\u0026amp;#34;) public class SampleServiceImpl implements SampleService { } The following code is to reference a service whose Group is groupDemo:\n@SofaReference(binding = @SofaReferenceBinding(bindingType = \u0026amp;#34;dubbo\u0026amp;#34;), uniqueId = \u0026amp;#34;groupDemo\u0026amp;#34;, jvmFirst = false) private SampleService sampleService;  Note that Dubbo protocol currently only supports Zookeeper as service registry center.\n ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/dubbo-usage/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"1bf72c194a20a5dccea70423690191f4","permalink":"/en/projects/sofa-rpc/dubbo-usage/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/dubbo-usage/","summary":"In SOFARPC, to use different communication protocols, it is only required to use different Bindings. If you need to use the Dubbo protocol, just set Binding to Dubbo. The following shows an example using Annotation. For other usage methods, refer to Basic usage of Bolt protocol.\nPublish Service To publish a Dubbo service, just set the bindingType of @SofaServiceBinding to dubbo:\n@Service @SofaService(bindings = {@SofaServiceBinding(bindingType = \u0026#34;dubbo\u0026#34;)}) public class SampleServiceImpl implements SampleService { } Reference Service To reference a Dubbo service, just set the bindingType of @SofaReferenceBinding to dubbo:","tags":null,"title":"Basic usage of Dubbo protocol","type":"projects","url":"/en/projects/sofa-rpc/dubbo-usage/","wordcount":203},{"author":null,"categories":null,"content":"In SOFARPC, to use different communication protocols, it is only required to use different Bindings. If you need to use the H2C protocol, just set Binding to H2C. The following shows an example using Annotation. For other usage methods, refer to Basic usage of Bolt protocol.\nPublish Service To publish an H2C service, just set the bindingType of @SofaServiceBinding to h2c:\n@Service @SofaService(bindings = {@SofaServiceBinding(bindingType = \u0026amp;#34;h2c\u0026amp;#34;)}) public class SampleServiceImpl implements SampleService { } Reference Service To reference a H2C service, just set the bindingType of @SofaReferenceBinding to h2c:\n@SofaReference(binding = @SofaReferenceBinding(bindingType = \u0026amp;#34;h2c\u0026amp;#34;), jvmFirst = false) private SampleService sampleService; ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/h2c-usage/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"fa75eff1e99b3acad5087160a1b44a09","permalink":"/en/projects/sofa-rpc/h2c-usage/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/h2c-usage/","summary":"In SOFARPC, to use different communication protocols, it is only required to use different Bindings. If you need to use the H2C protocol, just set Binding to H2C. The following shows an example using Annotation. For other usage methods, refer to Basic usage of Bolt protocol.\nPublish Service To publish an H2C service, just set the bindingType of @SofaServiceBinding to h2c:\n@Service @SofaService(bindings = {@SofaServiceBinding(bindingType = \u0026#34;h2c\u0026#34;)}) public class SampleServiceImpl implements SampleService { } Reference Service To reference a H2C service, just set the bindingType of @SofaReferenceBinding to h2c:","tags":null,"title":"Basic usage of H2C protocol","type":"projects","url":"/en/projects/sofa-rpc/h2c-usage/","wordcount":100},{"author":null,"categories":null,"content":"In SOFARPC (Not In SOFABoot/SpringBoot)，when use Http as a protocol of server，we can use Json as the way of serialization，for some basic test scenes.\nSOFARPC API Usage Service Publish ServerConfig serverConfig = new ServerConfig() .setStopTimeout(60000) .setPort(12300) .setProtocol(RpcConstants.PROTOCOL_TYPE_HTTP) .setDaemon(true); ProviderConfig\u0026amp;lt;HttpService\u0026amp;gt; providerConfig = new ProviderConfig\u0026amp;lt;HttpService\u0026amp;gt;() .setInterfaceId(HttpService.class.getName()) .setRef(new HttpServiceImpl()) .setApplication(new ApplicationConfig().setAppName(\u0026amp;#34;serverApp\u0026amp;#34;)) .setServer(serverConfig) .setUniqueId(\u0026amp;#34;uuu\u0026amp;#34;) .setRegister(false); providerConfig.export(); Service Consume Because of the Http+Json，So users can use HttpClient to start a normal call, this is a piece of code in test.\nprivate ObjectMapper mapper = new ObjectMapper(); HttpClient httpclient = HttpClientBuilder.create().build(); // POST normal request String url = \u0026amp;#34;http://127.0.0.1:12300/com.alipay.sofa.rpc.server.http.HttpService:uuu/object\u0026amp;#34;; HttpPost httpPost = new HttpPost(url); httpPost.setHeader(RemotingConstants.HEAD_SERIALIZE_TYPE, \u0026amp;#34;json\u0026amp;#34;); ExampleObj obj = new ExampleObj(); obj.setId(1); obj.setName(\u0026amp;#34;xxx\u0026amp;#34;); byte[] bytes = mapper.writeValueAsBytes(obj); ByteArrayEntity entity = new ByteArrayEntity(bytes, ContentType.create(\u0026amp;#34;application/json\u0026amp;#34;)); httpPost.setEntity(entity); HttpResponse httpResponse = httpclient.execute(httpPost); Assert.assertEquals(200, httpResponse.getStatusLine().getStatusCode()); byte[] data = EntityUtils.toByteArray(httpResponse.getEntity()); ExampleObj result = mapper.readValue(data, ExampleObj.class); Assert.assertEquals(\u0026amp;#34;xxxxx\u0026amp;#34;, result.getName()); You will get some result.\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/http-json/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"28abdf6369247346bad670c639a422b8","permalink":"/en/projects/sofa-rpc/http-json/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/http-json/","summary":"In SOFARPC (Not In SOFABoot/SpringBoot)，when use Http as a protocol of server，we can use Json as the way of serialization，for some basic test scenes.\nSOFARPC API Usage Service Publish ServerConfig serverConfig = new ServerConfig() .setStopTimeout(60000) .setPort(12300) .setProtocol(RpcConstants.PROTOCOL_TYPE_HTTP) .setDaemon(true); ProviderConfig\u0026lt;HttpService\u0026gt; providerConfig = new ProviderConfig\u0026lt;HttpService\u0026gt;() .setInterfaceId(HttpService.class.getName()) .setRef(new HttpServiceImpl()) .setApplication(new ApplicationConfig().setAppName(\u0026#34;serverApp\u0026#34;)) .setServer(serverConfig) .setUniqueId(\u0026#34;uuu\u0026#34;) .setRegister(false); providerConfig.export(); Service Consume Because of the Http+Json，So users can use HttpClient to start a normal call, this is a piece of code in test.","tags":null,"title":"Basic usage of HTTP protocol","type":"projects","url":"/en/projects/sofa-rpc/http-json/","wordcount":140},{"author":null,"categories":null,"content":"In SOFARPC, using different communication protocols is equal to using different Bindings. If you need to use the RESTful protocol, just set Binding to REST.\nPublish Service When defining a RESTful service interface, you need to add meta information to the interface using the annotations in JAXRS standard, such as the following interface:\n@Path(\u0026amp;#34;sample\u0026amp;#34;) public interface SampleService { @GET @Path(\u0026amp;#34;hello\u0026amp;#34;) String hello(); }  The annotations in JAXRS standard can be found in RESTEasy documentation.\n After the interface is defined, you can publish the implementation of the interface as a service, for example, by means of Annotation:\n@Service @SofaService(bindings = {@SofaServiceBinding(bindingType = \u0026amp;#34;rest\u0026amp;#34;)}) public class RestfulSampleServiceImpl implements SampleService { @Override public String hello() { return \u0026amp;#34;Hello\u0026amp;#34;; } } If you want to publish the service by other methods, please refer to Basic usage of Bolt protocol.\nAccess services through browser After the service is published, you can directly access the service through the browser. For the above service, the access address is as follows:\nhttp://localhost:8341/sample/hello The default port for SOFARPC RESTful service is 8341.\nReference Service In addition to accessing RESTful services published by SOFARPC through a browser, you can also reference services through the standard SOFARPC service reference methods, such as Annotation:\n@SofaReference(binding = @SofaReferenceBinding(bindingType = \u0026amp;#34;rest\u0026amp;#34;)) private SampleService sampleService; If you want to reference the service by other methods, please refer to Basic usage of Bolt protocol.\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/restful-basic/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"d41f976864ba8f8221f5b5d26f354d1c","permalink":"/en/projects/sofa-rpc/restful-basic/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-rpc/restful-basic/","summary":"In SOFARPC, using different communication protocols is equal to using different Bindings. If you need to use the RESTful protocol, just set Binding to REST.\nPublish Service When defining a RESTful service interface, you need to add meta information to the interface using the annotations in JAXRS standard, such as the following interface:\n@Path(\u0026#34;sample\u0026#34;) public interface SampleService { @GET @Path(\u0026#34;hello\u0026#34;) String hello(); }  The annotations in JAXRS standard can be found in RESTEasy documentation.","tags":null,"title":"Basic usage of RESTful protocol","type":"projects","url":"/en/projects/sofa-rpc/restful-basic/","wordcount":228},{"author":null,"categories":null,"content":"Test code\nTest environment and conditions  Three 16-core 20 GB memory Docker containers as the server nodes (3 replicas) Two to eight 8-core Docker containers as clients 24 Raft groups. Each server node has eight leaders responsible for processing read/right requests. Followers do not have the permission to read. The target of stress testing is the RheaKV module of JRaft. Only the put and get APIs are subject to stress testing. Linearizable reads are guaranteed for the get API. The key size and value size are both 16 bytes. The read percentage is 10% and the write percentage is 90%.  Currently, the test scenarios are relatively simple. We will add more test scenarios in the future.\nTest scenario 1 Scenario 1: Test conditions    Number of clients Client batching Storage type Read/write ratio Replicator pipeline Key size Value size     8 Enabled MemoryDB 1:9 Enabled 16 bytes 16 bytes    Scenario 1: Result summary  Eight clients achieved 400,000+ ops, and the p95 RT is within 8 ms. Three server nodes didn\u0026amp;rsquo;t reach their maximum load. The load is about 15, and the CPU usage is about 40%.  Scenario 1: Load of three servers Scenario 1: Server 1 top - 20:11:14 up 10 days, 23:09, 1 user, load average: 12.29, 6.92, 4.00 Tasks: 36 total, 1 running, 35 sleeping, 0 stopped, 0 zombie %Cpu0 : 24.3 us, 17.7 sy, 0.0 ni, 50.0 id, 2.0 wa, 0.0 hi, 0.0 si, 6.0 st %Cpu1 : 21.9 us, 18.5 sy, 0.0 ni, 49.5 id, 2.0 wa, 0.0 hi, 0.0 si, 8.1 st %Cpu2 : 20.6 us, 18.6 sy, 0.0 ni, 53.2 id, 2.0 wa, 0.0 hi, 0.0 si, 5.6 st %Cpu3 : 23.3 us, 20.0 sy, 0.0 ni, 50.3 id, 1.3 wa, 0.0 hi, 0.0 si, 5.0 st %Cpu4 : 24.1 us, 19.1 sy, 0.0 ni, 49.8 id, 2.3 wa, 0.0 hi, 0.0 si, 4.7 st %Cpu5 : 21.3 us, 18.9 sy, 0.0 ni, 53.2 id, 2.0 wa, 0.0 hi, 0.0 si, 4.7 st %Cpu6 : 24.7 us, 18.4 sy, 0.0 ni, 50.2 id, 2.0 wa, 0.0 hi, 0.0 si, 4.7 st %Cpu7 : 24.8 us, 17.8 sy, 0.0 ni, 50.0 id, 1.7 wa, 0.0 hi, 0.0 si, 5.7 st %Cpu8 : 26.0 us, 18.3 sy, 0.0 ni, 51.3 id, 2.3 wa, 0.0 hi, 0.0 si, 2.0 st %Cpu9 : 26.6 us, 16.9 sy, 0.0 ni, 52.2 id, 2.0 wa, 0.0 hi, 0.0 si, 2.3 st %Cpu10 : 31.7 us, 17.7 sy, 0.0 ni, 46.3 id, 2.3 wa, 0.0 hi, 0.0 si, 2.0 st %Cpu11 : 23.2 us, 18.9 sy, 0.0 ni, 53.3 id, 2.3 wa, 0.0 hi, 0.0 si, 2.3 st %Cpu12 : 25.6 us, 18.3 sy, 0.0 ni, 51.5 id, 2.3 wa, 0.0 hi, 0.0 si, 2.3 st %Cpu13 : 22.6 us, 18.3 sy, 0.0 ni, 54.5 id, 2.3 wa, 0.0 hi, 0.0 si, 2.3 st %Cpu14 : 24.7 us, 17.3 sy, 0.0 ni, 54.0 id, 1.7 wa, 0.0 hi, 0.0 si, 2.3 st %Cpu15 : 61.8 us, 8.3 sy, 0.0 ni, 28.2 id, 0.3 wa, 0.0 hi, 0.0 si, 1.3 st KiB Mem : 62914560 total, 6854596 free, 39128016 used, 16931948 buff/cache KiB Swap: 2097148 total, 2097148 free, 0 used. 6854596 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 15682 root 20 0 12.853g 8.859g 24064 S 708.7 14.8 26:49.38 java Scenario 1: Server 2 top - 20:11:47 up 10 days, 23:03, 1 user, load average: 17.68, 8.50, 4.56 Tasks: 33 total, 1 running, 31 sleeping, 0 stopped, 1 zombie %Cpu0 : 22.7 us, 17.3 sy, 0.0 ni, 35.0 id, 8.3 wa, 0.0 hi, 0.0 si, 16.7 st %Cpu1 : 20.1 us, 19.4 sy, …","date":-62135596800,"description":"","dir":"projects/sofa-jraft/benchmark-performance/","fuzzywordcount":8900,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"4530827525ca87732eaf76ae34f03603","permalink":"/en/projects/sofa-jraft/benchmark-performance/","publishdate":"0001-01-01T00:00:00Z","readingtime":42,"relpermalink":"/en/projects/sofa-jraft/benchmark-performance/","summary":"Test code\nTest environment and conditions  Three 16-core 20 GB memory Docker containers as the server nodes (3 replicas) Two to eight 8-core Docker containers as clients 24 Raft groups. Each server node has eight leaders responsible for processing read/right requests. Followers do not have the permission to read. The target of stress testing is the RheaKV module of JRaft. Only the put and get APIs are subject to stress testing.","tags":null,"title":"Benchmark data","type":"projects","url":"/en/projects/sofa-jraft/benchmark-performance/","wordcount":8817},{"author":null,"categories":null,"content":"测试代码\n测试环境\u0026amp;amp;条件  3 台 16C 20G 内存的 docker 容器作为 server node (3 副本) 2 ~ 8 台 8C docker 容器 作为 client 24 个 raft 复制组，平均每台 server node 上各自有 8 个 leader 负责读写请求，不开启 follower 读 压测目标为 JRaft 中的 RheaKV 模块，只压测 put、get 两个接口，其中 get 是保证线性一致读的，key 和 value 大小均为 16 字节 读比例 10%，写比例 90%  目前的测试场景比较简单，以后会增加更多测试场景\n测试场景1 场景1: 测试条件    Client 数量 Client-Batching Storage-Type 读写比例 Replicator-Pipeline key 大小 value 大小     8 开启 MemoryDB 1:9 开启 16 字节 16字节    场景1: 结果汇总：  8 个 client 一共达到 40w+ ops，p95 RT 在 8ms 以内 3 个 server 节点负载没达到极限 load 15 左右，cpu 40% 左右  场景1: 3 个 server 机器负载： 场景1: server1 top - 20:11:14 up 10 days, 23:09, 1 user, load average: 12.29, 6.92, 4.00 Tasks: 36 total, 1 running, 35 sleeping, 0 stopped, 0 zombie %Cpu0 : 24.3 us, 17.7 sy, 0.0 ni, 50.0 id, 2.0 wa, 0.0 hi, 0.0 si, 6.0 st %Cpu1 : 21.9 us, 18.5 sy, 0.0 ni, 49.5 id, 2.0 wa, 0.0 hi, 0.0 si, 8.1 st %Cpu2 : 20.6 us, 18.6 sy, 0.0 ni, 53.2 id, 2.0 wa, 0.0 hi, 0.0 si, 5.6 st %Cpu3 : 23.3 us, 20.0 sy, 0.0 ni, 50.3 id, 1.3 wa, 0.0 hi, 0.0 si, 5.0 st %Cpu4 : 24.1 us, 19.1 sy, 0.0 ni, 49.8 id, 2.3 wa, 0.0 hi, 0.0 si, 4.7 st %Cpu5 : 21.3 us, 18.9 sy, 0.0 ni, 53.2 id, 2.0 wa, 0.0 hi, 0.0 si, 4.7 st %Cpu6 : 24.7 us, 18.4 sy, 0.0 ni, 50.2 id, 2.0 wa, 0.0 hi, 0.0 si, 4.7 st %Cpu7 : 24.8 us, 17.8 sy, 0.0 ni, 50.0 id, 1.7 wa, 0.0 hi, 0.0 si, 5.7 st %Cpu8 : 26.0 us, 18.3 sy, 0.0 ni, 51.3 id, 2.3 wa, 0.0 hi, 0.0 si, 2.0 st %Cpu9 : 26.6 us, 16.9 sy, 0.0 ni, 52.2 id, 2.0 wa, 0.0 hi, 0.0 si, 2.3 st %Cpu10 : 31.7 us, 17.7 sy, 0.0 ni, 46.3 id, 2.3 wa, 0.0 hi, 0.0 si, 2.0 st %Cpu11 : 23.2 us, 18.9 sy, 0.0 ni, 53.3 id, 2.3 wa, 0.0 hi, 0.0 si, 2.3 st %Cpu12 : 25.6 us, 18.3 sy, 0.0 ni, 51.5 id, 2.3 wa, 0.0 hi, 0.0 si, 2.3 st %Cpu13 : 22.6 us, 18.3 sy, 0.0 ni, 54.5 id, 2.3 wa, 0.0 hi, 0.0 si, 2.3 st %Cpu14 : 24.7 us, 17.3 sy, 0.0 ni, 54.0 id, 1.7 wa, 0.0 hi, 0.0 si, 2.3 st %Cpu15 : 61.8 us, 8.3 sy, 0.0 ni, 28.2 id, 0.3 wa, 0.0 hi, 0.0 si, 1.3 st KiB Mem : 62914560 total, 6854596 free, 39128016 used, 16931948 buff/cache KiB Swap: 2097148 total, 2097148 free, 0 used. 6854596 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 15682 root 20 0 12.853g 8.859g 24064 S 708.7 14.8 26:49.38 java 场景1: server2 top - 20:11:47 up 10 days, 23:03, 1 user, load average: 17.68, 8.50, 4.56 Tasks: 33 total, 1 running, 31 sleeping, 0 stopped, 1 zombie %Cpu0 : 22.7 us, 17.3 sy, 0.0 ni, 35.0 id, 8.3 wa, 0.0 hi, 0.0 si, 16.7 st %Cpu1 : 20.1 us, 19.4 sy, 0.0 ni, 43.8 id, 9.4 wa, 0.0 hi, 0.0 si, 7.4 st %Cpu2 : 23.3 us, 20.0 sy, 0.0 ni, 39.7 id, 10.3 wa, 0.0 hi, 0.0 si, 6.7 st %Cpu3 : 24.1 us, 20.1 sy, 0.0 ni, 40.8 id, 9.4 wa, 0.0 hi, 0.0 si, 5.7 st %Cpu4 : 21.4 us, 17.7 sy, 0.0 ni, 37.1 id, 9.0 wa, 0.0 hi, 0.0 si, 14.7 st %Cpu5 : 22.6 us, 19.6 sy, 0.0 ni, 40.5 id, 10.6 wa, 0.0 hi, 0.0 si, 6.6 st %Cpu6 : 23.6 us, 19.9 sy, 0.0 ni, 40.2 id, 10.3 wa, 0.0 hi, 0.0 si, 6.0 st %Cpu7 : 20.5 us, 19.9 sy, 0.0 ni, 44.4 id, 9.9 wa, 0.0 hi, 0.0 si, 5.3 st %Cpu8 : 40.7 us, 13.3 sy, 0.0 ni, 34.3 id, 9.0 wa, 0.0 hi, 0.0 si, 2.7 st %Cpu9 : 39.9 us, 14.0 sy, 0.0 ni, 35.2 …","date":-62135596800,"description":"","dir":"projects/sofa-jraft/benchmark-performance/","fuzzywordcount":9300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"4530827525ca87732eaf76ae34f03603","permalink":"/projects/sofa-jraft/benchmark-performance/","publishdate":"0001-01-01T00:00:00Z","readingtime":19,"relpermalink":"/projects/sofa-jraft/benchmark-performance/","summary":"测试代码 测试环境\u0026amp;条件 3 台 16C 20G 内存的 docker 容器作为 server node (3 副本) 2 ~ 8 台 8C docker 容器 作为 client 24 个 raft 复制组，平均每台 server node 上各自有 8 个 leader 负责读写请求","tags":null,"title":"Benchmark 数据","type":"projects","url":"/projects/sofa-jraft/benchmark-performance/","wordcount":9269},{"author":null,"categories":null,"content":"Bolt protocol is a TCP-based custom protocol that performs better than HTTP. Within Ant Financial, a large number of RPCs use the Bolt protocol to communicate:\n Basic usage Calling type Timeout control Generic call Serialization protocol Custom thread pool  ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/bolt/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"b812f6aadadf38b79140a711ff6aa6cd","permalink":"/en/projects/sofa-rpc/bolt/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/bolt/","summary":"Bolt protocol is a TCP-based custom protocol that performs better than HTTP. Within Ant Financial, a large number of RPCs use the Bolt protocol to communicate:\n Basic usage Calling type Timeout control Generic call Serialization protocol Custom thread pool  ","tags":null,"title":"Bolt protocol","type":"projects","url":"/en/projects/sofa-rpc/bolt/","wordcount":39},{"author":null,"categories":null,"content":"Bolt 协议一个基于 TCP 的自定义的协议，相比 HTTP 来说，性能更好，在蚂蚁金服内部，大量的 RPC 都是采用 Bolt 协议来进行通信：\n 基本使用 调用方式 超时控制 泛化调用 序列化协议 自定义线程池  ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/bolt/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"b812f6aadadf38b79140a711ff6aa6cd","permalink":"/projects/sofa-rpc/bolt/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/bolt/","summary":"Bolt 协议一个基于 TCP 的自定义的协议，相比 HTTP 来说，性能更好，在蚂蚁金服内部，大量的 RPC 都是采用 Bolt 协议来进行通信： 基本使用 调用方式 超时控制 泛化调用 序列","tags":null,"title":"Bolt 协议","type":"projects","url":"/projects/sofa-rpc/bolt/","wordcount":79},{"author":null,"categories":null,"content":"Bolt 协议基本使用 发布服务 使用 SOFARPC 发布一个 Bolt 协议的服务，只需要增加名称为 Bolt 的 Binding 即可，不同的使用方式添加 Bolt Binding 的方式如下：\nXML 使用 XML 发布一个 Bolt 协议只需要在 \u0026amp;lt;sofa:service\u0026amp;gt; 标签下增加 \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; 标签即可：\n\u0026amp;lt;sofa:service ref=\u0026amp;#34;sampleService\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofa.rpc.sample.SampleService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt/\u0026amp;gt; \u0026amp;lt;/sofa:service\u0026amp;gt; Annotation 使用 Annotation 发布一个 Bolt 协议的服务只需要设置 @SofaServiceBinding 的 bindingType 为 bolt 即可：\n@Service @SofaService(bindings = {@SofaServiceBinding(bindingType = \u0026amp;#34;bolt\u0026amp;#34;)}) public class SampleServiceImpl implements SampleService { } Spring 环境下 API 方式 在 Spring 或者 Spring Boot 环境下发布一个 Bolt 协议的服务只需要往 ServiceParam 里面增加一个 BoltBindingParam 即可：\nServiceParam serviceParam = new ServiceParam(); serviceParam.setInterfaceType(SampleService.class); // 设置服务接口 serviceParam.setInstance(new SampleServiceImpl()); // 设置服务接口的实现  List\u0026amp;lt;BindingParam\u0026amp;gt; params = new ArrayList\u0026amp;lt;BindingParam\u0026amp;gt;(); BindingParam serviceBindingParam = new BoltBindingParam(); params.add(serviceBindingParam); serviceParam.setBindingParams(params); 非 Spring 环境下的 API 方式 在非 Spring 环境下使用 SOFARPC 的裸 API 提供 Bolt 协议的服务，只需要将 Protocol 为 Bolt 的 ServerConfig 设置给对应的 ProviderConfig：\nRegistryConfig registryConfig = new RegistryConfig() .setProtocol(\u0026amp;#34;zookeeper\u0026amp;#34;) .setAddress(\u0026amp;#34;127.0.0.1:2181\u0026amp;#34;); // 新建一个协议为 Bolt 的 ServerConfig ServerConfig serverConfig = new ServerConfig() .setPort(8803) .setProtocol(\u0026amp;#34;bolt\u0026amp;#34;); ProviderConfig\u0026amp;lt;SampleService\u0026amp;gt; providerConfig = new ProviderConfig\u0026amp;lt;SampleService\u0026amp;gt;() .setInterfaceId(SampleService.class.getName()) .setRef(new SampleServiceImpl()) .setServer(serverConfig) // 将 ServerConfig 设置给 ProviderConfig，表示这个服务发布的协议为 Bolt。  .setRegistry(registryConfig); providerConfig.export(); 引用服务 使用 SOFARPC 引用一个 Bolt 服务，只需要增加名称为 Bolt 的 Binding 即可，不同的使用方式添加 Bolt Binding 的方式如下：\nXML 使用 XML 引用一个 Bolt 协议的服务只需要在 \u0026amp;lt;sofa:reference\u0026amp;gt; 标签下增加 \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; 标签即可：\n\u0026amp;lt;sofa:reference id=\u0026amp;#34;sampleService\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofa.rpc.sample.SampleService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt/\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt; Annotation 使用 Annotation 引用一个 Bolt 协议的服务只需要设置 @SofaReferenceBinding 的 bindingType 为 bolt 即可：\n@SofaReference(binding = @SofaReferenceBinding(bindingType = \u0026amp;#34;bolt\u0026amp;#34;)) private SampleService sampleService; Spring 环境下 API 方式 在 Spring 或者 Spring Boot 环境下引用一个 Bolt 协议的服务只需要往 ReferenceParam 里面增加一个 BoltBindingParam 即可：\nReferenceClient referenceClient = clientFactory.getClient(ReferenceClient.class); ReferenceParam\u0026amp;lt;SampleService\u0026amp;gt; referenceParam = new ReferenceParam\u0026amp;lt;SampleService\u0026amp;gt;(); referenceParam.setInterfaceType(SampleService.class); BindingParam refBindingParam = new BoltBindingParam(); referenceParam.setBindingParam(refBindingParam); 非 Spring 环境下的 API 方式 在非 Spring 环境下使用 SOFARPC 的裸 API 引用一个 Bolt 协议的服务，只需要设置 ConsumerConfig 的 Protocol 为 bolt 即可：\nConsumerConfig\u0026amp;lt;SampleService\u0026amp;gt; consumerConfig = new ConsumerConfig\u0026amp;lt;SampleService\u0026amp;gt;() .setInterfaceId(SampleService.class.getName()) …","date":-62135596800,"description":"","dir":"projects/sofa-rpc/bolt-usage/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"dd929c0a3cd2f4620ddf0d30d98ba85d","permalink":"/projects/sofa-rpc/bolt-usage/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-rpc/bolt-usage/","summary":"Bolt 协议基本使用 发布服务 使用 SOFARPC 发布一个 Bolt 协议的服务，只需要增加名称为 Bolt 的 Binding 即可，不同的使用方式添加 Bolt Binding 的方式如下： XML 使用 XML 发布一个 Bolt 协议只需要","tags":null,"title":"Bolt 协议基本使用","type":"projects","url":"/projects/sofa-rpc/bolt-usage/","wordcount":570},{"author":null,"categories":null,"content":"泛化调用提供了让客户端在不需要依赖服务端的接口情况下就能够发起调用的能力。目前 SOFARPC 的泛化调用仅支持在 Bolt 通信协议下使用 Hessian2 作为序列化协议，其他的方式并不支持。\nSOFABoot 环境 发布服务 发布服务没有什么特殊的,正常发布服务即可.比如\n\u0026amp;lt;!-- generic --\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;#34;sampleGenericServiceImpl\u0026amp;#34; class=\u0026amp;#34;com.alipay.sofa.rpc.samples.generic.SampleGenericServiceImpl\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;sofa:service ref=\u0026amp;#34;sampleGenericServiceImpl\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofa.rpc.samples.generic.SampleGenericService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt/\u0026amp;gt; \u0026amp;lt;/sofa:service\u0026amp;gt; 引用服务 \u0026amp;lt;sofa:reference jvm-first=\u0026amp;#34;false\u0026amp;#34; id=\u0026amp;#34;sampleGenericServiceReference\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofa.rpc.api.GenericService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;sofa:global-attrs generic-interface=\u0026amp;#34;com.alipay.sofa.rpc.samples.generic.SampleGenericService\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt; 其中,jvm-first根据实际情况,默认可以不写,接口写泛化调用的通用接口,generic-interface中写上自己要调用的接口名称即可.\n发起调用 GenericService sampleGenericServiceReference = (GenericService) applicationContext .getBean(\u0026amp;#34;sampleGenericServiceReference\u0026amp;#34;); GenericObject genericResult = (GenericObject) sampleGenericServiceReference.$genericInvoke(\u0026amp;#34;sayGeneric\u0026amp;#34;, new String[] { \u0026amp;#34;com.alipay.sofa.rpc.samples.generic.SampleGenericParamModel\u0026amp;#34; }, new Object[] { genericObject }); RPC API ConsumerConfig\u0026amp;lt;GenericService\u0026amp;gt; consumerConfig = new ConsumerConfig\u0026amp;lt;GenericService\u0026amp;gt;() .setInterfaceId(\u0026amp;#34;com.alipay.sofa.rpc.quickstart.HelloService\u0026amp;#34;) .setGeneric(true); GenericService testService = consumerConfig.refer(); String result = (String) testService.$invoke(\u0026amp;#34;sayHello\u0026amp;#34;, new String[] { \u0026amp;#34;java.lang.String\u0026amp;#34; },new Object[] { \u0026amp;#34;1111\u0026amp;#34; }); 如上通过 setGeneric 设置该服务为泛化服务，设置服务方的接口名。以 GenericService 作为泛化服务，通过 GenericService 就能够发起泛化调用了。发起调用时，需要传入方法名，方法类型，方法参数。\n如果参数或者返回结果在客户端也需要泛化表示。可以通过 GenericObject 来实现。\nGenericObject genericObject = new GenericObject(\u0026amp;#34;com.alipay.sofa.rpc.invoke.generic.TestObj\u0026amp;#34;); genericObject.putField(\u0026amp;#34;str\u0026amp;#34;, \u0026amp;#34;xxxx\u0026amp;#34;); genericObject.putField(\u0026amp;#34;num\u0026amp;#34;, 222); GenericObject result = (GenericObject) testService.$genericInvoke(\u0026amp;#34;echoObj\u0026amp;#34;, new String[] { \u0026amp;#34;com.alipay.sofa.rpc.invoke.generic.TestObj\u0026amp;#34; }, new Object[] { genericObject }); String str = result.getField(\u0026amp;#34;str\u0026amp;#34;); String num = result.getField(\u0026amp;#34;num\u0026amp;#34;); 如上就能获得序列化结果。完整的泛化调用方式使用说明如下：\n/** * Java Bean */ public class People { private String name; private int age; // getters and setters } /** * 服务方提供的接口 */ interface SampleService { String hello(String arg); People hello(People people); String[] hello(String[] args); } /** * 客户端 */ public class ConsumerClass { GenericService genericService; public void do() { // 1. $invoke仅支持方法参数类型在当前应用的 ClassLoader 中存在的情况  genericService.$invoke(\u0026amp;#34;hello\u0026amp;#34;, new String[]{ String.class.getName() }, new Object[]{\u0026amp;#34;I\u0026amp;#39;m an arg\u0026amp;#34;}); // 2. $genericInvoke支持方法参数类型在当前应用的 ClassLoader 中不存在的情况。  // 2.1 构造参数  GenericObject genericObject = new …","date":-62135596800,"description":"","dir":"projects/sofa-rpc/generic-invoke/","fuzzywordcount":800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"84ac624dc99a42a8f89489aa10304ef7","permalink":"/projects/sofa-rpc/generic-invoke/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-rpc/generic-invoke/","summary":"泛化调用提供了让客户端在不需要依赖服务端的接口情况下就能够发起调用的能力。目前 SOFARPC 的泛化调用仅支持在 Bolt 通信协议下使用 Hessian2 作为序列化协议，其他的方","tags":null,"title":"Bolt 协议泛化调用","type":"projects","url":"/projects/sofa-rpc/generic-invoke/","wordcount":710},{"author":null,"categories":null,"content":"调用方式 SOFARPC 在 Bolt 协议下提供了多种调用方式满足不同的场景。\n同步 在同步的调用方式下，客户端发起调用后会等待服务端返回结果再进行后续的操作。这是 SOFARPC 的默认调用方式，无需进行任何设置即可。\n异步 异步调用的方式下，客户端发起调用后不会等到服务端的结果，继续执行后面的业务逻辑。服务端返回的结果会被 SOFARPC 缓存，当客户端需要结果的时候，再主动调用 API 获取。如果需要将一个服务设置为异步的调用方式，在对应的使用方式下设置 type 属性即可：\nXML 方式 在 XML 方式下，设置 \u0026amp;lt;sofa:global-attrs\u0026amp;gt; 标签的 type 属性为 future 即可：\n\u0026amp;lt;sofa:reference interface=\u0026amp;#34;com.example.demo.SampleService\u0026amp;#34; id=\u0026amp;#34;sampleService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;sofa:global-attrs type=\u0026amp;#34;future\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt; Annotation 方式 在 Annotation 方式下，设置 @SofaReferenceBinding 的 invokeType 属性为 future 即可：\n@SofaReference(binding = @SofaReferenceBinding(bindingType = \u0026amp;#34;bolt\u0026amp;#34;, invokeType = \u0026amp;#34;future\u0026amp;#34;)) private SampleService sampleService; Spring 环境下 API 方式 在 Spring 环境下使用 API，设置 BoltBindingParam 的 type 属性即可：\nBoltBindingParam boltBindingParam = new BoltBindingParam(); boltBindingParam.setType(\u0026amp;#34;future\u0026amp;#34;); 在非 Spring 环境下 API 方式 在非 Spring 环境下使用 SOFARPC 裸 API，设置 ConsumerConfig 的 invokeType 属性即可：\nConsumerConfig\u0026amp;lt;SampleService\u0026amp;gt; consumerConfig = new ConsumerConfig\u0026amp;lt;SampleService\u0026amp;gt;() .setInterfaceId(SampleService.class.getName()) .setRegistry(registryConfig) .setProtocol(\u0026amp;#34;bolt\u0026amp;#34;) .setInvokeType(\u0026amp;#34;future\u0026amp;#34;); 获取调用结果 使用异步调用的方式，目前提供了两种方式来获取异步调用的结果：\n直接获取结果 用户可以通过以下的方式来直接获取异步调用的结果：\nString result = (String)SofaResponseFuture.getResponse(0, true); 其中第一个参数是获取结果的超时时间，第二个参数表示是否清除线程上下文中的结果。\n获取 JDK 原生 Future 用户可以通过以下的方式来获取 JDK 的原生的 Future 对象，再可以从任意地方去调用这个 Future 对象来获取结果：\nFuture future = SofaResponseFuture.getFuture(true); 其中的第一个参数表示是否清除线程上下文中的结果。\n回调 SOFARPC Bolt 协议的回调方式可以让 SOFARPC 在发起调用后不等待结果，在客户端收到服务端返回的结果后，自动回调用户实现的一个回调接口。\n使用 SOFARPC Bolt 协议的回调方式，首先需要实现一个回调接口，并且在对应的配置中设置回调接口，再将调用方式设置为 callback。\n实现回调接口 SOFARPC 提供了一个回调的接口 com.alipay.sofa.rpc.core.invoke.SofaResponseCallback，用户使用 SOFARPC Bolt 协议的回调方式，首先需要实现这个接口，该接口提供了三个方法：\n onAppResponse：当客户端接收到服务端的正常返回的时候，SOFARPC 会回调这个方法。 onAppException：当客户端接收到服务端的异常响应的时候，SOFARPC 会回调这个方法。 onSofaException：当 SOFARPC 本身出现一些错误，比如路由错误的时候，SOFARPC 会回调这个方法。  设置回调接口 实现回调接口之后，用户需要将实现类设置到对应的服务引用配置中，并且将调用方式设置为 callback。\nSOFARPC 为设置回调接口提供了两种方式，分别为 Callback Class 和 Callback Ref。Callback Class 的方式直接设置回调的类名，SOFARPC 会通过调用回调类的默认构造函数的方式生成回调类的实例。Callback Ref 的方式则为用户直接提供回调类的实例。\nXML 方式 如果通过 XML 的方式引用服务，将 \u0026amp;lt;sofa:global-attrs\u0026amp;gt; 标签的 type 属性设置为 callback，并且设置 callback-ref 或者 callback-class 属性即可：\n\u0026amp;lt;bean id=\u0026amp;#34;sampleCallback\u0026amp;#34; class=\u0026amp;#34;com.example.demo.SampleCallback\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;sofa:reference interface=\u0026amp;#34;com.example.demo.SampleService\u0026amp;#34; id=\u0026amp;#34;sampleService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;sofa:global-attrs type=\u0026amp;#34;callback\u0026amp;#34; callback-ref=\u0026amp;#34;sampleCallback\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt; 在 XML 的方式下，callback-ref 的值需要是回调类的 Bean 名称。\nAnnotation 方式 如果通过 Annotation 的方式引用服务，设置 @SofaReferenceBinding 注解的 invokeType 属性为 callback，并且设置 callbackClass 或者 callbackRef 属性即可：\n@SofaReference(binding = @SofaReferenceBinding(bindingType = \u0026amp;#34;bolt\u0026amp;#34;, invokeType = …","date":-62135596800,"description":"","dir":"projects/sofa-rpc/invoke-type/","fuzzywordcount":1700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"e296d9344b6aa9f550e6213b97da084b","permalink":"/projects/sofa-rpc/invoke-type/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/projects/sofa-rpc/invoke-type/","summary":"调用方式 SOFARPC 在 Bolt 协议下提供了多种调用方式满足不同的场景。 同步 在同步的调用方式下，客户端发起调用后会等待服务端返回结果再进行后续的操作。这是 SOFARPC 的","tags":null,"title":"Bolt 协议调用方式","type":"projects","url":"/projects/sofa-rpc/invoke-type/","wordcount":1619},{"author":null,"categories":null,"content":"超时控制 使用 Bolt 协议进行通信的时候，SOFARPC 的超时时间默认为 3 秒，用户可以在引用服务的时候去设置超时时间，又分别可以在服务以及方法的维度设置超时时间，SOFARPC 的超时时间的设置的单位都为毫秒。\n服务维度 如果需要在发布服务的时候在服务维度设置超时时间，设置对应的 timeout 参数到对应的值即可。\nXML 方式 如果使用 XML 的方式引用服务，设置 \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; 标签下的 \u0026amp;lt;sofa:global-attrs\u0026amp;gt; 标签的 timeout 属性的值即可：\n\u0026amp;lt;sofa:reference interface=\u0026amp;#34;com.example.demo.SampleService\u0026amp;#34; id=\u0026amp;#34;sampleService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;sofa:global-attrs timeout=\u0026amp;#34;2000\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt; Annotation 方式 如果使用 Annotation 引用服务，设置 @SofaReferenceBinding 的 timeout 属性的值即可：\n@SofaReference(binding = @SofaReferenceBinding(bindingType = \u0026amp;#34;bolt\u0026amp;#34;, timeout = 2000)) private SampleService sampleService; Spring 环境 API 方式 如果在 Spring 或者 Spring Boot 的环境下引用服务，设置 BoltBindingParam 的 timeout 属性的值即可：\nBoltBindingParam boltBindingParam = new BoltBindingParam(); boltBindingParam.setTimeout(2000) 非 Spring 环境下 API 方式 如果在非 Spring 环境下直接使用 SOFARPC 的裸 API 引用服务，设置 ConsumerConfig 的 timeout 属性即可：\nConsumerConfig\u0026amp;lt;SampleService\u0026amp;gt; consumerConfig = new ConsumerConfig\u0026amp;lt;SampleService\u0026amp;gt;() .setInterfaceId(SampleService.class.getName()) .setRegistry(registryConfig) .setProtocol(\u0026amp;#34;bolt\u0026amp;#34;) .setTimeout(2000); 方法维度 如果想要单独调整一个服务中某一个方法的超时时间，可以通过在方法维度上设置超时时间来实现。\n对于某一个方法来说，优先方法维度的超时时间，如果没有设置，则使用服务维度的超时时间。\nXML 方式 如果使用 XML 的方式引用一个服务，设置对应的 \u0026amp;lt;sofa:method\u0026amp;gt; 标签的 timeout 属性即可：\n\u0026amp;lt;sofa:reference interface=\u0026amp;#34;com.example.demo.SampleService\u0026amp;#34; id=\u0026amp;#34;sampleService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;sofa:method name=\u0026amp;#34;hello\u0026amp;#34; timeout=\u0026amp;#34;2000\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt; Annotation 方式 目前暂未提供通过 Annotation 的方式来设置方法级别的超时时间。\nSpring 环境 API 方式 如果在 Spring 或者 Spring Boot 的环境下引用服务，设置 RpcBindingMethodInfo 的 timeout 属性的值即可：\nBoltBindingParam boltBindingParam = new BoltBindingParam(); RpcBindingMethodInfo rpcBindingMethodInfo = new RpcBindingMethodInfo(); rpcBindingMethodInfo.setName(\u0026amp;#34;hello\u0026amp;#34;); rpcBindingMethodInfo.setTimeout(2000); List\u0026amp;lt;RpcBindingMethodInfo\u0026amp;gt; rpcBindingMethodInfos = new ArrayList\u0026amp;lt;\u0026amp;gt;(); rpcBindingMethodInfos.add(rpcBindingMethodInfo); boltBindingParam.setMethodInfos(rpcBindingMethodInfos); 非 Spring 环境 API 方式 如果在非 Spring 环境下使用 SOFARPC 的裸 API 引用服务，设置 MethodConfig 的 timeout 属性即可：\nMethodConfig methodConfig = new MethodConfig(); methodConfig.setName(\u0026amp;#34;hello\u0026amp;#34;); methodConfig.setTimeout(2000); List\u0026amp;lt;MethodConfig\u0026amp;gt; methodConfigs = new ArrayList\u0026amp;lt;MethodConfig\u0026amp;gt;(); methodConfigs.add(methodConfig); ConsumerConfig\u0026amp;lt;SampleService\u0026amp;gt; consumerConfig = new ConsumerConfig\u0026amp;lt;SampleService\u0026amp;gt;() .setInterfaceId(SampleService.class.getName()) .setRegistry(registryConfig) .setProtocol(\u0026amp;#34;bolt\u0026amp;#34;) .setMethods(methodConfigs); ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/bolt-timeout/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"cf14f73dc0c4672a9255ef55b56de419","permalink":"/projects/sofa-rpc/bolt-timeout/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-rpc/bolt-timeout/","summary":"超时控制 使用 Bolt 协议进行通信的时候，SOFARPC 的超时时间默认为 3 秒，用户可以在引用服务的时候去设置超时时间，又分别可以在服务以及方法的维度","tags":null,"title":"Bolt 协议超时控制","type":"projects","url":"/projects/sofa-rpc/bolt-timeout/","wordcount":584},{"author":null,"categories":null,"content":"As one of the developing directions of cloud native technology, Serverless architecture enables you to further improve resource utilization and focus on service development. With our workshop, you can experience new features such as quick creation of Serveless applications, automatic second-level 0-1-N scaling based on service requests, and quick troubleshooting via log viewer.\nWorkshop procedure Flow diagram Preview Preparation  Access to Serverless application service address Login with account and password Git clone this project to local  Step 1-1: Publish backend Java application  Select Create quickly Select Java Runtime Upload the code package balance-mng.jar The entry method can be automatically recognized Port: 8080 Copy and save the backend service address after creation View the number of computing instances of backend service: 0  Step 1-2: Publish frontend NodeJS application  Select create an application Select the buildpack NodeJS Upload the code package stock-mng.zip The entry method can be automatically recognized Select nodejs-0.0.1.1-pre at runtime Port: 3000 Set the environment variable BALANCEMNG_URL as the backend service address  Step 2: 0-1 cold boot capability  Access frontend service View the changes in the number of the computing instances of backend service  Step 3: Log and monitoring  View application service logs via Log Shell View usage amount via monitoring  Step 4: Configure time trigger  Configure timing trigger to call application at fixed time View the triggering results via operation records  Step 5: Create versions and control traffic  Clone the frontend application and create a new version Upload the code package stock-mng-v2.zip Configure router to visit V1 and V2 at 1:1 ratio View the effect in the browser  Step 6: Quick M-n capability for high-concurrency  Simulate high concurrency situtation via scripts and access the frontend application service Check how the Serverless application perform quick M-N computing instance changes  ","date":-62135596800,"description":"With this guide, you can experience new features such as quick creation of Serveless applications, automatic second-level 0-1-N scaling based on service requests, quick troubleshooting via log viewer, and application startup at fixed time.","dir":"guides/kc-serverless-demo/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"f355d1b598fed47b730bd74ad25f3683","permalink":"/en/guides/kc-serverless-demo/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/guides/kc-serverless-demo/","summary":"As one of the developing directions of cloud native technology, Serverless architecture enables you to further improve resource utilization and focus on service development. With our workshop, you can experience new features such as quick creation of Serveless applications, automatic second-level 0-1-N scaling based on service requests, and quick troubleshooting via log viewer.\nWorkshop procedure Flow diagram Preview Preparation  Access to Serverless application service address Login with account and password Git clone this project to local  Step 1-1: Publish backend Java application  Select Create quickly Select Java Runtime Upload the code package balance-mng.","tags":null,"title":"Build applications on the cloud based on Serverless","type":"guides","url":"/en/guides/kc-serverless-demo/","wordcount":290},{"author":null,"categories":null,"content":"Procedure This guide introduces how to quickly build a microservice based on SOFAStack. It mainly includes the following steps.\n Publish service using SOFABoot and SOFARPC Call service using SOFABoot and SOFARPC View Tracer information reported by SOFATracer via ZipKin View Metrics information via SOFALookout  Architecture Tasks 1. Preparation Clone the project demo from GitHub to local\ngit clone https://github.com/sofastack-guides/kc-sofastack-demo.git Import the project into IDEA or Eclipse. After import, the interface is as follows:\n balance-mng: account management system, providing deduction balance service stock-mng: account system, providing deduction inventory service  2. Introduce dependencies Add the following dependencies into the pom.xml files of balance-mng and stock-mng project modules.\n\u0026amp;lt;!--SOFARPC dependency--\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;rpc-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!--SOFATracer dependency--\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;tracer-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!--SOFARegistry dependency--\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;registry-client-all\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!--runtime dependency--\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;runtime-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!--SOFALookout dependency--\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa.lookout\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;lookout-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; For balance-mng project, you need to introduce the dependencies into the pom file of balance-mng-imp module.\nFor stock-mng project, you need to introduce the dependencies into the pom file of stock-mng module.\n3. Add configurations Copy the following configurations into the application.properties file of balance-mng and stock-mng project module.\n# 1、Add Service Registry address com.alipay.sofa.rpc.registry.address=sofa://118.31.43.62:9603 # 2、Add the zipkin address where tracer data is reported com.alipay.sofa.tracer.zipkin.base-url=http://139.224.123.199:9411 # 3、Add the server-side address where the metrics data is reported com.alipay.sofa.lookout.agent-host-address=139.224.123.35 For balance-mng project, you need to add configurations to the application.properties file in balance-mng-bootstrap module.\nFor stock-mng project, you need to add configurations to the application.properties file in stock-mng module.\n4. Modify unique id Since everyone shares a set of service discoveries, to differentiate the services published by different users, it is required to add a unique id to the service.\nKubeCon workshop will prepare a SOFAStack account for each user in the format ofuser0@sofastack.io to user99@sofastack.io. The first half of the account, namely user0 …","date":-62135596800,"description":"This guide introduces how to quickly build a microservice based on SOFAStack. ","dir":"guides/sofastack-quick-start/","fuzzywordcount":600,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"78bfd4806a86dc15ac86eee16fb85c82","permalink":"/en/guides/sofastack-quick-start/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/en/guides/sofastack-quick-start/","summary":"Procedure This guide introduces how to quickly build a microservice based on SOFAStack. It mainly includes the following steps.\n Publish service using SOFABoot and SOFARPC Call service using SOFABoot and SOFARPC View Tracer information reported by SOFATracer via ZipKin View Metrics information via SOFALookout  Architecture Tasks 1. Preparation Clone the project demo from GitHub to local\ngit clone https://github.com/sofastack-guides/kc-sofastack-demo.git Import the project into IDEA or Eclipse. After import, the interface is as follows:","tags":null,"title":"Build microservices with SOFAStack","type":"guides","url":"/en/guides/sofastack-quick-start/","wordcount":586},{"author":null,"categories":null,"content":"SOFARPC provides a variety of calling types under the Bolt protocol to meet different scenarios.\nSynchronous In the synchronous calling type, after the client initiates a call, it will wait for the server to return the result and then perform subsequent operations. This is the default calling type of SOFARPC.\nAsynchronous In the asynchronous calling type, after the client initiates a call, it will not wait for the result from the server but continue to execute the subsequent business logic. The result returned by the server will be cached by SOFARPC. When the client needs the result, it can call the API to get the result. To set a service to be asynchronous, you can configure the type attribute in the corresponding usage mode:\nXML In the XML mode, set the type attribute of the \u0026amp;lt;sofa:global-attrs\u0026amp;gt; tag to future:\n\u0026amp;lt;sofa:reference interface=\u0026amp;#34;com.example.demo.SampleService\u0026amp;#34; id=\u0026amp;#34;sampleService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;sofa:global-attrs type=\u0026amp;#34;future\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt; Annotation In Annotation mode, set the invokeType attribute of @SofaReferenceBinding to future:\n@SofaReference(binding = @SofaReferenceBinding(bindingType = \u0026amp;#34;bolt\u0026amp;#34;, invokeType = \u0026amp;#34;future\u0026amp;#34;)) private SampleService sampleService; API in Spring environment When using the API in Spring environment, you just need to set the type attribute of BoltBindingParam:\nBoltBindingParam boltBindingParam = new BoltBindingParam(); boltBindingParam.setType(\u0026amp;#34;future\u0026amp;#34;); API in non-Spring environment When using the bare API of SOFARPC in a non-Spring environment, you just need to set the invokeType attribute of ConsumerConfig:\nConsumerConfig\u0026amp;lt;SampleService\u0026amp;gt; consumerConfig = new ConsumerConfig\u0026amp;lt;SampleService\u0026amp;gt;() .setInterfaceId(SampleService.class.getName()) .setRegistry(registryConfig) .setProtocol(\u0026amp;#34;bolt\u0026amp;#34;) .setInvokeType(\u0026amp;#34;future\u0026amp;#34;); Get the calling result Currently, there are two ways to get the result of an asynchronous call:\nGet result directly You can directly get the result of an asynchronous call in the following way:\nString result = (String)SofaResponseFuture.getResponse(0, true); The first parameter is the timeout period for getting the result, and the second parameter indicates whether to clear the result in the thread context.\nGet JDK native Future You can get the JDK native Future object in the following way, and then call the Future object from anywhere to get the result:\nFuture future = SofaResponseFuture.getFuture(true); The first parameter indicates whether to clear the result in the thread context.\nCallback By using the callback type of the SOFARPC Bolt protocol, SOFARPC doesn\u0026amp;rsquo;t need to wait for the result after initiating a call. After the client receives the result returned from the server, it can automatically call back a callback interface implemented by the user.\nTo use the callback type of the SOFARPC Bolt protocol, you first need to implement a callback …","date":-62135596800,"description":"","dir":"projects/sofa-rpc/invoke-type/","fuzzywordcount":1000,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"e296d9344b6aa9f550e6213b97da084b","permalink":"/en/projects/sofa-rpc/invoke-type/","publishdate":"0001-01-01T00:00:00Z","readingtime":5,"relpermalink":"/en/projects/sofa-rpc/invoke-type/","summary":"SOFARPC provides a variety of calling types under the Bolt protocol to meet different scenarios.\nSynchronous In the synchronous calling type, after the client initiates a call, it will wait for the server to return the result and then perform subsequent operations. This is the default calling type of SOFARPC.\nAsynchronous In the asynchronous calling type, after the client initiates a call, it will not wait for the result from the server but continue to execute the subsequent business logic.","tags":null,"title":"Calling type","type":"projects","url":"/en/projects/sofa-rpc/invoke-type/","wordcount":908},{"author":null,"categories":null,"content":"Client built-in extension metrics The extension modules currently in effect by default are lookout-ext-jvm and lookout-ext-os (from v1.5.0).\nJVM thread    metric name metric tags specification     jvm.threads.totalStarted  \u0026amp;mdash;   jvm.threads.active  \u0026amp;mdash;   jvm.threads.peak  \u0026amp;mdash;   jvm.threads.daemon  \u0026amp;mdash;    JVM class loading    metric name metric tags specification     jvm.classes.unloaded  \u0026amp;mdash;   jvm.classes.loaded  \u0026amp;mdash;   jvm.classes.total  \u0026amp;mdash;    JVM memory    metric name metric tags specification     jvm.memory.heap.init  \u0026amp;mdash;   jvm.memory.heap.used  \u0026amp;mdash;   jvm.memory.heap.max  \u0026amp;mdash;   jvm.memory.heap.committed  \u0026amp;mdash;    JVM garbage recycling    metric name metric tags specification     jvm.gc.young.time  \u0026amp;mdash;   jvm.gc.young.count  \u0026amp;mdash;   jvm.gc.old.time  \u0026amp;mdash;   jvm.gc.old.count  \u0026amp;mdash;    Machine file system information    metric name metric tags specification     instance.file.system.free.space root（the available filesystem roots） \u0026amp;mdash;   instance.file.system.total.space root \u0026amp;mdash;   instance.file.system.usabe.space root \u0026amp;mdash;    Machine information    metric name metric tags specification     instance.mem.free  \u0026amp;mdash;   instance.mem.total  \u0026amp;mdash;   instance.processors  \u0026amp;mdash;   instance.uptime  \u0026amp;mdash;   instance.systemload.average  \u0026amp;mdash;    Linux operating system information (enabled by default after version 1.5.0)    metric name metric tags specification     os.systemload.average.1min  \u0026amp;mdash;   os.systemload.average.5min  \u0026amp;mdash;   os.systemload.average.15min  \u0026amp;mdash;   os.cpu.idle  \u0026amp;mdash;   os.cpu.iowait  \u0026amp;mdash;   os.cpu.irq  \u0026amp;mdash;   os.cpu.nice  \u0026amp;mdash;   os.cpu.softirq  \u0026amp;mdash;   os.cpu.system  \u0026amp;mdash;   os.cpu.user  \u0026amp;mdash;   os.disk.usage.percent.used device,root,type \u0026amp;mdash;   os.disk.usage.total.bytes device,root,type \u0026amp;mdash;   os.disk.usage.used.bytes device,root,type \u0026amp;mdash;   os.net.stats.in.bytes intfc \u0026amp;mdash;   os.net.stats.in.compressed intfc \u0026amp;mdash;   os.net.stats.in.dropped intfc \u0026amp;mdash;   os.net.stats.in.errs intfc \u0026amp;mdash;   os.net.stats.in.fifo.errs intfc \u0026amp;mdash;   os.net.stats.in.frame.errs intfc \u0026amp;mdash;   os.net.stats.in.multicast intfc \u0026amp;mdash;   os.net.stats.in.packets intfc \u0026amp;mdash;   os.net.stats.out.bytes intfc \u0026amp;mdash;   os.net.stats.out.carrier.errs intfc \u0026amp;mdash;   os.net.stats.out.collisions intfc \u0026amp;mdash;   os.net.stats.out.compressed intfc \u0026amp;mdash;   os.net.stats.out.dropped intfc \u0026amp;mdash;   os.net.stats.out.errs intfc \u0026amp;mdash;   os.net.stats.out.fifo.errs intfc \u0026amp;mdash;   os.net.stats.out.packets intfc \u0026amp;mdash;   os.memory.stats.buffers.bytes \u0026amp;mdash; \u0026amp;gt;= 1.5.3   os.memory.stats.cached.bytes \u0026amp;mdash; \u0026amp;gt;= 1.5.3   os.memory.stats.free.bytes \u0026amp;mdash; \u0026amp;gt;= 1.5.3   os.memory.stats.total.bytes \u0026amp;mdash; \u0026amp;gt;= 1.5.3    ","date":-62135596800,"description":"","dir":"projects/sofa-lookout/client-ext-metrics/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"c8a4fb3d904e359e99db9d4e81e60812","permalink":"/en/projects/sofa-lookout/client-ext-metrics/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-lookout/client-ext-metrics/","summary":"Client built-in extension metrics The extension modules currently in effect by default are lookout-ext-jvm and lookout-ext-os (from v1.5.0).\nJVM thread    metric name metric tags specification     jvm.threads.totalStarted  \u0026mdash;   jvm.threads.active  \u0026mdash;   jvm.threads.peak  \u0026mdash;   jvm.threads.daemon  \u0026mdash;    JVM class loading    metric name metric tags specification     jvm.classes.unloaded  \u0026mdash;   jvm.","tags":null,"title":"Client built-in extension metrics","type":"projects","url":"/en/projects/sofa-lookout/client-ext-metrics/","wordcount":224},{"author":null,"categories":null,"content":"The client module is a complex module which contains cluster, router, address holder，connection holder, and load balancer, and interacts with proxy, registry center and other modules.\nSee the following flow chart:\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/client-invoke-flow/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"310d99d64b808a3b526563e92c699952","permalink":"/en/projects/sofa-rpc/client-invoke-flow/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/client-invoke-flow/","summary":"The client module is a complex module which contains cluster, router, address holder，connection holder, and load balancer, and interacts with proxy, registry center and other modules.\nSee the following flow chart:","tags":null,"title":"Client call flow","type":"projects","url":"/en/projects/sofa-rpc/client-invoke-flow/","wordcount":31},{"author":null,"categories":null,"content":"Client configuration example lookoutConfig.setProperty(LookoutConfig.LOOKOUT_AGENT_HOST_ADDRESS,\u0026amp;#34;127.0.0.1\u0026amp;#34;); Description of server configuration item    Configuration item Corresponding SpringBoot configuration item Default value Description     lookout.enable com.alipay.sofa.lookout.enable true Function switch, it defaults to true. If you change it to false (empty objects and empty methods), then all metrics comsume almost no memory and computing resource   lookout.max.metrics.num com.alipay.sofa.lookout.max-metrics-num 5000 Maximum number limit of metrics, over which will be automatically ignored   lookout.prometheus.exporter.server.port com.alipay.sofa.lookout.prometheus-exporter-server-port 9494 The port got by Prometheus   Lookout.exporter.enable com.alipay.sofa.lookout.exporter-enable false Whether or not to enable services that support passive collection   Lookout.agent.host.address com.alipay.sofa.lookout.agent-host-address - Proactively report the annotation address of the Agent server. Multiple addresses are separated by commas    Description of client log configuration    Configuration item of system property Corresponding SpringBoot configuration item Default Value Description     -Dlogging.level.com.alipay.lookout=? logging.level.com.alipay.lookout warn The log level of Lookout client. Debug to see the details of the report data   -Dlogging.path=? logging.path Directory of the current user Modify SpringBoot V1 log directory, including \u0026amp;ldquo;lookout/\u0026amp;rdquo; log subdirectory    Custom client configuration (suitable for SpringBoot technology stack mode) Use configuration custom extensions: MetricConfigCustomizerConfig\n@Configuration public class MetricConfigCustomizerConfig { @Bean public MetricConfigCustomizer metricConfigCustomizer() { return new MetricConfigCustomizer() { @Override public void customize(MetricConfig metricConfig) { metricConfig.addProperty(\u0026amp;#34;testaa\u0026amp;#34;, \u0026amp;#34;testbb\u0026amp;#34;); } }; } } ","date":-62135596800,"description":"","dir":"projects/sofa-lookout/client-configuration/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"5fd84950d4d565d3fb20781337792bf1","permalink":"/en/projects/sofa-lookout/client-configuration/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-lookout/client-configuration/","summary":"Client configuration example lookoutConfig.setProperty(LookoutConfig.LOOKOUT_AGENT_HOST_ADDRESS,\u0026#34;127.0.0.1\u0026#34;); Description of server configuration item    Configuration item Corresponding SpringBoot configuration item Default value Description     lookout.enable com.alipay.sofa.lookout.enable true Function switch, it defaults to true. If you change it to false (empty objects and empty methods), then all metrics comsume almost no memory and computing resource   lookout.max.metrics.num com.alipay.sofa.lookout.max-metrics-num 5000 Maximum number limit of metrics, over which will be automatically ignored   lookout.","tags":null,"title":"Client configuration","type":"projects","url":"/en/projects/sofa-lookout/client-configuration/","wordcount":192},{"author":null,"categories":null,"content":"1. Create a Maven project After deploying the servers, we can create a new Maven project to use services provided by SOFARegistry. Create a new Maven project, and then import the following dependency:\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;registry-client-all\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${registry.client.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 2. Publish data // Create a client instance. RegistryClientConfig config = DefaultRegistryClientConfigBuilder.start().setRegistryEndpoint(\u0026amp;#34;127.0.0.1\u0026amp;#34;).setRegistryEndpointPort(9603).build(); DefaultRegistryClient registryClient = new DefaultRegistryClient(config); registryClient.init(); // Create a publisher registry. String dataId = \u0026amp;#34;com.alipay.test.demo.service:1.0@DEFAULT\u0026amp;#34;; PublisherRegistration registration = new PublisherRegistration(dataId); // Register the registry with the client and publish data. registryClient.register(registration, \u0026amp;#34;10.10.1.1:12200?xx=yy\u0026amp;#34;); Perform the following steps to publish data by using SOFARegistry:\n Create a client instance. Create a publisher registry. Register the registry with the client and publish data.  2.1 Create a client instance The key to creating a client instance is to create a RegistryClientConfig object. When creating a RegistryClientConfig object, you need to specify the RegistryEndpoint and RegistryEndpointPort.\n RegistryEndpoint: the endpoint of any session node of SOFARegistry RegistryEndpointPort: the session.server.httpServerPort port number configured for a session node  2.2 Create a publisher registry To create a publisher registry, you only need to create a PublisherRegistration object and specify the dataId, which is the unique identifier of the publisher service.\n2.3 Publish data You can call the register method of the RegistryClient to publish data. This method requires two parameters: the first is a publisher registry with the specified dataId of a service, and the second is a string type data value.\n3. Subscribe to the data // Create a client instance. RegistryClientConfig config = DefaultRegistryClientConfigBuilder.start().setRegistryEndpoint(\u0026amp;#34;127.0.0.1\u0026amp;#34;).setRegistryEndpointPort(9603).build(); DefaultRegistryClient registryClient = new DefaultRegistryClient(config); registryClient.init(); // Create SubscriberDataObserver. SubscriberDataObserver subscriberDataObserver = new SubscriberDataObserver() { public void handleData(String dataId, UserData userData) { System.out.println(\u0026amp;#34;receive data success, dataId: \u0026amp;#34; + dataId + \u0026amp;#34;, data: \u0026amp;#34; + userData); } }; // Create a subscriber registry and specify the subscription level. ScopeEnum covers three subscription levels: zone, dataCenter, and global. String dataId = \u0026amp;#34;com.alipay.test.demo.service:1.0@DEFAULT\u0026amp;#34;; SubscriberRegistration registration = new SubscriberRegistration(dataId, subscriberDataObserver); registration.setScopeEnum(ScopeEnum.global); // Register the registry with the client and …","date":-62135596800,"description":"","dir":"projects/sofa-registry/client-quick-start/","fuzzywordcount":600,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"66e300d44b2f2a903d976bf83eb7c16e","permalink":"/en/projects/sofa-registry/client-quick-start/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/en/projects/sofa-registry/client-quick-start/","summary":"1. Create a Maven project After deploying the servers, we can create a new Maven project to use services provided by SOFARegistry. Create a new Maven project, and then import the following dependency:\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alipay.sofa\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;registry-client-all\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${registry.client.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2. Publish data // Create a client instance. RegistryClientConfig config = DefaultRegistryClientConfigBuilder.start().setRegistryEndpoint(\u0026#34;127.0.0.1\u0026#34;).setRegistryEndpointPort(9603).build(); DefaultRegistryClient registryClient = new DefaultRegistryClient(config); registryClient.init(); // Create a publisher registry. String dataId = \u0026#34;com.alipay.test.demo.service:1.0@DEFAULT\u0026#34;; PublisherRegistration registration = new PublisherRegistration(dataId); // Register the registry with the client and publish data.","tags":null,"title":"Client usage","type":"projects","url":"/en/projects/sofa-registry/client-quick-start/","wordcount":558},{"author":null,"categories":null,"content":" Project address\n Introduction During merged deployment, Biz packages can communicate with each other by releasing and referencing JVM services apart from using the RPC framework. This sample project is intended to demonstrate how two Biz packages communicate by JVM services.\nWithin the biz-jvm-invocation-sample project, there are three sub-projects whose functions are as follows:\n facade: A common Java module that defines the SampleJvmService interface.  package me.qlong.tech.service; public interface SampleJvmService { String service(); }  app-one: A SOFABoot Web application that defines a simple rest request and use the @SofaReference annotation to reference the SampleJvmService. When a page request is triggered, an attempt is made to call the JVM service. The key code is:  package me.qlong.controller; import com.alipay.sofa.runtime.api.annotation.SofaReference; import me.qlong.tech.service.SampleJvmService; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class HelloController { @SofaReference private SampleJvmService sampleJvmService; @RequestMapping(\u0026amp;#34;/hello\u0026amp;#34;) public String hello() { return sampleJvmService.service(); } }  app-two: A non-web application in SOFABoot that uses the @SofaService annotation to publish the SampleJvmService.  package me.qlong.tech.service.impl; import com.alipay.sofa.runtime.api.annotation.SofaService; import me.qlong.tech.service.SampleJvmService; import org.springframework.stereotype.Component; @SofaService @Component public class AppTwoSampleService implements SampleJvmService{ public String service() { return \u0026amp;#34;App Two\u0026amp;#34;; } } Dependency To communicate between Biz packages through JVM services, you must add dependencies on the SOFARuntime package and the corresponding Ark Plugin as follows:\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;runtime-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;classifier\u0026amp;gt;ark-plugin\u0026amp;lt;/classifier\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;runtime-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; For detailed information about publishing and referencing JVM services, see the SOFABoot Documentation. You are advised to use annotations in Jarslink2.0.\nDemo  cd biz-jvm-invocation-sample/facade \u0026amp;amp;\u0026amp;amp; mvn clean install Execute the mvn clean install command in the facade root directory, and install the facade package in the local Maven repository so that you can add a facade dependency in app-one and app-two:  \u0026amp;lt;!--service facade--\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;me.qlong.tech\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;facade\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;1.0.0\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   cd biz-jvm-invocation-sample/app-one \u0026amp;amp;\u0026amp;amp; mvn clean package Execute the mvn clean package command in the app-one root directory and package the application into Ark …","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-jarslink-jarslink-invocation-demo/","fuzzywordcount":600,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"59778c5223dc6267bd537be6c79b658a","permalink":"/en/projects/sofa-boot/sofa-jarslink-jarslink-invocation-demo/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/en/projects/sofa-boot/sofa-jarslink-jarslink-invocation-demo/","summary":"Project address\n Introduction During merged deployment, Biz packages can communicate with each other by releasing and referencing JVM services apart from using the RPC framework. This sample project is intended to demonstrate how two Biz packages communicate by JVM services.\nWithin the biz-jvm-invocation-sample project, there are three sub-projects whose functions are as follows:\n facade: A common Java module that defines the SampleJvmService interface.  package me.qlong.tech.service; public interface SampleJvmService { String service(); }  app-one: A SOFABoot Web application that defines a simple rest request and use the @SofaReference annotation to reference the SampleJvmService.","tags":null,"title":"Communicate across applications","type":"projects","url":"/en/projects/sofa-boot/sofa-jarslink-jarslink-invocation-demo/","wordcount":523},{"author":null,"categories":null,"content":"SOFARPC supports different communication protocols and currently supports Bolt, RESTful and Dubbo. For details, please refer to the corresponding document of each protocol:\n Bolt Protocol  Basic usage Calling type Timeout control Generic call Serialization protocol Custom thread pool   RESTful  Basic usage Custom filter Integrate Swagger   Dubbo  Basic usage   H2C  Basic usage    ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/protocol/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"18f51cb12f7a0384a71ab22349292a08","permalink":"/en/projects/sofa-rpc/protocol/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/protocol/","summary":"SOFARPC supports different communication protocols and currently supports Bolt, RESTful and Dubbo. For details, please refer to the corresponding document of each protocol:\n Bolt Protocol  Basic usage Calling type Timeout control Generic call Serialization protocol Custom thread pool   RESTful  Basic usage Custom filter Integrate Swagger   Dubbo  Basic usage   H2C  Basic usage    ","tags":null,"title":"Communication protocols","type":"projects","url":"/en/projects/sofa-rpc/protocol/","wordcount":51},{"author":null,"categories":null,"content":"How to compile  Install JDK7 and above, and Maven 3.2.5 and above.\n Directly download the code and then execute the following command:\ncd sofa-jarslink mvn clean install Note: you cannot compile the code under a sub-directory (i.e., sub-module). Since there are many modules, the configuration is restricted to the root directory only to avoid repetitive configuration of some packaging plugins such as the formatting plugin and License plugin. There will be an error message if you execute the packaging command in a sub-module.\n","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-jarslink-compile/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"23c8cae6050d7a772f45d3ff2b4ce889","permalink":"/en/projects/sofa-boot/sofa-jarslink-compile/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-boot/sofa-jarslink-compile/","summary":"How to compile  Install JDK7 and above, and Maven 3.2.5 and above.\n Directly download the code and then execute the following command:\ncd sofa-jarslink mvn clean install Note: you cannot compile the code under a sub-directory (i.e., sub-module). Since there are many modules, the configuration is restricted to the root directory only to avoid repetitive configuration of some packaging plugins such as the formatting plugin and License plugin. There will be an error message if you execute the packaging command in a sub-module.","tags":null,"title":"Compile Jarslink project","type":"projects","url":"/en/projects/sofa-boot/sofa-jarslink-compile/","wordcount":83},{"author":null,"categories":null,"content":" Install JDK7 or later and Maven 3.2.5 or later.\n Download the codes directly and execute the following commands:\ncd sofa-rpc mvn clean install Note: You can not build under a subdirectory (namely the submodule). Because there are too many SOFARPC modules, if every submodule needs to be installed and deployed, there will be much useless records in the repository. This issue is considered in the process of designing the SOFARPC project structure. The current structure saves you the trouble of installing and deploying all submodules, and you just have to install and deploy one module, namely the sofa-rpc-all (all) module.\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/how-to-build/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"52ad3debb35be8743c97bb4b6b77f22b","permalink":"/en/projects/sofa-rpc/how-to-build/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/how-to-build/","summary":"Install JDK7 or later and Maven 3.2.5 or later.\n Download the codes directly and execute the following commands:\ncd sofa-rpc mvn clean install Note: You can not build under a subdirectory (namely the submodule). Because there are too many SOFARPC modules, if every submodule needs to be installed and deployed, there will be much useless records in the repository. This issue is considered in the process of designing the SOFARPC project structure.","tags":null,"title":"Compile SOFARPC project","type":"projects","url":"/en/projects/sofa-rpc/how-to-build/","wordcount":100},{"author":null,"categories":null,"content":"Provide all the parameters that can be configured.\n Service publishing and reference configuration Warm-up forwarding configuration Fault tolerance configuration  ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/configuration/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"b1a8a8c426beab292165716f1dff1ae4","permalink":"/en/projects/sofa-rpc/configuration/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/configuration/","summary":"Provide all the parameters that can be configured.\n Service publishing and reference configuration Warm-up forwarding configuration Fault tolerance configuration  ","tags":null,"title":"Configuration parameters","type":"projects","url":"/en/projects/sofa-rpc/configuration/","wordcount":19},{"author":null,"categories":null,"content":"connection_manager 用于描述 MOSN 的路由配置，通常与 proxy 配合使用。\n{ \u0026amp;quot;router_config_name\u0026amp;quot;:\u0026amp;quot;\u0026amp;quot;, \u0026amp;quot;virtual_hosts\u0026amp;quot;: [ ] }  router_config_name，唯一的路由配置标识，与 proxy 中配置的字段对应。 virtual_hosts，描述具体的路由规则细节。  VirtualHost { \u0026amp;#34;name\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;domains\u0026amp;#34;:[], \u0026amp;#34;routers\u0026amp;#34;:[] }  name，字符串。用作 virtual host 的唯一标识。 domains，字符串数组。表示一组可以匹配到该 virtual host 的 domain，支持配置通配符。domain 的匹配优先级如下：  首先匹配精确的，如 www.foo.com。 其次匹配最长后缀的通配符，如 *.foo.com、*-bar.foo.com，其中如果一个 domain 是 foo-bar.foo.com，那么会优先匹配 *-bar.foo.com。 最后匹配任意domain的通配符 * 。   routers，一组具体的路由匹配规则。  Router { \u0026amp;#34;match\u0026amp;#34;:{}, \u0026amp;#34;route\u0026amp;#34;:{}, \u0026amp;#34;per_filter_config\u0026amp;#34;:{} }  match，路由的匹配参数。 route，路由行为，描述请求将被路由的 upstream 信息。 per_filter_config，是一个 key: json 格式的 json。 其中 key 需要匹配一个 stream filter 的 type，key 对应的 json 是该 stream filter 的 config。  当配置了该字段时，对于某些 stream filter（依赖具体 filter 的实现），可以使用该字段表示的配置覆盖原有 stream filter 的配置，以此做到路由匹配级别的 stream filter 配置。    match { \u0026amp;#34;prefix\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;path\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;regex\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;headers\u0026amp;#34;: [] }  路径（path）匹配  prefix，表示路由会匹配 path 的前缀，该配置的优先级高于 path 和 regex。 如果 prefix 被配置，那么请求首先要满足 path 的前缀与 prefix 配置相符合。 path，表示路由会匹配精确的 path，该配置的优先级高于 regex。如果 path被配置，那么请求首先要满足 path 与 path 配置相符合。 regex，表示路由会按照正则匹配的方式匹配 path。如果 regex 被配置，那么请求首先要满足 path 与 regex 配置相符合。 路径匹配配置同时存在时，只有高优先级的配置会生效。   Heaer 匹配  headers，表示一组请求需要匹配的 header。请求需要满足配置中所有的 Header 配置条件才算匹配成功。    header { \u0026amp;#34;name\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;value\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;regex\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34; }  name，表示 header 的 key。 value，表示 header 对应 key 的 value。 regex，bool 类型，如果为 true，表示 value 支持按照正则表达式的方式进行匹配。  route { \u0026amp;quot;cluster_name\u0026amp;quot;:\u0026amp;quot;\u0026amp;quot;, \u0026amp;quot;metadata_match\u0026amp;quot;:\u0026amp;quot;\u0026amp;quot;, \u0026amp;quot;timeout\u0026amp;quot;:\u0026amp;quot;\u0026amp;quot;, \u0026amp;quot;retry_policy\u0026amp;quot;:{} }  cluster_name，表示请求将路由到的 upstream cluster。 metadata_match，metadata，如果配置了该字段，表示该路由会基于该 metadata 去匹配 upstream cluster 的 subset 。 timeout，Duration String，表示默认情况下请求转发的超时时间。如果请求中明确指定了超时时间，那么这个配置会被忽略。 retry_policy，重试配置，表示如果请求在遇到了特定的错误时采取的重试策略，默认没有配置的情况下，表示没有重试。  retry_policy { \u0026amp;#34;retry_on\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;retry_timeout\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;num_retries\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34; }  retry_on，bool 类型，表示是否开启重试。 retry_timeout，Duration String，表示每次重试的超时时间。当 retry_timeout 大于 route 配置的 timeout 或者请求明确指定的 timeout 时，属于无效配置。 num_retries，表示最大的重试次数。  ","date":-62135596800,"description":"","dir":"projects/mosn/configuration/listener/network-filter/connection-manager/","fuzzywordcount":1200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"88e2d06bd6137225eeebf9015b2192a2","permalink":"/projects/mosn/configuration/listener/network-filter/connection-manager/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/mosn/configuration/listener/network-filter/connection-manager/","summary":"connection_manager 用于描述 MOSN 的路由配置，通常与 proxy 配合使用。 { \u0026quot;router_config_name\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;virtual_hosts\u0026quot;: [ ] } router_config_name，唯一的路由配置标识，与 proxy 中配置的字段对应。 vir","tags":null,"title":"connection_manager","type":"projects","url":"/projects/mosn/configuration/listener/network-filter/connection-manager/","wordcount":1188},{"author":null,"categories":null,"content":"To use Consul as service registry center, you need to add this dependency\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.ecwid.consul\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;consul-api\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;1.4.2\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; and need to configure it in application.properties as follows:\ncom.alipay.sofa.rpc.registry.address=consul://127.0.0.1:8500 The value after consul: is the connection address of the consul. If you need to set some other parameters, you can also configure as follows:\ncom.alipay.sofa.rpc.registry.address=consul://127.0.0.1:8500?a=1\u0026amp;amp;b=2 ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/registry-consul/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"e6b0aa843ea0ad401c3184f6ce87649b","permalink":"/en/projects/sofa-rpc/registry-consul/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/registry-consul/","summary":"To use Consul as service registry center, you need to add this dependency\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.ecwid.consul\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;consul-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.4.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; and need to configure it in application.properties as follows:\ncom.alipay.sofa.rpc.registry.address=consul://127.0.0.1:8500 The value after consul: is the connection address of the consul. If you need to set some other parameters, you can also configure as follows:\ncom.alipay.sofa.rpc.registry.address=consul://127.0.0.1:8500?a=1\u0026amp;b=2 ","tags":null,"title":"Consul","type":"projects","url":"/en/projects/sofa-rpc/registry-consul/","wordcount":54},{"author":null,"categories":null,"content":" You can visit Development Route first to learn more about development tasks and future planning.\n Preparations Before contributing any code, we need to know how to use the Git tool and the GitHub website.\n Refer to the Git official books for the Git tool usage. The first few chapters will help you get a quick start. Read Git collaboration process through  GitHub Code Contribution Process Submitting an issue Whether you want to fix a bug of SOFAArk or add a new feature of SOFAArk, you have to submit an issue to describe your demand before you submit the code on GitHub address in SOFAArk. There are several advantages of doing so:\n There will not be any conflict with other developers or their plans for this project to result in repetitive work. The maintenance personnel of SOFAArk will discuss about the bug or new function you submitted, to determine if the modification is necessary, or if there is any room for improvement or any better solution. Start developing and submitting code after agreement to reduce the cost of communication between both parties as well as the number of rejected pull requests.  Getting the source code To modify or add a function, click the fork button in the upper left corner to copy a SOFAArk trunk code to your code repository, after submitting an issue.\nPulling a branch Perform all the SOFAArk modifications on the branch, and submit a pull request after the modifications, which will be merged to the trunk by the project maintenance personnel after Code Review.\nTherefore, after getting the introduction to source code steps, you need to:\n  Download the code locally. You may select the git/https mode in this step.\ngit clone https://github.com/{your account}/sofa-ark.git   Pull a branch to prepare for code modification.\ngit branch add_xxx_feature   After the preceding command is executed, your code repository will switch to the corresponding branch. To view the current branch, execute the following command:\ngit branch -a If you want to switch back to the trunk, execute the following command:\ngit checkout -b master If you want to switch back to the branch, execute the following command:\ngit checkout -b \u0026amp;#34;branchName\u0026amp;#34; Modify the code and submit it locally. After a branch is pulled, you can modify the code.\nWhen modifying the code, note the following:   Keep the code style consistent. SOFAArk uses the Maven plug-in to keep the code style consistent. Before submitting the code, execute the following commands locally:\nmvn clean compile   Supplement unit test code.\n  New modifications should have passed existing unit tests.\n  You should provide the new unit test to prove that the previous code has bugs and the new code has fixed such bugs. Execute the following command to run all tests:\nmvn clean test   Other do\u0026amp;rsquo;s and don\u0026amp;rsquo;ts  Retain the original style of the code you are editing, especially the spaces and line feeds in the code. Delete useless annotations. Annotate the places where the logic and functionality are …","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-contribution/","fuzzywordcount":800,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"dbf77f98884a71c5c7a3fbb4dd189cfe","permalink":"/en/projects/sofa-boot/sofa-ark-contribution/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/en/projects/sofa-boot/sofa-ark-contribution/","summary":"You can visit Development Route first to learn more about development tasks and future planning.\n Preparations Before contributing any code, we need to know how to use the Git tool and the GitHub website.\n Refer to the Git official books for the Git tool usage. The first few chapters will help you get a quick start. Read Git collaboration process through  GitHub Code Contribution Process Submitting an issue Whether you want to fix a bug of SOFAArk or add a new feature of SOFAArk, you have to submit an issue to describe your demand before you submit the code on GitHub address in SOFAArk.","tags":null,"title":"Contribution","type":"projects","url":"/en/projects/sofa-boot/sofa-ark-contribution/","wordcount":792},{"author":null,"categories":null,"content":" You can go into the development route to learn more about development tasks and future planning.\n Preparations Before contributing any code, we need to know how to use the Git tool and the GitHub website.\n For the use of git tools, refer to official books on git and get familiarized by reading the first few chapters. For the git collaboration process, refer to the article named Git Collaboration Process.  GitHub Code Contribution Process Submitting an issue No Matter whether you are fixing a Jarslink bug or adding a Jarslink feature, submit an issue on the Jarslink GitHub address to describe the bug you are going to fix or the feature you intend to add before you submit the code. There are several advantages of doing so:\n There will not be any conflict with other developers or their plans for this project to result in repetitive work. The Jarslink maintenance personnel will discuss the bug or new feature you submitted to determine whether the modification is necessary, or if there is any room for improvement or a better solution. Start developing and submitting code after agreement to reduce the cost of communication between both parties as well as the number of rejected pull requests.  Getting the source code To modify or add a feature, click the fork button in the upper left corner to copy Jarslink trunk code to your code repository, after submitting an issue.\nPulling a branch Perform all the Jarslink modifications on the branch, and submit a pull request after the modifications, which will be merged into the trunk by the project maintenance personnel after the code review.\nTherefore, after getting the introduction to source code steps, you need to:\n  Download the code locally. You may select the git/https mode in this step.\ngit clone https://github.com/your account name/sofa-jarslink.git   Pull a branch to prepare for code modification.\ngit branch add_xxx_feature After the preceding command is executed, your code repository will switch to the corresponding branch. To view the current branch, execute the following command:\ngit branch -a If you want to switch back to the trunk, execute the following command:\ngit checkout -b master If you want to switch back to the branch, execute the following command:\ngit checkout -b \u0026amp;quot;branchName\u0026amp;quot;   Modify the code and submit it locally. After a branch is pulled, you can modify the code.\nWhen modifying the code, note the following:   Keep the code style consistent.\nJarslink uses the Maven plugin to keep the code style consistent. Before submitting the code, be sure to execute the following commands locally\nmvn clean compile   Supplement unit test code.\n  New modifications should have passed existing unit tests.\n  You should provide the new unit test to prove that the previous code has bugs and the new code has fixed such bugs.\nExecute the following command to run all tests:\nmvn clean test You can also use the IDE to help execute a command.\n  Other do\u0026amp;rsquo;s and don\u0026amp;rsquo;ts  Retain the original style …","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-jarslink-contribution/","fuzzywordcount":900,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"d4c1185c6a691679f6dc9dba033550ce","permalink":"/en/projects/sofa-boot/sofa-jarslink-contribution/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/en/projects/sofa-boot/sofa-jarslink-contribution/","summary":"You can go into the development route to learn more about development tasks and future planning.\n Preparations Before contributing any code, we need to know how to use the Git tool and the GitHub website.\n For the use of git tools, refer to official books on git and get familiarized by reading the first few chapters. For the git collaboration process, refer to the article named Git Collaboration Process.","tags":null,"title":"Contribution","type":"projects","url":"/en/projects/sofa-boot/sofa-jarslink-contribution/","wordcount":827},{"author":null,"categories":null,"content":" Before you read this document, you are suggested to read the SOFARPC development roadmap to learn about development tasks and future plans.\n Preparations Before you contribute code, you need to learn the basic use of Git tool and GitHub website.\n For how to use the Git tool, see Git official documenation and pay attention to the first few chapters. For Git collaboration process, see Git collaboration process.  GitHub code contribution process Submit an issue No matter to fix SOFARPC bugs or add SOFARPC features, before submitting the codes, you must submit an issue on SOFARPC\u0026amp;rsquo;s GitHub to describe the bugs to be fixed and the functions you want to add.\nThere are several benefits of doing this:\n Avoid the conflict with other developers or their plans for this project, thus eliminating repetitive work. SOFARPC operations staff discuss your bugs or new features to determine if the changes are necessary and whether there is space for improvement or a better approach. Reduce communication cost between you and the SOFARPC operations staff, thus reducing the cases that pull request is rejected.  Get source codes To modify or add features, after you submit the issue, you can click Fork in the upper left corner to copy the SOFARPC trunk code to your code repository.\nPull branches All SOFARPC modifications are made on the branch. After modification, submit the pull request. After the code review, the project operations staff merge the branches to the trunk.\nTherefore, you must complete the following steps after getting the source codes:\n  Download the codes locally through Git or HTTPs.``` git clone https://github.com/your account name/sofa-rpc.git\n   Pull branches for code modifications.``` git branch add_xxx_feature ```    After executing the above command, your code repository switches to the corresponding branch. Execute the following command to see your current branch:``` git branch -a ```  If you want to switch back to the trunk, execute the following command:git checkout -b master\nIf you want to switch back to the branch, execute the following command:git checkout -b \u0026amp;quot;branchName\u0026amp;quot;\nModify and submit codes locally Once the branch is pulled, you can modify the code.\nAttentions for modifying codes   Keep a consistent code style.SOFARPC keeps the code format consistent through the Maven plugin. You must execute the following command locally before committing the code:\nmvn clean compile   Supplemental unit test code.\n  New modifications should have passed the existing unit tests.\n  Provide new unit tests to prove that the previous code has bugs, and the new code has fixed these bugs.You can run all tests with the following command:\nmvn clean test You can also use IDE to assist the test running.\n  Other attentions  Keep the original code style, especially the spacing and alignment. Delete the useless comments directly. Add comments for the logics and functions that cannot be easily understood. Update documentation timely.  After …","date":-62135596800,"description":"","dir":"projects/sofa-rpc/contributing/","fuzzywordcount":800,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"448a7b9a949bd2d9e2e71ac6c237f9df","permalink":"/en/projects/sofa-rpc/contributing/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/en/projects/sofa-rpc/contributing/","summary":"Before you read this document, you are suggested to read the SOFARPC development roadmap to learn about development tasks and future plans.\n Preparations Before you contribute code, you need to learn the basic use of Git tool and GitHub website.\n For how to use the Git tool, see Git official documenation and pay attention to the first few chapters. For Git collaboration process, see Git collaboration process.  GitHub code contribution process Submit an issue No matter to fix SOFARPC bugs or add SOFARPC features, before submitting the codes, you must submit an issue on SOFARPC\u0026rsquo;s GitHub to describe the bugs to be fixed and the functions you want to add.","tags":null,"title":"Contribution","type":"projects","url":"/en/projects/sofa-rpc/contributing/","wordcount":748},{"author":null,"categories":null,"content":"SOFARPC uses some third-party open-source components which include but not limited to:\n  Major dependencies\n Netty under Apache License 2.0 SLF4j under MIT License SOFA Bolt under Apache License 2.0 Javassist under Apache License 2.0 Resteasy under Apache License 2.0 SOFA Hessian under Apache License 2.0    Extended dependencies\n protobuf under New BSD License Snappy under New BSD License dubbo under Apache License 2.0    ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/notice/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"b6c87388d5c1462f13d92012639a08b2","permalink":"/en/projects/sofa-rpc/notice/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/notice/","summary":"SOFARPC uses some third-party open-source components which include but not limited to:\n  Major dependencies\n Netty under Apache License 2.0 SLF4j under MIT License SOFA Bolt under Apache License 2.0 Javassist under Apache License 2.0 Resteasy under Apache License 2.0 SOFA Hessian under Apache License 2.0    Extended dependencies\n protobuf under New BSD License Snappy under New BSD License dubbo under Apache License 2.0    ","tags":null,"title":"Copyright","type":"projects","url":"/en/projects/sofa-rpc/notice/","wordcount":62},{"author":null,"categories":null,"content":"Copyright statement of dependent components SOFADashboard uses some third-party open-source components, including but not limited to:\n Spring under Apache 2.0 license Spring Boot under Apache 2.0 license SLF4j under the MIT License SOFABolt under Apache License 2.0 SOFABolt under Apache License 2.0 Curator under Apache License 2.0  ","date":-62135596800,"description":"","dir":"projects/sofa-dashboard/notice/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"a9ebe38d245302f94ab7bfa793329926","permalink":"/en/projects/sofa-dashboard/notice/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-dashboard/notice/","summary":"Copyright statement of dependent components SOFADashboard uses some third-party open-source components, including but not limited to:\n Spring under Apache 2.0 license Spring Boot under Apache 2.0 license SLF4j under the MIT License SOFABolt under Apache License 2.0 SOFABolt under Apache License 2.0 Curator under Apache License 2.0  ","tags":null,"title":"Copyright statement","type":"projects","url":"/en/projects/sofa-dashboard/notice/","wordcount":47},{"author":null,"categories":null,"content":"Copyright statement of dependent components SOFARegistry uses some third-party open-source components, including but not limited to:\n Spring under Apache 2.0 license Spring Boot under Apache 2.0 license Netty under Apache License 2.0 SLF4j under the MIT License jersey under CDDL Version 1.1 SOFAJRaft under Apache License 2.0 SOFABolt under Apache License 2.0 SOFAHessian under Apache License 2.0  If you find anything we have missed, please let us know.\n","date":-62135596800,"description":"","dir":"projects/sofa-registry/notice/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"c40263ffd56a2f1292756c9fafea55e2","permalink":"/en/projects/sofa-registry/notice/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-registry/notice/","summary":"Copyright statement of dependent components SOFARegistry uses some third-party open-source components, including but not limited to:\n Spring under Apache 2.0 license Spring Boot under Apache 2.0 license Netty under Apache License 2.0 SLF4j under the MIT License jersey under CDDL Version 1.1 SOFAJRaft under Apache License 2.0 SOFABolt under Apache License 2.0 SOFAHessian under Apache License 2.0  If you find anything we have missed, please let us know.","tags":null,"title":"Copyright statement","type":"projects","url":"/en/projects/sofa-registry/notice/","wordcount":68},{"author":null,"categories":null,"content":"本文档主要介绍一个基于 jraft 的分布式计数器的例子。\n场景 在多个节点（机器）组成的一个 raft group 中保存一个分布式计数器，该计数器可以递增和获取，并且在所有节点之间保持一致，任何少数节点的挂掉都不会影响对外提供的两个服务：\n incrmentAndGet(delta) 递增 delta 数值并返回递增后的值。 get() 获取最新的值  RPC 请求 jraft 底层使用 bolt 作为通讯框架，定义两个请求\n IncrementAndGetRequest，用于递增  public class IncrementAndGetRequest implements Serializable { private static final long serialVersionUID = -5623664785560971849L; private long delta; public long getDelta() { return this.delta; } public void setDelta(long delta) { this.delta = delta; } }  GetValueRequest，用于获取最新值：  public class GetValueRequest implements Serializable { private static final long serialVersionUID = 9218253805003988802L; public GetValueRequest() { super(); } } 应答结果 ValueResponse，包括：\n success　是否成功 value 成功情况下返回的最新值 errorMsg 失败情况下的错误信息 redirect　发生了重新选举，需要跳转的新的leader节点。  public class ValueResponse implements Serializable { private static final long serialVersionUID = -4220017686727146773L; private long value; private boolean success; /** * redirect peer id */ private String redirect; private String errorMsg; public String getErrorMsg() { return this.errorMsg; } public void setErrorMsg(String errorMsg) { this.errorMsg = errorMsg; } ...... }  IncrementAndGetRequest 用于 Leader 服务端接收 IncrementAndAddClosure 请求后的回调处理：  public class IncrementAndAddClosure implements Closure { private CounterServer counterServer; private IncrementAndGetRequest request; private ValueResponse response; private Closure done; // 网络应答callback  public IncrementAndAddClosure(CounterServer counterServer, IncrementAndGetRequest request, ValueResponse response, Closure done) { super(); this.counterServer = counterServer; this.request = request; this.response = response; this.done = done; } @Override public void run(Status status) { // 返回应答给客户端  if (this.done != null) { done.run(status); } } public IncrementAndGetRequest getRequest() { return this.request; } public void setRequest(IncrementAndGetRequest request) { this.request = request; } public ValueResponse getResponse() { return this.response; } } 服务端 状态机 CounterStateMachine 首先持有一个初始值：\npublic class CounterStateMachine extends StateMachineAdapter { /** * counter value */ private AtomicLong value = new AtomicLong(0); 实现核心的 onApply(iterator) 方法，应用用户提交的请求到状态机：\n@Override public void onApply(Iterator iter) { // 遍历日志  while (iter.hasNext()) { long delta = 0; IncrementAndAddClosure closure = null; // done 回调不为null，必须在应用日志后调用，如果不为 null，说明当前是leader。  if (iter.done() != null) { // 当前是leader，可以直接从 IncrementAndAddClosure 中获取 delta，避免反序列化  closure = (IncrementAndAddClosure) iter.done(); delta = closure.getRequest().getDelta(); } else { // 其他节点应用此日志，需要反序列化 IncrementAndGetRequest，获取 delta  ByteBuffer data = iter.getData(); try { IncrementAndGetRequest request = Codecs.getSerializer(Codecs.Hessian2).decode(data.array(), IncrementAndGetRequest.class.getName()); delta = request.getDelta(); } catch (CodecException e) { LOG.error(\u0026amp;#34;Fail to decode IncrementAndGetRequest\u0026amp;#34;, e); } } long prev = this.value.get(); // 更新状态机  long …","date":-62135596800,"description":"","dir":"projects/sofa-jraft/counter-example/","fuzzywordcount":2500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"f9c54b9f7883ccb1d7c259b7101f4674","permalink":"/projects/sofa-jraft/counter-example/","publishdate":"0001-01-01T00:00:00Z","readingtime":5,"relpermalink":"/projects/sofa-jraft/counter-example/","summary":"本文档主要介绍一个基于 jraft 的分布式计数器的例子。 场景 在多个节点（机器）组成的一个 raft group 中保存一个分布式计数器，该计数器可以递增和获取，并且在所有","tags":null,"title":"Counter 例子详解","type":"projects","url":"/projects/sofa-jraft/counter-example/","wordcount":2404},{"author":null,"categories":null,"content":" Project address\n Introduction Jarslink 2.0 is available for both Spring Boot and SOFABoot; we just need to add the specified dependencies. To be convenient, it is recommended to use Jarslink 2.0 in the form of SOFABoot projects. This sample project is intended to demonstrate how to quickly reform a Spring Boot project into a SOFABoot project.\nReform After creating a Spring Boot project in the official Spring Boot website, we only need to introduce the SOFABoot dependencies. First, modify the configuration file pom.xml of the Maven project.\n\u0026amp;lt;parent\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-starter-parent\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${spring.boot.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;relativePath/\u0026amp;gt; \u0026amp;lt;/parent\u0026amp;gt; Replace as\n\u0026amp;lt;parent\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofaboot-dependencies\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.5.0-SNAPSHOT\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/parent\u0026amp;gt; Note: Currently Jarslink 2.0.0 is still at its snapshot version, and the SOFABoot 2.5.0 that it depends on will be released in the near future, so for the moment, the SOFABoot 2.5.0-SNAPSHOT version has to be introduced as the dependency. The pull of the SNAPSHOT package requires special configuration, for which you can refer to FAQ: How do I configure for pulling a SNAPSHOT dependency package?\nThen, add a Spring Boot or SOFABoot official Starter, such as:\n\u0026amp;lt;dependencies\u0026amp;gt; \u0026amp;lt;!-- Jarslink2.0 --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-jarslink-ark-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;classifier\u0026amp;gt;ark-plugin\u0026amp;lt;/classifier\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.0.0-SNAPSHOT\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!-- Web --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-starter-web\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;/dependencies\u0026amp;gt; To package the application into an Ark package or Biz package, we need to configure the sofa-Ark-maven-plugin packaging plugin in the main pom.xml file, and delete the native packaging plugin the Spring Boot configuration.\n\u0026amp;lt;build\u0026amp;gt; \u0026amp;lt;plugins\u0026amp;gt; \u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;executions\u0026amp;gt; \u0026amp;lt;execution\u0026amp;gt; \u0026amp;lt;!--goal executed to generate executable-ark-jar --\u0026amp;gt; \u0026amp;lt;goals\u0026amp;gt; \u0026amp;lt;goal\u0026amp;gt;repackage\u0026amp;lt;/goal\u0026amp;gt; \u0026amp;lt;/goals\u0026amp;gt; \u0026amp;lt;configuration\u0026amp;gt; \u0026amp;lt;!--specify destination where executable-ark-jar will be saved, default saved to ${project.build.directory}--\u0026amp;gt; \u0026amp;lt;outputDirectory\u0026amp;gt;./target\u0026amp;lt;/outputDirectory\u0026amp;gt; \u0026amp;lt;!--default none--\u0026amp;gt; \u0026amp;lt;arkClassifier\u0026amp;gt;executable-ark\u0026amp;lt;/arkClassifier\u0026amp;gt; \u0026amp;lt;/configuration\u0026amp;gt; \u0026amp;lt;/execution\u0026amp;gt; \u0026amp;lt;/executions\u0026amp;gt; \u0026amp;lt;/plugin\u0026amp;gt; \u0026amp;lt;/plugins\u0026amp;gt; \u0026amp;lt;/build\u0026amp;gt; Finally, add a parameter that SOFABoot must use under the application.properties file for the project, including spring.application.name (used to mark the name …","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-jarslink-jarslink-app-demo/","fuzzywordcount":500,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"46cb9153d039f01a375a569c2a9a5535","permalink":"/en/projects/sofa-boot/sofa-jarslink-jarslink-app-demo/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-boot/sofa-jarslink-jarslink-app-demo/","summary":"Project address\n Introduction Jarslink 2.0 is available for both Spring Boot and SOFABoot; we just need to add the specified dependencies. To be convenient, it is recommended to use Jarslink 2.0 in the form of SOFABoot projects. This sample project is intended to demonstrate how to quickly reform a Spring Boot project into a SOFABoot project.\nReform After creating a Spring Boot project in the official Spring Boot website, we only need to introduce the SOFABoot dependencies.","tags":null,"title":"Create a SOFABoot application","type":"projects","url":"/en/projects/sofa-boot/sofa-jarslink-jarslink-app-demo/","wordcount":417},{"author":null,"categories":null,"content":"SOFARPC provides a good extensibility mechanism, which provide SPI capabilities for each module. SOFARPC uses multiple filters to intercept requests and responses. These filters can be customized and extended by users. The execution order of custom filters is after the built-in filters. The procedure is as follows:\nBolt filter 1 Create a new custom filter.\npublic class CustomFilter extends Filter { @Override public boolean needToLoad(FilterInvoker invoker) { return true; } @Override public SofaResponse invoke(FilterInvoker invoker, SofaRequest request) throws SofaRpcException { SofaResponse response = invoker.invoke(request); return response; } } 2 The custom filter will be added into the interceptor chain. There are three specific ways to do this step.\n Method 1: In API. In this way, the custom filter can take effect in the specified provider or consumer.  // Service provider providerConfig.setFilterRef(Arrays.asList(new CustomFilter())); // Service caller consumerConfig.setFilterRef(Arrays.asList(new CustomFilter()));  Method 2: Add @Extension annotation + configuration extension file to the class.  @Extension(\u0026amp;#34;customer\u0026amp;#34;) public class CustomFilter extends Filter { @Override public boolean needToLoad(FilterInvoker invoker) { return true; } @Override public SofaResponse invoke(FilterInvoker invoker, SofaRequest request) throws SofaRpcException { SofaResponse response = invoker.invoke(request); return response; } } Create a new extension file META-INF/services/sofa-rpc/com.alipay.sofa.rpc.filter.Filter with the following content:\ncustomer=com.alipay.sofa.rpc.custom.CustomFilter Code injection.\n// Service provider providerConfig.setFilter(Arrays.asList(\u0026amp;#34;customer\u0026amp;#34;)); // Service caller consumerConfig.setFilter(Arrays.asList(\u0026amp;#34;customer\u0026amp;#34;));  Method 3: Add @Extension annotation + @AutoActive annotation + configuration extension file to the class. In this way, the code injection step in method 2 is replaced with the @AutoActive annotation. The custom filter can take effect in all providers or consumers. The providerSide parameter indicates whether it takes effect on the server, and the consumerSide parameter indicates whether it takes effect on the client.  @Extension(\u0026amp;#34;customer\u0026amp;#34;) @AutoActive(providerSide = true, consumerSide = true) public class customerFilter extends Filter { // ... } ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/custom-filter/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"30ff5937b52a7c2dd8028e878979a33d","permalink":"/en/projects/sofa-rpc/custom-filter/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-rpc/custom-filter/","summary":"SOFARPC provides a good extensibility mechanism, which provide SPI capabilities for each module. SOFARPC uses multiple filters to intercept requests and responses. These filters can be customized and extended by users. The execution order of custom filters is after the built-in filters. The procedure is as follows:\nBolt filter 1 Create a new custom filter.\npublic class CustomFilter extends Filter { @Override public boolean needToLoad(FilterInvoker invoker) { return true; } @Override public SofaResponse invoke(FilterInvoker invoker, SofaRequest request) throws SofaRpcException { SofaResponse response = invoker.","tags":null,"title":"Custom filter","type":"projects","url":"/en/projects/sofa-rpc/custom-filter/","wordcount":285},{"author":null,"categories":null,"content":"The route service address in SOFARPC is abstracted into a processing chain, and is processed by each router. Like filter, SOFARPC provides the same extensibility for router.\n@Extension(value = \u0026amp;#34;customerRouter\u0026amp;#34;) @AutoActive(consumerSide = true) public class CustomerRouter extends Router { @Override public void init(ConsumerBootstrap consumerBootstrap) { } @Override public boolean needToLoad(ConsumerBootstrap consumerBootstrap) { return true; } @Override public List\u0026amp;lt;ProviderInfo\u0026amp;gt; route(SofaRequest request, List\u0026amp;lt;ProviderInfo\u0026amp;gt; providerInfos) { return providerInfos; } Create a extension file META-INF/services/sofa-rpc/com.alipay.sofa.rpc.client.Router with the following content:\ncustomerRouter=com.alipay.sofa.rpc.custom.CustomRouter This file customized a CustomerRouter, which takes effect in all consumers. The parameter ConsumerBootstrap in init method is a wrapper class of the referenced service, and can get objects such as ConsumerConfig, proxy class, and service address pool. needToLoad indicates whether the Router is valid, and the route method is the method for filtering addresses.\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/custom-router/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"236e8d4bda3e856267a3575853aa900c","permalink":"/en/projects/sofa-rpc/custom-router/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/custom-router/","summary":"The route service address in SOFARPC is abstracted into a processing chain, and is processed by each router. Like filter, SOFARPC provides the same extensibility for router.\n@Extension(value = \u0026#34;customerRouter\u0026#34;) @AutoActive(consumerSide = true) public class CustomerRouter extends Router { @Override public void init(ConsumerBootstrap consumerBootstrap) { } @Override public boolean needToLoad(ConsumerBootstrap consumerBootstrap) { return true; } @Override public List\u0026lt;ProviderInfo\u0026gt; route(SofaRequest request, List\u0026lt;ProviderInfo\u0026gt; providerInfos) { return providerInfos; } Create a extension file META-INF/services/sofa-rpc/com.","tags":null,"title":"Custom router","type":"projects","url":"/en/projects/sofa-rpc/custom-router/","wordcount":131},{"author":null,"categories":null,"content":"SOFARPC supports custom business thread pools. A separate business thread pool can be set up for the specified service, isolated from SOFARPC\u0026amp;rsquo;s global business thread pool. Multiple services can share a single thread pool.\nSOFARPC requires that the type of custom thread pool must be com.alipay.sofa.rpc.server.UserThreadPool.\nUse XML If you publish the service using XML, you can first set the bean of the thread pool whose class is com.alipay.sofa.rpc.server.UserThreadPool, and then set the bean in the thread-pool-ref attribute of \u0026amp;lt;sofa:global-attrs\u0026amp;gt; tag.\n\u0026amp;lt;bean id=\u0026amp;#34;helloService\u0026amp;#34; class=\u0026amp;#34;com.alipay.sofa.rpc.quickstart.HelloService\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;!-- Customize a thread pool --\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;#34;customExecutor\u0026amp;#34; class=\u0026amp;#34;com.alipay.sofa.rpc.server.UserThreadPool\u0026amp;#34; init-method=\u0026amp;#34;init\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;#34;corePoolSize\u0026amp;#34; value=\u0026amp;#34;10\u0026amp;#34; /\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;#34;maximumPoolSize\u0026amp;#34; value=\u0026amp;#34;10\u0026amp;#34; /\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;#34;queueSize\u0026amp;#34; value=\u0026amp;#34;0\u0026amp;#34; /\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt; \u0026amp;lt;sofa:service ref=\u0026amp;#34;helloService\u0026amp;#34; interface=\u0026amp;#34;XXXService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;!-- Set the thread pool to a Service --\u0026amp;gt; \u0026amp;lt;sofa:global-attrs thread-pool-ref=\u0026amp;#34;customExecutor\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;/sofa:service\u0026amp;gt; Use Annotation If you publish the service using Annotation, you can set the bean of the custom thread pool by setting the userThreadPool attribute of @SofaServiceBinding:\n@SofaService(bindings = {@SofaServiceBinding(bindingType = \u0026amp;#34;bolt\u0026amp;#34;, userThreadPool = \u0026amp;#34;customThreadPool\u0026amp;#34;)}) public class SampleServiceImpl implements SampleService { } Use API in Spring environment If you publish a service using the API in Spring environment, you can configure a custom thread pool by calling the setUserThreadPool method of BoltBindingParam:\nBoltBindingParam boltBindingParam = new BoltBindingParam(); boltBindingParam.setUserThreadPool(new UserThreadPool()); Use API in non-Spring environment If you publish service using the API in non-Spring environment, you can set a custom thread pool as follows:\nUserThreadPool threadPool = new UserThreadPool(); threadPool.setCorePoolSize(10); threadPool.setMaximumPoolSize(100); threadPool.setKeepAliveTime(200); threadPool.setPrestartAllCoreThreads(false); threadPool.setAllowCoreThreadTimeOut(false); threadPool.setQueueSize(200); UserThreadPoolManager.registerUserThread(ConfigUniqueNameGenerator.getUniqueName(providerConfig), threadPool); As above, a custom thread pool is set up for the HelloService service.\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/custom-thread-pool/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"4d582a7894b2381248522f3a1fc400c9","permalink":"/en/projects/sofa-rpc/custom-thread-pool/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-rpc/custom-thread-pool/","summary":"SOFARPC supports custom business thread pools. A separate business thread pool can be set up for the specified service, isolated from SOFARPC\u0026rsquo;s global business thread pool. Multiple services can share a single thread pool.\nSOFARPC requires that the type of custom thread pool must be com.alipay.sofa.rpc.server.UserThreadPool.\nUse XML If you publish the service using XML, you can first set the bean of the thread pool whose class is com.alipay.sofa.rpc.server.UserThreadPool, and then set the bean in the thread-pool-ref attribute of \u0026lt;sofa:global-attrs\u0026gt; tag.","tags":null,"title":"Custom thread pool","type":"projects","url":"/en/projects/sofa-rpc/custom-thread-pool/","wordcount":252},{"author":null,"categories":null,"content":"You can view basic information of your application on SOFADashboard, including the IP address, ports, and health check status. This feature is dependent on the SOFADashboard client. If you want to display the information about an application on the SOFADashboard control page, import the sofa-dashboard-client dependency.\n\u0026amp;lt;denpendency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-dashboard-client\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/denpendency\u0026amp;gt; Function display ","date":-62135596800,"description":"","dir":"projects/sofa-dashboard/dashboard-client/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"60586c6dfee1f2afcdac88cbe7a36b83","permalink":"/en/projects/sofa-dashboard/dashboard-client/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-dashboard/dashboard-client/","summary":"You can view basic information of your application on SOFADashboard, including the IP address, ports, and health check status. This feature is dependent on the SOFADashboard client. If you want to display the information about an application on the SOFADashboard control page, import the sofa-dashboard-client dependency.\n\u0026lt;denpendency\u0026gt; \u0026lt;groupId\u0026gt;com.alipay.sofa\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;sofa-dashboard-client\u0026lt;/artifactId\u0026gt; \u0026lt;/denpendency\u0026gt; Function display ","tags":null,"title":"Dashboard client","type":"projects","url":"/en/projects/sofa-dashboard/dashboard-client/","wordcount":52},{"author":null,"categories":null,"content":"In this document will demonstrate how to use SOFATracer to track of Datasource.\nAssuming you have built a simple Spring Web project based on SOFABoot, Then you can be operated by the following steps:\nIntroduce SOFATracer Introduce SOFATracer dependency in the new Spring Boot project:\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;tracer-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.2.0\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; Introduce h2database dependencies For convenience, we use the h2database memory database for test. So, we need to introduce the following dependencies:\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.h2database\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;h2\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;scope\u0026amp;gt;runtime\u0026amp;lt;/scope\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;mysql\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;mysql-connector-java\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; Introduce the required connection pool dependencies Introduce the required connection pool dependency packages, such as druid, c3p0, tomcat, dbcp, Hikari, and so on.\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alibaba\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;druid\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;1.0.12\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;c3p0\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;c3p0\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;0.9.1.1\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.apache.tomcat\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;tomcat-jdbc\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;8.5.31\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;commons-dbcp\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;commons-dbcp\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;1.4\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.zaxxer\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;HikariCP-java6\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.3.8\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; Configure data source Taking HikariCP as the example, we create a new Spring configuration file named datasource.xml, which defines the followings:\n\u0026amp;lt;?xml version=\u0026amp;#34;1.0\u0026amp;#34; encoding=\u0026amp;#34;UTF-8\u0026amp;#34;?\u0026amp;gt; \u0026amp;lt;beans xmlns=\u0026amp;#34;http://www.springframework.org/schema/beans\u0026amp;#34; xmlns:xsi=\u0026amp;#34;http://www.w3.org/2001/XMLSchema-instance\u0026amp;#34; xsi:schemaLocation=\u0026amp;#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;!-- dataSource pool --\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;#34;simpleDataSource\u0026amp;#34; class=\u0026amp;#34;com.zaxxer.hikari.HikariDataSource\u0026amp;#34; destroy-method=\u0026amp;#34;close\u0026amp;#34; primary=\u0026amp;#34;true\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;#34;driverClassName\u0026amp;#34; value=\u0026amp;#34;org.h2.Driver\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;#34;jdbcUrl\u0026amp;#34; value=\u0026amp;#34;jdbc:h2:~/test\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;#34;username\u0026amp;#34; value=\u0026amp;#34;sofa\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;#34;password\u0026amp;#34; value=\u0026amp;#34;123456\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt; \u0026amp;lt;/beans\u0026amp;gt; Application configuration  Required configuration  It should be noted that it is required to configure the application …","date":-62135596800,"description":"","dir":"projects/sofa-tracer/usage-of-datasource/","fuzzywordcount":700,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"d9d8f6756a294104647067eaa7827f61","permalink":"/en/projects/sofa-tracer/usage-of-datasource/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/en/projects/sofa-tracer/usage-of-datasource/","summary":"In this document will demonstrate how to use SOFATracer to track of Datasource.\nAssuming you have built a simple Spring Web project based on SOFABoot, Then you can be operated by the following steps:\nIntroduce SOFATracer Introduce SOFATracer dependency in the new Spring Boot project:\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alipay.sofa\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;tracer-sofa-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; Introduce h2database dependencies For convenience, we use the h2database memory database for test. So, we need to introduce the following dependencies:","tags":null,"title":"DataSource Integration","type":"projects","url":"/en/projects/sofa-tracer/usage-of-datasource/","wordcount":641},{"author":null,"categories":null,"content":"Datasource Log Format SOFATracer tracks the standard JDBC data source and outputs the chain data of SQL statement execution, in the default JSON format.\nDataSource digest log (datasource-client-digest.log) The data is output in JSON format. Each key meaning is as follows:\n   Key Meaning     Time log printing time   Local.app Current application name   traceId TraceId   spanId SpanId   Database.name Database name   Sql SQL execution statement   Result.code SQL execution status code   Total.time SQL statement execution total time   Connection.establish.span SQL execution connection establishment time   Db.execute.cost SQL execution time   Database.type Database type   Database.endpoint Database url   Current.thread.name Current thread name   Baggage Transparently transmitted baggage data    Example:\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2018-09-28 01:11:56.715\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;SOFATracerDataSource\u0026amp;#34;,\u0026amp;#34;traceId\u0026amp;#34;:\u0026amp;#34;1e1bcab91538068316462100111113\u0026amp;#34;,\u0026amp;#34;spanId\u0026amp;#34;:\u0026amp;#34;0.1.2\u0026amp;#34;,\u0026amp;#34;database.name\u0026amp;#34;:\u0026amp;#34;test\u0026amp;#34;,\u0026amp;#34;sql\u0026amp;#34;:\u0026amp;#34;CREATE TABLE TEST(ID INT PRIMARY KEY%2C NAME VARCHAR(255));\u0026amp;#34;,\u0026amp;#34;result.code\u0026amp;#34;:\u0026amp;#34;success\u0026amp;#34;,\u0026amp;#34;total.time\u0026amp;#34;:\u0026amp;#34;228ms\u0026amp;#34;,\u0026amp;#34;connection.establish.span\u0026amp;#34;:\u0026amp;#34;220ms\u0026amp;#34;,\u0026amp;#34;db.execute.cost\u0026amp;#34;:\u0026amp;#34;3ms\u0026amp;#34;,\u0026amp;#34;database.type\u0026amp;#34;:\u0026amp;#34;h2\u0026amp;#34;,\u0026amp;#34;database.endpoint\u0026amp;#34;:\u0026amp;#34;jdbc:h2:~/test:-1\u0026amp;#34;,\u0026amp;#34;current.thread.name\u0026amp;#34;:\u0026amp;#34;http-nio-8080-exec-1\u0026amp;#34;,\u0026amp;#34;baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;} DataSource statistical Log (datasource-client-stat.log) stat.key is the set of statistical keywords in this period, which uniquely determines a set of statistical data, including local.app, database.name, and SQL field.\nExample:\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2018-09-28 01:12:43.647\u0026amp;#34;,\u0026amp;#34;stat.key\u0026amp;#34;:{\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;SOFATracerDataSource\u0026amp;#34;,\u0026amp;#34;database.name\u0026amp;#34;:\u0026amp;#34;test\u0026amp;#34;, \u0026amp;#34;sql\u0026amp;#34;:\u0026amp;#34;CREATE TABLE TEST(ID INT PRIMARY KEY%2C NAME VARCHAR(255));\u0026amp;#34;},\u0026amp;#34;count\u0026amp;#34;:1,\u0026amp;#34;total.cost.milliseconds\u0026amp;#34;:228,\u0026amp;#34;success\u0026amp;#34;:\u0026amp;#34;true\u0026amp;#34;,\u0026amp;#34;load.test\u0026amp;#34;:\u0026amp;#34;F\u0026amp;#34;} ","date":-62135596800,"description":"","dir":"projects/sofa-tracer/log-format-datasource/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"647de768aff8ececc8276d247c5afee1","permalink":"/en/projects/sofa-tracer/log-format-datasource/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-tracer/log-format-datasource/","summary":"Datasource Log Format SOFATracer tracks the standard JDBC data source and outputs the chain data of SQL statement execution, in the default JSON format.\nDataSource digest log (datasource-client-digest.log) The data is output in JSON format. Each key meaning is as follows:\n   Key Meaning     Time log printing time   Local.app Current application name   traceId TraceId   spanId SpanId   Database.","tags":null,"title":"DataSource log","type":"projects","url":"/en/projects/sofa-tracer/log-format-datasource/","wordcount":147},{"author":null,"categories":null,"content":"在本文档将演示如何使用 SOFATracer 对 DataSource 进行埋点。\n SOFATracer 2.2.0 基于标准的 JDBC 接口实现，支持对标准的数据库连接池（如 DBCP、Druid、c3p0、tomcat、HikariCP、BoneCP）埋点。下面演示如何接入 SOFATracer 埋点能力。\n 假设你已经基于 SOFABoot 构建了一个简单的 Spring Web 工程，那么可以通过如下步骤进行操作：\n依赖引入 引入 SOFATracer 依赖 \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;tracer-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 引入 h2database 依赖 为了方便，我们使用 h2database 内存数据库测试，引入如下依赖：\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.h2database\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;h2\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;scope\u0026amp;gt;runtime\u0026amp;lt;/scope\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;mysql\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;mysql-connector-java\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 引入所需的连接池依赖 用户引入所需的连接池依赖包，如 druid, c3p0, tomcat, dbcp, Hikari 等。\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alibaba\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;druid\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;1.0.12\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;c3p0\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;c3p0\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;0.9.1.1\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.apache.tomcat\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;tomcat-jdbc\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;8.5.31\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;commons-dbcp\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;commons-dbcp\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;1.4\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.zaxxer\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;HikariCP-java6\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.3.8\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 配置数据源 我们以 HikariCP 为例，新建一个名为datasource.xml Spring 配置文件，定义如下内容:\n\u0026amp;lt;?xml version=\u0026amp;#34;1.0\u0026amp;#34; encoding=\u0026amp;#34;UTF-8\u0026amp;#34;?\u0026amp;gt; \u0026amp;lt;beans xmlns=\u0026amp;#34;http://www.springframework.org/schema/beans\u0026amp;#34; xmlns:xsi=\u0026amp;#34;http://www.w3.org/2001/XMLSchema-instance\u0026amp;#34; xsi:schemaLocation=\u0026amp;#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;!-- dataSource pool --\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;#34;simpleDataSource\u0026amp;#34; class=\u0026amp;#34;com.zaxxer.hikari.HikariDataSource\u0026amp;#34; destroy-method=\u0026amp;#34;close\u0026amp;#34; primary=\u0026amp;#34;true\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;#34;driverClassName\u0026amp;#34; value=\u0026amp;#34;org.h2.Driver\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;#34;jdbcUrl\u0026amp;#34; value=\u0026amp;#34;jdbc:h2:~/test\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;#34;username\u0026amp;#34; value=\u0026amp;#34;sofa\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;#34;password\u0026amp;#34; value=\u0026amp;#34;123456\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt; \u0026amp;lt;/beans\u0026amp;gt; 应用配置  必要配置  需要注意一点，引入 SOFATracer 需要强制配置应用名，否则应用启动失败。这一属性和 SOFABoot 框架要求一致，配置如下：\nspring.application.name=SOFATracerDataSource  非必要配置  为了该演示工程正常运行，需要配置 h2database 属性；另为了方便查看日志，配置日志路径。如下：\n# logging path logging.path=./logs # h2 web consloe 路径 spring.h2.console.path=/h2-console # 开启 h2 web consloe，默认为 false spring.h2.console.enabled=true #允许远程访问 h2 web consloe spring.h2.console.settings.web-allow-others=true spring.datasource.username=sofa spring.datasource.password=123456 …","date":-62135596800,"description":"","dir":"projects/sofa-tracer/usage-of-datasource/","fuzzywordcount":1100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"d9d8f6756a294104647067eaa7827f61","permalink":"/projects/sofa-tracer/usage-of-datasource/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/sofa-tracer/usage-of-datasource/","summary":"在本文档将演示如何使用 SOFATracer 对 DataSource 进行埋点。 SOFATracer 2.2.0 基于标准的 JDBC 接口实现，支持对标准的数据库连接池（如 DBCP、Druid、c3p0、tomcat、H","tags":null,"title":"DataSource 埋点接入","type":"projects","url":"/projects/sofa-tracer/usage-of-datasource/","wordcount":1037},{"author":null,"categories":null,"content":"SOFATracer 对标准的 JDBC 数据源进行埋点，输出 SQL 语句执行链路数据，默认日志输出为 JSON 数据格式。\nDataSource 摘要日志（datasource-client-digest.log） 以 JSON 格式输出的数据，相应 key 的含义解释如下：\n   key 表达含义     time 日志打印时间   local.app 当前应用名   traceId TraceId   spanId SpanId   span.kind Span 类型   result.code 状态码   current.thread.name 当前线程名   time.cost.milliseconds span 耗时   database.name 数据库名称   sql sql执行语句   connection.establish.span sql执行建连时间   db.execute.cost sql执行时间   database.type 数据库类型   database.endpoint 数据库url   sys.baggage 系统透传的 baggage 数据   biz.baggage 业务透传的 baggage 数据    样例：\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2019-09-02 21:31:31.566\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;SOFATracerDataSource\u0026amp;#34;,\u0026amp;#34;traceId\u0026amp;#34;:\u0026amp;#34;0a0fe91d156743109138810017302\u0026amp;#34;,\u0026amp;#34;spanId\u0026amp;#34;:\u0026amp;#34;0.1\u0026amp;#34;,\u0026amp;#34;span.kind\u0026amp;#34;:\u0026amp;#34;client\u0026amp;#34;,\u0026amp;#34;result.code\u0026amp;#34;:\u0026amp;#34;00\u0026amp;#34;,\u0026amp;#34;current.thread.name\u0026amp;#34;:\u0026amp;#34;http-nio-8080-exec-1\u0026amp;#34;,\u0026amp;#34;time.cost.milliseconds\u0026amp;#34;:\u0026amp;#34;15ms\u0026amp;#34;,\u0026amp;#34;database.name\u0026amp;#34;:\u0026amp;#34;test\u0026amp;#34;,\u0026amp;#34;sql\u0026amp;#34;:\u0026amp;#34;DROP TABLE IF EXISTS TEST; CREATE TABLE TEST(ID INT PRIMARY KEY%2C NAME VARCHAR(255));\u0026amp;#34;,\u0026amp;#34;connection.establish.span\u0026amp;#34;:\u0026amp;#34;128ms\u0026amp;#34;,\u0026amp;#34;db.execute.cost\u0026amp;#34;:\u0026amp;#34;15ms\u0026amp;#34;,\u0026amp;#34;database.type\u0026amp;#34;:\u0026amp;#34;h2\u0026amp;#34;,\u0026amp;#34;database.endpoint\u0026amp;#34;:\u0026amp;#34;jdbc:h2:~/test:-1\u0026amp;#34;,\u0026amp;#34;sys.baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;,\u0026amp;#34;biz.baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;} DataSource 统计日志（datasource-client-stat.log） stat.key 即本段时间内的统计关键字集合，统一关键字集合唯一确定一组统计数据，包含local.app、database.name、和 sql 字段.\n样例：\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2019-09-02 21:31:50.435\u0026amp;#34;,\u0026amp;#34;stat.key\u0026amp;#34;:{\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;SOFATracerDataSource\u0026amp;#34;,\u0026amp;#34;database.name\u0026amp;#34;:\u0026amp;#34;test\u0026amp;#34;,\u0026amp;#34;sql\u0026amp;#34;:\u0026amp;#34;DROP TABLE IF EXISTS TEST; CREATE TABLE TEST(ID INT PRIMARY KEY%2C NAME VARCHAR(255));\u0026amp;#34;},\u0026amp;#34;count\u0026amp;#34;:1,\u0026amp;#34;total.cost.milliseconds\u0026amp;#34;:15,\u0026amp;#34;success\u0026amp;#34;:\u0026amp;#34;true\u0026amp;#34;,\u0026amp;#34;load.test\u0026amp;#34;:\u0026amp;#34;F\u0026amp;#34;} ","date":-62135596800,"description":"","dir":"projects/sofa-tracer/log-format-datasource/","fuzzywordcount":400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"647de768aff8ececc8276d247c5afee1","permalink":"/projects/sofa-tracer/log-format-datasource/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-tracer/log-format-datasource/","summary":"SOFATracer 对标准的 JDBC 数据源进行埋点，输出 SQL 语句执行链路数据，默认日志输出为 JSON 数据格式。 DataSource 摘要日志（datasource-client-digest.","tags":null,"title":"DataSource 日志","type":"projects","url":"/projects/sofa-tracer/log-format-datasource/","wordcount":330},{"author":null,"categories":null,"content":"﻿SOFABoot is based on Spring Boot. It means SOFABoot manages SOFA middleware dependencies and provides the Starter for Spring Boot, facilitating the use of SOFA middleware in Spring Boot.\nSOFABoot dependency management You must load SOFABoot\u0026amp;rsquo;s management dependencies before using SOFA middleware. In a way similar to use Spring Boot, add the configuration tag \u0026amp;lt;parent/\u0026amp;gt; in the project settings:\n\u0026amp;lt;parent\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofaboot-dependencies\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${sofa.boot.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/parent\u0026amp;gt; Where ${sofa.boot.version} represents the SOFABoot version (refer to release history).\nUse Middleware of SOFAStack For SOFABoot, use -sofa-boot-starter suffixes to name middleware components. If you want to use middleware, simply add its dependencies; To use SOFARPC, for example, simply add the following Maven dependencies:\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;rpc-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; Note that there is no version declaration in the above Maven dependencies as the version has already been declared in sofabook-dependencies. This allows for unified upgrade of all SOFA middleware versions, allaying concerns over dependency conflicts or incompatibility brought by upgrade of a single middleware version. The SOFABoot middleware under control is listed as follows:\n   Middleware starter     SOFARPC rpc-sofa-boot-starter   SOFATracer tracer-sofa-boot-starter   SOFALookout lookout-sofa-boot-starter    Introducing SOFABoot Extension Based on Spring Boot, SOFABoot provides extended capabilities such as health check, module isolation, and class isolation. In accordance with Spring Boot\u0026amp;rsquo;s the dependency-as-a-service principle, the extension capability will be ready immediately after relevant dependencies are added. Currently, there are several extension modules available:\n   Extension components starter     Health check healthcheck-sofa-boot-starter   Module isolation Isle-Sofa-boot-starter   Class isolation sofa-Ark-springboot-starter   Test extension test-Sofa-boot-starter    Introducing the SOFA middleware: the Ark plug-in SOFABoot provides a class isolation component—SOFAArk, which enables users to package third-party packages with dependency conflicts into an Ark plug-in. At run time, the Ark plug-in is loaded with a separate classloader; it is isolated from other Ark plug-ins and business dependencies to address class conflicts. SOFABoot provides SOFARPC and SOFATracer\u0026amp;rsquo;s Ark plug-ins; the Ark plug-in SOFARPC, for example, is loaded into the application to replace SOFARPC starter, to isolate the application from SOFARPC and its indirect dependencies. The controlled Ark plug-ins are listed as follows:\n   Ark plug-in plugin     SOFARPC rpc-sofa-boot-plugin   SOFATracer tracer-sofa-boot-plugin    Introducing SOFABoot namespace Before using SOFA middleware, we need to add relevant …","date":-62135596800,"description":"","dir":"projects/sofa-boot/dependency-management/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"dabdbd425f20dee4d7ab580d43574456","permalink":"/en/projects/sofa-boot/dependency-management/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-boot/dependency-management/","summary":"﻿SOFABoot is based on Spring Boot. It means SOFABoot manages SOFA middleware dependencies and provides the Starter for Spring Boot, facilitating the use of SOFA middleware in Spring Boot.\nSOFABoot dependency management You must load SOFABoot\u0026rsquo;s management dependencies before using SOFA middleware. In a way similar to use Spring Boot, add the configuration tag \u0026lt;parent/\u0026gt; in the project settings:\n\u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;com.alipay.sofa\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;sofaboot-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${sofa.boot.version}\u0026lt;/version\u0026gt; \u0026lt;/parent\u0026gt; Where ${sofa.boot.version} represents the SOFABoot version (refer to release history).","tags":null,"title":"Dependency management","type":"projects","url":"/en/projects/sofa-boot/dependency-management/","wordcount":391},{"author":null,"categories":null,"content":"Environment preparation To use SOFARegistry, you need to prepare the basic environment first. SOFARegistry depends on the following environment:\n Linux, UNIX, Mac, and Windows are supported. JDK8 Compile it with Apache Maven 3.2.5 or later versions.  Two deployment modes  Integrated deployment  Package and integrate the three roles of meta, data, and session into one jvm, which can be deployed on a standalone machine or a cluster. The deployment is simple.   Independent deployment  Deploy the meta, data, and session roles separately. You can deploy each of them on a standalone machine or a cluster. You can deploy different numbers of servers for each role as needed. We recommend that you use this deployment mode in the production environment.    Deployment steps 1. Download source code, and compile and package the code 1.1 Download the source code git clone https://github.com/sofastack/sofa-registry.git cd sofa-registry 1.2 Compile and package the code mvn clean package -DskipTests 2. Deploy SOFARegistry 2.1 Integrated deployment Package and integrate the three roles of meta, data, and session into one jvm, which can be deployed on a standalone machine or a cluster.\n2.1.1 Standalone deployment For more information about the standalone deployment mode of integrated deployment, see Quick start- Server deployment.\n2.1.2 Cluster deployment  Decompress registry-integration.tgz and modify the configuration file.  Cluster deployment: In this mode, you need to build a cluster of two or more servers. We recommend that you use at least three servers. Note: Currently, you cannot deploy more than one SOFARegistry instance on the same server, which means you must have at least three different servers. The method for deploying SOFARegistry on each server is basically the same as that in standalone deployment:\ncp server/distribution/integration/target/registry-integration.tgz \u0026amp;lt;somewhere\u0026amp;gt; cd \u0026amp;lt;somewhere\u0026amp;gt; \u0026amp;amp;\u0026amp;amp; mkdir registry-integration tar -zxvf registry-integration.tgz -C registry-integration The difference is that, when you deploy each server in the cluster deployment mode, you need to modify the conf/application.properties configuration:\n# Enter the IP addresses or hostnames of the three servers in the following fields (the hostname will be resolved to the IP address within SOFARegistry) nodes.metaNode=DefaultDataCenter:\u0026amp;lt;hostname1\u0026amp;gt;,\u0026amp;lt;hostname2\u0026amp;gt;,\u0026amp;lt;hostname3\u0026amp;gt; nodes.localDataCenter=DefaultDataCenter nodes.localRegion=DefaultZone  Start registry-integration  After modifying the configuration file for each server, you can start registry-integration as specified in Server deployment.\n Linux/Unix/Mac: sh bin/startup.sh. Windows: Double click the startup.bat file under the bin directory. Check the running status: For each server, you can access the healthcheck API provided by these three roles, or view logs/registry-startup.log to check the running status.  # View the healthcheck API of the meta role (one leader and two followers): $ …","date":-62135596800,"description":"","dir":"projects/sofa-registry/deployment/","fuzzywordcount":1000,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"7e28583bc38be66af8d704d7fbcd9dd4","permalink":"/en/projects/sofa-registry/deployment/","publishdate":"0001-01-01T00:00:00Z","readingtime":5,"relpermalink":"/en/projects/sofa-registry/deployment/","summary":"Environment preparation To use SOFARegistry, you need to prepare the basic environment first. SOFARegistry depends on the following environment:\n Linux, UNIX, Mac, and Windows are supported. JDK8 Compile it with Apache Maven 3.2.5 or later versions.  Two deployment modes  Integrated deployment  Package and integrate the three roles of meta, data, and session into one jvm, which can be deployed on a standalone machine or a cluster. The deployment is simple.","tags":null,"title":"Deployment","type":"projects","url":"/en/projects/sofa-registry/deployment/","wordcount":951},{"author":null,"categories":null,"content":"1. How to compile  Install JDK7 or later versions, and Maven 3.2.5 or later versions. Directly download the code, and execute the following command in the code directory:\n mvn clean install 2. Version release Version number ACTS uses a three-digit version number in the form of major, minor, and patch, for example, 1.0.1.\nFor more information, see https://semver.org/.\n Major version number: All versions within a major version number must be compatible with each other. They are not necessarily compatible with other major versions. However, it is best to be downward compatible. Minor version number: represents feature enhancement. The larger the version number, more features it has. Patch number: represents the BugFix version. Such versions are only used for bug fixing. The larger the version number, the more stable the application is.  Version maintenance At most two versions can be maintained simultaneously.\nFor example, if the current version of the master branch code is 1.3.0, the BugFix branch of version 1.2.x will be maintained, but bugs in branch 1.1.x will no longer be fixed. Therefore, a version upgrade for 1.1.x is recommended.\nRelease process  The develop branches use SNAPSHOT versions, for example, 1.3.0-SNAPSHOT. Upon formal release, SNAPSHOT is replaced with a formal version number, for example 1.3.0. After the formal release, the next version is pulled, for example, 1.3.1-SNAPSHOT.  3. Testing Unit test Add the unit test case to the model that you have developed. The package name of the test class is identical to that of the tested class.\n","date":-62135596800,"description":"","dir":"projects/sofa-acts/developer-guide/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"fcacc7e89b979f3aec8dc3333a7a3c37","permalink":"/en/projects/sofa-acts/developer-guide/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-acts/developer-guide/","summary":"1. How to compile  Install JDK7 or later versions, and Maven 3.2.5 or later versions. Directly download the code, and execute the following command in the code directory:\n mvn clean install 2. Version release Version number ACTS uses a three-digit version number in the form of major, minor, and patch, for example, 1.0.1.\nFor more information, see https://semver.org/.\n Major version number: All versions within a major version number must be compatible with each other.","tags":null,"title":"Developer guide","type":"projects","url":"/en/projects/sofa-acts/developer-guide/","wordcount":249},{"author":null,"categories":null,"content":"Develope guide of code contribution First refer to the basic Notes for code contribution  Note the test case coverage; Note the code format;  Verify samples  Import the sample Maven project separately; Modify the dependency version in the corresponding Pom file; Verify that samples can work correctly as well.  ","date":-62135596800,"description":"","dir":"projects/sofa-lookout/development-use-guide/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"423a54ec3f5fbfc9c0e150eb853738ae","permalink":"/en/projects/sofa-lookout/development-use-guide/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-lookout/development-use-guide/","summary":"Develope guide of code contribution First refer to the basic Notes for code contribution  Note the test case coverage; Note the code format;  Verify samples  Import the sample Maven project separately; Modify the dependency version in the corresponding Pom file; Verify that samples can work correctly as well.  ","tags":null,"title":"Development guide","type":"projects","url":"/en/projects/sofa-lookout/development-use-guide/","wordcount":48},{"author":null,"categories":null,"content":"SOFARPC supports scenarios where a specified address is called.\nThe use of direct call in Java API is as follows, only set the direct connection address:\nConsumerConfig\u0026amp;lt;HelloService\u0026amp;gt; consumer = new ConsumerConfig\u0026amp;lt;HelloService\u0026amp;gt;() .setInterfaceId(HelloService.class.getName()) .setRegistry(registryConfig) .setDirectUrl(\u0026amp;#34;bolt://127.0.0.1:12201\u0026amp;#34;); The use of direct call in XML is as follows:\n\u0026amp;lt;sofa:reference interface=\u0026amp;#34;com.alipay.sample.HelloService\u0026amp;#34; id=\u0026amp;#34;helloService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;sofa:route target-url=\u0026amp;#34;127.0.0.1:12200\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt; The use of direct call in Annotation is as follows:\n@SofaReference(binding = @SofaReferenceBinding(bindingType = \u0026amp;#34;bolt\u0026amp;#34;, directUrl = \u0026amp;#34;127.0.0.1:12220\u0026amp;#34;)) private SampleService sampleService; ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/peer-to-peer/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"b1815c322f5dc9528f6429d1d5e38369","permalink":"/en/projects/sofa-rpc/peer-to-peer/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/peer-to-peer/","summary":"SOFARPC supports scenarios where a specified address is called.\nThe use of direct call in Java API is as follows, only set the direct connection address:\nConsumerConfig\u0026lt;HelloService\u0026gt; consumer = new ConsumerConfig\u0026lt;HelloService\u0026gt;() .setInterfaceId(HelloService.class.getName()) .setRegistry(registryConfig) .setDirectUrl(\u0026#34;bolt://127.0.0.1:12201\u0026#34;); The use of direct call in XML is as follows:\n\u0026lt;sofa:reference interface=\u0026#34;com.alipay.sample.HelloService\u0026#34; id=\u0026#34;helloService\u0026#34;\u0026gt; \u0026lt;sofa:binding.bolt\u0026gt; \u0026lt;sofa:route target-url=\u0026#34;127.0.0.1:12200\u0026#34;/\u0026gt; \u0026lt;/sofa:binding.bolt\u0026gt; \u0026lt;/sofa:reference\u0026gt; The use of direct call in Annotation is as follows:\n@SofaReference(binding = @SofaReferenceBinding(bindingType = \u0026#34;bolt\u0026#34;, directUrl = \u0026#34;127.0.0.1:12220\u0026#34;)) private SampleService sampleService; ","tags":null,"title":"Direct call","type":"projects","url":"/en/projects/sofa-rpc/peer-to-peer/","wordcount":73},{"author":null,"categories":null,"content":"Fault Recover Including Fault-Hystrix and Fault-Tolerance features.\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/fault/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"e567dc5e291867e92c8dd1c4f953b768","permalink":"/en/projects/sofa-rpc/fault/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/fault/","summary":"Fault Recover Including Fault-Hystrix and Fault-Tolerance features.","tags":null,"title":"Disaster recovery","type":"projects","url":"/en/projects/sofa-rpc/fault/","wordcount":7},{"author":null,"categories":null,"content":"Distributed consensus algorithm Understand distributed consensus  Multiple participants reach a complete consensus on one thing: one conclusion for one thing. The conclusion cannot be overthrown.  Typical distributed consensus algorithms  Paxos: It is considered as the foundation of distributed consensus algorithms. Other algorithms are its variants. However, the Paxos paper only provides the process of a single proposal, without describing the details of multi-paxos that is required for state machine replication. Paxos implementation involves high engineering complexity, for example, multiple-point writes and log hole tolerance. Zab: It is applied in ZooKeeper and widely used in the industry. However, it is not available as a universal library. Raft: It is known for being easy to understand. There are many renowned Raft implementations in the industry, such as etcd, Braft, and TiKV.  Introduction to Raft Raft is in nature a Paxos-based distributed consensus algorithm that is much easier to understand than Paxos. Unlike Paxos, Raft divides the protocols into independent modules, and uses a streamlined design, making the Raft protocol easier to implement.\nSpecifically, Raft divides consensus protocols into almost completely decoupled modules, such as leader election, membership change, log replication, and snapshot.\nRaft adopts a more streamlined design by preventing reordering commits, simplifying roles (it has only three roles: leader, follower, and candidate), allowing only the leader to write, and using randomized timeout values to design leader election.\nFeature: strong leader  The system can have only one leader at the same time, and only the leader can accept requests sent by clients. The leader is responsible for communication with all followers, sending proposals to all followers, and receiving responses from the majority of followers. The leader also needs to send heartbeats to all followers to maintain its leadership.  To summarize, a strong leader tells its followers: \u0026amp;ldquo;Do not say anything. Do what I said and let me know when you finish!\u0026amp;quot; In addition, a leader must always remain active by sending heartbeats to followers. Otherwise, a follower will take its place.\nReplicated state machine Assume we have an infinitely incrementing sequence (system) a[1, 2, 3…]. If for any integer i, the value of a[i] meets the distributed consensus requirement, the system meets the requirement of a consensus state machine. Basically, all real life systems are subject to continuous operations, and reaching consensus on a single value is definitely not enough. To make sure all replicas of a real life system are consistent, we usually convert the operations into entries of a write-ahead-log(WAL). Then, we make sure all replicas of the system reach a consensus on the WAL entries, so that each replica performs operations of the WAL entries in order. As a result, the replicas are in consistent states.\n A client sent a write (operation) request to the …","date":-62135596800,"description":"","dir":"projects/sofa-jraft/consistency-raft-jraft/","fuzzywordcount":4900,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"a0e98df1bec305cca7db6fc34fc97771","permalink":"/en/projects/sofa-jraft/consistency-raft-jraft/","publishdate":"0001-01-01T00:00:00Z","readingtime":23,"relpermalink":"/en/projects/sofa-jraft/consistency-raft-jraft/","summary":"Distributed consensus algorithm Understand distributed consensus  Multiple participants reach a complete consensus on one thing: one conclusion for one thing. The conclusion cannot be overthrown.  Typical distributed consensus algorithms  Paxos: It is considered as the foundation of distributed consensus algorithms. Other algorithms are its variants. However, the Paxos paper only provides the process of a single proposal, without describing the details of multi-paxos that is required for state machine replication.","tags":null,"title":"Distributed consensus - Raft and JRaft","type":"projects","url":"/en/projects/sofa-jraft/consistency-raft-jraft/","wordcount":4868},{"author":null,"categories":null,"content":"SOFARPC provides support for the Dubbo protocol, making it convenient for you to interface with existing Dubbo service.\n Basic usage  ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/dubbo/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"87d78ed0c2d06fe7e1dbf9cb9d6c1c9d","permalink":"/en/projects/sofa-rpc/dubbo/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/dubbo/","summary":"SOFARPC provides support for the Dubbo protocol, making it convenient for you to interface with existing Dubbo service.\n Basic usage  ","tags":null,"title":"Dubbo","type":"projects","url":"/en/projects/sofa-rpc/dubbo/","wordcount":20},{"author":null,"categories":null,"content":"Dubbo Integration In this document will demonstrate how to use SOFATracer to track of Dubbo, this example [address] (https://github.com/sofastack-guides/sofa-tracer-guides/tree/master/tracer-sample-with-dubbo).\nPrepare Environment The versions of the framework components used in this case are as follows:\n SOFABoot 3.1.1/SpringBoot 2.1.0.RELEASE SOFATracer 2.4.0/3.0.4 JDK 8  This case includes three submodules:\n tracer-sample-with-dubbo-consumer service provider tracer-sample-with-dubbo-provider service consumer tracer-sample-with-dubbo-facade service interface define  New SOFABoot project as parent project After creating a Spring Boot project, you need to introduce the SOFABoot\u0026amp;rsquo;s dependency. First, you need to unzip the generated zip package of Spring Boot project and modify the Maven project configuration file pom.xml.\n\u0026amp;lt;parent\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-starter-parent\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${spring.boot.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;relativePath/\u0026amp;gt; \u0026amp;lt;/parent\u0026amp;gt; Replace the above with the followings:\n\u0026amp;lt;parent\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofaboot-dependencies\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${sofa.boot.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/parent\u0026amp;gt; The ${sofa.boot.version} specifies the latest version of SOFABoot. For more information about SOFABoot versions, refer to Release notes.\nNew tracer-sample-with-dubbo-facade Module provider a service interface\npublic interface HelloService { String SayHello(String name); } New tracer-sample-with-dubbo-provider Module   provider SOFATracer dependency\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;tracer-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  SOFATracer versions are controlled by SOFABoot versions. If the SOFABoot versions used do not match, you need to manually specify a tracer version that is higher than 2.4.0.\n   application.properties Configuration\n# Spring boot application spring.application.name=dubbo-provider # Base packages to scan Dubbo Component: @org.apache.dubbo.config.annotation.Service dubbo.scan.base-packages=com.alipay.sofa.tracer.examples.dubbo.impl ## Filter dubbo.provider.filter=dubboSofaTracerFilter # Dubbo Protocol dubbo.protocol.name=dubbo ## Dubbo Registry dubbo.registry.address=zookeeper://localhost:2181 logging.path=./logs   Publish the Dubbo service using annotations\n@Service public class HelloServiceImpl implements HelloService { @Override public String SayHello(String name) { return \u0026amp;#34;Hello , \u0026amp;#34;+name; } }   New tracer-sample-with-dubbo-consumer Module   provider SOFATracer dependency\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;tracer-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   application.properties Configuration\nspring.application.name=dubbo-consumer dubbo.registry.address=zookeeper://localhost:2181 …","date":-62135596800,"description":"","dir":"projects/sofa-tracer/usage-of-dubbo/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"03f845606b454a7224333238aeecd9ab","permalink":"/en/projects/sofa-tracer/usage-of-dubbo/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-tracer/usage-of-dubbo/","summary":"Dubbo Integration In this document will demonstrate how to use SOFATracer to track of Dubbo, this example [address] (https://github.com/sofastack-guides/sofa-tracer-guides/tree/master/tracer-sample-with-dubbo).\nPrepare Environment The versions of the framework components used in this case are as follows:\n SOFABoot 3.1.1/SpringBoot 2.1.0.RELEASE SOFATracer 2.4.0/3.0.4 JDK 8  This case includes three submodules:\n tracer-sample-with-dubbo-consumer service provider tracer-sample-with-dubbo-provider service consumer tracer-sample-with-dubbo-facade service interface define  New SOFABoot project as parent project After creating a Spring Boot project, you need to introduce the SOFABoot\u0026rsquo;s dependency.","tags":null,"title":"Dubbo Integration","type":"projects","url":"/en/projects/sofa-tracer/usage-of-dubbo/","wordcount":296},{"author":null,"categories":null,"content":"Dubbo Log Format SOFATracer integrates Dubbo and outputs the requested link log data format. The default is JSON data format.\nDubbo service consumer digest log（dubbo-client-digest.log） The data is output in JSON format. Each key meaning is as follows:\n   key Meaning     time Log printing time   traceId TraceId   spanId SpanId   span.kind span Type   local.app Current application name   protocol protocol   service service interface   method service method   invoke.type invoke type   remote.host remote host   remote.port remote port   local.host local host   client.serialize.time request serialize time   client.deserialize.time response deserialize time   req.size.bytes Request Body Size   resp.size.bytes Response Body Size   result.code result code   current.thread.name Current thread name   time.cost.milliseconds Request time (ms)   baggage Transparently transmitted baggage data    Example:\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2019-04-03 11:36:01.909\u0026amp;#34;,\u0026amp;#34;traceId\u0026amp;#34;:\u0026amp;#34;0a0fe8451554262561656100126684\u0026amp;#34;,\u0026amp;#34;spanId\u0026amp;#34;:\u0026amp;#34;0\u0026amp;#34;,\u0026amp;#34;span.kind\u0026amp;#34;:\u0026amp;#34;client\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;dubbo-consumer\u0026amp;#34;,\u0026amp;#34;protocol\u0026amp;#34;:\u0026amp;#34;dubbo\u0026amp;#34;,\u0026amp;#34;service\u0026amp;#34;:\u0026amp;#34;com.alipay.sofa.tracer.examples.dubbo.facade.HelloService\u0026amp;#34;,\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;SayHello\u0026amp;#34;,\u0026amp;#34;invoke.type\u0026amp;#34;:\u0026amp;#34;sync\u0026amp;#34;,\u0026amp;#34;remote.host\u0026amp;#34;:\u0026amp;#34;10.15.232.69\u0026amp;#34;,\u0026amp;#34;remote.port\u0026amp;#34;:\u0026amp;#34;20880\u0026amp;#34;,\u0026amp;#34;local.host\u0026amp;#34;:\u0026amp;#34;10.15.232.69\u0026amp;#34;,\u0026amp;#34;client.serialize.time\u0026amp;#34;:35,\u0026amp;#34;client.deserialize.time\u0026amp;#34;:0,\u0026amp;#34;req.size.bytes\u0026amp;#34;:323,\u0026amp;#34;resp.size.bytes\u0026amp;#34;:323,\u0026amp;#34;result.code\u0026amp;#34;:\u0026amp;#34;00\u0026amp;#34;,\u0026amp;#34;current.thread.name\u0026amp;#34;:\u0026amp;#34;main\u0026amp;#34;,\u0026amp;#34;time.cost.milliseconds\u0026amp;#34;:252,\u0026amp;#34;baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;} Dubbo service provider digest log（dubbo-server-digest.log） The data is output in JSON format. Each key meaning is as follows:\n   key Meaning     time Log printing time   traceId TraceId   spanId SpanId   span.kind span Type   local.app current application name   service service inteface   method service method   local.host local host   local.host local port   protocol protocol   server.serialize.time response serialize time   server.deserialize.time request deserialize time   result.code result code   current.thread.name current thread name   time.cost.milliseconds Request time (ms)   baggage Transparently transmitted baggage data    Example\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2019-04-03 …","date":-62135596800,"description":"","dir":"projects/sofa-tracer/log-format-dubbo/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"9bac8256ee1a74546b74799f9f1c0de9","permalink":"/en/projects/sofa-tracer/log-format-dubbo/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-tracer/log-format-dubbo/","summary":"Dubbo Log Format SOFATracer integrates Dubbo and outputs the requested link log data format. The default is JSON data format.\nDubbo service consumer digest log（dubbo-client-digest.log） The data is output in JSON format. Each key meaning is as follows:\n   key Meaning     time Log printing time   traceId TraceId   spanId SpanId   span.kind span Type   local.app Current application name   protocol protocol   service service interface   method service method   invoke.","tags":null,"title":"Dubbo log","type":"projects","url":"/en/projects/sofa-tracer/log-format-dubbo/","wordcount":219},{"author":null,"categories":null,"content":"SOFARPC 提供了 Dubbo 协议的支持，可以让用户非常方便地和现有的 Dubbo 的系统做对接。\n 基本使用  ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/dubbo/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"87d78ed0c2d06fe7e1dbf9cb9d6c1c9d","permalink":"/projects/sofa-rpc/dubbo/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/dubbo/","summary":"SOFARPC 提供了 Dubbo 协议的支持，可以让用户非常方便地和现有的 Dubbo 的系统做对接。 基本使用","tags":null,"title":"Dubbo 协议","type":"projects","url":"/projects/sofa-rpc/dubbo/","wordcount":37},{"author":null,"categories":null,"content":"在 SOFARPC 中，使用不同的通信协议只要设置使用不同的 Binding 即可，如果需要使用 Dubbo 协议，只要将 Binding 设置为 Dubbo 即可。下面使用以注解的方式来例举，其他的使用方式可以参考 Bolt 协议基本使用，这里不再重复说明。：\n发布服务 发布一个 Dubbo 的服务，只需要将 @SofaServiceBinding 的 bindingType 设置为 dubbo 即可：\n@Service @SofaService(bindings = {@SofaServiceBinding(bindingType = \u0026amp;#34;dubbo\u0026amp;#34;)}) public class SampleServiceImpl implements SampleService { } 引用服务 引用一个 Dubbo 的服务，只需要将 @SofaReferenceBinding 的 bindingType 设置为 dubbo 即可：\n@SofaReference(binding = @SofaReferenceBinding(bindingType = \u0026amp;#34;dubbo\u0026amp;#34;), jvmFirst = false) private SampleService sampleService; 设置 Dubbo 服务的 Group 在 SOFARPC 的模型中，没有直接的一个字段叫做 Group，但是 SOFARPC 有一个 uniqueId 的模型，可以直接映射到 Dubbo 的模型中的 Group，比如下面的代码，就是发布了一个 Group 为 groupDemo 的服务：\n@Service @SofaService(bindings = {@SofaServiceBinding(bindingType = \u0026amp;#34;dubbo\u0026amp;#34;)}, uniqueId = \u0026amp;#34;groupDemo\u0026amp;#34;) public class SampleServiceImpl implements SampleService { } 如下的代码，就是引用了一个 Group 为 groupDemo 的服务：\n@SofaReference(binding = @SofaReferenceBinding(bindingType = \u0026amp;#34;dubbo\u0026amp;#34;), uniqueId = \u0026amp;#34;groupDemo\u0026amp;#34;, jvmFirst = false) private SampleService sampleService;  注意，目前 Dubbo 协议只支持 Zookeeper 作为服务注册中心。\n ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/dubbo-usage/","fuzzywordcount":400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"1bf72c194a20a5dccea70423690191f4","permalink":"/projects/sofa-rpc/dubbo-usage/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/dubbo-usage/","summary":"在 SOFARPC 中，使用不同的通信协议只要设置使用不同的 Binding 即可，如果需要使用 Dubbo 协议，只要将 Binding 设置为 Dubbo 即可。下面使用以注解的方式来例举，其他的使用方式可以","tags":null,"title":"Dubbo 协议基本使用","type":"projects","url":"/projects/sofa-rpc/dubbo-usage/","wordcount":322},{"author":null,"categories":null,"content":"在本文档将演示如何使用 SOFATracer 对 Dubbo 进行埋点，本示例工程地址。\n基础环境 本案例使用的各框架组件的版本如下：\n SOFABoot 3.1.1/SpringBoot 2.1.0.RELEASE SOFATracer 2.4.0/3.0.4 JDK 8  本案例包括三个子模块：\n tracer-sample-with-dubbo-consumer 服务调用方 tracer-sample-with-dubbo-provider 服务提供方 tracer-sample-with-dubbo-facade 接口  原理 SOFATracer 对象 Dubbo 的埋点实现依赖于 Dubbo 的 SPI 机制来实现，Tracer 中基于 调用拦截扩展 自定义了 DubboSofaTracerFilter 用于实现对 Dubbo 的调用埋点。由于 DubboSofaTracerFilter 并没有成为 Dubbo 的官方扩展，因此在使用 SOFATracer 时需要安装 调用拦截扩展 中 所提供的方式进行引用，即：\n\u0026amp;lt;!-- 消费方调用过程拦截 --\u0026amp;gt; \u0026amp;lt;dubbo:reference filter=\u0026amp;#34;dubboSofaTracerFilter\u0026amp;#34; /\u0026amp;gt; \u0026amp;lt;!-- 消费方调用过程缺省拦截器，将拦截所有reference --\u0026amp;gt; \u0026amp;lt;dubbo:consumer filter=\u0026amp;#34;dubboSofaTracerFilter\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;!-- 提供方调用过程拦截 --\u0026amp;gt; \u0026amp;lt;dubbo:service filter=\u0026amp;#34;dubboSofaTracerFilter\u0026amp;#34; /\u0026amp;gt; \u0026amp;lt;!-- 提供方调用过程缺省拦截器，将拦截所有service --\u0026amp;gt; \u0026amp;lt;dubbo:provider filter=\u0026amp;#34;dubboSofaTracerFilter\u0026amp;#34;/\u0026amp;gt; 新建 SOFABoot 工程作为父工程 在创建好一个 Spring Boot 的工程之后，接下来就需要引入 SOFABoot 的依赖，首先，需要将上文中生成的 Spring Boot 工程的 zip 包解压后，修改 Maven 项目的配置文件 pom.xml，将\n\u0026amp;lt;parent\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-starter-parent\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${spring.boot.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;relativePath/\u0026amp;gt; \u0026amp;lt;/parent\u0026amp;gt; 替换为：\n\u0026amp;lt;parent\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofaboot-dependencies\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${sofa.boot.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/parent\u0026amp;gt; 这里的 ${sofa.boot.version} 指定具体的 SOFABoot 版本，参考发布历史。\n新建 tracer-sample-with-dubbo-facade 提供一个接口\npublic interface HelloService { String SayHello(String name); } 新建 tracer-sample-with-dubbo-provider   在工程模块的 pom 文件中添加 SOFATracer 依赖\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;tracer-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  SOFATracer 版本受 SOFABoot 版本管控，如果使用的 SOFABoot 版本不匹配，则需要手动指定 tracer 版本，且版本需高于 2.4.0.\n   在工程的 application.properties 文件下添加相关参数，\n# Spring boot application spring.application.name=dubbo-provider # Base packages to scan Dubbo Component: @org.apache.dubbo.config.annotation.Service dubbo.scan.base-packages=com.alipay.sofa.tracer.examples.dubbo.impl ## Filter 必须配置 dubbo.provider.filter=dubboSofaTracerFilter # Dubbo Protocol dubbo.protocol.name=dubbo ## Dubbo Registry dubbo.registry.address=zookeeper://localhost:2181 logging.path=./logs   使用注解方式发布 Dubbo 服务\n@Service public class HelloServiceImpl implements HelloService { @Override public String SayHello(String name) { return \u0026amp;#34;Hello , \u0026amp;#34;+name; } }   新建 tracer-sample-with-dubbo-consumer   在工程模块的 pom 文件中添加 SOFATracer 依赖\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;tracer-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   在工程的 application.properties 文件下添加相关参数\nspring.application.name=dubbo-consumer dubbo.registry.address=zookeeper://localhost:2181 # Filter 必须配置 dubbo.consumer.filter=dubboSofaTracerFilter logging.path=./logs   服务引用\n@Reference(async = false) public HelloService helloService; @Bean public …","date":-62135596800,"description":"","dir":"projects/sofa-tracer/usage-of-dubbo/","fuzzywordcount":800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"03f845606b454a7224333238aeecd9ab","permalink":"/projects/sofa-tracer/usage-of-dubbo/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-tracer/usage-of-dubbo/","summary":"在本文档将演示如何使用 SOFATracer 对 Dubbo 进行埋点，本示例工程地址。 基础环境 本案例使用的各框架组件的版本如下： SOFABoot 3.1.1/SpringBoot 2.1.0.RELEASE SOFATracer 2.4.0/3.0.4 JDK 8 本案例包括三个子模块： tracer-sample-with-dubbo-consumer 服务调","tags":null,"title":"Dubbo 埋点接入","type":"projects","url":"/projects/sofa-tracer/usage-of-dubbo/","wordcount":758},{"author":null,"categories":null,"content":"SOFATracer 集成 Dubbo 后输出请求的链路数据格式，默认为 JSON 数据格式。\nDubbo 服务消费方摘要日志（dubbo-client-digest.log） 以 JSON 格式输出的数据，相应 key 的含义解释如下：\n   key 表达含义     time 日志打印时间   local.app 当前应用名   traceId TraceId   spanId SpanId   span.kind Span 类型   result.code 状态码   current.thread.name 当前线程名   time.cost.milliseconds span 耗时   protocol 协议   service 服务接口   method 调用方法   invoke.type 调用类型   remote.host 目标主机   remote.port 目标端口   local.host 本地主机   client.serialize.time 请求序列化时间   client.deserialize.time 响应反序列化时间   req.size.bytes Request Body 大小   resp.size.bytes Response Body 大小   error 错误信息   sys.baggage 系统透传的 baggage 数据   biz.baggage 业务透传的 baggage 数据    样例：\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2019-09-02 23:36:08.250\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;dubbo-consumer\u0026amp;#34;,\u0026amp;#34;traceId\u0026amp;#34;:\u0026amp;#34;1e27a79c156743856804410019644\u0026amp;#34;,\u0026amp;#34;spanId\u0026amp;#34;:\u0026amp;#34;0\u0026amp;#34;,\u0026amp;#34;span.kind\u0026amp;#34;:\u0026amp;#34;client\u0026amp;#34;,\u0026amp;#34;result.code\u0026amp;#34;:\u0026amp;#34;00\u0026amp;#34;,\u0026amp;#34;current.thread.name\u0026amp;#34;:\u0026amp;#34;http-nio-8080-exec-2\u0026amp;#34;,\u0026amp;#34;time.cost.milliseconds\u0026amp;#34;:\u0026amp;#34;205ms\u0026amp;#34;,\u0026amp;#34;protocol\u0026amp;#34;:\u0026amp;#34;dubbo\u0026amp;#34;,\u0026amp;#34;service\u0026amp;#34;:\u0026amp;#34;com.glmapper.bridge.boot.service.HelloService\u0026amp;#34;,\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;SayHello\u0026amp;#34;,\u0026amp;#34;invoke.type\u0026amp;#34;:\u0026amp;#34;sync\u0026amp;#34;,\u0026amp;#34;remote.host\u0026amp;#34;:\u0026amp;#34;192.168.2.103\u0026amp;#34;,\u0026amp;#34;remote.port\u0026amp;#34;:\u0026amp;#34;20880\u0026amp;#34;,\u0026amp;#34;local.host\u0026amp;#34;:\u0026amp;#34;192.168.2.103\u0026amp;#34;,\u0026amp;#34;client.serialize.time\u0026amp;#34;:35,\u0026amp;#34;client.deserialize.time\u0026amp;#34;:5,\u0026amp;#34;req.size.bytes\u0026amp;#34;:336,\u0026amp;#34;resp.size.bytes\u0026amp;#34;:48,\u0026amp;#34;error\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;,\u0026amp;#34;sys.baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;,\u0026amp;#34;biz.baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;} Dubbo 服务提供方摘要日志（dubbo-server-digest.log） 以 JSON 格式输出的数据，相应 key 的含义解释如下：\n   key 表达含义     time 日志打印时间   local.app 当前应用名   traceId TraceId   spanId SpanId   span.kind Span 类型   result.code 状态码   current.thread.name 当前线程名   time.cost.milliseconds span 耗时   protocol 协议   service 服务接口   method 调用方法   invoke.type 调用类型   local.host 本地主机   local.port 本地端口   server.serialize.time 响应序列化时间   server.deserialize.time 请求反序列化时间   req.size.bytes Request Body 大小   resp.size.bytes Response Body 大小   error 错误信息   sys.baggage 系统透传的 baggage 数据   biz.baggage 业务透传的 baggage 数据    样例：\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2019-09-02 23:36:08.219\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;dubbo-provider\u0026amp;#34;,\u0026amp;#34;traceId\u0026amp;#34;:\u0026amp;#34;1e27a79c156743856804410019644\u0026amp;#34;,\u0026amp;#34;spanId\u0026amp;#34;:\u0026amp;#34;0\u0026amp;#34;,\u0026amp;#34;span.kind\u0026amp;#34;:\u0026amp;#34;server\u0026amp;#34;,\u0026amp;#34;result.code\u0026amp;#34;:\u0026amp;#34;00\u0026amp;#34;,\u0026amp;#34;current.thread.name\u0026amp;#34;:\u0026amp;#34;DubboServerHandler-192.168.2.103:20880-thread-2\u0026amp;#34;,\u0026amp;#34;time.cost.milliseconds\u0026amp;#34;:\u0026amp;#34;9ms\u0026amp;#34;,\u0026amp;#34;protocol\u0026amp;#34;:\u0026amp;#34;dubbo\u0026amp;#34;,\u0026amp;#34;service\u0026amp;#34;:\u0026amp;#34;com.glmapper.bridge.boot.service.HelloService\u0026amp;#34;,\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;SayHello\u0026amp;#34;,\u0026amp;#34;local.host\u0026amp;#34;:\u0026amp;#34;192.168.2.103\u0026amp;#34;,\u0026amp;#34;local.port\u0026amp;#34;:\u0026amp;#34;62443\u0026amp;#34;,\u0026amp;#34;server.serialize.time\u0026amp;#34;:0,\u0026amp;#34;server.deserialize.time\u0026amp;#34;:27,\u0026amp;#34;req.size.bytes\u0026amp;#34;:336,\u0026amp;#34;resp.size.bytes\u0026amp;#34;:0,\u0026amp;#34;error\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;,\u0026amp;#34;sys.baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;,\u0026amp;#34;biz.baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;} Dubbo 统计日志 stat.key 即本段时间内的统计关键字集合，统一关键字集合唯一确定一组统计数据，包 …","date":-62135596800,"description":"","dir":"projects/sofa-tracer/log-format-dubbo/","fuzzywordcount":500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"9bac8256ee1a74546b74799f9f1c0de9","permalink":"/projects/sofa-tracer/log-format-dubbo/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-tracer/log-format-dubbo/","summary":"SOFATracer 集成 Dubbo 后输出请求的链路数据格式，默认为 JSON 数据格式。 Dubbo 服务消费方摘要日志（dubbo-client-digest.log） 以 JSON 格式输出的数据","tags":null,"title":"Dubbo 日志","type":"projects","url":"/projects/sofa-tracer/log-format-dubbo/","wordcount":462},{"author":null,"categories":null,"content":"The engine architecture is shown in the following diagram. Node A node in a Raft cluster connects and encapsulates all underlayer service modules, and main service interfaces that are visible to users. Specifically, the leader node of a raft group calls apply(task) to commit new tasks to the state machine replication cluster made up by the Raft group, which will then apply the task to the business state machine.\nStorage  It stores Raft configuration changes and log entries converted from requests submitted by users, and replicates log entries from the leader\u0026amp;rsquo;s log to followers\u0026#39; logs. LogStorage stores logs, while LogManager is responsible for calling the underlayer storage, caching and batch submitting storage calls, and conducting necessary checks and optimization. MetaStorage stores the metadata and records the internal states of the Raft implementation, for example, the current term of the node and the node to vote for. Optional. Snapshot storage is used to store users\u0026#39; state-machine snapshots and meta information. SnapshotStorage stores snapshots, while SnapshotExecutor manages the actual storage, remote installation, and replication of snapshots.  State machine  StateMachine is an implementation of users\u0026#39; core logic. It calls the onApply(Iterator) method to apply log entries that are submitted with Node#apply(task) to the business state machine. FSMCaller encapsulates state transition calls that are sent to the User StateMachine, writes log entries, implements a finite-state machine (FSM), conducts necessary checks, and merges requests for batch submission and concurrent processing.  Replication  Replicator is used by the leader to replicate log entries to followers. It does the same thing as an AppendEntries RPC of Raft. Without log entries, it is sent by the leader as heartbeats. ReplicatorGroup is used by a Raft group to manage all replicators, and to perform necessary permission checks and dispatches.  RPC The RPC module is used for network communication between nodes.\n The RPC server is built in a node to receive requests from other nodes or clients, and to redirect such requests to the corresponding service modules. The RPC client is used to issue requests to other nodes, such as requests for votes, log replication requests, and heartbeats.  ","date":-62135596800,"description":"","dir":"projects/sofa-jraft/engine-architecture/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"d2cc9de133aed20695229d0cde5b6ff9","permalink":"/en/projects/sofa-jraft/engine-architecture/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-jraft/engine-architecture/","summary":"The engine architecture is shown in the following diagram. Node A node in a Raft cluster connects and encapsulates all underlayer service modules, and main service interfaces that are visible to users. Specifically, the leader node of a raft group calls apply(task) to commit new tasks to the state machine replication cluster made up by the Raft group, which will then apply the task to the business state machine.\nStorage  It stores Raft configuration changes and log entries converted from requests submitted by users, and replicates log entries from the leader\u0026rsquo;s log to followers' logs.","tags":null,"title":"Engine architecture","type":"projects","url":"/en/projects/sofa-jraft/engine-architecture/","wordcount":347},{"author":null,"categories":null,"content":"ExtensionLoader To ensure that all steps of SOFARPC have sufficient scalability, SOFARPC defines a very flexible extension mechanism in which all extension implementations are equal.\nThis mechanism is very useful for both SOFARPC developers and users. SOFARPC abstracts itself into multiple modules which have no explicit dependencies on each other and interact via SPI.\nThis extension mechanism abstracts the interaction method of SPI. If you have read the documents about Filter and Router, you may have such experience.\nThe following sections introduce how to extend through the SPI interaction method.\nSOFARPC provides the capabilities of ExtensionLoader.\nDesign extension points SOFARPC defines an annotation @Extensible, which is on the interface or abstract class to identify that the class is an extension point. Namely, it informs SOFARPC that the class is extensible and SOFARPC needs to find the implementation of the extension point. In addition, the annotation defines the file name of the implementation class and whether the class is a singleton.\n@Documented @Retention(RetentionPolicy.RUNTIME) @Target({ ElementType.TYPE }) public @interface Extensible { /** * Specify the name of the custom extension file, which is the full class name by default * * @return Custom extension file name */ String file() default \u0026amp;#34;\u0026amp;#34;; /** * Whether the extension class uses a singleton, yes by default * * @return Whether to use a singleton */ boolean singleton() default true; /** * Whether the extension class needs to be encoded, not by default * * @return Whether to encode */ boolean coded() default false; } SOFARPC also defines the @Extension annotation, which indicates an extension implementation class. It also defines the name that the extension point uses when looking for an extension implementation in the file.\n@Documented @Retention(RetentionPolicy.RUNTIME) @Target({ ElementType.TYPE }) public @interface Extension { /** * Extension point name * * @return Extension point name */ String value(); /** * Extension point coding, not required by default; it is required when the interface needs to be encoded * * @return Extension point encoding * @see Extensible#coded() */ byte code() default -1; /** * Priority sorting, not required by default, the larger number, the higher priority * * @return Sort */ int order() default 0; /** * Whether to override other extensions with low {@link #order()} * * @return Whether to override other low-order extensions * @since 5.2.0 */ boolean override() default false; /** * Exclude other extensions, namely exclude other extensions with low {@link #order()} * * @return Excludes other extensions * @since 5.2.0 */ String[] rejection() default {}; } Add extension point  Define extension points.  @Extensible public interface Person { void getName(); } Define the extension implementation.  @Extension(\u0026amp;#34;A\u0026amp;#34;) public class PersonA implements Person{ @Override public void getName() { System.out.println(\u0026amp;#34;li wei\u0026amp;#34;); } } Compile …","date":-62135596800,"description":"","dir":"projects/sofa-rpc/extension-loader/","fuzzywordcount":700,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"acc5628da3a7ea2df5eb68bd8ec17159","permalink":"/en/projects/sofa-rpc/extension-loader/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/en/projects/sofa-rpc/extension-loader/","summary":"ExtensionLoader To ensure that all steps of SOFARPC have sufficient scalability, SOFARPC defines a very flexible extension mechanism in which all extension implementations are equal.\nThis mechanism is very useful for both SOFARPC developers and users. SOFARPC abstracts itself into multiple modules which have no explicit dependencies on each other and interact via SPI.\nThis extension mechanism abstracts the interaction method of SPI. If you have read the documents about Filter and Router, you may have such experience.","tags":null,"title":"Extension mechanism","type":"projects","url":"/en/projects/sofa-rpc/extension-loader/","wordcount":603},{"author":null,"categories":null,"content":"Customize different engine stages You can rewrite APIs provided by ActsTestBase in the test script or in the base class.\n Rewrite the prepare, execute, check, and clear actions. For example, you can add some actions before or after super.prepare(). Rewrite the process method. You can add some actions before or after super.process() to reorchestrate the entire script. For example, you can add some personalized steps in the existing clear \u0026amp;gt; prepare \u0026amp;gt; execute \u0026amp;gt; check process. Rewrite beforeActsTest and afterActsTest to add some personalized actions before or after the running of each test case, such as preparing the context and refreshing the cache.  Parameterization In response expectation and database expectation data, you can use $Variable name to define a value as a variable. You can set values of the variable in the test script. Supported scope: request parameters, responses, and database table fields. Supported types: Currently, only string parameterization is supported.\nUsage:\n(1) Add $ before a value to define it as a variable in the interface.\n(2) Assign values to the variables in the test script.\n@Override public void beforeActsTest(ActsRuntimeContext actsRuntimeContext) { actsRuntimeContext.paramMap.put(\u0026amp;#34;roleId\u0026amp;#34;, \u0026amp;#34;123\u0026amp;#34;); actsRuntimeContext.refreshDataParam(); } When you write the database expectation, you can use the equal sign = to assign a value to the variable. This indicates that the value is a query result, and subsequent tables can use this variable as the value.\nAssume that the interface will insert data into two tables.\n   id_A value_A     123 abc       id_B value_B     abc efg    When you query these two tables, first query for value_A based on id_A in Table A that is returned by the interface. Then use value_A as a condition for the query in Table B. You can set the values as follows in the plug-in.\n   Field Flag Value     id_A C $param1   value_A Y =param2       Field Flag Value     id_B C $param2   value_B Y efg    Operation description:\n =param2 and $param2 indicate that the ACTS framework will first query for value_A in Table A, and then select from B where id_B = value_A to obtain the property value of id_B in Table B. $param1 indicates that you can assign a value to id_A in the code, for example:  actsRuntimeContext.paramMap.put(\u0026amp;#34;param1\u0026amp;#34;,\u0026amp;#34;123\u0026amp;#34;); This snippet assigns the value 123 to the variable param1. You can write this snippet to beforeActsTest in the test script to make the ACTS framework query table A before assigning the value 123 to id_A.\nComponentization Currently, only string componentization is supported.\nIf a property is a dynamically generated string, for example, some IDs. You can use the at sign @ to call a component to generate this property. The component must be placed in the component package at the same level as the test module, namely: com.corpname.appname.acts.component (appname is the name of the system, and corpname is the name of the company, for example, …","date":-62135596800,"description":"","dir":"projects/sofa-acts/usage-api/","fuzzywordcount":1200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"ce7e264713a6f7a3f0672e2432489f59","permalink":"/en/projects/sofa-acts/usage-api/","publishdate":"0001-01-01T00:00:00Z","readingtime":6,"relpermalink":"/en/projects/sofa-acts/usage-api/","summary":"Customize different engine stages You can rewrite APIs provided by ActsTestBase in the test script or in the base class.\n Rewrite the prepare, execute, check, and clear actions. For example, you can add some actions before or after super.prepare(). Rewrite the process method. You can add some actions before or after super.process() to reorchestrate the entire script. For example, you can add some personalized steps in the existing clear \u0026gt; prepare \u0026gt; execute \u0026gt; check process.","tags":null,"title":"Extensions","type":"projects","url":"/en/projects/sofa-acts/usage-api/","wordcount":1102},{"author":null,"categories":null,"content":"Q: What should I do if NoSuchMethodError is returned? Generally, this error is returned in the case of dependency conflicts. Commonly known dependency conflicts are listed as follows. Exclude the corresponding dependencies when you encounter relevant conflicts.\nLog conflict commons-logging conflict \u0026amp;lt;exclusion\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;commons-logging\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;commons-logging\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;/exclusion\u0026amp;gt; logback-classic conflict Rule out logback-classic by the location of the conflict. For example, application dependencies spring-boot-starter-logging and spring-test conflict with each other.\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-starter-logging\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;1.4.2.RELEASE\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;exclusions\u0026amp;gt; \u0026amp;lt;exclusion\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;ch.qos.logback\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;logback-classic\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/exclusion\u0026amp;gt; \u0026amp;lt;/exclusions\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-test\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;4.3.4.RELEASE\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;exclusions\u0026amp;gt; \u0026amp;lt;exclusion\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;ch.qos.logback\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;logback-classic\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/exclusion\u0026amp;gt; \u0026amp;lt;/exclusions\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; snakeyaml conflict java.lang.NoSuchMethodError: org.yaml.snakeyaml.Yaml.\u0026amp;lt;init\u0026amp;gt;(Lorg/yaml/snakeyaml/constructor/BaseConstructor;)V org.yaml referenced in spring-boot-starter-test conflicts with org.yaml referenced in org.testing. In the following sample code, a conflict of org.yaml in spring-boot-starter-test is ruled out (it can also be ruled out at other conflict locations such as org.testing):\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-starter-test\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;scope\u0026amp;gt;test\u0026amp;lt;/scope\u0026amp;gt; \u0026amp;lt;exclusions\u0026amp;gt; \u0026amp;lt;exclusion\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.yaml\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;snakeyaml\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/exclusion\u0026amp;gt; \u0026amp;lt;/exclusions\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; Q: What should I do if NoClassDefFoundError is returned? Generally, this error is returned in the case of missing dependencies or dependency conflicts.\nMockito returns a no class found error While using Mockito with SOFABoot, you do not have to import Mockito if the spring-boot-starter-test dependency already exists.\nQ: What should I do if \u0026amp;ldquo;No bean dataAccessConfigManager available\u0026amp;rdquo; is returned? This error is returned because the application starter class specified by the test script does not have the acts-core.xml file. You can add the acts-core.xml file according to the following figure.\nQ: What should I do if \u0026amp;ldquo;No runnable methods\u0026amp;rdquo; is returned? Generally, this error is caused when you run your Junit test with the ACTS test script. You can use the TestNG framework to run the ACTS test script.\nQ: What should I do in the case of a model …","date":-62135596800,"description":"","dir":"projects/sofa-acts/faq/","fuzzywordcount":700,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"5f89d1f5695cbe6b669a8738741529bd","permalink":"/en/projects/sofa-acts/faq/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/en/projects/sofa-acts/faq/","summary":"Q: What should I do if NoSuchMethodError is returned? Generally, this error is returned in the case of dependency conflicts. Commonly known dependency conflicts are listed as follows. Exclude the corresponding dependencies when you encounter relevant conflicts.\nLog conflict commons-logging conflict \u0026lt;exclusion\u0026gt; \u0026lt;artifactId\u0026gt;commons-logging\u0026lt;/artifactId\u0026gt; \u0026lt;groupId\u0026gt;commons-logging\u0026lt;/groupId\u0026gt; \u0026lt;/exclusion\u0026gt; logback-classic conflict Rule out logback-classic by the location of the conflict. For example, application dependencies spring-boot-starter-logging and spring-test conflict with each other.\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-logging\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.","tags":null,"title":"FAQ","type":"projects","url":"/en/projects/sofa-acts/faq/","wordcount":633},{"author":null,"categories":null,"content":"Common issues Q: Is SOFARPC the version used inside Ant Financial? Yes, SOFARPC has excellent extension interfaces, and the version for internal use just has some additional extension implementations based on the open source version. For example, the cloud-based commercial version integrates the Ant Financial Technology\u0026amp;rsquo;s shared registry center, Distributed System Tracing (DST) and other products. The version for internal use integrates Ant Financial\u0026amp;rsquo;s internal registry center, LDC router and other individual extensions.\nQ: Does SOFARPC use ZooKeeper as the registry center internally? Can it integrate other registry centers such as etcd? Ant Financial uses its self-developed registry products internally. SOFARPC\u0026amp;rsquo;s registry modules are extensible. All the registry modules use the same set of core interfaces for both internal and external use. Currently, the open-source version has integrated with ZooKeeper, and other registry implementation communities are being integrated.\nQ: What is the difference between SOFARPC and Dubbo? Dubbo, developed by Alibaba Group, is an excellent open-source RPC framework featuring high performance and good scalability. Dubbo is a comparatively mature open source framework, with a large number of users and rich open source ecology. Now, it has joined the Apache Foundation for incubation. Dubbo was first widely used in the Alibaba B2B department.\nOriginated from HSF in Alibaba Group, SOFARPC now has grown to an independent product. SOFARPC has carried out a lot of reconstruction and optimization on the aspects of protocol, network, routing, and scalability to meet the large-scale financial business scenarios of Ant Financial. In the Ant Financial\u0026amp;rsquo;s middleware (SOFAStack) ecosystem, SOFARPC is supported by a comprehensive microservices technology stack, including Microservices R\u0026amp;amp;D framework, RPC framework, service registry center, distributed scheduling task, throttling framework, Dynamic Configuration, DST, Metrics and others. By Dec. 11, 2017, SOFARPC has been used by thousands of systems in Ant Financial, and the production environment has released more than tens of thousands of interfaces.\nHowever, in the open source field, SOFARPC is still at the initial stage, and its open source ecosystem is still under construction. With the advancement of the open source plan, various related components will be available in the subsequent versions to improve the microservices stack. You are welcome to build SOFAStack together with us.\nIn terms of performance, the technical points of both products involved in protocols are similar. As for scalability, both products have good scalability. As for other functional differences, here are some features that have been opened source or will be open sourced in the near future for reference:\n SOFARPC supports HTTP/2 and GRPC protocols and provides such capabilities as service warm-up weight, automatic degradation upon fault, negotiation mechanism, and CRC data …","date":-62135596800,"description":"","dir":"projects/sofa-rpc/faq/","fuzzywordcount":800,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"a6ec77ce5a423c5345394f42c64a416b","permalink":"/en/projects/sofa-rpc/faq/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/en/projects/sofa-rpc/faq/","summary":"Common issues Q: Is SOFARPC the version used inside Ant Financial? Yes, SOFARPC has excellent extension interfaces, and the version for internal use just has some additional extension implementations based on the open source version. For example, the cloud-based commercial version integrates the Ant Financial Technology\u0026rsquo;s shared registry center, Distributed System Tracing (DST) and other products. The version for internal use integrates Ant Financial\u0026rsquo;s internal registry center, LDC router and other individual extensions.","tags":null,"title":"FAQ","type":"projects","url":"/en/projects/sofa-rpc/faq/","wordcount":742},{"author":null,"categories":null,"content":"Usually, a service have multiple service providers in a cluster. Some of the service providers may have persistent connections still survived due to network, configuration, long-term fullgc, full thread pool, hardware failure and others, but the program cannot respond properly. The stand-alone fault tolerance function can degrade the exceptional service providers so that the client requests can be pointed to the healthy node. When the exceptional nodes become normal, the standalone fault tolerance function will restore the nodes, so that the client requests can gradually distribute traffic to the nodes. The standalone fault tolerance function solves the problem that service failures continue to affect the business, avoids the avalanche effect, reduces the long response time required for manual intervention and increases system availability.\nRunning mechanism:\n Standalone fault tolerance counts the number of calls and the number of exceptions in a time range, and calculates the abnormal rate of IP for each service and the average abnormal rate of the service. When the IP abnormal rate is greater than the service average abnormal rate to a certain ratio, the dimension of the service + ip is degraded. If the weight of the service + ip dimension is not degraded to 0, then when the call of the service + ip dimension is normal, the weight will be restored. The entire calculation and control process proceeds asynchronously, thus not blocking the call.  The standalone fault tolerance is used as follows:\nFaultToleranceConfig faultToleranceConfig = new FaultToleranceConfig(); faultToleranceConfig.setRegulationEffective(true); faultToleranceConfig.setDegradeEffective(true); faultToleranceConfig.setTimeWindow(20); faultToleranceConfig.setWeightDegradeRate(0.5); FaultToleranceConfigManager.putAppConfig(\u0026amp;#34;appName\u0026amp;#34;, faultToleranceConfig); As above, after the standalone fault tolerance switch is turned on, the application will calculate the exceptions every 20s time window. If a service + IP calling dimension is determined to be a faulty node, the weight of the service + IP will be degraded to 0.5 times.\nFor more detailed parameters, please refer to Standalone troubleshooting\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/fault-tolerance/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"7501b0fac1d1d89c61de0d591e29e1d0","permalink":"/en/projects/sofa-rpc/fault-tolerance/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-rpc/fault-tolerance/","summary":"Usually, a service have multiple service providers in a cluster. Some of the service providers may have persistent connections still survived due to network, configuration, long-term fullgc, full thread pool, hardware failure and others, but the program cannot respond properly. The stand-alone fault tolerance function can degrade the exceptional service providers so that the client requests can be pointed to the healthy node. When the exceptional nodes become normal, the standalone fault tolerance function will restore the nodes, so that the client requests can gradually distribute traffic to the nodes.","tags":null,"title":"Fault tolerance","type":"projects","url":"/en/projects/sofa-rpc/fault-tolerance/","wordcount":306},{"author":null,"categories":null,"content":"Fault tolerance automatically monitors the RPC calls, degrades the weight of the failed node, and recovers the weight when the node restored to normal. The bolt protocol is currently supported.\nIn SOFABoot, you only need to configure fault tolerance parameters to application.properties. You can select not to configure all parameters but only configure the parameters that you care about. Then, the remaining parameters will take the default values. Note that rpc.aft.regulation.effective is a global switch for this function. If it is off, the function will not work and other parameters will not take effect.\n   Attribute Description Default value     timeWindow Time window size: the period in which statistics are calculated. 10s   leastWindowCount Minimum number of calls in the time window: Only data that has reached this minimum value in the time window will be added in calculation and control. 10 times   leastWindowExceptionRateMultiple Degradation ratio of the exception rate in the time window to the average exception rate of the service: When calculating the statistical information, the average exception rate of all valid call IPs of the service is calculated. If the exception rate of an IP is greater than or equal to the lowest ratio, the IP will be degraded. 6 times   weightDegradeRate Degradation ratio: The rate of degradation of an address when it is degraded. 1/20   weightRecoverRate Recovery ratio: The recovery ratio of the address when it is weighted. 2 times   degradeEffective Degradation switch: If the application turns on this switch, it will degrade the address that matches the degradation criteria; otherwise, only the log will be printed. false (off)   degradeLeastWeight Degradation minimum weight: If the address weight is degraded to the weight less than this minimum weight, the minimum weight will be used. 1   degradeMaxIpCount Maximum number of IPs for degradation: The number of IPs in the same service that have been degraded cannot exceed this value. 2   regulationEffective Global switch: If the switch is turned on by the application, the entire standalone fault tolerance function will be turned on; otherwise, this function will not be used at all. false (off)     Example  Com.alipay.sofa.rpc.aft.time.window=20 Com.alipay.sofa.rpc.aft.least.window.count=30 Com.alipay.sofa.rpc.aft.least.window.exception.rate.multiple=6 Com.alipay.sofa.rpc.aft.weight.degrade.rate=0.5 Com.alipay.sofa.rpc.aft.weight.recover.rate=1.2 Com.alipay.sofa.rpc.aft.degrade.effective=ture Com.alipay.sofa.rpc.aft.degrade.least.weight=1 Com.alipay.sofa.rpc.aft.degrade.max.ip.count=2 Com.alipay.sofa.rpc.aft.regulation.effective=true As configured above, the fault tolerance function and degradation switch are enabled. When a node fails too many times, its weight is degraded, and during recovery, the weight will be restored. The node healthy is measured every 20s, and the nodes called for more than 30 times in 20s are recognized as calculation data. If the exception …","date":-62135596800,"description":"","dir":"projects/sofa-rpc/configuration-fault-tolerance/","fuzzywordcount":500,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"a132b54b2398534d1773489e2b0db166","permalink":"/en/projects/sofa-rpc/configuration-fault-tolerance/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/en/projects/sofa-rpc/configuration-fault-tolerance/","summary":"Fault tolerance automatically monitors the RPC calls, degrades the weight of the failed node, and recovers the weight when the node restored to normal. The bolt protocol is currently supported.\nIn SOFABoot, you only need to configure fault tolerance parameters to application.properties. You can select not to configure all parameters but only configure the parameters that you care about. Then, the remaining parameters will take the default values. Note that rpc.","tags":null,"title":"Fault tolerance configuration","type":"projects","url":"/en/projects/sofa-rpc/configuration-fault-tolerance/","wordcount":487},{"author":null,"categories":null,"content":"Feature architecture SOFABolt provides the following basic features:  Basic communication functions (remoting-core)  Netty-based, highly-effective network I/O and thread model practice Connection management (lock-free connection establishment, timed disconnection, automatic reconnection) Basic communication models (oneway, sync, future, callback) Timeout control Batch unpacking and batch submission processor Heartbeat and IDLE event processing   Protocol framework (protocol-skeleton)  Commands and command processor Coding and decoding processor Heartbeat trigger   Custom private protocol implementation - RPC communication protocol (protocol-implementation)  RPC communication protocol design Flexible deserialization timing control Request processing timeout FailFast mechanism User request processor (UserProcessor) Duplex communication    Usage 1 Use SOFABolt as a remote communication framework. You do not need to consider the details of how to implement a private protocol, just use our built-in RPC communication protocol. You can simply enable the client side and the server side, and simultaneously register a user request processor, thereby completing the remote calling. In addition, basic features such as connection management and heartbeat are available by default. Currently supported call types are shown in the figure below:\n For a sample demonstration, refer to our user guide.  Usage 2 Use SOFABolt as a protocol framework. You can reuse the basic functions of the basic communication model, the interface definitions included in the protocols, etc. Then, according to the private protocol you designed, you can customize the command types, command processors, decoding processors, etc. The RPC and message command definition structure is as shown in the figure below:\n","date":-62135596800,"description":"","dir":"projects/sofa-bolt/sofa-bolt-functions/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"fde29139cbd8b786326a6479e52814dd","permalink":"/en/projects/sofa-bolt/sofa-bolt-functions/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-bolt/sofa-bolt-functions/","summary":"Feature architecture SOFABolt provides the following basic features:  Basic communication functions (remoting-core)  Netty-based, highly-effective network I/O and thread model practice Connection management (lock-free connection establishment, timed disconnection, automatic reconnection) Basic communication models (oneway, sync, future, callback) Timeout control Batch unpacking and batch submission processor Heartbeat and IDLE event processing   Protocol framework (protocol-skeleton)  Commands and command processor Coding and decoding processor Heartbeat trigger   Custom private protocol implementation - RPC communication protocol (protocol-implementation)  RPC communication protocol design Flexible deserialization timing control Request processing timeout FailFast mechanism User request processor (UserProcessor) Duplex communication    Usage 1 Use SOFABolt as a remote communication framework.","tags":null,"title":"Features","type":"projects","url":"/en/projects/sofa-bolt/sofa-bolt-functions/","wordcount":237},{"author":null,"categories":null,"content":"Features  Service publishing and reference Communication Protocol  Bolt protocol  Basic usage Calling type Timeout control Generic call Serialization protocol Custom thread pool   RESTful protocol  Basic usage Custom filter Integrated Swagger   Dubbo  Basic usage   H2C  Basic usage     Registry center Direct call Load balancing Custom filter Custom router addressing Call retry Tracing  SOFATracer Skywalking   Custom thread pool Link data transparent transmission Warm-up weight Fault tolerance Node cross-language call Graceful shutdown  ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/features/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"0059809aed46360e8787e945ff098610","permalink":"/en/projects/sofa-rpc/features/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/features/","summary":"Features  Service publishing and reference Communication Protocol  Bolt protocol  Basic usage Calling type Timeout control Generic call Serialization protocol Custom thread pool   RESTful protocol  Basic usage Custom filter Integrated Swagger   Dubbo  Basic usage   H2C  Basic usage     Registry center Direct call Load balancing Custom filter Custom router addressing Call retry Tracing  SOFATracer Skywalking   Custom thread pool Link data transparent transmission Warm-up weight Fault tolerance Node cross-language call Graceful shutdown  ","tags":null,"title":"Features","type":"projects","url":"/en/projects/sofa-rpc/features/","wordcount":68},{"author":null,"categories":null,"content":"本文描述的是 MOSN 的 FilterChain 配置。\nFilterChain 是 MOSN Listener 配置中核心逻辑配置，不同的 FilterChain 配置描述了 Listener 会如何处理请求。\n目前 MOSN 一个 Listener 只支持一个 FilterChain。\nFilterChain 的配置结构如下所示。\n{ \u0026amp;#34;tls_context\u0026amp;#34;: {}, \u0026amp;#34;tls_context_set\u0026amp;#34;: [], \u0026amp;#34;filters\u0026amp;#34;: [] } tls_context_set  一组 tls_context 配置，MOSN 默认使用 tls_context_set 来描述 listener 的 TLS 的证书信息。 一个 listener 可同时支持配置多张 TLS 证书。  tls_context  单独配置 tls_context 而不是使用 tls_context_set 是兼容 MOSN 历史配置（只支持一张证书配置时）的场景，这种配置方式后面会逐步废弃。 tls_context 的详细配置说明，参考 tls_context。  filters 一组 network filter 配置。\nnetwork filter network filter 描述了 MOSN 在连接建立以后如何在 4 层处理连接数据。\n{ \u0026amp;#34;type\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;config\u0026amp;#34;: {} }  type 是一个字符串，描述了 filter 的类型。 config 可以是任意 json 配置，描述不同 filter 的配置。 network filter 可自定义扩展实现，默认支持的 type 包括 proxy、tcp proxy、connection_manager。  connection_manager 是一个特殊的 network filter，它需要和 proxy 一起使用，用于描述 proxy 中路由相关的配置，是一个兼容性质的配置，后续可能有修改。    ","date":-62135596800,"description":"","dir":"projects/mosn/configuration/listener/filter-chain/","fuzzywordcount":400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"d79979b85edad41aa6f0b3d8fe3295ee","permalink":"/projects/mosn/configuration/listener/filter-chain/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/mosn/configuration/listener/filter-chain/","summary":"本文描述的是 MOSN 的 FilterChain 配置。 FilterChain 是 MOSN Listener 配置中核心逻辑配置，不同的 FilterChain 配置描述了 Listener 会如何处理请求。 目前 MOSN 一个 Listener 只支持一个 FilterChain。 FilterChain 的配","tags":null,"title":"FilterChain 配置","type":"projects","url":"/projects/mosn/configuration/listener/filter-chain/","wordcount":389},{"author":null,"categories":null,"content":"Framework preparation Before reading, you can download and install ACTS IDE and import the ACTS framework by refering to Quick start.\nThis topic mainly describes the encoding, datasource configuration, and quick configuration to help you use the ACTS framework.\nEncoding Ensure that the encoding of ACTS and that of the system code are consistent, specifically, ensure that the encoding for script generation and the encoding of the IDEA workspace are consistent with the encoding of your application code. Otherwise, the code may get corrupted.\nThe encoding selected for test script generation is shown as follows.\nEncoding of the IDEA workspace:\nDatasource configuration The purpose of configuring data sources in ACTS is to ensure that you can use the system\u0026amp;rsquo;s data sources to properly perform database addition, deletion, and query operations during the preparation, clearance, and check stages.\nDatasource configuration Configure the mapping relationship between the ModuleName, datasource, and tables at the DAL layer in src/test/resource/config/acts-config.properties. The name of datasources starts with ds_ as follows:\ndatasource_bundle_name =com.alipay.testapp.common.dal ds_bean1=table1,table2 ds_bean2=table3,table4 #Configuration format #ds_datasource bean=logical table 1,logical table 2 Bean 1 and bean 2 are the names of the datasource beans at the DAL layer of the application code. Multiple datasources are supported. The table name supports regular expressions and sharding suffixes are not required. In the case of multiple datasources, a table must belong to only one datasource. See the following figure.\nDirect JDBC connection to the database The direct JDBC connection to the database is used to generate the DB data model. The configuration in devdb.conf or testdb.conf under src/test/resource/config/dbConf/ is as follows:\nxxx_url = jdbc:oracle:thin:@localhost:1521:cifdb xxx_username = myname xxx_password = mypswd Quick configuration description The quick test framework configuration mainly generates the basic Java classes and the necessary configuration files:\nJava classes   AppNameActsBaseUtils.java\nThe utility class that is commonly used in the test script writing process to get various data from the ACTS framework. The initial version provides only common methods. You can add desired methods by yourself.\n  AppNameActsTestBase.java\nThe encapsulated application test base class. If you have special business system requirements, you can encapsulate additional methods based on this class. If not, ignore this file.\n  Configuration files ","date":-62135596800,"description":"","dir":"projects/sofa-acts/usage-ready/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"c3a89cbf42d55c98206a08e94d05ffde","permalink":"/en/projects/sofa-acts/usage-ready/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-acts/usage-ready/","summary":"Framework preparation Before reading, you can download and install ACTS IDE and import the ACTS framework by refering to Quick start.\nThis topic mainly describes the encoding, datasource configuration, and quick configuration to help you use the ACTS framework.\nEncoding Ensure that the encoding of ACTS and that of the system code are consistent, specifically, ensure that the encoding for script generation and the encoding of the IDEA workspace are consistent with the encoding of your application code.","tags":null,"title":"Framework preparation","type":"projects","url":"/en/projects/sofa-acts/usage-ready/","wordcount":358},{"author":null,"categories":null,"content":"Generic calls provide the ability for clients to initiate calls without having to rely on the server`s interface. Currently, the generic call of SOFARPC only supports using Hessian2 as the serialization protocol under the Bolt communication protocol.\nSOFABoot environment Publish Service There is nothing special about publishing a service. Just publish the service normally, for example:\n\u0026amp;lt;!-- generic --\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;#34;sampleGenericServiceImpl\u0026amp;#34; class=\u0026amp;#34;com.alipay.sofa.rpc.samples.generic.SampleGenericServiceImpl\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;sofa:service ref=\u0026amp;#34;sampleGenericServiceImpl\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofa.rpc.samples.generic.SampleGenericService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt/\u0026amp;gt; \u0026amp;lt;/sofa:service\u0026amp;gt; Reference Service \u0026amp;lt;sofa:reference jvm-first=\u0026amp;#34;false\u0026amp;#34; id=\u0026amp;#34;sampleGenericServiceReference\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofa.rpc.api.GenericService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;sofa:global-attrs generic-interface=\u0026amp;#34;com.alipay.sofa.rpc.samples.generic.SampleGenericService\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt; The jvm-first can be left empty according to the actual situation. The interface should be the general interface of generic call. As for the generic-interface, you can just write in the name of the interface to be called.\nInitiate a call GenericService sampleGenericServiceReference = (GenericService) applicationContext .getBean(\u0026amp;#34;sampleGenericServiceReference\u0026amp;#34;); GenericObject genericResult = (GenericObject) sampleGenericServiceReference.$genericInvoke(\u0026amp;#34;sayGeneric\u0026amp;#34;, new String[] { \u0026amp;#34;com.alipay.sofa.rpc.samples.generic.SampleGenericParamModel\u0026amp;#34; }, new Object[] { genericObject }); RPC API ConsumerConfig\u0026amp;lt;GenericService\u0026amp;gt; consumerConfig = new ConsumerConfig\u0026amp;lt;GenericService\u0026amp;gt;() .setInterfaceId(\u0026amp;#34;com.alipay.sofa.rpc.quickstart.HelloService\u0026amp;#34;) .setGeneric(true); GenericService testService = consumerConfig.refer(); String result = (String) testService.$invoke(\u0026amp;#34;sayHello\u0026amp;#34;, new String[] { \u0026amp;#34;java.lang.String\u0026amp;#34; },new Object[] { \u0026amp;#34;1111\u0026amp;#34; }); You can set the service as a generic service and set the interface name of the server by setGeneric as above. GenericService is used as a generic service, and GenericService can initiate generic calls. You need to pass in the method name, method type, and method parameters when invoking a call.\nIf the parameter or return result is also required to be generalized on the client side, you can achieve this with GenericObject.\nGenericObject genericObject = new GenericObject(\u0026amp;#34;com.alipay.sofa.rpc.invoke.generic.TestObj\u0026amp;#34;); genericObject.putField(\u0026amp;#34;str\u0026amp;#34;, \u0026amp;#34;xxxx\u0026amp;#34;); genericObject.putField(\u0026amp;#34;num\u0026amp;#34;, 222); GenericObject result = (GenericObject) testService.$genericInvoke(\u0026amp;#34;echoObj\u0026amp;#34;, new String[] { \u0026amp;#34;com.alipay.sofa.rpc.invoke.generic.TestObj\u0026amp;#34; }, new Object[] { genericObject }); String str = result.getField(\u0026amp;#34;str\u0026amp;#34;); String num = result.getField(\u0026amp;#34;num\u0026amp;#34;); The …","date":-62135596800,"description":"","dir":"projects/sofa-rpc/generic-invoke/","fuzzywordcount":600,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"84ac624dc99a42a8f89489aa10304ef7","permalink":"/en/projects/sofa-rpc/generic-invoke/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/en/projects/sofa-rpc/generic-invoke/","summary":"Generic calls provide the ability for clients to initiate calls without having to rely on the server`s interface. Currently, the generic call of SOFARPC only supports using Hessian2 as the serialization protocol under the Bolt communication protocol.\nSOFABoot environment Publish Service There is nothing special about publishing a service. Just publish the service normally, for example:\n\u0026lt;!-- generic --\u0026gt; \u0026lt;bean id=\u0026#34;sampleGenericServiceImpl\u0026#34; class=\u0026#34;com.alipay.sofa.rpc.samples.generic.SampleGenericServiceImpl\u0026#34;/\u0026gt; \u0026lt;sofa:service ref=\u0026#34;sampleGenericServiceImpl\u0026#34; interface=\u0026#34;com.alipay.sofa.rpc.samples.generic.SampleGenericService\u0026#34;\u0026gt; \u0026lt;sofa:binding.bolt/\u0026gt; \u0026lt;/sofa:service\u0026gt; Reference Service \u0026lt;sofa:reference jvm-first=\u0026#34;false\u0026#34; id=\u0026#34;sampleGenericServiceReference\u0026#34; interface=\u0026#34;com.","tags":null,"title":"Generic call","type":"projects","url":"/en/projects/sofa-rpc/generic-invoke/","wordcount":501},{"author":null,"categories":null,"content":"This document introduces how to use SOFARPC for service publishing and reference in SOFABoot.\nYou can get the code sample of this document by clicking here. Note that the code sample requires a local installation of the zookeeper environment. If not, you need to remove the com.alipay.sofa.rpc.registry.address configuration in application.properties to use the local file as a registry center.\nCreate a project  Prepare environment: SOFABoot requires JDK7 or JDK8 and needs to be compiled with Apache Maven 2.2.5 or above. Build SOFABoot project: SOFABoot is based on Spring Boot. So you can use Spring Boot\u0026amp;rsquo;s project generation tool to generate a standard Spring Boot project. Add SOFABoot dependency: The generated standard Spring Boot project directly uses Spring parent dependency, which should be changed to the parent dependency provided by SOFABoot. The parent dependency provides and manages a variety of starters provided by SOFABoot.  \u0026amp;lt;parent\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-starter-parent\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${spring.boot.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;relativePath/\u0026amp;gt; \u0026amp;lt;/parent\u0026amp;gt; Replace the above with the followings:\n\u0026amp;lt;parent\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofaboot-dependencies\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;3.0.0\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/parent\u0026amp;gt; Configure application.properties: application.properties is the configuration file in SOFABoot project. Here you need to configure the application name.  spring.application.name=AppName Introduce RPC starter:  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;rpc-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; Declare the xsd file of SOFABoot:  In the XML configuration file to be used, configure the declaration of the header xsd file to the followings. This enables development using the XML elements defined by SOFABoot.\n\u0026amp;lt;?xml version=\u0026amp;#34;1.0\u0026amp;#34; encoding=\u0026amp;#34;UTF-8\u0026amp;#34;?\u0026amp;gt; \u0026amp;lt;beans xmlns=\u0026amp;#34;http://www.springframework.org/schema/beans\u0026amp;#34; xmlns:xsi=\u0026amp;#34;http://www .w3.org/2001/XMLSchema-instance\u0026amp;#34; xmlns:sofa=\u0026amp;#34;http://sofastack.io/schema/sofaboot\u0026amp;#34; xmlns:context=\u0026amp;#34;http://www.springframework.org/schema/context\u0026amp;#34; xsi:schemaLocation =\u0026amp;#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://sofastack.io/schema/sofaboot http://sofastack .io/schema/sofaboot.xsd\u0026amp;#34; Define service interface and implementation public interface HelloSyncService { String saySync(String string); } public class HelloSyncServiceImpl implements HelloSyncService { @Override public String saySync(String string) { return string; } } Publish service on server Configure the followings in the xml file. When the Spring context is refreshed, SOFABoot registers the service implementation on the server, communicates with the client by bolt protocol, and publishes metadata such as address to …","date":-62135596800,"description":"","dir":"projects/sofa-rpc/getting-started-with-sofa-boot/","fuzzywordcount":500,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"0dd5e0e5116473aee630cba38679d493","permalink":"/en/projects/sofa-rpc/getting-started-with-sofa-boot/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/en/projects/sofa-rpc/getting-started-with-sofa-boot/","summary":"This document introduces how to use SOFARPC for service publishing and reference in SOFABoot.\nYou can get the code sample of this document by clicking here. Note that the code sample requires a local installation of the zookeeper environment. If not, you need to remove the com.alipay.sofa.rpc.registry.address configuration in application.properties to use the local file as a registry center.\nCreate a project  Prepare environment: SOFABoot requires JDK7 or JDK8 and needs to be compiled with Apache Maven 2.","tags":null,"title":"Get started with SOFABoot","type":"projects","url":"/en/projects/sofa-rpc/getting-started-with-sofa-boot/","wordcount":437},{"author":null,"categories":null,"content":"This document introduces how to apply SOFARPC for service publishing and reference. This example will simulate a server locally to listen to a port and publish a service, and the client will reference the service for direct call.\nYou can get the code sample of this document by clicking here.\nCreate a project You need to install JDK 6 or above and Maven 3 or above.\nCreate a new Maven project and introduce SOFARPC dependency.\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-rpc-all\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;latest version\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; Note: The latest version can be found at https://github.com/sofastack/sofa-rpc/releases.\nWrite a server implementation Step 1: Create interface\n/** * Quick Start demo interface */ public interface HelloService { String sayHello(String string); } Step 2: Create interface implementation\n/** * Quick Start demo implement */ public class HelloServiceImpl implements HelloService { @Override public String sayHello(String string { System.out.println(\u0026amp;#34;Server receive: \u0026amp;#34; + string); return \u0026amp;#34;hello \u0026amp;#34; + string + \u0026amp;#34; !\u0026amp;#34;; } } Step 3: Write the server code\n/** * Quick Start Server */ public class QuickStartServer { public static void main(String[] args) { ServerConfig serverConfig = new ServerConfig() .setProtocol(\u0026amp;#34;bolt\u0026amp;#34;) // Set a protocol, which is bolt by default  .setPort(12200) // set a port, which is 12200 by default  .setDaemon(false); // non-daemon thread  ProviderConfig\u0026amp;lt;HelloService\u0026amp;gt; providerConfig = new ProviderConfig\u0026amp;lt;HelloService\u0026amp;gt;() .setInterfaceId(HelloService.class.getName()) // Specify the interface  .setRef(new HelloServiceImpl()) // Specify the implementation  .setServer(serverConfig); // Specify the server  providerConfig.export (); // Publish service  } } Write a client implementation Step 1: Get the server interface\nIn general, the server provides the interface class to the client in the form of jar. In this example, this step is skipped since the server and client are in the same project.\nStep 2: Write the client code\n/** * Quick Start client */ public class QuickStartClient { public static void main(String[] args) { ConsumerConfig\u0026amp;lt;HelloService\u0026amp;gt; consumerConfig = new ConsumerConfig\u0026amp;lt;HelloService\u0026amp;gt;() .setInterfaceId(HelloService.class.getName()) // Specify the interface  .setProtocol(\u0026amp;#34;bolt\u0026amp;#34;) // Specify the protocol.setDirectUrl  .setDirectUrl(\u0026amp;#34;bolt://127.0.0.1:12200\u0026amp;#34;); // Specify the direct connection address  // Generate the proxy class  HelloService helloService = consumerConfig.refer(); while (true) { System.out.println(helloService.sayHello(\u0026amp;#34;world\u0026amp;#34;)); try { Thread.sleep(2000); } catch (Exception e) { } } } } Run Start the server and client separately.\nThe server outputs:\n Server receive: The world\n The client outputs:\n hello world !\n More For more examples, please refer to: example\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/getting-started-with-rpc/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"192d252b0b36266622284b68d10e9fe4","permalink":"/en/projects/sofa-rpc/getting-started-with-rpc/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-rpc/getting-started-with-rpc/","summary":"This document introduces how to apply SOFARPC for service publishing and reference. This example will simulate a server locally to listen to a port and publish a service, and the client will reference the service for direct call.\nYou can get the code sample of this document by clicking here.\nCreate a project You need to install JDK 6 or above and Maven 3 or above.\nCreate a new Maven project and introduce SOFARPC dependency.","tags":null,"title":"Get started with SOFARPC","type":"projects","url":"/en/projects/sofa-rpc/getting-started-with-rpc/","wordcount":371},{"author":null,"categories":null,"content":"Graceful shutdown includes two parts. One is the RPC framework as client, and the other is the RPC framework as server.\nAs server As the server, the RPC framework should not be violently shutdown.\ncom.alipay.sofa.rpc.context.RpcRuntimeContext Added a ShutdownHook to the static initialization snippet:\n// Add jvm shutdown event if (RpcConfigs.getOrDefaultValue(RpcOptions.JVM_SHUTDOWN_HOOK, true)) { Runtime.getRuntime().addShutdownHook(new Thread(new Runnable() { @Override public void run() { if (LOGGER.isWarnEnabled()) { LOGGER.warn(\u0026amp;#34;SOFA RPC Framework catch JVM shutdown event, Run shutdown hook now.\u0026amp;#34;); } destroy(false); } }, \u0026amp;#34;SOFA-RPC-ShutdownHook\u0026amp;#34;)); } The logic in ShutdownHook is executed first when the publishing platform or users run the following method kill pid. In the destroy operation, the RPC framework first performs actions such as canceling service registration to the registry center and closing the service port.\nprivate static void destroy(boolean active) { RpcRunningState.setShuttingDown (true); for (Destroyable.DestroyHook destroyHook : DESTROY_HOOKS) { destroyHook.preDestroy(); } List\u0026amp;lt;ProviderConfig\u0026amp;gt; providerConfigs = new ArrayList\u0026amp;lt;ProviderConfig\u0026amp;gt;(); for (ProviderBootstrap bootstrap : EXPORTED_PROVIDER_CONFIGS) { providerConfigs.add(bootstrap.getProviderConfig()); } // First, unregister the server  List\u0026amp;lt;Registry\u0026amp;gt; registries = RegistryFactory.getRegistries(); if (CommonUtils.isNotEmpty(registries) \u0026amp;amp;\u0026amp;amp; CommonUtils.isNotEmpty(providerConfigs)) { for (Registry registry : registries) { registry.batchUnRegister(providerConfigs); } } / / Shut down the port that has been started ServerFactory.destroyAll(); // Close the published service  for (ProviderBootstrap bootstrap : EXPORTED_PROVIDER_CONFIGS) { bootstrap.unExport(); } // Close the called service  for (ConsumerBootstrap bootstrap : REFERRED_CONSUMER_CONFIGS) { ConsumerConfig config = bootstrap.getConsumerConfig(); If (!CommonUtils.isFalse(config.getParameter(RpcConstants.HIDDEN_KEY_DESTROY))) { // Unless you do not let the active unrefer  bootstrap.unRefer(); } } // Shut down the registry center  RegistryFactory.destroyAll(); / / Close some public resources of the client ClientTransportFactory.closeAll(); // Uninstall the module  if (!RpcRunningState.isUnitTestMode()) { ModuleFactory.uninstallModules(); } // Uninstall the hook  for (Destroyable.DestroyHook destroyHook : DESTROY_HOOKS) { destroyHook.postDestroy(); } // Clean up the cache  RpcCacheManager.clearAll(); RpcRunningState.setShuttingDown (false); if (LOGGER.isWarnEnabled()) { LOGGER.warn(\u0026amp;#34;SOFA RPC Framework has been release all resources {}...\u0026amp;#34;, active ? \u0026amp;#34;actively \u0026amp;#34; : \u0026amp;#34;\u0026amp;#34;); } } Taking bolt as an example, closing the port is not an immediate action.\n@Override public void destroy() { if (!started) { return; } int stopTimeout = serverConfig.getStopTimeout(); If (stopTimeout \u0026amp;gt; 0) { // need to wait for the end time  AtomicInteger count = …","date":-62135596800,"description":"","dir":"projects/sofa-rpc/graceful-shutdown/","fuzzywordcount":700,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"53af179e23ba184b01eb8234c055b15d","permalink":"/en/projects/sofa-rpc/graceful-shutdown/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/en/projects/sofa-rpc/graceful-shutdown/","summary":"Graceful shutdown includes two parts. One is the RPC framework as client, and the other is the RPC framework as server.\nAs server As the server, the RPC framework should not be violently shutdown.\ncom.alipay.sofa.rpc.context.RpcRuntimeContext Added a ShutdownHook to the static initialization snippet:\n// Add jvm shutdown event if (RpcConfigs.getOrDefaultValue(RpcOptions.JVM_SHUTDOWN_HOOK, true)) { Runtime.getRuntime().addShutdownHook(new Thread(new Runnable() { @Override public void run() { if (LOGGER.isWarnEnabled()) { LOGGER.warn(\u0026#34;SOFA RPC Framework catch JVM shutdown event, Run shutdown hook now.","tags":null,"title":"Graceful shutdown","type":"projects","url":"/en/projects/sofa-rpc/graceful-shutdown/","wordcount":669},{"author":null,"categories":null,"content":"H2C protocol SOFARPC provides support for the H2C protocol, which can be used to publish and reference services.\n Basic usage  ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/h2c/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"45b6d6ba0ca1ae7f6d415d79c184f766","permalink":"/en/projects/sofa-rpc/h2c/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/h2c/","summary":"H2C protocol SOFARPC provides support for the H2C protocol, which can be used to publish and reference services.\n Basic usage  ","tags":null,"title":"H2C","type":"projects","url":"/en/projects/sofa-rpc/h2c/","wordcount":20},{"author":null,"categories":null,"content":"SOFARPC 提供了 H2C 协议的支持，可以可以采用 H2C 协议来进行服务的发布和引用\n 基本使用  ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/h2c/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"45b6d6ba0ca1ae7f6d415d79c184f766","permalink":"/projects/sofa-rpc/h2c/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/h2c/","summary":"SOFARPC 提供了 H2C 协议的支持，可以可以采用 H2C 协议来进行服务的发布和引用 基本使用","tags":null,"title":"H2C","type":"projects","url":"/projects/sofa-rpc/h2c/","wordcount":35},{"author":null,"categories":null,"content":"在 SOFARPC 中，使用不同的通信协议只要设置使用不同的 Binding 即可，如果需要使用 H2C 协议，只要将 Binding 设置为 H2C 即可。下面使用以注解的方式来例举，其他的使用方式可以参考 Bolt 协议基本使用，这里不再重复说明。：\n发布服务 发布一个 H2C 的服务，只需要将 @SofaServiceBinding 的 bindingType 设置为 h2c 即可：\n@Service @SofaService(bindings = {@SofaServiceBinding(bindingType = \u0026amp;#34;h2c\u0026amp;#34;)}) public class SampleServiceImpl implements SampleService { } 引用服务 引用一个 H2C 的服务，只需要将 @SofaReferenceBinding 的 bindingType 设置为 h2c 即可：\n@SofaReference(binding = @SofaReferenceBinding(bindingType = \u0026amp;#34;h2c\u0026amp;#34;), jvmFirst = false) private SampleService sampleService; ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/h2c-usage/","fuzzywordcount":200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"fa75eff1e99b3acad5087160a1b44a09","permalink":"/projects/sofa-rpc/h2c-usage/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/h2c-usage/","summary":"在 SOFARPC 中，使用不同的通信协议只要设置使用不同的 Binding 即可，如果需要使用 H2C 协议，只要将 Binding 设置为 H2C 即可。下面使用以注解的方式来例举，其他的使用方式可以","tags":null,"title":"H2C 协议基本使用","type":"projects","url":"/projects/sofa-rpc/h2c-usage/","wordcount":168},{"author":null,"categories":null,"content":"SOFABoot provides Readiness Check to enhance Spring Boot\u0026amp;rsquo;s Health Check. If you need to use the SOFA middleware, you are advised to use the Health Check extension of SOFABoot to launch application examples in a more elegant way.\nEnable Health Check To enable the Health Check feature in SOFABoot, you only need to import the following starter:\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;healthcheck-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; Without the Health Check extension, users still can perform Liveness Check with native Spring Boot Actuator directly relying on the HealthIndicator interface.\nSecurity alert From SOFABoot 2.3.0 on, the Health Check depends on the Actuator component in SpringBoot 1.4.x, and the component opens a lot of EndPoint such as \u0026amp;lsquo;/dump \u0026#39; and \u0026amp;lsquo;/trace\u0026amp;rsquo;. So there may be a security risk. Refer to the Security Recommendations in the official document for settings.\nSpringBoot 1.5.x and SpringBoot 2.x. have fixed some security issues. SOFABoot will be supported by upgrading the SpringBoot kernel.\nView Health Check results After adding the Health Check extension, you can directly browser http://localhost:8080/health/readiness to view the Readiness Check results. To view the Liveness Check results, access the URL of the Spring Boot Health Check results. http://localhost:8080/health。\nIn SOFABoot, you can also view Health Check results by checking the specific logs in the health-check directory. Generally, such logs contain the following content:\n2018-04-06 23:29:50,240 INFO main - Readiness check result: success At present, the SOFA middleware has controlled upstream traffic access through the Readiness Check offered by SOFABoot. But, apart from the middleware, traffic of an application may come from other sources such as the load balancer. To control such traffic, users are advised to view the Readiness Check results by PAAS and determine whether to launch corresponding nodes in the load balancer based on the results.\n** Note: Versions after SOFABoot 2.x no longer indirectly introduce spring-boot-starter-web dependencies. To view Health Check results in the browser, you need to introduce Web container dependencies in the project. **\n** Note: In SOFABoot 3.x, the endpoint path has been changed from health/readiness to actuator/readiness**\nReadiness Check extension SOFABoot allows extension in every phase of the Readiness Check. Applications can be extended according to their needs. In version 2.x, the extendable points are as follows:\n   Callback interface Description     org.springframework.context.ApplicationListener If you want to do something before the Readiness Check, you can monitor the SofaBootBeforeHealthCheckEvent event of this listener.   org.springframework.boot.actuate.health.HealthIndicator If you want to add a check item to the Readiness Check in SOFABoot, you can directly extend this interface of Spring Boot. …","date":-62135596800,"description":"","dir":"projects/sofa-boot/health-check/","fuzzywordcount":800,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"a366b25125fa4aedb08a9cef572db1c8","permalink":"/en/projects/sofa-boot/health-check/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/en/projects/sofa-boot/health-check/","summary":"SOFABoot provides Readiness Check to enhance Spring Boot\u0026rsquo;s Health Check. If you need to use the SOFA middleware, you are advised to use the Health Check extension of SOFABoot to launch application examples in a more elegant way.\nEnable Health Check To enable the Health Check feature in SOFABoot, you only need to import the following starter:\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alipay.sofa\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;healthcheck-sofa-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; Without the Health Check extension, users still can perform Liveness Check with native Spring Boot Actuator directly relying on the HealthIndicator interface.","tags":null,"title":"Health check","type":"projects","url":"/en/projects/sofa-boot/health-check/","wordcount":707},{"author":null,"categories":null,"content":"Prerequisites Before contributing any code, you need to know how to use the Git tools and the GitHub website.\n For the use of Git tools, refer to the official Pro Git book and get familiar with it by reading the first few chapters. For the Git collaboration process, refer to the article Git Workflows.  GitHub Code Contribution Process Submit an issue Regardless of whether you are fixing an ACTS bug or adding an ACTS feature, submit an issue on ACTS GitHub to describe the bug you are going to fix or the feature you intend to add before you submit the code. There are several advantages of doing so:\n There will not be any conflict with other developers or their plans for this project to result in repetitive work. The ACTS maintenance personnel will discuss the issue or new feature you submitted to determine whether the modification is necessary, or if there is any room for improvement or a better solution. Start code development and submit the code after an agreement is reached. This reduces the cost of communication between both parties and the number of rejected pull requests.  Get the source code To modify or add a feature after submitting an issue, click the fork button in the upper left corner to copy the master branch code to your code repository.\nPull a branch All ACTS modifications are performed on branches. After the modification, submit a pull request. The modifications will then be merged into the master branch by the project maintenance personnel after the code review. Therefore, after getting familiar with how to get the source code, you need to:\n  Download the code locally. You may select the git/https mode in this step.\nGit clone https://github.com/your account name/acts.git   Pull a branch to prepare for code modification.\ngit branch add_xxx_feature After the preceding command is executed, your code repository will switch to the corresponding branch. To view the current branch, execute the following command:\ngit branch -a If you want to switch back to the master branch, execute the following command:\ngit checkout -b master If you want to switch back to the branch, execute the following command:\ngit checkout -b \u0026amp;quot;branchName\u0026amp;quot;   Modify the code and submit it locally After a branch is pulled, you can modify the code.\n  After modifying the code, execute the following command to submit all modifications to your local repository:\ngit commit -am \u0026#39;Add xx feature\u0026#39;   When modifying the code, note the following:   Keep the code style consistent.\n  ACTS uses the Maven plug-in to keep the code style consistent. Before submitting the code, be sure to execute the following command locally.\nmvn clean compile   Supplement unit test code.\n  New modifications should have passed existing unit tests.\n  Provide a new unit test to prove that the previous code has bugs and the bugs have been fixed in the new code. Execute the following command to run all tests:\nmvn clean test You can also use the IDE to help run a test.\n  Other do\u0026amp;rsquo;s and …","date":-62135596800,"description":"","dir":"projects/sofa-acts/contributing/","fuzzywordcount":900,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"cd68baede6258921f83665ef0a446f1f","permalink":"/en/projects/sofa-acts/contributing/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/en/projects/sofa-acts/contributing/","summary":"Prerequisites Before contributing any code, you need to know how to use the Git tools and the GitHub website.\n For the use of Git tools, refer to the official Pro Git book and get familiar with it by reading the first few chapters. For the Git collaboration process, refer to the article Git Workflows.  GitHub Code Contribution Process Submit an issue Regardless of whether you are fixing an ACTS bug or adding an ACTS feature, submit an issue on ACTS GitHub to describe the bug you are going to fix or the feature you intend to add before you submit the code.","tags":null,"title":"How to contribute","type":"projects","url":"/en/projects/sofa-acts/contributing/","wordcount":808},{"author":null,"categories":null,"content":" We recommend that you go to the Roadmap topic to learn about the development tasks and plans first.\n Prerequisites Before contributing any code, you need to know how to use the Git tools and the GitHub website.\n For the use of Git tools, refer to the official Pro Git book and get familiar with it by reading the first few chapters. For the Git collaboration process, refer to Git Workflows.  GitHub Code Contribution Process Submitting an issue Regardless of whether you are fixing a SOFADashboard bug or adding a SOFADashboard feature, submit an issue on SOFADashboard GitHub to describe the bug you are going to fix or the feature you intend to add before you submit the code.\nThere are several advantages of doing so:\n There will not be any conflict with other developers or their plans for this project. This avoids repetitive work. The SOFADashboard maintenance personnel will discuss the issue or new feature you submitted to determine whether the modification is necessary, or if there is any room for improvement or a better solution. Start code development and submit the code after an agreement is reached. This reduces the cost of communication between both parties and the number of rejected pull requests.  Get the source code To modify or add a feature after submitting an issue, click the fork button in the upper left corner to copy the master branch code to your code repository.\nPull a branch All SOFADashboard modifications are performed on branches. After the modification, submit a pull request. The modifications will then be merged into the master branch by the project maintenance personnel after the code review. Therefore, after getting familiar with how to get the source code, you need to:\n  Download the code locally. You may select the git/https mode in this step.\ngit clone https://github.com/your account name/sofa-dashboard.git   Pull a branch to prepare for code modification.\ngit branch add_xxx_feature   After the preceding command is executed, your code repository is switched to the corresponding branch. To view the current branch, execute the following command:\ngit branch -a   If you want to switch back to the master branch, execute the following command:\ngit checkout -b master   If you want to switch back to the branch, execute the following command:\ngit checkout -b \u0026amp;#34;branchName\u0026amp;#34;   Modify the code and submit it locally After a branch is pulled, you can modify the code.\nWhen modifying the code, note the following:   Keep the code style consistent.\nSOFADashboard uses the Maven plug-in to keep the code style consistent. Before submitting the code, be sure to execute the following command locally.\nmvn clean compile   Add the unit test code.\n  Modifications should have passed existing unit tests.\n  You should provide a new unit test to prove that the previous code has bugs and the bugshave been fixed in the new code. You can execute the following code to run all tests:\nmvn clean test   You can also use the IDE to help run a test.\n  Other …","date":-62135596800,"description":"","dir":"projects/sofa-dashboard/contribution/","fuzzywordcount":900,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"584584be9c13f2d36c85890dd192368a","permalink":"/en/projects/sofa-dashboard/contribution/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/en/projects/sofa-dashboard/contribution/","summary":"We recommend that you go to the Roadmap topic to learn about the development tasks and plans first.\n Prerequisites Before contributing any code, you need to know how to use the Git tools and the GitHub website.\n For the use of Git tools, refer to the official Pro Git book and get familiar with it by reading the first few chapters. For the Git collaboration process, refer to Git Workflows.","tags":null,"title":"How to contribute","type":"projects","url":"/en/projects/sofa-dashboard/contribution/","wordcount":836},{"author":null,"categories":null,"content":" We recommend that you go to the Roadmap topic to learn about the development tasks and plans first.\n Prerequisites Before contributing any code, you need to know how to use the Git tools and the GitHub website.\n For the use of git tools, refer to official books on gitand get familiarized by reading the first few chapters. For the Git collaboration process, refer to Git Workflows.  GitHub Code Contribution Process Submit an issue Regardless of whether you are fixing a SOFARegistry bug or adding a SOFARegistry feature, submit an issue on the SOFARegistry GitHub address to describe the bug you are going to fix or the feature you intend to add before you submit the code. There are several advantages of doing so:\n There will not be any conflict with other developers or their plans for this project. This avoids repetitive work. The SOFARegistry maintenance personnel will discuss the issue or new feature you submitted to determine whether the modification is necessary, or if there is any room for improvement or a better solution. Start code development and submit the code after an agreement is reached. This reduces the cost of communication between both parties and the number of rejected pull requests.  Get the source code To modify or add a feature after submitting an issue, click the fork button in the upper left corner to copy the master branch code to your code repository.\nPull a branch All SOFARegistry modifications are performed on branches. After the modification, submit a pull request. The modifications will then be merged into the master branch by the project maintenance personnel after the code review.\nTherefore, after getting familiar with how to get the source code, you need to:\n Download the code locally. You may select the git/https mode in this step.  git clone https://github.com/your account name/sofa-registry.git  Pull a branch to prepare for code modification.  git branch add_xxx_feature After the preceding command is executed, your code repository is switched to the corresponding branch. To view the current branch, execute the following command:\ngit branch -a If you want to switch back to the master branch, execute the following command:\ngit checkout -b master If you want to switch back to the branch, execute the following command:\ngit checkout -b \u0026amp;#34;branchName\u0026amp;#34; Modify the code and submit it locally After a branch is pulled, you can modify the code.\nWhen modifying the code, note the following:  Keep the code style consistent.  SOFARegistry uses the Maven plug-in to keep the code style consistent. Before submitting the code, be sure to execute the following command locally.\nmvn clean compile  Add the unit test code. Modifications should have passed existing unit tests. You should provide a new unit test to prove that the previous code has bugs and the bugs have been fixed in the new code. You can execute the following code to run all tests:  mvn clean test You can also use the IDE to help run a test.\nOther do\u0026amp;rsquo;s and …","date":-62135596800,"description":"","dir":"projects/sofa-registry/contributing/","fuzzywordcount":900,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"c08b5945719137833634c111c43a8d9e","permalink":"/en/projects/sofa-registry/contributing/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/en/projects/sofa-registry/contributing/","summary":"We recommend that you go to the Roadmap topic to learn about the development tasks and plans first.\n Prerequisites Before contributing any code, you need to know how to use the Git tools and the GitHub website.\n For the use of git tools, refer to official books on gitand get familiarized by reading the first few chapters. For the Git collaboration process, refer to Git Workflows.  GitHub Code Contribution Process Submit an issue Regardless of whether you are fixing a SOFARegistry bug or adding a SOFARegistry feature, submit an issue on the SOFARegistry GitHub address to describe the bug you are going to fix or the feature you intend to add before you submit the code.","tags":null,"title":"How to contribute","type":"projects","url":"/en/projects/sofa-registry/contributing/","wordcount":839},{"author":null,"categories":null,"content":"How to contribute SOFABolt\u0026amp;rsquo;s code is open source. You can submit your contributions to the code after signing the required agreement.\nContributor License Agreement Alterations and modifications made to SOFABolt\u0026amp;rsquo;s code must comply with the Contributor License Agreement.\nPrerequisites Before contributing any code, you need to know how to use the Git tool and the GitHub website.\nFor the use of Git tools, refer to the official Pro Git book and get familiar with the tools by reading the first few chapters.\nFor the Git collaboration process, refer to Git Workflows.\nGitHub Code Contribution Process Submit an issue Regardless of whether you are fixing a Bolt bug or adding a Bolt feature, submit an issue on the Bolt GitHub address to describe the bug you are going to fix or the feature you intend to add before you submit the code. There are several advantages of doing so:\n There will not be any conflict with other developers or their plans for this project. This avoids repetitive work. The Bolt maintenance personnel will discuss the issue or new feature you submitted to determine whether the modification is necessary, or if there is any room for improvement or a better solution. Start developing and submitting code after agreement to reduce the cost of communication between both parties as well as the number of rejected pull requests.  Get the source code To modify or add a feature after submitting an issue, click the fork button in the upper left corner to copy the Bolt\u0026amp;rsquo;s master branch code to your code repository.\nPull a branch All Bolt modifications are performed on branches. After the modification, submit a pull request. The modifications will then be merged into the master branch by the project maintenance personnel after the code review. Therefore, after getting familiar with the getting source code step, you need to:\n Download the code locally. You may select the git/https mode in this step.  git clone https://github.com/sofastack/sofa-bolt.git  Pull a branch to prepare for code modification.  git branch add_xxx_feature  After the preceding command is executed, your code repository is switched to the corresponding branch. To view the current branch, execute the following command:  git branch -a  If you want to switch back to the master branch, execute the following command:  git checkout -b master  If you want to switch back to your branch, execute the following command:  git checkout -b \u0026amp;#34;branchName\u0026amp;#34;  If you want to directly pull a branch from GitHub, execute the following command:  git clone -b branchname https://xxx.git Modify the code and submit it locally After a branch is pulled, you can modify the code.\nWhen modifying the code, note the following:  Keep the code style consistent. Bolt uses the Maven plug-in to keep the code style consistent. Before submitting the code, be sure to execute the following command locally.  mvn clean package  Add the unit test code. Modifications should have passed existing unit tests. …","date":-62135596800,"description":"","dir":"projects/sofa-bolt/sofa-bolt-contribution/","fuzzywordcount":1200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"c044ad534cf99e4d6d400113b490f816","permalink":"/en/projects/sofa-bolt/sofa-bolt-contribution/","publishdate":"0001-01-01T00:00:00Z","readingtime":6,"relpermalink":"/en/projects/sofa-bolt/sofa-bolt-contribution/","summary":"How to contribute SOFABolt\u0026rsquo;s code is open source. You can submit your contributions to the code after signing the required agreement.\nContributor License Agreement Alterations and modifications made to SOFABolt\u0026rsquo;s code must comply with the Contributor License Agreement.\nPrerequisites Before contributing any code, you need to know how to use the Git tool and the GitHub website.\nFor the use of Git tools, refer to the official Pro Git book and get familiar with the tools by reading the first few chapters.","tags":null,"title":"How to contribute to SOFABolt","type":"projects","url":"/en/projects/sofa-bolt/sofa-bolt-contribution/","wordcount":1140},{"author":null,"categories":null,"content":"Prerequisites Before contributing any code, you need to know how to use the Git tools and the GitHub website.\n For the use of Git tools, refer to the official Pro Git book and get familiar with it by reading the first few chapters. For the Git collaboration process, refer to Git Workflows.  GitHub Code Contribution Process Submit an issue Regardless of whether you are fixing a SOFAJRaft bug or adding a SOFAJRaft feature, submit an issue on the SOFAJRaft GitHub to describe the bug you are going to fix or the feature you intend to add before you submit the code. There are several advantages of doing so:\n There will not be any conflict with other developers or their plans for this project. This avoids repetitive work. The SOFAJRaft maintenance personnel will discuss the issue or new feature you submitted to determine whether the modification is necessary, or if there is any room for improvement or a better solution. Start code development and submit the code after an agreement is reached. This reduces the cost of communication between both parties and the number of rejected pull requests.  Get the source code To modify or add a feature after submitting an issue, click the fork button in the upper left corner to copy the master branch code to your code repository.\nPull a branch We recommend that you first read the SOFAJRaft Branch management policy.\nAll SOFAJRaft modifications are performed on branches. After the modification, submit a pull request. The modifications will then be merged into the master branch by the project maintenance personnel after the code review. Therefore, after getting familiar with how to get the source code, you need to:\n  Download the code locally. You may select the git/https mode in this step.\ngit clone https://github.com/your account name/sofa-jraft   Pull a branch to prepare for code modification.\ngit branch add_xxx_feature   After the preceding command is executed, your code repository is switched to the corresponding branch. To view the current branch, execute the following command:\ngit branch -a   If you want to switch back to the master branch, execute the following command:\ngit checkout -b master   If you want to switch back to the branch, execute the following command:\ngit checkout -b \u0026amp;#34;branchName\u0026amp;#34;   Modify the code and submit it locally After a branch is pulled, you can modify the code.\nWhen modifying the code, note the following:   Keep the code style consistent. SOFAJRaft uses the Maven plug-in to keep the code style consistent. Before submitting the code, be sure to execute the following command locally.\nmvn clean compile   Add the unit test code.\n  New modifications should have passed existing unit tests.\n  Provide a new unit test to prove that the previous code has bugs and the bugs have been fixed in the new code. Execute the following command to run all tests:\nmvn clean test You can also use the IDE to help execute a command.\n  Other do\u0026amp;rsquo;s and don\u0026amp;rsquo;ts  Retain the original style of the code …","date":-62135596800,"description":"","dir":"projects/sofa-jraft/how-to-contribute-code-to-sofajraft/","fuzzywordcount":900,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"99034715298f73cd835672b872141609","permalink":"/en/projects/sofa-jraft/how-to-contribute-code-to-sofajraft/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/en/projects/sofa-jraft/how-to-contribute-code-to-sofajraft/","summary":"Prerequisites Before contributing any code, you need to know how to use the Git tools and the GitHub website.\n For the use of Git tools, refer to the official Pro Git book and get familiar with it by reading the first few chapters. For the Git collaboration process, refer to Git Workflows.  GitHub Code Contribution Process Submit an issue Regardless of whether you are fixing a SOFAJRaft bug or adding a SOFAJRaft feature, submit an issue on the SOFAJRaft GitHub to describe the bug you are going to fix or the feature you intend to add before you submit the code.","tags":null,"title":"How to contribute to SOFAJRaft","type":"projects","url":"/en/projects/sofa-jraft/how-to-contribute-code-to-sofajraft/","wordcount":841},{"author":null,"categories":null,"content":"","date":-62135596800,"description":"","dir":"projects/sofa-rpc/http/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"0e92b5faec8584280cc296255f3a4541","permalink":"/en/projects/sofa-rpc/http/","publishdate":"0001-01-01T00:00:00Z","readingtime":0,"relpermalink":"/en/projects/sofa-rpc/http/","summary":"","tags":null,"title":"HTTP","type":"projects","url":"/en/projects/sofa-rpc/http/","wordcount":0},{"author":null,"categories":null,"content":"Http 协议基本使用 在 SOFARPC (非SOFABoot 环境)中，当使用Http作为服务端协议的时候，支持Json作为序列化方式，作为一些基础的测试方式使用。\nSOFARPC API 使用 发布服务 // 只有1个线程 执行 ServerConfig serverConfig = new ServerConfig() .setStopTimeout(60000) .setPort(12300) .setProtocol(RpcConstants.PROTOCOL_TYPE_HTTP) .setDaemon(true); // 发布一个服务，每个请求要执行1秒 ProviderConfig\u0026amp;lt;HttpService\u0026amp;gt; providerConfig = new ProviderConfig\u0026amp;lt;HttpService\u0026amp;gt;() .setInterfaceId(HttpService.class.getName()) .setRef(new HttpServiceImpl()) .setApplication(new ApplicationConfig().setAppName(\u0026amp;#34;serverApp\u0026amp;#34;)) .setServer(serverConfig) .setUniqueId(\u0026amp;#34;uuu\u0026amp;#34;) .setRegister(false); providerConfig.export(); 服务引用 因为是Http+Json，所以引用方可以直接通过HttpClient进行调用,以下为一段测试代码。\nprivate ObjectMapper mapper = new ObjectMapper(); HttpClient httpclient = HttpClientBuilder.create().build(); // POST 正常请求 String url = \u0026amp;#34;http://127.0.0.1:12300/com.alipay.sofa.rpc.server.http.HttpService:uuu/object\u0026amp;#34;; HttpPost httpPost = new HttpPost(url); httpPost.setHeader(RemotingConstants.HEAD_SERIALIZE_TYPE, \u0026amp;#34;json\u0026amp;#34;); ExampleObj obj = new ExampleObj(); obj.setId(1); obj.setName(\u0026amp;#34;xxx\u0026amp;#34;); byte[] bytes = mapper.writeValueAsBytes(obj); ByteArrayEntity entity = new ByteArrayEntity(bytes, ContentType.create(\u0026amp;#34;application/json\u0026amp;#34;)); httpPost.setEntity(entity); HttpResponse httpResponse = httpclient.execute(httpPost); Assert.assertEquals(200, httpResponse.getStatusLine().getStatusCode()); byte[] data = EntityUtils.toByteArray(httpResponse.getEntity()); ExampleObj result = mapper.readValue(data, ExampleObj.class); Assert.assertEquals(\u0026amp;#34;xxxxx\u0026amp;#34;, result.getName()); ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/http-json/","fuzzywordcount":300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"28abdf6369247346bad670c639a422b8","permalink":"/projects/sofa-rpc/http-json/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/http-json/","summary":"Http 协议基本使用 在 SOFARPC (非SOFABoot 环境)中，当使用Http作为服务端协议的时候，支持Json作为序列化方式，作为一些基础的测试方式使用。","tags":null,"title":"Http 协议基本使用","type":"projects","url":"/projects/sofa-rpc/http-json/","wordcount":242},{"author":null,"categories":null,"content":"HttpClient Integration In this document will demonstrate how to use SOFATracer to track of HttpClient, this example [address] (https://github.com/sofastack-guides/sofa-tracer-guides/tree/master/tracer-sample-with-httpclient).\nAssuming you have built a simple Spring Web project based on SOFABoot, Then you can be operated by the following steps:\nIntroduce dependency \u0026amp;lt;!-- SOFATracer dependency --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;tracer-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!-- HttpClient dependency --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.apache.httpcomponents\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;httpclient\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;!-- 4.5.X --\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;4.5.3\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.apache.httpcomponents\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;httpasyncclient\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;!-- 4.X --\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;4.1.3\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; Project Configuration Then, add the parameters to be used by SOFATracer under the project\u0026amp;rsquo;s application.properties file, including spring.application.name that indicates the current application name and logging.path that specifies the log output directory.\n# Application Name spring.application.name=HttpClientDemo # logging path logging.path=./logs Add a Controller that provides RESTful service @RestController public class SampleRestController { private final AtomicLong counter = new AtomicLong(0); /** * Request http://localhost:8080/httpclient?name= * @param name name * @return Map of Result */ @RequestMapping(\u0026amp;#34;/httpclient\u0026amp;#34;) public Map\u0026amp;lt;String, Object\u0026amp;gt; greeting(@RequestParam(value = \u0026amp;#34;name\u0026amp;#34;, defaultValue = \u0026amp;#34;httpclient\u0026amp;#34;) String name) { Map\u0026amp;lt;String, Object\u0026amp;gt; map = new HashMap\u0026amp;lt;String, Object\u0026amp;gt;(); map.put(\u0026amp;#34;count\u0026amp;#34;, counter.incrementAndGet()); map.put(\u0026amp;#34;name\u0026amp;#34;, name); return map; } } Construct HttpClient to initiate a call to the RESTful service above The code example is as follows:\n Construct an HttpClient synchronous call instance:  HttpClientBuilder httpClientBuilder = HttpClientBuilder.create(); // SOFATracer SofaTracerHttpClientBuilder.clientBuilder(httpClientBuilder); CloseableHttpClient httpClient = httpClientBuilder.setConnectionManager(connManager).disableAutomaticRetries() .build();  Construct an HttpClient asynchronous call instance:  RequestConfig requestConfig = RequestConfig.custom().setSocketTimeout(6000).setConnectTimeout(6000).setConnectionRequestTimeout(6000).build(); HttpAsyncClientBuilder httpAsyncClientBuilder = HttpAsyncClientBuilder.create(); //tracer SofaTracerHttpClientBuilder.asyncClientBuilder(httpAsyncClientBuilder); CloseableHttpAsyncClient asyncHttpclient = httpAsyncClientBuilder.setDefaultRequestConfig(requestConfig).build(); When you construct the HttpClient via the SofaTracerHttpClientBuilder (clientBuilder method for synchronous call instance, and asyncClientBuilder method for …","date":-62135596800,"description":"","dir":"projects/sofa-tracer/usage-of-httpclient/","fuzzywordcount":500,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"3efb3d0d5bd884665537aa974ec21359","permalink":"/en/projects/sofa-tracer/usage-of-httpclient/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/en/projects/sofa-tracer/usage-of-httpclient/","summary":"HttpClient Integration In this document will demonstrate how to use SOFATracer to track of HttpClient, this example [address] (https://github.com/sofastack-guides/sofa-tracer-guides/tree/master/tracer-sample-with-httpclient).\nAssuming you have built a simple Spring Web project based on SOFABoot, Then you can be operated by the following steps:\nIntroduce dependency \u0026lt;!-- SOFATracer dependency --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alipay.sofa\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;tracer-sofa-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- HttpClient dependency --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.httpcomponents\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;httpclient\u0026lt;/artifactId\u0026gt; \u0026lt;!-- 4.5.X --\u0026gt; \u0026lt;version\u0026gt;4.5.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.httpcomponents\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;httpasyncclient\u0026lt;/artifactId\u0026gt; \u0026lt;!-- 4.X --\u0026gt; \u0026lt;version\u0026gt;4.1.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; Project Configuration Then, add the parameters to be used by SOFATracer under the project\u0026rsquo;s application.","tags":null,"title":"HttpClient Integration","type":"projects","url":"/en/projects/sofa-tracer/usage-of-httpclient/","wordcount":499},{"author":null,"categories":null,"content":"HttpClient Log Format After integrating tracer-httpclient-plugin, SOFATracer outputs the link data requested by HttpClient in JSON data by default.\nHttpClient digest log (httpclient-digest.log) The data is output in JSON format. Each key meaning is as follows:\n   Key Meaning     Time log printing time   Local.app Current application name   traceId TraceId   spanId SpanId   Request.url Request URL   Method Request HTTP method   Result.code HTTP call returns status code   req.size.bytes Request body size   resp.size.bytes Response body size   Time.cost.milliseconds Request time (ms)   Current.thread.name Thread name   Remote.app Name of the called application   Baggage Transparently transmitted baggage data    Example:\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2018-09-27 21:58:43.067\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;HttpClientDemo\u0026amp;#34;,\u0026amp;#34;traceId\u0026amp;#34;:\u0026amp;#34;0a0fe8801538056723034100235072\u0026amp;#34;,\u0026amp;#34;spanId\u0026amp;#34;:\u0026amp;#34;0\u0026amp;#34;,\u0026amp;#34;request.url\u0026amp;#34;:\u0026amp;#34;http://localhost:8080/httpclient\u0026amp;#34;,\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;GET\u0026amp;#34;,\u0026amp;#34;result.code\u0026amp;#34;:\u0026amp;#34;200\u0026amp;#34;,\u0026amp;#34;req.size.bytes\u0026amp;#34;:0,\u0026amp;#34;resp.size.bytes\u0026amp;#34;:-1,\u0026amp;#34;time.cost.milliseconds\u0026amp;#34;:33,\u0026amp;#34;current.thread.name\u0026amp;#34;:\u0026amp;#34;I/O dispatcher 1\u0026amp;#34;,\u0026amp;#34;remote.app\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;,\u0026amp;#34;baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;} Note: The application name can be passed in as a parameter when constructing an HttpClient instance via SofaTracerHttpClientBuilder.\nHttpClient statistical Log (httpclient-stat.log) stat.key is the collection of statistical keywords in this period, which uniquely determines a set of statistical data, including local.app, request.url, and method field.\nExample:\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2018-09-27 21:59:42.233\u0026amp;#34;,\u0026amp;#34;stat.key\u0026amp;#34;:{\u0026amp;#34;request.url\u0026amp;#34;:\u0026amp;#34;http://localhost:8080/httpclient\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;HttpClientDemo\u0026amp;#34;,\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;GET\u0026amp;#34;},\u0026amp;#34;count\u0026amp;#34;:2,\u0026amp;#34;total.cost.milliseconds\u0026amp;#34;:562,\u0026amp;#34;success\u0026amp;#34;:\u0026amp;#34;true\u0026amp;#34;,\u0026amp;#34;load.test\u0026amp;#34;:\u0026amp;#34;F\u0026amp;#34;} ","date":-62135596800,"description":"","dir":"projects/sofa-tracer/log-format-httpclient/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"7df3d68ba21f1b2a43c0265fdc4eae3e","permalink":"/en/projects/sofa-tracer/log-format-httpclient/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-tracer/log-format-httpclient/","summary":"HttpClient Log Format After integrating tracer-httpclient-plugin, SOFATracer outputs the link data requested by HttpClient in JSON data by default.\nHttpClient digest log (httpclient-digest.log) The data is output in JSON format. Each key meaning is as follows:\n   Key Meaning     Time log printing time   Local.app Current application name   traceId TraceId   spanId SpanId   Request.url Request URL   Method Request HTTP method   Result.","tags":null,"title":"HttpClient log","type":"projects","url":"/en/projects/sofa-tracer/log-format-httpclient/","wordcount":143},{"author":null,"categories":null,"content":"在本文档将演示如何使用 SOFATracer 对 HttpClient 进行埋点，本示例工程地址。\n假设你已经基于 SOFABoot 构建了一个简单的 Spring Web 工程，那么可以通过如下步骤进行操作：\n依赖引入 \u0026amp;lt;!-- SOFATracer 依赖 --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;tracer-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!-- HttpClient 依赖 --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.apache.httpcomponents\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;httpclient\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;!-- 版本 4.5.X 系列 --\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;4.5.3\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.apache.httpcomponents\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;httpasyncclient\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;!-- 版本 4.X 系列 --\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;4.1.3\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 工程配置 在工程的 application.properties 文件下添加 SOFATracer 要使用的参数，包括spring.application.name 用于标示当前应用的名称；logging.path 用于指定日志的输出目录。\n# Application Name spring.application.name=HttpClientDemo # logging path logging.path=./logs 添加一个提供 RESTful 服务的 Controller 在工程代码中，添加一个简单的 Controller，例如：\n@RestController public class SampleRestController { private final AtomicLong counter = new AtomicLong(0); /** * Request http://localhost:8080/httpclient?name= * @param name name * @return Map of Result */ @RequestMapping(\u0026amp;#34;/httpclient\u0026amp;#34;) public Map\u0026amp;lt;String, Object\u0026amp;gt; greeting(@RequestParam(value = \u0026amp;#34;name\u0026amp;#34;, defaultValue = \u0026amp;#34;httpclient\u0026amp;#34;) String name) { Map\u0026amp;lt;String, Object\u0026amp;gt; map = new HashMap\u0026amp;lt;String, Object\u0026amp;gt;(); map.put(\u0026amp;#34;count\u0026amp;#34;, counter.incrementAndGet()); map.put(\u0026amp;#34;name\u0026amp;#34;, name); return map; } } 构造 HttpClient 发起一次对上文的 RESTful 服务的调用 代码示例如下：\n 构造 HttpClient 同步调用实例：  HttpClientBuilder httpClientBuilder = HttpClientBuilder.create(); //SOFATracer SofaTracerHttpClientBuilder.clientBuilder(httpClientBuilder); CloseableHttpClient httpClient = httpClientBuilder.setConnectionManager(connManager).disableAutomaticRetries() .build();  构造 HttpClient 异步调用实例：  RequestConfig requestConfig = RequestConfig.custom().setSocketTimeout(6000).setConnectTimeout(6000).setConnectionRequestTimeout(6000).build(); HttpAsyncClientBuilder httpAsyncClientBuilder = HttpAsyncClientBuilder.create(); //tracer SofaTracerHttpClientBuilder.asyncClientBuilder(httpAsyncClientBuilder); CloseableHttpAsyncClient asyncHttpclient = httpAsyncClientBuilder.setDefaultRequestConfig(requestConfig).build(); 通过 SofaTracerHttpClientBuilder(clientBuilder 方法构造同步，asyncClientBuilder 方法构造异步) 构造的 HttpClient 在发起对上文的 RESTful 服务调用的时候，就会埋点 SOFATracer 的链路的数据。\n运行 启动 SOFABoot 应用，在控制台中看到启动打印的日志如下：\n2018-09-27 20:31:21.465 INFO 33277 --- [ main] o.s.j.e.a.AnnotationMBeanExporter : Registering beans for JMX exposure on startup 2018-09-27 20:31:21.599 INFO 33277 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http) 2018-09-27 20:31:21.608 INFO 33277 --- [ main] c.a.s.t.e.h.HttpClientDemoApplication : Started HttpClientDemoApplication in 5.949 seconds (JVM running for 6.573) 当有类似如下的日志时，说明 HttpClient 的调用成功：\n2018-09-27 20:31:22.336 INFO 33277 --- [ …","date":-62135596800,"description":"","dir":"projects/sofa-tracer/usage-of-httpclient/","fuzzywordcount":800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"3efb3d0d5bd884665537aa974ec21359","permalink":"/projects/sofa-tracer/usage-of-httpclient/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-tracer/usage-of-httpclient/","summary":"在本文档将演示如何使用 SOFATracer 对 HttpClient 进行埋点，本示例工程地址。 假设你已经基于 SOFABoot 构建了一个简单的 Spring Web 工程，那么可以通过如下步骤进行操作： 依赖引入 \u0026lt;!-- SOFATracer 依","tags":null,"title":"HttpClient 埋点接入","type":"projects","url":"/projects/sofa-tracer/usage-of-httpclient/","wordcount":748},{"author":null,"categories":null,"content":"SOFATracer 集成 sofa-tracer-httpclient-plugin 插件后输出 HttpClient 请求的链路数据，默认为 JSON 数据格式。\nHttpClient 摘要日志（httpclient-digest.log） 以 JSON 格式输出的数据，相应 key 的含义解释如下：\n   key 表达含义     time 日志打印时间   local.app 当前应用名   traceId TraceId   spanId SpanId   span.kind Span 类型   result.code 状态码   current.thread.name 当前线程名   time.cost.milliseconds span 耗时   request.url 请求地址   method http method   req.size.bytes 请求大小   resp.size.bytes 响应大小   sys.baggage 系统透传的 baggage 数据   biz.baggage 业务透传的 baggage 数据    样例：\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2019-09-02 23:43:13.191\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;HttpClientDemo\u0026amp;#34;,\u0026amp;#34;traceId\u0026amp;#34;:\u0026amp;#34;1e27a79c1567438993170100210107\u0026amp;#34;,\u0026amp;#34;spanId\u0026amp;#34;:\u0026amp;#34;0\u0026amp;#34;,\u0026amp;#34;span.kind\u0026amp;#34;:\u0026amp;#34;client\u0026amp;#34;,\u0026amp;#34;result.code\u0026amp;#34;:\u0026amp;#34;200\u0026amp;#34;,\u0026amp;#34;current.thread.name\u0026amp;#34;:\u0026amp;#34;I/O dispatcher 1\u0026amp;#34;,\u0026amp;#34;time.cost.milliseconds\u0026amp;#34;:\u0026amp;#34;21ms\u0026amp;#34;,\u0026amp;#34;request.url\u0026amp;#34;:\u0026amp;#34;http://localhost:8080/httpclient\u0026amp;#34;,\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;GET\u0026amp;#34;,\u0026amp;#34;req.size.bytes\u0026amp;#34;:0,\u0026amp;#34;resp.size.bytes\u0026amp;#34;:-1,\u0026amp;#34;remote.app\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;,\u0026amp;#34;sys.baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;,\u0026amp;#34;biz.baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;} 备注：应用名称可以通过 SofaTracerHttpClientBuilder 构造 HttpClient 实例时以入参的形式传入。\nHttpClient 统计日志（httpclient-stat.log） stat.key 即本段时间内的统计关键字集合，统一关键字集合唯一确定一组统计数据，包含local.app、request.url、和 method 字段.\n样例：\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2019-09-02 23:44:11.785\u0026amp;#34;,\u0026amp;#34;stat.key\u0026amp;#34;:{\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;GET\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;HttpClientDemo\u0026amp;#34;,\u0026amp;#34;request.url\u0026amp;#34;:\u0026amp;#34;http://localhost:8080/httpclient\u0026amp;#34;},\u0026amp;#34;count\u0026amp;#34;:2,\u0026amp;#34;total.cost.milliseconds\u0026amp;#34;:229,\u0026amp;#34;success\u0026amp;#34;:\u0026amp;#34;true\u0026amp;#34;,\u0026amp;#34;load.test\u0026amp;#34;:\u0026amp;#34;F\u0026amp;#34;} ","date":-62135596800,"description":"","dir":"projects/sofa-tracer/log-format-httpclient/","fuzzywordcount":300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"7df3d68ba21f1b2a43c0265fdc4eae3e","permalink":"/projects/sofa-tracer/log-format-httpclient/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-tracer/log-format-httpclient/","summary":"SOFATracer 集成 sofa-tracer-httpclient-plugin 插件后输出 HttpClient 请求的链路数据，默认为 JSON 数据格式。 HttpClient 摘要日志（httpclient-digest.log） 以 JSON 格式输出的数据，相应 key 的含","tags":null,"title":"HttpClient 日志","type":"projects","url":"/projects/sofa-tracer/log-format-httpclient/","wordcount":280},{"author":null,"categories":null,"content":"SOFARPC is integrated Hystrix provides fuse capability and is currently available in the first preview version. More information about Hystrix can be found in [Hystrix Official Documentation] (https://github.com/Netflix/Hystrix), Hystrix integration capabilities are provided primarily by [ScienJus] (https://github.com/ScienJus), thanks for contribution.\nNext, let\u0026amp;rsquo;s talk about how to experience the fuse capability of Hystrix. The following example uses the SOFARPC 5.5.0 version. More Hystrix configuration and SOFABoot integration usage will be provided in subsequent releases, so stay tuned.\nWork preparation The Hystrix module is not loaded directly as an optional module by default. If you need to use it, you need to actively add the Hystrix maven dependency:\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.netflix.hystrix\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hystrix-core\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;1.5.12\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; By explicitly opening Hystrix by configuration, HystrixFilter will be loaded automatically:\n// Open globally RpcConfigs.putValue(HystrixConstants.SOFA_HYSTRIX_ENABLED, true); // Open for a specific Consumer ConsumerConfig\u0026amp;lt;HelloService\u0026amp;gt; consumerConfig = new ConsumerConfig\u0026amp;lt;HelloService\u0026amp;gt;() .setInterfaceId(HelloService.class.getName()) .setParameter(HystrixConstants.SOFA_HYSTRIX_ENABLED, String.valueOf(true)); FallbackFactory The FallbackFactory interface mainly provides the injection capability of the Fallback implementation, which is used to automatically perform the degraded logic when Hystrix executes an exception (throws an exception, timeout, thread pool rejection, and blown).\nDefine the interface Fallback implementation:\npublic class HelloServiceFallback implements HelloService { @Override public String sayHello(String name, int age) { return \u0026amp;#34;fallback \u0026amp;#34; + name + \u0026amp;#34; from server! age: \u0026amp;#34; + age; } } Inject Fallback implementation:\nConsumerConfig\u0026amp;lt;HelloService\u0026amp;gt; consumerConfig = new ConsumerConfig\u0026amp;lt;HelloService\u0026amp;gt;() .setInterfaceId(HelloService.class.getName()) .setParameter(HystrixConstants.SOFA_HYSTRIX_ENABLED, String.valueOf(true)); // You can directly inject Fallback implementation directly using the default FallbackFactory SofaHystrixConfig.registerFallback(consumerConfig, new HelloServiceFallback()); // You can also customize FallbackFactory to directly inject FallbackFactory SofaHystrixConfig.registerFallbackFactory(consumerConfig, new HelloServiceFallbackFactory()); When the server responds with a failure, the client automatically triggers the Fallback logic execution.\nSetterFactory SetterFactory provides Hystrix fine-grained configuration capabilities. SOFARPC has provided the default DefaultSetterFactory to generate the Setter for each caller. If there is a more customized description, it can also be provided for each ConsumerConfig. Customize SetterFactory.\nSofaHystrixConfig.registerSetterFactory(consumerConfig, new CustomSetterFactory()); In the implementation provided …","date":-62135596800,"description":"","dir":"projects/sofa-rpc/fault-hystrix/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"7482dc341bf16dd5671634ffa689604a","permalink":"/en/projects/sofa-rpc/fault-hystrix/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-rpc/fault-hystrix/","summary":"SOFARPC is integrated Hystrix provides fuse capability and is currently available in the first preview version. More information about Hystrix can be found in [Hystrix Official Documentation] (https://github.com/Netflix/Hystrix), Hystrix integration capabilities are provided primarily by [ScienJus] (https://github.com/ScienJus), thanks for contribution.\nNext, let\u0026rsquo;s talk about how to experience the fuse capability of Hystrix. The following example uses the SOFARPC 5.5.0 version. More Hystrix configuration and SOFABoot integration usage will be provided in subsequent releases, so stay tuned.","tags":null,"title":"Hystrix fault tolerance","type":"projects","url":"/en/projects/sofa-rpc/fault-hystrix/","wordcount":337},{"author":null,"categories":null,"content":"SOFARPC 已集成 Hystrix 提供熔断能力，当前提供第一个预览版。关于 Hystrix 的更多介绍可以参考 Hystrix 官方文档，Hystrix 集成能力主要由 ScienJus 提供，感谢贡献。\n接下来介绍一下如何体验 Hystrix 带来的熔断能力，以下示例使用 SOFARPC 5.5.0 版本，更多 Hystrix 的配置及 SOFABoot 集成使用方式将在后续版本提供，敬请关注。\n准备工作 Hystrix 模块作为可选模块默认不会直接加载，如需要使用，需要先主动加入 Hystrix maven 依赖：\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.netflix.hystrix\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hystrix-core\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;1.5.12\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 通过配置显式开启 Hystrix，将会自动加载 HystrixFilter：\n// 全局开启 RpcConfigs.putValue(HystrixConstants.SOFA_HYSTRIX_ENABLED, true); // 对特定 Consumer 开启 ConsumerConfig\u0026amp;lt;HelloService\u0026amp;gt; consumerConfig = new ConsumerConfig\u0026amp;lt;HelloService\u0026amp;gt;() .setInterfaceId(HelloService.class.getName()) .setParameter(HystrixConstants.SOFA_HYSTRIX_ENABLED, String.valueOf(true)); FallbackFactory FallbackFactory 接口主要提供 Fallback 实现的注入能力，用于在 Hystrix 执行出现异常（抛出异常、超时、线程池拒绝和熔断等）时自动执行降级逻辑。\n定义接口 Fallback 实现：\npublic class HelloServiceFallback implements HelloService { @Override public String sayHello(String name, int age) { return \u0026amp;#34;fallback \u0026amp;#34; + name + \u0026amp;#34; from server! age: \u0026amp;#34; + age; } } 注入 Fallback 实现：\nConsumerConfig\u0026amp;lt;HelloService\u0026amp;gt; consumerConfig = new ConsumerConfig\u0026amp;lt;HelloService\u0026amp;gt;() .setInterfaceId(HelloService.class.getName()) .setParameter(HystrixConstants.SOFA_HYSTRIX_ENABLED, String.valueOf(true)); // 可以直接使用默认的 FallbackFactory 直接注入 Fallback 实现 SofaHystrixConfig.registerFallback(consumerConfig, new HelloServiceFallback()); // 也可以自定义 FallbackFactory 直接注入 FallbackFactory SofaHystrixConfig.registerFallbackFactory(consumerConfig, new HelloServiceFallbackFactory()); 当服务端响应失败时，客户端会自动触发 Fallback 逻辑执行。\nSetterFactory SetterFactory 提供 Hystrix 细粒度配置能力，SOFARPC 已提供默认的 DefaultSetterFactory 来生成每个调用方对应的 Setter，如有更定制化的述求，也可以针对每个 ConsumerConfig 提供自定义 SetterFactory。\nSofaHystrixConfig.registerSetterFactory(consumerConfig, new CustomSetterFactory()); 默认提供的实现中 GroupKey 为 InterfaceId，CommandKey 为方法的名称。\n支持 Hystrix 的版本信息 SOFARPC: 5.5.0, SOFABoot: 2.5.3。\nSOAF RPC 集成验证 Hystrix 版本：1.5.12。\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/fault-hystrix/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"7482dc341bf16dd5671634ffa689604a","permalink":"/projects/sofa-rpc/fault-hystrix/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-rpc/fault-hystrix/","summary":"SOFARPC 已集成 Hystrix 提供熔断能力，当前提供第一个预览版。关于 Hystrix 的更多介绍可以参考 Hystrix 官方文档，Hystrix 集成能力主要由 ScienJus 提供，感谢贡献。 接下来介绍一","tags":null,"title":"Hystrix 客户端熔断","type":"projects","url":"/projects/sofa-rpc/fault-hystrix/","wordcount":552},{"author":null,"categories":null,"content":"Installation guide To use Istio in a non-Kubernetes environment, you must complete the following critical tasks first:\n Configure the Istio API server for the Istio control plane. You can also use MemStore to launch Pilot for demonstration purpose. Manually add SOFAMosn to all microservice instances and start in SideCar mode. Make sure that all requests are routed through SOFAMosn.  Set control plane The Istio control plane consists of four main services: Pilot, Mixter, Citadel, and API server.\nAPI server Istio\u0026amp;rsquo;s API server, which is based on Kubernetes API server, provides configuration management and role-based access control. The API server requires an etcd cluster as the underlying persistent storage.\nInstall locally Use the following Docker compose file to install an API server for POC:\nversion: \u0026amp;#39;2\u0026amp;#39; services: etcd: image: quay.io/coreos/etcd:latest networks: default: aliases: - etcd ports: - \u0026amp;#34;4001:4001\u0026amp;#34; - \u0026amp;#34;2380:2380\u0026amp;#34; - \u0026amp;#34;2379:2379\u0026amp;#34; environment: - SERVICE_IGNORE=1 command: [ \u0026amp;#34;/usr/local/bin/etcd\u0026amp;#34;, \u0026amp;#34;-advertise-client-urls=http://0.0.0.0:2379\u0026amp;#34;, \u0026amp;#34;-listen-client-urls=http://0.0.0.0:2379\u0026amp;#34; ] istio-apiserver: image: gcr.io/google_containers/kube-apiserver-amd64:v1.7.3 networks: default: aliases: - apiserver ports: - \u0026amp;#34;8080:8080\u0026amp;#34; privileged: true environment: - SERVICE_IGNORE=1 command: [ \u0026amp;#34;kube-apiserver\u0026amp;#34;, \u0026amp;#34;--etcd-servers\u0026amp;#34;, \u0026amp;#34;http://etcd:2379\u0026amp;#34;, \u0026amp;#34;--service-cluster-ip-range\u0026amp;#34;, \u0026amp;#34;10.99.0.0/16\u0026amp;#34;, \u0026amp;#34;--insecure-port\u0026amp;#34;, \u0026amp;#34;8080\u0026amp;#34;, \u0026amp;#34;-v\u0026amp;#34;, \u0026amp;#34;2\u0026amp;#34;, \u0026amp;#34;--insecure-bind-address\u0026amp;#34;, \u0026amp;#34;0.0.0.0\u0026amp;#34; ] Other control plane components Currently, SOFAMosn hasn\u0026amp;rsquo;t integrated with the components other than Pilot, so you don\u0026amp;rsquo;t need to install Mixer, Citadel and other components.\nAdd SOFAMosn Sidecar to microservice instances Every microservice application instance must have an associated SOFAMosn instance.\n","date":-62135596800,"description":"","dir":"projects/sofa-mesh/pilot-setup-zookeeper-installation/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"4c0bd56673dc8aebef9011a22496392d","permalink":"/en/projects/sofa-mesh/pilot-setup-zookeeper-installation/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-mesh/pilot-setup-zookeeper-installation/","summary":"Installation guide To use Istio in a non-Kubernetes environment, you must complete the following critical tasks first:\n Configure the Istio API server for the Istio control plane. You can also use MemStore to launch Pilot for demonstration purpose. Manually add SOFAMosn to all microservice instances and start in SideCar mode. Make sure that all requests are routed through SOFAMosn.  Set control plane The Istio control plane consists of four main services: Pilot, Mixter, Citadel, and API server.","tags":null,"title":"Installation guide","type":"projects","url":"/en/projects/sofa-mesh/pilot-setup-zookeeper-installation/","wordcount":221},{"author":null,"categories":null,"content":" Project address\n Introduction SOFABoot extends the Health Check of Spring Boot. For detailed information, see SOFABoot Documentation. This sample project is intended to demonstrate how to integrate the Health Check component of SOFABoot during merged deployment. Differences between the Health Check in merged deployment and that of a single SOFABoot application are as follows:\n During static merged deployment, all Biz packages must pass the Health Check before the Ark package can be started normally. When deploying the Biz packages dynamically in Jarslink2.0, all packages must pass the Health Check before successful deployment. In merged deployment, a new check item named multiApplicationHealthChecker will be added when you access Spring Boot\u0026amp;rsquo;s default /health. The item is used to check the health of all Biz packages. Only after all Biz packages pass the Health Check can the merged package pass the Health Check.  Dependency To integrate the Health Check capability of SOFABoot in merged deployment, you need to add the following dependencies:\n\u0026amp;lt;!--health check--\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;runtime-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;classifier\u0026amp;gt;ark-plugin\u0026amp;lt;/classifier\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;runtime-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;healthcheck-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;exclusions\u0026amp;gt; \u0026amp;lt;exclusion\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-starter-web\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/exclusion\u0026amp;gt; \u0026amp;lt;/exclusions\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; Note that spring-boot-starter-web is excluded to avoid starting multiple web applications when you introduce the healthcheck-sofa-boot-starter dependency.\nDemo   cd biz-health-check-sample/app-one \u0026amp;amp;\u0026amp;amp; mvn clean package Execute the mvn clean package command in the app-one root directory and package the application into an Ark or Biz package. The file will be exported to the biz-health-check-sample/app-one/target directory.\n  cd biz-health-check-sample/app-two \u0026amp;amp;\u0026amp;amp; mvn clean package Execute the mvn clean package command in the app-two root directory and package the application into an Ark or Biz package. The file will be exported to the biz-health-check-sample/app-two/target directory.\n  Use java -jar to start the Ark package for app-one.\n  After the Ark package has started, visit http://localhost:8080/health in the browser. This is Spring Boot\u0026amp;rsquo;s default Health Check endpoint. A new check item named multiApplicationHealthChecker is added in the results and there is now only one Biz package. The page is displayed as follows: …","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-jarslink-jarslink-health-demo/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"99832d969ec54b925c3dca1205b95165","permalink":"/en/projects/sofa-boot/sofa-jarslink-jarslink-health-demo/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-boot/sofa-jarslink-jarslink-health-demo/","summary":"Project address\n Introduction SOFABoot extends the Health Check of Spring Boot. For detailed information, see SOFABoot Documentation. This sample project is intended to demonstrate how to integrate the Health Check component of SOFABoot during merged deployment. Differences between the Health Check in merged deployment and that of a single SOFABoot application are as follows:\n During static merged deployment, all Biz packages must pass the Health Check before the Ark package can be started normally.","tags":null,"title":"Integrate SOFABoot health check","type":"projects","url":"/en/projects/sofa-boot/sofa-jarslink-jarslink-health-demo/","wordcount":386},{"author":null,"categories":null,"content":"Since rpc-sofa-boot-starter version 6.0.1, SOFARPC provide the ability to integrate RESTful service with Swagger easily.\nIf you are using rpc-sofa-boot-starter in SOFABoot or Spring Boot environment and you want to enable Swagger support, first, you need add Swagger dependencies in your pom.xml:\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;io.swagger.core.v3\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;swagger-jaxrs2\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.0.0\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.google.guava\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;guava\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;20.0\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; Then you need add a configuration com.alipay.sofa.rpc.restSwagger=true in application.properties.\nFinally, visit http://localhost:8341/swagger/openapi and you can get all the Swagger OpenAPI information about SOFARPC\u0026amp;rsquo;s RESTful services.\nIf you are not using rpc-sofa-boot-starter or the version of rpc-sofa-boot-starter you depends is smaller then 6.0.1, you can integration SOFARPC RESTful service with Swagger by using the following tutorial.\nCurrently, SOFARPC does not provide the ability to integrate RESTful service with Swagger via one click. The ability will be provided in future versions, but you can refer to this document to integrate RESTful service with Swagger in the existing versions of SOFARPC.\nFirst, you need to add Swagger related dependencies into your application. Since SOFARPC\u0026amp;rsquo;s RESTful protocol is based on the JAXRS, so you just need to add Swagger\u0026amp;rsquo;s JAXRS dependency:\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;io.swagger.core.v3\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;swagger-jaxrs2\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.0.0\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.google.guava\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;guava\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;20.0\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; The 20.0 version of Guava was added to resolve Guava version conflict.\nAdd a Swagger RESTful service To enable Swagger to expose SOFARPC\u0026amp;rsquo;s RESTful services through Swagger OpenAPI, we can provide Swagger\u0026amp;rsquo;s OpenAPI services through SOFARPC\u0026amp;rsquo;s RESTful services. First, you need to create a new interface:\n@Path(\u0026amp;#34;swagger\u0026amp;#34;) public interface OpenApiService { @GET @Path(\u0026amp;#34;openapi\u0026amp;#34;) @Produces(\u0026amp;#34;application/json\u0026amp;#34;) String openApi(); } Then provide an implementation class and publish it as a RESTful service of SOFARPC:\n@Service @SofaService(bindings = {@SofaServiceBinding(bindingType = \u0026amp;#34;rest\u0026amp;#34;)}, interfaceType = OpenApiService.class) public class OpenApiServiceImpl implements OpenApiService, InitializingBean { private OpenAPI openAPI; @Override public String openApi() { return Json.pretty(openAPI); } @Override public void afterPropertiesSet() { List\u0026amp;lt;Package\u0026amp;gt; resources = new ArrayList\u0026amp;lt;\u0026amp;gt;(); Resources.add(this.getClass().getPackage()); // Scan the package of the current class, or scan the packages of other SOFARPC RESTful service interfaces. …","date":-62135596800,"description":"","dir":"projects/sofa-rpc/restful-swagger/","fuzzywordcount":500,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"d068767fe0dd2922eecef69736684be8","permalink":"/en/projects/sofa-rpc/restful-swagger/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/en/projects/sofa-rpc/restful-swagger/","summary":"Since rpc-sofa-boot-starter version 6.0.1, SOFARPC provide the ability to integrate RESTful service with Swagger easily.\nIf you are using rpc-sofa-boot-starter in SOFABoot or Spring Boot environment and you want to enable Swagger support, first, you need add Swagger dependencies in your pom.xml:\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.swagger.core.v3\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;swagger-jaxrs2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.google.guava\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;guava\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;20.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; Then you need add a configuration com.alipay.sofa.rpc.restSwagger=true in application.properties.\nFinally, visit http://localhost:8341/swagger/openapi and you can get all the Swagger OpenAPI information about SOFARPC\u0026rsquo;s RESTful services.","tags":null,"title":"Integrate with Swagger","type":"projects","url":"/en/projects/sofa-rpc/restful-swagger/","wordcount":462},{"author":null,"categories":null,"content":"Jarslink2.0 supports receiving dynamic commands at runtime to manage the Biz package lifecycle. Before starting an Ark package that has introduced the Jarslink2.0 plugin, you can send commands through the telnet connection protocol with port 1234. For example, execute telnet ip 1234 to enter the Jarslink2.0 command interface and type \u0026amp;ldquo;help\u0026amp;rdquo; in the interface to obtain all relevant command manuals. Next we will introduce the syntax of each Jarslink2.0 command.\n  Install the Biz package: The installation command is used to dynamically deploy of applications. Its syntax is install -b $bizFile. You can replace -b with -biz. All Jarslink2.0 commands must contain either a –b or –biz. The \u0026amp;ldquo;install\u0026amp;rdquo; command has only one parameter, the Biz package URI, which can either be the path of a local file or the link to a remote file, for example, install -b file:///Users/qilong.zql/sample-ark-biz.jar.\n  Uninstall the Biz package: The uninstall command is used to close the application. The services released by the application and the resources that it occupied will be destroyed. Command syntax: uninstall -b -n $bizName -v $bizVersion. The command must specify the name and version number of the Biz package by -n and -v, which can be replaced with -name and -version. The name and version number of a Biz package are determined at the time of packaging. For detailed information, see Application Packaging.\n  Switch the Biz package: The switch command is used for the Biz package hot update to ensure service continuity. Jarslink2.0 allows loading different versions of Biz packages with the same name at runtime. However, only one Biz package can deliver services at one time. To upgrade the loaded Biz package that is delivering services at runtime, execute the installation command to install a later version of the Biz package. After installation, the newer version is inactive because the older version is providing services. Execute the switch command to switch to the newer version without suspending the services that the application is delivering. This is called a hot update. The command syntax is switch -b -n $bizName -v $bizVersion. Parameters are the same as the above.\n  Query the Biz package: The query command is used to query the Biz packages installed in JVM and their status. The command syntax is check -b -n $bizName -v $bizVersion, where the Biz package\u0026amp;rsquo;s name and version number are optional parameters. If you do not specify the name and the version number, information for all Biz packages will be returned. If you only specify the name, information for all versions with the specified name will be returned.\n  ","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-jarslink-jarslink-instruction/","fuzzywordcount":500,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"c7e69fe8035b59c0e191538c8ef3da18","permalink":"/en/projects/sofa-boot/sofa-jarslink-jarslink-instruction/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-boot/sofa-jarslink-jarslink-instruction/","summary":"Jarslink2.0 supports receiving dynamic commands at runtime to manage the Biz package lifecycle. Before starting an Ark package that has introduced the Jarslink2.0 plugin, you can send commands through the telnet connection protocol with port 1234. For example, execute telnet ip 1234 to enter the Jarslink2.0 command interface and type \u0026ldquo;help\u0026rdquo; in the interface to obtain all relevant command manuals. Next we will introduce the syntax of each Jarslink2.0 command.","tags":null,"title":"Interactive instruction","type":"projects","url":"/en/projects/sofa-boot/sofa-jarslink-jarslink-instruction/","wordcount":424},{"author":null,"categories":null,"content":"Introduction Jarslink2.0 is a functional SOFABoot plugin developed based on SOFAArk. It manages the merged deployment of multiple applications on top of the SOFAArk container, with the following features:\n It supports runtime dynamic installation and uninstallation of applications. It supports runtime application hot replacement capability to ensure service continuity. For cross-application communication, it supports the JVM services publish and reference. Cross-application communication can base on RPC framework or internal JVM services. It supports application Health Check.  Background At Ant Financial, it is common to deploy multiple applications on top of the same JVM. Main advantages of this approach are as follows:\n  Merged deployment of unrelated applications: Some applications have no service dependencies on each other when they are deployed independently and their volume of business is small, so it would be a waste of resources to start the Java Virtual Machine just for them. Merged deployment of these applications can save resources.\n  Merged deployment of related applications: Some applications have service dependencies between them. When deployed independently, RPC calls are used between applications. Despite the high stability of the distributed architecture, there are still delays caused by network jitter. By merged deployment of these applications, JVM internal calls will replace RPC calls, which reduces the call overhead.\n  Not only is there merged deployment between applications, but the near-client package has the same appeal.\nThe near-client package is a three-party component that provides a series of public services, normally introduced by the application as a dependency. This development mode is likely to cause two problems:\n  The three-party dependency that is introduced by the near-client package conflicts with the dependency of the application itself, so an isolated deployment is expected.\n  Since the near-client package is introduced by the application as a dependency, any upgrade of the near-client package will require upgrade of the application as well. However, as a common functional component, many business applications rely on the near-client package as a dependency, which entails a huge amount of transformation. Consequently, a dynamic upgrade of the near-client package is expected.\n  In addition to merged deployment, many Ant Financial business scenarios require hot deployment of modules, that is, when the application is running, a specific module needs to be dynamically replaced without affecting the normal running of other modules.\nJarslink2.0 is designed to solve such problems. It is an Ark Plugin developed based on SOFAArk and used to manage the merged deployment of multiple applications. Before getting to know Jarslink2.0, you need to understand the SOFAArk framework. For detailed information of SOFAArk, visit the link.\nPrinciple Jarslink2.0 is an Ark Plugin developed based on SOFAArk. Assuming that you have …","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-jarslink-jarslink-readme/","fuzzywordcount":700,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"48a4bc23f10f1ecca3960aecfd0a77d5","permalink":"/en/projects/sofa-boot/sofa-jarslink-jarslink-readme/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/en/projects/sofa-boot/sofa-jarslink-jarslink-readme/","summary":"Introduction Jarslink2.0 is a functional SOFABoot plugin developed based on SOFAArk. It manages the merged deployment of multiple applications on top of the SOFAArk container, with the following features:\n It supports runtime dynamic installation and uninstallation of applications. It supports runtime application hot replacement capability to ensure service continuity. For cross-application communication, it supports the JVM services publish and reference. Cross-application communication can base on RPC framework or internal JVM services.","tags":null,"title":"Introduction to Jarslink","type":"projects","url":"/en/projects/sofa-boot/sofa-jarslink-jarslink-readme/","wordcount":647},{"author":null,"categories":null,"content":"Pilot introduction The SOFAMesh project forked the Istio project to enhance Pilot\u0026amp;rsquo;s capabilities. Currently, the ongoing enhancements are focused on the following three areas:\n Support ZooKeeper as a registry center, and support SOFA, DUBBO and other microservice frameworks using ZooKeeper as a registry center. Support the common protocol framework. Use a common protocol, and support multiple protocols simultaneously based on Kubernetes DNS. Add register agent to support the container models of SOFA, Dubbo and HSF. Namely, a single application can register multiple service instances.  ","date":-62135596800,"description":"","dir":"projects/sofa-mesh/pilot-readme/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"7b098e394986596d8fb01e1fe2120829","permalink":"/en/projects/sofa-mesh/pilot-readme/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-mesh/pilot-readme/","summary":"Pilot introduction The SOFAMesh project forked the Istio project to enhance Pilot\u0026rsquo;s capabilities. Currently, the ongoing enhancements are focused on the following three areas:\n Support ZooKeeper as a registry center, and support SOFA, DUBBO and other microservice frameworks using ZooKeeper as a registry center. Support the common protocol framework. Use a common protocol, and support multiple protocols simultaneously based on Kubernetes DNS. Add register agent to support the container models of SOFA, Dubbo and HSF.","tags":null,"title":"Introduction to Pilot","type":"projects","url":"/en/projects/sofa-mesh/pilot-readme/","wordcount":84},{"author":null,"categories":null,"content":"﻿## Product description SOFAArk is a light-weight，java based classloader isolation framework open sourced by Ant Financial. Based on Fat Jar technology, the container can pack simple single-module Java applications or Spring Boot applications into a self-contained executable Fat Jar, known as an Ark package. When the java -jar command is used to start an Ark package embedded with the SOFAArk class isolation container, the SOFAArk container will start, and it then starts each Ark plugin and application.\nBackground In Java world, dependency is always a problem, and can cause various errors, such as LinkageError, NoSuchMethodError etc. There are many ways to solve the dependency problems, the Spring Boot\u0026amp;rsquo;s way is using a dependency management to manage all the dependencies, make sure that all the dependencies in the dependency management will not conflict and can work pretty well. This is quite a simple and efficient way, it can cover most scenario, but there is some exceptions.\nFor example, there is a project that need protobuf version 2 and protobuf version 3, and because protobuf version 3 is not compatible with version 2, so the project can not simply upgrade the protobuf to version 3 to solve the problem. There is same problem for hessian version 3 and version 4.\nTo cover those exceptions, we need to introduce a classloader isolation way, make different version of a framework loaded by different classloader. There are many framework that can do classloader isolation, perhaps the most famous one is OSGi, but OSGi classloader schema is too complex, beside classloader isolation, it also has ability to do hot deploy and a lot of other functionalities that we actually don\u0026amp;rsquo;t want.\nSo this is the origin of SOFAArk, it\u0026amp;rsquo;s goal is to use a light-weight classloader isolation mechanism to solve the problem that Spring Boot did not solve. And just a remind that SOFAArk is not bind to Spring Boot, actually it is a more general classloader isolation framework that can be used with any other frameworks too.\nHow SOFAArk Works There are three concepts in SOFAArk: Ark Container, Ark-Plugin and Ark-Biz; they are organized as what the following graph shows:\nFirst of all, we explain what roles these concepts play;\n  Ark Container: It\u0026amp;rsquo;s the runtime manager of total framework; it will startup in the first place, then it resolves Ark Plugin and Ark Biz in classpath and deploys them.\n  Ark Plugin: A fat jar packaged by sofa-ark-plugin-maven-plugin, generally it would bring with a class-index configuration which describes what class would be exported and imported. Ark Plugin can resolve classes from each other.\n  Ark Biz: A fat jar packaged by sofa-ark-maven-plugin, it mainly contains all staff what a project need in runtime. Ark Biz can resolve classes form Ark Plugin, but not inverse.\n  In runtime, Ark Container would automatically recognize Ark-Plugin and Ark-Biz in classpath, and load them with the independent classloader. According to …","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-readme/","fuzzywordcount":700,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"cdb6729fc7a63954b7559c8ea319f550","permalink":"/en/projects/sofa-boot/sofa-ark-readme/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/en/projects/sofa-boot/sofa-ark-readme/","summary":"﻿## Product description SOFAArk is a light-weight，java based classloader isolation framework open sourced by Ant Financial. Based on Fat Jar technology, the container can pack simple single-module Java applications or Spring Boot applications into a self-contained executable Fat Jar, known as an Ark package. When the java -jar command is used to start an Ark package embedded with the SOFAArk class isolation container, the SOFAArk container will start, and it then starts each Ark plugin and application.","tags":null,"title":"Introduction to SOFAArk","type":"projects","url":"/en/projects/sofa-boot/sofa-ark-readme/","wordcount":642},{"author":null,"categories":null,"content":"   MOSN, the short name of Modular Observable Smart Network, is a powerful proxy acting as Service Mesh\u0026amp;rsquo;s data plane like Envoy but written in Go. MOSN supports Envoy and Istio\u0026amp;rsquo;s APIs and can be integrated with Istio, so we use MOSN instead of Envoy in SOFAMesh. The initial version of MOSN was jointly contributed by Ant Financial and UC Business Unit of Alibaba, and we look forward to the community to participate in the follow-up development and build an open source excellent project together.\nCore competence  Integrated with Istio  Integrated with Istio 1.0 and V4 APIs to run based on full dynamic resource configuration   Core forwarding  Self-contained Web server Support TCP proxy Support TProxy mode   Multi-protocol  Support HTTP/1.1 and HTTP/2 Support SOFARPC Support Dubbo protocol (under development)   Core routing  Support Virtual Host routing Support Headers/URL/Prefix routing Support Host Metadata-based Subset routing Support retry   Backend Management and load balancing  Support connection pool Support throttling Support active backend health check Support load balancing strategies, such as Random and RR Support Host Metadata-based Subset load balancing strategy   Observability  Observe network data Observing protocol data   TLS  Support HTTP/1.1 on TLS Support HTTP/2.0 on TLS Support SOFARPC on TLS   Process management + Support smooth reload + Support smooth upgrade Extension capability + Support custom private protocols + Support adding custom extensions in protocol at the TCP IO layer  ","date":-62135596800,"description":"","dir":"projects/sofa-mesh/sofa-mosn-readme/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"11219bb3b9689ec5f328b8281bd62a95","permalink":"/en/projects/sofa-mesh/sofa-mosn-readme/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-mesh/sofa-mosn-readme/","summary":"MOSN, the short name of Modular Observable Smart Network, is a powerful proxy acting as Service Mesh\u0026rsquo;s data plane like Envoy but written in Go. MOSN supports Envoy and Istio\u0026rsquo;s APIs and can be integrated with Istio, so we use MOSN instead of Envoy in SOFAMesh. The initial version of MOSN was jointly contributed by Ant Financial and UC Business Unit of Alibaba, and we look forward to the community to participate in the follow-up development and build an open source excellent project together.","tags":null,"title":"Introduction to SOFAMosn","type":"projects","url":"/en/projects/sofa-mesh/sofa-mosn-readme/","wordcount":223},{"author":null,"categories":null,"content":"1. Create a Maven project and import the dependency \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;registry-client-all\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${registry.client.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 2. Create the SOFARegistry client instance The key code for creating the SOFARegistry client instance is as follows:\nRegistryClientConfig config = DefaultRegistryClientConfigBuilder.start().setRegistryEndpoint(\u0026amp;#34;127.0.0.1\u0026amp;#34;).setRegistryEndpointPort(9603).build(); DefaultRegistryClient registryClient = new DefaultRegistryClient(config); registryClient.init(); Properties related to SOFARegistry are specified by the DefaultRegistryClientConfigBuilder class, which provides the following key properties:\npublic class DefaultRegistryClientConfigBuilder { private String instanceId; private String zone = DEFAULT_ZONE; private String registryEndpoint; private int registryEndpointPort = 9603; private String dataCenter = DEFAULT_DATA_CENTER; private String appName; private int connectTimeout = 3000; private int socketTimeout = 3000; private int invokeTimeout = 1000; private int recheckInterval = 500; private int observerThreadCoreSize = 5; private int observerThreadMaxSize = 10; private int observerThreadQueueLength = 1000; private int syncConfigRetryInterval = 30000; }    Property Type Description     instanceId String The ID of the instance. Default value: DEFAULT_INSTANCE_ID. The same instance ID must be used for data publishing and subscription. The unique data identifier consists of dataId+group+instanceId.   zone String The zone where the instance is located. Default value: DEFAULT_ZONE.   registryEndpoint String The endpoint of any session node of the servers.   registryEndpointPort Integer The session.server.httpServerPort configured for a session node. Default value: 9603.   dataCenter String The data center of SOFARegistry. Default value: DefaultDataCenter.   appName String The name of the app that accesses SOFARegistry.   connectTimeout Integer Specifies the timeout for establishing a connection with a server. Default value: 3000 ms.   socketTimeout Integer Specifies the timeout for accessing the servers\u0026#39; REST API. Default value: 3000 ms.   invokeTimeout Integer Specifies the timeout for calling services on the servers. Default value: 1000 ms.   recheckInterval Integer Specifies the interval for checking the task queue. Default value: 500 ms.   observerThreadCoreSize Integer Specifies the number of core threads in the thread pool that process data pushed from the servers. Default value: 5.   observerThreadMaxSize Integer Specifies the maximum number of threads in the thread pool that process data pushed from the servers. Default value: 10.   observerThreadQueueLength Integer Specifies the maximum thread queue length of the thread pool that processes data pushed from the servers. Default value: 1000.   syncConfigRetryInterval Integer Specifies the retry interval to synchronize the registry …","date":-62135596800,"description":"","dir":"projects/sofa-registry/java-sdk/","fuzzywordcount":900,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"32cff5cc5d89ffa85b12c207a1c0c6f3","permalink":"/en/projects/sofa-registry/java-sdk/","publishdate":"0001-01-01T00:00:00Z","readingtime":5,"relpermalink":"/en/projects/sofa-registry/java-sdk/","summary":"1. Create a Maven project and import the dependency \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alipay.sofa\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;registry-client-all\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${registry.client.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2. Create the SOFARegistry client instance The key code for creating the SOFARegistry client instance is as follows:\nRegistryClientConfig config = DefaultRegistryClientConfigBuilder.start().setRegistryEndpoint(\u0026#34;127.0.0.1\u0026#34;).setRegistryEndpointPort(9603).build(); DefaultRegistryClient registryClient = new DefaultRegistryClient(config); registryClient.init(); Properties related to SOFARegistry are specified by the DefaultRegistryClientConfigBuilder class, which provides the following key properties:\npublic class DefaultRegistryClientConfigBuilder { private String instanceId; private String zone = DEFAULT_ZONE; private String registryEndpoint; private int registryEndpointPort = 9603; private String dataCenter = DEFAULT_DATA_CENTER; private String appName; private int connectTimeout = 3000; private int socketTimeout = 3000; private int invokeTimeout = 1000; private int recheckInterval = 500; private int observerThreadCoreSize = 5; private int observerThreadMaxSize = 10; private int observerThreadQueueLength = 1000; private int syncConfigRetryInterval = 30000; }    Property Type Description     instanceId String The ID of the instance.","tags":null,"title":"Java SDK","type":"projects","url":"/en/projects/sofa-registry/java-sdk/","wordcount":890},{"author":null,"categories":null,"content":"1. Maven 坐标 \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;registry-client-all\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${registry.client.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 2. 创建 SOFARegistry 客户端实例 构建 SOFARegistry 客户端实例的关键代码如下：\nRegistryClientConfig config = DefaultRegistryClientConfigBuilder.start().setRegistryEndpoint(\u0026amp;#34;127.0.0.1\u0026amp;#34;).setRegistryEndpointPort(9603).build(); DefaultRegistryClient registryClient = new DefaultRegistryClient(config); registryClient.init(); 其中注册中心相关的属性通过 DefaultRegistryClientConfigBuilder 构建指定，该类包含以下关键属性：\npublic class DefaultRegistryClientConfigBuilder { private String instanceId; private String zone = DEFAULT_ZONE; private String registryEndpoint; private int registryEndpointPort = 9603; private String dataCenter = DEFAULT_DATA_CENTER; private String appName; private int connectTimeout = 3000; private int socketTimeout = 3000; private int invokeTimeout = 1000; private int recheckInterval = 500; private int observerThreadCoreSize = 5; private int observerThreadMaxSize = 10; private int observerThreadQueueLength = 1000; private int syncConfigRetryInterval = 30000; }    属性名 属性类型 描述     instanceId String 实例ID，发布订阅时需要使用相同值，数据唯一标识由dataId+group+instanceId组成，默认值 DEFAULT_INSTANCE_ID。   zone String 单元化所属 zone，默认值 DEFAULT_ZONE。   registryEndpoint String 服务端任一 Session 节点地址。   registryEndpointPort int Session 节点配置的 session.server.httpServerPort 端口值，默认值 9603。   dataCenter String 数据中心，默认值 DefaultDataCenter。   appName String 应用名。   connectTimeout int 与服务端建立连接超时时间，默认值 3000ms。   socketTimeout int 访问服务端 REST 接口超时时间，默认值 3000ms。   invokeTimeout int 调用服务端服务超时时间，默认值 1000ms。   recheckInterval int 检测任务队列间隔时间，默认值 500ms。   observerThreadCoreSize int 处理服务端推送数据线程池核心线程大小，默认值 5。   observerThreadMaxSize int 处理服务端推送数据线程池最大线程大小，默认值 10。   observerThreadQueueLength int 处理服务端推送数据线程池队列大小，默认值 1000。   syncConfigRetryInterval int 同步服务端列表间隔时间，默认值 30000ms。    3. 发布数据 发布数据的关键代码如下：\n// 构造发布者注册表 PublisherRegistration registration = new PublisherRegistration(\u0026amp;#34;com.alipay.test.demo.service:1.0@DEFAULT\u0026amp;#34;); registration.setGroup(\u0026amp;#34;TEST_GROUP\u0026amp;#34;); registration.setAppName(\u0026amp;#34;TEST_APP\u0026amp;#34;); // 将注册表注册进客户端并发布数据 Publisher publisher = registryClient.register(registration, \u0026amp;#34;10.10.1.1:12200?xx=yy\u0026amp;#34;); // 如需覆盖上次发布的数据可以使用发布者模型重新发布数据 publisher.republish(\u0026amp;#34;10.10.1.1:12200?xx=zz\u0026amp;#34;); 发布数据的关键是构造 PublisherRegistration，该类包含三个属性：\n   属性名 属性类型 描述     dataId String 数据ID，发布订阅时需要使用相同值，数据唯一标识由 dataId + group + instanceId 组成。   group String 数据分组，发布订阅时需要使用相同值，数据唯一标识由 dataId + group + instanceId 组成，默认值 DEFAULT_GROUP。   appName String 应用 appName。    4. 订阅数据 订阅数据的关键代码如下：\n// 创建 SubscriberDataObserver SubscriberDataObserver subscriberDataObserver = new SubscriberDataObserver() { @Override public void handleData(String dataId, UserData userData) { System.out.println(\u0026amp;#34;receive data success, dataId: \u0026amp;#34; + dataId + \u0026amp;#34;, data: \u0026amp;#34; + userData); } }; // 构造订阅者注册表，设置订阅维度，ScopeEnum 共有三种级别 zone, dataCenter, global String dataId = …","date":-62135596800,"description":"","dir":"projects/sofa-registry/java-sdk/","fuzzywordcount":1400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"32cff5cc5d89ffa85b12c207a1c0c6f3","permalink":"/projects/sofa-registry/java-sdk/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/sofa-registry/java-sdk/","summary":"1. Maven 坐标 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alipay.sofa\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;registry-client-all\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${registry.client.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2. 创建 SOFARegistry 客户端实例 构建 SOFARegistry 客户端实例的关键代码如下： RegistryClientConfig config = DefaultRegistryClientConfigBuilder.start().setRegistryEndpoint(\u0026#34;127.0.0.1\u0026#34;).setRegistryEndpointPort(9603).build(); DefaultRegistryClient registryClient = new DefaultRegistryClient(config); registryClient.init(); 其中注册中心相关的属性通过 DefaultRegistryClientConfigBuilder 构建指定，该类包含以下关","tags":null,"title":"Java SDK","type":"projects","url":"/projects/sofa-registry/java-sdk/","wordcount":1368},{"author":null,"categories":null,"content":"In addition to hundreds of unit tests and some chaos tests, SOFAJRaft also uses a distributed verification and fault injection testing framework Jepsen to simulate many cases, and has passed all these tests:\n Randomized partitioning with two partitions: a big one and a small one Randomly adding and removing nodes Randomly stopping and starting nodes Randomly kill -9 and starting nodes Randomly dividing a cluster into two groups, with one node connection the two to simulate network partitioning Randomly dividing a cluster into different majority groups  sofa-jraft-jepsen project address\n","date":-62135596800,"description":"","dir":"projects/sofa-jraft/jepson-test/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"c60bc5083fdf888f6eef5b344b1ad157","permalink":"/en/projects/sofa-jraft/jepson-test/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-jraft/jepson-test/","summary":"In addition to hundreds of unit tests and some chaos tests, SOFAJRaft also uses a distributed verification and fault injection testing framework Jepsen to simulate many cases, and has passed all these tests:\n Randomized partitioning with two partitions: a big one and a small one Randomly adding and removing nodes Randomly stopping and starting nodes Randomly kill -9 and starting nodes Randomly dividing a cluster into two groups, with one node connection the two to simulate network partitioning Randomly dividing a cluster into different majority groups  sofa-jraft-jepsen project address","tags":null,"title":"Jepsen tests","type":"projects","url":"/en/projects/sofa-jraft/jepson-test/","wordcount":89},{"author":null,"categories":null,"content":"除了几百个单元测试以及部分 chaos 测试之外, SOFAJRaft 还使用 jepsen 这个分布式验证和故障注入测试框架模拟了很多种情况，都已验证通过：\n 随机分区，一大一小两个网络分区 随机增加和移除节点 随机停止和启动节点 随机 kill -9 和启动节点 随机划分为两组，互通一个中间节点，模拟分区情况 随机划分为不同的 majority 分组  sofa-jraft-jepsen 项目地址\n","date":-62135596800,"description":"","dir":"projects/sofa-jraft/jepson-test/","fuzzywordcount":200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"c60bc5083fdf888f6eef5b344b1ad157","permalink":"/projects/sofa-jraft/jepson-test/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-jraft/jepson-test/","summary":"除了几百个单元测试以及部分 chaos 测试之外, SOFAJRaft 还使用 jepsen 这个分布式验证和故障注入测试框架模拟了很多种情况，都已验证通过： 随机分区，一大一小两个网络分","tags":null,"title":"Jepsen 验证","type":"projects","url":"/projects/sofa-jraft/jepson-test/","wordcount":137},{"author":null,"categories":null,"content":"Introduction to RheaKV RheaKV is a lightweight, distributed, and embedded KV storage library, which is included in the JRaft project as a submodule.\nFeatures\n Embedded: RheaKV is embedded in applications in the form of Jar files. Strong consistency: RheaKV ensures data reliability and consistency based on the multi-raft distributed consensus protocol. Self-driven (not fully implemented at present): RheaKV supports automatic diagnosis, optimization, decision making, and recovery. Monitorable: RheaKV automatically reports meta information and state information by node to the PD. Basic APIs: get, put, and delete; cross-region APIs: scan, batch put, and distributed lock.  Architecture design Terms and definitions  PD: The global central master node that is responsible for scheduling the entire cluster. A PD server can manage multiple clusters, with each of them isolated by clusterId. The PD server requires separate deployment. Actually, many scenarios do not need automatic cluster management, and RheaKV does not support PD. Store: A physical storage node within a cluster. A store may contain one or more regions. Region: The minimal KV data unit. Each region can be understood as a database partition or database shard, and has a left closed and right open interval [startKey, endKey).  Storage design  The storage layer adopts a pluggable design and supports both MemoryDB and RocksDB currently:  MemoryDB is implemented based on ConcurrentSkipListMap and provides better performance. However, its independent storage capacity is restricted by the memory. RocksDB is suitable for scenarios with large data volumes, because its storage capacity is only restricted by the disk.   Strong data consistency is ensured. RheaKV synchronizes data to other replicas with the help of JRaft, and each data change is recorded as a Raft log entry. The log replication feature of Raft ensures all data is securely and reliably synchronized to all nodes within the same Raft group.  Scenarios  Lightweight state/meta information storage and cluster synchronization Distributed lock service  API description Generally, RheaKV APIs are divided into two types: synchronous APIs and asynchronous APIs. Methods whose names start with letter b (block) are synchronous blocking APIs, and the rest are asynchronous APIs. All asynchronous APIs return the same CompletableFuture parameter. The read method may contain another important parameter, that is readOnlySafe. When this parameter is set to true, linearizable read is supported. Read methods that do not contain this parameter provide linearizable read by default.\nget CompletableFuture\u0026amp;lt;byte[]\u0026amp;gt; get(final byte[] key); CompletableFuture\u0026amp;lt;byte[]\u0026amp;gt; get(final String key); CompletableFuture\u0026amp;lt;byte[]\u0026amp;gt; get(final byte[] key, final boolean readOnlySafe); CompletableFuture\u0026amp;lt;byte[]\u0026amp;gt; get(final String key, final boolean readOnlySafe); byte[] bGet(final byte[] key); byte[] bGet(final String key); byte[] bGet(final byte[] key, final boolean …","date":-62135596800,"description":"","dir":"projects/sofa-jraft/jraft-rheakv-user-guide/","fuzzywordcount":4100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"e6fa7125455982961214dfe82245be4d","permalink":"/en/projects/sofa-jraft/jraft-rheakv-user-guide/","publishdate":"0001-01-01T00:00:00Z","readingtime":20,"relpermalink":"/en/projects/sofa-jraft/jraft-rheakv-user-guide/","summary":"Introduction to RheaKV RheaKV is a lightweight, distributed, and embedded KV storage library, which is included in the JRaft project as a submodule.\nFeatures\n Embedded: RheaKV is embedded in applications in the form of Jar files. Strong consistency: RheaKV ensures data reliability and consistency based on the multi-raft distributed consensus protocol. Self-driven (not fully implemented at present): RheaKV supports automatic diagnosis, optimization, decision making, and recovery. Monitorable: RheaKV automatically reports meta information and state information by node to the PD.","tags":null,"title":"JRaft RheaKV user guide","type":"projects","url":"/en/projects/sofa-jraft/jraft-rheakv-user-guide/","wordcount":4088},{"author":null,"categories":null,"content":"RheaKV 是一个轻量级的分布式的嵌入式的 KV 存储 lib， rheaKV 包含在 jraft 项目中，是 jraft 的一个子模块。\n定位与特性\n 嵌入式: jar 包方式嵌入到应用中 强一致性: 基于 multi-raft 分布式一致性协议保证数据可靠性和一致性 自驱动 （目前未完全实现）: 自诊断, 自优化, 自决策, 自恢复 可监控: 基于节点自动上报到PD的元信息和状态信息 基本API: get/put/delete 和跨分区 scan/batch put, distributed lock 等等  架构设计 功能名词  PD: 全局的中心总控节点，负责整个集群的调度，一个 PD server 可以管理多个集群，集群之间基于 clusterId 隔离；PD server 需要单独部署，当然，很多场景其实并不需要自管理，rheaKV 也支持不启用 PD Store: 集群中的一个物理存储节点，一个 store 包含一个或多个 region Region: 最小的 KV 数据单元，可理解为一个数据分区或者分片，每个 region 都有一个左闭右开的区间 [startKey, endKey)  存储设计  存储层为可插拔设计， 目前支持 MemoryDB 和 RocksDB 两种实现：  MemoryDB 基于 ConcurrentSkipListMap 实现，有更好的性能，但是单机存储容量受内存限制 RocksDB 在存储容量上只受磁盘限制，适合更大数据量的场景   数据强一致性， 依靠 jraft 来同步数据到其他副本, 每个数据变更都会落地为一条 raft 日志, 通过 raft 的日志复制功能, 将数据安全可靠地同步到同 group 的全部节点中  使用场景  轻量级的状态/元信息存储以及集群同步 分布式锁服务  API 说明 整体上 rheaKV apis 分为异步和同步两类， 其中以 b （block）开头的方法均为同步阻塞方法， 其他为异步方法，异步方法均返回一个 CompletableFuture，对于 read method， 还有一个重要参数 readOnlySafe，为 true 时表示提供线性一致读， 不包含该参数的 read method 均为默认提供线性一致读\nget CompletableFuture\u0026amp;lt;byte[]\u0026amp;gt; get(final byte[] key); CompletableFuture\u0026amp;lt;byte[]\u0026amp;gt; get(final String key); CompletableFuture\u0026amp;lt;byte[]\u0026amp;gt; get(final byte[] key, final boolean readOnlySafe); CompletableFuture\u0026amp;lt;byte[]\u0026amp;gt; get(final String key, final boolean readOnlySafe); byte[] bGet(final byte[] key); byte[] bGet(final String key); byte[] bGet(final byte[] key, final boolean readOnlySafe); byte[] bGet(final String key, final boolean readOnlySafe);  String 类型入参，rheaKV 内部提供了更高效的 Utf8String encoder/decoder， 业务 key 为 String 时， 推荐的做法是直接使用 String 参数的接口 不需要线性一致读语义的场景可以将 readOnlySafe 设置为 false， 负载均衡器会优先选择本地调用，本地不能提供服务则轮询选择一台远程机器发起读请求  multiGet CompletableFuture\u0026amp;lt;Map\u0026amp;lt;ByteArray, byte[]\u0026amp;gt;\u0026amp;gt; multiGet(final List\u0026amp;lt;byte[]\u0026amp;gt; keys); CompletableFuture\u0026amp;lt;Map\u0026amp;lt;ByteArray, byte[]\u0026amp;gt;\u0026amp;gt; multiGet(final List\u0026amp;lt;byte[]\u0026amp;gt; keys, final boolean readOnlySafe); Map\u0026amp;lt;ByteArray, byte[]\u0026amp;gt; bMultiGet(final List\u0026amp;lt;byte[]\u0026amp;gt; keys); Map\u0026amp;lt;ByteArray, byte[]\u0026amp;gt; bMultiGet(final List\u0026amp;lt;byte[]\u0026amp;gt; keys, final boolean readOnlySafe);  multiGet 支持跨分区查询，rheaKV 内部会自动计算每个 key 的所属分区（region）并行发起调用， 最后合并查询结果 为了可以将 byte[] 放进 HashMap，这里曲线救国，返回值中 Map 的 key 为 ByteArray 对象，是对 byte[] 的一层包装，实现了 byte[] 的 hashCode  scan \u0026amp;amp; iterator CompletableFuture\u0026amp;lt;List\u0026amp;lt;KVEntry\u0026amp;gt;\u0026amp;gt; scan(final byte[] startKey, final byte[] endKey); CompletableFuture\u0026amp;lt;List\u0026amp;lt;KVEntry\u0026amp;gt;\u0026amp;gt; scan(final String startKey, final String endKey); CompletableFuture\u0026amp;lt;List\u0026amp;lt;KVEntry\u0026amp;gt;\u0026amp;gt; scan(final byte[] startKey, final byte[] endKey, final boolean readOnlySafe); CompletableFuture\u0026amp;lt;List\u0026amp;lt;KVEntry\u0026amp;gt;\u0026amp;gt; scan(final String startKey, final String endKey, final boolean readOnlySafe); List\u0026amp;lt;KVEntry\u0026amp;gt; bScan(final byte[] startKey, final byte[] endKey); List\u0026amp;lt;KVEntry\u0026amp;gt; bScan(final String startKey, final String endKey); List\u0026amp;lt;KVEntry\u0026amp;gt; bScan(final byte[] startKey, final byte[] endKey, final boolean readOnlySafe); List\u0026amp;lt;KVEntry\u0026amp;gt; bScan(final String startKey, final String endKey, final boolean readOnlySafe); RheaIterator\u0026amp;lt;KVEntry\u0026amp;gt; …","date":-62135596800,"description":"","dir":"projects/sofa-jraft/jraft-rheakv-user-guide/","fuzzywordcount":6500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"e6fa7125455982961214dfe82245be4d","permalink":"/projects/sofa-jraft/jraft-rheakv-user-guide/","publishdate":"0001-01-01T00:00:00Z","readingtime":13,"relpermalink":"/projects/sofa-jraft/jraft-rheakv-user-guide/","summary":"RheaKV 是一个轻量级的分布式的嵌入式的 KV 存储 lib， rheaKV 包含在 jraft 项目中，是 jraft 的一个子模块。 定位与特性 嵌入式: jar 包方式嵌入到应用中 强一致性: 基于 multi-raft 分布","tags":null,"title":"JRaft RheaKV 用户指南","type":"projects","url":"/projects/sofa-jraft/jraft-rheakv-user-guide/","wordcount":6402},{"author":null,"categories":null,"content":"0. Basic concepts  Every request submitted by log index to a Raft group is serialized into a log entry. Each log entry has an ID, which monotonically increases within the Raft group, and the log entries are replicated to every Raft node in the group. Term is a long-type number that monotonically increases within the Raft group. You can simply take it as the number of votes. The term of an elected leader is called the leader term. Before this leader steps down, log entries submitted during this period have the same term.  1. Configuration and supporting classes This topic mainly describes the configuration and utility methods and classes. The core objects are:\n Endpoint, which refers to a service address PeerId, which refers to ID of a Raft node Configuration, which refers to the configuration of a Raft group, or a node list in other words.  1.1 Endpoint Endpoint refers to a service address, including the IP address and the port number. Raft nodes must not be started on the IPv4 address 0.0.0.0. The startup IP address must be clearly specified Create a address, and bind it to port 8080 of the local host, as shown in the following example:\nEndpoint addr = new Endpoint(\u0026amp;#34;localhost\u0026amp;#34;, 8080); String s = addr.toString(); // The result is localhost:8080  PeerId peer = new PeerId(); boolean success = peer.parse(s); // Specifies whether parsing the endpoint from a string is supported. The result is true. 1.2 PeerId A PeerId indicates a participant (leader, follower, or candidate) of the Raft protocol. It comprises three elements in the format of ip:port:index, where ip is the IP address of the node, port is the port number, and index is the serial number of the same port. Currently, the index is not used, and is always set to 0. This field is reserved to allow starting different Raft nodes from the same port and to differentiate them by index.\nCreate a PeerId and set the index to 0, the IP to localhost, and the port to 8080:\nPeerId peer = new PeerId(\u0026amp;#34;localhost\u0026amp;#34;, 8080); EndPoint addr = peer.getEndpoint(); // Gets the endpoint of a node int index = peer.getIdx(); // Gets the index of a node, which is always set to 0 currently  String s = peer.toString(); // The result is localhost:8080 boolean success = peer.parse(s); // Specifies whether PeerId parsing from a string is supported. The result is true. 1.3 Configuration It refers to the configuration of a Raft group, or a participant list in other words.\nPeerId peer1 = ... PeerId peer2 = ... PeerId peer3 = ... // A Raft group that consists of three nodes Configuration conf = new Configuration(); conf.addPeer(peer1); conf.addPeer(peer2); conf.addPeer(peer3); 1.4 JRaftUtils utility class To enable users conveniently create objects such as Endpoint, PeerId, and Configuration, Jraft provides the JRaftUtils class to help users quickly create the required objects from strings.\nEndpoint addr = JRaftUtils.getEndpoint(\u0026amp;#34;localhost:8080\u0026amp;#34;); PeerId peer = …","date":-62135596800,"description":"","dir":"projects/sofa-jraft/jraft-user-guide/","fuzzywordcount":6700,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"105dfa34c3b20df1f2c23c112730507d","permalink":"/en/projects/sofa-jraft/jraft-user-guide/","publishdate":"0001-01-01T00:00:00Z","readingtime":32,"relpermalink":"/en/projects/sofa-jraft/jraft-user-guide/","summary":"0. Basic concepts  Every request submitted by log index to a Raft group is serialized into a log entry. Each log entry has an ID, which monotonically increases within the Raft group, and the log entries are replicated to every Raft node in the group. Term is a long-type number that monotonically increases within the Raft group. You can simply take it as the number of votes. The term of an elected leader is called the leader term.","tags":null,"title":"JRaft user guide","type":"projects","url":"/en/projects/sofa-jraft/jraft-user-guide/","wordcount":6632},{"author":null,"categories":null,"content":"1. 基本概念说明  log index 提交到 raft group 中的任务都将序列化为一条日志存储下来，每条日志一个编号，在整个 raft group 内单调递增并复制到每个 raft 节点。 term 在整个 raft group 中单调递增的一个 long 数字，可以简单地认为表示一轮投票的编号，成功选举出来的 leader 对应的 term 称为 leader term，在这个 leader 没有发生变更的阶段内提交的日志都将拥有相同的 term 编号。  2. 配置和辅助类 本节主要介绍 jraft 的配置和辅助工具相关接口和类。核心包括：\n Endpoint 表示一个服务地址。 PeerId 表示一个 raft 参与节点。 Configuration 表示一个 raft group 配置，也就是节点列表。  2.1 地址 Endpoint Endpoint 表示一个服务地址，包括 IP 和端口， raft 节点不允许启动在 0.0.0.0 所有的 IPv4 上，需要明确指定启动的 IP 创建一个地址，绑定在 localhost 的 8080 端口上，如下例：\nEndpoint addr = new Endpoint(\u0026amp;#34;localhost\u0026amp;#34;, 8080); String s = addr.toString(); // 结果为 localhost:8080  PeerId peer = new PeerId(); boolean success = peer.parse(s); // 可以从字符串解析出地址，结果为 true 2.2 节点 PeerId PeerId 表示一个 raft 协议的参与者（leader/follower/candidate etc.)， 它由三元素组成： ip:port:index， IP 就是节点的 IP， port 就是端口， index 表示同一个端口的序列号，目前没有用到，总被认为是 0。预留此字段是为了支持同一个端口启动不同的 raft 节点，通过 index 区分。\n创建一个 PeerId, index 指定为 0， ip 和端口分别是 localhost 和 8080:\nPeerId peer = new PeerId(\u0026amp;#34;localhost\u0026amp;#34;, 8080); EndPoint addr = peer.getEndpoint(); // 获取节点地址 int index = peer.getIdx(); // 获取节点序号，目前一直为 0  String s = peer.toString(); // 结果为 localhost:8080 boolean success = peer.parse(s); // 可以从字符串解析出 PeerId，结果为 true 2.3 配置 Configuration Configuration 表示一个 raft group 的配置，也就是参与者列表：\nPeerId peer1 = ... PeerId peer2 = ... PeerId peer3 = ... // 由 3 个节点组成的 raft group Configuration conf = new Configuration(); conf.addPeer(peer1); conf.addPeer(peer2); conf.addPeer(peer3); 2.4 工具类 JRaftUtils 为了方便创建 Endpoint/PeerId/Configuration 等对象， jraft 提供了 JRaftUtils 来快捷地从字符串创建出所需要的对象：\nEndpoint addr = JRaftUtils.getEndpoint(\u0026amp;#34;localhost:8080\u0026amp;#34;); PeerId peer = JRaftUtils.getPeerId(\u0026amp;#34;localhost:8080\u0026amp;#34;); // 三个节点组成的 raft group 配置，注意节点之间用逗号隔开 Configuration conf = JRaftUtils.getConfiguration(\u0026amp;#34;localhost:8081,localhost:8082,localhost:8083\u0026amp;#34;); 2.5 回调 Closure 和状态 Status Closure 就是一个简单的 callback 接口， jraft 提供的大部分方法都是异步的回调模式，结果通过此接口通知：\npublic interface Closure { /** * Called when task is done. * * @param status the task status. */ void run(Status status); } 结果通过 Status 告知，Status#isOk() 告诉你成功还是失败，错误码和错误信息可以通过另外两个方法获取：\nboolean success= status.isOk(); RaftError error = status.getRaftError(); // 错误码，RaftError 是一个枚举类 String errMsg = status.getErrorMsg(); // 获取错误详情 Status 提供了一些方法来方便地创建：\n// 创建一个成功的状态 Status ok = Status.OK(); // 创建一个失败的错误，错误信息支持字符串模板 String filePath = \u0026amp;#34;/tmp/test\u0026amp;#34;; Status status = new Status(RaftError.EIO, \u0026amp;#34;Fail to read file from %s\u0026amp;#34;, filePath); 2.6 任务 Task Task 是用户使用 jraft 最核心的类之一，用于向一个 raft 复制分组提交一个任务，这个任务提交到 leader，并复制到其他 follower 节点， Task 包括：\n ByteBuffer data 任务的数据，用户应当将要复制的业务数据通过一定序列化方式（比如 java/hessian2) 序列化成一个 ByteBuffer，放到 task 里。 long expectedTerm = -1 任务提交时预期的 leader term，如果不提供(也就是默认值 -1 )，在任务应用到状态机之前不会检查 leader 是否发生了变更，如果提供了（从状态机回调中获取，参见下文），那么在将任务应用到状态机之前，会检查 term 是否匹配，如果不匹配将拒绝该任务。 Closure done 任务的回调，在任务完成的时候通知此对象，无论成功还是失败。这个 closure 将在 StateMachine#onApply(iterator) 方法应用到状态机的时候，可以拿到并调用，一般用于客户端应答的返回。  创建一个简单 Task 实例：\nClosure done = ...; Task task = new Task(); …","date":-62135596800,"description":"","dir":"projects/sofa-jraft/jraft-user-guide/","fuzzywordcount":11400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"105dfa34c3b20df1f2c23c112730507d","permalink":"/projects/sofa-jraft/jraft-user-guide/","publishdate":"0001-01-01T00:00:00Z","readingtime":23,"relpermalink":"/projects/sofa-jraft/jraft-user-guide/","summary":"1. 基本概念说明 log index 提交到 raft group 中的任务都将序列化为一条日志存储下来，每条日志一个编号，在整个 raft group 内单调递增并复制到每个 raft 节点。 term 在整个 raft group 中单","tags":null,"title":"JRaft 用户指南","type":"projects","url":"/projects/sofa-jraft/jraft-user-guide/","wordcount":11301},{"author":null,"categories":null,"content":"SOFABoot 提供三种方式给开发人员发布和引用 JVM 服务\n XML 方式 Annotation 方式 编程 API 方式  XML 方式 服务发布 首先需要定义一个 Bean：\n\u0026amp;lt;bean id=\u0026amp;#34;sampleService\u0026amp;#34; class=\u0026amp;#34;com.alipay.sofa.runtime.test.service.SampleServiceImpl\u0026amp;#34;\u0026amp;gt; 然后通过 SOFA 提供的 Spring 扩展标签来将上面的 Bean 发布成一个 SOFA JVM 服务。\n\u0026amp;lt;sofa:service interface=\u0026amp;#34;com.alipay.sofa.runtime.test.service.SampleService\u0026amp;#34; ref=\u0026amp;#34;sampleService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.jvm/\u0026amp;gt; \u0026amp;lt;/sofa:service\u0026amp;gt; 上面的配置中的 interface 指的是需要发布成服务的接口，ref 指向的是需要发布成 JVM 服务的 Bean，至此，我们就已经完成了一个 JVM 服务的发布。\n服务引用 使用 SOFA 提供的 Spring 扩展标签引用服务:\n\u0026amp;lt;sofa:reference interface=\u0026amp;#34;com.alipay.sofa.runtime.test.service.SampleService\u0026amp;#34; id=\u0026amp;#34;sampleServiceRef\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.jvm/\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt; 上面的配置中的 interface 是服务的接口，需要和发布服务时配置的 interface 一致。id 属性的含义同 Spring BeanId。上面的配置会生成一个 id 为 sampleServiceRef 的 Spring Bean，你可以将 sampleServiceRef 这个 Bean 注入到当前 SOFABoot 模块 Spring 上下文的任意地方。\n service/reference 标签还支持 RPC 服务发布，相关文档: RPC 服务发布与引用\n Annotation 方式  警告\n如果一个服务已经被加上了 @SofaService 的注解，它就不能再用 XML 的方式去发布服务了，选择一种方式发布服务，而不是两种混用。\n 除了通过 XML 方式发布 JVM 服务和引用之外，SOFABoot 还提供了 Annotation 的方式来发布和引用 JVM 服务。通过 Annotation 方式发布 JVM 服务，只需要在实现类上加一个 @SofaService 注解即可，如下：\n@SofaService public class SampleImpl implements SampleInterface { public void test() { } }  提示\n@SofaService 的作用是将一个 Bean 发布成一个 JVM 服务，这意味着虽然你可以不用再写 \u0026amp;lt;sofa:service/\u0026amp;gt; 的配置，但是还是需要事先将 @SofaService 所注解的类配置成一个 Spring Bean。\n 在使用 XML 配置 \u0026amp;lt;sofa:service/\u0026amp;gt; 的时候，我们配置了一个 interface 属性，但是在使用 @SofaService 注解的时候，却没有看到有配置服务接口的地方。这是因为当被 @SofaService 注解的类只有一个接口的时候，框架会直接采用这个接口作为服务的接口。当被 @SofaService 注解的类实现了多个接口时，可以设置 @SofaService 的 interfaceType 字段来指定服务接口，比如下面这样：\n@SofaService(interfaceType=SampleInterface.class) public class SampleImpl implements SampleInterface, Serializable { public void test() { } } 和 @SofaService 对应，Sofa 提供了 @SofaReference 来引用一个 JVM 服务。假设我们需要在一个 Spring Bean 中使用 SampleJvmService 这个 JVM 服务，那么只需要在字段上加上一个 @SofaReference 的注解即可：\npublic class SampleServiceRef { @SofaReference private SampleService sampleService; } 和 @SofaService 类似，我们也没有在 @SofaReference 上指定服务接口，这是因为 @SofaReference 在不指定服务接口的时候，会采用被注解字段的类型作为服务接口，你也可以通过设定 @SofaReference 的 interfaceType 属性来指定：\npublic class SampleServiceRef { @SofaReference(interfaceType=SampleService.class) private SampleService sampleService; } 使用 @SofaService 注解发布服务时，需要在实现类上打上 @SofaService 注解；在 Spring Boot 使用 Bean Method 创建 Bean 时，会导致 @Bean 和 @SofaService 分散在两处，而且无法对同一个实现类使用不同的 unique id。因此自 SOFABoot v2.6.0 及 v3.1.0 版本起，支持 @SofaService 作用在 Bean Method 之上，例如：\n@Configuration public class SampleSofaServiceConfiguration { @Bean(\u0026amp;#34;sampleSofaService\u0026amp;#34;) @SofaService(uniqueId = \u0026amp;#34;service1\u0026amp;#34;) SampleService service() { return new SampleServiceImpl(\u0026amp;#34;\u0026amp;#34;); } } 同样为了方便在 Spring Boot Bean Method 使用注解 @SofaReference 引用服务，自 SOFABoot v2.6.0 及 v3.1.0 版本起，支持在 Bean Method 参数上使用 @SofaReference 注解引用 JVM 服务，例如：\n@Configuration public class MultiSofaReferenceConfiguration { @Bean(\u0026amp;#34;sampleReference\u0026amp;#34;) TestService service(@Value(\u0026amp;#34;$spring.application.name\u0026amp;#34;) …","date":-62135596800,"description":"","dir":"projects/sofa-boot/module-service/","fuzzywordcount":2000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"527472fbe57ce450e4e2b41d878704cb","permalink":"/projects/sofa-boot/module-service/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/projects/sofa-boot/module-service/","summary":"SOFABoot 提供三种方式给开发人员发布和引用 JVM 服务 XML 方式 Annotation 方式 编程 API 方式 XML 方式 服务发布 首先需要定义一个 Bean： \u0026lt;bean id=\u0026#34;sampleService\u0026#34; class=\u0026#34;com.alipay.sofa.runtime.test.service.SampleServiceImpl\u0026#34;\u0026gt; 然后通过 SOFA 提供的 Spring 扩展标签来将上","tags":null,"title":"JVM 服务发布与引用","type":"projects","url":"/projects/sofa-boot/module-service/","wordcount":1926},{"author":null,"categories":null,"content":"In the Interactive Instructions section, we have described the set of instructions that Jarslink2.0 supports. In this section, we will focus on all the possible state transitions behind these instructions in the following diagram of a Biz package being loaded from a static file to the runtime and to being uninstalled.\nThe diagram above basically shows the complete life cycle of a Biz package. Now we will explain the direction of each state transition in the diagram:\n  Label 1: Execute the install instruction, and Jarslink2.0 will resolve the file format. If the format is correct, it is the Biz package file, and the Biz package will be registered and installed.\n  Label 2: When the Biz package is successfully installed, the Biz package\u0026amp;rsquo;s main function is executed, the Spring context is loaded successfully, and passes the health check. If Biz packages with the same name but different versions are detected to be activated, the Biz package state will be set to an inactive state. The JVM services that are published by an inactive Biz package will not be called.\n  Label 3: When the Biz package is successfully installed, the Biz package\u0026amp;rsquo;s main function is executed, the Spring context is loaded successfully, and passes the health check. If Biz packages with the same name but different versions are detected to be activated, the Biz package state will be set as active and can provide services.\n  Label 4: If there are any exceptions or a health check failure, the Biz package state will be set to broken. During the installation, the resources that the Biz package occupies will be quickly released and unregistered, at which point the Biz state will be set to unresolved.\n  Label 5: When running, Jarslink2.0 can load Biz packages with the same name but different versions, but only one Biz package is in the active state and can provide services. Execute the switch instruction, and the two Biz packages\u0026#39; states will be interchanged.\n  Label 6: Execute the uninstallation instruction, the Biz package will be uninstalled, and its occupied resources and published services will be unregistered.\n  ","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-jarslink-jarslink-lifecycle/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"0f166dd5388f3dc7d968bce31d0f6e4f","permalink":"/en/projects/sofa-boot/sofa-jarslink-jarslink-lifecycle/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-boot/sofa-jarslink-jarslink-lifecycle/","summary":"In the Interactive Instructions section, we have described the set of instructions that Jarslink2.0 supports. In this section, we will focus on all the possible state transitions behind these instructions in the following diagram of a Biz package being loaded from a static file to the runtime and to being uninstalled.\nThe diagram above basically shows the complete life cycle of a Biz package. Now we will explain the direction of each state transition in the diagram:","tags":null,"title":"Lifecycle","type":"projects","url":"/en/projects/sofa-boot/sofa-jarslink-jarslink-lifecycle/","wordcount":346},{"author":null,"categories":null,"content":"The link data transparent transmission function allows the applications to store data in the calling context, and then any applications in the entire link can operate the data. This feature is used as follows. Data can be put into the request and response of the link for transparent transmission, and then the applications can get the corresponding data from the link.\nRpcInvokeContext.getContext().putRequestBaggage(\u0026amp;#34;key_request\u0026amp;#34;,\u0026amp;#34;value_request\u0026amp;#34;); RpcInvokeContext.getContext().putResponseBaggage(\u0026amp;#34;key_response\u0026amp;#34;,\u0026amp;#34;value_response\u0026amp;#34;); String requestValue=RpcInvokeContext.getContext().getRequestBaggage(\u0026amp;#34;key_request\u0026amp;#34;); String responseValue=RpcInvokeContext.getContext().getResponseBaggage(\u0026amp;#34;key_response\u0026amp;#34;); Example For example, in the scenario of A -\u0026amp;gt; B -\u0026amp;gt; C, the request arguments set by A are transmitted to B and C. On return, response arguments of C and B are transmitted to A.\nRequester A is set as follows:\n// Set the value of the request transparently before calling RpcInvokeContext context = RpcInvokeContext.getContext(); context.putRequestBaggage(\u0026amp;#34;reqBaggageB\u0026amp;#34;, \u0026amp;#34;a2bbb\u0026amp;#34;); // Call service String result = service.hello(); // Get the result value context.getResponseBaggage(\u0026amp;#34;respBaggageB\u0026amp;#34;); Business code for B is as follows:\npublic String hello() { / / Get the value of the request transparent transmission RpcInvokeContext context = RpcInvokeContext.getContext(); String reqBaggage = context.getRequestBaggage(\u0026amp;#34;reqBaggageB\u0026amp;#34;); //  doSomthing(); // result passes a value transparently  context.putResponseBaggage(\u0026amp;#34;respBaggageB\u0026amp;#34;, \u0026amp;#34;b2aaa\u0026amp;#34;); return result; } If you start the child thread halfway, you need to set the context of the child thread:\nCountDownLatch latch = new CountDownLatch(1); final RpcInvokeContext parentContext = RpcInvokeContext.peekContext(); Thread thread = new Thread(new Runnable(){ public void run(){ Try { RpcInvokeContext.setContext(parentContext); / / Call a remote service xxxService.sayHello(); latch.countDown(); } finally { RpcInvokeContext.removeContext(); } } }, \u0026amp;#34;new-thread\u0026amp;#34;); thread.start(); // If failed to get the transparently transmitted data of the return value. latch.await(); //wait // Return ends, and you can get the value returned by transparent transmission. Compare with SOFATracer SOFATracer is an open-source distributed link tracing system of Ant Finanicial. RPC has been integrated with Tracer and is enabled by default.\nThe differences between data transparent transmission and data transfer by Tracer are as follows:\n RPC data transparent transmission is business-oriented. And it can implement two-way data transmission in the full link. The caller can transmit data to the service provider, and the service provider can also transmit data to the caller. SOFATracer is middleware-oriented and is more suitable for the data transfer without service itself perceving. It can only implement one-way data transmission. The transparent …","date":-62135596800,"description":"","dir":"projects/sofa-rpc/invoke-chain-pass-data/","fuzzywordcount":500,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"96cfb41f07a6a2ad979b53093ff5eee9","permalink":"/en/projects/sofa-rpc/invoke-chain-pass-data/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/en/projects/sofa-rpc/invoke-chain-pass-data/","summary":"The link data transparent transmission function allows the applications to store data in the calling context, and then any applications in the entire link can operate the data. This feature is used as follows. Data can be put into the request and response of the link for transparent transmission, and then the applications can get the corresponding data from the link.\nRpcInvokeContext.getContext().putRequestBaggage(\u0026#34;key_request\u0026#34;,\u0026#34;value_request\u0026#34;); RpcInvokeContext.getContext().putResponseBaggage(\u0026#34;key_response\u0026#34;,\u0026#34;value_response\u0026#34;); String requestValue=RpcInvokeContext.getContext().getRequestBaggage(\u0026#34;key_request\u0026#34;); String responseValue=RpcInvokeContext.getContext().getResponseBaggage(\u0026#34;key_response\u0026#34;); Example For example, in the scenario of A -\u0026gt; B -\u0026gt; C, the request arguments set by A are transmitted to B and C.","tags":null,"title":"Link data transparent transmission","type":"projects","url":"/en/projects/sofa-rpc/invoke-chain-pass-data/","wordcount":427},{"author":null,"categories":null,"content":"本文描述的是 MOSN listener 配置。\n Listener 配置详细描述了 MOSN 启动时监听的端口，以及对应的端口对应不同逻辑的配置。 Listener 的配置可以通过Listener动态接口进行添加和修改。  { \u0026amp;#34;name\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;type\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;address\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;bind_port\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;use_original_dst\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;access_logs\u0026amp;#34;:[], \u0026amp;#34;filter_chains\u0026amp;#34;:[], \u0026amp;#34;stream_filters\u0026amp;#34;:[], \u0026amp;#34;inspector\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;connection_idle_timeout\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34; } name 用于唯一区分 Listener，如果配置为空，会默认生成一个 UUID 作为 name。在对 Listener 进行动态更新时，使用 name 作为索引，如果 name 不存在，则是新增一个 listener，如果 name 存在则是对 listener 进行更新。\ntype 标记 Listener 的类型，目前支持 ingress 和 egress 两种类型。不同 type 的 Listener 输出的 tracelog 不同。\naddress IP:Port 形式的字符串，Listener 监听的地址，唯一。\nbind_port bool 类型，表示 Listener 是否会占用 address 配置的地址，通常情况下都需要配置为true。\nuse_original_dst bool 类型，用于透明代理。\naccess_logs 一组 access_log 配置。\nfilter_chains 一组 FilterChain 配置，但是目前 MOSN 仅支持一个 filter_chain。\nstream_filters 一组 stream_filter 配置，目前只在 filter_chain 中配置了 filter 包含 proxy 时生效。\ninspector bool 类型，当此值为 true 时，表示即便 listener 在 filter_chain 中配置开启了 TLS 监听，listener 依然可以处理非 TLS 的请求。\nconnection_idle_timeout Duration String，空闲连接超时配置。当 listener 上建立的连接空闲超过配置的超时时间以后，MOSN 会将此连接关闭。\n","date":-62135596800,"description":"","dir":"projects/mosn/configuration/listener/overview/","fuzzywordcount":500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"028e9053b21853890114c38d55d15390","permalink":"/projects/mosn/configuration/listener/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/mosn/configuration/listener/overview/","summary":"本文描述的是 MOSN listener 配置。 Listener 配置详细描述了 MOSN 启动时监听的端口，以及对应的端口对应不同逻辑的配置。 Listener 的配置可以通过Listener动态接口进行添加","tags":null,"title":"Listener 配置","type":"projects","url":"/projects/mosn/configuration/listener/overview/","wordcount":447},{"author":null,"categories":null,"content":"SOFARPC provides a variety of load balancing algorithms and currently supports the following five types:\n   Type Name Description     random Random algorithm The default load balancing algorithm.   localPref Local preference algorithm Firstly detect whether the service is published locally, if not, random algorithm is used.   roundRobin Round Robin algorithm Method-level polling, the polling is carried out separately to each method, without affecting each other.   consistentHash Consistent hash algorithm The same method-level request is routed to the same node.   weightRoundRobin Weighted Round Robin algorithm Poll nodes by weight. Not recommended due to poor performance.    To use a specific load balancing algorithm, you can configure as follows:\nIn XML If you reference the service using XML, you can configure it by setting the loadBalancer property of the sofa:global-attrs tag:\n\u0026amp;lt;sofa:reference interface=\u0026amp;#34;com.example.demo.SampleService\u0026amp;#34; id=\u0026amp;#34;sampleService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;sofa:global-attrs loadBalancer=\u0026amp;#34;roundRobin\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt; In Annotation It is currently not supported to configure a load balancing algorithm for a reference in Annotation. The function will be provided in subsequent releases.\nIn API under Spring environment If you use the API in a Spring or Spring Boot environment, you can configure it by calling the setLoadBalancer method of BoltBindingParam:\nBoltBindingParam boltBindingParam = new BoltBindingParam(); boltBindingParam.setLoadBalancer(\u0026amp;#34;roundRobin\u0026amp;#34;); In API under non-Spring environment If you directly use the bare API provided by SOFARPC in a non-Spring environment, you can configure it by calling the setLoadBalancer method of ConsumerConfig:\nConsumerConfig consumerConfig = new ConsumerConfig(); consumerConfig.setLoadbalancer(\u0026amp;#34;random\u0026amp;#34;); ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/load-balance/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"739984ca9a414429304f85010fd73ad0","permalink":"/en/projects/sofa-rpc/load-balance/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-rpc/load-balance/","summary":"SOFARPC provides a variety of load balancing algorithms and currently supports the following five types:\n   Type Name Description     random Random algorithm The default load balancing algorithm.   localPref Local preference algorithm Firstly detect whether the service is published locally, if not, random algorithm is used.   roundRobin Round Robin algorithm Method-level polling, the polling is carried out separately to each method, without affecting each other.","tags":null,"title":"Load balance","type":"projects","url":"/en/projects/sofa-rpc/load-balance/","wordcount":230},{"author":null,"categories":null,"content":"To use local file as service registry center, you can configure it in application.properties as follows:\ncom.alipay.sofa.rpc.registry.address=local:///home/admin/registry/localRegistry.reg The /home/admin/registry/localRegistry.reg is the directory of the local files to be used.\nOn windows OS, the above path indicates the following directory:\ncom.alipay.sofa.rpc.registry.address=local://c://users/localRegistry.reg ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/registry-local/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"33bc89393392e21b3917f090313c0df5","permalink":"/en/projects/sofa-rpc/registry-local/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/registry-local/","summary":"To use local file as service registry center, you can configure it in application.properties as follows:\ncom.alipay.sofa.rpc.registry.address=local:///home/admin/registry/localRegistry.reg The /home/admin/registry/localRegistry.reg is the directory of the local files to be used.\nOn windows OS, the above path indicates the following directory:\ncom.alipay.sofa.rpc.registry.address=local://c://users/localRegistry.reg ","tags":null,"title":"Local","type":"projects","url":"/en/projects/sofa-rpc/registry-local/","wordcount":40},{"author":null,"categories":null,"content":"1. registry-meta 1.1 Push switch When publishing new SOFARegistry versions, to minimize the impact on services, and avoid large amounts of push messages caused by large-scale service endpoint changes during the server restart process, we will temporarily turn off the push service at the management layer. After publishing the new SOFARegistry version, we can turn on the push service and restore the normal working conditions. Data subscription and service publication information generated for the period when the push service is turned off will be subject to global push for compensation.\nTurn on the push service:\ncurl \u0026amp;#34;http://\u0026amp;lt;meta_ip\u0026amp;gt;:9615/stopPushDataSwitch/close\u0026amp;#34; Turn off the push service:\ncurl \u0026amp;#34;http://\u0026amp;lt;meta_ip\u0026amp;gt;:9615/stopPushDataSwitch/open\u0026amp;#34; 1.2 Query the endpoint list View the endpoint list of the meta cluster:\ncurl \u0026amp;#34;http://\u0026amp;lt;meta_ip\u0026amp;gt;:9615/digest/META/node/query\u0026amp;#34; View the endpoint list of the data cluster:\ncurl \u0026amp;#34;http://\u0026amp;lt;meta_ip\u0026amp;gt;:9615/digest/DATA/node/query\u0026amp;#34; View the endpoint list of the session cluster:\ncurl \u0026amp;#34;http://\u0026amp;lt;meta_ip\u0026amp;gt;:9615/digest/SESSION/node/query\u0026amp;#34; 1.3 Scale up/down the meta cluster 1.3.1 Modify the cluster: changePeer You can call this operation to modify the Raft cluster list when you have scaled up/down the cluster. This allows you to correctly add nodes to or remove nodes from the cluster:\ncurl -X POST \u0026amp;#34;http://\u0026amp;lt;meta_ip\u0026amp;gt;:9615/manage/changePeer\u0026amp;#34; -d \u0026amp;#34;ipAddressList=\u0026amp;lt;ip1\u0026amp;gt;,\u0026amp;lt;ip2\u0026amp;gt;,\u0026amp;lt;ip3\u0026amp;gt;\u0026amp;#34; 1.3.2 Reset the cluster: resetPeer When a cluster is unavailable, for example, two of three servers are not functional, the cluster can not carry out leader election. Here, you can call this operation to reset the cluster list. For example, you can reset the cluster to a one-server cluster (with the only functional server) to resume election and restore service.\ncurl -X POST \u0026amp;#34;http://\u0026amp;lt;meta_ip\u0026amp;gt;:9615/manage/resetPeer\u0026amp;#34; -d \u0026amp;#34;ipAddressList=\u0026amp;lt;ip1\u0026amp;gt;,\u0026amp;lt;ip2\u0026amp;gt;,\u0026amp;lt;ip3\u0026amp;gt;\u0026amp;#34; 2. registry-data 2.1 Query data View the pub count:\ncurl \u0026amp;#34;http://\u0026amp;lt;data_ip\u0026amp;gt;:9622/digest/datum/count\u0026amp;#34; You can call this operation to view data published by a client based on its IP address and port number.\ncurl -X POST \u0026amp;#34;http://\u0026amp;lt;data_ip\u0026amp;gt;:9622/digest/connect/query\u0026amp;#34; -H \u0026amp;#34;Content-Type: application/json\u0026amp;#34; -d \u0026amp;#39;{\u0026amp;#34;\u0026amp;lt;clientIP\u0026amp;gt;\u0026amp;#34;:\u0026amp;#34;\u0026amp;lt;client port\u0026amp;gt;\u0026amp;#34;}\u0026amp;#39; 3. registry-session 3.1 Query data You can call this operation to view data published by a client based on its IP address and port number.\ncurl -X POST \u0026amp;#34;http://\u0026amp;lt;session_ip\u0026amp;gt;:9603/digest/pub/connect/query\u0026amp;#34; -H \u0026amp;#34;Content-Type: application/json\u0026amp;#34; -d \u0026amp;#39;[\u0026amp;#34;\u0026amp;lt;clientIP\u0026amp;gt;:\u0026amp;lt;client port\u0026amp;gt;\u0026amp;#34;]\u0026amp;#39; You can call this operation to view data subscribed to by a client based on its IP address and port number.\ncurl -X POST \u0026amp;#34;http://\u0026amp;lt;session_ip\u0026amp;gt;:9603/digest/sub/connect/query\u0026amp;#34; -H \u0026amp;#34;Content-Type: application/json\u0026amp;#34; -d …","date":-62135596800,"description":"","dir":"projects/sofa-registry/management-api/","fuzzywordcount":500,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"2cf59ac422c84c279d73c1f7f1cd0902","permalink":"/en/projects/sofa-registry/management-api/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-registry/management-api/","summary":"1. registry-meta 1.1 Push switch When publishing new SOFARegistry versions, to minimize the impact on services, and avoid large amounts of push messages caused by large-scale service endpoint changes during the server restart process, we will temporarily turn off the push service at the management layer. After publishing the new SOFARegistry version, we can turn on the push service and restore the normal working conditions. Data subscription and service publication information generated for the period when the push service is turned off will be subject to global push for compensation.","tags":null,"title":"Management commands","type":"projects","url":"/en/projects/sofa-registry/management-api/","wordcount":406},{"author":null,"categories":null,"content":"pom dependencies \u0026amp;lt;!-- jraft --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;jraft-core\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!-- jsr305 --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.google.code.findbugs\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;jsr305\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;3.0.2\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!-- bolt --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;bolt\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;1.5.3\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hessian\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;3.3.6\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!-- log --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.slf4j\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;slf4j-api\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;1.7.21\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!-- disruptor --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.lmax\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;disruptor\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;3.3.7\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;commons-io\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;commons-io\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.4\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;commons-lang\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;commons-lang\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.6\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!-- protobuf --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.google.protobuf\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;protobuf-java\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;3.5.1\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!-- protostuff --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;io.protostuff\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;protostuff-core\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;1.6.0\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;io.protostuff\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;protostuff-runtime\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;1.6.0\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!-- rocksdb --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.rocksdb\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;rocksdbjni\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;5.14.2\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!-- java thread affinity --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;net.openhft\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;affinity\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;3.1.7\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!-- metrics --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;io.dropwizard.metrics\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;metrics-core\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;4.0.2\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; ","date":-62135596800,"description":"","dir":"projects/sofa-jraft/maven-dependency/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"abb08cef5ebf1a10a723597a65415313","permalink":"/en/projects/sofa-jraft/maven-dependency/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-jraft/maven-dependency/","summary":"pom dependencies \u0026lt;!-- jraft --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alipay.sofa\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jraft-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- jsr305 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.google.code.findbugs\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jsr305\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.0.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- bolt --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alipay.sofa\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;bolt\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.5.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alipay.sofa\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;hessian\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.3.6\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- log --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.slf4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;slf4j-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7.21\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- disruptor --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.lmax\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;disruptor\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.3.7\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;commons-io\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-io\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.4\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;commons-lang\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-lang\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.6\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- protobuf --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.google.protobuf\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;protobuf-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.5.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- protostuff --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.protostuff\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;protostuff-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.","tags":null,"title":"Maven dependencies","type":"projects","url":"/en/projects/sofa-jraft/maven-dependency/","wordcount":104},{"author":null,"categories":null,"content":"pom依赖 \u0026amp;lt;!-- jraft --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;jraft-core\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!-- jsr305 --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.google.code.findbugs\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;jsr305\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;3.0.2\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!-- bolt --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;bolt\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;1.5.3\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hessian\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;3.3.6\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!-- log --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.slf4j\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;slf4j-api\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;1.7.21\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!-- disruptor --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.lmax\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;disruptor\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;3.3.7\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;commons-io\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;commons-io\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.4\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;commons-lang\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;commons-lang\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.6\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!-- protobuf --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.google.protobuf\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;protobuf-java\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;3.5.1\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!-- protostuff --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;io.protostuff\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;protostuff-core\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;1.6.0\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;io.protostuff\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;protostuff-runtime\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;1.6.0\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!-- rocksdb --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.rocksdb\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;rocksdbjni\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;5.14.2\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!-- java thread affinity --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;net.openhft\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;affinity\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;3.1.7\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!-- metrics --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;io.dropwizard.metrics\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;metrics-core\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;4.0.2\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; ","date":-62135596800,"description":"","dir":"projects/sofa-jraft/maven-dependency/","fuzzywordcount":200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"abb08cef5ebf1a10a723597a65415313","permalink":"/projects/sofa-jraft/maven-dependency/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-jraft/maven-dependency/","summary":"pom依赖 \u0026lt;!-- jraft --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alipay.sofa\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jraft-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- jsr305 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.google.code.findbugs\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jsr305\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.0.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- bolt --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alipay.sofa\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;bolt\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.5.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alipay.sofa\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;hessian\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.3.6\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- log --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.slf4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;slf4j-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7.21\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- disruptor --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.lmax\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;disruptor\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.3.7\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;commons-io\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-io\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.4\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;commons-lang\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-lang\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.6\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- protobuf --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.google.protobuf\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;protobuf-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.5.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- protostuff","tags":null,"title":"Maven 依赖说明","type":"projects","url":"/projects/sofa-jraft/maven-dependency/","wordcount":107},{"author":null,"categories":null,"content":"In Jarslink 2.0, merged deployment refers to loading and running multiple Biz packages in the same JVM. In the section Application Packaging, we have described the relationship between the Spring Boot/SOFABoot application and the Biz package. We may think that merged deployment here refers to loading and running multiple Spring Boot/SOFABoot applications in the same JVM.\nIt is mentioned at the end of Application Packaging that a Biz package can be released to a remote repository through the mvn deploy command, similar to releasing common Jar packages. It comes naturally to mind that the advantage of doing so is that the Biz package generated by other applications can be introduced in the form of dependencies, just like introducing common Jar package dependencies. Then, what is the purpose of introducing the Biz package generated by other applications into your application? Also, how do we dynamically install and uninstall Biz packages in Jarslink 2.0?\nTo answer the two questions above is to understand the concepts of static merged deployment and dynamic merged deployment.\nStatic merged deployment To answer the first question: What is the purpose of introducing the Biz package generated by other applications into your application?\nIn the section Application Packaging, we have described how to package an application into an Ark package and offered a rough equation: Ark package = Biz package + SOFAArk framework + Ark Plugin. When a Biz package generated by other applications is introduced in the application, what kind of packaged Ark package will it be? The conclusion is that the packaging plugin will treat special dependency packages like the Biz package differently. The plugin will package all the non-Biz package dependencies into the application\u0026amp;rsquo;s Biz package, but will consider the introduced Biz package as equal to those of the current application. The final Ark package will contain multiple Biz packages. For details, refer to Ark Package Directory Structure. At this point, when you use java -jar to start this Ark package, you will find that all the contained Biz packages will be started as well.\nTo sum up, the application introduces the Biz packages generated by other applications in the form of dependencies, and the Ark package packaged by this application will contain multiple Biz packages. By executing this Ark package, all the Biz packages will be started, known as static merged deployment.\nStatic merged deployment does not depend on Jarslink 2.0 but is available directly with the SOFAArk packaging plugin.\nNote that the startup order of multiple Biz packages is controllable. When each Biz package is generated, you can use the packaging plugin to configure its priority, whose value is 100 by default. The higher the priority, the lower the value is. The priority determines the startup order of the Biz package.\nDynamic merged deployment To answer the second question: how do you dynamically install and uninstall Biz packages in Jarslink …","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-jarslink-jarslink-deploy/","fuzzywordcount":800,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"ce787203d9d834b7f796b3dbb40bf55d","permalink":"/en/projects/sofa-boot/sofa-jarslink-jarslink-deploy/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/en/projects/sofa-boot/sofa-jarslink-jarslink-deploy/","summary":"In Jarslink 2.0, merged deployment refers to loading and running multiple Biz packages in the same JVM. In the section Application Packaging, we have described the relationship between the Spring Boot/SOFABoot application and the Biz package. We may think that merged deployment here refers to loading and running multiple Spring Boot/SOFABoot applications in the same JVM.\nIt is mentioned at the end of Application Packaging that a Biz package can be released to a remote repository through the mvn deploy command, similar to releasing common Jar packages.","tags":null,"title":"Merged deployment","type":"projects","url":"/en/projects/sofa-boot/sofa-jarslink-jarslink-deploy/","wordcount":749},{"author":null,"categories":null,"content":"Quickly understand of ACTS models When you write a test case, you need to prepare some database tables, request parameter data of methods, or data for validating database tables and responses. You can save such data in models, and import it to preparation data or validation data when you edit the test case. This allows you to conveniently reuse data. Currently, ACTS models can be divided into database models and class models.\nIn conventional test case compilation, data preparation of models, such as database models, request parameter models, and response models, is based on the test code. The complexity of models increases with the business complexity, especially in financial-level business applications, where a class or data table may have dozens of properties or fields, and where class nesting is common. In this case, constructing complex objects is extremely difficult and prone to omissions. Some of the most frequently occurring problems are listed as follows:\n Omissions may occur and troubleshooting takes a lot of time for a large number of tables. Field names of tables are difficult to remember, and spelling errors frequently occur. The large number and complex types of interface request parameters are frustrating. There are so many class properties that important properties are prone to omission. Object construction with nested structures requires continuous effort in creating and setting values. Important properties are easily omitted when the inheritance and implementation relationships are complex.  ACTS models can effectively address the above problems by formatting classes and tables in CSV, which makes the structure of classes easier to understand. Class models and data table models can help you quickly create objects, and serialize them into the YAML file. ACTS models allow you to conveniently manage test case data.\nStorage location of models You can view existing models under the resource/model directory of the test module.\nGenerate data table model Sample data table model 1. Validation flag description\nY: indicates that the data is to be inserted. N: indicates that the data is not to be inserted. C: indicates that ACTS will clean the inserted data by taking this value as the where condition. F: indicates that the value of this column is a database function. L: indicates that a large field data record requires line wrap. The preparation method for this data record is: A=B;C=D.  2. Quickly import data from models during test case editing\nWhen editing database table data (including preparing table data and expectation data) in ACTS IDE, you can right click to add a model of the specified table, to import all fields and values of the specified table directly from the CSV file of the table model for quick editing. For more information about the use of DB models, see Prepare database data.\nGenerate table model Click OK to generate the model as shown in Figure 9.\nACTS also supports table model generation without a direct JDBC connection. …","date":-62135596800,"description":"","dir":"projects/sofa-acts/usage-model/","fuzzywordcount":800,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"65aaf62462b3b0ea142ca75a5b61eb0d","permalink":"/en/projects/sofa-acts/usage-model/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/en/projects/sofa-acts/usage-model/","summary":"Quickly understand of ACTS models When you write a test case, you need to prepare some database tables, request parameter data of methods, or data for validating database tables and responses. You can save such data in models, and import it to preparation data or validation data when you edit the test case. This allows you to conveniently reuse data. Currently, ACTS models can be divided into database models and class models.","tags":null,"title":"Models","type":"projects","url":"/en/projects/sofa-acts/usage-model/","wordcount":726},{"author":null,"categories":null,"content":"Since version 2.4.0, SOFABoot has started to support modular development capability based on Spring context isolation. To better understand the concept of modular development of SOFABoot, let\u0026amp;rsquo;s distinguish several common forms of modularization:\n Modularization based on code organization: This is the most common form. Codes with different functions are placed under different Java projects at development time and into different jar packages at compile time. At runtime, all Java classes are under the same classpath without any isolation; Modularization based on Spring context isolation: Use the Spring context to perform isolation of different function modules. At development and compile time, the codes and configurations are also placed under different Java projects. At runtime, however, if Spring beans are in different Spring contexts, they are invisible to each other, so dependency injection occurs within the same context. But, all the Java classes are still under the same ClassLoader; Modularization based on ClassLoader isolation: Borrow the ClassLoader to perform isolation. Each module has an independent ClassLoader, and the classpath between modules differs. SOFAArk is the practice of such modularization.  SOFABoot Modular Development belongs to the second modularization form\u0026amp;ndash;modularization based on Spring context isolation. Each SOFABoot module uses an independent Spring context to avoid BeanId conflicts between different SOFABoot modules and effectively reduces the cost of communication between teams during enterprise-level multi-module development.\nMore details about SOFABoot module is introduced in the article.\nFeature Description Import Dependency  To use SOFABoot module, you should import the following dependency:  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;isle-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; SOFABoot Module SOFABoot framework has defined the concept of SOFABoot module: A SOFABoot module is a common Jar package including Java code, Spring configuration files, and SOFABoot module identifiers. A SOFABoot application can be comprised of multiple SOFABoot modules, each of which has independent Spring context.\nThe modular development with SOFABoot provides developers with the following features:\n At runtime, the Spring context of each SOFABoot module is isolated, so the defined Beans between modules will not affect each other; Each SOFABoot module is full-featured and self-contained, allowing for easy migration and reuse in different SOFABoot applications. Developers only need to copy the whole SOFABoot module to the application and adjust the Maven dependence before running it.  For the format definition of SOFABoot module, see: Module Configuration.\nInvocation between SOFABoot Modules After isolation of context, the Bean between modules cannot be directly injected, so the SOFA service is required for invocation between the modules. Currently, SOFABoot offers two …","date":-62135596800,"description":"","dir":"projects/sofa-boot/modular-development/","fuzzywordcount":600,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"95bc080787c3614bfa485d2f3cd0de4c","permalink":"/en/projects/sofa-boot/modular-development/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/en/projects/sofa-boot/modular-development/","summary":"Since version 2.4.0, SOFABoot has started to support modular development capability based on Spring context isolation. To better understand the concept of modular development of SOFABoot, let\u0026rsquo;s distinguish several common forms of modularization:\n Modularization based on code organization: This is the most common form. Codes with different functions are placed under different Java projects at development time and into different jar packages at compile time. At runtime, all Java classes are under the same classpath without any isolation; Modularization based on Spring context isolation: Use the Spring context to perform isolation of different function modules.","tags":null,"title":"Modular development","type":"projects","url":"/en/projects/sofa-boot/modular-development/","wordcount":578},{"author":null,"categories":null,"content":"The SOFABoot module combines a regular JAR with some SOFABoot-specific configurations, which enables a JAR to be identified by SOFABoot and modularized.\nThere are two differences between a complete SOFABoot module and a regular JAR:\n A SOFABoot module contains a sofa-module.properties file, where the name and the dependencies of the module are defined. We can place one or more Spring configuration files in the SOFABoot module\u0026amp;rsquo;s META-INF/spring directory; and SOFABoot will automatically load them as Spring configurations for that module.  Inside the sofa-module.properties file Let\u0026amp;rsquo;s look at a complete sofa-module.properties file:\nModule-Name=com.alipay.test.biz.service.impl Spring-Parent=com.alipay.test.common.dal Require-Module=com.alipay.test.biz.shared Module-Profile=dev Module-Name This is the name of a SOFABoot module, which is also the unique identifier of the module. In a SOFABoot application, the Module-Name of a SOFABoot module must be different from that of another SOFABoot module. Note that the SOFABoot modules of a SOFABoot application runtime do not only cover the modules of the current application but also the modules introduced by dependency from other applications. When determining whether a module is unique, you must take these SOFABoot modules into consideration.\nRequire-Module This defines the dependency order of different modules. The value contains a comma-separated list of SOFABoot module names. For example, in the preceding configuration, it indicates that the current module depends on the com.alipay.test.biz.shared module. The SOFABoot framework processes this dependency by starting the com.alipay.test.biz.shared module before the current module.\nIn most cases, you do not have to define the Require-Module for a module. It is required only when the startup of a module\u0026amp;rsquo;s Spring context depends on that of another module\u0026amp;rsquo;s. For example, you have published a JVM Service in module A. In the init method of a Bean in module B, you need to call the JVM Service with a SOFA Reference. Assume that module B is started before module A, the Bean of module B will fail because the JVM Service of module A is not published yet and the init method fails. In this case, you can use the Require-Module to force module A to start before module B.\nSpring-Parent In a SOFABoot application, each SOFABoot module has a separate Spring context, and these Spring contexts are isolated from each other. Although this modular approach has many benefits, it can still cause some inconveniences in certain scenarios. For these scenarios, you can use the Spring-Parent to connect the Spring contexts of two SOFABoot modules. The name of a module can be configured with the Spring-Parent property. For example, in the preceding configuration, the Spring context of com.alipay.test.common.dal is set to the parent of the current module\u0026amp;rsquo;s Spring context.\nDue to Spring\u0026amp;rsquo;s limitations, a module\u0026amp;rsquo;s Spring-Parent contains only one module …","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofaboot-module/","fuzzywordcount":600,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"2dbb8a536237f21afbee1e3f320b8193","permalink":"/en/projects/sofa-boot/sofaboot-module/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/en/projects/sofa-boot/sofaboot-module/","summary":"The SOFABoot module combines a regular JAR with some SOFABoot-specific configurations, which enables a JAR to be identified by SOFABoot and modularized.\nThere are two differences between a complete SOFABoot module and a regular JAR:\n A SOFABoot module contains a sofa-module.properties file, where the name and the dependencies of the module are defined. We can place one or more Spring configuration files in the SOFABoot module\u0026rsquo;s META-INF/spring directory; and SOFABoot will automatically load them as Spring configurations for that module.","tags":null,"title":"Module configuration","type":"projects","url":"/en/projects/sofa-boot/sofaboot-module/","wordcount":565},{"author":null,"categories":null,"content":"SOFABoot will calculate the dependency tree based on the Require-Module. For example, the following dependency tree represents that Modules B and C depend on Module A, Module E depends on Module D, and Module F depends on Module E:\nThe dependency tree guarantees that Module A starts before Modules B and C, Module D before Module E, and Module E before Module F, but without defining the start orders between Modules B and C, or Modules B, C and Modules D, E and F, which can start either in serial or parallel.\nSOFABoot will start the modules in parallel by default. During use, if you want to disable parallel start, you can add the following parameter to application.properties:\ncom.alipay.sofa.boot.module-start-up-parallel=false ","date":-62135596800,"description":"","dir":"projects/sofa-boot/parallel-start/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"a6ef51b78d2a4f9af0debbc25ea45e8a","permalink":"/en/projects/sofa-boot/parallel-start/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-boot/parallel-start/","summary":"SOFABoot will calculate the dependency tree based on the Require-Module. For example, the following dependency tree represents that Modules B and C depend on Module A, Module E depends on Module D, and Module F depends on Module E:\nThe dependency tree guarantees that Module A starts before Modules B and C, Module D before Module E, and Module E before Module F, but without defining the start orders between Modules B and C, or Modules B, C and Modules D, E and F, which can start either in serial or parallel.","tags":null,"title":"Module parallel startup","type":"projects","url":"/en/projects/sofa-boot/parallel-start/","wordcount":119},{"author":null,"categories":null,"content":"Instructions on performance report The following performance report presents the performance comparison data of MOSN 0.1.0 with envoy in terms of pure TCP forwarding for Bolt and HTTP1.x protocols, mainly including QPS, RTT, failure rate, success rate and other indicators.\nIt is significant to note the following optimizations in v0.1.0 which are intended to improve the forwarding performance of MOSN.\n For thread model, MOSN uses the worker goroutine pool to handle stream events, and uses two independent goroutines to handle read and write IO separately. For single-core forwarding, in the case of specifying P=1, MOSN binds CPU with cores to improve the call execution efficiency of the system and the locality affinity of cache. For memory, in the case of binding single core, MOSN uses SLAB-style recycling mechanism to improve reuse and reduce memory copy. For IO, MOSN mainly implements optimization by controlling the read/write buffer size, read/write timing, read/write frequency and other parameters.  The performance test data is as follows:\nTCP proxy performance data For the same deployment mode, this report compares MOSN 0.1.0 and envoy for the upper-layer protocol Bolt (SOFARPC related protocol) and HTTP1.1 respectively.\nDeployment mode The pressure test is deployed in a pure proxy mode. The client process accesses the server process through the MOSN process and serves as a forwarding proxy. The client process, MOSN process, and server process run on the machines which belong to different network segments. The network delay of the direct access from the client to server is about 2.5ms.\nClient Bolt protocol (send 1K string) The client that sends the Bolt protocol data uses the online pressure generators developed by Ant Financial and deploys the SOFARPC client.\nOn the pressure generator performance page, you can see the QPS, success/failure counts, RT and other parameters.\nHTTP1.1 protocol (send 1K string) Use ApacheBench/2.3. The test instructions are:\nab -n $RPC -c $CPC -p 1k.txt -T \u0026amp;#34;text/plain\u0026amp;#34; -k http://11.166.161.136:12200/tcp_bench \u0026amp;gt; ab.log.$CPU_IDX \u0026amp;amp; Mesh machine specifications The mesh runs in a container where the CPU is an exclusive logical core. The specifications are as follows:\n   Category Information     OS 3.10.0-327.ali2008.alios7.x86_64   CPU Intel(R) Xeon(R) CPU E5-2650 v2 @ 2.60GHz X 1    Upstream machine specifications    Category Information     OS 2.6.32-431.17.1.el6.FASTSOCKET   CPU Intel(R) Xeon(R) CPU E5620 @ 2.40GHz X 16    Bolt protocol test result Performance data    Indicators MOSN Envoy     QPS 103500 104000   RT 16.23ms 15.88ms   MEM 31m 18m   CPU 100% 100%    Conclusion For single-core TCP forwarding, there is little difference between MOSN 0.1.0 and Envoy 1.7 in terms of performance in the condition with full load, such as QPS, RTT and success/failure counts. We will continue to optimize in the subsequent versions.\nHTTP/1.1 test result Since the HTTP/1.1 request response model is PING-PONG, QPS is …","date":-62135596800,"description":"","dir":"projects/mosn/reference-performance-report010/","fuzzywordcount":800,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"3cb22950b4be5a25b90f8aa1376786e9","permalink":"/en/projects/mosn/reference-performance-report010/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/en/projects/mosn/reference-performance-report010/","summary":"Instructions on performance report The following performance report presents the performance comparison data of MOSN 0.1.0 with envoy in terms of pure TCP forwarding for Bolt and HTTP1.x protocols, mainly including QPS, RTT, failure rate, success rate and other indicators.\nIt is significant to note the following optimizations in v0.1.0 which are intended to improve the forwarding performance of MOSN.\n For thread model, MOSN uses the worker goroutine pool to handle stream events, and uses two independent goroutines to handle read and write IO separately.","tags":null,"title":"MOSN 0.1.0 performance report","type":"projects","url":"/en/projects/mosn/reference-performance-report010/","wordcount":730},{"author":null,"categories":null,"content":"Instructions on performance report The following performance report presents the performance comparison data of MOSN 0.1.0 with envoy in terms of pure TCP forwarding for Bolt and HTTP1.x protocols, mainly including QPS, RTT, failure rate, success rate and other indicators.\nIt is significant to note the following optimizations in v0.1.0 which are intended to improve the forwarding performance of MOSN.\n For thread model, MOSN uses the worker goroutine pool to handle stream events, and uses two independent goroutines to handle read and write IO separately. For single-core forwarding, in the case of specifying P=1, MOSN binds CPU with cores to improve the call execution efficiency of the system and the locality affinity of cache. For memory, in the case of binding single core, MOSN uses SLAB-style recycling mechanism to improve reuse and reduce memory copy. For IO, MOSN mainly implements optimization by controlling the read/write buffer size, read/write timing, read/write frequency and other parameters.  The performance test data is as follows:\nTCP proxy performance data For the same deployment mode, this report compares MOSN 0.1.0 and envoy for the upper-layer protocol Bolt (SOFARPC related protocol) and HTTP1.1 respectively.\nDeployment mode The pressure test is deployed in a pure proxy mode. The client process accesses the server process through the MOSN process and serves as a forwarding proxy. The client process, MOSN process, and server process run on the machines which belong to different network segments. The network delay of the direct access from the client to server is about 2.5ms.\nClient Bolt protocol (send 1K string) The client that sends the Bolt protocol data uses the online pressure generators developed by Ant Financial and deploys the SOFARPC client.\nOn the pressure generator performance page, you can see the QPS, success/failure counts, RT and other parameters.\nHTTP1.1 protocol (send 1K string) Use ApacheBench/2.3. The test instructions are:\nab -n $RPC -c $CPC -p 1k.txt -T \u0026amp;#34;text/plain\u0026amp;#34; -k http://11.166.161.136:12200/tcp_bench \u0026amp;gt; ab.log.$CPU_IDX \u0026amp;amp; Mesh machine specifications The mesh runs in a container where the CPU is an exclusive logical core. The specifications are as follows:\n   Category Information     OS 3.10.0-327.ali2008.alios7.x86_64   CPU Intel(R) Xeon(R) CPU E5-2650 v2 @ 2.60GHz X 1    Upstream machine specifications    Category Information     OS 2.6.32-431.17.1.el6.FASTSOCKET   CPU Intel(R) Xeon(R) CPU E5620 @ 2.40GHz X 16    Bolt protocol test result Performance data    Indicators MOSN Envoy     QPS 103500 104000   RT 16.23ms 15.88ms   MEM 31m 18m   CPU 100% 100%    Conclusion For single-core TCP forwarding, there is little difference between MOSN 0.1.0 and Envoy 1.7 in terms of performance in the condition with full load, such as QPS, RTT and success/failure counts. We will continue to optimize in the subsequent versions.\nHTTP/1.1 test result Since the HTTP/1.1 request response model is PING-PONG, QPS is …","date":-62135596800,"description":"","dir":"projects/occlum/reference-performance-report010/","fuzzywordcount":800,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"035dfbc7e310acf31561343432aea680","permalink":"/en/projects/occlum/reference-performance-report010/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/en/projects/occlum/reference-performance-report010/","summary":"Instructions on performance report The following performance report presents the performance comparison data of MOSN 0.1.0 with envoy in terms of pure TCP forwarding for Bolt and HTTP1.x protocols, mainly including QPS, RTT, failure rate, success rate and other indicators.\nIt is significant to note the following optimizations in v0.1.0 which are intended to improve the forwarding performance of MOSN.\n For thread model, MOSN uses the worker goroutine pool to handle stream events, and uses two independent goroutines to handle read and write IO separately.","tags":null,"title":"MOSN 0.1.0 performance report","type":"projects","url":"/en/projects/occlum/reference-performance-report010/","wordcount":730},{"author":null,"categories":null,"content":"以下的的性能报告为 MOSN 0.1.0 在做 Bolt 与 HTTP1.x 协议的纯 TCP 转发上与 envoy 的一些性能对比数据，主要表现在 QPS、RTT、失败率/成功率等。\n这里需要强调的是，为了提高 MOSN 的转发性能，在 0.1.0 版本中，我们做了如下的一些优化手段：\n 在线程模型优化上，使用 worker 协程池处理 stream 事件，使用两个独立的协程分别处理读写 IO 在单核转发优化上，在指定 P=1 的情况下，我们通过使用 CPU 绑核的形式来提高系统调用的执行效率以及 cache 的 locality affinity 在内存优化上，同样是在单核绑核的情况下，我们通过使用 SLAB-style 的回收机制来提高复用，减少内存 copy 在 IO 优化上，主要是通过读写 buffer 大小以及读写时机和频率等参数的控制上进行调优  以下为具体的性能测试数据。\nTCP 代理性能数据 这里，针对相同的部署模式，我们分别针对上层协议为 \u0026amp;quot;Bolt(SofaRpc相关协议)\u0026amp;quot; 与 \u0026amp;quot;HTTP1.1\u0026amp;quot; 来进行对比。\n部署模式 压测采用纯代理模式部署，client 进程通过 MOSN 进程作为转发代理访问server进程。其中，client 进程，MOSN 进程，server 进程分别运行在属于不同网段的机器中。client 直连访问 server 网络延时为 2.5ms 左右。\n客户端 Bolt 协议（发送 1K 字符串） 发送 Bolt 协议数据的客户端使用 \u0026amp;ldquo;蚂蚁金服\u0026amp;quot;内部开发的线上压力机，并部署 sofa rpc client。 通过压力机的性能页面，可反映压测过程中的QPS、成功/失败次数，以及RT等参数。\nHTTP1.1 协议（发送 1K 字符串） 使用 ApacheBench/2.3, 测试指令:\nab -n $RPC -c $CPC -p 1k.txt -T \u0026amp;#34;text/plain\u0026amp;#34; -k http://11.166.161.136:12200/tcp_bench \u0026amp;gt; ab.log.$CPU_IDX \u0026amp;amp; Service mesh 运行机器规格 Service mesh 运行在容器中，其中 CPU 为独占的一个逻辑核，具体规格如下：\n   类别 信息     OS 3.10.0-327.ali2008.alios7.x86_64   CPU Intel(R) Xeon(R) CPU E5-2650 v2 @ 2.60GHz X 1    Upstream 运行机器规格    类别 信息     OS 2.6.32-431.17.1.el6.FASTSOCKET   CPU Intel(R) Xeon(R) CPU E5620 @ 2.40GHz X 16    Bolt 协议测试结果 性能数据    指标 MOSN Envoy     QPS 103500 104000   RT 16.23ms 15.88ms   MEM 31m 18m   CPU 100% 100%    结论 可以看到，在单核 TCP 转发场景下，MOSN 0.1.0 版本和 Envoy 1.7版本，在满负载情况下的 QPS、RTT、成功数/失败数等性能数据上相差不大，后续版本我们会继续优化。\nHTTP/1.1 测试结果 由于 HTTP/1.1 的请求响应模型为 PING-PONG，因此 QPS 与并发数会呈现正相关。下面分别进行不同并发数的测试。\n并发20    指标 MOSN Envoy     QPS 5600 5600   RT(mean) 3.549ms 3.545ms   RT(P99) 4ms 4ms   RT(P98) 4ms 4ms   RT(P95) 4ms 4ms   MEM 24m 23m   CPU 40% 20%    并发40    指标 MOSN Envoy     QPS 11150 11200   RT(mean) 3.583ms 3.565ms   RT(P99) 4ms 4ms   RT(P98) 4ms 4ms   RT(P95) 4ms 4ms   MEM 34m 24m   CPU 70% 40%    并发200    指标 MOSN Envoy     QPS 29670 38800   RT(mean) 5.715ms 5.068ms   RT(P99) 16ms 7ms   RT(P98) 13ms 7ms   RT(P95) 11ms 6ms   MEM 96m 24m   CPU 100% 95%    并发220    指标 MOSN Envoy     QPS 30367 41070   RT(mean) 8.201ms 5.369ms   RT(P99) 20ms 9ms   RT(P98) 19ms 8ms   RT(P95) 16ms 8ms   MEM 100m 24m   CPU 100% 100%    结论 可以看到，在上层协议为 HTTP/1.X 时，MOSN 的性能和 Envoy 的性能存在一定差距，对于这种现象我们的初步结论为：在 PING-PONG 的发包模型下，MOSN 无法进行 read/write 系统调用合并，相比 SOFARPC 可以合并的场景，syscall 数量大幅上升，因此导致相比 SOFARPC 的场景，HTTP 性能上相比 Envoy 会存在差距。针对这个问题，在 0.2.0 版本中，我们会进行相应的优化。\n附录 Envoy 版本信息  version：1.7 tag：1ef23d481a4701ad4a414d1ef98036bd2ed322e7  Envoy TCP 测试配置 static_resources: listeners: - address: socket_address: address: 0.0.0.0 port_value: 12200 filter_chains: - filters: - name: envoy.tcp_proxy config: stat_prefix: ingress_tcp cluster: sofa_server clusters: - name: sofa_server connect_timeout: 0.25s type: static lb_policy: round_robin hosts: - socket_address: address: 10.210.168.5 port_value: 12222 - socket_address: address: 10.210.168.5 port_value: 12223 - socket_address: address: 10.210.168.5 port_value: 12224 - socket_address: address: 10.210.168.5 port_value: 12225 admin: access_log_path: \u0026amp;#34;/dev/null\u0026amp;#34; …","date":-62135596800,"description":"","dir":"projects/mosn/reference-performance-report010/","fuzzywordcount":1300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"3cb22950b4be5a25b90f8aa1376786e9","permalink":"/projects/mosn/reference-performance-report010/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/mosn/reference-performance-report010/","summary":"以下的的性能报告为 MOSN 0.1.0 在做 Bolt 与 HTTP1.x 协议的纯 TCP 转发上与 envoy 的一些性能对比数据，主要表现在 QPS、RTT、失败率/成功率等。 这里需要强调的是，为了提","tags":null,"title":"MOSN 0.1.0 性能报告","type":"projects","url":"/projects/mosn/reference-performance-report010/","wordcount":1228},{"author":null,"categories":null,"content":"以下性能报告的基准版本为 MOSN 0.2.1。在 0.2.1 版本中，我们进行了如下一些优化手段：\n 添加内存复用框架，涵盖 io/protocol/stream/proxy 层级，减少对象分配、内存使用和 GC 压力。 针对大量链接场景，新增 Raw Epoll 模式，该模式使用了事件回调机制 + IO 协程池，规避了海量协程带来的堆栈内存消耗以及调度开销。  需要注意的是，由于目前 SOFARPC 和 H2 的压测工具还没有 pxx 指标的展示，我们在性能报告中选取的数据都为均值。后续需要我们自行进行相关压测环境工具的建设来完善相关指标（P99，P95……）\n总览 本次性能报告在0.1.0 性能报告的基础上，新增了若干场景的覆盖，总体包含以下几部分：\n 单核性能（sidecar场景）  7层代理  Bolt（串联） Http/1.1（串联） Http/2（串联）     多核性能（gateway场景）  7层代理  Bolt（直连） Http/1.1（直连） Http/2（直连）     长连接网关  Bolt（read/write loop with goroutine/raw epoll）    单核性能（sidecar 场景） 测试环境 机器信息    机器 OS CPU     11.166.190.224 3.10.0-327.ali2010.rc7.alios7.x86_64 Intel（R） Xeon（R） CPU E5-2640 v3 @ 2.60GHz   11.166.136.110 3.10.0-327.ali2010.rc7.alios7.x86_64 Intel（R） Xeon（R） CPU E5-2430 0 @ 2.20GHz   bolt client client 为压力平台，有 5 台压力机，共计与client MOSN 之间会建立 500 条链接    http1 client（10.210.168.5） ApacheBench/2.3 -n 2000000 -c 500 -k   http2 client（10.210.168.5） nghttp.h2load -n1000000 -c5 -m100 -t4    部署结构    压测模式 部署结构     串联 client \u0026amp;ndash;\u0026amp;gt; MOSN（11.166.190.224） \u0026amp;ndash;\u0026amp;gt; MOSN（11.166.136.110） \u0026amp;ndash;\u0026amp;gt; server（11.166.136.110）    网络时延    节点 PING     client \u0026amp;ndash;\u0026amp;gt; MOSN（11.166.190.224） 1.356ms   MOSN（11.166.190.224） \u0026amp;ndash;\u0026amp;gt; MOSN（11.166.136.110） 0.097 ms    请求模式    请求内容     1K req/resp    7层代理    场景 QPS RT(ms) MEM(K) CPU(%)     Bolt 16000 15.8 77184 98   Http/1.1 4610 67 47336 90   Http/2 5219 81 31244 74    多核性能（gateway 场景） 测试环境 机器信息    机器 OS CPU     11.166.190.224 3.10.0-327.ali2010.rc7.alios7.x86_64 Intel（R） Xeon（R） CPU E5-2640 v3 @ 2.60GHz   11.166.136.110 3.10.0-327.ali2010.rc7.alios7.x86_64 Intel（R） Xeon（R） CPU E5-2430 0 @ 2.20GHz   bolt client client为压力平台，有5台压力机，共计与client MOSN之间会建立500条链接    http1 client（10.210.168.5） ApacheBench/2.3 -n 2000000 -c 500 -k   http2 client（10.210.168.5） nghttp.h2load -n1000000 -c5 -m100 -t4    部署结构    压测模式 部署结构     直连 client \u0026amp;ndash;\u0026amp;gt; MOSN（11.166.190.224） \u0026amp;ndash;\u0026amp;gt; server（11.166.136.110）    网络时延    节点 PING     client \u0026amp;ndash;\u0026amp;gt; MOSN（11.166.190.224） 1.356ms   MOSN（11.166.190.224） \u0026amp;ndash;\u0026amp;gt; MOSN（11.166.136.110） 0.097 ms    请求模式    请求内容     1K req/resp    7层代理    场景 QPS RT(ms) MEM(K) CPU(%)     Bolt 45000 23.4 544732 380   Http/1.1 21584 23 42768 380   Http/2 8180 51.7 173180 300    长连接网关 测试环境 机器信息    机器 OS CPU     11.166.190.224 3.10.0-327.ali2010.rc7.alios7.x86_64 Intel(R) Xeon(R) CPU E5-2640 v3 @ 2.60GHz   11.166.136.110 3.10.0-327.ali2010.rc7.alios7.x86_64 Intel(R) Xeon(R) CPU E5-2430 0 @ 2.20GHz    部署结构    压测模式 部署结构     直连 client \u0026amp;ndash;\u0026amp;gt; MOSN（11.166.190.224） \u0026amp;ndash;\u0026amp;gt; server（11.166.136.110）    网络时延    节点 PING     client \u0026amp;ndash;\u0026amp;gt; MOSN（11.166.190.224） 1.356ms   MOSN（11.166.190.224） \u0026amp;ndash;\u0026amp;gt; MOSN（11.166.136.110） 0.097 ms    请求模式    链接数 请求内容     2 台压力机，每台 5w 链接 + 500 QPS，共计10W链接 + 1000 QPS 1K req/resp    长连接网关    场景 QPS MEM(g) CPU(%) goroutine     RWLoop + goroutine 1000 3.3 60 200028   Raw epoll 1000 2.5 18 28    总结 MOSN 0.2.1引入了内存复用框架，相比0.1.0，在 bolt 协议转发场景性能表现得到了大幅优化。在提升了20% 的 QPS 的同时，还优化了 30% 的内存占用。\n与此同时，我们对 HTTP/1.1 及 HTTP/2 的场景也进行了初步的性能测试，目前来看性能表现比 …","date":-62135596800,"description":"","dir":"projects/mosn/reference-performance-report021/","fuzzywordcount":1700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"7b04a2e6cf1c4f9e732dc1dfdab74c57","permalink":"/projects/mosn/reference-performance-report021/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/projects/mosn/reference-performance-report021/","summary":"以下性能报告的基准版本为 MOSN 0.2.1。在 0.2.1 版本中，我们进行了如下一些优化手段： 添加内存复用框架，涵盖 io/protocol/stream/proxy 层级，减少对象分配、内存使用和 GC 压力。","tags":null,"title":"MOSN 0.2.1 性能报告","type":"projects","url":"/projects/mosn/reference-performance-report021/","wordcount":1602},{"author":null,"categories":null,"content":"MOSN 的官方网站 mosn.io 正在建设中，文档临时托管在这里。\nMOSN 是一款使用 Go 语言开发的网络代理软件，作为云原生的网络数据平面，旨在为服务提供多协议，模块化，智能化，安全的代理能力。MOSN 是 Modular Open Smart Network-proxy 的简称。MOSN 可以与任何支持 xDS API 的 Service Mesh 集成，亦可以作为独立的四、七层负载均衡，API Gateway，云原生 Ingress 等使用。\n快速开始 请参考快速开始。\n核心能力  Istio集成  集成 Istio 1.0 版本与 V4 API，可基于全动态资源配置运行   核心转发  自包含的网络服务器 支持 TCP 代理 支持 TProxy 模式   多协议  支持 HTTP/1.1，HTTP/2 支持 SOFARPC 支持 Dubbo 协议（开发中）   核心路由  支持 Virtual Host 路由 支持 Headers/URL/Prefix 路由 支持基于 Host Metadata 的 Subset 路由 支持重试   后端管理\u0026amp;amp;负载均衡  支持连接池 支持熔断 支持后端主动健康检查 支持 Random/RR 等负载策略 支持基于 Host Metadata 的 Subset 负载策略   可观察性  观察网络数据 观察协议数据   TLS  支持 HTTP/1.1 on TLS 支持 HTTP/2.0 on TLS 支持 SOFARPC on TLS   进程管理  支持平滑 reload 支持平滑升级   扩展能力  支持自定义私有协议 支持在 TCP IO 层，协议层面加入自定义扩展    社区 MOSN 仍处在初级阶段，有很多能力需要补全，所以我们欢迎所有人参与进来与我们一起共建。\n如有任何疑问欢迎提交 Issue。\n","date":-62135596800,"description":"","dir":"projects/mosn/overview/","fuzzywordcount":500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"f25c59cbb758b4dae5de39e1f1c3a2f4","permalink":"/projects/mosn/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/mosn/overview/","summary":"MOSN 的官方网站 mosn.io 正在建设中，文档临时托管在这里。 MOSN 是一款使用 Go 语言开发的网络代理软件，作为云原生的网络数据平面，旨在为服务提供多协议，模块化，","tags":null,"title":"MOSN 介绍","type":"projects","url":"/projects/mosn/overview/","wordcount":470},{"author":null,"categories":null,"content":"Service Mesh 中 Sidecar 运维一直是一个比较棘手的问题，数据平面的 Sidecar 升级是常有的事情，如何在升级 Sidecar（MOSN）的时候而不影响业务，对于存量的长连接如何迁移，本文将为你介绍 MOSN 的解决之道。\n背景 本文介绍 MOSN 支持平滑升级的原因和解决方案，对于平滑升级的一些基础概念，大家可以通过 Nginx vs Enovy vs Mosn 平滑升级原理解析了解。\n先简单介绍一下为什么 Nginx 和 Envoy 不需要具备 MOSN 这样的连接无损迁移方案，主要还是跟业务场景相关，Nginx 和 Envoy 主要支持的是 HTTP1 和 HTTP2 协议，HTTP1使用 connection: Close，HTTP2 使用 Goaway Frame 都可以让 Client 端主动断链接，然后新建链接到新的 New process，但是针对 Dubbo、SOFA PRC 等常见的多路复用协议，它们是没有控制帧，Old process 的链接如果断了就会影响请求的。\n一般的升级做法就是切走应用的流量，比如自己UnPub掉服务，等待一段时间没有请求之后，升级MOSN，升级好之后再Pub服务，整个过程比较耗时，并且会有一段时间是不提供服务的，还要考虑应用的水位，在大规模场景下，就很难兼顾评估。MOSN 为了满足自身业务场景，开发了长连接迁移方案，把这条链接迁移到 New process 上，整个过程对 Client 透明，不需要重新建链接，达到请求无损的平滑升级。\n正常流程  Client 发送请求 Request 到 MOSN MOSN 转发请求 Request 到 Server Server 回复响应 Response 到 MOSN MOSN 回复响应 Response 到 Client  上图简单介绍了一个请求的正常流程，我们后面需要迁移的是 TCP1 链接，也就是 Client 到 MOSN 的连接，MOSN 到 Server 的链接 TCP2 不需要迁移，因为 MOSN 访问 Server 是根据 LoadBalance 选择，我们可以主动控制断链建链。\n平滑升级流程 触发条件 有两个方式可以触发平滑升级流程：\n MOSN 对 SIGHUP 做了监听，发送 SIGHUP 信号给 MOSN 进程，通过 ForkExec 生成一个新的 MOSN 进程。 直接重新启动一个新 MOSN 进程。  为什么提供两种方式？最开始我们支持的是方法1，也就是 nginx 和 Envoy 使用的方式，这个在虚拟机或者容器内替换 MOSN 二级制来升级是可行的，但是我们的场景需要满足容器间的升级，所以需要新拉起一个容器，就需要重新启动一个新的 MOSN 进程来做平滑升级，所以后续又支持了方法2。容器间升级还需要 operator 的支持，本文不展开叙述。\n交互流程 首先，老的 MOSN 在启动最后阶段会启动一个协程运行 ReconfigureHandler() 函数监听一个 Domain Socket（reconfig.sock）, 该接口的作用是让新的 MOSN 来感知是否存在老的 MOSN。\nfunc ReconfigureHandler() { l, err := net.Listen(\u0026amp;#34;unix\u0026amp;#34;, types.ReconfigureDomainSocket) for { uc, err := ul.AcceptUnix() _, err = uc.Write([]byte{0}) reconfigure(false) } } 触发平滑升级流程的两种方式最终都是启动一个新的 MOSN 进程，然后调用GetInheritListeners()，通过 isReconfigure() 函数来判断本机是否存在一个老的 MOSN（就是判断是否存在 reconfig.sock 监听），如果存在一个老的 MOSN，就进入迁移流程，反之就是正常的启动流程。\n// 保留了核心流程 func GetInheritListeners() ([]net.Listener, net.Conn, error) { if !isReconfigure() { return nil, nil, nil } l, err := net.Listen(\u0026amp;#34;unix\u0026amp;#34;, types.TransferListenDomainSocket) uc, err := ul.AcceptUnix() _, oobn, _, _, err := uc.ReadMsgUnix(buf, oob) file := os.NewFile(fd, \u0026amp;#34;\u0026amp;#34;) fileListener, err := net.FileListener(file) return listeners, uc, nil } 如果进入迁移流程，新的 MOSN 将监听一个新的 Domain Socket（listen.sock），用于老的 MOSN 传递 listen FD 到新的 MOSN。FD 的传递使用了sendMsg 和 recvMsg。在收到 listen FD 之后，调用 net.FileListener() 函数生产一个 Listener。此时，新老 MOSN 都同时拥有了相同的 Listen 套接字。\n// FileListener returns a copy of the network listener corresponding // to the open file f. // It is the caller\u0026amp;#39;s responsibility to close ln when finished. // Closing ln does not affect f, and closing f does not affect ln. func FileListener(f *os.File) (ln Listener, err error) { ln, err = fileListener(f) if err != nil { err = \u0026amp;amp;OpError{Op: \u0026amp;#34;file\u0026amp;#34;, Net: \u0026amp;#34;file+net\u0026amp;#34;, Source: nil, Addr: fileAddr(f.Name()), Err: err} } return } 这里的迁移和 Nginx 还是有一些区别，Nginx 是 fork 的方式，子进程自动就继承了 listen FD，MOSN 是新启动的进程，不存在父子关系，所以需要通过 sendMsg 的方式来传递。\n在进入迁移流程和 Listen 的迁移过程中，一共使用了两个 Domain Socket：\n reconfig.sock 是 Old MOSN 监听，用于 New MOSN 来判断是否存在 listen.sock 是 New MOSN 监听，用于 Old MOSN 传递 listen FD  两个 sock 其实是可以复用的，也可以用 reconfig.sock 进行 listen 的传递，由于一些 …","date":-62135596800,"description":"","dir":"projects/mosn/concept/smooth-upgrade/","fuzzywordcount":4000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"2c09c045287c33c760368abe02bb8986","permalink":"/projects/mosn/concept/smooth-upgrade/","publishdate":"0001-01-01T00:00:00Z","readingtime":8,"relpermalink":"/projects/mosn/concept/smooth-upgrade/","summary":"Service Mesh 中 Sidecar 运维一直是一个比较棘手的问题，数据平面的 Sidecar 升级是常有的事情，如何在升级 Sidecar（MOSN）的时候而不影响业务，对于存量的长连接","tags":null,"title":"MOSN 平滑升级原理解析","type":"projects","url":"/projects/mosn/concept/smooth-upgrade/","wordcount":3957},{"author":null,"categories":null,"content":"SOFARPC already supports using Nacos as a service registry. Suppose you have deployed Nacos Server locally according to Nacos\u0026amp;rsquo;s [Quick Start] (https://nacos.io/zh-cn/docs/quick-start.html), and the service discovery port is set to 8848 by default.\nTo use Nacos as a service registry in SOFARPC, you only need to add the following configuration to application.properties:\ncom.alipay.sofa.rpc.registry.address=nacos://127.0.0.1:8848 If you use SOFARPC directly, not SOFABoot, you need to add dependency of nacos, notice that version is what you want to use in your project.\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alibaba.nacos\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;nacos-client\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; The current version of Nacos is supported:\nSOFARPC: 5.5.0, SOFABoot: 2.5.3。\nSOFARPC integration verification Nacos server version:0.6.0。\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/registry-nacos/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"cc161f22cd2145fe309e63087581adc1","permalink":"/en/projects/sofa-rpc/registry-nacos/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/registry-nacos/","summary":"SOFARPC already supports using Nacos as a service registry. Suppose you have deployed Nacos Server locally according to Nacos\u0026rsquo;s [Quick Start] (https://nacos.io/zh-cn/docs/quick-start.html), and the service discovery port is set to 8848 by default.\nTo use Nacos as a service registry in SOFARPC, you only need to add the following configuration to application.properties:\ncom.alipay.sofa.rpc.registry.address=nacos://127.0.0.1:8848 If you use SOFARPC directly, not SOFABoot, you need to add dependency of nacos, notice that version is what you want to use in your project.","tags":null,"title":"Nacos","type":"projects","url":"/en/projects/sofa-rpc/registry-nacos/","wordcount":101},{"author":null,"categories":null,"content":"前言 本文是对 Nginx、Envoy 及 MOSN 的平滑升级原理区别的分析，适合对 Nginx 实现原理比较感兴趣的同学阅读，需要具备一定的网络编程知识。\n平滑升级的本质就是 listener fd 的迁移，虽然 Nginx、Envoy、MOSN 都提供了平滑升级支持，但是鉴于它们进程模型的差异，反映在实现上还是有些区别的。这里来探讨下它们其中的区别，并着重介绍 Nginx 的实现。\nNginx 相信有很多人认为 Nginx 的 reload 操作就能完成平滑升级，其实这是个典型的理解错误。实际上 reload 操作仅仅是平滑重启，并没有真正的升级新的二进制文件，也就是说其运行的依然是老的二进制文件。\nNginx 自身也并没有提供平滑升级的命令选项，其只能靠手动触发信号来完成。具体正确的操作步骤可以参考这里：Upgrading Executable on the Fly，这里只分析下其实现原理。\nNginx 的平滑升级是通过 fork + execve 这种经典的处理方式来实现的。准备升级时，Old Master 进程收到信号然后 fork 出一个子进程，注意此时这个子进程运行的依然是老的镜像文件。紧接着这个子进程会通过 execve 调用执行新的二进制文件来替换掉自己，成为 New Master。\n那么问题来了：New Master 启动时按理说会执行 bind + listen 等操作来初始化监听，而这时候 Old Master 还没有退出，端口未释放，执行 execve 时理论上应该会报：Address already in use 错误，但是实际上这里却没有任何问题，这是为什么？\n因为 Nginx 在 execve 的时候压根就没有重新 bind + listen，而是直接把 listener fd 添加到 epoll 的事件表。因为这个 New Master 本来就是从 Old Master 继承而来，自然就继承了 Old Master 的 listener fd，但是这里依然有一个问题：该怎么通知 New Master 呢？\n环境变量。execve 在执行的时候可以传入环境变量。实际上 Old Master 在 fork 之前会将所有 listener fd 添加到 NGINX 环境变量：\nngx_pid_t ngx_exec_new_binary(ngx_cycle_t *cycle, char *const *argv) { ... ctx.path = argv[0]; ctx.name = \u0026amp;#34;new binary process\u0026amp;#34;; ctx.argv = argv; n = 2; env = ngx_set_environment(cycle, \u0026amp;amp;n); ... env[n++] = var; env[n] = NULL; ... ctx.envp = (char *const *) env; ccf = (ngx_core_conf_t *) ngx_get_conf(cycle-\u0026amp;gt;conf_ctx, ngx_core_module); if (ngx_rename_file(ccf-\u0026amp;gt;pid.data, ccf-\u0026amp;gt;oldpid.data) == NGX_FILE_ERROR) { ... return NGX_INVALID_PID; } pid = ngx_execute(cycle, \u0026amp;amp;ctx); return pid; } Nginx 在启动的时候，会解析 NGINX 环境变量：\nstatic ngx_int_t ngx_add_inherited_sockets(ngx_cycle_t *cycle) { ... inherited = (u_char *) getenv(NGINX_VAR); if (inherited == NULL) { return NGX_OK; } if (ngx_array_init(\u0026amp;amp;cycle-\u0026amp;gt;listening, cycle-\u0026amp;gt;pool, 10, sizeof(ngx_listening_t)) != NGX_OK) { return NGX_ERROR; } for (p = inherited, v = p; *p; p++) { if (*p == \u0026amp;#39;:\u0026amp;#39; || *p == \u0026amp;#39;;\u0026amp;#39;) { s = ngx_atoi(v, p - v); ... v = p + 1; ls = ngx_array_push(\u0026amp;amp;cycle-\u0026amp;gt;listening); if (ls == NULL) { return NGX_ERROR; } ngx_memzero(ls, sizeof(ngx_listening_t)); ls-\u0026amp;gt;fd = (ngx_socket_t) s; } } ... ngx_inherited = 1; return ngx_set_inherited_sockets(cycle); } 一旦检测到是继承而来的 socket，那就说明已经打开了，不会再继续 bind + listen 了：\nngx_int_t ngx_open_listening_sockets(ngx_cycle_t *cycle) { ... /* TODO: configurable try number */ for (tries = 5; tries; tries--) { failed = 0; /* for each listening socket */ ls = cycle-\u0026amp;gt;listening.elts; for (i = 0; i \u0026amp;lt; cycle-\u0026amp;gt;listening.nelts; i++) { ... if (ls[i].inherited) { /* TODO: close on exit */ /* TODO: nonblocking */ /* TODO: deferred accept */ continue; } ... ngx_log_debug2(NGX_LOG_DEBUG_CORE, log, 0, \u0026amp;#34;bind() %V #%d \u0026amp;#34;, \u0026amp;amp;ls[i].addr_text, s);  if (bind(s, ls[i].sockaddr, ls[i].socklen) == -1) { ... } ... } } if (failed) { ngx_log_error(NGX_LOG_EMERG, log, 0, \u0026amp;#34;still could not bind()\u0026amp;#34;); return NGX_ERROR; } return NGX_OK; } Envoy Envoy 使用的是单进程多线程模型，其局限就是无法通过环境变量来传递 listener fd。因此 Envoy 采用的是 UDS（unix domain sockets）方案。当 New Envoy 启动完成后，会通过 UDS 向 Old Envoy 请求 listener …","date":-62135596800,"description":"","dir":"projects/mosn/concept/nginx-envoy-mosn-hot-upgrade/","fuzzywordcount":1600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"63ca389b7e6e0a585d0183ad71887f65","permalink":"/projects/mosn/concept/nginx-envoy-mosn-hot-upgrade/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/projects/mosn/concept/nginx-envoy-mosn-hot-upgrade/","summary":"前言 本文是对 Nginx、Envoy 及 MOSN 的平滑升级原理区别的分析，适合对 Nginx 实现原理比较感兴趣的同学阅读，需要具备一定的网络编程知识。 平滑升级的","tags":null,"title":"Nginx vs Envoy vs MOSN 平滑升级原理解析","type":"projects","url":"/projects/mosn/concept/nginx-envoy-mosn-hot-upgrade/","wordcount":1525},{"author":null,"categories":null,"content":"If you need to call SOFARPC through NodeJs, you can start by following this document.\nInstall First install the SOFARPC Node.\nhttps://github.com/sofastack/sofa-rpc-node\nUse the following command:\n$ npm install sofa-rpc-node --save Code sample Expose an RPC service and publish it to registry center \u0026amp;#39;use strict\u0026amp;#39;; const { RpcServer } = require(\u0026amp;#39;sofa-rpc-node\u0026amp;#39;).server; const { ZookeeperRegistry } = require(\u0026amp;#39;sofa-rpc-node\u0026amp;#39;).registry; const logger = console; // 1. Create a Zookeeper registry client const registry = new ZookeeperRegistry({ logger, Address: \u0026amp;#39;127.0.0.1:2181\u0026amp;#39;, // need to start a zkServer locally }); // 2. Create an RPC Server instance const server = new RpcServer({ logger, Registry, // incoming registry client  port: 12200, }); // 3. Add service server.addService({ interfaceName: \u0026amp;#39;com.nodejs.test.TestService\u0026amp;#39;, }, { async plus(a, b) { return a + b; }, }); // 4. Start the server and publish the service server.start() .then(() =\u0026amp;gt; { server.publish(); }); Call RPC service (Get service list from registry center) \u0026amp;#39;use strict\u0026amp;#39;; const { RpcClient } = require(\u0026amp;#39;sofa-rpc-node\u0026amp;#39;).client; const { ZookeeperRegistry } = require(\u0026amp;#39;sofa-rpc-node\u0026amp;#39;).registry; const logger = console; // 1. Create a Zookeeper registry client const registry = new ZookeeperRegistry({ logger, address: \u0026amp;#39;127.0.0.1:2181\u0026amp;#39;, }); async function invoke() { // 2. Create an RPC Client instance  const client = new RpcClient({ logger, registry, }); // 3. Create a service consumer  const consumer = client.createConsumer({ interfaceName: \u0026amp;#39;com.nodejs.test.TestService\u0026amp;#39;, }); // 4. Wait for the consumer ready (subscribe to the service list from registry center...)  await consumer.ready(); // 5. Execute generic call  const result = await consumer.invoke(\u0026amp;#39;plus\u0026amp;#39;, [ 1, 2 ], { responseTimeout: 3000 }); console.log(\u0026amp;#39;1 + 2 = \u0026amp;#39; + result); } invoke().catch(console.error); Call RPC service (direct call) \u0026amp;#39;use strict\u0026amp;#39;; const { RpcClient } = require(\u0026amp;#39;sofa-rpc-node\u0026amp;#39;).client; const logger = console; async function invoke() { // No need to pass in the registry instance  const client = new RpcClient({ logger, }); const consumer = client.createConsumer({ interfaceName: \u0026amp;#39;com.nodejs.test.TestService\u0026amp;#39;, serverHost: \u0026amp;#39;127.0.0.1:12200\u0026amp;#39;, // directly specify the service address  }); await consumer.ready(); const result = await consumer.invoke(\u0026amp;#39;plus\u0026amp;#39;, [ 1, 2 ], { responseTimeout: 3000 }); console.log(\u0026amp;#39;1 + 2 = \u0026amp;#39; + result); } invoke().catch(console.error); Expose and call the protobuf interface Define interface Define the interface with *.proto\nsyntax = \u0026amp;#34;proto3\u0026amp;#34;;package com.alipay.sofa.rpc.test;// optional option java_multiple_files = false;service ProtoService { rpc echoObj (EchoRequest) returns (EchoResponse) {}}message EchoRequest { string name = 1; Group group = 2;}message EchoResponse { int32 code = 1; string message = 2;}enum Group { A = 0; B = 1;}Server code \u0026amp;#39;use …","date":-62135596800,"description":"","dir":"projects/sofa-rpc/node-and-java-communicate/","fuzzywordcount":700,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"3329852e9991868a3cdc473b861ca750","permalink":"/en/projects/sofa-rpc/node-and-java-communicate/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/en/projects/sofa-rpc/node-and-java-communicate/","summary":"If you need to call SOFARPC through NodeJs, you can start by following this document.\nInstall First install the SOFARPC Node.\nhttps://github.com/sofastack/sofa-rpc-node\nUse the following command:\n$ npm install sofa-rpc-node --save Code sample Expose an RPC service and publish it to registry center \u0026#39;use strict\u0026#39;; const { RpcServer } = require(\u0026#39;sofa-rpc-node\u0026#39;).server; const { ZookeeperRegistry } = require(\u0026#39;sofa-rpc-node\u0026#39;).registry; const logger = console; // 1. Create a Zookeeper registry client const registry = new ZookeeperRegistry({ logger, Address: \u0026#39;127.","tags":null,"title":"NodeJS support","type":"projects","url":"/en/projects/sofa-rpc/node-and-java-communicate/","wordcount":624},{"author":null,"categories":null,"content":"快速上手 如果你有通过 NodeJs 调用 SOFARPC 的需求.可以按照如下的文档来开始.\n安装 首先按照文档安装\nhttps://github.com/sofastack/sofa-rpc-node\n使用命令.\n$ npm install sofa-rpc-node --save 代码示例 暴露一个 RPC 服务，并发布到注册中心 \u0026amp;#39;use strict\u0026amp;#39;; const { RpcServer } = require(\u0026amp;#39;sofa-rpc-node\u0026amp;#39;).server; const { ZookeeperRegistry } = require(\u0026amp;#39;sofa-rpc-node\u0026amp;#39;).registry; const logger = console; // 1. 创建 zk 注册中心客户端 const registry = new ZookeeperRegistry({ logger, address: \u0026amp;#39;127.0.0.1:2181\u0026amp;#39;, // 需要本地启动一个 zkServer }); // 2. 创建 RPC Server 实例 const server = new RpcServer({ logger, registry, // 传入注册中心客户端  port: 12200, }); // 3. 添加服务 server.addService({ interfaceName: \u0026amp;#39;com.nodejs.test.TestService\u0026amp;#39;, }, { async plus(a, b) { return a + b; }, }); // 4. 启动 Server 并发布服务 server.start() .then(() =\u0026amp;gt; { server.publish(); }); 调用 RPC 服务（从注册中心获取服务列表） \u0026amp;#39;use strict\u0026amp;#39;; const { RpcClient } = require(\u0026amp;#39;sofa-rpc-node\u0026amp;#39;).client; const { ZookeeperRegistry } = require(\u0026amp;#39;sofa-rpc-node\u0026amp;#39;).registry; const logger = console; // 1. 创建 zk 注册中心客户端 const registry = new ZookeeperRegistry({ logger, address: \u0026amp;#39;127.0.0.1:2181\u0026amp;#39;, }); async function invoke() { // 2. 创建 RPC Client 实例  const client = new RpcClient({ logger, registry, }); // 3. 创建服务的 consumer  const consumer = client.createConsumer({ interfaceName: \u0026amp;#39;com.nodejs.test.TestService\u0026amp;#39;, }); // 4. 等待 consumer ready（从注册中心订阅服务列表...）  await consumer.ready(); // 5. 执行泛化调用  const result = await consumer.invoke(\u0026amp;#39;plus\u0026amp;#39;, [ 1, 2 ], { responseTimeout: 3000 }); console.log(\u0026amp;#39;1 + 2 = \u0026amp;#39; + result); } invoke().catch(console.error); 调用 RPC 服务（直连模式） \u0026amp;#39;use strict\u0026amp;#39;; const { RpcClient } = require(\u0026amp;#39;sofa-rpc-node\u0026amp;#39;).client; const logger = console; async function invoke() { // 不需要传入 registry 实例了  const client = new RpcClient({ logger, }); const consumer = client.createConsumer({ interfaceName: \u0026amp;#39;com.nodejs.test.TestService\u0026amp;#39;, serverHost: \u0026amp;#39;127.0.0.1:12200\u0026amp;#39;, // 直接指定服务地址  }); await consumer.ready(); const result = await consumer.invoke(\u0026amp;#39;plus\u0026amp;#39;, [ 1, 2 ], { responseTimeout: 3000 }); console.log(\u0026amp;#39;1 + 2 = \u0026amp;#39; + result); } invoke().catch(console.error); 暴露和调用 protobuf 接口 接口定义 通过 *.proto 来定义接口\nsyntax = \u0026amp;#34;proto3\u0026amp;#34;;package com.alipay.sofa.rpc.test;// 可选 option java_multiple_files = false;service ProtoService { rpc echoObj (EchoRequest) returns (EchoResponse) {}}message EchoRequest { string name = 1; Group group = 2;}message EchoResponse { int32 code = 1; string message = 2;}enum Group { A = 0; B = 1;}服务端代码 \u0026amp;#39;use strict\u0026amp;#39;; const antpb = require(\u0026amp;#39;antpb\u0026amp;#39;); const protocol = require(\u0026amp;#39;sofa-bolt-node\u0026amp;#39;); const { RpcServer } = require(\u0026amp;#39;sofa-rpc-node\u0026amp;#39;).server; const { ZookeeperRegistry } = require(\u0026amp;#39;sofa-rpc-node\u0026amp;#39;).registry; const logger = console; // 传入 *.proto 文件存放的目录，加载接口定义 const proto = antpb.loadAll(\u0026amp;#39;/path/proto\u0026amp;#39;); // 将 proto 设置到协议中 protocol.setOptions({ proto }); const registry = new ZookeeperRegistry({ logger, address: \u0026amp;#39;127.0.0.1:2181\u0026amp;#39;, }); const server = …","date":-62135596800,"description":"","dir":"projects/sofa-rpc/node-and-java-communicate/","fuzzywordcount":800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"3329852e9991868a3cdc473b861ca750","permalink":"/projects/sofa-rpc/node-and-java-communicate/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-rpc/node-and-java-communicate/","summary":"快速上手 如果你有通过 NodeJs 调用 SOFARPC 的需求.可以按照如下的文档来开始. 安装 首先按照文档安装 https://github.com/sofastack/sofa-rpc-node 使用命令. $ npm install sofa-rpc-node --save 代码示例 暴露一个 RPC 服务，并发布到注册","tags":null,"title":"Node跨语言调用","type":"projects","url":"/projects/sofa-rpc/node-and-java-communicate/","wordcount":749},{"author":null,"categories":null,"content":"OkHttp Integration In this document will demonstrate how to use SOFATracer to track of OkHttp, this example [address] (https://github.com/sofastack-guides/sofa-tracer-guides/tree/sofaboot-2.x/tracer-sample-with-okhttp).\nAssuming you have built a simple Spring Web project based on SOFABoot, Then you can be operated by the following steps:\nDependency introduction \u0026amp;lt;!-- SOFATracer dependency --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;tracer-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!-- okhttp dependency --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.squareup.okhttp3\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;okhttp\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;3.12.1\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; Project Configuration Then, add the parameters to be used by SOFATracer in the project\u0026amp;rsquo;s application.properties file, including spring.application.name that indicates the name of the current application and logging.path that specifies the log output directory.\n# Application Name spring.application.name=HttpClientDemo # logging path logging.path=./logs # port server.port=8081 Add a Controller that provides RESTful services In the project, provide a simple Controller, for example:\n@RestController public class SampleRestController { private final AtomicLong counter = new AtomicLong(0); /** * Request http://localhost:8081/okhttp?name=sofa * @param name name * @return Map of Result */ @RequestMapping(\u0026amp;#34;/okhttp\u0026amp;#34;) public Map\u0026amp;lt;String, Object\u0026amp;gt; greeting(@RequestParam(value = \u0026amp;#34;name\u0026amp;#34;, defaultValue = \u0026amp;#34;okhttp\u0026amp;#34;) String name) { Map\u0026amp;lt;String, Object\u0026amp;gt; map = new HashMap\u0026amp;lt;\u0026amp;gt;(); map.put(\u0026amp;#34;count\u0026amp;#34;, counter.incrementAndGet()); map.put(\u0026amp;#34;name\u0026amp;#34;, name); return map; } } Construct OkHttp to initiate a call to the RESTful service above The code example is as follows:\n Construct the OkHttp Client instance:  OkHttpClientInstance httpClient = new OkHttpClientInstance(); String httpGetUrl = \u0026amp;#34;http://localhost:8081/okhttp?name=sofa\u0026amp;#34;; String responseStr = httpClient.executeGet(httpGetUrl); Run Start the SOFABoot app and see the log in the console as follows:\n2019-04-12 13:38:09.896 INFO 51193 --- [ main] o.s.j.e.a.AnnotationMBeanExporter : Registering beans for JMX exposure on startup 2019-04-12 13:38:09.947 INFO 51193 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8081 (http) 2019-04-12 13:38:09.952 INFO 51193 --- [ main] c.a.s.t.e.okhttp.OkHttpDemoApplication : Started OkHttpDemoApplication in 3.314 seconds (JVM running for 4.157) When there is a log similar to the following, the call to OkHttp is successful:\n2019-04-12 13:38:10.205 INFO 51193 --- [ main] c.a.s.t.e.okhttp.OkHttpDemoApplication : Response is {\u0026amp;quot;count\u0026amp;quot;:1,\u0026amp;quot;name\u0026amp;quot;:\u0026amp;quot;sofa\u0026amp;quot;} View log In the application.properties, the log printing directory we configured is ./logs, which is the root directory of the current application (we can configure it based on actual …","date":-62135596800,"description":"","dir":"projects/sofa-tracer/usage-of-okhttp/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"2b665b984dd33a4c04b5cd7b4de2410c","permalink":"/en/projects/sofa-tracer/usage-of-okhttp/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-tracer/usage-of-okhttp/","summary":"OkHttp Integration In this document will demonstrate how to use SOFATracer to track of OkHttp, this example [address] (https://github.com/sofastack-guides/sofa-tracer-guides/tree/sofaboot-2.x/tracer-sample-with-okhttp).\nAssuming you have built a simple Spring Web project based on SOFABoot, Then you can be operated by the following steps:\nDependency introduction \u0026lt;!-- SOFATracer dependency --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alipay.sofa\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;tracer-sofa-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- okhttp dependency --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.squareup.okhttp3\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;okhttp\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.12.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; Project Configuration Then, add the parameters to be used by SOFATracer in the project\u0026rsquo;s application.","tags":null,"title":"OkHttp Integration","type":"projects","url":"/en/projects/sofa-tracer/usage-of-okhttp/","wordcount":375},{"author":null,"categories":null,"content":"OkHttp Log Format SOFATracer integrates OkHttp and outputs the requested link log data format. The default is JSON data format.\nOkHttp digest log（okhttp-digest.log） The data is output in JSON format. Each key meaning is as follows:\n   key Meaning     time Log printing time   local.app Current application name   traceId TraceId   spanId SpanId   request.url Request URL   method Request HTTP method   result.code HTTP return status code   req.size.bytes Request Body Size   resp.size.bytes Response Body Size   time.cost.milliseconds Request time (ms)   current.thread.name Current thread name   remote.app remote app   baggage Transparently transmitted baggage data    Example:\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2019-04-12 13:38:10.187\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;OkHttpDemo\u0026amp;#34;,\u0026amp;#34;traceId\u0026amp;#34;:\u0026amp;#34;0a0fe85a1555047489980100151193\u0026amp;#34;,\u0026amp;#34;spanId\u0026amp;#34;:\u0026amp;#34;0\u0026amp;#34;,\u0026amp;#34;request.url\u0026amp;#34;:\u0026amp;#34;http://localhost:8081/okhttp?name=sofa\u0026amp;#34;,\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;GET\u0026amp;#34;,\u0026amp;#34;result.code\u0026amp;#34;:\u0026amp;#34;200\u0026amp;#34;,\u0026amp;#34;req.size.bytes\u0026amp;#34;:0,\u0026amp;#34;resp.size.bytes\u0026amp;#34;:0,\u0026amp;#34;time.cost.milliseconds\u0026amp;#34;:207,\u0026amp;#34;current.thread.name\u0026amp;#34;:\u0026amp;#34;main\u0026amp;#34;,\u0026amp;#34;remote.app\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;,\u0026amp;#34;baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;} OkHttp stat log（okhttp-stat.log） stat.key is the collection of statistical keywords in this period, which uniquely determines a set of statistical data, including local.app, request.url, and method field.\nExample:\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2019-04-12 13:39:09.720\u0026amp;#34;,\u0026amp;#34;stat.key\u0026amp;#34;:{\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;GET\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;OkHttpDemo\u0026amp;#34;,\u0026amp;#34;request.url\u0026amp;#34;:\u0026amp;#34;http://localhost:8081/okhttp?name=sofa\u0026amp;#34;},\u0026amp;#34;count\u0026amp;#34;:1,\u0026amp;#34;total.cost.milliseconds\u0026amp;#34;:207,\u0026amp;#34;success\u0026amp;#34;:\u0026amp;#34;true\u0026amp;#34;,\u0026amp;#34;load.test\u0026amp;#34;:\u0026amp;#34;F\u0026amp;#34;} ","date":-62135596800,"description":"","dir":"projects/sofa-tracer/log-format-okhttp/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"dbc9555f43d0b2eda22f10ed45713fb9","permalink":"/en/projects/sofa-tracer/log-format-okhttp/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-tracer/log-format-okhttp/","summary":"OkHttp Log Format SOFATracer integrates OkHttp and outputs the requested link log data format. The default is JSON data format.\nOkHttp digest log（okhttp-digest.log） The data is output in JSON format. Each key meaning is as follows:\n   key Meaning     time Log printing time   local.app Current application name   traceId TraceId   spanId SpanId   request.url Request URL   method Request HTTP method   result.","tags":null,"title":"OkHttp log","type":"projects","url":"/en/projects/sofa-tracer/log-format-okhttp/","wordcount":119},{"author":null,"categories":null,"content":"在本文档将演示如何使用 SOFATracer 对 OkHttp 进行埋点，本示例工程地址。\n假设你已经基于 SOFABoot 构建了一个简单的 Spring Web 工程，那么可以通过如下步骤进行操作：\n依赖引入 \u0026amp;lt;!-- SOFATracer 依赖 --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;tracer-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!-- okhttp 依赖 --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.squareup.okhttp3\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;okhttp\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;3.12.1\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 工程配置 在工程的 application.properties 文件下添加 SOFATracer 要使用的参数，包括spring.application.name 用于标示当前应用的名称；logging.path 用于指定日志的输出目录。\n# Application Name spring.application.name=OkHttpClientDemo # logging path logging.path=./logs # port server.port=8081 添加一个提供 RESTful 服务的 Controller 在工程代码中，添加一个简单的 Controller，例如：\n@RestController public class SampleRestController { private final AtomicLong counter = new AtomicLong(0); /** * Request http://localhost:8081/okhttp?name=sofa * @param name name * @return Map of Result */ @RequestMapping(\u0026amp;#34;/okhttp\u0026amp;#34;) public Map\u0026amp;lt;String, Object\u0026amp;gt; greeting(@RequestParam(value = \u0026amp;#34;name\u0026amp;#34;, defaultValue = \u0026amp;#34;okhttp\u0026amp;#34;) String name) { Map\u0026amp;lt;String, Object\u0026amp;gt; map = new HashMap\u0026amp;lt;\u0026amp;gt;(); map.put(\u0026amp;#34;count\u0026amp;#34;, counter.incrementAndGet()); map.put(\u0026amp;#34;name\u0026amp;#34;, name); return map; } } 构造 OkHttp 发起一次对上文的 RESTful 服务的调用 代码示例如下：\n 构造 OkHttp Client 调用实例：  OkHttpClientInstance httpClient = new OkHttpClientInstance(); String httpGetUrl = \u0026amp;#34;http://localhost:8081/okhttp?name=sofa\u0026amp;#34;; String responseStr = httpClient.executeGet(httpGetUrl); 运行 启动 SOFABoot 应用，在控制台中看到启动打印的日志如下：\n2019-04-12 13:38:09.896 INFO 51193 --- [ main] o.s.j.e.a.AnnotationMBeanExporter : Registering beans for JMX exposure on startup 2019-04-12 13:38:09.947 INFO 51193 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8081 (http) 2019-04-12 13:38:09.952 INFO 51193 --- [ main] c.a.s.t.e.okhttp.OkHttpDemoApplication : Started OkHttpDemoApplication in 3.314 seconds (JVM running for 4.157) 当有类似如下的日志时，说明 OkHttp 的调用成功：\n2019-04-12 13:38:10.205 INFO 51193 --- [ main] c.a.s.t.e.okhttp.OkHttpDemoApplication : Response is {\u0026amp;quot;count\u0026amp;quot;:1,\u0026amp;quot;name\u0026amp;quot;:\u0026amp;quot;sofa\u0026amp;quot;} 查看日志 在上面的 application.properties 里面，我们配置的日志打印目录是 ./logs 即当前应用的根目录（我们可以根据自己的实践需要进行配置），在当前工程的根目录下可以看到类似如下结构的日志文件：\n./logs ├── spring.log └── tracelog ├── okhttp-digest.log ├── okhttp-stat.log ├── spring-mvc-digest.log ├── spring-mvc-stat.log ├── static-info.log └── tracer-self.log 示例中通过构造 OkHttp 对象发起 RESTful 服务的调用，调用完成后可以在 okhttp-digest.log 中看到类似如下的日志:\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2019-09-03 …","date":-62135596800,"description":"","dir":"projects/sofa-tracer/usage-of-okhttp/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"2b665b984dd33a4c04b5cd7b4de2410c","permalink":"/projects/sofa-tracer/usage-of-okhttp/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-tracer/usage-of-okhttp/","summary":"在本文档将演示如何使用 SOFATracer 对 OkHttp 进行埋点，本示例工程地址。 假设你已经基于 SOFABoot 构建了一个简单的 Spring Web 工程，那么可以通过如下步骤进行操作： 依赖引入 \u0026lt;!-- SOFATracer 依","tags":null,"title":"OkHttp 埋点接入","type":"projects","url":"/projects/sofa-tracer/usage-of-okhttp/","wordcount":578},{"author":null,"categories":null,"content":"SOFATracer 集成 OkHttp 后输出请求的链路数据格式，默认为 JSON 数据格式。\nOkHttp 摘要日志（okhttp-digest.log） 以 JSON 格式输出的数据，相应 key 的含义解释如下：\n   key 表达含义     time 日志打印时间   local.app 当前应用名   traceId TraceId   spanId SpanId   request.url 请求 URL   method 请求 HTTP 方法   result.code HTTP 返回状态码   req.size.bytes Request Body 大小   resp.size.bytes Response Body 大小   time.cost.milliseconds 请求耗时（ms）   current.thread.name 当前线程名   remote.app 目标应用   baggage 透传的 baggage 数据    样例：\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2019-09-03 11:35:28.429\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;OkHttpDemo\u0026amp;#34;,\u0026amp;#34;traceId\u0026amp;#34;:\u0026amp;#34;0a0fe9271567481728265100112783\u0026amp;#34;,\u0026amp;#34;spanId\u0026amp;#34;:\u0026amp;#34;0\u0026amp;#34;,\u0026amp;#34;span.kind\u0026amp;#34;:\u0026amp;#34;client\u0026amp;#34;,\u0026amp;#34;result.code\u0026amp;#34;:\u0026amp;#34;200\u0026amp;#34;,\u0026amp;#34;current.thread.name\u0026amp;#34;:\u0026amp;#34;main\u0026amp;#34;,\u0026amp;#34;time.cost.milliseconds\u0026amp;#34;:\u0026amp;#34;164ms\u0026amp;#34;,\u0026amp;#34;request.url\u0026amp;#34;:\u0026amp;#34;http://localhost:8081/okhttp?name=sofa\u0026amp;#34;,\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;GET\u0026amp;#34;,\u0026amp;#34;result.code\u0026amp;#34;:\u0026amp;#34;200\u0026amp;#34;,\u0026amp;#34;req.size.bytes\u0026amp;#34;:0,\u0026amp;#34;resp.size.bytes\u0026amp;#34;:0,\u0026amp;#34;remote.app\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;,\u0026amp;#34;sys.baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;,\u0026amp;#34;biz.baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;} OkHttp 统计日志（okhttp-stat.log） stat.key 即本段时间内的统计关键字集合，统一关键字集合唯一确定一组统计数据，包含local.app、request.url、和 method 字段.\n样例：\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2019-09-03 11:43:06.975\u0026amp;#34;,\u0026amp;#34;stat.key\u0026amp;#34;:{\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;GET\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;OkHttpDemo\u0026amp;#34;,\u0026amp;#34;request.url\u0026amp;#34;:\u0026amp;#34;http://localhost:8081/okhttp?name=sofa\u0026amp;#34;},\u0026amp;#34;count\u0026amp;#34;:1,\u0026amp;#34;total.cost.milliseconds\u0026amp;#34;:174,\u0026amp;#34;success\u0026amp;#34;:\u0026amp;#34;true\u0026amp;#34;,\u0026amp;#34;load.test\u0026amp;#34;:\u0026amp;#34;F\u0026amp;#34;} ","date":-62135596800,"description":"","dir":"projects/sofa-tracer/log-format-okhttp/","fuzzywordcount":300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"dbc9555f43d0b2eda22f10ed45713fb9","permalink":"/projects/sofa-tracer/log-format-okhttp/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-tracer/log-format-okhttp/","summary":"SOFATracer 集成 OkHttp 后输出请求的链路数据格式，默认为 JSON 数据格式。 OkHttp 摘要日志（okhttp-digest.log） 以 JSON 格式输出的数据，相应 key 的含义解释如下","tags":null,"title":"OkHttp 日志","type":"projects","url":"/projects/sofa-tracer/log-format-okhttp/","wordcount":242},{"author":null,"categories":null,"content":"OpenFeign Integration In this document will demonstrate how to use SOFATracer to track of OpenFeign.\nPrepare Environment The versions of the framework components used in this case are as follows:\n Spring Cloud Greenwich.RELEASE SOFABoot 3.1.1/SpringBoot 2.1.0.RELEASE SOFATracer 3.0.4 JDK 8  This case includes two submodules:\n tracer-sample-with-openfeign-provider service provider tracer-sample-with-openfeign-consumer service consumer  New SOFABoot project as parent project After creating a Spring Boot project, you need to introduce the SOFABoot\u0026amp;rsquo;s dependency. First, you need to unzip the generated zip package of Spring Boot project and modify the Maven project configuration file pom.xml.\n\u0026amp;lt;parent\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-starter-parent\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${spring.boot.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;relativePath/\u0026amp;gt; \u0026amp;lt;/parent\u0026amp;gt; Replace the above with the followings:\n\u0026amp;lt;parent\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofaboot-dependencies\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${sofa.boot.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/parent\u0026amp;gt; The ${sofa.boot.version} specifies the latest version of SOFABoot. For more information about SOFABoot versions, refer to Release notes.\nNew tracer-sample-with-openfeign-provider Module   Introducing dependence\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;tracer-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.cloud\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-cloud-starter-zookeeper-discovery\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.cloud\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-cloud-starter-openfeign\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  SOFATracer versions are controlled by SOFABoot versions. If the SOFABoot versions used do not match, you need to manually specify a tracer version that is higher than 3.0.4.\n   application.properties Configuration\nspring.application.name=tracer-provider server.port=8800 spring.cloud.zookeeper.connect-string=localhost:2181 spring.cloud.zookeeper.discovery.enabled=true spring.cloud.zookeeper.discovery.instance-id=tracer-provider   Simple resource class\n@RestController public class UserController { @RequestMapping(\u0026amp;#34;/feign\u0026amp;#34;) public String testFeign(HttpServletRequest request) { return \u0026amp;#34;hello tracer feign\u0026amp;#34;; } }   New tracer-sample-with-openfeign-consumer Module   Introducing dependence\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;tracer-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.cloud\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-cloud-starter-zookeeper-discovery\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.cloud\u0026amp;lt;/groupId\u0026amp;gt; …","date":-62135596800,"description":"","dir":"projects/sofa-tracer/usage-of-openfeign/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"75d9940033ad3b4342eab9d5c7a191f1","permalink":"/en/projects/sofa-tracer/usage-of-openfeign/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-tracer/usage-of-openfeign/","summary":"OpenFeign Integration In this document will demonstrate how to use SOFATracer to track of OpenFeign.\nPrepare Environment The versions of the framework components used in this case are as follows:\n Spring Cloud Greenwich.RELEASE SOFABoot 3.1.1/SpringBoot 2.1.0.RELEASE SOFATracer 3.0.4 JDK 8  This case includes two submodules:\n tracer-sample-with-openfeign-provider service provider tracer-sample-with-openfeign-consumer service consumer  New SOFABoot project as parent project After creating a Spring Boot project, you need to introduce the SOFABoot\u0026rsquo;s dependency.","tags":null,"title":"OpenFeign Integration","type":"projects","url":"/en/projects/sofa-tracer/usage-of-openfeign/","wordcount":366},{"author":null,"categories":null,"content":"OpenFeign Log Format SOFATracer integrates Spring Cloud OpenFeign and outputs the requested link log data format. The default is JSON data format.\nSpring Cloud OpenFeign digest log（feign-digest.log） The data is output in JSON format. Each key meaning is as follows:\n   key Meaning     time Log printing time   local.app Current application name   traceId TraceId   spanId SpanId   request.url Request URL   method Request HTTP method   result.code HTTP return status code   error error massage   req.size.bytes Request Body Size   resp.size.bytes Response Body Size   time.cost.milliseconds Request time (ms)   current.thread.name Current thread name   remote.host remote host   remote.port remote port   component.client.impl component name   baggage Transparently transmitted baggage data    Example:\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2019-03-28 18:08:06.800\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;tracer-consumer\u0026amp;#34;,\u0026amp;#34;traceId\u0026amp;#34;:\u0026amp;#34;0a0fe88f1553767685981100124403\u0026amp;#34;,\u0026amp;#34;spanId\u0026amp;#34;:\u0026amp;#34;0.1\u0026amp;#34;,\u0026amp;#34;request.url\u0026amp;#34;:\u0026amp;#34;http://10.15.232.143:8800/feign\u0026amp;#34;,\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;GET\u0026amp;#34;,\u0026amp;#34;result.code\u0026amp;#34;:\u0026amp;#34;200\u0026amp;#34;,\u0026amp;#34;error\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;,\u0026amp;#34;req.size.bytes\u0026amp;#34;:0,\u0026amp;#34;resp.size.bytes\u0026amp;#34;:18,\u0026amp;#34;time.cost.milliseconds\u0026amp;#34;:206,\u0026amp;#34;current.thread.name\u0026amp;#34;:\u0026amp;#34;http-nio-8082-exec-1\u0026amp;#34;,\u0026amp;#34;remote.host\u0026amp;#34;:\u0026amp;#34;10.15.232.143\u0026amp;#34;,\u0026amp;#34;remote.port\u0026amp;#34;:\u0026amp;#34;8800\u0026amp;#34;,\u0026amp;#34;component.client.impl\u0026amp;#34;:\u0026amp;#34;open-feign\u0026amp;#34;,\u0026amp;#34;baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;} Spring Cloud OpenFeign stat log（feign-stat.log） stat.key is the collection of statistical keywords in this period, which uniquely determines a set of statistical data, including local.app, request.url, and method field.\nExample:\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2019-03-28 18:09:06.800\u0026amp;#34;,\u0026amp;#34;stat.key\u0026amp;#34;:{\u0026amp;#34;request.url\u0026amp;#34;:\u0026amp;#34;http://10.15.232.143:8800/feign\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;tracer-consumer\u0026amp;#34;,\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;GET\u0026amp;#34;},\u0026amp;#34;count\u0026amp;#34;:1,\u0026amp;#34;total.cost.milliseconds\u0026amp;#34;:206,\u0026amp;#34;success\u0026amp;#34;:\u0026amp;#34;Y\u0026amp;#34;,\u0026amp;#34;load.test\u0026amp;#34;:\u0026amp;#34;F\u0026amp;#34;} ","date":-62135596800,"description":"","dir":"projects/sofa-tracer/log-format-openfeign/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"81864817e297a7bf019705c72f8ff0a8","permalink":"/en/projects/sofa-tracer/log-format-openfeign/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-tracer/log-format-openfeign/","summary":"OpenFeign Log Format SOFATracer integrates Spring Cloud OpenFeign and outputs the requested link log data format. The default is JSON data format.\nSpring Cloud OpenFeign digest log（feign-digest.log） The data is output in JSON format. Each key meaning is as follows:\n   key Meaning     time Log printing time   local.app Current application name   traceId TraceId   spanId SpanId   request.url Request URL   method Request HTTP method   result.","tags":null,"title":"OpenFeign log","type":"projects","url":"/en/projects/sofa-tracer/log-format-openfeign/","wordcount":134},{"author":null,"categories":null,"content":"在本文档将演示如何使用 SOFATracer 对 Spring Cloud OpenFeign 进行埋点。\n基础环境 本案例使用的各框架组件的版本如下：\n Spring Cloud Greenwich.RELEASE SOFABoot 3.1.1/SpringBoot 2.1.0.RELEASE SOFATracer 3.0.4 JDK 8  本案例包括两个子工程：\n tracer-sample-with-openfeign-provider 服务提供方 tracer-sample-with-openfeign-consumer 服务调用方  新建 SOFABoot 工程作为父工程 在创建好一个 Spring Boot 的工程之后，接下来就需要引入 SOFABoot 的依赖，首先，需要将上文中生成的 Spring Boot 工程的 zip 包解压后，修改 Maven 项目的配置文件 pom.xml，将\n\u0026amp;lt;parent\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-starter-parent\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${spring.boot.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;relativePath/\u0026amp;gt; \u0026amp;lt;/parent\u0026amp;gt; 替换为：\n\u0026amp;lt;parent\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofaboot-dependencies\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${sofa.boot.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/parent\u0026amp;gt; 这里的 ${sofa.boot.version} 指定具体的 SOFABoot 版本，参考发布历史。\n新建 tracer-sample-with-openfeign-provider   在工程模块的 pom 文件中添加 SOFATracer 依赖\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;tracer-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.cloud\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-cloud-starter-zookeeper-discovery\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.cloud\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-cloud-starter-openfeign\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  SOFATracer 版本受 SOFABoot 版本管控，如果使用的 SOFABoot 版本不匹配，则需要手动指定 tracer 版本，且版本需高于 3.0.4.\n   在工程的 application.properties 文件下添加相关参数\nspring.application.name=tracer-provider server.port=8800 spring.cloud.zookeeper.connect-string=localhost:2181 spring.cloud.zookeeper.discovery.enabled=true spring.cloud.zookeeper.discovery.instance-id=tracer-provider   简单的资源类\n@RestController public class UserController { @RequestMapping(\u0026amp;#34;/feign\u0026amp;#34;) public String testFeign(HttpServletRequest request) { return \u0026amp;#34;hello tracer feign\u0026amp;#34;; } }   新建 tracer-sample-with-openfeign-consumer   在工程模块的 pom 文件中添加 SOFATracer 依赖\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;tracer-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.cloud\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-cloud-starter-zookeeper-discovery\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.cloud\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-cloud-starter-openfeign\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   在工程的 application.properties 文件下添加相关参数\nspring.application.name=tracer-consumer server.port=8082 spring.cloud.zookeeper.connect-string=localhost:2181 spring.cloud.zookeeper.discovery.enabled=true spring.cloud.zookeeper.discovery.instance-id=tracer-consumer   定义 feign 资源\n@FeignClient(value = \u0026amp;#34;tracer-provider\u0026amp;#34;,fallback = FeignServiceFallbackFactory.class) public interface FeignService { @RequestMapping(value = \u0026amp;#34;/feign\u0026amp;#34;, method = RequestMethod.GET) String …","date":-62135596800,"description":"","dir":"projects/sofa-tracer/usage-of-openfeign/","fuzzywordcount":700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"75d9940033ad3b4342eab9d5c7a191f1","permalink":"/projects/sofa-tracer/usage-of-openfeign/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-tracer/usage-of-openfeign/","summary":"在本文档将演示如何使用 SOFATracer 对 Spring Cloud OpenFeign 进行埋点。 基础环境 本案例使用的各框架组件的版本如下： Spring Cloud Greenwich.RELEASE SOFABoot 3.1.1/SpringBoot 2.1.0.RELEASE SOFATracer 3.0.4 JDK 8 本案例包括两个子工程： tracer-sample-with-openfeign-provider 服务提供方 tracer-sample-with-openfeign-consumer","tags":null,"title":"OpenFeign 埋点接入","type":"projects","url":"/projects/sofa-tracer/usage-of-openfeign/","wordcount":600},{"author":null,"categories":null,"content":"SOFATracer 集成 Spring Cloud OpenFeign 后输出请求的链路数据格式，默认为 JSON 数据格式。\nSpring Cloud OpenFeign 摘要日志（feign-digest.log） 以 JSON 格式输出的数据，相应 key 的含义解释如下：\n   key 表达含义     time 日志打印时间   local.app 当前应用名   traceId TraceId   spanId SpanId   span.kind Span 类型   result.code 状态码   current.thread.name 当前线程名   time.cost.milliseconds span 耗时   request.url 请求地址   method http method   error 错误信息   req.size.bytes 请求大小   resp.size.bytes 响应大小   sys.baggage 系统透传的 baggage 数据   biz.baggage 业务透传的 baggage 数据    样例：\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2019-09-03 10:28:52.363\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;tracer-consumer\u0026amp;#34;,\u0026amp;#34;traceId\u0026amp;#34;:\u0026amp;#34;0a0fe9271567477731347100110969\u0026amp;#34;,\u0026amp;#34;spanId\u0026amp;#34;:\u0026amp;#34;0.1\u0026amp;#34;,\u0026amp;#34;span.kind\u0026amp;#34;:\u0026amp;#34;client\u0026amp;#34;,\u0026amp;#34;result.code\u0026amp;#34;:\u0026amp;#34;200\u0026amp;#34;,\u0026amp;#34;current.thread.name\u0026amp;#34;:\u0026amp;#34;http-nio-8082-exec-1\u0026amp;#34;,\u0026amp;#34;time.cost.milliseconds\u0026amp;#34;:\u0026amp;#34;219ms\u0026amp;#34;,\u0026amp;#34;request.url\u0026amp;#34;:\u0026amp;#34;http://10.15.233.39:8800/feign\u0026amp;#34;,\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;GET\u0026amp;#34;,\u0026amp;#34;error\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;,\u0026amp;#34;req.size.bytes\u0026amp;#34;:0,\u0026amp;#34;resp.size.bytes\u0026amp;#34;:18,\u0026amp;#34;remote.host\u0026amp;#34;:\u0026amp;#34;10.15.233.39\u0026amp;#34;,\u0026amp;#34;remote.port\u0026amp;#34;:\u0026amp;#34;8800\u0026amp;#34;,\u0026amp;#34;sys.baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;,\u0026amp;#34;biz.baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;} Spring Cloud OpenFeign 统计日志（feign-stat.log）ls stat.key 即本段时间内的统计关键字集合，统一关键字集合唯一确定一组统计数据，包含local.app、request.url、和 method 字段.\n样例：\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2019-09-03 10:29:34.528\u0026amp;#34;,\u0026amp;#34;stat.key\u0026amp;#34;:{\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;GET\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;tracer-consumer\u0026amp;#34;,\u0026amp;#34;request.url\u0026amp;#34;:\u0026amp;#34;http://10.15.233.39:8800/feign\u0026amp;#34;},\u0026amp;#34;count\u0026amp;#34;:2,\u0026amp;#34;total.cost.milliseconds\u0026amp;#34;:378,\u0026amp;#34;success\u0026amp;#34;:\u0026amp;#34;true\u0026amp;#34;,\u0026amp;#34;load.test\u0026amp;#34;:\u0026amp;#34;F\u0026amp;#34;} ","date":-62135596800,"description":"","dir":"projects/sofa-tracer/log-format-openfeign/","fuzzywordcount":300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"81864817e297a7bf019705c72f8ff0a8","permalink":"/projects/sofa-tracer/log-format-openfeign/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-tracer/log-format-openfeign/","summary":"SOFATracer 集成 Spring Cloud OpenFeign 后输出请求的链路数据格式，默认为 JSON 数据格式。 Spring Cloud OpenFeign 摘要日志（feign-digest.log） 以 JSON 格式输出的数据，相应 key 的含义解","tags":null,"title":"OpenFeign 日志","type":"projects","url":"/projects/sofa-tracer/log-format-openfeign/","wordcount":253},{"author":null,"categories":null,"content":"MOSN\u0026amp;rsquo;s official website mosn.io is under construction. The documents are temporarily hosted here.\nMOSN is a network proxy written in Golang. It can be used as a cloud-native network data plane, providing services with the following proxy functions: multi-protocol, modular, intelligent, and secure. MOSN is the short name of Modular Open Smart Network-proxy. MOSN can be integrated with any Service Mesh wich support xDS API. It can also be used as an independent Layer 4 or Layer 7 load balancer, API Gateway, cloud-native Ingress, etc.\nCore competence  Integrated with Istio  Integrated with Istio 1.0 and V4 APIs to run based on full dynamic resource configuration   Core forwarding  Self-contained Web server Support TCP proxy Support TProxy mode   Multi-protocol  Support HTTP/1.1 and HTTP/2 Support SOFARPC Support Dubbo protocol (under development)   Core routing  Support Virtual Host routing Support Headers/URL/Prefix routing Support Host Metadata-based Subset routing Support retry   Backend Management and load balancing  Support connection pool Support throttling Support active backend health check Support load balancing strategies, such as Random and RR Support Host Metadata-based Subset load balancing strategy   Observability  Observe network data Observing protocol data   TLS  Support HTTP/1.1 on TLS Support HTTP/2.0 on TLS Support SOFARPC on TLS   Process management + Support smooth reload + Support smooth upgrade Extension capability + Support custom private protocols + Support adding custom extensions in protocol at the TCP IO layer  Acknowledgement MOSN builds on open source projects such as Envoy and Istio, thanks to the efforts of the open source community.\n","date":-62135596800,"description":"","dir":"projects/mosn/overview/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"f25c59cbb758b4dae5de39e1f1c3a2f4","permalink":"/en/projects/mosn/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/mosn/overview/","summary":"MOSN\u0026rsquo;s official website mosn.io is under construction. The documents are temporarily hosted here.\nMOSN is a network proxy written in Golang. It can be used as a cloud-native network data plane, providing services with the following proxy functions: multi-protocol, modular, intelligent, and secure. MOSN is the short name of Modular Open Smart Network-proxy. MOSN can be integrated with any Service Mesh wich support xDS API. It can also be used as an independent Layer 4 or Layer 7 load balancer, API Gateway, cloud-native Ingress, etc.","tags":null,"title":"Overview","type":"projects","url":"/en/projects/mosn/overview/","wordcount":245},{"author":null,"categories":null,"content":"MOSN\u0026amp;rsquo;s official website mosn.io is under construction. The documents are temporarily hosted here.\nMOSN is a network proxy written in Golang. It can be used as a cloud-native network data plane, providing services with the following proxy functions: multi-protocol, modular, intelligent, and secure. MOSN is the short name of Modular Open Smart Network-proxy. MOSN can be integrated with any Service Mesh wich support xDS API. It can also be used as an independent Layer 4 or Layer 7 load balancer, API Gateway, cloud-native Ingress, etc.\nCore competence  Integrated with Istio  Integrated with Istio 1.0 and V4 APIs to run based on full dynamic resource configuration   Core forwarding  Self-contained Web server Support TCP proxy Support TProxy mode   Multi-protocol  Support HTTP/1.1 and HTTP/2 Support SOFARPC Support Dubbo protocol (under development)   Core routing  Support Virtual Host routing Support Headers/URL/Prefix routing Support Host Metadata-based Subset routing Support retry   Backend Management and load balancing  Support connection pool Support throttling Support active backend health check Support load balancing strategies, such as Random and RR Support Host Metadata-based Subset load balancing strategy   Observability  Observe network data Observing protocol data   TLS  Support HTTP/1.1 on TLS Support HTTP/2.0 on TLS Support SOFARPC on TLS   Process management + Support smooth reload + Support smooth upgrade Extension capability + Support custom private protocols + Support adding custom extensions in protocol at the TCP IO layer  Acknowledgement MOSN builds on open source projects such as Envoy and Istio, thanks to the efforts of the open source community.\n","date":-62135596800,"description":"","dir":"projects/occlum/overview/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"1d8851c81ed6dacf04ebbe841d1b2835","permalink":"/en/projects/occlum/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/occlum/overview/","summary":"MOSN\u0026rsquo;s official website mosn.io is under construction. The documents are temporarily hosted here.\nMOSN is a network proxy written in Golang. It can be used as a cloud-native network data plane, providing services with the following proxy functions: multi-protocol, modular, intelligent, and secure. MOSN is the short name of Modular Open Smart Network-proxy. MOSN can be integrated with any Service Mesh wich support xDS API. It can also be used as an independent Layer 4 or Layer 7 load balancer, API Gateway, cloud-native Ingress, etc.","tags":null,"title":"Overview","type":"projects","url":"/en/projects/occlum/overview/","wordcount":245},{"author":null,"categories":null,"content":"Introduction SOFALookout is a lightweight and open source middleware service of Ant Financial that solves the metrics and monitoring issues of the system. The services it provides include: Event logging, collecting, processing, storing, and querying of Metrics. The open source project consists of two separate parts, the client and server side services.\nClient-side service SOFALookout Client is a Java SDK that helps developers log events of metrics in project code. It also allows you to view real-time status information for the Java application.\n +------------------+ Reg: API: | dimension meters +--------+ +------------------+ | flatmap +---------------------------+ +-----------\u0026amp;gt; | Default/DropwizardMetrics| | +---------------------------+ | | http +--------------+ +-----------\u0026amp;gt; |Lookout server| | +--------------+ +----------------------+ | add common tags dimension EXTS: | JVM,OS,GC... +----+ +----------------------+ Server-side services SOFALookout Server helps you solve system state metrics in a distributed environment. Its data sources include, but not limited to the projects that use the lookout-client package. The server will be available in the next release, so stay tuned.\n","date":-62135596800,"description":"","dir":"projects/sofa-lookout/overview/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"8a8a8ef02ca95d4d11e3e4b195bbae70","permalink":"/en/projects/sofa-lookout/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-lookout/overview/","summary":"Introduction SOFALookout is a lightweight and open source middleware service of Ant Financial that solves the metrics and monitoring issues of the system. The services it provides include: Event logging, collecting, processing, storing, and querying of Metrics. The open source project consists of two separate parts, the client and server side services.\nClient-side service SOFALookout Client is a Java SDK that helps developers log events of metrics in project code. It also allows you to view real-time status information for the Java application.","tags":null,"title":"Overview","type":"projects","url":"/en/projects/sofa-lookout/overview/","wordcount":160},{"author":null,"categories":null,"content":"SOFARPC is a Java-based RPC service framework open sourced by Ant Financial, which provides remote service call between applications, high scalability and fault tolerance features. Currently, all RPC calls of Ant Financial businesses use SOFARPC. SOFARPC provides users with functions such as load balancing, traffic forwarding, link tracing, link data transparent transmission, and fault removal.\nIn addition, SOFARPC supports different protocols, currently including bolt, RESTful, dubbo, and H2C. Bolt is a network communication framework based on Netty developed by Ant Financial Services Group.\nImplementation principle  When an SOFARPC application is started, if the current application needs to publish RPC services, SOFARPC will register these services to the service registry center. As shown in the figure, the service points to the Registry. When the SOFARPC application that references this service is started, it subscribes to the metadata information of the corresponding service from the service registry. After receiving the subscription request, the service registry will push the publisher\u0026amp;rsquo;s metadata list to the service reference party in real time. As shown in the figure, Register points to Reference. When the service reference party gets the addresses, it can pick up the address and initiate the call. As shown in the figure, Reference points to Service.  ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/overview/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"62f0806ad40fcaaeab6a82470b14a2e2","permalink":"/en/projects/sofa-rpc/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/overview/","summary":"SOFARPC is a Java-based RPC service framework open sourced by Ant Financial, which provides remote service call between applications, high scalability and fault tolerance features. Currently, all RPC calls of Ant Financial businesses use SOFARPC. SOFARPC provides users with functions such as load balancing, traffic forwarding, link tracing, link data transparent transmission, and fault removal.\nIn addition, SOFARPC supports different protocols, currently including bolt, RESTful, dubbo, and H2C. Bolt is a network communication framework based on Netty developed by Ant Financial Services Group.","tags":null,"title":"Overview","type":"projects","url":"/en/projects/sofa-rpc/overview/","wordcount":203},{"author":null,"categories":null,"content":"Introduction This sample project shows how to build an executable-ark-jar based on a springboot project with the tool of sofa-ark-maven-plugin.\nPreparation As this project depends on the ark-plugin generated by the project of sample-ark-plugin, please ensure the sample sample-ark-plugin installed in your local maven repository before run this project.\nTools The Maven plugin of sofa-ark-maven-plugin is provided to build a standard executable-ark-jar, and just needs some simple configurations. Its maven coordinates is:\n\u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${sofa.ark.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/plugin\u0026amp;gt;  Refer to the document of plugin use for details\n Step By Step Based on the sample project, we will describe step by step how to package a Spring Boot Web project to an executable Ark package\nCreating Spring Boot Web Project Download a standard Spring Boot Web project from the official website https://start.spring.io/\nIntroducing sample-ark-plugin Configure items as follows under the main pom.xml of the project, and add the Ark Plugin dependency generated from another sample project, reference documents\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sample-ark-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;classifier\u0026amp;gt;ark-plugin\u0026amp;lt;/classifier\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${sofa.ark.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; Configuring Packaging Plugin Configure the Maven plugin (sofa-Ark-maven-plugin) as follows under the main pom.xml of the project:\n\u0026amp;lt;build\u0026amp;gt; \u0026amp;lt;plugins\u0026amp;gt; \u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;executions\u0026amp;gt; \u0026amp;lt;execution\u0026amp;gt; \u0026amp;lt;id\u0026amp;gt;default-cli\u0026amp;lt;/id\u0026amp;gt; \u0026amp;lt;!--goal executed to generate executable-ark-jar --\u0026amp;gt; \u0026amp;lt;goals\u0026amp;gt; \u0026amp;lt;goal\u0026amp;gt;repackage\u0026amp;lt;/goal\u0026amp;gt; \u0026amp;lt;/goals\u0026amp;gt; \u0026amp;lt;configuration\u0026amp;gt; \u0026amp;lt;!--specify destination where executable-ark-jar will be saved, default saved to ${project.build.directory}--\u0026amp;gt; \u0026amp;lt;outputDirectory\u0026amp;gt;./target\u0026amp;lt;/outputDirectory\u0026amp;gt; \u0026amp;lt;!--default none--\u0026amp;gt; \u0026amp;lt;arkClassifier\u0026amp;gt;executable-ark\u0026amp;lt;/arkClassifier\u0026amp;gt; \u0026amp;lt;/configuration\u0026amp;gt; \u0026amp;lt;/execution\u0026amp;gt; \u0026amp;lt;/executions\u0026amp;gt; \u0026amp;lt;/plugin\u0026amp;gt; \u0026amp;lt;/plugins\u0026amp;gt; \u0026amp;lt;/build\u0026amp;gt; In this sample project, we have configured only a fraction of the items, but they are enough to generate an executable Ark package. The meaning of each configuration item is shown below:\n  outputDirectory: the directory for the output Ark package files after packaging of mvn package;\n  arkClassifier: the value of classifier included in the Maven coordinates of the Ark specified for release, which is null by default;\n  Note that arkClassifier is null by default. If you do not specify a classifier, the Jar package uploaded to the repository is actually an executable Ark package. If you need to distinguish it from common packaging, you need to configure a value for this …","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-ark-demo/","fuzzywordcount":800,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"2c97c409788f41051c79836d277997be","permalink":"/en/projects/sofa-boot/sofa-ark-ark-demo/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/en/projects/sofa-boot/sofa-ark-ark-demo/","summary":"Introduction This sample project shows how to build an executable-ark-jar based on a springboot project with the tool of sofa-ark-maven-plugin.\nPreparation As this project depends on the ark-plugin generated by the project of sample-ark-plugin, please ensure the sample sample-ark-plugin installed in your local maven repository before run this project.\nTools The Maven plugin of sofa-ark-maven-plugin is provided to build a standard executable-ark-jar, and just needs some simple configurations. Its maven coordinates is:","tags":null,"title":"Package into Ark JAR","type":"projects","url":"/en/projects/sofa-boot/sofa-ark-ark-demo/","wordcount":757},{"author":null,"categories":null,"content":"Introduction This sample project demonstrates how to use Maven plugins to package a general Java project into an Ark plugin that meets the standard specifications.\nBackground In actual development, dependency conflicts often occur. Suppose we have developed a class library named sample-lib, and it might conflict with the existing dependencies when the business application is imported. At this point, we hope the library can be isolated from other business dependencies, without negotiating with each other over dependency package versions. Ark Plugin is exactly the result of our best practice under this demand background. It runs on top of the Ark Container, which is loaded by a container. Any Ark Plugin is loaded by a separate ClassLoader to be isolated from each other. There are four concepts of Ark Plugin:\n  Import class: When the plugin starts up, a plugin used to export the class is first delegated to load the class. If that fails, it will attempt to load from inside this plugin;\n  Export class: If the class has been imported by other plugins, it will be first loaded from this plugin;\n  Import resource: When the plugin is searching for resources, a plugin used to export the class is first delegated to load the class. If that fails, it will attempt to load from inside this plugin.\n  Export resource: If the resource has been imported by other plugins, it will be first loaded from this plugin;\n   Refer to the plugin specifications for more details\n Tools Upon simple configurations, the officially provided Maven plugin sofa-ark-plugin-maven-plugin can package common Java projects into a standard-format Ark Plugin. The coordinates of Maven plugin are:\n\u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-plugin-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${sofa.ark.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/plugin\u0026amp;gt;  For more information, see the plugin configuration document\n Getting started Based on this sample project, we will describe how to build an Ark plugin step by step.\nCreate a Standard Maven Project This is a standard Maven project consisting of two modules:\n  The common module: contains the plugin export class\n  The plugin module: contains com.alipay.sofa.ark.spi.service.PluginActivator interface implementation class and a plugin service class. The plugin packaging tool sofa-ark-plugin-maven-plugin can be configured in the module\u0026amp;rsquo;s pom.xml file;\n  Configuring Packaging Plugin Package the plugin in the pom.xml file according to the following configurations:\n\u0026amp;lt;build\u0026amp;gt; \u0026amp;lt;plugins\u0026amp;gt; \u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-plugin-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${project.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;executions\u0026amp;gt; \u0026amp;lt;execution\u0026amp;gt; \u0026amp;lt;id\u0026amp;gt;default-cli\u0026amp;lt;/id\u0026amp;gt; \u0026amp;lt;goals\u0026amp;gt; \u0026amp;lt;goal\u0026amp;gt;ark-plugin\u0026amp;lt;/goal\u0026amp;gt; \u0026amp;lt;/goals\u0026amp;gt; \u0026amp;lt;configuration\u0026amp;gt; \u0026amp;lt;!--can only configure no more than one activator--\u0026amp;gt; …","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-ark-plugin-demo/","fuzzywordcount":700,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"d8125843ced13352dd228299f222c74d","permalink":"/en/projects/sofa-boot/sofa-ark-ark-plugin-demo/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/en/projects/sofa-boot/sofa-ark-ark-plugin-demo/","summary":"Introduction This sample project demonstrates how to use Maven plugins to package a general Java project into an Ark plugin that meets the standard specifications.\nBackground In actual development, dependency conflicts often occur. Suppose we have developed a class library named sample-lib, and it might conflict with the existing dependencies when the business application is imported. At this point, we hope the library can be isolated from other business dependencies, without negotiating with each other over dependency package versions.","tags":null,"title":"Package into Ark Plugin","type":"projects","url":"/en/projects/sofa-boot/sofa-ark-ark-plugin-demo/","wordcount":661},{"author":null,"categories":null,"content":"SOFA Mesh 项目 fork 了 Istio 项目，对 Pilot 的能力进行增强，目前在进行中的增强主要集中在下面三个方面：\n 支持 Zookeeper 作为注册中心，并在此基础上支持 SOFA、DUBBO 等使用 Zookeeper 作为注册中心的微服务框架。 支持通用协议框架，使用一个通用协议，在 Kubernetes DNS 的基础上同时支持多种协议。 新增 register agent，支持 SOFA、DUBBO 和 HSF 的容器模型，即支持单个应用注册多个服务实例。  ","date":-62135596800,"description":"","dir":"projects/sofa-mesh/pilot-readme/","fuzzywordcount":200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"7b098e394986596d8fb01e1fe2120829","permalink":"/projects/sofa-mesh/pilot-readme/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-mesh/pilot-readme/","summary":"SOFA Mesh 项目 fork 了 Istio 项目，对 Pilot 的能力进行增强，目前在进行中的增强主要集中在下面三个方面： 支持 Zookeeper 作为注册中心，并在此基础上支持 SOFA、DUBBO 等","tags":null,"title":"Pilot 介绍","type":"projects","url":"/projects/sofa-mesh/pilot-readme/","wordcount":165},{"author":null,"categories":null,"content":"Print traceId And spanId To Application Log SLF4J provides MDC (Mapped Diagnostic Contexts), which supports you to define and modify log output formats and content. This document introduces the SLF4J MDC feature integrated in SOFATracer, which allows you to output the current SOFATracer context TraceId and SpanId with simply modifying the log configuration file.\nPrerequisites In order to properly print the TraceId and SpanId parameters in the logs of the application, the log programming interface needs to be programmed for SLF4J. That is, the programming interface for printing log does not rely on specific log implementation.\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.slf4j\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;slf4j-api\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; Introduce dependency For SOFABoot or Spring Boot application, you need to introduce the specific log implementation. It is recommended to introduce Logback and Log4j2 instead of Log4j. Also, it is suggested to use only one log implementation rather than multiple implementations.\n Logback implementation:  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-starter-logging\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  Log4j2 implementation:  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-starter-log4j2\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;!--SOFABoot does not control log4j2 version --\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;1.4.2.RELEASE\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; Configuration method The corresponding TraceId and SpanId are printed based on SLF4J MDC. First, the log programming interface in application should be oriented to SLF4J, as follows:\n/ / Introduce interface import org.slf4j.Logger; import org.slf4j.LoggerFactory; / / Construct log printing instance private static final Logger logger = LoggerFactory.getLogger(XXX.class); Second, to correctly print the TraceId and SpanId parameters, we also need to configure the extra parameters of PatternLayout in the log configuration file. The two parameters are %X{SOFA-TraceId} and %X. {SOFA-SpanId}, whose values ​​can be obtained from MDC.\npattern parameter configured with Logback as an example:\n\u0026amp;lt;pattern\u0026amp;gt;%d{yyyy-MM-dd HH:mm:ss.SSS} %5p [%X{SOFA-TraceId}, %X{SOFA-SpanId}] ---- %m%n\u0026amp;lt;/pattern\u0026amp;gt;  Key configuration items: As a part of the Logback pattern, [%X{SOFA-TraceId},%X{SOFA-SpanId}] replaces the placeholders in the pattern with the specific TraceId and SpanId in the current thread process when the corresponding appender is called. If there is no corresponding TraceId and SpanId in the current thread, the placeholder is replaced with \u0026amp;ldquo;null\u0026amp;rdquo;.  Log4j2 PatternLayout configuration sample:\n\u0026amp;lt;PatternLayout pattern=\u0026amp;#34;%d{yyyy-MM-dd HH:mm:ss.SSS} %5p [%X{SOFA-TraceId},%X{SOFA-SpanId}] ---- %m%n \u0026amp;#34; /\u0026amp;gt; Log4j PatternLayout configuration sample:\n\u0026amp;lt;layout class=\u0026amp;#34;org.apache.log4j.PatternLayout\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;param name=\u0026amp;#34;ConversionPattern\u0026amp;#34; …","date":-62135596800,"description":"","dir":"projects/sofa-tracer/print-traceid-spanid/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"0d8cc680f811d1db2cffddbba269571c","permalink":"/en/projects/sofa-tracer/print-traceid-spanid/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-tracer/print-traceid-spanid/","summary":"Print traceId And spanId To Application Log SLF4J provides MDC (Mapped Diagnostic Contexts), which supports you to define and modify log output formats and content. This document introduces the SLF4J MDC feature integrated in SOFATracer, which allows you to output the current SOFATracer context TraceId and SpanId with simply modifying the log configuration file.\nPrerequisites In order to properly print the TraceId and SpanId parameters in the logs of the application, the log programming interface needs to be programmed for SLF4J.","tags":null,"title":"Print traceId and spanId in application log","type":"projects","url":"/en/projects/sofa-tracer/print-traceid-spanid/","wordcount":360},{"author":null,"categories":null,"content":"Describe several methods to use SOFARPC in different environments.\n Use API in non-Spring environment Use XML in SOFABoot environment Use Annotation in SOFABoot environment Use dynamic API in SOFABoot environment  ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/programming/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"9a947dae761c84aa4d95121c076ac552","permalink":"/en/projects/sofa-rpc/programming/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/programming/","summary":"Describe several methods to use SOFARPC in different environments.\n Use API in non-Spring environment Use XML in SOFABoot environment Use Annotation in SOFABoot environment Use dynamic API in SOFABoot environment  ","tags":null,"title":"Programming","type":"projects","url":"/en/projects/sofa-rpc/programming/","wordcount":30},{"author":null,"categories":null,"content":"Configure HTTP protocol Mesher  See the sample project that MOSN forwards HTTP http-sample.  Configure SOFARPC protocol Mesher  See the sample project that MOSN forwards SOFARPC sofarpc-sample.  Configure TCP protocol Mesher  See the sample project that MOSN serves as a TCP Proxy tcpproxy-sample.  ","date":-62135596800,"description":"","dir":"projects/mosn/quick-start-run-samples/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"600c182fdee786a59e14899ba0fce8a1","permalink":"/en/projects/mosn/quick-start-run-samples/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/mosn/quick-start-run-samples/","summary":"Configure HTTP protocol Mesher  See the sample project that MOSN forwards HTTP http-sample.  Configure SOFARPC protocol Mesher  See the sample project that MOSN forwards SOFARPC sofarpc-sample.  Configure TCP protocol Mesher  See the sample project that MOSN serves as a TCP Proxy tcpproxy-sample.  ","tags":null,"title":"Project sample","type":"projects","url":"/en/projects/mosn/quick-start-run-samples/","wordcount":42},{"author":null,"categories":null,"content":"Configure HTTP protocol Mesher  See the sample project that MOSN forwards HTTP http-sample.  Configure SOFARPC protocol Mesher  See the sample project that MOSN forwards SOFARPC sofarpc-sample.  Configure TCP protocol Mesher  See the sample project that MOSN serves as a TCP Proxy tcpproxy-sample.  ","date":-62135596800,"description":"","dir":"projects/occlum/quick-start-run-samples/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"93784b2fca67986e00aa3bc5ea0dbb6b","permalink":"/en/projects/occlum/quick-start-run-samples/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/occlum/quick-start-run-samples/","summary":"Configure HTTP protocol Mesher  See the sample project that MOSN forwards HTTP http-sample.  Configure SOFARPC protocol Mesher  See the sample project that MOSN forwards SOFARPC sofarpc-sample.  Configure TCP protocol Mesher  See the sample project that MOSN serves as a TCP Proxy tcpproxy-sample.  ","tags":null,"title":"Project sample","type":"projects","url":"/en/projects/occlum/quick-start-run-samples/","wordcount":42},{"author":null,"categories":null,"content":"Some sample projects are provided in the source project to assist in the use of the project. The readme file of the sample project has additional instructions for use, and you need to import these sample projects separately into IDE.\nClient-side sample project  lookout-client-samples-java   This sample project demonstrates how to use and configure the client in code form in a normal Java project.\n lookout-client-samples-boot   This sample project demonstrates how to use and configure the client in a SpringBoot (or SofaBoot) project.\n lookout-client-samples-prometheus   The sample project demonstrates how to use and configure the client to use prometheus in a SpringBoot (or SofaBoot) project.\nServer-side sample project ","date":-62135596800,"description":"","dir":"projects/sofa-lookout/use-guide-samples/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"a8a0fcd3f99ce2fb46e4d543e30797c9","permalink":"/en/projects/sofa-lookout/use-guide-samples/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-lookout/use-guide-samples/","summary":"Some sample projects are provided in the source project to assist in the use of the project. The readme file of the sample project has additional instructions for use, and you need to import these sample projects separately into IDE.\nClient-side sample project  lookout-client-samples-java   This sample project demonstrates how to use and configure the client in code form in a normal Java project.\n lookout-client-samples-boot   This sample project demonstrates how to use and configure the client in a SpringBoot (or SofaBoot) project.","tags":null,"title":"Project sample","type":"projects","url":"/en/projects/sofa-lookout/use-guide-samples/","wordcount":105},{"author":null,"categories":null,"content":"proxy 是 MOSN 最常用的 network filter，其配置格式如下。\n{ \u0026amp;#34;downstream_protocol\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;upstream_protocol\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;router_config_name\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;extend_config\u0026amp;#34;:{} }  downstream_protocol 描述 proxy 期望收到的请求协议，在连接收到数据时，会使用此协议去解析数据包并完成转发，如果收到的数据包协议和配置不符，MOSN 会将连接断开。 upstream_protocol 描述 proxy 将以何种协议转发数据，通常情况下应该和downstream_protocol 保持一致，只有特殊的场景会进行对应协议的转换。 router_config_name 描述 proxy 的路由配置的索引，通常情况下，这个配置会和同 listener 下的 connection_manager 中配置的 router_config_name 保持一致。 extend_config 扩展配置，目前仅在 MOSN 的 XProtocol 协议中使用。  ","date":-62135596800,"description":"","dir":"projects/mosn/configuration/listener/network-filter/proxy/","fuzzywordcount":300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"b04f78179a47a64d7e209b6660bfa80f","permalink":"/projects/mosn/configuration/listener/network-filter/proxy/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/mosn/configuration/listener/network-filter/proxy/","summary":"proxy 是 MOSN 最常用的 network filter，其配置格式如下。 { \u0026#34;downstream_protocol\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;upstream_protocol\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;router_config_name\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;extend_config\u0026#34;:{} } downstream_protocol 描述 proxy 期望收到的请求协议，在连接收到数据时，会使用此协议去解析数据包并完成转发，","tags":null,"title":"proxy","type":"projects","url":"/projects/mosn/configuration/listener/network-filter/proxy/","wordcount":221},{"author":null,"categories":null,"content":"﻿SOFABoot provides developers with three ways to publish and reference JVM services\n XML Annotation Programming API  XML Service Publish First, we need to define a Bean:\n\u0026amp;lt;bean id=\u0026amp;#34;sampleService\u0026amp;#34; class=\u0026amp;#34;com.alipay.sofa.runtime.test.service.SampleServiceImpl\u0026amp;#34;\u0026amp;gt; Then, publish the Bean as a SOFA JVM service by using the Spring extension tag provided by SOFA.\n\u0026amp;lt;sofa:service interface=\u0026amp;#34;com.alipay.sofa.runtime.test.service.SampleService\u0026amp;#34; ref=\u0026amp;#34;sampleService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.jvm/\u0026amp;gt; \u0026amp;lt;/sofa:service\u0026amp;gt; In the preceding configuration, the interface parameter indicates the interface for releasing services, and the ref parameter indicates the Bean to be published as a JVM service.\nAt this point, we have published a JVM service success.\nService Reference We can also reference a JVM service by using the Spring extension tag provided by SOFA.\n\u0026amp;lt;sofa:reference interface=\u0026amp;#34;com.alipay.sofa.runtime.test.service.SampleService\u0026amp;#34; id=\u0026amp;#34;sampleServiceRef\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.jvm/\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt; In the preceding configuration, the interface parameter indicates the service interface, which must be consistent with that configured during the service publish. The meaning of the ID attribute is the same as Spring BeanId. A Spring Bean with the ID sampleServiceRef will be generated from the above configuration. We can inject it anywhere in the Spring context of the current SOFABoot module.\n service/reference tag also supports RPC service publish, with related document: RPC Service Publish and Reference\n Annotation  Warning\nIf a service has been annotated with @SofaService, it cannot be published in the mode of XML. Choose one mode to publish the service instead of a mixture of two modes.\n In addition to publishing JVM services and reference through XML, SOFABoot also provides Annotation for JVM services publish and reference. To publish JVM services through Annotation, we only need to add an annotation @SofaService to the implementation class, as follows:\n@SofaService public class SampleImpl implements SampleInterface { public void test() { } }  Prompt\n@SofaService is used to publish a Spring Bean as a JVM service, which means that although you may not write the configuration of \u0026amp;lt;sofa:service/\u0026amp;gt;, you still need to configure the class annotated with @SofaService as a Spring Bean.\n When configuring \u0026amp;lt;sofa:service/\u0026amp;gt; in the XML mode, you have configured an interface for the service. However, when using the @SofaService annotation, you haven\u0026amp;rsquo;t configured the service interface. This is because when the class annotated with @SofaService has implemented only one interface, the framework directly uses the interface as the service interface. What if the class annotated with @SofaService has implemented multiple interfaces? In this case, you can set the interfaceType field of @SofaService to specify the service interface, as shown below:\n@SofaService(interfaceType=SampleInterface.class) public …","date":-62135596800,"description":"","dir":"projects/sofa-boot/module-service/","fuzzywordcount":1100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"527472fbe57ce450e4e2b41d878704cb","permalink":"/en/projects/sofa-boot/module-service/","publishdate":"0001-01-01T00:00:00Z","readingtime":5,"relpermalink":"/en/projects/sofa-boot/module-service/","summary":"﻿SOFABoot provides developers with three ways to publish and reference JVM services\n XML Annotation Programming API  XML Service Publish First, we need to define a Bean:\n\u0026lt;bean id=\u0026#34;sampleService\u0026#34; class=\u0026#34;com.alipay.sofa.runtime.test.service.SampleServiceImpl\u0026#34;\u0026gt; Then, publish the Bean as a SOFA JVM service by using the Spring extension tag provided by SOFA.\n\u0026lt;sofa:service interface=\u0026#34;com.alipay.sofa.runtime.test.service.SampleService\u0026#34; ref=\u0026#34;sampleService\u0026#34;\u0026gt; \u0026lt;sofa:binding.jvm/\u0026gt; \u0026lt;/sofa:service\u0026gt; In the preceding configuration, the interface parameter indicates the interface for releasing services, and the ref parameter indicates the Bean to be published as a JVM service.","tags":null,"title":"Publish and reference JVM services","type":"projects","url":"/en/projects/sofa-boot/module-service/","wordcount":1001},{"author":null,"categories":null,"content":"To run this demo, you should sign up an Ant Financial technology account. Please see Ant Finanical Official Site to see more details.\nDemo content Service Mesh applies the communication capabilities between services to the infrastructure, thus decoupling and lightweighting applications.\nHowever, Service Mesh itself is still complex. CloudMesh can easily implement Service Mesh technology by hosting Service Mesh on the cloud.\nWith our workshop, you can easily deploy applications developed in multiple programming languages ​​to CloudMesh, thereby experiencing the capabilities of Service Mesh. The capabilities include accessing services, monitoring traffic, experiencing service goverance, managing Sidecar, and gray release of new versions of services.\nThis demo focuses on the powerful traffic control capability of CloudMesh. In the process of gray release, you can precisely control the gray traffic ratio, and monitor the actual traffic trend in CloudMesh:\nThe general gray release function occupies twice capacity in the gray process.\nThe gray release function of CloudMesh does not need to occupy extra capacity in gray release process, and also allows pausing the release process to modify gray ratio multiple times.\nOperation guide For convenience, we have prepared a detailed operation guide for this demo.\nClick here to visit online version.\n","date":-62135596800,"description":"This guide introduces how to quickly deploy applications to CloudMesh, access services, monitor traffic, experience service governance, manage Sidecar, and perform gray release of new versions of services.","dir":"guides/kc-cloud-mesh-demo/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"e389a65e6736e909718275cd76505525","permalink":"/en/guides/kc-cloud-mesh-demo/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/guides/kc-cloud-mesh-demo/","summary":"To run this demo, you should sign up an Ant Financial technology account. Please see Ant Finanical Official Site to see more details.\nDemo content Service Mesh applies the communication capabilities between services to the infrastructure, thus decoupling and lightweighting applications.\nHowever, Service Mesh itself is still complex. CloudMesh can easily implement Service Mesh technology by hosting Service Mesh on the cloud.\nWith our workshop, you can easily deploy applications developed in multiple programming languages ​​to CloudMesh, thereby experiencing the capabilities of Service Mesh.","tags":null,"title":"Put Service Mesh into practice with CloudMesh","type":"guides","url":"/en/guides/kc-cloud-mesh-demo/","wordcount":199},{"author":null,"categories":null,"content":"This topic comprises four parts:\n Part 1: Install the ACTS IDE visual editor on Intellij IDEA. Part 2: Import the ACTS dependency to a multi-module project. Part 3: Establish the ACTS framework in the test module to manage ACTS test cases. Part 4: Generate the ACTS test script.  1. Install ACTS IDE We recommend that you use Intellij IDEA 2017. For the sake of your data security, please download the ACTS IDE installation package from the following source only: Click to download ACTS IDE.\nLocal installation: Choose Preferences \u0026amp;gt; Plugins. Install the plugin from disk and restart Intellij IDEA. 2. Import the ACTS dependency Before introducing the dependencies, make sure your application is a multi-module project (including the test module). After you import the dependency, ACTS places all test code under the test module for convenient ACTS test case management.\nYou can read the following information based on the actual situation of your application:\nIf your application is a complete multi-module project, you can refer to section 2.1 to import the ACTS dependency. If your application is a multi-module project without a test module, you can refer to section 2.2 to quickly create a test module. If your application is not a multi-module project, you can refer to section 2.3 to quickly create a multi-module project. If you have not created a project yet, you can use SOFABoot to quickly create an application.\n2.1 Multi-module application - with the test module You only need to import acts-bom to the pom.xml file of the test module.\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa.acts\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;acts-bom\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${acts.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;type\u0026amp;gt;pom\u0026amp;lt;/type\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 2.2 Multi-module application - without the test module Here, Intellij IDEA is used to create the submodule.\nRight click the parent project, choose New \u0026amp;gt; Module, and enter the name for the test module, which follows the pattern of appname-test. The step-by-step procedure is illustrated in the following figures.\nStep 1: Create a test module Step 2: Manage the test module Manage the test module that you have created in the pom.xml file under the parent project.\nStep 3: Import the ACTS dependency Find the test module that you just created and import acts-bom to its pom.xml file.\n\u0026amp;lt;! -- Import the pom file that contains SOFABootApplication --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.example\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;example-service\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;! -- Import the ACTS dependency --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa.acts\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;acts-bom\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${acts.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;type\u0026amp;gt;pom\u0026amp;lt;/type\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 2.3 Single-module application If you already have a sound single-module SOFABoot application, you can quickly create a multi-module project based on the existing project in the following …","date":-62135596800,"description":"","dir":"projects/sofa-acts/getting-started/","fuzzywordcount":700,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"dfc5fb9b394ea14c280568dcb881a8b0","permalink":"/en/projects/sofa-acts/getting-started/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/en/projects/sofa-acts/getting-started/","summary":"This topic comprises four parts:\n Part 1: Install the ACTS IDE visual editor on Intellij IDEA. Part 2: Import the ACTS dependency to a multi-module project. Part 3: Establish the ACTS framework in the test module to manage ACTS test cases. Part 4: Generate the ACTS test script.  1. Install ACTS IDE We recommend that you use Intellij IDEA 2017. For the sake of your data security, please download the ACTS IDE installation package from the following source only: Click to download ACTS IDE.","tags":null,"title":"Quick start","type":"projects","url":"/en/projects/sofa-acts/getting-started/","wordcount":650},{"author":null,"categories":null,"content":"This topic helps you quickly download, install, and use SOFADashboard on your computer.\nPrepare the environment sofa-dashboard-backend needs to be run in a Java environment. Make sure that it can be used normally in the following runtime environments:\n JDK 1.8+: Download and Configure. Maven 3.2.5+: Download and Configure.  sofa-dashboard-frontend uses the Ant Design Pro scaffold. For more information about the frontend environment, see Ant Design.\nInitialize the database  MySQL version: 5.6+\n SOFAArk control uses MySQL for resource data storage. You can find the SofaDashboardDB.sql script under the project directory and run this script to initialize database tables.\nZooKeeper  ZooKeeper 3.4.x and ZooKeeper 3.5.x\n Service governance and SOFAArk control of SOFADashboard are dependent on ZooKeeper, therefore you need to start the ZooKeeper service locally. For more information, see ZooKeeper Document.\nRun the backend project \u0026amp;gt; git clone https://github.com/sofastack/sofa-dashboard.git \u0026amp;gt; cd sofa-dashboard \u0026amp;gt; mvn clean package -DskipTests \u0026amp;gt; cd sofa-dashboard-backend/sofa-dashboard-web/target/ \u0026amp;gt; java -jar sofa-dashboard-web-1.0.0-SNAPSHOT.jar Run the frontend project sofa-dashboard-front is the frontend code-based project of SOFADashboard. It is developed based on the open-source frontend framework antd of Ant Financial.\n\u0026amp;gt; cd sofa-dashboard-front \u0026amp;gt; npm i \u0026amp;gt; npm start ","date":-62135596800,"description":"","dir":"projects/sofa-dashboard/quick-start/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"fa4c5f48810727f71d675255f19617a3","permalink":"/en/projects/sofa-dashboard/quick-start/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-dashboard/quick-start/","summary":"This topic helps you quickly download, install, and use SOFADashboard on your computer.\nPrepare the environment sofa-dashboard-backend needs to be run in a Java environment. Make sure that it can be used normally in the following runtime environments:\n JDK 1.8+: Download and Configure. Maven 3.2.5+: Download and Configure.  sofa-dashboard-frontend uses the Ant Design Pro scaffold. For more information about the frontend environment, see Ant Design.\nInitialize the database  MySQL version: 5.","tags":null,"title":"Quick start","type":"projects","url":"/en/projects/sofa-dashboard/quick-start/","wordcount":186},{"author":null,"categories":null,"content":"This article is intended to help developers who are new to the MOSN project to quickly build a development environment, and compile, test, package, and run sample code.\nNote: MOSN is developed based on Go 1.12.7 and uses dep for dependency management.\nPrepare running environment  If you use a container to run MOSN, you must install Docker first. If you use a local machine, you must use a Unix-like environment. Install Go\u0026amp;rsquo;s build environment. Install dep. See the official installation documentation.  Get codes The codes for the MOSN project are hosted in GitHub and can be obtained in the following way:\ngo get mosn.io/mosn If an error occurs when run \u0026amp;ldquo;go get\u0026amp;rdquo;, just create the project manually.\n# Enter src dirctory under GOPATH cd $GOPATH/src # Create mosn.io dirctory mkdir -p mosn.io cd mosn.io # clone MOSN codes git clone git@github.com:mosn/mosn.git cd sofa-mosn The final path of MOSN source codes is $GOPATH/src/mosn.io/mosn.\nImport by using IDE Use the Golang IDE to import the $GOPATH/src/mosn.io/mosn project. Goland is recommended.\nCompile codes In the project root directory, select the following command to compile the MOSN binary file according to your machine type and the environment where you want to execute binary:\nCompile with Docker image\nmake build // compile linux 64bit executable binary non-docker, local compilation\nCompile local executable binary files.\nmake build-local Non-Linux machine compiles Linux 64-bit executable binary files crosswise.\nmake build-linux64 Non-Linux machine compiles Linux 32-bit executable binary files crosswise.\nmake build-linux32 Once compiled, the compiled binary files can be found in the build/bundles/${version}/binary directory.\nCreate image Run the following command to create an image:\nmake image Run test In the project root directory, run the unit test:\nmake unit-test In the project root directory, run the integrate test(slow):\nmake integrate Start MOSN from configuration file ./mosn start -c \u0026amp;#39;$CONFIG_FILE\u0026amp;#39; Start MOSN forwarding sample program See the sample project in the examples directory.\nUse MOSN to build a Service Mesh platform See Integrate Istio.\n","date":-62135596800,"description":"","dir":"projects/mosn/quick-start-setup/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"d41615315adb522aa4b84762f113a574","permalink":"/en/projects/mosn/quick-start-setup/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/mosn/quick-start-setup/","summary":"This article is intended to help developers who are new to the MOSN project to quickly build a development environment, and compile, test, package, and run sample code.\nNote: MOSN is developed based on Go 1.12.7 and uses dep for dependency management.\nPrepare running environment  If you use a container to run MOSN, you must install Docker first. If you use a local machine, you must use a Unix-like environment.","tags":null,"title":"Quick start guide","type":"projects","url":"/en/projects/mosn/quick-start-setup/","wordcount":325},{"author":null,"categories":null,"content":"This article is intended to help developers who are new to the MOSN project to quickly build a development environment, and compile, test, package, and run sample code.\nNote: MOSN is developed based on Go 1.12.7 and uses dep for dependency management.\nPrepare running environment  If you use a container to run MOSN, you must install Docker first. If you use a local machine, you must use a Unix-like environment. Install Go\u0026amp;rsquo;s build environment. Install dep. See the official installation documentation.  Get codes The codes for the MOSN project are hosted in GitHub and can be obtained in the following way:\ngo get mosn.io/mosn If an error occurs when run \u0026amp;ldquo;go get\u0026amp;rdquo;, just create the project manually.\n# Enter src dirctory under GOPATH cd $GOPATH/src # Create mosn.io dirctory mkdir -p mosn.io cd mosn.io # clone MOSN codes git clone git@github.com:mosn/mosn.git cd sofa-mosn The final path of MOSN source codes is $GOPATH/src/mosn.io/mosn.\nImport by using IDE Use the Golang IDE to import the $GOPATH/src/mosn.io/mosn project. Goland is recommended.\nCompile codes In the project root directory, select the following command to compile the MOSN binary file according to your machine type and the environment where you want to execute binary:\nCompile with Docker image\nmake build // compile linux 64bit executable binary non-docker, local compilation\nCompile local executable binary files.\nmake build-local Non-Linux machine compiles Linux 64-bit executable binary files crosswise.\nmake build-linux64 Non-Linux machine compiles Linux 32-bit executable binary files crosswise.\nmake build-linux32 Once compiled, the compiled binary files can be found in the build/bundles/${version}/binary directory.\nCreate image Run the following command to create an image:\nmake image Run test In the project root directory, run the unit test:\nmake unit-test In the project root directory, run the integrate test(slow):\nmake integrate Start MOSN from configuration file ./mosn start -c \u0026amp;#39;$CONFIG_FILE\u0026amp;#39; Start MOSN forwarding sample program See the sample project in the examples directory.\nUse MOSN to build a Service Mesh platform See Integrate Istio.\n","date":-62135596800,"description":"","dir":"projects/occlum/quick-start-setup/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"cd757e2e2cca38a99b2de1c0be1f6807","permalink":"/en/projects/occlum/quick-start-setup/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/occlum/quick-start-setup/","summary":"This article is intended to help developers who are new to the MOSN project to quickly build a development environment, and compile, test, package, and run sample code.\nNote: MOSN is developed based on Go 1.12.7 and uses dep for dependency management.\nPrepare running environment  If you use a container to run MOSN, you must install Docker first. If you use a local machine, you must use a Unix-like environment.","tags":null,"title":"Quick start guide","type":"projects","url":"/en/projects/occlum/quick-start-setup/","wordcount":325},{"author":null,"categories":null,"content":"﻿In this document, we will create a Spring Boot project and introduce the basic dependencies of SOFABoot as well as its Health Check expansion capability, to demonstrate how to get started quickly with SOFABoot.\nEnvironment Preparation To use SOFABoot, we need to prepare the basic environment first. SOFABoot depends on the following environment:\n JDK7 or JDK8 Needs to be compiled with Apache Maven 3.2.5 or above  Create Project SOFABoot is directly built on Spring Boot, so it can be generated by Spring Boot Generators. In this document, we need to add a web dependency for final view of its effect in the browser.\nAdd SOFABoot dependencies When creating a Spring Boot project, we need to import SOFABoot dependencies. First, extract the \u0026amp;lsquo;zip\u0026amp;rsquo; package of the project generated above and modify the \u0026amp;lsquo;pom.xml\u0026amp;rsquo; file, or the maven project configuration file. Replace\n\u0026amp;lt;parent\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-starter-parent\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${spring.boot.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;relativePath/\u0026amp;gt; \u0026amp;lt;/parent\u0026amp;gt; as:\n\u0026amp;lt;parent\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofaboot-dependencies\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${sofa.boot.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/parent\u0026amp;gt; Here, ${sofa.boot.version} denotes the SOFABoot version (please refer to release note). Then, add a SOFABoot dependency of Health Check extension and Spring Boot Web Starter.\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;healthcheck-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-starter-web\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; Finally, configure parameters commonly used in the SOFABoot project in the application.properties file. The spring.application.name parameter is required to name the current application; the logging path specifies the output directory for logging information.\n# Application Name spring.application.name=SOFABoot Demo # logging path logging.path=./logs Advice to refer to the SOFABoot Module document before learn this demo.\nRun it We can import the project into IDE and run the \u0026amp;lsquo;main\u0026amp;rsquo; method in the generated project (generally in the XXXApplication class) to start the application, or we can execute the mvn spring-boot:run command under the project\u0026amp;rsquo;s root directory, which will print the startup logging in the console:\n2018-04-05 21:36:26.572 INFO ---- Initializing ProtocolHandler [\u0026amp;quot;http-nio-8080\u0026amp;quot;] 2018-04-05 21:36:26.587 INFO ---- Starting ProtocolHandler [http-nio-8080] 2018-04-05 21:36:26.608 INFO ---- Using a shared selector for servlet write/read 2018-04-05 21:36:26.659 INFO ---- Tomcat started on port(s): 8080 (http) We can browse http://localhost:8080/sofaboot/versions to view the version summary generated by Maven plugin in SOFABoot. The result is like the …","date":-62135596800,"description":"","dir":"projects/sofa-boot/quick-start/","fuzzywordcount":1400,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"7f582b905fde4a56791c03d4dd6b5a57","permalink":"/en/projects/sofa-boot/quick-start/","publishdate":"0001-01-01T00:00:00Z","readingtime":7,"relpermalink":"/en/projects/sofa-boot/quick-start/","summary":"﻿In this document, we will create a Spring Boot project and introduce the basic dependencies of SOFABoot as well as its Health Check expansion capability, to demonstrate how to get started quickly with SOFABoot.\nEnvironment Preparation To use SOFABoot, we need to prepare the basic environment first. SOFABoot depends on the following environment:\n JDK7 or JDK8 Needs to be compiled with Apache Maven 3.2.5 or above  Create Project SOFABoot is directly built on Spring Boot, so it can be generated by Spring Boot Generators.","tags":null,"title":"Quick start guide","type":"projects","url":"/en/projects/sofa-boot/quick-start/","wordcount":1379},{"author":null,"categories":null,"content":"SOFATracer integration component list reference:Introduction To SOFATracer, Please pay attention to the SOFATracer version and JDK version of different components when using.\nPrepare Environment To use SOFABoot, you need to prepare the basic environment first. SOFABoot relies on the following environments:\n JDK7 or JDK8 Apache Maven 3.2.5+ required for compilation  Samples List The following Samples projects are all SOFABoot projects (also supported in the SpringBoot project). For information on how to create SOFABoot projects, please refer to SOFABoot quick start.\n Component Integration  Spring MVC Integration HttpClient Integration DataSource Integration RestTemplate Integration OkHttp Integration SOFARPC Integration Dubbo Integration Spring Cloud OpenFeign Integration   Sampling Report Data To Zipkin  ","date":-62135596800,"description":"","dir":"projects/sofa-tracer/componentaccess/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"42fbb0f6b6d459b7b04d45cad143d4ff","permalink":"/en/projects/sofa-tracer/componentaccess/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-tracer/componentaccess/","summary":"SOFATracer integration component list reference:Introduction To SOFATracer, Please pay attention to the SOFATracer version and JDK version of different components when using.\nPrepare Environment To use SOFABoot, you need to prepare the basic environment first. SOFABoot relies on the following environments:\n JDK7 or JDK8 Apache Maven 3.2.5+ required for compilation  Samples List The following Samples projects are all SOFABoot projects (also supported in the SpringBoot project). For information on how to create SOFABoot projects, please refer to SOFABoot quick start.","tags":null,"title":"Quick start guide","type":"projects","url":"/en/projects/sofa-tracer/componentaccess/","wordcount":106},{"author":null,"categories":null,"content":"Quick start for client Common Java Project Add the Maven dependency of the client to the application:\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa.lookout\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;lookout-client\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${lookout.client.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; Lookout-client relies on the lookout-reg-server module by default (supports reporting metrics data to the lookout server). If you want to use a different type of registry (such as lookout-reg-prometheus), then add the corresponding dependency.\nBefore starting to use the SOFALookout Client, you must firstly build a global client instance (com.alipay.lookout.client.DefaultLookoutClient).\nLookoutConfig lookoutConfig = new LookoutConfig(); DefaultLookoutClient client = new DefaultLookoutClient(\u0026amp;#34;appName\u0026amp;#34;); // Choose to build the Registry you need to use (if you need multiple registry types, it is recommended to use the same lookoutConfig instance for centralized management). LookoutRegistry lookoutRegistry = new LookoutRegistry(lookoutConfig); // Client can add a registry instance (at least one) after the client is created. client.addRegistry(lookoutRegistry); // (Optional) Uniformly register the metrics of extended modules for the registry instances that have been added or will be added to the client. client.registerExtendedMetrics(); Then get the Registry instance through the client and use it:\n// The registry is a \u0026amp;#34;combination\u0026amp;#34; registry Registry registry = client.getRegistry(); //demo Id id = registry.createId(\u0026amp;#34;http_requests_total\u0026amp;#34;); Counter counter = registry.counter(id); counter.inc(); For the use of the client, see Project sample.\n","date":-62135596800,"description":"","dir":"projects/sofa-lookout/quick-start-client-java/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"5dc476aa21ece4789859f1af598d4445","permalink":"/en/projects/sofa-lookout/quick-start-client-java/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-lookout/quick-start-client-java/","summary":"Quick start for client Common Java Project Add the Maven dependency of the client to the application:\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alipay.sofa.lookout\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lookout-client\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${lookout.client.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; Lookout-client relies on the lookout-reg-server module by default (supports reporting metrics data to the lookout server). If you want to use a different type of registry (such as lookout-reg-prometheus), then add the corresponding dependency.\nBefore starting to use the SOFALookout Client, you must firstly build a global client instance (com.","tags":null,"title":"Quick start guide for common Java project","type":"projects","url":"/en/projects/sofa-lookout/quick-start-client-java/","wordcount":197},{"author":null,"categories":null,"content":"This project demonstrates how to use SOFALookout in SOFABoot and connect to the Actuator of Spring Boot. If you want to connect to Prometheus or other Registry, see the Registry section.\nCreate a SpringBoot (or SofaBoot) project Create a new Spring Boot application (In case of SOFABoot project, import to SOFABoot as described in SOFABoot Documentation - Dependency Management.\nIntroduce Lookout\u0026amp;rsquo;s Starter dependency Introduce the following dependency in pom.xml:\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa.lookout\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;lookout-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; In case of Spring Boot project, it is required to specify a version.\nCreate a Metrics indicator After completing the introduction of dependencies, you can add the following methods to the startup class in Spring Boot:\n@Autowired private Registry registry; @PostConstruct public void init() { Counter counter = registry.counter(registry.createId(\u0026amp;#34;http_requests_total\u0026amp;#34;).withTag(\u0026amp;#34;instant\u0026amp;#34;, NetworkUtil.getLocalAddress().getHostName())); counter.inc(); } The above code directly injects a Registry field through @Autowired. Through the Registry field, you can create the corresponding Counter, and then modify the Counter data to generate the Metrics of the SOFALookout.\nAdd configuration item In SOFABoot project, you need to add a configuration item for the application name: spring.application.name=xxx.\nConnect to Spring Boot Actuator After adding a new indicator, you can choose to connect to the Spring Boot Actuator. Then the following dependency is required:\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-starter-actuator\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; After adding the above dependency, you can launch the application locally, visit http://localhost:8080/metrics, and you can see the metrics added earlier, as follows:\n\u0026amp;quot;http_requests_total.instant-MacBook-Pro-4.local\u0026amp;quot;: 1, The above codes are at lookout-client-samples-boot, you can Download them as a reference.\n","date":-62135596800,"description":"","dir":"projects/sofa-lookout/quick-start-client-boot/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"27e057f8a8a4ac97f42ea66ca6a17fdd","permalink":"/en/projects/sofa-lookout/quick-start-client-boot/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-lookout/quick-start-client-boot/","summary":"This project demonstrates how to use SOFALookout in SOFABoot and connect to the Actuator of Spring Boot. If you want to connect to Prometheus or other Registry, see the Registry section.\nCreate a SpringBoot (or SofaBoot) project Create a new Spring Boot application (In case of SOFABoot project, import to SOFABoot as described in SOFABoot Documentation - Dependency Management.\nIntroduce Lookout\u0026rsquo;s Starter dependency Introduce the following dependency in pom.xml:\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.","tags":null,"title":"Quick start guide for SOFABoot project","type":"projects","url":"/en/projects/sofa-lookout/quick-start-client-boot/","wordcount":244},{"author":null,"categories":null,"content":"Raft 新特性 复制状态机 1. 复制状态机通过日志实现  每台机器一份日志 每个日志条目包含一条命令 状态机按顺序执行命令  2.应用于实际系统的一致性算法一般有以下特性  确保安全性 高可用性 不依赖时序保证一致性 一条命令能够尽可能快的在大多数节点对一轮RPC调用响应时完成  Paxos 算法的不足  算法复杂度高, 较难理解 工程复杂度高, 难以在实际环境中实现  Raft 设计原则  概念分解  Leader election Log replication Membership changes   通过减少状态数量将状态空间简化  日志不允许出现空洞, 并且 raft 限制了日志不一致的可能性 使用随机化时钟简化了领导选举的算法    Raft 一致性算法 State (状态)  在所有服务器上持久存储的(响应RPC之前稳定存储的)\n   currentTerm 服务器最后知道的任期号(从0开始递增)     votedFor 在当前任期内收到选票的候选人Id(如果没有就为null)   log[] 日志条目, 每个条目包含状态机要执行的命令以及从Leader收到日志时的任期号    在所有服务器上不稳定存在的\n   commitIndex 已知被提交的最大日志条目索引     lastApplied 已被状态机执行的最大日志条目索引    在Leader服务器上不稳定存在的\n   nextIndex[] 对于每一个follower, 记录需要发给他的下一条日志条目的索引     matchIndex[] 对于每一个follower, 记录已经复制完成的最大日志条目索引    AppendEntries RPC (日志复制) 由leader通过RPC向follower复制日志, 也会用作heartbeat\n 入参\n   term Leader任期号     leaderId Leader id, 为了能帮助客户端重定向到Leader服务器   prevLogIndex 前一个日志的索引   prevLogTerm 前一个日志所属的任期   entries[] 将要存储的日志条目列表(为空时代表heartbeat, 有时候为了效率会发送超过一条)   leaderCommit Leader已提交的日志条目索引    返回值\n   term 当前的任期号, 用于leader更新自己的任期号     success 如果其他follower包含能够匹配上prevLogIndex和prevLogTerm的日志, 那么为真    接收日志的follower需要实现的\n 如果term \u0026amp;lt; currentTerm, 不接受日志并返回false 如果索引prevLogIndex处的日志的任期号与prevLogTerm不匹配, 不接受日志并返回false 如果一条已存在的日志与新的冲突(index相同但是term不同), 则删除已经存在的日志条目和他之后所有的日志条目 添加任何在已有日志中不存在的条目 如果leaderCommit \u0026amp;gt; commitIndex, 则设置commitIndex = min(leaderCommit, index of last new entry)  RequestVote RPC (投票请求)  入参\n   term 候选人的任期号     candidateId 发起投票请求的候选人id   lastLogIndex 候选人最新的日志条目索引   lastLogTerm 候选人最新日志条目对应的任期号    返回值\n   term 目前的任期号, 用于候选人更新自己     voteGranted 如果候选人收到选票, 那么为true    接收日志的follower需要实现的\n 如果term \u0026amp;lt; currentTerm, 那么拒绝投票并返回false 如果votedFor为空或者与candidateId相同, 并且候选人的日志和自己一样新或者更新, 那么就给候选人投票并返回true  服务器要遵守的规则  所有服务器:  如果commitIndex \u0026amp;gt; lastApplied, 那么将lastApplied自增并把对应日志log[lastApplied]应用到状态机 如果RPC请求或响应包含一个term T大于currentTerm, 那么将currentTerm赋值为T并立即切换状态为follower   Follower:  无条件响应来自candidate和leader的RPC 如果在选举超时之前没收到任何来自leader的AppendEntries RPC或RequestVote RPC, 那么自己转换状态为candidate   Candidate:  转变为candidate之后开始发起选举  currentTerm自增 \u0026amp;ndash;\u0026amp;gt; 重置选举计时器 \u0026amp;ndash;\u0026amp;gt; 给自己投票 \u0026amp;ndash;\u0026amp;gt; 向其他服务器发起RequestVote RPC   如果收到了来自大多数服务器的投票, 转换状态成为leader 如果收到了来自新leader的AppendEntries RPC(Heartbeat), 转换状态为follower 如果选举超时, 开始新一轮的选举   Leader:  一旦成为leader, 想其他所有服务器发送空的AppendEntries RPC(Heartbeat), 并在空闲时间重复发送以防选举超时 如果收到来自客户端的请求, 向本地日志追加条目并向所有服务器发送AppendEntries RPC, 在收到大多数响应后将该条目应用到状态机并回复响应给客户端 如果leader上一次收到的日志索引大于一个follower的nextIndex, 那么通过AppendEntries RPC将nextIndex之后的所有日志发送出去; 如果发送成功, 将follower的nextIndex和matchIndex更新, 如果由于日志不一致导致失败, 那么将nextIndex递减并重新发送 如果存在一个N \u0026amp;gt; commitIndex和半数以上的matchIndex[i] \u0026amp;gt;= N并且log[N].term == currentTerm, 将commitIndex赋值为N    一致性算法总结    Election Safety 选举安全原则: 一个任期内最多允许有一个leader     Leader Append-Only 只增加日志原则: Leader只会增加日志条目, 永远不会覆盖或删除自己的日志   Log Matching 日志匹配原则: 如果两个日志在相同的的索引位置上并且任期号相同, 那么就可以认为这个日志从头到这个索引位置之间的条目完全相同   Leader Completeness 领导人完整性原则: 如果一个日志条目在一个给定任期内被提交, 那么这个条目一定会出现所有任期号更大的leader中   State Machine Safety 状态机安全原则: 如果一个服务器已经将给定索引位置上的日志条目应用到状态机, 那么所有其他服务器不可能在该索引位置应用不同 …","date":-62135596800,"description":"","dir":"projects/sofa-jraft/raft-introduction/","fuzzywordcount":5100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"b811e803d23b40da67657798801f8b51","permalink":"/projects/sofa-jraft/raft-introduction/","publishdate":"0001-01-01T00:00:00Z","readingtime":11,"relpermalink":"/projects/sofa-jraft/raft-introduction/","summary":"Raft 新特性 复制状态机 1. 复制状态机通过日志实现 每台机器一份日志 每个日志条目包含一条命令 状态机按顺序执行命令 2.应用于实际系统的一致性算法一般有以","tags":null,"title":"Raft 算法解读","type":"projects","url":"/projects/sofa-jraft/raft-introduction/","wordcount":5089},{"author":null,"categories":null,"content":"TBD\n","date":-62135596800,"description":"","dir":"projects/sofa-mesh/pilot-register-agent/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"da6c96fadd94eedcf961d50ce7b00600","permalink":"/projects/sofa-mesh/pilot-register-agent/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-mesh/pilot-register-agent/","summary":"TBD","tags":null,"title":"Register Agent","type":"projects","url":"/projects/sofa-mesh/pilot-register-agent/","wordcount":1},{"author":null,"categories":null,"content":"Register agent TBD\n","date":-62135596800,"description":"","dir":"projects/sofa-mesh/pilot-register-agent/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"da6c96fadd94eedcf961d50ce7b00600","permalink":"/en/projects/sofa-mesh/pilot-register-agent/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-mesh/pilot-register-agent/","summary":"Register agent TBD","tags":null,"title":"Register agent","type":"projects","url":"/en/projects/sofa-mesh/pilot-register-agent/","wordcount":3},{"author":null,"categories":null,"content":"Related articles  ISSUES User manual Chinese introductory article: Ant communication framework practices  ","date":-62135596800,"description":"","dir":"projects/sofa-bolt/related-links/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"6844d2a639b69fa3128132b8631f33e3","permalink":"/en/projects/sofa-bolt/related-links/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-bolt/related-links/","summary":"Related articles  ISSUES User manual Chinese introductory article: Ant communication framework practices  ","tags":null,"title":"Related articles","type":"projects","url":"/en/projects/sofa-bolt/related-links/","wordcount":12},{"author":null,"categories":null,"content":"To learn more, see https://github.com/mos/mosn/blob/master/CHANGELOG.md.\n","date":-62135596800,"description":"","dir":"projects/mosn/release-notes/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"62efb8e40401ab4612bcccaa6e942c97","permalink":"/en/projects/mosn/release-notes/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/mosn/release-notes/","summary":"To learn more, see https://github.com/mos/mosn/blob/master/CHANGELOG.md.","tags":null,"title":"Release notes","type":"projects","url":"/en/projects/mosn/release-notes/","wordcount":5},{"author":null,"categories":null,"content":"To learn more, see https://github.com/mos/mosn/blob/master/CHANGELOG.md.\n","date":-62135596800,"description":"","dir":"projects/occlum/release-notes/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"6b9dec1dd8c196e43129ab36a046a84f","permalink":"/en/projects/occlum/release-notes/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/occlum/release-notes/","summary":"To learn more, see https://github.com/mos/mosn/blob/master/CHANGELOG.md.","tags":null,"title":"Release notes","type":"projects","url":"/en/projects/occlum/release-notes/","wordcount":5},{"author":null,"categories":null,"content":"Release history For more information, refer to: https://github.com/sofastack/sofa-ark/releases\n","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-release/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"994c3569ea416ee5b0dea253f08af6be","permalink":"/en/projects/sofa-boot/sofa-ark-release/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-boot/sofa-ark-release/","summary":"Release history For more information, refer to: https://github.com/sofastack/sofa-ark/releases","tags":null,"title":"Release notes","type":"projects","url":"/en/projects/sofa-boot/sofa-ark-release/","wordcount":8},{"author":null,"categories":null,"content":"﻿## Release history For more information, refer to: https://github.com/sofastack/sofa-jarslink/releases\n","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-jarslink-release/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"4554e362f42cbc42b9408d9507cdf689","permalink":"/en/projects/sofa-boot/sofa-jarslink-release/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-boot/sofa-jarslink-release/","summary":"﻿## Release history For more information, refer to: https://github.com/sofastack/sofa-jarslink/releases","tags":null,"title":"Release notes","type":"projects","url":"/en/projects/sofa-boot/sofa-jarslink-release/","wordcount":9},{"author":null,"categories":null,"content":"For more information, see https://github.com/sofastack/sofa-dashboard/releases.\n","date":-62135596800,"description":"","dir":"projects/sofa-dashboard/release-node/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"3c8e6985123810c9692f47cc56b50081","permalink":"/en/projects/sofa-dashboard/release-node/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-dashboard/release-node/","summary":"For more information, see https://github.com/sofastack/sofa-dashboard/releases.","tags":null,"title":"Release notes","type":"projects","url":"/en/projects/sofa-dashboard/release-node/","wordcount":5},{"author":null,"categories":null,"content":" 1.2.5 April 1, 2019\n Bugs fixed  Fixed the conflict between jmh and the unit test code. Fixed the installation failure bug that would occur when the snapshot is too large. This bug may affect the addition of new nodes.   Features  Optimized part of the LogManagerImpl code to reduce CPU usage. Corrected some spelling errors.   Breaking changes  None    We strongly recommend that you upgrade to this version.\n 1.2.4 March 20, 2019\n Bugs fixed  Fixed stale read of lease read in a circumstance. Modified part of timestamps to monotonic time. Fixed the problem of the replicator being blocked in one circumstance. Resolved directory creation failures for some unit tests on Windows. Resolved process crashes caused by improper rocksdb options settings on Windows.   Features  Made the RocksDB options available for users to set. Optimized the pre-vote process, and used the lease mechanism to avoid the current term\u0026amp;rsquo;s interruption on a disconnected node (caused by network partitioning or no writes in the cluster for a long time) to improve the system availability. Updated SOFABolt to 1.5.3. Modified ReadWriteLock of the BallotBox to StampedLock, and provided the OptimisticRead implementation. Fixed a few spelling errors.   Breaking changes  None   Acknowledgements (in no particular order)  @pifuant @huangyunbin @shiftyman @slievrly     1.2.3 March 5, 2019 Released the first open source version.\n 1.2.2 February 21, 2019\n Bugs fixed  Made PeerId and Endpoint immutable, to avoid concurrency problems on APIs such as getLeaderId. Upgraded sofa-common to 1.0.12. The earlier version 1.0.9 was not released to the public GitHub repository.   Features  The JRaft-RheaKV implemented auto range split. When placementDriver(pd) is enabled, the pd can calculate and issue the range split command based on state information reported by each node. When pd is disabled, RheaKVCliService is provided to allow users to manually trigger range split by using the CLI service. Provided LogExceptionHandler generic support. Added MetricThreadPoolExecutor (an updated version of LogThreadPoolExecutor) to print the uncaught exception log and record the time for task.run() and replaced all ThreadPoolExecutors in JRaft with MetricThreadPoolExecutor to record time-consumption metric statistics. This metric can be used as an important reference for adjusting the thread pool configuration in actual application.   Breaking changes  Removed the reset method of Endpoint/PeerId.     V1.2.1 January 28, 2019\n Bugs fixed  Fixed a bug that RaftGroupService may mistakenly disable the shared rpcServer. Fixed the bug of the apply-order change caused by batch write of the RheaKV state machine. Fixed the time usage API error.   Features  Merged the code of duplicate functions of Jraft and RheaKV. Reduced memory usage of the log replication request handling process on followers. Optimized the synchronized conf read/write of the RouteTable to the read/write lock. Implemented lock safe with fencing and the …","date":-62135596800,"description":"","dir":"projects/sofa-jraft/release-log/","fuzzywordcount":900,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"9e24fb74a3cda6a600252b01f8a85db9","permalink":"/en/projects/sofa-jraft/release-log/","publishdate":"0001-01-01T00:00:00Z","readingtime":5,"relpermalink":"/en/projects/sofa-jraft/release-log/","summary":"1.2.5 April 1, 2019\n Bugs fixed  Fixed the conflict between jmh and the unit test code. Fixed the installation failure bug that would occur when the snapshot is too large. This bug may affect the addition of new nodes.   Features  Optimized part of the LogManagerImpl code to reduce CPU usage. Corrected some spelling errors.   Breaking changes  None    We strongly recommend that you upgrade to this version.","tags":null,"title":"Release notes","type":"projects","url":"/en/projects/sofa-jraft/release-log/","wordcount":855},{"author":null,"categories":null,"content":"For more information, see https://github.com/sofastack/sofa-registry/releases.\n","date":-62135596800,"description":"","dir":"projects/sofa-registry/release-notes/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"d92dddf77bbbd6078f3f96ba2224a53d","permalink":"/en/projects/sofa-registry/release-notes/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-registry/release-notes/","summary":"For more information, see https://github.com/sofastack/sofa-registry/releases.","tags":null,"title":"Release notes","type":"projects","url":"/en/projects/sofa-registry/release-notes/","wordcount":5},{"author":null,"categories":null,"content":"To learn more, see https://github.com/sofastack/sofa-rpc/releases.\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/release-notes/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"ab7d46caa6906863103b77b742ec7e84","permalink":"/en/projects/sofa-rpc/release-notes/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/release-notes/","summary":"To learn more, see https://github.com/sofastack/sofa-rpc/releases.","tags":null,"title":"Release notes","type":"projects","url":"/en/projects/sofa-rpc/release-notes/","wordcount":5},{"author":null,"categories":null,"content":"This example demonstrates how to remotely report link data to Zipkin by configuring SOFATracer in an application that integrates SOFATracer.\nThe following examples demonstrate how to use them in SOFABoot/SpringBoot projects and non-SOFABoot/SpringBoot projects, respectively.\nPrepare environment To use SOFABoot, you need to prepare the basic environment first. SOFABoot relies on the following environments:\n JDK7 or JDK8 Apache Maven 3.2.5+ required for compilation  Introduce SOFABoot After creating a Spring Boot project, you need to introduce the SOFABoot dependency. First, you need to unzip the zip package of the Spring Boot project generated above and modify the Maven project configuration file pom.xml.\n\u0026amp;lt;parent\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-starter-parent\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${spring.boot.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;relativePath/\u0026amp;gt; \u0026amp;lt;/parent\u0026amp;gt; Replace the above with the followings:\n\u0026amp;lt;parent\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofaboot-dependencies\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${sofa.boot.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/parent\u0026amp;gt; The ${sofa.boot.version} specifies the latest version of SOFABoot. For more about SOFABoot versions, see Release notes.\nAdd SOFATracer starter \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;tracer-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; Application configuration Finally, add the properties to be used by SOFATracer under the project\u0026amp;rsquo;s application.properties file, including spring.application.name to indicate the name of the current application; logging.path to specify the output directory of the log.\n# Application Name spring.application.name=SOFATracerReportZipkin # logging path logging.path=./logs # open zipkin report com.alipay.sofa.tracer.zipkin.enabled=true # specify zipkin server address com.alipay.sofa.tracer.zipkin.baseUrl=http://localhost:9411 Configure Zipkin Dependencies Considering that Zipkin\u0026amp;rsquo;s data reporting capability is not the ability of SOFATracer to be enabled by default,it‘s desirable to add the following Zipkin data reporting dependencies when using SOFATracer for data reporting:\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;io.zipkin.zipkin2\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;zipkin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.11.12\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;io.zipkin.reporter2\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;zipkin-reporter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.7.13\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;\tStart the Zipkin server Start the Zipkin server to receive the link data reported by SOFATracer and display it. Zipkin Server can be configured with reference to this document.\nRunning You can import the project into IDE and run the main method in the project to start the application. In the console, you can see the log about startup as follows:\n2018-05-12 13:12:05.868 INFO 76572 --- …","date":-62135596800,"description":"","dir":"projects/sofa-tracer/report-to-zipkin/","fuzzywordcount":500,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"d28d192386829452262116de9c32b570","permalink":"/en/projects/sofa-tracer/report-to-zipkin/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/en/projects/sofa-tracer/report-to-zipkin/","summary":"This example demonstrates how to remotely report link data to Zipkin by configuring SOFATracer in an application that integrates SOFATracer.\nThe following examples demonstrate how to use them in SOFABoot/SpringBoot projects and non-SOFABoot/SpringBoot projects, respectively.\nPrepare environment To use SOFABoot, you need to prepare the basic environment first. SOFABoot relies on the following environments:\n JDK7 or JDK8 Apache Maven 3.2.5+ required for compilation  Introduce SOFABoot After creating a Spring Boot project, you need to introduce the SOFABoot dependency.","tags":null,"title":"Report data to Zipkin","type":"projects","url":"/en/projects/sofa-tracer/report-to-zipkin/","wordcount":463},{"author":null,"categories":null,"content":"For REST，we provide a Filter to support cors now.\nSOFARPC API Usage For users who use SOFARPC API directly，they can add parameters in ServerConfig.\nMap\u0026amp;lt;String,String\u0026amp;gt; parameters=new HashMap\u0026amp;lt;String, String\u0026amp;gt;() parameters.put(RpcConstants.ALLOWED_ORIGINS,\u0026amp;#34;abc.com,cdf.com\u0026amp;#34;); serverConfig.setParameters(parameters); XML Usage You can add this configuration to application.properties\ncom.alipay.sofa.rpc.rest.allowed.origins=a.com,b.com ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/restful-cors/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"549f73920842ebb121abf87566761c47","permalink":"/en/projects/sofa-rpc/restful-cors/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/restful-cors/","summary":"For REST，we provide a Filter to support cors now.\nSOFARPC API Usage For users who use SOFARPC API directly，they can add parameters in ServerConfig.\nMap\u0026lt;String,String\u0026gt; parameters=new HashMap\u0026lt;String, String\u0026gt;() parameters.put(RpcConstants.ALLOWED_ORIGINS,\u0026#34;abc.com,cdf.com\u0026#34;); serverConfig.setParameters(parameters); XML Usage You can add this configuration to application.properties\ncom.alipay.sofa.rpc.rest.allowed.origins=a.com,b.com ","tags":null,"title":"REST Cors","type":"projects","url":"/en/projects/sofa-rpc/restful-cors/","wordcount":40},{"author":null,"categories":null,"content":"对于 REST，我们设计了一个 JAXRSProviderManager 管理器类。在服务端生效，生效时间为服务启动时。如果希望有一个通用的 异常处理类，用来处理REST的某中异常类型的信息。可以实现一个REST 的处理类。如下示例是一个拦截SofaRpcException 的通用处理器。\n@PreMatching public class CustomExceptionMapper implements ExceptionMapper\u0026amp;lt;SofaRpcException\u0026amp;gt; { @Override public Response toResponse(SofaRpcException exception) { return Response.status(500).entity(exception.getMessage()).build(); } } 并将该处理器注册到JAXRSProviderManager中，时机可以在Main方法中。具体说明可以参考RESTful-Filter。\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/restful-exception/","fuzzywordcount":300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"0ff4ef4139b228537d2ce4d52a213651","permalink":"/projects/sofa-rpc/restful-exception/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/restful-exception/","summary":"对于 REST，我们设计了一个 JAXRSProviderManager 管理器类。在服务端生效，生效时间为服务启动时。如果希望有一个通用的 异常处理类，用来处理REST的某中异常类型的","tags":null,"title":"REST Exception","type":"projects","url":"/projects/sofa-rpc/restful-exception/","wordcount":204},{"author":null,"categories":null,"content":"For REST, we designed a JAXRSProviderManager manager class. It takes effect on the server when the service starts.\ncom.alipay.sofa.rpc.server.rest.RestServer#registerProvider For the user-defined Filter class, you can call it after the initialization is complete.\ncom.alipay.sofa.rpc.config.JAXRSProviderManager#registerCustomProviderInstance To register filter, since the custom Filter follows REST specification, you need to implement the following interface:\njavax.ws.rs.container.ContainerResponseFilter or javax.ws.rs.container.ContainerRequestFilter After the REST server is started, if using bare SOFARPC, you need to register filter first before starting the service. In SOFABoot environment, it is similar. The specific encoding method is as follows:\ncom.alipay.sofa.rpc.server.rest.TraceRequestFilter com.alipay.sofa.rpc.server.rest.TraceResponseFilter ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/restful-filter/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"53eb86b2504bf3beda2aca24437d6dab","permalink":"/en/projects/sofa-rpc/restful-filter/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/restful-filter/","summary":"For REST, we designed a JAXRSProviderManager manager class. It takes effect on the server when the service starts.\ncom.alipay.sofa.rpc.server.rest.RestServer#registerProvider For the user-defined Filter class, you can call it after the initialization is complete.\ncom.alipay.sofa.rpc.config.JAXRSProviderManager#registerCustomProviderInstance To register filter, since the custom Filter follows REST specification, you need to implement the following interface:\njavax.ws.rs.container.ContainerResponseFilter or javax.ws.rs.container.ContainerRequestFilter After the REST server is started, if using bare SOFARPC, you need to register filter first before starting the service.","tags":null,"title":"REST filter","type":"projects","url":"/en/projects/sofa-rpc/restful-filter/","wordcount":89},{"author":null,"categories":null,"content":"对于 REST，我们设计了一个 JAXRSProviderManager 管理器类。在服务端生效，生效时间为服务启动时。\ncom.alipay.sofa.rpc.server.rest.RestServer#registerProvider 对于用户自定义的 Filter 类，可以在初始化完成后，调用\ncom.alipay.sofa.rpc.config.JAXRSProviderManager#registerCustomProviderInstance 进行注册，其中自定义的 Filter 遵循 REST 的规范，需要实现如下接口：\njavax.ws.rs.container.ContainerResponseFilter 或者 javax.ws.rs.container.ContainerRequestFilter REST server 启动之后，对于裸 SOFARPC 的使用，需要先注册，再启动服务。对于 SOFABoot 环境下的使用，也是类似的过程，具体的写法可以参考：\ncom.alipay.sofa.rpc.server.rest.TraceRequestFilter com.alipay.sofa.rpc.server.rest.TraceResponseFilter ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/restful-filter/","fuzzywordcount":200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"53eb86b2504bf3beda2aca24437d6dab","permalink":"/projects/sofa-rpc/restful-filter/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/restful-filter/","summary":"对于 REST，我们设计了一个 JAXRSProviderManager 管理器类。在服务端生效，生效时间为服务启动时。 com.alipay.sofa.rpc.server.rest.RestServer#registerProvider 对于用户自定义的 Filter 类，可以在初始化完成后，调用 com.alipay.sofa.rpc.config.JAXRSProviderManager#registerCustomProviderInstance 进行注册，其中","tags":null,"title":"REST 自定义 Filter","type":"projects","url":"/projects/sofa-rpc/restful-filter/","wordcount":152},{"author":null,"categories":null,"content":"对于 REST，我们内置了一个跨域 Filter 的支持。\nSOFARPC API 使用 对于使用 SOFARPC API 的用户，可以在 ServerConfig 中添加一个参数表明即可\nMap\u0026amp;lt;String,String\u0026amp;gt; parameters=new HashMap\u0026amp;lt;String, String\u0026amp;gt;() parameters.put(RpcConstants.ALLOWED_ORIGINS,\u0026amp;#34;abc.com,cdf.com\u0026amp;#34;); serverConfig.setParameters(parameters); XML 方式使用 直接通过配置\ncom.alipay.sofa.rpc.rest.allowed.origins=a.com,b.com 即可\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/restful-cors/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"549f73920842ebb121abf87566761c47","permalink":"/projects/sofa-rpc/restful-cors/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/restful-cors/","summary":"对于 REST，我们内置了一个跨域 Filter 的支持。 SOFARPC API 使用 对于使用 SOFARPC API 的用户，可以在 ServerConfig 中添加一个参数表明即可 Map\u0026lt;String,String\u0026gt; parameters=new HashMap\u0026lt;String, String\u0026gt;() parameters.put(RpcConstants.ALLOWED_ORIGINS,\u0026#34;abc.com,cdf.com\u0026#34;); serverConfig.setParameters(parameters); XML 方式使用 直接通过配置 com.alipay.sofa.rpc.rest.allowed.origins=a.com,b.com 即可","tags":null,"title":"REST 跨域","type":"projects","url":"/projects/sofa-rpc/restful-cors/","wordcount":70},{"author":null,"categories":null,"content":"SOFARPC supports RESTful protocol, making it convenient for users to publish an interface in the manner of RESTful.\n Basic usage Custom Filter Integrate Swagger  ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/restful/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"f238d7f58de0c4a0e12d566ea9e09f52","permalink":"/en/projects/sofa-rpc/restful/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/restful/","summary":"SOFARPC supports RESTful protocol, making it convenient for users to publish an interface in the manner of RESTful.\n Basic usage Custom Filter Integrate Swagger  ","tags":null,"title":"RESTful","type":"projects","url":"/en/projects/sofa-rpc/restful/","wordcount":24},{"author":null,"categories":null,"content":"SOFARPC 提供了 RESTful 协议的支持，可以让用户非常方便地将一个接口通过 RESTful 的方式发布出去。\n 基本使用 自定义 Filter 通用异常处理 集成 Swagger  ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/restful/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"f238d7f58de0c4a0e12d566ea9e09f52","permalink":"/projects/sofa-rpc/restful/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/restful/","summary":"SOFARPC 提供了 RESTful 协议的支持，可以让用户非常方便地将一个接口通过 RESTful 的方式发布出去。 基本使用 自定义 Filter 通用异常处理 集成 Swagger","tags":null,"title":"RESTful 协议","type":"projects","url":"/projects/sofa-rpc/restful/","wordcount":54},{"author":null,"categories":null,"content":"在 SOFARPC 中，使用不同的通信协议即使用不同的 Binding 即可，如果需要使用 RESTful 协议，只要将 Binding 设置为 REST 即可。\n发布服务 在定义 RESTful 的服务接口的时候，需要采用 JAXRS 标准的注解在接口上加上元信息，比如下面的接口：\n@Path(\u0026amp;#34;sample\u0026amp;#34;) public interface SampleService { @GET @Path(\u0026amp;#34;hello\u0026amp;#34;) String hello(); }  JAXRS 的标准的注解的使用方式可以参考 RESTEasy 的文档。\n 在定义好了接口之后，将接口的实现发布成一个服务，比如，通过 Annotation 的方式：\n@Service @SofaService(bindings = {@SofaServiceBinding(bindingType = \u0026amp;#34;rest\u0026amp;#34;)}) public class RestfulSampleServiceImpl implements SampleService { @Override public String hello() { return \u0026amp;#34;Hello\u0026amp;#34;; } } 如果要通过其他的方式发布服务，请参考 Bolt 协议基本使用。\n通过浏览器访问服务 在发布服务之后，用户可以通过浏览器来直接访问服务，对于上面的服务，访问的地址如下：\nhttp://localhost:8341/sample/hello SOFARPC 的 RESTful 服务的默认端口为 8341。\n引用服务 除了通过浏览器访问 SOFARPC 发布的 RESTful 服务之外，用户也可以通过 SOFARPC 标准的服务引用的方式来引用服务，比如通过 Annotation 的方式：\n@SofaReference(binding = @SofaReferenceBinding(bindingType = \u0026amp;#34;rest\u0026amp;#34;)) private SampleService sampleService; 如果要使用其他的方式引用服务，请参考 Bolt 协议基本使用。\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/restful-basic/","fuzzywordcount":400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"d41f976864ba8f8221f5b5d26f354d1c","permalink":"/projects/sofa-rpc/restful-basic/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/restful-basic/","summary":"在 SOFARPC 中，使用不同的通信协议即使用不同的 Binding 即可，如果需要使用 RESTful 协议，只要将 Binding 设置为 REST 即可。 发布服务 在定义 RESTful 的服务接口的时候，需要采用 JAXRS 标准的注","tags":null,"title":"RESTful 协议基本使用","type":"projects","url":"/projects/sofa-rpc/restful-basic/","wordcount":358},{"author":null,"categories":null,"content":"RestTemplate Integration In this document will demonstrate how to use SOFATracer to track of RestTemplate, this example address.\nAssuming you have built a simple Spring Web project based on SOFABoot, Then you can be operated by the following steps:\nIntroduce dependency \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;tracer-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;!-- SOFABoot version unified management --\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; Project Configuration Then, add the parameters to be used by SOFATracer in the project\u0026amp;rsquo;s application.properties file, including spring.application.name that indicates the name of the current application and logging.path that specifies the log output directory.\n# Application Name spring.application.name=SOFATracerSpringMVC # logging path logging.path=./logs Add a Controller that provides RESTFul services In the project, provide a simple Controller, for example:\n@RestController public class SampleController { private final AtomicLong counter = new AtomicLong(0); @RequestMapping(\u0026amp;#34;/rest\u0026amp;#34;) public Map\u0026amp;lt;String, Object\u0026amp;gt; rest() { Map\u0026amp;lt;String, Object\u0026amp;gt; map = new HashMap\u0026amp;lt;String, Object\u0026amp;gt;(); map.put(\u0026amp;#34;count\u0026amp;#34;, counter.incrementAndGet()); return map; } @RequestMapping(\u0026amp;#34;/asyncrest\u0026amp;#34;) public Map\u0026amp;lt;String, Object\u0026amp;gt; asyncrest() throws InterruptedException { Map\u0026amp;lt;String, Object\u0026amp;gt; map = new HashMap\u0026amp;lt;String, Object\u0026amp;gt;(); map.put(\u0026amp;#34;count\u0026amp;#34;, counter.incrementAndGet()); Thread.sleep(5000); return map; } } Construct the RestTemplate in API model to initiate a call to the RESTful service above  Construct a RestTemplate synchronous call instance  RestTemplate restTemplate = SofaTracerRestTemplateBuilder.buildRestTemplate(); ResponseEntity\u0026amp;lt;String\u0026amp;gt; responseEntity = restTemplate.getForEntity( \u0026amp;#34;http://sac.alipay.net:8080/rest\u0026amp;#34;, String.class);  Construct a RestTemplate asynchronous call instance  AsyncRestTemplate asyncRestTemplate = SofaTracerRestTemplateBuilder .buildAsyncRestTemplate(); ListenableFuture\u0026amp;lt;ResponseEntity\u0026amp;lt;String\u0026amp;gt;\u0026amp;gt; forEntity = asyncRestTemplate.getForEntity( \u0026amp;#34;http://sac.alipay.net:8080/asyncrest\u0026amp;#34;, String.class); Get the RestTemplate in an automatic injection @Autowired RestTemplate restTemplate; Run the project Start the SOFABoot app and see the log in the console as follows:\n2018-10-24 10:45:28.683 INFO 5081 --- [ main] o.s.j.e.a.AnnotationMBeanExporter : Registering beans for JMX exposure on startup 2018-10-24 10:45:28.733 INFO 5081 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http) 2018-10-24 10:45:28.736 INFO 5081 --- [ main] c.a.s.t.e.r.RestTemplateDemoApplication : Started RestTemplateDemoApplication in 2.163 seconds (JVM running for 3.603) Successful call：\n2018-10-24 10:45:28.989 INFO 5081 --- [ main] c.a.s.t.e.r.RestTemplateDemoApplication : Response is {\u0026amp;quot;count\u0026amp;quot;:1} 2018-10-24 10:45:34.014 INFO 5081 --- [ main] c.a.s.t.e.r.RestTemplateDemoApplication : …","date":-62135596800,"description":"","dir":"projects/sofa-tracer/usage-of-resttemplate/","fuzzywordcount":500,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"8b66d6ad488bd59ecbf113b37825d58e","permalink":"/en/projects/sofa-tracer/usage-of-resttemplate/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/en/projects/sofa-tracer/usage-of-resttemplate/","summary":"RestTemplate Integration In this document will demonstrate how to use SOFATracer to track of RestTemplate, this example address.\nAssuming you have built a simple Spring Web project based on SOFABoot, Then you can be operated by the following steps:\nIntroduce dependency \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alipay.sofa\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;tracer-sofa-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;!-- SOFABoot version unified management --\u0026gt; \u0026lt;/dependency\u0026gt; Project Configuration Then, add the parameters to be used by SOFATracer in the project\u0026rsquo;s application.properties file, including spring.application.name that indicates the name of the current application and logging.","tags":null,"title":"RestTemplate Integration","type":"projects","url":"/en/projects/sofa-tracer/usage-of-resttemplate/","wordcount":434},{"author":null,"categories":null,"content":"RestTemplate Log Format SOFATracer integrates RestTemplate and outputs the requested link log data format. The default is JSON data format.\nRestTemplate digest log（resttemplate-digest.log） The data is output in JSON format. Each key meaning is as follows:\n   key Meaning     time Log printing time   local.app Current application name   traceId TraceId   spanId SpanId   request.url Request URL   method Request HTTP method   result.code HTTP return status code   resp.size.bytes Response Body Size   time.cost.milliseconds Request time (ms)   current.thread.name Current thread name   remote.app remote app name   baggage Transparently transmitted baggage data    Example:\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2018-10-24 10:45:28.977\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;RestTemplateDemo\u0026amp;#34;,\u0026amp;#34;traceId\u0026amp;#34;:\u0026amp;#34;0a0fe8b3154034912878910015081\u0026amp;#34;,\u0026amp;#34;spanId\u0026amp;#34;:\u0026amp;#34;0\u0026amp;#34;,\u0026amp;#34;request.url\u0026amp;#34;:\u0026amp;#34;http://sac.alipay.net:8080/rest\u0026amp;#34;,\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;GET\u0026amp;#34;,\u0026amp;#34;result.code\u0026amp;#34;:\u0026amp;#34;200\u0026amp;#34;,\u0026amp;#34;resp.size.bytes\u0026amp;#34;:0,\u0026amp;#34;time.cost.milliseconds\u0026amp;#34;:188,\u0026amp;#34;current.thread.name\u0026amp;#34;:\u0026amp;#34;main\u0026amp;#34;,\u0026amp;#34;remote.app\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;,\u0026amp;#34;baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;} RestTemplate stat log（resttemplate-stat.log） stat.key is the collection of statistical keywords in this period, which uniquely determines a set of statistical data, including local.app, request.url, and method field.\nExample:\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2018-10-24 10:46:28.769\u0026amp;#34;,\u0026amp;#34;stat.key\u0026amp;#34;:{\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;GET\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;RestTemplateDemo\u0026amp;#34;,\u0026amp;#34;request.url\u0026amp;#34;:\u0026amp;#34;http://sac.alipay.net:8080/rest\u0026amp;#34;},\u0026amp;#34;count\u0026amp;#34;:1,\u0026amp;#34;total.cost.milliseconds\u0026amp;#34;:5009,\u0026amp;#34;success\u0026amp;#34;:\u0026amp;#34;true\u0026amp;#34;,\u0026amp;#34;load.test\u0026amp;#34;:\u0026amp;#34;F\u0026amp;#34;} ","date":-62135596800,"description":"","dir":"projects/sofa-tracer/log-format-resttemplate/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"c52c919080b467801700a8a1f156c513","permalink":"/en/projects/sofa-tracer/log-format-resttemplate/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-tracer/log-format-resttemplate/","summary":"RestTemplate Log Format SOFATracer integrates RestTemplate and outputs the requested link log data format. The default is JSON data format.\nRestTemplate digest log（resttemplate-digest.log） The data is output in JSON format. Each key meaning is as follows:\n   key Meaning     time Log printing time   local.app Current application name   traceId TraceId   spanId SpanId   request.url Request URL   method Request HTTP method   result.","tags":null,"title":"RestTemplate log","type":"projects","url":"/en/projects/sofa-tracer/log-format-resttemplate/","wordcount":116},{"author":null,"categories":null,"content":"在本文档将演示如何使用 SOFATracer 对 RestTemplate 进行埋点，本示例工程地址。\n假设你已经基于 SOFABoot 构建了一个简单的 Spring Web 工程，那么可以通过如下步骤进行操作：\n依赖引入 \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;tracer-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 工程配置 在工程的 application.properties 文件下添加 SOFATracer 要使用的参数，包括 spring.application.name 用于标示当前应用的名称；logging.path 用于指定日志的输出目录。\n# Application Name spring.application.name=TestTemplateDemo # logging path logging.path=./logs 添加一个提供 RESTful 服务的 Controller 在工程代码中，添加一个简单的 Controller，例如：\n@RestController public class SampleController { private final AtomicLong counter = new AtomicLong(0); @RequestMapping(\u0026amp;#34;/rest\u0026amp;#34;) public Map\u0026amp;lt;String, Object\u0026amp;gt; rest() { Map\u0026amp;lt;String, Object\u0026amp;gt; map = new HashMap\u0026amp;lt;String, Object\u0026amp;gt;(); map.put(\u0026amp;#34;count\u0026amp;#34;, counter.incrementAndGet()); return map; } @RequestMapping(\u0026amp;#34;/asyncrest\u0026amp;#34;) public Map\u0026amp;lt;String, Object\u0026amp;gt; asyncrest() throws InterruptedException { Map\u0026amp;lt;String, Object\u0026amp;gt; map = new HashMap\u0026amp;lt;String, Object\u0026amp;gt;(); map.put(\u0026amp;#34;count\u0026amp;#34;, counter.incrementAndGet()); Thread.sleep(5000); return map; } } 以 API 方式构造 RestTemplate 发起一次对上文的 RESTful 服务的调用  构造 RestTemplate 同步调用实例  RestTemplate restTemplate = SofaTracerRestTemplateBuilder.buildRestTemplate(); ResponseEntity\u0026amp;lt;String\u0026amp;gt; responseEntity = restTemplate.getForEntity( \u0026amp;#34;http://sac.alipay.net:8080/rest\u0026amp;#34;, String.class);  构造 RestTemplate 异步调用实例  AsyncRestTemplate asyncRestTemplate = SofaTracerRestTemplateBuilder .buildAsyncRestTemplate(); ListenableFuture\u0026amp;lt;ResponseEntity\u0026amp;lt;String\u0026amp;gt;\u0026amp;gt; forEntity = asyncRestTemplate.getForEntity( \u0026amp;#34;http://sac.alipay.net:8080/asyncrest\u0026amp;#34;, String.class); 以自动注入的方式获取 RestTemplate @Autowired RestTemplate restTemplate; 运行 启动 SOFABoot 应用，将会在控制台中看到启动打印的日志：\n2018-10-24 10:45:28.683 INFO 5081 --- [ main] o.s.j.e.a.AnnotationMBeanExporter : Registering beans for JMX exposure on startup 2018-10-24 10:45:28.733 INFO 5081 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http) 2018-10-24 10:45:28.736 INFO 5081 --- [ main] c.a.s.t.e.r.RestTemplateDemoApplication : Started RestTemplateDemoApplication in 2.163 seconds (JVM running for 3.603) 调用成功：\n2018-10-24 10:45:28.989 INFO 5081 --- [ main] c.a.s.t.e.r.RestTemplateDemoApplication : Response is {\u0026amp;#34;count\u0026amp;#34;:1} 2018-10-24 10:45:34.014 INFO 5081 --- [ main] c.a.s.t.e.r.RestTemplateDemoApplication : Async Response is {\u0026amp;#34;count\u0026amp;#34;:2} 2018-10-24 10:45:34.014 INFO 5081 --- [ main] c.a.s.t.e.r.RestTemplateDemoApplication : test finish ....... 查看日志 在上面的 application.properties 里面，我们配置的日志打印目录是 ./logs 即当前应用的根目录（我们可以根据自己的实践需要进行配置），在当前工程的根目录下可以看到类似如下结构的日志文件：\n./logs ├── spring.log └── tracelog ├── resttemplate-digest.log ├── resttemplate-stat.log ├── spring-mvc-digest.log ├── spring-mvc-stat.log ├── static-info.log └── tracer-self.log 示例中通过构造两个 RestTemplate（一个同步一个异步） 发起对同一个 RESTful 服务的调用，调用完成后可以在 restTemplate-digest.log 中看到类似如下的日志：\n 摘要日志  {\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2019-09-03 …","date":-62135596800,"description":"","dir":"projects/sofa-tracer/usage-of-resttemplate/","fuzzywordcount":700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"8b66d6ad488bd59ecbf113b37825d58e","permalink":"/projects/sofa-tracer/usage-of-resttemplate/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-tracer/usage-of-resttemplate/","summary":"在本文档将演示如何使用 SOFATracer 对 RestTemplate 进行埋点，本示例工程地址。 假设你已经基于 SOFABoot 构建了一个简单的 Spring Web 工程，那么可以通过如下步骤进行操作： 依赖引入 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alipay.sofa\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;tracer-sofa-boot-starter\u0026lt;/artifactId\u0026gt;","tags":null,"title":"RestTemplate 埋点接入","type":"projects","url":"/projects/sofa-tracer/usage-of-resttemplate/","wordcount":610},{"author":null,"categories":null,"content":"SOFATracer 集成 RestTemplate 后输出请求的链路数据格式，默认为 JSON 数据格式。\nRestTemplate 摘要日志（resttemplate-digest.log） 以 JSON 格式输出的数据，相应 key 的含义解释如下：\n   key 表达含义     time 日志打印时间   local.app 当前应用名   traceId TraceId   spanId SpanId   span.kind Span 类型   result.code 状态码   current.thread.name 当前线程名   time.cost.milliseconds span 耗时   request.url 请求地址   method http method   req.size.bytes 请求大小   resp.size.bytes 响应大小   sys.baggage 系统透传的 baggage 数据   biz.baggage 业务透传的 baggage 数据    样例：\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2019-09-03 10:33:10.336\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;RestTemplateDemo\u0026amp;#34;,\u0026amp;#34;traceId\u0026amp;#34;:\u0026amp;#34;0a0fe9271567477985327100211176\u0026amp;#34;,\u0026amp;#34;spanId\u0026amp;#34;:\u0026amp;#34;0\u0026amp;#34;,\u0026amp;#34;span.kind\u0026amp;#34;:\u0026amp;#34;client\u0026amp;#34;,\u0026amp;#34;result.code\u0026amp;#34;:\u0026amp;#34;200\u0026amp;#34;,\u0026amp;#34;current.thread.name\u0026amp;#34;:\u0026amp;#34;SimpleAsyncTaskExecutor-1\u0026amp;#34;,\u0026amp;#34;time.cost.milliseconds\u0026amp;#34;:\u0026amp;#34;5009ms\u0026amp;#34;,\u0026amp;#34;request.url\u0026amp;#34;:\u0026amp;#34;http://localhost:8801/asyncrest\u0026amp;#34;,\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;GET\u0026amp;#34;,\u0026amp;#34;req.size.bytes\u0026amp;#34;:0,\u0026amp;#34;resp.size.bytes\u0026amp;#34;:0,\u0026amp;#34;sys.baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;,\u0026amp;#34;biz.baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;} RestTemplate 统计日志（resttemplate-stat.log） stat.key 即本段时间内的统计关键字集合，统一关键字集合唯一确定一组统计数据，包含local.app、request.url、和 method 字段.\n样例：\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2019-09-03 10:34:04.130\u0026amp;#34;,\u0026amp;#34;stat.key\u0026amp;#34;:{\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;GET\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;RestTemplateDemo\u0026amp;#34;,\u0026amp;#34;request.url\u0026amp;#34;:\u0026amp;#34;http://localhost:8801/asyncrest\u0026amp;#34;},\u0026amp;#34;count\u0026amp;#34;:1,\u0026amp;#34;total.cost.milliseconds\u0026amp;#34;:5009,\u0026amp;#34;success\u0026amp;#34;:\u0026amp;#34;true\u0026amp;#34;,\u0026amp;#34;load.test\u0026amp;#34;:\u0026amp;#34;F\u0026amp;#34;} ","date":-62135596800,"description":"","dir":"projects/sofa-tracer/log-format-resttemplate/","fuzzywordcount":300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"c52c919080b467801700a8a1f156c513","permalink":"/projects/sofa-tracer/log-format-resttemplate/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-tracer/log-format-resttemplate/","summary":"SOFATracer 集成 RestTemplate 后输出请求的链路数据格式，默认为 JSON 数据格式。 RestTemplate 摘要日志（resttemplate-digest.log） 以 JSON 格式输出的数据，相应 key 的","tags":null,"title":"RestTemplate 日志","type":"projects","url":"/projects/sofa-tracer/log-format-resttemplate/","wordcount":254},{"author":null,"categories":null,"content":"SOFARPC supports a framework-level retry strategy when the cluster mode is FailOver (SOFARPC uses FailOver mode by default). Retry is only initiated if there is a framework-level exception or a timeout exception on the server. If the business itself throws an exception, the service will not be called again. SOFARPC does not perform any retry by default.\n Note: Although the system will retry calling in case of timeout exception, the server still needs to guarantee the idempotency of the service. Otherwise there may be risks.\n Use XML If you subscribe to the service using XML, you can set the number of retries by setting the retries parameter of sofa:global-attrs:\n\u0026amp;lt;sofa:reference jvm-first=\u0026amp;#34;false\u0026amp;#34; id=\u0026amp;#34;retriesServiceReferenceBolt\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofa.rpc.samples.retries.RetriesService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;sofa:global-attrs retries=\u0026amp;#34;2\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt; Use Annotation If you are using Annotation, you can set the retries attribute of @SofaReferenceBinding annotation:\n@SofaReference(binding = @SofaReferenceBinding(bindingType = \u0026amp;#34;bolt\u0026amp;#34;, retries = 2)) private SampleService sampleService; Use API in Spring environment If you are using the API in Spring environment, you can call the setRetries method of BoltBindingParam:\nBoltBindingParam boltBindingParam = new BoltBindingParam(); boltBindingParam.setRetries(2); Use API in non-Spring environment If you are using the bare API of SOFARPC directly in non-Spring environment, you can call the setRetries method of ConsumerConfig:\nConsumerConfig\u0026amp;lt;RetriesService\u0026amp;gt; consumerConfig = new ConsumerConfig\u0026amp;lt;RetriesService\u0026amp;gt;(); consumerConfig.setRetries(2); ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/retry-invoke/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"d60b44aa8f1b49ab6c1bbc55593a91da","permalink":"/en/projects/sofa-rpc/retry-invoke/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/retry-invoke/","summary":"SOFARPC supports a framework-level retry strategy when the cluster mode is FailOver (SOFARPC uses FailOver mode by default). Retry is only initiated if there is a framework-level exception or a timeout exception on the server. If the business itself throws an exception, the service will not be called again. SOFARPC does not perform any retry by default.\n Note: Although the system will retry calling in case of timeout exception, the server still needs to guarantee the idempotency of the service.","tags":null,"title":"Retry strategy","type":"projects","url":"/en/projects/sofa-rpc/retry-invoke/","wordcount":205},{"author":null,"categories":null,"content":"SOFAJRaft 2019 年 4-7 月开发计划  (p1) Telnet 服务（或其他，越简单越好），作为一种在线排查问题的手段，主要提供以下几个功能  Raft_stat: 以 node 节点为 root，能列出大部分甚至所有相关 stat Metrics: 展示当前节点最新的所有 metrics 指标度量(虽然日志里有相关数据但是相对分散)   (p1) 扩展点：引入 SPI 机制，先列出几个扩展点  LogStorage LogEntry codec RaftMetaStorage Metric 指标度量   (p1) 对于 multi-raft-group 场景，提供一个 manual rebalance api 用于平衡各个节点的 leaders 数量 (p2) 文档国际化 (p2) 添加 Learner 角色，只用于同步数据不参与投票 (p3) RheaKV 完成 jepsen 验证  ","date":-62135596800,"description":"","dir":"projects/sofa-jraft/road-map/","fuzzywordcount":200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"d39cc6e615d623f8dfc320f32dcbdfa6","permalink":"/projects/sofa-jraft/road-map/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-jraft/road-map/","summary":"SOFAJRaft 2019 年 4-7 月开发计划 (p1) Telnet 服务（或其他，越简单越好），作为一种在线排查问题的手段，主要提供以下几个功能 Raft_stat: 以 node 节点为 root，能列出大部分甚至所有","tags":null,"title":"Road Map","type":"projects","url":"/projects/sofa-jraft/road-map/","wordcount":194},{"author":null,"categories":null,"content":"Roadmap Version 1.5.1  Fixed code style problems in the project: https://github.com/alipay/sofa-bolt/issues/85 Fixed known bugs in the project: https://github.com/alipay/sofa-bolt/issues/82 The RPC layer supports message list dispatching from the I/O thread: https://github.com/alipay/sofa-bolt/pull/84  Version 1.6.0 Overall goal  Unify lifecycle APIs for all components Extract and incorporate network component APIs Converge configuration methods and enhance configuration scalability  Unify lifecycle APIs for all components In the current Bolt version, APIs of lifecycle management components are named inconsistently, for example:\n ReconnectManager does not need startup or initialization, and the disabling method is stop. The initialization method for DefaultConnectionMonitor of is start, and the disabling method is destroy. The initialization method forRpcClient init, and the disabling method is shutdown. The initialization method forRpcTaskScanner is start, and the disabling method is shutdown.  We plan to unify lifecycle APIs of all components in V1.6.0:\n For components that are subject to lifecycle management, which require initialization before use and must release resources after use, their startup/shutdown APIs are to be unified.  Extract and incorporate network component APIs Network operations of Bolt are mainly performed by using the remoting class, which is provided as an abstract class. We plan to converge methods of this class, and provide them in the form of APIs in the future. There are a few advantages of doing so:\n Standardized usage Stable service Convenient internal code iteration  Taking the ReconnectManager as an example. It provides the public addCancelUrl method, which is not called in the Bolt project. This may cause problems:\n IDE will give a warning. Users may get confused on whether they should delete this method.  We plan to solve the these problems in V1.6.0 by extracting a set of stable APIs, which are convenient for users to use, helpful to improve code readability, and can lay a solid foundation for future iterations.\nConverge configuration methods and enhance configuration scalability Currently, Bolt supports the following configuration methods:\n ProtocolSwitch: supports protocol configuration (enabling or disabling CRC validation), and creates configuration objects by static means. GlobalSwitch: offers instance-level configuration, and offers GlobalSwitch configuration items to every AbstractConfigurableInstance. The default value is taken from the SystemProperty, and the configuration can be adjusted through an API. ConfigItem: enumerates Netty-related configuration items that cannot be inherited or extended before you modify the source code. ConfigManager: reads SystemProperty configurations by static means. Configs: defines the configuration item names and specifies their default values.  Generally, Bolt\u0026amp;rsquo;s configuration items look to be loose and scattered and are hard for users to extend their usage. Some …","date":-62135596800,"description":"","dir":"projects/sofa-bolt/sofa-bolt-roadmap/","fuzzywordcount":600,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"3d4eac90b5c8e657d14eb885ab1f9a92","permalink":"/en/projects/sofa-bolt/sofa-bolt-roadmap/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/en/projects/sofa-bolt/sofa-bolt-roadmap/","summary":"Roadmap Version 1.5.1  Fixed code style problems in the project: https://github.com/alipay/sofa-bolt/issues/85 Fixed known bugs in the project: https://github.com/alipay/sofa-bolt/issues/82 The RPC layer supports message list dispatching from the I/O thread: https://github.com/alipay/sofa-bolt/pull/84  Version 1.6.0 Overall goal  Unify lifecycle APIs for all components Extract and incorporate network component APIs Converge configuration methods and enhance configuration scalability  Unify lifecycle APIs for all components In the current Bolt version, APIs of lifecycle management components are named inconsistently, for example:","tags":null,"title":"Roadmap","type":"projects","url":"/en/projects/sofa-bolt/sofa-bolt-roadmap/","wordcount":539},{"author":null,"categories":null,"content":"","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-roadmap/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"c4532d11cef15d8fe3ff5e04c7b08f90","permalink":"/en/projects/sofa-boot/sofa-ark-roadmap/","publishdate":"0001-01-01T00:00:00Z","readingtime":0,"relpermalink":"/en/projects/sofa-boot/sofa-ark-roadmap/","summary":"","tags":null,"title":"Roadmap","type":"projects","url":"/en/projects/sofa-boot/sofa-ark-roadmap/","wordcount":0},{"author":null,"categories":null,"content":"","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-jarslink-roadmap/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"f1d0bf15efba08535f9574e1c8344cab","permalink":"/en/projects/sofa-boot/sofa-jarslink-roadmap/","publishdate":"0001-01-01T00:00:00Z","readingtime":0,"relpermalink":"/en/projects/sofa-boot/sofa-jarslink-roadmap/","summary":"","tags":null,"title":"Roadmap","type":"projects","url":"/en/projects/sofa-boot/sofa-jarslink-roadmap/","wordcount":0},{"author":null,"categories":null,"content":"Development plans of SOFAJRaft from April to July 2019  (p1) Implement the Telnet service (or similar equivalents, the simpler the better) as an online troubleshooting means. It should be able to provide the following functions:  Raft_stat: List most or all stats of a Raft node. Metrics: Uniformly display the latest values of all metrics for the current node (the related data is scattered in the log).   (p1) Extension points: introduce the SPI mechanism. Some of the extension points are listed as follows:  LogStorage LogEntry codec RaftMetaStorage Metrics   (p1) Provide a manual rebalance API for the multi-raft-group scenario to balance the number of leaders on each node. (p2) Translate the document into multiple languages. (p2) Add a learner role that only replicates data and does not vote. (p3) Complete jepsen tests for RheaKV.  ","date":-62135596800,"description":"","dir":"projects/sofa-jraft/road-map/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"d39cc6e615d623f8dfc320f32dcbdfa6","permalink":"/en/projects/sofa-jraft/road-map/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-jraft/road-map/","summary":"Development plans of SOFAJRaft from April to July 2019  (p1) Implement the Telnet service (or similar equivalents, the simpler the better) as an online troubleshooting means. It should be able to provide the following functions:  Raft_stat: List most or all stats of a Raft node. Metrics: Uniformly display the latest values of all metrics for the current node (the related data is scattered in the log).   (p1) Extension points: introduce the SPI mechanism.","tags":null,"title":"Roadmap","type":"projects","url":"/en/projects/sofa-jraft/road-map/","wordcount":132},{"author":null,"categories":null,"content":"Task list Some of the existing internal features will be available in subsequent iterations.\nThe features that have been implemented are listed in the following table. You are welcome to claim the tasks and make contributions.\n   Task type Task Degree of difficulty Claimant and time Planned completion time Progress Related issues     Documentation Document translation Low       Code Flexible persistent connection management Low    #56   Code etcd registry center implementation Medium @wynn5a2018-6   #153   Code eureka registry center implementation Medium @liufeiit2018-4   #52   Code gRPC support High    #57   Code CXF protocol High    #58   Code TLS support High        Version iteration Plan v5.5.0  Support JSON serialization Support H2 TLS Implement flexible connection pool Integrate Hystrix Support Consul registry center  v5.6.0  Support GRPC communication layer Support etcd registry center Support SOFAMesh Implement BOLT version negotiation and CRC verification  v5.7.0  Support Telnet built-in instructions Support SpringBoot 2.0 Support Mock function Support encryption  v5.8.0  Support authorization Support SofaRegistry Support Reactive  ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/roadmap/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"6064fc180911f520f6d1590b88595693","permalink":"/en/projects/sofa-rpc/roadmap/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/roadmap/","summary":"Task list Some of the existing internal features will be available in subsequent iterations.\nThe features that have been implemented are listed in the following table. You are welcome to claim the tasks and make contributions.\n   Task type Task Degree of difficulty Claimant and time Planned completion time Progress Related issues     Documentation Document translation Low       Code Flexible persistent connection management Low    #56   Code etcd registry center implementation Medium @wynn5a2018-6   #153   Code eureka registry center implementation Medium @liufeiit2018-4   #52   Code gRPC support High    #57   Code CXF protocol High    #58   Code TLS support High        Version iteration Plan v5.","tags":null,"title":"Roadmap","type":"projects","url":"/en/projects/sofa-rpc/roadmap/","wordcount":150},{"author":null,"categories":null,"content":"Tasks The following table lists the features that have not yet been implemented. We encourage you to claim the tasks and make a contribution.\n   Type Task Difficulty Claimed by and on Planned completion time Progress Related issues     Document SOFADashboard Parameter Configuration Guide Simple       Code Support for SOFARegistry Medium       Code Support for Docker Medium       Code Support for Kubernetes Medium       Code Support for Apollo Medium       Code Frontend optimization Medium        ","date":-62135596800,"description":"","dir":"projects/sofa-dashboard/roadmap/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"a740c874742b504de9011b07f3a4ddb5","permalink":"/en/projects/sofa-dashboard/roadmap/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-dashboard/roadmap/","summary":"Tasks The following table lists the features that have not yet been implemented. We encourage you to claim the tasks and make a contribution.\n   Type Task Difficulty Claimed by and on Planned completion time Progress Related issues     Document SOFADashboard Parameter Configuration Guide Simple       Code Support for SOFARegistry Medium       Code Support for Docker Medium       Code Support for Kubernetes Medium       Code Support for Apollo Medium       Code Frontend optimization Medium        ","tags":null,"title":"Roadmap and task claim","type":"projects","url":"/en/projects/sofa-dashboard/roadmap/","wordcount":67},{"author":null,"categories":null,"content":"Roadmap Tasks We have some internal implementations of some new features, which will be released along with the iterations when sorted out.\nFeatures that are not implemented yet are listed in the following table. We encourage you to claim the tasks and contribute to SOFARegistry.\n   Type Task Difficulty Claimed by and on Planned completion time Progress Related issues     Document Document Translation Low       Code Support for Spring Cloud Medium       Code Data self-check High       Code Blacklist filtering Medium       Code SOFARegistry Dashboard High       Code Support for other microservice frameworks Medium       Code Support for Docker \u0026amp;amp; Kubernetes High       Code Multi-language client support High        Version iteration plan v5.3.0  Support for Spring Cloud Data self-check Blacklist filtering  v5.4.0  SOFARegistry Dashboard Support for other microservice frameworks  v5.5.0  Support for Docker \u0026amp;amp; Kubernetes Multi-language client support  ","date":-62135596800,"description":"","dir":"projects/sofa-registry/roadmap/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"b0ab45d52ba3eb7db590a4f5e4197c9e","permalink":"/en/projects/sofa-registry/roadmap/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-registry/roadmap/","summary":"Roadmap Tasks We have some internal implementations of some new features, which will be released along with the iterations when sorted out.\nFeatures that are not implemented yet are listed in the following table. We encourage you to claim the tasks and contribute to SOFARegistry.\n   Type Task Difficulty Claimed by and on Planned completion time Progress Related issues     Document Document Translation Low       Code Support for Spring Cloud Medium       Code Data self-check High       Code Blacklist filtering Medium       Code SOFARegistry Dashboard High       Code Support for other microservice frameworks Medium       Code Support for Docker \u0026amp; Kubernetes High       Code Multi-language client support High        Version iteration plan v5.","tags":null,"title":"Roadmap and task claims","type":"projects","url":"/en/projects/sofa-registry/roadmap/","wordcount":128},{"author":null,"categories":null,"content":"In SOFABoot, the RPC framework provides some configuration parameters at the application level, and supports application-level parameter configuration, such as port and thread pool, which are bound by Spring Boot\u0026amp;rsquo;s @ConfigurationProperties. The binding attribute class is com.alipay.sofa.rpc.boot.config.SofaBootRpcProperties, and the configuration prefix is as follows:\nstatic final String PREFIX = \u0026amp;#34;com.alipay.sofa.rpc\u0026amp;#34;; Then in the application.properties file, you can currently configure the following options. Also, you can write the codes based on your own coding habits as well as according to the Spring Boot specification, camel, underline and so on.\n#Standalone fault tolerance com.alipay.sofa.rpc.aft.regulation.effective # Whether to enable standalone fault tolerance com.alipay.sofa.rpc.aft.degrade.effective # Whether to enable degradation com.alipay.sofa.rpc.aft.time.window # Time window com.alipay.sofa.rpc.aft.least.window.count # Minimum number of calls com.alipay.sofa.rpc.aft.least.window.exception.rate.multiple # minimum exception rate com.alipay.sofa.rpc.aft.weight.degrade.rate # Degradation rate com.alipay.sofa.rpc.aft.weight.recover.rate # Recovery rate com.alipay.sofa.rpc.aft.degrade.least.weight #Minimum degrading weight com.alipay.sofa.rpc.aft.degrade.max.ip.count # Maximum number of degraded IPs # bolt com.alipay.sofa.rpc.bolt.port # bolt port com.alipay.sofa.rpc.bolt.thread.pool.core.size # Number of bolt core threads com.alipay.sofa.rpc.bolt.thread.pool.max.size # Maximum number of bolt threads com.alipay.sofa.rpc.bolt.thread.pool.queue.size # bolt thread pool queue com.alipay.sofa.rpc.bolt.accepts.size # Number of connections that server allows client to establish # rest com.alipay.sofa.rpc.rest.hostname # rest hostname com.alipay.sofa.rpc.rest.port # rest port com.alipay.sofa.rpc.rest.io.thread.size # Number of rest io threads com.alipay.sofa.rpc.rest.context.path # rest context path com.alipay.sofa.rpc.rest.thread.pool.core.size # Number of rest core threads com.alipay.sofa.rpc.rest.thread.pool.max.size # Maximum number of rest threads com.alipay.sofa.rpc.rest.max.request.size # Maximum rest request size com.alipay.sofa.rpc.rest.telnet # Whether to allow rest telnet com.alipay.sofa.rpc.rest.daemon # Whether to hold the port. If true, exit with the main thread exit # dubbo com.alipay.sofa.rpc.dubbo.port # dubbo port com.alipay.sofa.rpc.dubbo.io.thread.size # dubbo io thread size com.alipay.sofa.rpc.dubbo.thread.pool.max.size # Maximum number of dubbo business threads com.alipay.sofa.rpc.dubbo.accepts.size # Number of connections that server allows client to establish com.alipay.sofa.rpc.dubbo.thread.pool.core.size #Number of dubbo core Threads com.alipay.sofa.rpc.dubbo.thread.pool.queue.size #Maximum number of dubbo threads # registry com.alipay.sofa.rpc.registry.address # Registry center address com.alipay.sofa.rpc.virtual.host # virtual host com.alipay.sofa.rpc.bound.host # bind host …","date":-62135596800,"description":"","dir":"projects/sofa-rpc/application-rpc-config/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"bd19b2ced39a8deb802c13e525093fac","permalink":"/en/projects/sofa-rpc/application-rpc-config/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-rpc/application-rpc-config/","summary":"In SOFABoot, the RPC framework provides some configuration parameters at the application level, and supports application-level parameter configuration, such as port and thread pool, which are bound by Spring Boot\u0026rsquo;s @ConfigurationProperties. The binding attribute class is com.alipay.sofa.rpc.boot.config.SofaBootRpcProperties, and the configuration prefix is as follows:\nstatic final String PREFIX = \u0026#34;com.alipay.sofa.rpc\u0026#34;; Then in the application.properties file, you can currently configure the following options. Also, you can write the codes based on your own coding habits as well as according to the Spring Boot specification, camel, underline and so on.","tags":null,"title":"RPC application parameter configuration","type":"projects","url":"/en/projects/sofa-rpc/application-rpc-config/","wordcount":381},{"author":null,"categories":null,"content":"ProviderConfig    Attribute Name Default value Comment     id ID Generated automatically    application Application object Empty ApplicationConfig    interfaceId Service interface (unique identifier)  Use the actual interface class for both normal calls and return calls.   uniqueId Service tag (unique identifier)     filterRef Filter configuration example  List   filter Filter configuration alias  separated by commas   registry Registry center on the server  List   methods Method-level configuration  Map\u0026amp;lt;String, MethodConfig\u0026amp;gt;   serialization Serialization protocol hessian2    register Whether to register true It depends on the implementation and may not take effect.   subscribe Whether to subscribe true It depends on the implementation and may not take effect.   proxy Proxy type javassist As well as JDK dynamic proxy   ref Service interface implementation class     server server  List, and it can be sent to multiple servers at once   delay Time for delaying service publishing  Service delay   weight Service static weight     include Included methods     exclude Methods not included     dynamic Whether to dynamically register     priority Service priority     bootstrap Service publishing starter bolt    executor Custom thread pool     timeout Execution timeout period for server     concurrents Concurrent execution request  Maximum number of parallel executable requests per method under interface. -1 indicates turning off the concurrent filter, and 0 means that filtering is enabled but not limited   cacheRef Result cache implementation class     mockRef Mock implementation class     mock Whether to enable Mock     validation Whether to enable parameter verification (jsr303)     compress Whether to start compression false    cache Whether to enable result caching false    parameters Extra attributes  Map\u0026amp;lt;String, String\u0026amp;gt;    ConsumerConfig    Attribute Name Default value Comment     id ID Generated automatically    application Application object Empty ApplicationConfig    interfaceId Service interface (unique identifier)  Use the actual interface class for both normal calls and return calls.   uniqueId Service tag (Unique identifier)     filterRef Filter configuration example  List   filter Filter configuration alias  List   registry Registry center on the server  List   methods Method-level configuration  Map\u0026amp;lt;String, MethodConfig\u0026amp;gt;   serialization Serialization protocol hessian2    register Whether to register true It depends on the implementation and may not take effect.   subscribe Whether to subscribe true It depends on the implementation and may not take effect.   proxy proxy type javassist As well as JDK dynamic proxy   protocol Call protocol bolt Currently supports bolt, rest, dubbo   directUrl Direct address  Directly connected to register   generic Whether to generalize calls false    connectTimeout Timeout period for connection establishment 3000(cover 5000)    disconnectTimeout Timeout period for disconnection 5000(cover …","date":-62135596800,"description":"","dir":"projects/sofa-rpc/configuration-common/","fuzzywordcount":1100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"2eb5963f4785f5f828f0e15759272971","permalink":"/en/projects/sofa-rpc/configuration-common/","publishdate":"0001-01-01T00:00:00Z","readingtime":6,"relpermalink":"/en/projects/sofa-rpc/configuration-common/","summary":"ProviderConfig    Attribute Name Default value Comment     id ID Generated automatically    application Application object Empty ApplicationConfig    interfaceId Service interface (unique identifier)  Use the actual interface class for both normal calls and return calls.   uniqueId Service tag (unique identifier)     filterRef Filter configuration example  List   filter Filter configuration alias  separated by commas   registry Registry center on the server  List   methods Method-level configuration  Map\u0026lt;String, MethodConfig\u0026gt;   serialization Serialization protocol hessian2    register Whether to register true It depends on the implementation and may not take effect.","tags":null,"title":"RPC publishing and reference configuration","type":"projects","url":"/en/projects/sofa-rpc/configuration-common/","wordcount":1084},{"author":null,"categories":null,"content":"ProviderConfig    属性 名称 默认值 备注     id ID 自动生成    application 应用对象 空ApplicationConfig    interfaceId 服务接口（唯一标识元素）  不管是普通调用和返回调用，这里都设置实际的接口类   uniqueId 服务标签（唯一标识元素）     filterRef 过滤器配置实例  List   filter 过滤器配置别名  多个用逗号隔开   registry 服务端注册中心  List   methods 方法级配置  Map\u0026amp;lt;String, MethodConfig\u0026amp;gt;   serialization 序列化协议 hessian2    register 是否注册 true 取决于实现，可能不生效。   subscribe 是否订阅 true 取决于实现，可能不生效。   proxy 代理类型 javassist 还有JDK动态代理   ref 服务接口实现类     server 服务端  List，可以一次发到多个服务端   delay 服务延迟发布时间  服务延迟   weight 服务静态权重     include 包含的方法     exclude 不包含的方法     dynamic 是否动态注册     priority 服务优先级     bootstrap 服务发布启动器 bolt    executor 自定义线程池     timeout 服务端执行超时时间     concurrents 并发执行请求  接口下每方法的最大可并行执行请求数，配置-1关闭并发过滤器，等于0表示开启过滤但是不限制   cacheRef 结果缓存实现类     mockRef Mock实现类     mock 是否开启Mock     validation 是否开启参数验证(jsr303)     compress 是否启动压缩 false    cache 是否启用结果缓存 false    parameters 额外属性  Map\u0026amp;lt;String, String\u0026amp;gt;    ConsumerConfig    属性 名称 默认值 备注     id ID 自动生成    application 应用对象 空ApplicationConfig    interfaceId 服务接口（唯一标识元素）  不管是普通调用和返回调用，这里都设置实际的接口类   uniqueId 服务标签（唯一标识元素）     filterRef 过滤器配置实例  List   filter 过滤器配置别名  List   registry 服务端注册中心  List   methods 方法级配置  Map\u0026amp;lt;String, MethodConfig\u0026amp;gt;   serialization 序列化协议 hessian2    register 是否注册 true 取决于实现，可能不生效。   subscribe 是否订阅 true 取决于实现，可能不生效。   proxy 代理类型 javassist 还有JDK动态代理   protocol 调用的协议 bolt 目前支持bolt，rest，dubbo   directUrl 直连地址  直连后register   generic 是否泛化调用 false    connectTimeout 建立连接超时时间 3000(cover 5000)    disconnectTimeout 断开连接等等超时时间 5000(cover 10000)    cluster 集群模式 failover    connectionHolder 连接管理器实现 all    loadBalancer 负载均衡算法 random    lazy 是否延迟建立长连接 false    sticky 是否使用粘性连接 false 跳过负载均衡算法使用上一个地址   inJVM 是否转为JVM调用 true JVM发现服务提供者，转为走本地   check 是否检查强依赖 false 无可用服务端启动失败   heartbeat 心跳间隔 30000 客户端给服务端发心跳间隔。取决于实现，可能不生效。   reconnect 重连间隔 10000 客户端重建端口长连接的间隔。取决于实现，可能不生效。   router 路由器配置别名  List   routerRef 路由器配置实例  List   bootstrap 服务引用启动器 bolt    addressWait 等待地址获取时间 -1 取决于实现，可能不生效。   timeout 调用超时时间 3000(cover 5000)    retries 失败后重试次数 0 跟集群模式有关，failover读取此参数。   invokeType 调用类型 sync    onReturn 并发执行请求数  接口下每方法的最大可并行执行请求数，配置-1关闭并发过滤器，等于0表示开启过滤但是不限制   cacheRef 结果缓存实现类     mockRef Mock实现类     cache 是否启用结果缓存 false    mock 是否开启Mock     validation 是否开启参数验证  基于JSR303   compress 是否启动压缩 false    parameters 额外属性  Map\u0026amp;lt;String, String\u0026amp;gt;    MethodConfig    属性 名称 默认值 备注     name 方法名     timeout 调用超时时间 null    retries 失败后重试次数 null    invokeType 调用类型 null    validation 是否开启参数验证 null 基于JSR303   onReturn 返回时调用的SofaResponseCallback null 用于实现Callback等   concurrent 并发执行请求数 null 接口下每方法的最大可并行执行请求数，配置-1关闭并发过滤器，等于0表示开启过滤但是不限制。   validation 是否开启参数验证 null    compress 是否启动压缩 null    parameters 额外属性  Map\u0026amp;lt;String, String\u0026amp;gt;    ServerConfig    id Id 默认值 备注     protocol 协议 bolt 目前支持bolt，rest，dubbo   host 主机 0.0.0.0    port 端口 12200 默认端口 bolt:12200, rest:8341, h2c:12300, dubbo:20880   contextPath 上下文路径 /    ioThreads IO线程池数 0 取决于实现，可能不生效。例如bolt默认cpu*2。0表示自动计算。   threadPoolType 业务线程池类型 cached    coreThreads 业务线程池核心大小 80(override …","date":-62135596800,"description":"","dir":"projects/sofa-rpc/configuration-common/","fuzzywordcount":1800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"2eb5963f4785f5f828f0e15759272971","permalink":"/projects/sofa-rpc/configuration-common/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/projects/sofa-rpc/configuration-common/","summary":"ProviderConfig 属性 名称 默认值 备注 id ID 自动生成 application 应用对象 空ApplicationConfig interfaceId 服务接口（唯一标识元素） 不管是普通调用和返回调用，这里都设置","tags":null,"title":"RPC 发布订阅配置","type":"projects","url":"/projects/sofa-rpc/configuration-common/","wordcount":1782},{"author":null,"categories":null,"content":"在 SOFABoot 的使用场景下，RPC 框架在应用层面，提供一些配置参数，支持的应用级别的参数配置，如端口，线程池等信息，都是通过 Spring Boot的@ConfigurationProperties 进行的绑定。绑定属性类是com.alipay.sofa.rpc.boot.config.SofaBootRpcProperties，配置前缀是\nstatic final String PREFIX = \u0026amp;#34;com.alipay.sofa.rpc\u0026amp;#34;; 那么在 application.properties 文件中，目前可以配置以下几个选项。其中使用者也可以根据自己的编码习惯，按照 Spring Boot的规范，按照驼峰，中划线等进行书写。\n# 单机故障剔除 com.alipay.sofa.rpc.aft.regulation.effective # 是否开启单机故障剔除功能 com.alipay.sofa.rpc.aft.degrade.effective # 是否开启降级 com.alipay.sofa.rpc.aft.time.window # 时间窗口 com.alipay.sofa.rpc.aft.least.window.count # 最小调用次数 com.alipay.sofa.rpc.aft.least.window.exception.rate.multiple # 最小异常率 com.alipay.sofa.rpc.aft.weight.degrade.rate # 降级速率 com.alipay.sofa.rpc.aft.weight.recover.rate # 恢复速率 com.alipay.sofa.rpc.aft.degrade.least.weight #降级最小权重 com.alipay.sofa.rpc.aft.degrade.max.ip.count # 最大降级 ip # bolt com.alipay.sofa.rpc.bolt.port # bolt 端口 com.alipay.sofa.rpc.bolt.thread.pool.core.size # bolt 核心线程数 com.alipay.sofa.rpc.bolt.thread.pool.max.size # bolt 最大线程数 com.alipay.sofa.rpc.bolt.thread.pool.queue.size # bolt 线程池队列 com.alipay.sofa.rpc.bolt.accepts.size # 服务端允许客户端建立的连接数 # rest com.alipay.sofa.rpc.rest.hostname # rest hostname com.alipay.sofa.rpc.rest.port # rest port com.alipay.sofa.rpc.rest.io.thread.size # rest io 线程数 com.alipay.sofa.rpc.rest.context.path # rest context path com.alipay.sofa.rpc.rest.thread.pool.core.size # rest 核心线程数 com.alipay.sofa.rpc.rest.thread.pool.max.size # rest 最大线程数 com.alipay.sofa.rpc.rest.max.request.size # rest 最大请求大小 com.alipay.sofa.rpc.rest.telnet # 是否允许 rest telnet com.alipay.sofa.rpc.rest.daemon # 是否hold住端口，true的话随主线程退出而退出 # dubbo com.alipay.sofa.rpc.dubbo.port # dubbo port com.alipay.sofa.rpc.dubbo.io.thread.size # dubbo io 线程大小 com.alipay.sofa.rpc.dubbo.thread.pool.max.size # dubbo 业务线程最大数 com.alipay.sofa.rpc.dubbo.accepts.size # dubbo 服务端允许客户端建立的连接数 com.alipay.sofa.rpc.dubbo.thread.pool.core.size #dubbo 核心线程数 com.alipay.sofa.rpc.dubbo.thread.pool.queue.size #dubbo 最大线程数 # registry com.alipay.sofa.rpc.registry.address # 注册中心地址 com.alipay.sofa.rpc.virtual.host # virtual host com.alipay.sofa.rpc.bound.host # 绑定 host com.alipay.sofa.rpc.virtual.port # virtual端口 com.alipay.sofa.rpc.enabled.ip.range # 多网卡 ip 范围 com.alipay.sofa.rpc.bind.network.interface # 绑定网卡 # h2c com.alipay.sofa.rpc.h2c.port # h2c 端口 com.alipay.sofa.rpc.h2c.thread.pool.core.size # h2c 核心线程数 com.alipay.sofa.rpc.h2c.thread.pool.max.size # h2c 最大线程数 com.alipay.sofa.rpc.h2c.thread.pool.queue.size # h2c 队列大小 com.alipay.sofa.rpc.h2c.accepts.size # 服务端允许客户端建立的连接数 # 扩展 com.alipay.sofa.rpc.lookout.collect.disable # 是否关闭 lookout # 代理 com.alipay.sofa.rpc.consumer.repeated.reference.limit # 允许客户端对同一个服务生成的引用代理数量，默认为3; ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/application-rpc-config/","fuzzywordcount":700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"bd19b2ced39a8deb802c13e525093fac","permalink":"/projects/sofa-rpc/application-rpc-config/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-rpc/application-rpc-config/","summary":"在 SOFABoot 的使用场景下，RPC 框架在应用层面，提供一些配置参数，支持的应用级别的参数配置，如端口，线程池等信息，都是通过 Spring Boot的@Config","tags":null,"title":"RPC 应用参数配置","type":"projects","url":"/projects/sofa-rpc/application-rpc-config/","wordcount":620},{"author":null,"categories":null,"content":"Sampling Currently,SOFATracer provides two sampling modes. One is the fixed sampling rate based on BitSet. The other is the sampling provided to the user to customize the implementation sampling.The following example shows how to use it.\nThis example is based on the tracer-sampled-with-springmvc project,Except for application.properties, everything else is the same.\nSampling mode based on fixed sampling rate Add sampling related configuration items in application.properties #Sampling rate 0~100 com.alipay.sofa.tracer.samplerPercentage=100 #Sampling type name com.alipay.sofa.tracer.samplerName=PercentageBasedSampler Verification  When the sample rate is set to 100, the digest log is printed each time. When the sample rate is set to 0, the digest log is not printed. Print by probability when the sampling rate is set between 0 and 100.  The result is verified by requesting 10 times.\n1、When the sample rate is set to 100, the digest log is printed each time.\nStart the project and enter in the browser:http://localhost:8080/springmvc ,And refresh the address 10 times, check the log as follows:\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2018-11-09 11:54:47.643\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;SOFATracerSpringMVC\u0026amp;#34;,\u0026amp;#34;traceId\u0026amp;#34;:\u0026amp;#34;0a0fe8ec154173568757510019269\u0026amp;#34;,\u0026amp;#34;spanId\u0026amp;#34;:\u0026amp;#34;0.1\u0026amp;#34;,\u0026amp;#34;request.url\u0026amp;#34;:\u0026amp;#34;http://localhost:8080/springmvc\u0026amp;#34;,\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;GET\u0026amp;#34;,\u0026amp;#34;result.code\u0026amp;#34;:\u0026amp;#34;200\u0026amp;#34;,\u0026amp;#34;req.size.bytes\u0026amp;#34;:-1,\u0026amp;#34;resp.size.bytes\u0026amp;#34;:0,\u0026amp;#34;time.cost.milliseconds\u0026amp;#34;:68,\u0026amp;#34;current.thread.name\u0026amp;#34;:\u0026amp;#34;http-nio-8080-exec-1\u0026amp;#34;,\u0026amp;#34;baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;} {\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2018-11-09 11:54:50.980\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;SOFATracerSpringMVC\u0026amp;#34;,\u0026amp;#34;traceId\u0026amp;#34;:\u0026amp;#34;0a0fe8ec154173569097710029269\u0026amp;#34;,\u0026amp;#34;spanId\u0026amp;#34;:\u0026amp;#34;0.1\u0026amp;#34;,\u0026amp;#34;request.url\u0026amp;#34;:\u0026amp;#34;http://localhost:8080/springmvc\u0026amp;#34;,\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;GET\u0026amp;#34;,\u0026amp;#34;result.code\u0026amp;#34;:\u0026amp;#34;200\u0026amp;#34;,\u0026amp;#34;req.size.bytes\u0026amp;#34;:-1,\u0026amp;#34;resp.size.bytes\u0026amp;#34;:0,\u0026amp;#34;time.cost.milliseconds\u0026amp;#34;:3,\u0026amp;#34;current.thread.name\u0026amp;#34;:\u0026amp;#34;http-nio-8080-exec-2\u0026amp;#34;,\u0026amp;#34;baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;} {\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2018-11-09 11:54:51.542\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;SOFATracerSpringMVC\u0026amp;#34;,\u0026amp;#34;traceId\u0026amp;#34;:\u0026amp;#34;0a0fe8ec154173569153910049269\u0026amp;#34;,\u0026amp;#34;spanId\u0026amp;#34;:\u0026amp;#34;0.1\u0026amp;#34;,\u0026amp;#34;request.url\u0026amp;#34;:\u0026amp;#34;http://localhost:8080/springmvc\u0026amp;#34;,\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;GET\u0026amp;#34;,\u0026amp;#34;result.code\u0026amp;#34;:\u0026amp;#34;200\u0026amp;#34;,\u0026amp;#34;req.size.bytes\u0026amp;#34;:-1,\u0026amp;#34;resp.size.bytes\u0026amp;#34;:0,\u0026amp;#34;time.cost.milliseconds\u0026amp;#34;:3,\u0026amp;#34;current.thread.name\u0026amp;#34;:\u0026amp;#34;http-nio-8080-exec-4\u0026amp;#34;,\u0026amp;#34;baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;} {\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2018-11-09 …","date":-62135596800,"description":"","dir":"projects/sofa-tracer/sampler/","fuzzywordcount":500,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"48856a040da01abc84213934c1c5fce4","permalink":"/en/projects/sofa-tracer/sampler/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-tracer/sampler/","summary":"Sampling Currently,SOFATracer provides two sampling modes. One is the fixed sampling rate based on BitSet. The other is the sampling provided to the user to customize the implementation sampling.The following example shows how to use it.\nThis example is based on the tracer-sampled-with-springmvc project,Except for application.properties, everything else is the same.\nSampling mode based on fixed sampling rate Add sampling related configuration items in application.properties #Sampling rate 0~100 com.alipay.sofa.tracer.samplerPercentage=100 #Sampling type name com.","tags":null,"title":"Sampling modes","type":"projects","url":"/en/projects/sofa-tracer/sampler/","wordcount":426},{"author":null,"categories":null,"content":"1. Integrated deployment 1.1 Scale up registry-integration Assume that three registry-integration servers have been deployed currently, which are namely node1, node2, and node 3. The new node to be added to the cluster is node 4.\nOperation steps:\nStep 1. Deploy the new registry-integration node\nFirst, deploy registry-integration.tgz on node4 by referencing the Deployment topic. Note that you need to set the nodes.metaNode configuration item on node4 to a 4-server endpoint list:\nnodes.metaNode=DefaultDataCenter:\u0026amp;lt;node1\u0026amp;gt;,\u0026amp;lt;node2\u0026amp;gt;,\u0026amp;lt;node3\u0026amp;gt;,\u0026amp;lt;node4\u0026amp;gt; In this step, after node4 is started, visit curl http://\u0026amp;lt;node4\u0026amp;gt;:9615/health/check. The status will be unhealthy, because node4 has not been added to the cluster yet. To add it to the cluster, perform the next step.\nStep 2. Call the changePeer operation to add a new node to a cluster\nRun the changePeer command on one of the existing servers (node1, node2, and node3), to modify the current cluster from a three-node cluster (node1, node2, and node3) to a four-node cluster (node1, node2, node3, and node4):\ncurl -X POST \u0026amp;#34;http://\u0026amp;lt;node1\u0026amp;gt;:9615/manage/changePeer\u0026amp;#34; -d \u0026amp;#34;ipAddressList=\u0026amp;lt;node1\u0026amp;gt;,\u0026amp;lt;node2\u0026amp;gt;,\u0026amp;lt;node3\u0026amp;gt;,\u0026amp;lt;node4\u0026amp;gt;\u0026amp;#34; After completing this step, visit curl http://\u0026amp;lt;node4\u0026amp;gt;:9615/health/check. The status will be healthy.\n1.2 Scale down registry-integration Assume that you have three servers in one cluster, which are respectively node1, node2, and node3, and you want to scale down node3.\n1.2.1 Smooth scale-down Operation steps:\nStep 1. Call the changePeer operation to remove a node\nRun the changePeer command on either node1 or node2 to change the cluster list from \u0026amp;ldquo;node1, node2, node3\u0026amp;rdquo; to \u0026amp;ldquo;node1,node2\u0026amp;rdquo;. This removes node3 from the endpoint list of the cluster:\ncurl -X POST \u0026amp;#34;http://\u0026amp;lt;node1\u0026amp;gt;:9615/manage/changePeer\u0026amp;#34; -d \u0026amp;#34;ipAddressList=\u0026amp;lt;node1\u0026amp;gt;,\u0026amp;lt;node2\u0026amp;gt;\u0026amp;#34; After completing this step, visit curl http://\u0026amp;lt;node3\u0026amp;gt;:9615/health/check. The status will be unhealthy, because node3 has already been removed from the cluster.\nStep 2. Close node3\nThis step is optional, because node3 has already been removed from the cluster, and it does not affect the cluster even if it is still running.\n1.2.2 Handling of node failure If node3 is no longer functional, you need to remove it from the cluster.\nOperation steps:\nStep 1. Call the changePeer operation to remove a node\nRun the changePeer command on either node1 or node2 to change the cluster list from \u0026amp;ldquo;node1, node2, node3\u0026amp;rdquo; to \u0026amp;ldquo;node1,node2\u0026amp;rdquo;. This removes node3 from the endpoint list of the cluster:\ncurl -X POST \u0026amp;#34;http://\u0026amp;lt;node1\u0026amp;gt;:9615/manage/changePeer\u0026amp;#34; -d \u0026amp;#34;ipAddressList=\u0026amp;lt;node1\u0026amp;gt;,\u0026amp;lt;node2\u0026amp;gt;\u0026amp;#34; 2. Independent deployment 2.1 Scale up registry-meta Assume that you have already deployed three registry-meta servers, which are respectively metaNode1, metaNode2, and metaNode3. The new node to be added to the cluster is node …","date":-62135596800,"description":"","dir":"projects/sofa-registry/scale/","fuzzywordcount":1000,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"57de6dc4da1292063ff25ecea9ffbd08","permalink":"/en/projects/sofa-registry/scale/","publishdate":"0001-01-01T00:00:00Z","readingtime":5,"relpermalink":"/en/projects/sofa-registry/scale/","summary":"1. Integrated deployment 1.1 Scale up registry-integration Assume that three registry-integration servers have been deployed currently, which are namely node1, node2, and node 3. The new node to be added to the cluster is node 4.\nOperation steps:\nStep 1. Deploy the new registry-integration node\nFirst, deploy registry-integration.tgz on node4 by referencing the Deployment topic. Note that you need to set the nodes.metaNode configuration item on node4 to a 4-server endpoint list:","tags":null,"title":"Scaling","type":"projects","url":"/en/projects/sofa-registry/scale/","wordcount":954},{"author":null,"categories":null,"content":"Quickly understand ACTS scripts Do you have to frequently compile test cases? Are you frustrated by the following problems?\n You have to repeat assertEquals, which is definitely not creative. Missing an assert may lead to false success, while mistaking one may ruin your mood. If the scenario is complex, the test code may be longer than the service code, which is painful. You have to migrate utility classes every time you start writing test cases for a new application.  A TestNG test case is shown on the left side, and an ACTS test case on the right. Repeated coding is gone, and the code size is significantly reduced. Unlike ordinary test scripts, ACTS scripts inherit from the ActsTestBase class, which is encapsulated with data loading methods, driving methods, execution engines, and validation rules. Users do not have to clean or prepare data, run test cases, or validate results. ACTS implements zero coding for simple services, which greatly reduces the coding and maintenance costs.\nGenerate test scripts Prerequisites: Be sure to use Maven to compile your project and generate the object model. Otherwise, ACTS IDE may encounter unexpected errors, such as edit failures and incorrect data.\nRight click a the method defined in the interface and select ACTS Function \u0026amp;gt; Generate Test Case.\nRun test script Method: Right click the tested method in ACTS script, and select TestNG to run the test script as shown in the following figure.\nSpecify a test script to run   Set test_only＝^T in src/test/resource/config/acts-config.properties to run only the test case whose name starts with T. You can also replace ^T with other regular expressions.\n  In this case, you can modify the name of the test case that you want to run by adding T in front of its name. ACTS only runs a test case whose name starts with T.\n  Split test cases of the test script ACTS stores all test case data of a test script in the same YAML file by default. You can determine whether to store test case data by test script or by test case by configuring the option spilt_yaml_by_case. It is set to false by default, which means all test case data of the same test script is stored in one YAML file.\nYou can set spilt_yaml_by_case=true in acts-config.properties to store each test case of a new test script in a separate YAML file that is named after the case ID. This reduces the chances of file conflicts in the case where multiple developers work on the same interface.\nIn addition, ACTS provides a utility class that allows you split a legacy YAML file of a specified test script under a specified path by test case. See the following.\nBaseDataUtil.saveYamlDataToCaseByCase\n Note: Before the split, we recommend that you rename the original YAML file for backup, and then use the test case editor to check whether the content of the split files is correct. The original YAML file must be deleted if the split files are correct, because they cannot coexist.  Coding for data preparation ACTS provides context APIs …","date":-62135596800,"description":"","dir":"projects/sofa-acts/usage-script/","fuzzywordcount":900,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"0d20739dedad1f11277bd02ed65329c3","permalink":"/en/projects/sofa-acts/usage-script/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/en/projects/sofa-acts/usage-script/","summary":"Quickly understand ACTS scripts Do you have to frequently compile test cases? Are you frustrated by the following problems?\n You have to repeat assertEquals, which is definitely not creative. Missing an assert may lead to false success, while mistaking one may ruin your mood. If the scenario is complex, the test code may be longer than the service code, which is painful. You have to migrate utility classes every time you start writing test cases for a new application.","tags":null,"title":"Scripts","type":"projects","url":"/en/projects/sofa-acts/usage-script/","wordcount":825},{"author":null,"categories":null,"content":"SEATA Demo for SOFAStack Cloud Native Workshop on KubeCon China 2019\nAT mode 1.Introduce maven dependencies Introduce the following dependencies into the POM file of the parent project (seata-demo-at/pom.xml):\n... \u0026amp;lt;properties\u0026amp;gt; ... \u0026amp;lt;seata.version\u0026amp;gt;0.6.1\u0026amp;lt;/seata.version\u0026amp;gt; \u0026amp;lt;netty4.version\u0026amp;gt;4.1.24.Final\u0026amp;lt;/netty4.version\u0026amp;gt; \u0026amp;lt;/properties\u0026amp;gt; ... \u0026amp;lt;dependencyManagement\u0026amp;gt; \u0026amp;lt;dependencies\u0026amp;gt; ... \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;io.seata\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;seata-all\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${seata.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;io.seata\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;seata-server\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${seata.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;exclusions\u0026amp;gt; \u0026amp;lt;exclusion\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;javax.servlet\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;servlet-api\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/exclusion\u0026amp;gt; \u0026amp;lt;/exclusions\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;io.netty\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;netty-all\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${netty4.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;/dependencies\u0026amp;gt; \u0026amp;lt;/dependencyManagement\u0026amp;gt; Introduce the following dependencies into the POM file of the stock-mng project (seata-demo-at/stock-mng/pom.xml):\n\u0026amp;lt;dependencies\u0026amp;gt; .... \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;io.seata\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;seata-all\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;io.netty\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;netty-all\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependencies\u0026amp;gt; Introduce the following dependencies into the POM file of the balance-mng-impl project (seata-demo-at/balance-mng/balance-mng-impl/pom.xml):\n\u0026amp;lt;dependencies\u0026amp;gt; .... \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;io.seata\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;seata-all\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;io.seata\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;seata-server\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;io.netty\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;netty-all\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependencies\u0026amp;gt; 2. Use Seata\u0026amp;rsquo;s DataSourceProxy to proxy actual data source and configure GlobalTransactionScanner to scan @GlobalTransaction annotation Add the following java snippet to the main methods in BalanceMngApplication and StockMngApplication classes:\n... import io.seata.rm.datasource.DataSourceProxy; import io.seata.spring.annotation.GlobalTransactionScanner; ... @Configuration public static class DataSourceConfig { @Bean @Primary @ConfigurationProperties(prefix = \u0026amp;#34;spring.datasource.hikari\u0026amp;#34;) public DataSource dataSource(DataSourceProperties properties) { HikariDataSource dataSource = createDataSource(properties, HikariDataSource.class); if (StringUtils.hasText(properties.getName())) { dataSource.setPoolName(properties.getName()); } return new DataSourceProxy(dataSource); } @SuppressWarnings(\u0026amp;#34;unchecked\u0026amp;#34;) protected static …","date":-62135596800,"description":"This guide introduces how to use the AT mode and TCC mode of the open-source distributed transaction framework Seata to solve the final consistency of service data.","dir":"guides/kc-seata-demo/","fuzzywordcount":1500,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"60071a0eb44bf0901fb187eefd63ccdb","permalink":"/en/guides/kc-seata-demo/","publishdate":"0001-01-01T00:00:00Z","readingtime":7,"relpermalink":"/en/guides/kc-seata-demo/","summary":"SEATA Demo for SOFAStack Cloud Native Workshop on KubeCon China 2019\nAT mode 1.Introduce maven dependencies Introduce the following dependencies into the POM file of the parent project (seata-demo-at/pom.xml):\n... \u0026lt;properties\u0026gt; ... \u0026lt;seata.version\u0026gt;0.6.1\u0026lt;/seata.version\u0026gt; \u0026lt;netty4.version\u0026gt;4.1.24.Final\u0026lt;/netty4.version\u0026gt; \u0026lt;/properties\u0026gt; ... \u0026lt;dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; ... \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.seata\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;seata-all\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${seata.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.seata\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;seata-server\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${seata.version}\u0026lt;/version\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;javax.servlet\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;servlet-api\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.netty\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;netty-all\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${netty4.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/dependencyManagement\u0026gt; Introduce the following dependencies into the POM file of the stock-mng project (seata-demo-at/stock-mng/pom.","tags":null,"title":"Seata distributed transaction practice","type":"guides","url":"/en/guides/kc-seata-demo/","wordcount":1464},{"author":null,"categories":null,"content":"SOFABoot RPC Starter provides a variety of registry center options as well as convenient configurations.\nCurrently, bolt, rest, and dubbo all support Zookeeper as registry center. In addition, bolt and rest support the local file system as registry center, which is generally used for testing.\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/registry-usage/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"5a1a4619c8ac4a9fc27b8576472aed9f","permalink":"/en/projects/sofa-rpc/registry-usage/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/registry-usage/","summary":"SOFABoot RPC Starter provides a variety of registry center options as well as convenient configurations.\nCurrently, bolt, rest, and dubbo all support Zookeeper as registry center. In addition, bolt and rest support the local file system as registry center, which is generally used for testing.","tags":null,"title":"Select Service Registry","type":"projects","url":"/en/projects/sofa-rpc/registry-usage/","wordcount":45},{"author":null,"categories":null,"content":"When using the Bolt communication protocol, SOFARPC can choose different serialization protocols, which can be hessian2 or protobuf currently.\nBy default, SOFARPC uses hessian2 as the serialization protocol. If you need to set the serialization protocol to protobuf, you need to configure the following settings when publishing the service:\n\u0026amp;lt;sofa:service ref=\u0026amp;#34;sampleService\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofarpc.demo.SampleService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;sofa:global-attrs serialize-type=\u0026amp;#34;protobuf\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;/sofa:service\u0026amp;gt; That is to add the \u0026amp;lt;sofa:global-attrs\u0026amp;gt; tag to the \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; tag and set the serialize-type attribute to protobuf.\nCorrespondingly, when referencing the service, you also need to change the serialization protocol to protobuf. The setting method is similar to publishing the service:\n\u0026amp;lt;sofa:reference interface=\u0026amp;#34;com.alipay.sofarpc.demo.SampleService\u0026amp;#34; id=\u0026amp;#34;sampleServiceRef\u0026amp;#34; jvm-first=\u0026amp;#34;false\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;sofa:global-attrs serialize-type=\u0026amp;#34;protobuf\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt; Currently, when you use Annotation for service reference, it is not yet supported to set serialization protocol. But this will be supported in future versions. For details, see ISSUE: https://github.com/sofastack/sofa-boot/issues/278\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/serialization/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"87e2faa84c2c7a7605243dc096bc4e17","permalink":"/en/projects/sofa-rpc/serialization/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/serialization/","summary":"When using the Bolt communication protocol, SOFARPC can choose different serialization protocols, which can be hessian2 or protobuf currently.\nBy default, SOFARPC uses hessian2 as the serialization protocol. If you need to set the serialization protocol to protobuf, you need to configure the following settings when publishing the service:\n\u0026lt;sofa:service ref=\u0026#34;sampleService\u0026#34; interface=\u0026#34;com.alipay.sofarpc.demo.SampleService\u0026#34;\u0026gt; \u0026lt;sofa:binding.bolt\u0026gt; \u0026lt;sofa:global-attrs serialize-type=\u0026#34;protobuf\u0026#34;/\u0026gt; \u0026lt;/sofa:binding.bolt\u0026gt; \u0026lt;/sofa:service\u0026gt; That is to add the \u0026lt;sofa:global-attrs\u0026gt; tag to the \u0026lt;sofa:binding.bolt\u0026gt; tag and set the serialize-type attribute to protobuf.","tags":null,"title":"Serialization protocol","type":"projects","url":"/en/projects/sofa-rpc/serialization/","wordcount":138},{"author":null,"categories":null,"content":"Deployment SOFARegistry supports two types of deployment modes, which are integrated deployment and independent deployment. This topic describes the simplest integrated single-node deployment. For more information about deployment modes, see the Deployment topic.\nDeployment steps 1. Download the source code or installation package. Download the source code. git clone https://github.com/sofastack/sofa-registry.git cd sofa-registry mvn clean package -DskipTests cp server/distribution/integration/target/registry-integration.tgz \u0026amp;lt;somewhere\u0026amp;gt; cd \u0026amp;lt;somewhere\u0026amp;gt; \u0026amp;amp;\u0026amp;amp; mkdir registry-integration tar -zxvf registry-integration.tgz -C registry-integration cd registry-integration Download the installation package. You can download the latest registry-integration-$version.tar.gz package from Releases.\nmkdir registry-integration tar -zxvf registry-integration-$version.tar.gz -C registry-integration cd registry-integration 2. Start registry-integration. Linux/Unix/Mac Startup command: sh bin/startup.sh\nWindows Double click the startup.bat file under the bin directory.\n3. Check the running status. You can access the healthcheck API provided by these three roles, or view logs/registry-startup.log to check the running status.\n# View the healthcheck API of the meta role: $ curl http://localhost:9615/health/check {\u0026amp;#34;success\u0026amp;#34;:true,\u0026amp;#34;message\u0026amp;#34;:\u0026amp;#34;... raftStatus:Leader\u0026amp;#34;} # View the healthcheck API of the data role: $ curl http://localhost:9622/health/check {\u0026amp;#34;success\u0026amp;#34;:true,\u0026amp;#34;message\u0026amp;#34;:\u0026amp;#34;... status:WORKING\u0026amp;#34;} # View the healthcheck API of the session role: $ curl http://localhost:9603/health/check {\u0026amp;#34;success\u0026amp;#34;:true,\u0026amp;#34;message\u0026amp;#34;:\u0026amp;#34;...\u0026amp;#34;} ","date":-62135596800,"description":"","dir":"projects/sofa-registry/server-quick-start/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"b620900b56ba04f4668838846a97698a","permalink":"/en/projects/sofa-registry/server-quick-start/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-registry/server-quick-start/","summary":"Deployment SOFARegistry supports two types of deployment modes, which are integrated deployment and independent deployment. This topic describes the simplest integrated single-node deployment. For more information about deployment modes, see the Deployment topic.\nDeployment steps 1. Download the source code or installation package. Download the source code. git clone https://github.com/sofastack/sofa-registry.git cd sofa-registry mvn clean package -DskipTests cp server/distribution/integration/target/registry-integration.tgz \u0026lt;somewhere\u0026gt; cd \u0026lt;somewhere\u0026gt; \u0026amp;\u0026amp; mkdir registry-integration tar -zxvf registry-integration.tgz -C registry-integration cd registry-integration Download the installation package.","tags":null,"title":"Server deployment","type":"projects","url":"/en/projects/sofa-registry/server-quick-start/","wordcount":176},{"author":null,"categories":null,"content":"本文是关于 MOSN server 配置的说明。\n虽然 MOSN 的配置结构里 servers 是一个 server 数组，但是目前最多只支持配置一个server。\nserver 描述的 MOSN 的基本的全局参数如下所示。\n{ \u0026amp;quot;default_log_path\u0026amp;quot;:\u0026amp;quot;\u0026amp;quot;, \u0026amp;quot;default_log_level\u0026amp;quot;:\u0026amp;quot;\u0026amp;quot;, \u0026amp;quot;global_log_roller\u0026amp;quot;:\u0026amp;quot;\u0026amp;quot;, \u0026amp;quot;graceful_timeout\u0026amp;quot;:\u0026amp;quot;\u0026amp;quot;, \u0026amp;quot;processor\u0026amp;quot;:\u0026amp;quot;\u0026amp;quot;, \u0026amp;quot;listeners\u0026amp;quot;:[] } default_log_path 默认的错误日志文件路径，支持配置完整的日志路径，以及标准输出（stdout）和标准错误（stderr）。\n 如果配置为空，则默认输出到标准错误（stderr）。  default_log_level 默认的错误日志级别，支持DEBUG、INFO、WARN、ERROR、FATAL。\n 如果配置为空，则默认为 INFO。  global_log_roller  日志轮转配置，会对所有的日志生效，如 tracelog、accesslog、defaultlog。 字符串配置，支持两种模式的配置，一种是按时间轮转，一种是按日志大小轮转。同时只能有一种模式生效。 按照日志大小轮转  size， 表示日志达到多少 M 进行轮转。 age，表示最多保存多少天的日志。 keep，表示最多保存多少个日志。 compress，表示日志是否压缩，on 为压缩，off 为不压缩。    \u0026amp;quot;global_log_roller\u0026amp;quot;: \u0026amp;quot;size=100 age=10 keep=10 compress=off\u0026amp;quot;  按照时间轮转  time，表示每个多少个小时轮转一次。    \u0026amp;quot;global_log_roller\u0026amp;quot;:\u0026amp;quot;time=1\u0026amp;quot; graceful_timeout  Duration String 的字符串配置，表示 MOSN 在进行平滑升级时，等待连接关闭的最大时间。 如果没有配置，默认为 30s。  processor MOSN 使用的 GOMAXPROCS 数量\n 如果没有配置，默认为 CPU 数量。 如果配置为 0，等价于没有配置。  Listeners 一组 Listener 的配置。\n","date":-62135596800,"description":"","dir":"projects/mosn/configuration/server/overview/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"3b43981b2aebeca5879d566d8264f6b6","permalink":"/projects/mosn/configuration/server/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/mosn/configuration/server/overview/","summary":"本文是关于 MOSN server 配置的说明。 虽然 MOSN 的配置结构里 servers 是一个 server 数组，但是目前最多只支持配置一个server。 server 描述的 MOSN 的基本的全局参数如下所示。 { \u0026quot;default_log_path\u0026quot;:\u0026quot;\u0026quot;,","tags":null,"title":"Server 配置说明","type":"projects","url":"/projects/mosn/configuration/server/overview/","wordcount":526},{"author":null,"categories":null,"content":"SOFADashboard\u0026amp;rsquo;s service governance mainly manages SOFARPC services.\nConsole The service governance console mainly provides two basic functions: service name query and service information display. When you click the hyperlink of a service ID, you are redirected to the details page of the service.\nService provider details page Service consumer details page ","date":-62135596800,"description":"","dir":"projects/sofa-dashboard/governance/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"e547baf489fd5d125be9e67a366854b6","permalink":"/en/projects/sofa-dashboard/governance/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-dashboard/governance/","summary":"SOFADashboard\u0026rsquo;s service governance mainly manages SOFARPC services.\nConsole The service governance console mainly provides two basic functions: service name query and service information display. When you click the hyperlink of a service ID, you are redirected to the details page of the service.\nService provider details page Service consumer details page ","tags":null,"title":"Service governance","type":"projects","url":"/en/projects/sofa-dashboard/governance/","wordcount":51},{"author":null,"categories":null,"content":"The basic configuration for SOFARPC service publishing and reference is described in the \u0026amp;ldquo;Programming Interface\u0026amp;rdquo; chapter. Here are some of the features of service publishing and referencing.\nOne service publishes multiple protocols In SOFARPC, a service can be published as multiple protocols, which allows the callers to call the service provider using different protocols.\nIf you use the Java API, you can build multiple ServerConfigs as follows to set different protocols for different ServerConfigs and then assign these ServerConfigs to ProviderConfig:\nList\u0026amp;lt;ServerConfig\u0026amp;gt; serverConfigs = new ArrayList\u0026amp;lt;ServerConfig\u0026amp;gt;(); serverConfigs.add(serverConfigA); serverConfigs.add(serverConfigB); providerConfig.setServer(serverConfigs); If you use XML, add multiple bindings directly in the \u0026amp;lt;sofa:service\u0026amp;gt; tag:\n\u0026amp;lt;sofa:service ref=\u0026amp;#34;sampleFacadeImpl\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofa.rpc.bean.SampleFacade\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt/\u0026amp;gt; \u0026amp;lt;sofa:binding.rest/\u0026amp;gt; \u0026amp;lt;sofa:binding.dubbo/\u0026amp;gt; \u0026amp;lt;/sofa:service\u0026amp;gt; If you use annotation, add multiple bindings in @SofaService:\n@SofaService ( interfaceType = SampleService.class, bindings = { @SofaServiceBinding(bindingType = \u0026amp;#34;rest\u0026amp;#34;), @SofaServiceBinding(bindingType = \u0026amp;#34;bolt\u0026amp;#34;) } ) public class SampleServiceImpl implements SampleService { // ... } One service registers multiple registry centers If you use the API, build multiple RegistryConfigs and assign them to ProviderConfig:\nList\u0026amp;lt;RegistryConfig\u0026amp;gt; registryConfigs = new ArrayList\u0026amp;lt;RegistryConfig\u0026amp;gt;(); registryConfigs.add(registryA); registryConfigs.add(registryB); providerConfig.setRegistry(registryConfigs); Method-level parameter settings In the Java API mode, you can set the corresponding parameters by calling the set method of the MethodConfig object, as shown below:\nMethodConfig methodConfigA = new MethodConfig(); MethodConfig methodConfigB = new MethodConfig(); List\u0026amp;lt;MethodConfig\u0026amp;gt; methodConfigs = new ArrayList\u0026amp;lt;MethodConfig\u0026amp;gt;(); methodConfigs.add(methodConfigA); methodConfigs.add(methodConfigB); providerConfig.setMethods(methodConfigs); //server settings consumerConfig.setMethods(methodConfigs); //Client settings In the XML mode, you can use the \u0026amp;lt;sofa:method\u0026amp;gt; tag in the corresponding binding to set the corresponding parameters:\n\u0026amp;lt;sofa:reference id=\u0026amp;#34;personReferenceBolt\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofa.boot.examples.demo.rpc.bean.PersonService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;sofa:global-attrs timeout=\u0026amp;#34;3000\u0026amp;#34; address-wait-time=\u0026amp;#34;2000\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;!-- Call timeout; address wait time. --\u0026amp;gt; \u0026amp;lt;sofa:route target-url=\u0026amp;#34;127.0.0.1:22000\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;!-- Directly connected address --\u0026amp;gt; \u0026amp;lt;sofa:method name=\u0026amp;#34;sayName\u0026amp;#34; timeout=\u0026amp;#34;3000\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;!-- Method level configuration --\u0026amp;gt; \u0026amp;lt;/sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt; \u0026amp;lt;sofa:service ref=\u0026amp;#34;sampleFacadeImpl\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofa.rpc.bean.SampleFacade\u0026amp;#34;\u0026amp;gt; …","date":-62135596800,"description":"","dir":"projects/sofa-rpc/publish-and-reference/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"6a78b8b84b226eaf1e6d2b1ff1d15fee","permalink":"/en/projects/sofa-rpc/publish-and-reference/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-rpc/publish-and-reference/","summary":"The basic configuration for SOFARPC service publishing and reference is described in the \u0026ldquo;Programming Interface\u0026rdquo; chapter. Here are some of the features of service publishing and referencing.\nOne service publishes multiple protocols In SOFARPC, a service can be published as multiple protocols, which allows the callers to call the service provider using different protocols.\nIf you use the Java API, you can build multiple ServerConfigs as follows to set different protocols for different ServerConfigs and then assign these ServerConfigs to ProviderConfig:","tags":null,"title":"Service publishing and reference","type":"projects","url":"/en/projects/sofa-rpc/publish-and-reference/","wordcount":348},{"author":null,"categories":null,"content":"This document describes the complete SOFARPC service publishing and reference in the SOFABoot environment.\nPublish service \u0026amp;lt;bean id=\u0026amp;#34;helloSyncServiceImpl\u0026amp;#34; class=\u0026amp;#34;com.alipay.sofa.rpc.samples.invoke.HelloSyncServiceImpl\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;sofa:service ref=\u0026amp;#34;helloSyncServiceImpl\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofa.rpc.samples.invoke.HelloSyncService\u0026amp;#34; unique-id=\u0026amp;#34;\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;sofa:global-attrs registry=\u0026amp;#34;\u0026amp;#34; serialize-type=\u0026amp;#34;\u0026amp;#34; filter=\u0026amp;#34;\u0026amp;#34; timeout=\u0026amp;#34;3000\u0026amp;#34; thread-pool-ref=\u0026amp;#34;\u0026amp;#34; warm-up-time=\u0026amp;#34;60000\u0026amp;#34; warm-up-weight=\u0026amp;#34;10\u0026amp;#34; weight=\u0026amp;#34;100\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;sofa:binding.rest\u0026amp;gt; \u0026amp;lt;/sofa:binding.rest\u0026amp;gt; \u0026amp;lt;/sofa:service\u0026amp;gt;    Attribute Name Default value Comment     id ID bean名    class Class None    ref Service interface implementation class     interface Service interface (unique identifier)  Use actual interface class for both normal calls and return calls   unique-id Service tag (unique identifier)     filter Filter configuration alias  Separated by commas   registry Server registry center  Separated by commas   timeout Execution timeout period on the server     serialize-type Serialization protocol hessian2,protobuf    thread-pool-ref Thread pool used by the current interface of the server None    weight Service static weight     warm-up-weight Service warm-up weight     warm-up-time Service warm-up time  Unit: millisecond    Reference service \u0026amp;lt;sofa:reference jvm-first=\u0026amp;#34;false\u0026amp;#34; id=\u0026amp;#34;helloSyncServiceReference\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofa.rpc.samples.invoke.HelloSyncService\u0026amp;#34; unique-id=\u0026amp;#34;\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;sofa:global-attrs type=\u0026amp;#34;sync\u0026amp;#34; timeout=\u0026amp;#34;3000\u0026amp;#34; callback-ref=\u0026amp;#34;\u0026amp;#34; callback-class=\u0026amp;#34;\u0026amp;#34; address-wait-time=\u0026amp;#34;1000\u0026amp;#34; connect.num=\u0026amp;#34;1\u0026amp;#34; check=\u0026amp;#34;false\u0026amp;#34; connect.timeout=\u0026amp;#34;1000\u0026amp;#34; filter=\u0026amp;#34;\u0026amp;#34; generic-interface=\u0026amp;#34;\u0026amp;#34; idle.timeout=\u0026amp;#34;1000\u0026amp;#34; idle.timeout.read=\u0026amp;#34;1000\u0026amp;#34; lazy=\u0026amp;#34;false\u0026amp;#34; loadBalancer=\u0026amp;#34;\u0026amp;#34; registry=\u0026amp;#34;\u0026amp;#34; retries=\u0026amp;#34;1\u0026amp;#34; serialize-type=\u0026amp;#34;\u0026amp;#34; /\u0026amp;gt; \u0026amp;lt;sofa:route target-url=\u0026amp;#34;xxx:12200\u0026amp;#34; /\u0026amp;gt; \u0026amp;lt;sofa:method name=\u0026amp;#34;hello\u0026amp;#34; callback-class=\u0026amp;#34;\u0026amp;#34; callback-ref=\u0026amp;#34;\u0026amp;#34; timeout=\u0026amp;#34;3000\u0026amp;#34; type=\u0026amp;#34;sync\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt;    Attribute Name Default value Comment     id ID Generated automatically    jvm-first Whether to call the service of local machine first true    interface Service interface (unique identifier)  Use actual interface class for both normal calls and return calls   unique-id Service tag (unique identifier)     local-first whether refer to the service via jvm call true set it to false if this is to call a remote service via rpc   type Calling type sync callback,sync,future,oneway   filter Filter configuration alias  List   registry Server registry center  List   method Method-level configuration  Same as above …","date":-62135596800,"description":"","dir":"projects/sofa-rpc/rpc-config-xml-explain/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"4b5110e9eb6cf6c6f287aef0fd210047","permalink":"/en/projects/sofa-rpc/rpc-config-xml-explain/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/rpc-config-xml-explain/","summary":"This document describes the complete SOFARPC service publishing and reference in the SOFABoot environment. Publish service \u0026lt;bean id=\u0026#34;helloSyncServiceImpl\u0026#34; class=\u0026#34;com.alipay.sofa.rpc.samples.invoke.HelloSyncServiceImpl\u0026#34;/\u0026gt; \u0026lt;sofa:service ref=\u0026#34;helloSyncServiceImpl\u0026#34; interface=\u0026#34;com.alipay.sofa.rpc.samples.invoke.HelloSyncService\u0026#34; unique-id=\u0026#34;\u0026#34;\u0026gt; \u0026lt;sofa:binding.bolt\u0026gt; \u0026lt;sofa:global-attrs registry=\u0026#34;\u0026#34; serialize-type=\u0026#34;\u0026#34; filter=\u0026#34;\u0026#34; timeout=\u0026#34;3000\u0026#34; thread-pool-ref=\u0026#34;\u0026#34; warm-up-time=\u0026#34;60000\u0026#34; warm-up-weight=\u0026#34;10\u0026#34; weight=\u0026#34;100\u0026#34;/\u0026gt; \u0026lt;/sofa:binding.bolt\u0026gt; \u0026lt;sofa:binding.rest\u0026gt; \u0026lt;/sofa:binding.rest\u0026gt; \u0026lt;/sofa:service\u0026gt; Attribute Name Default value Comment id ID bean名 class Class None ref Service interface implementation class interface Service interface (unique identifier) Use actual interface class for both normal calls","tags":null,"title":"Service publishing and reference in SOFABoot","type":"projects","url":"/en/projects/sofa-rpc/rpc-config-xml-explain/","wordcount":356},{"author":null,"categories":null,"content":"If you want to extend a registry center, you should take a look at the abstract classes of the registry center.\npackage com.alipay.sofa.rpc.registry; @Extensible(singleton = false) public abstract class Registry implements Initializable, Destroyable { public abstract boolean start(); public abstract void register(ProviderConfig config); public abstract void unRegister(ProviderConfig config); public abstract void batchUnRegister(List\u0026amp;lt;ProviderConfig\u0026amp;gt; configs); public abstract List\u0026amp;lt;ProviderGroup\u0026amp;gt; subscribe(ConsumerConfig config); public abstract void unSubscribe(ConsumerConfig config); public abstract void batchUnSubscribe(List\u0026amp;lt;ConsumerConfig\u0026amp;gt; configs); } You can see the main necessary interfaces.\n Start the registry client and maintain the connection; Destroy the registry client and release resources; Publish service and cache publish information; Unpublish service and delete cache; Subscribe to service list, return data synchronously or asynchronously, and receive notifications upon changes Unsubscribe service list and delete cache  Other interfaces:\n When the registry center node is disconnected, the local call is not affected. Switch from one disconnected registry center node to another one by itself. After switching to another registry center node, the system resumes the registration and subscription information automatically. The registry data is cached to the local file. Even if no registry center node is connected, the service provider and caller can restart and call normally.  ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/registry-extension-guide/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"c952ecbea16f7ae68ad095ab8baf0583","permalink":"/en/projects/sofa-rpc/registry-extension-guide/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/registry-extension-guide/","summary":"If you want to extend a registry center, you should take a look at the abstract classes of the registry center.\npackage com.alipay.sofa.rpc.registry; @Extensible(singleton = false) public abstract class Registry implements Initializable, Destroyable { public abstract boolean start(); public abstract void register(ProviderConfig config); public abstract void unRegister(ProviderConfig config); public abstract void batchUnRegister(List\u0026lt;ProviderConfig\u0026gt; configs); public abstract List\u0026lt;ProviderGroup\u0026gt; subscribe(ConsumerConfig config); public abstract void unSubscribe(ConsumerConfig config); public abstract void batchUnSubscribe(List\u0026lt;ConsumerConfig\u0026gt; configs); } You can see the main necessary interfaces.","tags":null,"title":"Service Registry extension guide","type":"projects","url":"/en/projects/sofa-rpc/registry-extension-guide/","wordcount":192},{"author":null,"categories":null,"content":"Sidecar 模式是 Service Mesh 中习惯采用的模式，是容器设计模式的一种，在 Service Mesh 出现之前该模式就一直存在，本文将为您讲解 Sidecar 模式。\n什么是 Sidecar 模式 将应用程序的功能划分为单独的进程可以被视为 Sidecar 模式。如图所示，Sidecar 模式允许您在应用程序旁边添加更多功能，而无需额外第三方组件配置或修改应用程序代码。\n就像连接了 Sidecar 的三轮摩托车一样，在软件架构中， Sidecar 连接到父应用并且为其添加扩展或者增强功能。Sidecar 应用与主应用程序松散耦合。它可以屏蔽不同编程语言的差异，统一实现微服务的可观察性、监控、日志记录、配置、断路器等功能。\n使用 Sidecar 模式的优势 Sidecar 模式具有以下优势：\n  将与应用业务逻辑无关的功能抽象到共同基础设施降低了微服务代码的复杂度。\n  因为不再需要编写相同的第三方组件配置文件和代码，所以能够降低微服务架构中的代码重复度。\n  降低应用程序代码和底层平台的耦合度。\n  Sidecar 模式如何工作 Sidecar 是容器应用模式的一种，也是在 Service Mesh 中发扬光大的一种模式，详见 Service Mesh 架构解析，其中详细描述使用了节点代理和 Sidecar 模式的 Service Mesh 架构。\n使用 Sidecar 模式部署服务网格时，无需在节点上运行代理，但是集群中将运行多个相同的 Sidecar 副本。在 Sidecar 部署方式中，每个应用的容器旁都会部署一个伴生容器，这个容器称之为 Sidecar 容器。Sidecar 接管进出应用容器的所有流量。在 Kubernetes 的 Pod 中，在原有的应用容器旁边注入一个 Sidecar 容器，两个容器共享存储、网络等资源，可以广义的将这个包含了 Sidecar 容器的 Pod 理解为一台主机，两个容器共享主机资源。\n","date":-62135596800,"description":"","dir":"projects/mosn/concept/sidecar-pattern/","fuzzywordcount":700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"38b45799d69d52f24f26008cd2ad7da5","permalink":"/projects/mosn/concept/sidecar-pattern/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/mosn/concept/sidecar-pattern/","summary":"Sidecar 模式是 Service Mesh 中习惯采用的模式，是容器设计模式的一种，在 Service Mesh 出现之前该模式就一直存在，本文将为您讲解 Sidecar 模式。 什么是 Sidecar 模式 将应用程序的功能划分为","tags":null,"title":"Sidecar 模式","type":"projects","url":"/projects/mosn/concept/sidecar-pattern/","wordcount":602},{"author":null,"categories":null,"content":"Since SOFARPC 5.4.0, the link analysis feature of Skywalking is supported. You can use it as needed. The Skywalking must be 6.0.0-alpha and above.\nThis document does not cover the backend deployment. If you need it, please refer to the official Skywalking documentation.\nInstall Java agent   Locate the agent directory in the downloaded Skywalking release package.\n  Set agent.service_name in config/agent.config, which can be any English character. Generally, it can be your own system name.\n  Set the collector.backend_service Skywalking backend address in config/agent.config, which defaults to 127.0.0.1:11800. It is used for local verification.\n  Add -javaagent:/path/to/skywalking-package/agenxt/skywalking-agent.jar to the application, which must be placed before the -jar parameter. The skywalking-agent can be gotten in official release package. The new directory structure is as follows:\n  +-- agent +-- activations apm-toolkit-log4j-1.x-activation.jar apm-toolkit-log4j-2.x-activation.jar apm-toolkit-logback-1.x-activation.jar ... +-- config agent.config +-- plugins sofa-rpc-plugin-6.0.0-alpha.jar apm-feign-default-http-9.x.jar apm-httpClient-4.x-plugin.jar ..... skywalking-agent.jar Note: Ensure that the plugins/sofa-rpc-plugin-**.jar file exists.\nStart the application. After a period of RPC calls, you can view the UI to observe the calling link.  More For more relevant documents, please refer to\nSkywalking Agent installation documentation Skywalking Backend deployment documentation\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/skywalking-usage/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"3cd5fb45f1b981d0a8c54c8ce43b190b","permalink":"/en/projects/sofa-rpc/skywalking-usage/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/skywalking-usage/","summary":"Since SOFARPC 5.4.0, the link analysis feature of Skywalking is supported. You can use it as needed. The Skywalking must be 6.0.0-alpha and above.\nThis document does not cover the backend deployment. If you need it, please refer to the official Skywalking documentation.\nInstall Java agent   Locate the agent directory in the downloaded Skywalking release package.\n  Set agent.service_name in config/agent.config, which can be any English character. Generally, it can be your own system name.","tags":null,"title":"Skywalking","type":"projects","url":"/en/projects/sofa-rpc/skywalking-usage/","wordcount":181},{"author":null,"categories":null,"content":"SOFARPC 在5.4.0 及之后的版本中，已经支持 Skywalking 的链路分析的功能，用户可以根据需要进行使用，其中Skywalking 的版本 要求6.0.0-alpha及以上。本文档，不涉及后端的部署，如有需要，可查看 Skywalking 官方文档。\n安装 Java agent 1.在下载的 Skywalking 的release 包中找到 agent 目录。\n2.在config/agent.config 中设置 agent.service_name，可以是任何英文字符，一般可以设置为自己的系统名。\n3.在config/agent.config 中设置 collector.backend_service Skywalking 的后端地址，默认指向 127.0.0.1:11800,这个是为了本地验证的。\n4.给应用程序添加 -javaagent:/path/to/skywalking-package/agenxt/skywalking-agent.jar，其中注意，一定要放在 -jar 参数之前。 Agent 在 kywalking 的 官方 release 包. 新的目录结构如下.\n+-- agent +-- activations apm-toolkit-log4j-1.x-activation.jar apm-toolkit-log4j-2.x-activation.jar apm-toolkit-logback-1.x-activation.jar ... +-- config agent.config +-- plugins sofa-rpc-plugin-6.0.0-alpha.jar apm-feign-default-http-9.x.jar apm-httpClient-4.x-plugin.jar ..... skywalking-agent.jar 注意，确保plugins/sofa-rpc-plugin-**.jar 文件存在。\n5.启动应用程序，经过一段时间RPC调用后，可以查看 UI 来观察链路。\n更多 更多文档请参考\n Skywalking Agent 安装文档 Skywalking Backend 部署文档  ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/skywalking-usage/","fuzzywordcount":500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"3cd5fb45f1b981d0a8c54c8ce43b190b","permalink":"/projects/sofa-rpc/skywalking-usage/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/skywalking-usage/","summary":"SOFARPC 在5.4.0 及之后的版本中，已经支持 Skywalking 的链路分析的功能，用户可以根据需要进行使用，其中Skywalking 的版本 要求6.0.0-alpha","tags":null,"title":"Skywalking 链路分析","type":"projects","url":"/projects/sofa-rpc/skywalking-usage/","wordcount":482},{"author":null,"categories":null,"content":"AntCoreTest (ACTS) is a white-box test framework developed by Ant Financial based on years\u0026#39; testing knowledge and experience with the financial-level distributed architecture for the purpose of providing enterprises with a highly efficient, precise, and automated interface testing services. In addition to general testing capabilities such as data-driven testing provided by conventional open source frameworks like TestNG, ACTS offers new features such as model-driven testing, visualized editing, and a standard process engine to assist engineers with efficient and high quality test case compilation as well as standard and precise test validation for interface testing.\nACTS is a next generation testing framework based on the data model-driven testing engine. ACTS is applicable to context environments that require the integration of TestNg and Spring. ACTS uses the YAML file as the data carrier and builds data model drivers upon it, providing features such as the all-in-one editor, precise validation, and efficient test case management to significantly improve testing efficiency.\nOperating principle   Upon the start of the test script, ActsDataProvider starts the tested method (the method annotated by @Test), loads the corresponding test case data file (YAML file), and converts the data into corresponding PrepareData objects.\n  When runTest starts running, it passes PrepareData and test case names to ACTS. ACTS then assembles such information into the ActsRuntimeContext class, transmits it in the entire process, and initializes the TestUnitHandler. The running period of the runTest process method consists of the following stages:\n   Action Method     Clear clear(actsRuntimeContext)   Prepare prepare(actsRuntimeContext)   Execute execute(actsRuntimeContext)   Check check(actsRuntimeContext)      Description:\n Clear: Clean up the preparation data and validation data to avoid the negative impact of dirty data on the test script. Prepare: Prepare data such as DB data. Execute: Call the tested method, and capture the corresponding information, such as responses and exception messages. Check: Validate the corresponding information such as the responses, DB data, and exception messages based on the test data.  Features ACTS provides the following features:\n2.1 All-in-one editor The ACTS framework separates the test data from the test code, and provides the visual editor ACTS IDE. ACTS IDE can help you quickly enter, view, and manage the test case data, which significantly reduces repetitive coding.\n2.2 Precise validation To improve data fill-in efficiency and reduce omission of check points among the expectation data, such as response expectations and database expectations, the ACTS framework provides a run and backfill function. In addition, ACTS uses validation rule flags to implement precise validation of the expectation data.\n2.3 Flexible scalability ACTS provides a rich variety of APIs, which are encapsulated in the ActsRuntimeContext class. The APIs …","date":-62135596800,"description":"","dir":"projects/sofa-acts/overview/","fuzzywordcount":600,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"ac57071cd0d40a63359d476d05344c61","permalink":"/en/projects/sofa-acts/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/en/projects/sofa-acts/overview/","summary":"AntCoreTest (ACTS) is a white-box test framework developed by Ant Financial based on years' testing knowledge and experience with the financial-level distributed architecture for the purpose of providing enterprises with a highly efficient, precise, and automated interface testing services. In addition to general testing capabilities such as data-driven testing provided by conventional open source frameworks like TestNG, ACTS offers new features such as model-driven testing, visualized editing, and a standard process engine to assist engineers with efficient and high quality test case compilation as well as standard and precise test validation for interface testing.","tags":null,"title":"SOFAActs overview","type":"projects","url":"/en/projects/sofa-acts/overview/","wordcount":536},{"author":null,"categories":null,"content":"ACTS（AntCoreTest）源于蚂蚁金服多年金融级分布式架构工程的测试实践的积累与沉淀，是一款白盒测试框架，旨在为企业提供高效、精细化的接口自动化测试。 与现有的诸如 TestNG 等开源框架相比，ACTS 除了具备通用的数据自动化驱动等测试能力外，还具有契合快速的互联网发展和复杂的分布式金融系统特点的模型驱动、可视化编辑和标准流程引擎等新特性，可辅助工程师高效、高质量地完成接口测试用例编写以及标准化精准化测试验证。\nACTS 是基于数据模型驱动测试引擎执行的的新一代测试框架（如图1所示），适配 TestNg+Spring 的测试上下文环境，以 YAML 为数据载体并在此上构建数据模型驱动，实现了一站式编辑、精细化校验和高效用例管理等，可以有效提高测试效率。\n运行原理  测试脚本启动的时，ActsDataProvider 会启动被测方法（被 @Test 注解的方法），加载对应的用例数据文件(以 YAML 文件承载)，然后转换成对应的 PrepareData 对象； runTest 开始执行时会传入 PrepareData 和用例名称，ACTS 根据这些信息组装出 ActsRuntimeContext 上下文并在整个过程中传递，同时初始化 TestUnitHandler 测试处理器。runTest -\u0026amp;gt; process 方法执行期包含如下四个子流程：    说明 方法     清理 clear(actsRuntimeContext)   准备 prepare(actsRuntimeContext)   执行 execute(actsRuntimeContext)   检查 check(actsRuntimeContext)      方法功能说明：\n 清理阶段：清理准备数据、校验数据，防止脏数据对测试脚本产生影响； 准备阶段：准备 DB 数据等； 执行阶段：调用被测方法，捕获返回结果和异常等信息； 检查阶段：根据测试数据，校验返回结果、DB 数据和异常信息等内容。  功能描述 ACTS 提供了以下能力：\n2.1 一站式编辑 框架实现了测试数据与测试代码的分离，同时配套提供可视化编辑器 ACTS IDE，通过 ACTS IDE 可以快速地录入、查看和管理用例数据，有效减少重复性编码。\n2.2 精细化校验 为了提高返回结果、DB 数据等期望数据的填写效率和减少检验点遗漏，框架提供了预跑返填功能；同时在 ACTS 校验规则标签的标记下，实现期望 DB 数据、期望结果等数据的精细化校验。\n2.3 灵活可扩展 ACTS 提供了丰富的 API ，其封装于 ActsRuntimeContext 类中，借助 API 可快速获取和设置自定义参数、用例入参、期望结果等，满足用户对用例数据的自定义操作；\n同时，框架的 ActsTestBase 测试基类对外暴露各个执行阶段方法，包括 prepare，execute，check，clear 等，例如在测试类中通过重写 process 方法可将整个测试脚本重新编排。\n2.4 统一配置能力 配置文件中提供丰富的配置能力以定制化框架的个性需求。\n应用场景 基于 SOFABoot 搭建的应用，在 Intellij IDEA 开发环境下快速编写和执行接口测试用例。推荐使用 Intellij IDEA 2017 以便能更好地兼容 ACTS IDE。\n","date":-62135596800,"description":"","dir":"projects/sofa-acts/overview/","fuzzywordcount":1000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"ac57071cd0d40a63359d476d05344c61","permalink":"/projects/sofa-acts/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-acts/overview/","summary":"ACTS（AntCoreTest）源于蚂蚁金服多年金融级分布式架构工程的测试实践的积累与沉淀，是一款白盒测试框架，旨在为企业提供高效、精细化","tags":null,"title":"SOFAActs 介绍","type":"projects","url":"/projects/sofa-acts/overview/","wordcount":994},{"author":null,"categories":null,"content":"SOFAArk offers a variety of methods to support multi-application (module) consolidation and deployment, including command line-based control and API-based control. SOFAArk control is an implementation of SOFADashboard\u0026amp;rsquo;s control over APIs. SOFAArk control is implemented by pushing commands to and parsing commands in ZooKeeper.\nSOFAArk control mainly provides the following functions:\n Plug-in registration: registers the ark-biz package with SOFADashboard as basic data processors. Application association: binds the ark-biz package with host applications. Plug-in details: On the plug-in details page, you can view the information about all host applications that are associated with the current ark-biz package, as well as the status information of the ark-biz package in these host applications. Command push: On the plug-in details page, you can push some commands for specific applications and IP addresses, such as install and uninstall. When these commands are written to a ZooKeeper node, all host applications that listen to this node will parse the commands and perform related operations.  Plug-in registration Register the ark-biz package with SOFADashboard:\nEnter basic information of the plug-in\nAfter successful registration, the plug-in is displayed on the module list as follows.\nApplication association Click Associate application in the Actions column of a plug-in on the module list to associate it with an application.\nClick Associate application in the Actions column of the plug-in to associate it with an application.\nPlug-in details Click Details in the Actions column of a plug-in to view all apps and app instances associated with the current plug-in.\n Version switch  After switching the plug-in to V2.0.0, the status information is empty, because the plug-in V2.0.0 has not been installed in the host application.\nCommand push SOFADashboard supports command push in two dimensions:\n Application-based command push, where all instances of the specified application listen to this command IP-based and group-based command push for single-IP address scenarios  IP-based command push Click Install. The page is refreshed after about 1s to 1.5s.\n Application-based command push is similar.\n ","date":-62135596800,"description":"","dir":"projects/sofa-dashboard/ark-console/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"b42cffbb8e55a4c47412e49de0e9b228","permalink":"/en/projects/sofa-dashboard/ark-console/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-dashboard/ark-console/","summary":"SOFAArk offers a variety of methods to support multi-application (module) consolidation and deployment, including command line-based control and API-based control. SOFAArk control is an implementation of SOFADashboard\u0026rsquo;s control over APIs. SOFAArk control is implemented by pushing commands to and parsing commands in ZooKeeper.\nSOFAArk control mainly provides the following functions:\n Plug-in registration: registers the ark-biz package with SOFADashboard as basic data processors. Application association: binds the ark-biz package with host applications.","tags":null,"title":"SOFAArk control","type":"projects","url":"/en/projects/sofa-dashboard/ark-console/","wordcount":321},{"author":null,"categories":null,"content":"SOFAArk 是一款基于 Java 实现的轻量级类隔离容器，主要提供类隔离和应用(模块)合并部署能力，由蚂蚁金服公司开源贡献；\n在大型软件开发过程中，通常会推荐底层功能插件化，业务功能模块化的开发模式，以期达到低耦合、高内聚、功能复用的优点。基于此，SOFAArk 提供了一套较为规范化的插件化、模块化的开发方案，产品能力主要包括：\n 定义类加载模型，运行时底层插件、业务应用(模块)之间均相互隔离，单一插件和应用(模块)由不同的 ClassLoader 加载，可以有效避免相互之间的包冲突，提升插件和模块功能复用能力； 定义插件开发规范，提供 maven 打包工具，简单快速将多个二方包打包成插件（Ark Plugin，以下简称 Plugin） 定义模块开发规范，提供 maven 打包工具，简单快速将应用打包成模块 (Ark Biz，以下简称 Biz) 针对 Plugin、Biz 提供标准的编程界面，包括服务、事件、扩展点等机制 支持多 Biz 的合并部署，开发阶段将多个 Biz 打包成可执行 Fat Jar，或者运行时使用 API 或配置中心(Zookeeper)动态地安装卸载 Biz  基于以上能力，SOFAArk 可以帮助解决依赖包冲突、多应用(模块)合并部署等场景问题。\n场景 包冲突 日常使用 Java 开发，常常会遇到包依赖冲突的问题，尤其当应用变得臃肿庞大，包冲突的问题也会变得更加棘手，导致各种各样的报错，例如 LinkageError, NoSuchMethodError 等；实际开发中，可以采用多种方法来解决包冲突问题，比较常见的是类似 Spring Boot 的做法，统一管理应用所有依赖包的版本，保证这些三方包不存在依赖冲突；这种做法只能有效避免包冲突问题，不能根本上解决包冲突的问题；如果某个应用的确需要在运行时使用两个相互冲突的包，例如 protobuf2 和 protobuf3，那么类似 Spring Boot 的做法依然解决不了问题。\n为了彻底解决包冲突的问题，需要借助类隔离机制，使用不同的 ClassLoader 加载不同版本的三方依赖，进而隔离包冲突问题； OSGI 作为业内最出名的类隔离框架，自然是可以被用于解决上述包冲突问题，但是 OSGI 框架太过臃肿，功能繁杂；为了解决包冲突问题，引入 OSGI 框架，有牛刀杀鸡之嫌，且反而使工程变得更加复杂，不利于开发；\nSOFAArk 采用轻量级的类隔离方案来解决日常经常遇到的包冲突问题，在蚂蚁金服内部服务于整个 SOFABoot 技术体系，弥补 Spring Boot 没有的类隔离能力。SOFAArk 提出了一种特殊的包结构 \u0026amp;ndash; Ark Plugin，在遇到包冲突时，用户可以使用 Maven 插件将若干冲突包打包成 Plugin，运行时由独立的 PluginClassLoader 加载，从而解决包冲突。\n假设如下场景，如果工程需要引入两个三方包：A 和 B，但是 A 需要依赖版本号为 0.1 的 C 包，而恰好 B 需要依赖版本号为 0.2 的 C 包，且 C 包的这两个版本无法兼容：\n此时，即可使用 SOFAArk 解决该依赖冲突问题；只需要把 A 和版本为 0.1 的 C 包一起打包成一个 Ark 插件，然后让应用工程引入该插件依赖即可；\n合并部署 复杂项目通常需要跨团队协作开发，各自负责不同的组件，而众所周知，协调跨团队合作开发会遇到不少问题；比如各自技术栈不统一导致的依赖冲突，又比如往同一个 Git 仓库提交代码常常导致 merge 冲突。因此，如果能让每个团队将负责的功能组件当成一个个单独的应用开发，运行时合并部署，通过统一的编程界面交互，那么将极大的提升开发效率及应用可扩展性。SOFAArk 提出了一种特殊的包结构 \u0026amp;ndash; Ark Biz，用户可以使用 Maven 插件将应用打包成 Biz，允许多 Biz 在 SOFAArk 容器之上合并部署，并通过统一的编程界面交互。\n静态合并部署 SOFAArk 提供了静态合并部署能力，在开发阶段，应用可以将其他应用打成的 Biz 包通过 Maven 依赖的方式引入，而当自身被打成可执行 Fat Jar 时，可以将其他应用 Biz 包一并打入，启动时，则会根据优先级依次启动各应用。每个 Biz 使用独立的 BizClassLoader 加载，不需要考虑相互依赖冲突问题，Biz 之间则通过 SofaService/SofaReference JVM 服务进行交互。\n动态合并部署 动态合并部署区别于静态合并部署最大的一点是，运行时通过 API 或者配置中心（Zookeeper）来控制 Biz 的部署和卸载。动态合并部署的设计理念图如下：\n无论是静态还是动态合并部署都会有宿主应用（master biz）的概念, 如果 Ark 包只打包了一个 Biz，则该 Biz 默认成为宿主应用；如果 Ark 包打包了多个 Biz 包，需要配置指定宿主应用。宿主应用不允许被卸载，一般而言，宿主应用会作为流量入口的中台系统，具体的服务实现会放在不同的动态 Biz 中，供宿主应用调用。宿主应用可以使用 SOFAArk 提供的客户端 API 实现动态应用的部署和卸载。除了 API, SOFAArk 提供了 Config Plugin，用于对接配置中心（目前支持 Zookeeper），运行时接受动态配置；Config Plugin 会解析下发的配置，控制动态应用的部署和卸载。\n原理 SOFAArk 包含三个概念，Ark Container, Ark Plugin 和 Ark Biz; 运行时逻辑结构图如下:\n在介绍这三个概念之前，先介绍上述 Ark 包概念；Ark 包是满足特定目录格式要求的可运行 Fat Jar，使用官方提供的 Maven 插件 sofa-ark-maven-plugin 可以将单个或多个应用打包成标准格式的 Ark 包；使用 java -jar 命令即可在 SOFAArk 容器之上启动所有应用；Ark 包通常包含 Ark Container、Ark Plugin 和 Ark Biz；以下我们针对这三个概念简单做下名词解释：\n  Ark Container: SOFAArk 容器，负责 Ark 包启动运行时的管理；Ark Plugin 和 Ark Biz 运行在 SOFAArk 容器之上；容器具备管理插件和应用的功能；容器启动成功后，会自动解析 classpath 包含的 Ark Plugin 和 Ark Biz 依赖，完成隔离加载并按优先级依次启动之；\n  Ark Plugin: Ark 插件，满足特定目录格式要求的 Fat Jar，使用官方提供的 Maven 插件 sofa-ark-plugin-maven-plugin 可以将一个或多个普通的 Java jar 打包成一个标准格式的 Ark Plugin；Ark Plugin 会包含一份配置文件，通常包括插件类导入导出配置、资源导入导出配置、插件启动优先级等；运行时，SOFAArk 容器会使用独立的 PluginClassLoader加载插件，并根据插件配置构建类加载索引表、资源加载索引表，使插件和插件之 …","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-readme/","fuzzywordcount":2600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"cdb6729fc7a63954b7559c8ea319f550","permalink":"/projects/sofa-boot/sofa-ark-readme/","publishdate":"0001-01-01T00:00:00Z","readingtime":6,"relpermalink":"/projects/sofa-boot/sofa-ark-readme/","summary":"SOFAArk 是一款基于 Java 实现的轻量级类隔离容器，主要提供类隔离和应用(模块)合并部署能力，由蚂蚁金服公司开源贡献； 在大型软件开发过程中，通常会推荐底层","tags":null,"title":"SOFAArk 介绍","type":"projects","url":"/projects/sofa-boot/sofa-ark-readme/","wordcount":2577},{"author":null,"categories":null,"content":"SOFAArk 本身提供了多种方式来支持多应用(模块)合并部署 ，包括基于命令行的管控，基于 API 的管控等；SOFAARK 管控是 SOFADashboard 针对 API 的管控的一种实现。通过面向 Zookeeper 进行命令的推送和命令的解析执行。\nSOFAArk 管控主要包括以下功能：\n 插件注册：将 ark-biz 插件注册到 SOFADashboard，作为基础数据 关联应用：将 ark-biz 插件与宿主应用进行绑定 插件详情：通过插件详情页，可以看下当前 ark-biz 插件下所有关联的宿主应用信息，以及宿主应用中的ark-biz 状态信息 命令推送：插件详情页，可以针对应用维度、分组维度、IP 维度 推送一些指令，比如 install、uninstall 等等，当这些命令被写入到 Zookeeper 的某个节点上时，所有监听此节点的 宿主应用均会解析此指令，并进行相关的操作  插件管理 插件注册 将 ark-biz 插件注册到 SOFADashboard：\n插件删除 添加插件版本 插件版本 biz 包路径 删除版本 关联应用 点击模块列表操作菜单栏中的关联应用，可以将一个应用与插件进行绑定：\n动态管控 点击插件列表后面的 详情 按钮，可以查看当前插件下所有应用信息和应用实例信息。\n命令推送 SOFADashboard 提供三种维度的命令推送\n 基于应用维度，当前应用所有的实例都会监听到此命令变更 基于IP 维度，分组维度的单 ip 场景  动态模块详情 点击 状态详细按钮，左侧栏将会展开 \u0026amp;ldquo;抽屉\u0026amp;rdquo; 展示详情状态数据\n","date":-62135596800,"description":"","dir":"projects/sofa-dashboard/ark-console/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"b42cffbb8e55a4c47412e49de0e9b228","permalink":"/projects/sofa-dashboard/ark-console/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-dashboard/ark-console/","summary":"SOFAArk 本身提供了多种方式来支持多应用(模块)合并部署 ，包括基于命令行的管控，基于 API 的管控等；SOFAARK 管控是 SOFADashboard 针对 API 的管控的一种实现。通过面","tags":null,"title":"SOFAArk 管控","type":"projects","url":"/projects/sofa-dashboard/ark-console/","wordcount":541},{"author":null,"categories":null,"content":"SOFAArk 的配置目录不是必须存在，如果需要，统一放在工程根目录 ${baseDir}/conf/ark 下，执行 sofa-ark-maven-plugin 打包，将会自动将该目录下的配置打包至 Ark 包，例如 Ark 包目录为：\n. ├── META-INF │ └── MANIFEST.MF ├── SOFA-ARK │ ├── biz │ │ └── demo-0.0.1-SNAPSHOT-ark-biz.jar │ └── container │ └── sofa-ark-all-0.6.0-SNAPSHOT.jar ├── com │ └── alipay │ └── sofa │ └── ark │ ├── ... │ └── conf └── ark ├── bootstrap-dev.properties ├── bootstrap.properties └── log └── logback-conf.xml 注意事项：如果应用中包含 SOFAArk 配置，打包时需要注意 baseDir 配置，用于指定工程根目录，具体参考文档\n上述 conf/ark 目录中可以配置 SOFAArk 容器启动配置以及日志配置，下面介绍配置的使用.\nconf/ark/bootstrap.properties 是 SOFAArk 容器默认启动配置文件，配置内容包括：日志配置、plugin 激活和钝化配置、biz 激活和钝化配置.\n日志配置 SOFAArk 容器日志内部实现使用 logback, 日志配置参数包括：\n logging.path   容器日志目录根路径，这里只影响 SOFAArk 容器日志路径，不影响应用日志，应用自身日志由自身配置决定，默认打印在 ${user.admin}/logs 目录\n  logging.level.com.alipay.sofa.ark   设置 SOFAArk 容器日志级别，默认为 INFO\n  logging.config.com.alipay.sofa.ark   指定自定义日志配置文件名，用于覆盖 SOFAArk 容器自带的日志配置文件。建议自定义配置文件放在 conf/ark/log 目录中\n  sofa.middleware.log.com.alipay.sofa.ark.console   配置容器日志是否打印在 console，默认为 false.\n  sofa.middleware.log.com.alipay.sofa.ark.console.level   配合上述配置项使用，如果打印在 console ，该配置项用于配置 SOFAArk 容器打印在 console 的日志级别\n 插件配置  ark.plugin.active.include   指定激活哪些插件，多个插件使用 \u0026amp;lsquo;,\u0026amp;rsquo; 分隔；默认激活 Ark 包中所有的插件。\n  ark.plugin.active.exclude   指定排除哪些插件，多个插件使用 \u0026amp;lsquo;,\u0026amp;rsquo; 分隔；默认为空\n 注：如果同时配置了这两个属性，以 ark.plugin.active.include 为准\nbiz配置  ark.biz.active.include   指定激活哪些 Biz，多个 Biz 使用 \u0026amp;lsquo;,\u0026amp;rsquo; 分隔；默认激活 Ark 包中所有的 Biz.\n  ark.biz.active.exclude   指定排除哪些 Biz，多个 Biz 使用 \u0026amp;lsquo;,\u0026amp;rsquo; 分隔；默认为空\n  com.alipay.sofa.ark.master.biz   指定宿主 Biz 名，如果 Ark 包中只有一个 Biz，则不用设置，默认设置为宿主 Biz; 否则需要显示设置\n 注：如果同时配置了前两个属性，以 ark.biz.active.include 为准\n动态配置 SOFAArk 提供了对接 Zookeeper 的插件，目前用于动态接收 Biz 指令，目前只支持 Zookeeper，配置格式如下：\ncom.alipay.sofa.ark.config.address=zookeeper://ip:port?key1=value1\u0026amp;amp;key2=value2 特别注意，SOFAArk 有一个默认的逻辑，如果用户配置了 com.alipay.sofa.ark.config.address，且 Ark 包中打入了多个 Biz，则只会启动宿主应用(master biz)；这样做的原因是如果配置了动态配置，SOFAArk 会优先根据动态配置控制 Biz 的部署。\nProfile 机制 默认 SOFAArk 容器使用 bootstrap.properties 配置，实际开发中，可能根据运行环境加载不同的配置，SOFAArk 提供了 profile 机制. 指定 profile 值，SOFAArk 容器会加载 bootstrap-${profile}.properties 配置文件。指定 profile 的配置有两种方式：\n 通过 -D VM 参数传入，例如：-Dark.profile=dev,dev2 多个值使用 \u0026amp;lsquo;,\u0026amp;rsquo; 隔开。 通过应用启动参数传入，例如：java -jar demo-executable-ark.jar -Aprofile=dev,dev2 多个值使用 \u0026amp;lsquo;,\u0026amp;rsquo; 隔开。  ","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-ark-config/","fuzzywordcount":1100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"70dd9c389e65ee3f89573cf93bd466ec","permalink":"/projects/sofa-boot/sofa-ark-ark-config/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/sofa-boot/sofa-ark-ark-config/","summary":"SOFAArk 的配置目录不是必须存在，如果需要，统一放在工程根目录 ${baseDir}/conf/ark 下，执行 sofa-ark-maven-plugin 打包，将会自动将该目录下的配置打包至 Ark 包，例如 Ark 包目录为： . ├── META-INF │ └─","tags":null,"title":"SOFAArk 配置","type":"projects","url":"/projects/sofa-boot/sofa-ark-ark-config/","wordcount":1023},{"author":null,"categories":null,"content":"Introduction SOFABolt is a network communication framework implemented based on Netty and developed by Ant Finance.\n Netty was developed to let Java programmers focus more on the implementation of network communication-based business logic, and not worry excessively about network low-level NIO implementation or network problems that are difficult to debug. SOFABolt was developed to let middleware developers focus more on the implementation of products\u0026#39; functional performance, and not on making the communication framework\u0026amp;rsquo;s wheels over and over again.  Bolt takes its name from a Disney movie character. Bolt is a light, easy-to-use, high-performance, and flexibly scalable communication framework based on the Netty best practices. In the past few years, we have solved a lot of problems in terms of network communication for microservices and message oriented middleware. We have accumulated a lot of experience and have been constantly optimizing and improving our solutions. We hope that our solutions can be incorporated into the SOFABolt base component to serve more network communication scenarios. At present, SOFABolt has already been put to use in many Ant Middleware products, such as microservice products (SOFARPC), message queue, distributed transactions, distributed switches, and configuration centers.\nMultiple languages supported  node Python cpp  ","date":-62135596800,"description":"","dir":"projects/sofa-bolt/overview/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"5ee08df7c4bbd2c3be846e16f3bc81b1","permalink":"/en/projects/sofa-bolt/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-bolt/overview/","summary":"Introduction SOFABolt is a network communication framework implemented based on Netty and developed by Ant Finance.\n Netty was developed to let Java programmers focus more on the implementation of network communication-based business logic, and not worry excessively about network low-level NIO implementation or network problems that are difficult to debug. SOFABolt was developed to let middleware developers focus more on the implementation of products' functional performance, and not on making the communication framework\u0026rsquo;s wheels over and over again.","tags":null,"title":"SOFABolt overview","type":"projects","url":"/en/projects/sofa-bolt/overview/","wordcount":196},{"author":null,"categories":null,"content":"功能架构 SOFABolt　的基础功能：  基础通信功能 ( remoting-core )  基于 Netty 高效的网络 IO 与线程模型运用 连接管理 (无锁建连，定时断链，自动重连) 基础通信模型 ( oneway，sync，future，callback ) 超时控制 批量解包与批量提交处理器 心跳与 IDLE 事件处理   协议框架 ( protocol-skeleton )  命令与命令处理器 编解码处理器 心跳触发器   私有协议定制实现 - RPC 通信协议 ( protocol-implementation )  RPC 通信协议的设计 灵活的反序列化时机控制 请求处理超时 FailFast 机制 用户请求处理器 ( UserProcessor ) 双工通信    用法1 将 SOFABolt 用作一个远程通信框架，使用者可以不用关心如何实现一个私有协议的细节，直接使用我们内置的 RPC 通信协议。可以非常简单的启动客户端与服务端，同时注册一个用户请求处理器，即可完成远程调用。同时，像连接管理、心跳等基础功能特性都默认可以使用。 当前支持的调用类型如下图所示：\n 示例 Demo 请参考我们的 用户手册  用法2 将 SOFABolt 用作一个协议框架，使用者可以复用基础的通信模型、协议包含的接口定义等基础功能。然后根据自己设计的私有协议自定义 Command 类型、Command 处理器、编解码处理器等。如下图所示，RPC 和消息的 Command 定义结构：\n","date":-62135596800,"description":"","dir":"projects/sofa-bolt/sofa-bolt-functions/","fuzzywordcount":500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"fde29139cbd8b786326a6479e52814dd","permalink":"/projects/sofa-bolt/sofa-bolt-functions/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-bolt/sofa-bolt-functions/","summary":"功能架构 SOFABolt 的基础功能： 基础通信功能 ( remoting-core ) 基于 Netty 高效的网络 IO 与线程模型运用 连接管理 (无锁建连，定时断链，自动重连) 基础通信模型 ( oneway，","tags":null,"title":"SOFABolt 功能介绍","type":"projects","url":"/projects/sofa-bolt/sofa-bolt-functions/","wordcount":450},{"author":null,"categories":null,"content":"参与贡献 开放代码允许在签署协议之后,提交贡献代码.\n版权协议 对 SOFABolt 代码的修改和变更，需要遵守版权协议。\n准备工作  贡献代码前需要先了解git工具的使用和GitHub网站的使用。 git 工具用法可以查看git官方书籍,需要阅读前几章来熟悉。 git 协作流程可以查看这篇文章Git协作流程  GitHub 贡献代码流程 提issue 不论你是修复 Bolt 的bug还是新增 Bolt 的功能，在你提交代码之前，在 Bolt 的GitHub上提交一个 issue, 描述你要修复的问题或者要增加的功能。这么做有几个好处:\n 不会与其它开发者或是他们对这个项目的计划发生冲突,产生重复工作。Bolt 的维护人员会对你提的bug或者新增功能进行相关讨论，确定该修改是不是必要，有没有提升的空间或更好的办法。 在达成一致后再开发,并提交代码，减少双方沟通成本，也减少pull request被拒绝的情况。  获取源码 要修改或新增功能，在提issue后，点击左上角的fork按钮，复制一份 Bolt 主干代码到你的代码仓库。\n拉分支 Bolt 所有修改都在分支上进行，修改完后提交 pull request ， 在code review 后由项目维护人员 merge 到主干。 因此，在获取源码步骤介绍后，你需要：\n 下载代码到本地,这一步你可以选择git/https方式.  git clone https://github.com/sofastack/sofa-bolt.git  拉分支准备修改代码  git branch add_xxx_feature  执行完上述命令后，你的代码仓库就切换到相应分支了。执行如下命令可以看到你当前分支：  git branch -a  如果你想切换回主干，执行下面命令:  git checkout -b master  如果你想切换回分支，执行下面命令：  git checkout -b \u0026amp;#34;branchName\u0026amp;#34;  想直接从github上拉取分支到本地  git clone -b branchname https://xxx.git 修改代码提交到本地 拉完分支后，就可以修改代码了。\n修改代码注意事项  代码风格保持一致 Bolt 通过 Maven插件来保持代码格式一致.在提交代码前,务必本地执行  mvn clean package  补充单元测试代码 新有修改应该通过已有的单元测试. 应该提供新的单元测试来证明以前的代码存在bugs，而新的代码已经解决了这些bugs.  你可以用如下命令运行所有测试\nmvn clean test 也可以通过IDE来辅助运行.\n其它注意事项  请保持你编辑的代码的原有风格,尤其是空格换行等. 对于无用的注释, 请直接删除 对逻辑和功能不容易被理解的地方添加注释. 及时更新文档 修改完代码后，执行如下命令提交所有修改到本地:  git commit -am \u0026amp;#39;添加xx功能\u0026amp;#39; 提交代码到远程仓库 在代码提交到本地后，就是与远程仓库同步代码了。执行如下命令提交本地修改到github上：\ngit push origin \u0026amp;#34;branchname\u0026amp;#34; 如果前面你是通过fork来做的,那么那么这里的 origin 是push到你的代码仓库，而不是 Bolt 的代码仓库.\n提交合并代码到主干的请求 在你的代码提交到GitHub后，你就可以发送请求来把你改好的代码合入 Bolt 主干代码了。此时你需要进入你的 GitHub 上的对应仓库，按右上角的 pull request按钮。选择目标分支,一般就是主干master, 系统会通知 Bolt 的人员，Bolt 人员会 review 你的代码，符合要求后就会合入主干，成为 Bolt 主干代码的一部分。\n代码review 在你提交代码后，你的代码会被指派给维护人员review,请保持耐心。如果在数天后，仍然没有人对你的提交给予任何回复，可以在pull request下面留言,并@对应的人员. 对于代码review的意见会提交到对应issue。如果觉得建议是合理的，也请你把这些建议更新到你的补丁中。\n合并代码到主干 在代码 Bolt 通过后，就由 Bolt 维护人员操作合入主干了。这一步不用参与,review合并之后,你会收到合并成功的提示.\nContributing to SOFABolt SOFABolt is released under the Apache 2.0 license, and follows a very standard Github development process, using Github tracker for issues and merging pull requests into master . If you would like to contribute something, or simply want to hack on the code this document should help you get started.\nSign the Contributor License Agreement Before we accept a non-trivial patch or pull request we will need you to sign the Contributor License Agreement. Signing the contributor’s agreement does not grant anyone commit rights to the main repository, but it does mean that we can accept your contributions, and you will get an author credit if we do. Active contributors might be asked to join the core team, and given the ability to merge pull requests.\nCode Conventions None of these is essential for a pull request, but they will all help.\n  we provided a code formatter file, it will formatting automatically your project when during process of building.\n  Make sure all new .java files to have a simple Javadoc class comment with at least an @author tag identifying you, and preferably at least a paragraph on what the class is for.\n  Add the ASF …","date":-62135596800,"description":"","dir":"projects/sofa-bolt/sofa-bolt-contribution/","fuzzywordcount":1700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"c044ad534cf99e4d6d400113b490f816","permalink":"/projects/sofa-bolt/sofa-bolt-contribution/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/projects/sofa-bolt/sofa-bolt-contribution/","summary":"参与贡献 开放代码允许在签署协议之后,提交贡献代码. 版权协议 对 SOFABolt 代码的修改和变更，需要遵守版权协议。 准备工作 贡献代码前需要先了解git工具的使","tags":null,"title":"SOFABolt 参与贡献","type":"projects","url":"/projects/sofa-bolt/sofa-bolt-contribution/","wordcount":1658},{"author":null,"categories":null,"content":"发展路线 Version 1.5.1  修复项目中代码风格的问题：https://github.com/alipay/sofa-bolt/issues/85 修复项目中已知的BUG：https://github.com/alipay/sofa-bolt/issues/82 RPC 层支持从 IO 线程派发 message list：https://github.com/alipay/sofa-bolt/pull/84  Version 1.6.0 整体目标  统一生命周期组件 抽象并沉淀网络组件的API 收敛配置入口\u0026amp;amp;增强配置的可扩展性  统一生命周期组件 在1.5.x的Bolt版本中，管理组件的生命周期相关的API命名并不统一，比如：\n ReconnectManager不需要启动或者初始化，关闭方法为stop DefaultConnectionMonitor初始化方法为start，关闭的方法为destroy RpcClient初始化方法为init，关闭的方法为shutdown RpcTaskScanner初始化的方法为start，关闭方法为shutdown  在1.6.0版本里，统一了所有组件的生命周期接口：\n 对于有生命周期的组件，即使用前需要进行初始化，使用完毕需要释放资源的，统一提供startup/shutdown接口  抽象并沉淀网络组件的API Bolt中remoting类是网络操作的主要入口，目前以抽象类的形式提供，后续希望对方法进行收敛，暴露对应的接口：\n 标准化，规范使用 沉淀接口，保持稳定 收敛入口，便于内部的代码迭代  在1.5.x的版本中，ReconnectManager类尽管提供了public的addCancelUrl方法，但是这个方法在Bolt项目中没有调用：\n IDE会给出警告 给用户造成困惑：这个方法可否删除？  在1.6.0版本中解决了以上的问题，抽象出一套稳定的API，便于用户使用、提升代码可读性，同时也为后续的迭代打下基础。\n收敛配置入口\u0026amp;amp;增强配置的可扩展性 1.5.x版本的Bolt配置入口有以下几个：\n ProtocolSwitch：协议配置（是否开启CRC校验），通过静态的方法创建配置对象 GlobalSwitch：实例级配置，每个AbstractConfigurableInstance拥有自己的GlobalSwitch配置，默认值取自SystemProperty，可以通过API调整配置 ConfigItem：Netty相关的配置项的枚举，不可以继承拓展（用户需要修改源码） ConfigManager：配置读取入口，通过静态方法读取SystemProperty的配置 Configs：配置项名称的定义和配置项的默认值  整体上看Bolt的配置项比较零散，且对用户来说难以拓展使用，有以接口暴露的配置项、有以静态方法暴露的配置项，配置项可以通过系统参数配置也可以通过API执行配置。\n且Bolt配置项存在相互影响的问题，比如一个产品同时使用了RPC和消息，而RPC和消息底层都依赖于Bolt，那么基于SystemProperty的配置将无法做到RPC和消息的配置隔离。\n在1.6.0版本中对配置模块进行了调整，在兼容当前版本配置的情况下：\n 收敛配置入口，提供统一的配置的编程界面（以类似Netty的Option的方式进行配置） 支持配置隔离，不同的Bolt实例使用不同的配置项 提升配置的可扩展性  ","date":-62135596800,"description":"","dir":"projects/sofa-bolt/sofa-bolt-roadmap/","fuzzywordcount":1400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"3d4eac90b5c8e657d14eb885ab1f9a92","permalink":"/projects/sofa-bolt/sofa-bolt-roadmap/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/sofa-bolt/sofa-bolt-roadmap/","summary":"发展路线 Version 1.5.1 修复项目中代码风格的问题：https://github.com/alipay/sofa-bolt/issues/85 修复项目中已","tags":null,"title":"SOFABolt 发展路线","type":"projects","url":"/projects/sofa-bolt/sofa-bolt-roadmap/","wordcount":1356},{"author":null,"categories":null,"content":"介绍 SOFABolt 是蚂蚁金融服务集团开发的一套基于 Netty 实现的网络通信框架。\n 为了让 Java 程序员能将更多的精力放在基于网络通信的业务逻辑实现上，而不是过多的纠结于网络底层 NIO 的实现以及处理难以调试的网络问题，Netty 应运而生。 为了让中间件开发者能将更多的精力放在产品功能特性实现上，而不是重复地一遍遍制造通信框架的轮子，SOFABolt 应运而生。  Bolt 名字取自迪士尼动画-闪电狗，是一个基于 Netty 最佳实践的轻量、易用、高性能、易扩展的通信框架。 这些年我们在微服务与消息中间件在网络通信上解决过很多问题，积累了很多经验，并持续的进行着优化和完善，我们希望能把总结出的解决方案沉淀到 SOFABolt 这个基础组件里，让更多的使用网络通信的场景能够统一受益。 目前该产品已经运用在了蚂蚁中间件的微服务 (SOFARPC)、消息中心、分布式事务、分布式开关、以及配置中心等众多产品上。\n多语言  node python cpp  ","date":-62135596800,"description":"","dir":"projects/sofa-bolt/overview/","fuzzywordcount":400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"5ee08df7c4bbd2c3be846e16f3bc81b1","permalink":"/projects/sofa-bolt/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-bolt/overview/","summary":"介绍 SOFABolt 是蚂蚁金融服务集团开发的一套基于 Netty 实现的网络通信框架。 为了让 Java 程序员能将更多的精力放在基于网络通信的业务逻辑实现上，而不是过多的纠结于","tags":null,"title":"SOFABolt 概述","type":"projects","url":"/projects/sofa-bolt/overview/","wordcount":369},{"author":null,"categories":null,"content":"用户指南 maven coordinator \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;bolt\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  check release note for version\n 1. 基础功能 1.1 实现用户请求处理器 (UserProcessor) 我们提供了两种用户请求处理器，SyncUserProcessor 与 AsyncUserProcessor。 二者的区别在于，前者需要在当前处理线程以return返回值的形式返回处理结果；而后者，有一个 AsyncContext 存根，可以在当前线程，也可以在异步线程，调用 sendResponse 方法返回处理结果。示例可参考如下两个类：\n 同步请求处理器 异步请求处理器  1.2 实现连接事件处理器 (ConnectionEventProcessor) 我们提供了两种事件监听，建连事件（ConnectionEventType.CONNECT）与断连事件（ConnectionEventType.CLOSE），用户可以创建自己的事件处理器，并注册到客户端或者服务端。客户端与服务端，都可以监听到各自的建连与断连事件。\n 处理连接建立事件 处理连接断开事件  1.3 客户端与服务端初始化 (RpcClient，RpcServer) 我们提供了一个 RpcClient 与 RpcServer，经过简单的必要功能初始化，或者功能开关，即可使用。一个最简单的例子如下：\n 客户端初始化示例 服务端初始化示例  1.4 基础通信模型 我们提供了四种通信模型：\n1.Oneway 调用\n当前线程发起调用后，不关心调用结果，不做超时控制，只要请求已经发出，就完成本次调用。注意 Oneway 调用不保证成功，而且发起方无法知道调用结果。因此通常用于可以重试，或者定时通知类的场景，调用过程是有可能因为网络问题，机器故障等原因，导致请求失败。业务场景需要能接受这样的异常场景，才可以使用。请参考示例。\n2. Sync 同步调用\n当前线程发起调用后，需要在指定的超时时间内，等到响应结果，才能完成本次调用。如果超时时间内没有得到结果，那么会抛出超时异常。这种调用模式最常用。注意要根据对端的处理能力，合理设置超时时间。请参考示例。\n3. Future调用\n当前线程发起调用，得到一个 RpcResponseFuture 对象，当前线程可以继续执行下一次调用。可以在任意时刻，使用 RpcResponseFuture 对象的 get() 方法来获取结果，如果响应已经回来，此时就马上得到结果；如果响应没有回来，则会阻塞住当前线程，直到响应回来，或者超时时间到。请参考示例。\n4. Callback异步调用\n当前线程发起调用，则本次调用马上结束，可以马上执行下一次调用。发起调用时需要注册一个回调，该回调需要分配一个异步线程池。待响应回来后，会在回调的异步线程池，来执行回调逻辑。请参考示例。\n1.5 日志打印 SOFABolt 只依赖 SLF4J 作为日志门面。同时提供了 log4j、log4j2、logback 三种日志模板，使用者只需要在运行时依赖某一种日志实现，我们依赖的 sofa-common-tools 组件，会在运行时动态感知是哪一种日志实现，同时加载正确的日志模板，进行打印。日志会打印在 ~/logs/bolt/ 目录下面，包括如下几种日志：\n common-default.log：默认日志，打印一些客户端、服务器启动、关闭等通信过程的普通日志 common-error.log：异常日志，框架运行过程中出现的异常 connection-event.log：连接事件日志 remoting-rpc.log：RPC 协议相关的日志  关于日志依赖，可以参考日志实现依赖参考\n2. 进阶功能 2.1 请求上下文 在调用过程中，我们还提供了带 InvokeContext 的接口，并一路传递下去，可以在自定义序列化器，用户请求处理器中获得。我们分为两种场景来使用请求上下文：\n 客户端：用户可以设置一些针对本次请求生效的参数，比如序列化类型，是否开启crc等机制。同时可以从上下文中获取建连耗时，连接信息等。 服务端：用户可以从用户请求处理器中获得请求到达后的排队耗时，连接信息等 注意：客户端与服务端的上下文是独立的，即客户端设置的上下文只在客户端可见，对服务端不可见；反之同理。 使用示例  2.2 双工通信 除了服务端可以注册用户请求处理器，我们的客户端也可以注册用户请求处理器。此时，服务端就可以发起对客户端的调用，也可以使用 1.4 提到了任何一种通信模型。\n 示例1：使用 Connection 对象的双工通信，注意使用 Connection 对象的双工通信，服务端需要通过事件监听处理器或者用户请求处理器，自己保存好 Connection 对象。 示例2：使用 Address 的双工通信，注意使用 Address 方式的双工通信，需要在初始化 RpcServer 时，打开 manageConnection 开关，表示服务端会根据客户端发起的建连，维护一份地址与连接的映射关系。默认不需要双工通信的时候，这个功能是关闭的。  2.3 建立多连接与连接预热 通常来说，点对点的直连通信，客户端和服务端，一个 IP 一个连接对象就够用了。不管是吞吐能力还是并发度，都能满足一般业务的通信需求。而有一些场景，比如不是点对点直连通信，而是经过了 LVS VIP，或者 F5 设备的连接，此时，为了负载均衡和容错，会针对一个 URL 地址建立多个连接。我们提供如下方式来建立多连接，即发起调用时传入的 URL 增加如下参数 127.0.0.1:12200?_CONNECTIONNUM=30\u0026amp;amp;_CONNECTIONWARMUP=true，表示针对这个 IP 地址，需要建立30个连接，同时需要预热连接。其中预热与不预热的区别是：\n 预热：即第一次调用（比如 Sync 同步调用），就建立30个连接 不预热：每一次调用，创建一个连接，直到创建满30个连接 使用示例  2.4 自动断连与重连 通常 RPC 调用过程，是不需要断链与重连的。因为每次 RPC 调用过程，都会校验是否有可用连接，如果没有则新建一个。但有一些场景，是需要断链和保持长连接的：\n 自动断连：比如通过 LVS VIP 或者 F5 建立多个连接的场景，因为网络设备的负载均衡机制，有可能某一些连接固定映射到了某几台后端的 RS 上面，此时需要自动断连，然后重连，靠建连过程的随机性来实现最终负载均衡。注意，开启了自动断连的场景，通常需要配合重连使用。 重连：比如客户端发起建连后，由服务端来通过双工通信，发起请求到客户端。此时如果没有重连机制，则无法实现。 使用示例，注意考虑一个进程可能会有多个 SOFABolt 的通信实例，我们提供了全局开关以及用户开关两种开关方式：  //  …","date":-62135596800,"description":"","dir":"projects/sofa-bolt/sofa-bolt-handbook/","fuzzywordcount":3600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"2a0a2e3c7749dbcdceea064f6f850e33","permalink":"/projects/sofa-bolt/sofa-bolt-handbook/","publishdate":"0001-01-01T00:00:00Z","readingtime":8,"relpermalink":"/projects/sofa-bolt/sofa-bolt-handbook/","summary":"用户指南 maven coordinator \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alipay.sofa\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;bolt\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; check release note for version 1. 基础功能 1.1 实现用户请求处理器 (UserProcessor) 我们提供了两种用户请求处理器，SyncUserProcessor 与 Async","tags":null,"title":"SOFABolt 用户手册","type":"projects","url":"/projects/sofa-bolt/sofa-bolt-handbook/","wordcount":3516},{"author":null,"categories":null,"content":"相关链接  ISSUES 用户手册 中文介绍文章: 蚂蚁通信框架实践  ","date":-62135596800,"description":"","dir":"projects/sofa-bolt/related-links/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"6844d2a639b69fa3128132b8631f33e3","permalink":"/projects/sofa-bolt/related-links/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-bolt/related-links/","summary":"相关链接 ISSUES 用户手册 中文介绍文章: 蚂蚁通信框架实践","tags":null,"title":"SOFABolt 相关链接","type":"projects","url":"/projects/sofa-bolt/related-links/","wordcount":24},{"author":null,"categories":null,"content":"﻿# Upgrade SOFABoot from 2.3.x/2.4.x to 2.5.x SOFABoot 2.3.x/2.4.x is developed based on Spring Boot 1.4.2.RELEASE, SOFABoot 2.5.x is developed based on Spring Boot 1.5.x. When upgrading SOFABoot 2.3.x/2.4.x to SOFABoot 2.5.x, we should pay special attention to the differences between the Spring Boot 1.5.x upgrade and the Spring Boot 1.4.x upgrade.\nRenamed Spring Boot Starters  spring-boot-starter-ws \u0026amp;ndash;\u0026amp;gt; spring-boot-starter-web-services spring-boot-starter-redis \u0026amp;ndash;\u0026amp;gt; spring-boot-starter-data-redis  Endpoint Security Control Spring Boot 1.5.x has security control over all sensitive endpoints by default, that is, endpoints such as /beans and /dump, which were previously accessible by default in version 1.4.x, are not accessible in version 1.5.x. To access such endpoints, we need to configure Spring Boot as follows:\n management.security.enabled=false\n Only /health, /info, and /docs are accessible by default in version 1.5.x. Please refer to official description for details:\n endpoints Accessing sensitive endpoints  ApplicationEvent Change ApplicationStartedEvent in 1.4.x has been renamed ApplicationStartingEvent in Spring Boot 1.5.x. The version 1.5.x remains forward compatible. Note that the ApplicationStartedEvent event has a completely different meaning in version 2.x.\n** Users who have upgraded the SOFABoot to the version 2.5.x are strongly advised to change ApplicationStartedEvent to ApplicationStartingEvent to avoid compatibility issues when upgrading SOFABoot to the version 3.0.x in the future.**\nProperty renaming  server.max-http-post-size \u0026amp;ndash;\u0026amp;gt; server.tomcat.max-http-post-size spring.data.neo4j.session.scope is removed  Refer to the configuration of Spring Boot 1.5.x changelog\nSummary The above are the major points worthy of notice when we upgrade SOFABoot 2.3.x/2.4.x to SOFABoot 2.5.x. For detailed information, refer to the Release Report of Spring Boot 1.5.x.\n","date":-62135596800,"description":"","dir":"projects/sofa-boot/upgrade_2_5_x/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"4b7dd4287b00106684831d2a8524a6f7","permalink":"/en/projects/sofa-boot/upgrade_2_5_x/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-boot/upgrade_2_5_x/","summary":"﻿# Upgrade SOFABoot from 2.3.x/2.4.x to 2.5.x SOFABoot 2.3.x/2.4.x is developed based on Spring Boot 1.4.2.RELEASE, SOFABoot 2.5.x is developed based on Spring Boot 1.5.x. When upgrading SOFABoot 2.3.x/2.4.x to SOFABoot 2.5.x, we should pay special attention to the differences between the Spring Boot 1.5.x upgrade and the Spring Boot 1.4.x upgrade.\nRenamed Spring Boot Starters  spring-boot-starter-ws \u0026ndash;\u0026gt; spring-boot-starter-web-services spring-boot-starter-redis \u0026ndash;\u0026gt; spring-boot-starter-data-redis  Endpoint Security Control Spring Boot 1.5.x has security control over all sensitive endpoints by default, that is, endpoints such as /beans and /dump, which were previously accessible by default in version 1.","tags":null,"title":"SOFABoot 2.5.x upgrade","type":"projects","url":"/en/projects/sofa-boot/upgrade_2_5_x/","wordcount":248},{"author":null,"categories":null,"content":"SOFABoot 2.3.x/2.4.x 升级到 2.5.x SOFABoot 2.3.x/2.4.x 基于 Spring Boot 1.4.2.RELEASE 版本开发，SOFABoot 2.5.x 则是基于 Spring Boot 1.5.x 版本开发。 从 SOFABoot 2.3.x/2.4.x 升级到 SOFABoot 2.5.x 需要重点考虑 Spring Boot 1.5.x 相较 Spring Boot 1.4.x 的升级注意点。\n重命名的 spring boot starters  spring-boot-starter-ws \u0026amp;ndash;\u0026amp;gt; spring-boot-starter-web-services spring-boot-starter-redis \u0026amp;ndash;\u0026amp;gt; spring-boot-starter-data-redis  endpoint 安全性控制 Spring Boot 1.5.x 对所有 Sensitive Endpoint 默认进行了安全管控，即之前在 1.4.x 默认能访问的诸如 /beans, /dump 等 endpoints 在 1.5.x 版本均不能访问。如果需要访问，需要配置：\n management.security.enabled=false\n 默认情况下，在 1.5.x 只有 /health, /info, /docs 能够访问。详细请参考官方描述：\n endpoints Accessing sensitive endpoints  ApplicationEvent 变更 Spring Boot 1.5.x 将 1.4.x 中的 ApplicationStartedEvent 重命名为 ApplicationStartingEvent，在 1.5.x 仍然保持向前兼容。需要格外注意的是，在 2.x 版本中，ApplicationStartedEvent 事件意义完全不一样。\n强烈建议升级到 SOFABoot 2.5.x 的用户，将应用中使用的 ApplicationStartedEvent 变更为 ApplicationStartingEvent；避免今后升级至 SOFABoot 3.0.x 出现兼容性问题\nProperty 重命名  server.max-http-post-size \u0026amp;ndash;\u0026amp;gt; server.tomcat.max-http-post-size spring.data.neo4j.session.scope 被移除  具体参考 Spring Boot 1.5.x 配置的 changelog\n总结 以上总结了从 SOFABoot 2.3.x/2.4.x 升级到 SOFABoot 2.5.x 的几个主要注意点，详细可以参考 Spring Boot 1.5.x 的发布报告\n","date":-62135596800,"description":"","dir":"projects/sofa-boot/upgrade_2_5_x/","fuzzywordcount":500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"4b7dd4287b00106684831d2a8524a6f7","permalink":"/projects/sofa-boot/upgrade_2_5_x/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-boot/upgrade_2_5_x/","summary":"SOFABoot 2.3.x/2.4.x 升级到 2.5.x SOFABoot 2.3.x/2.4.x 基于 Spring Boot 1.4.2.RELEASE 版本开发，SOFABoot 2.5.x 则是基于 Spring Boot 1.5.x 版本开发。 从 SOFABoot 2.3.x/2.4.x 升级到 SOFABoot 2.5.x 需要重点考虑 Spring Boot 1.5.x 相较 Spring Boot 1.4.x 的升级注意点。 重命","tags":null,"title":"SOFABoot 2.5.x 升级注意事项","type":"projects","url":"/projects/sofa-boot/upgrade_2_5_x/","wordcount":401},{"author":null,"categories":null,"content":"﻿## Preface As a Spring Boot-based development framework open sourced by Ant Financial, SOFABoot provides capabilities such as Readiness Check, class isolation, and log space isolation. In addition to enhancing the Spring Boot, SOFABoot provides users with the capability to easily use SOFA middleware in Spring Boot.\nWe have received a lot of feedback from community users since SOFABoot was open sourced in April 2018. We are also very pleased to see many community users take an active part in building the SOFAStack open source, which greatly increases our determination to prosper SOFAStack community and ecosystem. Here, we announce the release of the SOFABoot 3.0, which is developed based on Spring Boot 2.0. SOFABoot 3.0 allows us to seamlessly integrate the extension capability of SOFABoot with official components of Spring Boot 2.x. In addition, SOFABoot 3.0 is compatible with Spring Cloud components, which allows us to easily integrate Spring Cloud components like Zuul and Config in the SOFABoot framework.\nBelow are the major changes of SOFABoot 3.0 compared with SOFABoot 2.x.\nUpgrade Spring Boot to version 2.x Upgrade Spring Boot in SOFABoot 3.0 to version 2.0. As the Spring Boot community recently announced that the maintenance for version 1.x will end in August 2019, we will focus on SOFABoot 3.x in the future and will release SOFABoot 3.1 with Spring Boot upgraded to version 2.1 soon.\nSpring Cloud compatible Some components are not compatible with SOFABoot in SOFABoot 2.x. In SOFABoot 3.x, we have run thorough compatibility tests on Spring Cloud components and fixed all problems found to ensure good compatibility between SOFABoot 3.x and Spring Cloud.\nWebFlux framework compatible Spring Boot 2.x introduces the WebFlux framework. SOFABoot 3.x is compatible with WebFlux in two major aspects;\n Health Check is compatible with the ReactiveHealthIndicator extension interface. The Readiness Check will include the implementation of the interface extension; Compatible with buried points of WebFlux web requests. Point burying logs and files are compatible with common MVC requests. For detailed information, refer to MVC point burying request.  JDK version support SOFABoot 3.x must run on JDK 8 or higher versions and does not support JDK 6 and JDK 7.\nHealth Check SOFABoot adds Readiness Check capability to Spring Boot\u0026amp;rsquo;s Health Check capability, to ensure that all components and operations are in a healthy state before the application goes into services. Compared with SOFABoot 2.x, SOFABoot 3.0 features great adjustments to the Health Check. It abandons some internal compatibility logic of Ant Financial and uses a friendlier coding scheme. Besides, the Health Check of SOFABoot 3.0 offers extensions in various scenarios, supports the \u0026amp;lsquo;ReactiveHealthIndicator\u0026amp;rsquo; extension interface introduced in Spring Boot 2.x, and provides more Health Check extension features.\nAdjust the Readiness Check Endpoint path The Endpoint for checking the Health …","date":-62135596800,"description":"","dir":"projects/sofa-boot/upgrade_3_x/","fuzzywordcount":1000,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"91ba09adf6bc42aaf70645b9a19b409b","permalink":"/en/projects/sofa-boot/upgrade_3_x/","publishdate":"0001-01-01T00:00:00Z","readingtime":5,"relpermalink":"/en/projects/sofa-boot/upgrade_3_x/","summary":"﻿## Preface As a Spring Boot-based development framework open sourced by Ant Financial, SOFABoot provides capabilities such as Readiness Check, class isolation, and log space isolation. In addition to enhancing the Spring Boot, SOFABoot provides users with the capability to easily use SOFA middleware in Spring Boot.\nWe have received a lot of feedback from community users since SOFABoot was open sourced in April 2018. We are also very pleased to see many community users take an active part in building the SOFAStack open source, which greatly increases our determination to prosper SOFAStack community and ecosystem.","tags":null,"title":"SOFABoot 3.0 upgrade","type":"projects","url":"/en/projects/sofa-boot/upgrade_3_x/","wordcount":902},{"author":null,"categories":null,"content":"前言 SOFABoot 是蚂蚁金服开源的基于 Spring Boot 的研发框架，它在 Spring Boot 的基础上，提供了诸如 Readiness Check，类隔离，日志空间隔离等能力。在增强了 Spring Boot 的同时，SOFABoot 提供了让用户可以在 Spring Boot 中非常方便地使用 SOFA 中间件的能力。\n自今年 4 月份 SOFABoot 开源至今，我们收到了非常多来自社区同学的反馈，也非常高兴的看到很多社区同学积极的参与到 SOFAStack 开源共建，这极大了鼓舞了我们建设 SOFAStack 开源社区的决心，力图把 SOFAStack 社区和生态建设更加繁荣。在此，我们宣布推出 SOFABoot 3.0 版本，SOFABoot 3.0 是基于 Spring Boot 2.0 版本开发。在 SOFABoot 3.0 中，可以将 SOFABoot 扩展能力和 Spring Boot 2.x 官方组件无缝集成。此外，我们在 SOFABoot 3.0 中兼容了 Spring Cloud 组件集成，可以很方便地在 SOFABoot 框架中集成 Spring Cloud 组件，如 Zuul, Config 等。\n以下，本文将详细介绍 SOFABoot 3.0 相较 SOFABoot 2.x 的变更。\nSpring Boot 升级 2.x SOFABoot 3.0 版本升级 Spring Boot 版本至 2.0。鉴于Spring Boot 社区最近刚公告 1.x 版本将维护至明年 8 月份为止，未来，我们也将主力维护 SOFABoot 3.x 版本，近期也将发布 SOFABoot 3.1 升级 Spring Boot 版本至 2.1。\nSpring Cloud 兼容 在 SOFABoot 2.x 中，存在部分组件和 SOFABoot 兼容性问题。在 SOFABoot 3.x 中，对 Spring Cloud 各组件进行了比较完备的兼容性测试和问题修复，保证了 SOFABoot 3.x 与 Spring Cloud 良好的兼容性。\nWebFlux 框架兼容 Spring Boot 2.x 引入了 WebFlux 框架，SOFABoot 3.x 主要在两个方面兼容了 WebFlux 框架；\n 健康检查兼容了 ReactiveHealthIndicator 扩展接口，业务对这个接口的扩展实现将会纳入到 Readiness Check； 兼容对 WebFlux 网络请求进行埋点，埋点日志格式和文件保持对普通 MVC 请求兼容，详细参考MVC 埋点请求  JDK 版本支持 SOFABoot 3.x 最低要求运行在 JDK 8 及其以上版本，不支持 JDK 6，7。\n健康检查 SOFABoot 为 Spring Boot 的健康检查能力增加了 Readiness Check 能力，以确保应用在正常对外服务前，所有组件及业务本身处于健康状态。相较于与 SOFABoot 2.x, SOFABoot 3.0 在健康检查做了很大的重构，主要是剥离了部分蚂蚁金服内部兼容逻辑，采用更加友好的编码方案；其次，SOFABoot 3.0 健康检查提供了多种不同场景下的健康检查扩展形式，支持 Spring Boot 2.x 引入的 ReactiveHealthIndicator 扩展接口，丰富了健康检查扩展特性。\n调整 Readiness Check Endpoint 路径 在 SOFABoot 2.x 中，查看健康检查结果的 Endpoint 为 /health/readiness，而在 SOFABoot 3.0 中，变更为 /actuator/readiness。\n扩展接口变更 在 SOFABoot 3.x 中，提供四种方式扩展健康检查，分别是\n HealthChecker HealthIndicator(Spring Boot 原生) ReactiveHealthIndicator(Spring Boot 原生) ReadinessCheckCallback  这四个接口的扩展实现执行顺序是 HealthChecker \u0026amp;gt; HealthIndicator, ReactiveHealthIndicator \u0026amp;gt; ReadinessCheckCallback，相同接口的扩展实现执行顺序则遵循 Spring Boot 标准的方案。即扩展类可以额外实现两个标准的 Order 接口：\n org.springframework.core.Ordered org.springframework.core.PriorityOrdered  或者使用注解\n org.springframework.core.annotation.Order  这些接口的扩展实现处理结果将会在健康检查结果查中展现。\n删除 SofaBootBeforeHealthCheckEvent 事件 在 SOFABoot 2.x 中，我们没有提供支持对健康检查扩展实现进行排序，导致用户无法预期自身扩展执行时机。如上述，SOFABoot 3.x 支持各组件扩展实现的排序，因此该事件可以统一使用 HealthChecker 接口和高优先级顺序实现替代。其次，在 SOFABoot 2.x 中，SofaBootBeforeHealthCheckEvent  事件的处理逻辑结果并不会反应在健康检查结果中，使用 HealthChecker 替代之后，这部分逻辑处理自然变成健康检查的一部分，可供查看。\n删除 DefaultHealthChecker 接口 使用 JDK8 默认方法特性，删除 DefaultHealthChecker 接口，用户可以直接使用 HealthChecker 接口替代 DefaultHealthChecker.\n删除 SofaBootMiddlewareAfterReadinessCheckCallback 和 SofaBootAfterReadinessCheckCallback 接口 在 SOFABoot 2.x 中，这两个接口是两种场景下的健康检查回调；推荐 SOFABoot 官方 Starter 使用 SofaBootMiddlewareAfterReadinessCheckCallback，而业务应用推荐使用SofaBootAfterReadinessCheckCallback，框架将优先执行 SofaBootMiddlewareAfterReadinessCheckCallback 的扩展实现，然后执行 SofaBootAfterReadinessCheckCallback 的扩展实现。这样的设计有两个缺陷：\n 两个接口本质没有区别，但是隐藏了先后顺序逻辑，给用户引入了额外的学习成本； 只考虑了 SofaBootMiddlewareAfterReadinessCheckCallback 和 SofaBootAfterReadinessCheckCallback 两个接口的顺序，但无法保证相同接口实现的执行顺序。  SOFABoot 3.x …","date":-62135596800,"description":"","dir":"projects/sofa-boot/upgrade_3_x/","fuzzywordcount":1700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"91ba09adf6bc42aaf70645b9a19b409b","permalink":"/projects/sofa-boot/upgrade_3_x/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/projects/sofa-boot/upgrade_3_x/","summary":"前言 SOFABoot 是蚂蚁金服开源的基于 Spring Boot 的研发框架，它在 Spring Boot 的基础上，提供了诸如 Readiness Check，类隔离，日志空间隔离等能力。在增强了 Spring Boot 的同时，SOFA","tags":null,"title":"SOFABoot 3.0 升级注意事项","type":"projects","url":"/projects/sofa-boot/upgrade_3_x/","wordcount":1679},{"author":null,"categories":null,"content":"Background kc-sofastack-demo has introduced how to quickly build an e-commerce microservice application and has implemented the service calling link tracking and application status monitoring.\nIn e-commerce system, the platforms often are not satisfied with the default product listing order, and always want to arrange some products in the conspicuous places. Also, there are some cases where the platforms would like to show different products to different users based on the collected user behaviors.\nBased on the background of kc-sofastack-demo, this guide will implement sorting the products dynamically based on the total amount of products of each onsite attendee.\nDemo content Implement the dynamic change of product sorting via the dynamic module capability provided by SOFABoot and the dynamic module control capability of SOFADashboard.\nImplement the change of application behavior without restarting the host and without changing the application configuration.\nThe project architecture is as follows:\nTasks 1. Preparation Clone the demo from GitHub to local\ngit clone https://github.com/sofastack-guides/kc-sofastack-dynamic-demo.git Then, import the project into IDEA or Eclipse.\n2. Package SOFABoot project as Ark JAR As shown in the following screenshot, add the Ark package plugin in the POM file and configure it:\nStep 1: Copy the Ark plugin and configuration to the specified positions in the above screenshot \u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;0.6.0\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;executions\u0026amp;gt; \u0026amp;lt;execution\u0026amp;gt; \u0026amp;lt;!--goal executed to generate executable-ark-jar --\u0026amp;gt; \u0026amp;lt;goals\u0026amp;gt; \u0026amp;lt;goal\u0026amp;gt;repackage\u0026amp;lt;/goal\u0026amp;gt; \u0026amp;lt;/goals\u0026amp;gt; \u0026amp;lt;!-- package configuration of ark-biz JAR --\u0026amp;gt; \u0026amp;lt;configuration\u0026amp;gt; \u0026amp;lt;!-- Whether to package, install and publish ark biz. The default value is false. For details, see Ark Biz documentation.--\u0026amp;gt; \u0026amp;lt;attach\u0026amp;gt;true\u0026amp;lt;/attach\u0026amp;gt; \u0026amp;lt;!-- The directory for ark package and ark biz package, defaulting to the build directory of project--\u0026amp;gt; \u0026amp;lt;outputDirectory\u0026amp;gt;target\u0026amp;lt;/outputDirectory\u0026amp;gt; \u0026amp;lt;!--default none--\u0026amp;gt; \u0026amp;lt;arkClassifier\u0026amp;gt;executable-ark\u0026amp;lt;/arkClassifier\u0026amp;gt; \u0026amp;lt;!-- The priority of starting ark-biz package. The smaller the value, the higher the priority.--\u0026amp;gt; \u0026amp;lt;priority\u0026amp;gt;200\u0026amp;lt;/priority\u0026amp;gt; \u0026amp;lt;!--Set the root directory of application, used to read ${base.dir}/conf/ark/bootstrap.application configuration file and defaulting to ${project.basedir}--\u0026amp;gt; \u0026amp;lt;baseDir\u0026amp;gt;../\u0026amp;lt;/baseDir\u0026amp;gt; \u0026amp;lt;/configuration\u0026amp;gt; \u0026amp;lt;/execution\u0026amp;gt; \u0026amp;lt;/executions\u0026amp;gt; \u0026amp;lt;/plugin\u0026amp;gt; Step 2: Run mvn clean package to package the project. The successfully packaged JAR file is as shown in the following screenshot:\n3. Build host application In the downloaded project, dynamic-stock-mng is the host application model. In this task, we will build dynamic-stock-mng as the host application of dynamic module.\nStep 1: Introduce Ark …","date":-62135596800,"description":"This guide introduce how to implement the merged deployment and dynmaic module push provided by SOFAArck based on the Ark control function of SOFADashboard.","dir":"guides/kc-sofastack-dynamic-demo/","fuzzywordcount":700,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"8bfd4a50e21ce9fc867b1cf18a8c9af3","permalink":"/en/guides/kc-sofastack-dynamic-demo/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/en/guides/kc-sofastack-dynamic-demo/","summary":"Background kc-sofastack-demo has introduced how to quickly build an e-commerce microservice application and has implemented the service calling link tracking and application status monitoring.\nIn e-commerce system, the platforms often are not satisfied with the default product listing order, and always want to arrange some products in the conspicuous places. Also, there are some cases where the platforms would like to show different products to different users based on the collected user behaviors.","tags":null,"title":"SOFABoot dynamic module practice","type":"guides","url":"/en/guides/kc-sofastack-dynamic-demo/","wordcount":630},{"author":null,"categories":null,"content":"SOFABoot supports modular isolation. But in actual usage scenarios, There is one case that beans in one module sometimes need to open some entries for another module to expand. SOFABoot draws on and uses the [Nuxeo Runtime] (https://github.com/nuxeo-archives/nuxeo-runtime) project and the nuxeo project and expands on it, provides the ability to extend points with Spring, We call it Extension Point.\nUsage Using extension point capabilities in SOFABoot requires the following three steps:\nDefine a bean that provides extension capabilities When using the SOFABoot extension point capability, you first need to define an interface that needs to be extended, like:\npackage com.alipay.sofa.boot.test; public interface IExtension { String say(); } Define the implementation of this interface:\npackage com.alipay.sofa.boot.test.impl; public class ExtensionImpl implements IExtension { private String word; @Override public String say() { return word; } public void setWord(String word) { this.word = word; } public void registerExtension(Extension extension) throws Exception { Object[] contributions = extension.getContributions(); String extensionPoint = extension.getExtensionPoint(); if (contributions == null) { return; } for (Object contribution : contributions) { if (\u0026amp;#34;word\u0026amp;#34;.equals(extensionPoint)) { setWord(((ExtensionDescriptor) contribution).getValue()); } } } } Here you can see that there is a method: registerExtension, you can temporarily ignore this method, and later will introduce its specific role.\nIn the module\u0026amp;rsquo;s Spring configuration file, we add configuration of this bean:\n\u0026amp;lt;bean id=\u0026amp;#34;extension\u0026amp;#34; class=\u0026amp;#34;com.alipay.sofa.boot.test.impl.ExtensionImpl\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;#34;word\u0026amp;#34; value=\u0026amp;#34;Hello, world\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt; Defining extension points There is a field word in the above bean. In practice, we want this field to be overridden by other module customizations. Here we expose it as an extension point.\nFirst, you need a class to describe this extension point:\n@XObject(\u0026amp;#34;word\u0026amp;#34;) public class ExtensionDescriptor { @XNode(\u0026amp;#34;value\u0026amp;#34;) private String value; public String getValue() { return value; } } Then define the extension point in xml:\n\u0026amp;lt;sofa:extension-point name=\u0026amp;#34;word\u0026amp;#34; ref=\u0026amp;#34;extension\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:object class=\u0026amp;#34;com.alipay.sofa.boot.test.extension.ExtensionDescriptor\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/sofa:extension-point\u0026amp;gt; among them:\n name is the name of the extension point ref is the bean to which the extension point is applied object is a concrete description of the contribution point of the extension point. This description is done by XMap (XMap is used to map Java objects and XML files. It is recommended to search XMap documents on the Internet to understand XMap)  Defining extension implements The above has defined the extension point, and we can extend this bean at this point:\n\u0026amp;lt;sofa:extension bean=\u0026amp;#34;extension\u0026amp;#34; point=\u0026amp;#34;word\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:content\u0026amp;gt; \u0026amp;lt;word\u0026amp;gt; …","date":-62135596800,"description":"","dir":"projects/sofa-boot/extension/","fuzzywordcount":1300,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"93225b6c1f2b68f2047a7cf49b76650b","permalink":"/en/projects/sofa-boot/extension/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/en/projects/sofa-boot/extension/","summary":"SOFABoot supports modular isolation. But in actual usage scenarios, There is one case that beans in one module sometimes need to open some entries for another module to expand. SOFABoot draws on and uses the [Nuxeo Runtime] (https://github.com/nuxeo-archives/nuxeo-runtime) project and the nuxeo project and expands on it, provides the ability to extend points with Spring, We call it Extension Point. Usage Using extension point capabilities in SOFABoot requires the following","tags":null,"title":"SOFABoot Extension Point","type":"projects","url":"/en/projects/sofa-boot/extension/","wordcount":1264},{"author":null,"categories":null,"content":"SOFABoot is a development framework open sourced by Ant Financial which is based on Spring Boot, provides capabilities such as Readiness Check, class isolation, and log space isolation. In addition to enhancing the Spring Boot, SOFABoot provides users with the capability to easily use SOFA middleware in Spring Boot.\nYou can view all the release notes in Release History. The correspondence between SOFABoot version and Spring Boot version is as follows:\n   SOFABoot version Spring Boot version     2.3.x 1.4.2.RELEASE   2.4.x 1.4.2.RELEASE   2.5.x 1.5.16.RELEASE   3.0.x 2.0.3.RELEASE   3.1.0 2.1.0.RELEASE    That is, the SOFABoot 2.3.x and 2.4.x series are based on Spring Boot 1.4.2.RELEASE; SOFABoot 2.5.x series are based on Spring Boot 1.5.x; SOFABoot 3.x series are based on Spring Boot 2.x. You can view and get the codes of all revisions in Release History. In addition, to facilitate users in the community to learn the latest development version of SOFABoot, we will release the SNAPSHOT version, which is a branch of the current development. To successfully pull the SNAPSHOT package from the central repository, it\u0026amp;rsquo;s necessary to add the following profile configuration to the local maven setting.xml file:\n\u0026amp;lt;profile\u0026amp;gt; \u0026amp;lt;id\u0026amp;gt;default\u0026amp;lt;/id\u0026amp;gt; \u0026amp;lt;activation\u0026amp;gt; \u0026amp;lt;activeByDefault\u0026amp;gt;true\u0026amp;lt;/activeByDefault\u0026amp;gt; \u0026amp;lt;/activation\u0026amp;gt; \u0026amp;lt;repositories\u0026amp;gt; \u0026amp;lt;repository\u0026amp;gt; \u0026amp;lt;snapshots\u0026amp;gt; \u0026amp;lt;enabled\u0026amp;gt;true\u0026amp;lt;/enabled\u0026amp;gt; \u0026amp;lt;/snapshots\u0026amp;gt; \u0026amp;lt;id\u0026amp;gt;maven-snapshot\u0026amp;lt;/id\u0026amp;gt; \u0026amp;lt;url\u0026amp;gt;https://oss.sonatype.org/content/repositories/snapshots\u0026amp;lt;/url\u0026amp;gt; \u0026amp;lt;/repository\u0026amp;gt; \u0026amp;lt;/repositories\u0026amp;gt; \u0026amp;lt;pluginRepositories\u0026amp;gt; \u0026amp;lt;pluginRepository\u0026amp;gt; \u0026amp;lt;snapshots\u0026amp;gt; \u0026amp;lt;enabled\u0026amp;gt;true\u0026amp;lt;/enabled\u0026amp;gt; \u0026amp;lt;/snapshots\u0026amp;gt; \u0026amp;lt;id\u0026amp;gt;maven-snapshot\u0026amp;lt;/id\u0026amp;gt; \u0026amp;lt;url\u0026amp;gt;https://oss.sonatype.org/content/repositories/snapshots\u0026amp;lt;/url\u0026amp;gt; \u0026amp;lt;/pluginRepository\u0026amp;gt; \u0026amp;lt;/pluginRepositories\u0026amp;gt; \u0026amp;lt;/profile\u0026amp;gt; Feature Description Based on Spring Boot, SOFABoot provides the following capabilities:\n Capability of expanding the Health Check of Spring Boot: Provide the Readiness Check based on the Health Check of Spring Boot, to ensure a secure launch of application examples. Capability of log space isolation: The middleware framework automatically finds the application\u0026amp;rsquo;s logs and realizes dependence on the logs and independent log printing, avoiding binding the middleware and the application logs. The capability is achieved through sofa-common-tools. Capability of providing class isolation: Provide class isolation based on the SOFAArk framework, making it easy for users to solve various class conflicts. Capability of providing modular development: Based on the Spring context isolation, provide modular development capability, with a separate Spring context for each SOFABoot module, to avoid BeanId conflicts between different SOFABoot modules. Integrated management of middleware: manage in a unified manner, provide a unified and easy-to-use …","date":-62135596800,"description":"","dir":"projects/sofa-boot/overview/","fuzzywordcount":500,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"fe6aed461c61b86dfed846a2dc0b7dcb","permalink":"/en/projects/sofa-boot/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/en/projects/sofa-boot/overview/","summary":"SOFABoot is a development framework open sourced by Ant Financial which is based on Spring Boot, provides capabilities such as Readiness Check, class isolation, and log space isolation. In addition to enhancing the Spring Boot, SOFABoot provides users with the capability to easily use SOFA middleware in Spring Boot.\nYou can view all the release notes in Release History. The correspondence between SOFABoot version and Spring Boot version is as follows:","tags":null,"title":"SOFABoot overview","type":"projects","url":"/en/projects/sofa-boot/overview/","wordcount":461},{"author":null,"categories":null,"content":"Spring 框架从 3.1.X 版本开始提供了 profile 功能: Bean Definition Profiles，SOFABoot 支持模块级 profile 能力，即在各个模块启动的时候决定模块是否能够启动。\n使用 Module-Profile 激活 module 使用 SOFABoot 的 profile 功能，需要在 application.properties 文件增加 com.alipay.sofa.boot.active-profiles 字段，该字段的值为逗号分隔的字符串，表示允许激活的 profile 列表，指定该字段后，SOFABoot 会为每个可以激活的模块指定此字段表示的 profile 列表。\nSOFABoot 模块的 sofa-module.properties 文件支持 Module-Profile 字段，该字段的值为逗号分隔的字符串，表示当前模块允许在哪些 profile 激活。Module-Profile 支持取反操作， !dev 表示 com.alipay.sofa.boot.active-profiles 不包含 dev 时被激活。\n当应用未指定 com.alipay.sofa.boot.active-profiles 参数时，表示应用所有模块均可启动。SOFABoot 模块未指定 Module-Profile 时，表示当前 SOFABoot 模块可以在任何 profile 启动。\n使用例子 激活 dev SOFABoot 模块 application.properties 中增加配置如下：\ncom.alipay.sofa.boot.active-profiles=dev 该配置表示激活 profile 为 dev 的模块。\n在每个需要限定为 dev profile 被激活模块的 sofa-module.properties 文件中增加如下配置：\nModule-Profile=dev 配置多个激活 profile application.properties 中增加配置如下：\ncom.alipay.sofa.boot.active-profiles=dev,test 该配置表示激活 profile 为 dev 或者 test 的模块。\n在 SOFABoot 模块的 sofa-module.properties 文件中增加如下配置：\nModule-Profile=test,product 该配置表示当 com.alipay.sofa.boot.active-profiles 包含 test 或者 product 时激活模块，由于当前指定的 com.alipay.sofa.boot.active-profiles 为 dev,test ，此模块将被激活。\nModule-Profile 取反 application.properties 中增加配置如下：\ncom.alipay.sofa.boot.active-profiles=dev 该配置表示激活 profile 为 dev 的模块。\n在 SOFABoot 模块的 sofa-module.properties 文件中增加如下配置：\nModule-Profile=!product 该配置表示当 com.alipay.sofa.boot.active-profiles 不包含 product 时激活模块，由于当前指定的 com.alipay.sofa.boot.active-profiles 为 dev ，此模块将被激活。\n设置激活模块 Spring 上下文的 spring.profiles.active 属性 application.properties 中增加配置如下：\ncom.alipay.sofa.boot.active-profiles=dev,test 该配置表示激活 profile 为 dev 或者 test 的模块，当一个模块满足上面的激活条件时，这个模块就会被启动，同时 Spring 上下文的环境信息 spring.profiles.active 也被设置为了 dev,test ，这样如下的配置 beanId 为 devBeanId 和 testBeanId 的bean都会被激活。\n\u0026amp;lt;?xml version=\u0026amp;#34;1.0\u0026amp;#34; encoding=\u0026amp;#34;UTF-8\u0026amp;#34;?\u0026amp;gt; \u0026amp;lt;beans xmlns=\u0026amp;#34;http://www.springframework.org/schema/beans\u0026amp;#34; xmlns:xsi=\u0026amp;#34;http://www.w3.org/2001/XMLSchema-instance\u0026amp;#34; xmlns:jdbc=\u0026amp;#34;http://www.springframework.org/schema/jdbc\u0026amp;#34; xmlns:jee=\u0026amp;#34;http://www.springframework.org/schema/jee\u0026amp;#34; xsi:schemaLocation=\u0026amp;#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\u0026amp;#34; default-autowire=\u0026amp;#34;byName\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;beans profile=\u0026amp;#34;dev\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;#34;devBeanId\u0026amp;#34; class=\u0026amp;#34;com.alipay.cloudenginetest.sofaprofilesenv.DemoBean\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;#34;name\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;value\u0026amp;gt;demoBeanDev\u0026amp;lt;/value\u0026amp;gt; \u0026amp;lt;/property\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt; \u0026amp;lt;/beans\u0026amp;gt; \u0026amp;lt;beans profile=\u0026amp;#34;test\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;#34;testBeanId\u0026amp;#34; class=\u0026amp;#34;com.alipay.cloudenginetest.sofaprofilesenv.DemoBean\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;#34;name\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;value\u0026amp;gt;demoBeanTest\u0026amp;lt;/value\u0026amp;gt; \u0026amp;lt;/property\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt; \u0026amp;lt;/beans\u0026amp;gt; \u0026amp;lt;/beans\u0026amp;gt; ","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofaboot-profile/","fuzzywordcount":700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"b29d568fa057cad0b440790d5cc65d07","permalink":"/projects/sofa-boot/sofaboot-profile/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-boot/sofaboot-profile/","summary":"Spring 框架从 3.1.X 版本开始提供了 profile 功能: Bean Definition Profiles，SOFABoot 支持模块级 profile 能力，即在各个模块启动的时候决定模块是否能够启动。 使用 Module-Profile 激","tags":null,"title":"SOFABoot Profile","type":"projects","url":"/projects/sofa-boot/sofaboot-profile/","wordcount":666},{"author":null,"categories":null,"content":"﻿Since 3.1.X Spring framework has started to support the profile function: Bean Definition Profiles, SOFABoot support modular-level profiling, it will determine whether a module can be started when each module is getting started.\nActivating Module Using Module-Profile To enable the SOFABoot profiling, we need to add the com.alipay.sofa.boot.active-profiles field in the application.properties file. The value of this field is a comma-separated string denoting a list of profiles allowed to be activated. After specifying it, SOFABoot will specify a profile list represented by the field for each module that can be activated.\nThe sofa-module.properties file of the SOFABoot module supports the Module-Profile field, which points to a comma-separated string of values representing which profiles are allowed to be activated. Module-Profile supports the inversion operation, !dev indicates that com.alipay.sofa.boot.active-profiles is activated when it does not contain dev.\nIf the value of the com.alipay.sofa.boot.active-profiles field is not specified in the application, all modules are allowed to be started. If the Module-Profile is not specified in the SOFABoot module, the current SOFABoot module can be started with any profile.\nExample Activating the dev SOFABoot Module Add the following configurations to the application.properties file:\ncom.alipay.sofa.boot.active-profiles=dev With this configuration, the module with dev profile will be activated.\nAdd the following configuration to each sofa-module.properties file where modules with dev profile need to be activated.\nModule-Profile=dev Configuring Multiple Activation Profiles Add the following configurations to the application.properties file:\ncom.alipay.sofa.boot.active-profiles=dev,test With this configuration, the modules with dev or test profile will be activated.\nAdd the following configuration to the SOFABoot\u0026amp;rsquo;s sofa-module.properties file:\nModule-Profile=test,product With this configuration, the module will be activated when the com.alipay.sofa.boot.active-profiles contains test or product. Since the com.alipay.sofa.boot.active-profiles is specified as dev and test, this module will be activated.\nThe Inverted Module-Profile Add the following configurations to the application.properties file:\ncom.alipay.sofa.boot.active-profiles=dev With this configuration, the module with dev profile will be activated.\nAdd the following configuration to the SOFABoot\u0026amp;rsquo;s sofa-module.properties file:\nModule-Profile=!product This will activate the module when the com.alipay.sofa.boot.active-profiles does not contain product. Since it is specified as dev, this module will be activated.\nSet the spring.profiles.active property that is used to activate the Spring context of the module. Add the following configurations to the application.properties file:\ncom.alipay.sofa.boot.active-profiles=dev,test With this configuration, the modules with dev or test profile will be activated. If a module meets those conditions, …","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofaboot-profile/","fuzzywordcount":500,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"b29d568fa057cad0b440790d5cc65d07","permalink":"/en/projects/sofa-boot/sofaboot-profile/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/en/projects/sofa-boot/sofaboot-profile/","summary":"﻿Since 3.1.X Spring framework has started to support the profile function: Bean Definition Profiles, SOFABoot support modular-level profiling, it will determine whether a module can be started when each module is getting started.\nActivating Module Using Module-Profile To enable the SOFABoot profiling, we need to add the com.alipay.sofa.boot.active-profiles field in the application.properties file. The value of this field is a comma-separated string denoting a list of profiles allowed to be activated.","tags":null,"title":"SOFABoot profile","type":"projects","url":"/en/projects/sofa-boot/sofaboot-profile/","wordcount":450},{"author":null,"categories":null,"content":"SOFABoot 是蚂蚁金服开源的基于 Spring Boot 的研发框架，它在 Spring Boot 的基础上，提供了诸如 Readiness Check，类隔离，日志空间隔离等能力。在增强了 Spring Boot 的同时，SOFABoot 提供了让用户可以在 Spring Boot 中非常方便地使用 SOFA 中间件的能力。\n你可以在发布历史中查看所有的发布报告，SOFABoot 版本和 Spring Boot 版本对应关系如下：\n   SOFABoot 版本 Spring Boot 版本     2.3.x 1.4.2.RELEASE   2.4.x 1.4.2.RELEASE   2.5.x 1.5.16.RELEASE   3.0.x 2.0.3.RELEASE   3.1.x 2.1.0.RELEASE   3.2.x 2.1.0.RELEASE   3.3.0～3.3.1 2.1.11.RELEASE   3.3.2 及以后 2.1.13.RELEASE    即 SOFABoot 2.3.x 和 2.4.x 系列版本构建在 Spring Boot 1.4.2.RELEASE 基础之上；SOFABoot 2.5.x 系列版本构建在 Spring Boot 1.5.x 基础之上；SOFABoot 3.x 系列版本将构建在 Spring Boot 2.x 基础之上。你可以在发布历史中查看获取所有的历史版本代码。另外为了方便社区同学能够基于最新开发版本的 SOFABoot 进行开发学习，我们会发布当前开发分支的 SNAPSHOT 版本。为顺利从中央仓库拉取 SNAPSHOT 包，需要在本地 maven setting.xml 文件增加如下 profile 配置:\n\u0026amp;lt;profile\u0026amp;gt; \u0026amp;lt;id\u0026amp;gt;default\u0026amp;lt;/id\u0026amp;gt; \u0026amp;lt;activation\u0026amp;gt; \u0026amp;lt;activeByDefault\u0026amp;gt;true\u0026amp;lt;/activeByDefault\u0026amp;gt; \u0026amp;lt;/activation\u0026amp;gt; \u0026amp;lt;repositories\u0026amp;gt; \u0026amp;lt;repository\u0026amp;gt; \u0026amp;lt;snapshots\u0026amp;gt; \u0026amp;lt;enabled\u0026amp;gt;true\u0026amp;lt;/enabled\u0026amp;gt; \u0026amp;lt;/snapshots\u0026amp;gt; \u0026amp;lt;id\u0026amp;gt;maven-snapshot\u0026amp;lt;/id\u0026amp;gt; \u0026amp;lt;url\u0026amp;gt;https://oss.sonatype.org/content/repositories/snapshots\u0026amp;lt;/url\u0026amp;gt; \u0026amp;lt;/repository\u0026amp;gt; \u0026amp;lt;/repositories\u0026amp;gt; \u0026amp;lt;pluginRepositories\u0026amp;gt; \u0026amp;lt;pluginRepository\u0026amp;gt; \u0026amp;lt;snapshots\u0026amp;gt; \u0026amp;lt;enabled\u0026amp;gt;true\u0026amp;lt;/enabled\u0026amp;gt; \u0026amp;lt;/snapshots\u0026amp;gt; \u0026amp;lt;id\u0026amp;gt;maven-snapshot\u0026amp;lt;/id\u0026amp;gt; \u0026amp;lt;url\u0026amp;gt;https://oss.sonatype.org/content/repositories/snapshots\u0026amp;lt;/url\u0026amp;gt; \u0026amp;lt;/pluginRepository\u0026amp;gt; \u0026amp;lt;/pluginRepositories\u0026amp;gt; \u0026amp;lt;/profile\u0026amp;gt; 目前 SOFABoot 最新版本为 3.1.0，基于 Spring Boot 2.1.0.RELEASE, 支持 JDK11。\n功能描述 SOFABoot 在 Spring Boot 基础上，提供了以下能力：\n 扩展 Spring Boot 健康检查的能力：在 Spring Boot 健康检查能力基础上，提供了 Readiness Check 的能力，保证应用实例安全上线。 提供模块化开发的能力：基于 Spring 上下文隔离提供模块化开发能力，每个 SOFABoot 模块使用独立的 Spring 上下文，避免不同 SOFABoot 模块间的 BeanId 冲突。 增加模块并行加载和 Spring Bean 异步初始化能力，加速应用启动； 增加日志空间隔离的能力：中间件框架自动发现应用的日志实现依赖并独立打印日志，避免中间件和应用日志实现绑定，通过 sofa-common-tools 实现。 增加类隔离的能力：基于 SOFAArk 框架提供类隔离能力，方便使用者解决各种类冲突问题。 增加中间件集成管理的能力：统一管控、提供中间件统一易用的编程接口、每一个 SOFA 中间件都是独立可插拔的组件。 提供完全兼容 Spring Boot的能力：SOFABoot 基于 Spring Boot 的基础上进行构建，并且完全兼容 Spring Boot。  应用场景 SOFABoot 本身就脱胎于蚂蚁金服内部对于 Spring Boot 的实践，补充了 Spring Boot 在大规模金融级生产场景下一些不足的地方，所以 SOFABoot 特别适合于这样的场景。\n当然，SOFABoot 的每个组件都是可选的，用户可以灵活选择其中的功能来使用，比如如果仅仅想在 Spring Boot 下面引入 SOFA 中间件，可以不需引入 SOFABoot 中的类隔离能力。\n","date":-62135596800,"description":"","dir":"projects/sofa-boot/overview/","fuzzywordcount":900,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"fe6aed461c61b86dfed846a2dc0b7dcb","permalink":"/projects/sofa-boot/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-boot/overview/","summary":"SOFABoot 是蚂蚁金服开源的基于 Spring Boot 的研发框架，它在 Spring Boot 的基础上，提供了诸如 Readiness Check，类隔离，日志空间隔离等能力。在增强了 Spring Boot 的同时，SOFABo","tags":null,"title":"SOFABoot 介绍","type":"projects","url":"/projects/sofa-boot/overview/","wordcount":874},{"author":null,"categories":null,"content":"SOFABoot 提供了类隔离框架 SOFAArk, 弥补了 Spring Boot 在类隔离能力上的缺失，用以解决在实际开发中常见的类冲突、包冲突问题，详细请参考 SOFAArk。\n在 SOFABoot 工程中使用类隔离能力，只需两步操作；配置 sofa-ark-maven-plugin 打包插件以及引入 sofa-ark-springboot-starter 类隔离框架依赖；\n配置 Maven 打包插件 官方提供了 Maven 插件 - sofa-ark-maven-plugin ，只需要简单的配置项，即可将 SpringBoot 工程打包成标准格式规范的可执行 Ark 包，插件坐标为：\n\u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/plugin\u0026amp;gt; 配置模板如下：\n\u0026amp;lt;build\u0026amp;gt; \u0026amp;lt;plugins\u0026amp;gt; \u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;executions\u0026amp;gt; \u0026amp;lt;execution\u0026amp;gt; \u0026amp;lt;id\u0026amp;gt;default-cli\u0026amp;lt;/id\u0026amp;gt; \u0026amp;lt;!--goal executed to generate executable-ark-jar --\u0026amp;gt; \u0026amp;lt;goals\u0026amp;gt; \u0026amp;lt;goal\u0026amp;gt;repackage\u0026amp;lt;/goal\u0026amp;gt; \u0026amp;lt;/goals\u0026amp;gt; \u0026amp;lt;configuration\u0026amp;gt; \u0026amp;lt;!--specify destination where executable-ark-jar will be saved, default saved to ${project.build.directory}--\u0026amp;gt; \u0026amp;lt;outputDirectory\u0026amp;gt;./target\u0026amp;lt;/outputDirectory\u0026amp;gt; \u0026amp;lt;!--default none--\u0026amp;gt; \u0026amp;lt;arkClassifier\u0026amp;gt;executable-ark\u0026amp;lt;/arkClassifier\u0026amp;gt; \u0026amp;lt;!-- all class exported by ark plugin would be resolved by ark biz in default, if configure denyImportClasses, then it would prefer to load them by ark biz itself --\u0026amp;gt; \u0026amp;lt;denyImportClasses\u0026amp;gt; \u0026amp;lt;class\u0026amp;gt;com.alipay.sofa.SampleClass1\u0026amp;lt;/class\u0026amp;gt; \u0026amp;lt;class\u0026amp;gt;com.alipay.sofa.SampleClass2\u0026amp;lt;/class\u0026amp;gt; \u0026amp;lt;/denyImportClasses\u0026amp;gt; \u0026amp;lt;!-- Corresponding to denyImportClasses, denyImportPackages is package-level --\u0026amp;gt; \u0026amp;lt;denyImportPackages\u0026amp;gt; \u0026amp;lt;package\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/package\u0026amp;gt; \u0026amp;lt;package\u0026amp;gt;org.springframework\u0026amp;lt;/package\u0026amp;gt; \u0026amp;lt;/denyImportPackages\u0026amp;gt; \u0026amp;lt;!-- denyImportResources can prevent resource exported by ark plugin with accurate name to be resolved --\u0026amp;gt; \u0026amp;lt;denyImportResources\u0026amp;gt; \u0026amp;lt;resource\u0026amp;gt;META-INF/spring/test1.xml\u0026amp;lt;/resource\u0026amp;gt; \u0026amp;lt;resource\u0026amp;gt;META-INF/spring/test2.xml\u0026amp;lt;/resource\u0026amp;gt; \u0026amp;lt;/denyImportResources\u0026amp;gt; \u0026amp;lt;/configuration\u0026amp;gt; \u0026amp;lt;/execution\u0026amp;gt; \u0026amp;lt;/executions\u0026amp;gt; \u0026amp;lt;/plugin\u0026amp;gt; \u0026amp;lt;/plugins\u0026amp;gt; \u0026amp;lt;/build\u0026amp;gt; 插件配置项解释：\n outputDirectory: 执行 mvn package 命令后，指定打出来的 ark 包存放目录，默认存放至 ${project.build.directory} arkClassifier: 执行 mvn depleoy 命令后，指定发布到仓库的 ark 包的maven坐标的 classifer 值, 默认为空；我们推荐配置此配置项用于和普通的 Fat Jar 加以名字上区别； denyImportClasses: 默认情况下，应用会优先加载 ark plugin 导出的类，使用该配置项，可以禁止应用从 ark plugin 加载其导出类； denyImportPackages: 对应上述的 denyImportClasses, 提供包级别的禁止导入； denyImportResources: 默认情况下，应用会优先加载 ark plugin 导出的资源，使用该配置项，可以禁止应用从 ark plugin 加载其导出资源；  添加类隔离框架依赖 在实际开发中，为了在跑测试用例时使用 SOFABoot 类隔离能力，需要在 SOFABoot 工程中添加如下的依赖：\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-springboot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 根据 SpringBoot 依赖即服务的原则，添加该依赖之后，应用启动之前，会优先启动 SOFABoot 类隔离容器；\nSOFABoot 的类隔离框架会自动检测应用中是否有引入 Ark Plugin（即需要被隔离的jar包，详情请参考 SOFAArk）, 并隔离加载；例如为了避免 SOFABoot 官方提供的 SOFARPC 组件和应用产生依赖冲突，SOFABoot提供了 SOFARPC 组件对应的 ark plugin 版，用户如果需要隔离 SOFARPC，只需要添加如下组件：\n\u0026amp;lt;dependency\u0026amp;gt; …","date":-62135596800,"description":"","dir":"projects/sofa-boot/classloader-isolation/","fuzzywordcount":1700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"e007416ab008c1dd4b886433dbf8af01","permalink":"/projects/sofa-boot/classloader-isolation/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/projects/sofa-boot/classloader-isolation/","summary":"SOFABoot 提供了类隔离框架 SOFAArk, 弥补了 Spring Boot 在类隔离能力上的缺失，用以解决在实际开发中常见的类冲突、包冲突问题，详细请参考 SOFAArk。 在 SOFABoot 工程中使用类","tags":null,"title":"SOFABoot 使用类隔离","type":"projects","url":"/projects/sofa-boot/classloader-isolation/","wordcount":1667},{"author":null,"categories":null,"content":"","date":-62135596800,"description":"本指南将基于 SOFADashboard 的 ARK 管控能力来实现 SOFAArk 提供的合并部署和动态模块推送的功能。","dir":"guides/kc-sofastack-dynamic-demo/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"8bfd4a50e21ce9fc867b1cf18a8c9af3","permalink":"/guides/kc-sofastack-dynamic-demo/","publishdate":"0001-01-01T00:00:00Z","readingtime":0,"relpermalink":"/guides/kc-sofastack-dynamic-demo/","summary":"","tags":null,"title":"SOFABoot 动态模块实践","type":"guides","url":"/guides/kc-sofastack-dynamic-demo/","wordcount":0},{"author":null,"categories":null,"content":"SOFABoot 支持模块化隔离，在实际的使用场景中，一个模块中的 bean 有时候需要开放一些入口，供另外一个模块扩展。SOFABoot 借鉴和使用了 Nuxeo Runtime 项目 以及 nuxeo 项目，并在上面扩展，与 Spring 融合，提供扩展点的能力。\n使用 在 SOFABoot 中使用扩展点能力，需要以下三个步骤：\n定义提供扩展能力的 bean 在使用 SOFABoot 扩展点能力时，首先需要定一个需要被扩展的 bean，先定一个接口：\npackage com.alipay.sofa.boot.test; public interface IExtension { String say(); } 定义这个接口的实现：\npackage com.alipay.sofa.boot.test.impl; public class ExtensionImpl implements IExtension { private String word; @Override public String say() { return word; } public void setWord(String word) { this.word = word; } public void registerExtension(Extension extension) throws Exception { Object[] contributions = extension.getContributions(); String extensionPoint = extension.getExtensionPoint(); if (contributions == null) { return; } for (Object contribution : contributions) { if (\u0026amp;#34;word\u0026amp;#34;.equals(extensionPoint)) { setWord(((ExtensionDescriptor) contribution).getValue()); } } } } 在这里可以看到有一个方法：registerExtension ，暂时可以先不用管这个方法，后续会介绍其具体的作用。\n在模块的 Spring 配置文件中，我们把这个 bean 给配置起来：\n\u0026amp;lt;bean id=\u0026amp;#34;extension\u0026amp;#34; class=\u0026amp;#34;com.alipay.sofa.boot.test.impl.ExtensionImpl\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;#34;word\u0026amp;#34; value=\u0026amp;#34;Hello, world\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt; 定义扩展点 在上面的 bean 中有一个字段 word ，在实际中，我们希望这个字段能够被其他的模块自定义进行覆盖，这里我们将其以扩展点的形式暴露出来。\n首先需要一个类去描述这个扩展点：\n@XObject(\u0026amp;#34;word\u0026amp;#34;) public class ExtensionDescriptor { @XNode(\u0026amp;#34;value\u0026amp;#34;) private String value; public String getValue() { return value; } } 然后在 xml 中定义扩展点：\n\u0026amp;lt;sofa:extension-point name=\u0026amp;#34;word\u0026amp;#34; ref=\u0026amp;#34;extension\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:object class=\u0026amp;#34;com.alipay.sofa.boot.test.extension.ExtensionDescriptor\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/sofa:extension-point\u0026amp;gt; 其中：\n name 为扩展点的名字 ref 为扩展点所作用在的 bean object 为扩展点的贡献点具体的描述，这个描述是通过 XMap 的方式来进行的(XMap 的作用是将 Java 对象和 XML 文件进行映射，这里建议通过在网上搜索下 XMap 的文档来了解 XMap)  定义扩展 上述已经将扩展点定义好了，此时我们就可以对这个 bean 进行扩展了:\n\u0026amp;lt;sofa:extension bean=\u0026amp;#34;extension\u0026amp;#34; point=\u0026amp;#34;word\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:content\u0026amp;gt; \u0026amp;lt;word\u0026amp;gt; \u0026amp;lt;value\u0026amp;gt;newValue\u0026amp;lt;/value\u0026amp;gt; \u0026amp;lt;/word\u0026amp;gt; \u0026amp;lt;/sofa:content\u0026amp;gt; \u0026amp;lt;/sofa:extension\u0026amp;gt; 其中：\n bean 为扩展所作用在的 bean point 为扩展点的名字 content 里面的内容为扩展的定义，其会通过 XMap 将内容解析为：扩展点的贡献点具体的描述对象，在这里即为 com.alipay.sofa.boot.test.extension.ExtensionDescriptor 对象  到这里，我们可以回头看一开始在 com.alipay.sofa.boot.test.impl.ExtensionImpl 中定义的 registerExtension 方法了，SOFABoot 在解析到贡献点时，会调用被扩展 bean 的 registerExtension 方法，其中包含了用户定义的贡献点处理逻辑，在上述的例子中，获取用户定义的 value 值，并将其设置到 word 字段中覆盖 bean 中原始定义的值。\n此时，调用 extension bean 的 say() 方法，可以看到返回扩展中定义的值: newValue 。\nXMap 支持和扩展 上述的例子中只是一个很简单的扩展，其实 XMap 包含了非常丰富的描述能力，包括 List, Map 等，这些可以通过查看 XMap 的文档来了解。\n在 SOFABoot 中，除了 XMap 原生的支持以外，还扩展了跟 Spring 集成的能力：\n 通过 XNode 扩展出了 XNodeSpring 通过 XNodeList 扩展出了 XNodeListSpring 通过 XNodeMap 扩展出了 XNodeMapSpring  这部分的扩展能力，让扩展点的能力更加丰富，描述对象中可以直接指向一个 SpringBean(用户配置 bean 的名字，SOFABoot 会根据名字从 spring 上下文中获取到 bean)，这里举一个使用 XNodeListSpring 的例子，依然是上述描述的三个步骤：\n定义提供扩展能力的 bean 接口定义：\n在这个接口里，返回一个 list，目标是这个 list 能够被通过扩展的方式填充\npackage com.alipay.sofa.boot.test; public interface IExtension { List\u0026amp;lt;SimpleSpringListBean\u0026amp;gt; …","date":-62135596800,"description":"","dir":"projects/sofa-boot/extension/","fuzzywordcount":2000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"93225b6c1f2b68f2047a7cf49b76650b","permalink":"/projects/sofa-boot/extension/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/projects/sofa-boot/extension/","summary":"SOFABoot 支持模块化隔离，在实际的使用场景中，一个模块中的 bean 有时候需要开放一些入口，供另外一个模块扩展。SOFABoot 借鉴和使用了 Nuxeo Runtime 项目 以及 nuxeo 项","tags":null,"title":"SOFABoot 拓展点","type":"projects","url":"/projects/sofa-boot/extension/","wordcount":1943},{"author":null,"categories":null,"content":"本文档将演示了如何在 SOFABoot 环境下应用 SOFARPC 进行服务的发布和引用。\n您可以直接在工程下找到本文档的示例代码。注意,示例代码中需要本地安装 zookeeper 环境,如果没有安装.需要将application.properties中的com.alipay.sofa.rpc.registry.address 配置注释掉.走本地文件注册中心的方式\n创建工程  环境准备：SOFABoot 需要 JDK7 或者 JDK8 ，需要采用 Apache Maven 2.2.5 或者以上的版本来编译。 工程构建：SOFABoot 构建在 Spring Boot 之上。因此可以使用 Spring Boot 的工程生成工具 来生成一个标准的Spring Boot 工程。 引入 SOFABoot 环境：生成的 Spring Boot 标准工程直接使用的 Spring Boot 的 parent 依赖，改为 SOFABoot 提供的 parent 依赖，该parent 提供并管控了多种 SOFABoot 提供的 starter。  \u0026amp;lt;parent\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-starter-parent\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${spring.boot.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;relativePath/\u0026amp;gt; \u0026amp;lt;/parent\u0026amp;gt; 替换为：\n\u0026amp;lt;parent\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofaboot-dependencies\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${sofa.boot.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/parent\u0026amp;gt; 这里的 ${sofa.boot.version} 指定具体的 SOFABoot 版本，参考发布历史 4. 配置 application.properties ：application.properties 是 SOFABoot 工程中的配置文件。这里需要配置一个必不可少的配置项，即应用名。\nspring.application.name=AppName 引入 RPC Starter：  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;rpc-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 声明 SOFABoot 的 xsd 文件：在要使用的 XML 配置文件中将头部 xsd 文件的声明设置为如下。这样就能够使用 SOFABoot 定义的 XML 元素进行开发。  \u0026amp;lt;?xml version=\u0026amp;#34;1.0\u0026amp;#34; encoding=\u0026amp;#34;UTF-8\u0026amp;#34;?\u0026amp;gt; \u0026amp;lt;beans xmlns=\u0026amp;#34;http://www.springframework.org/schema/beans\u0026amp;#34; xmlns:xsi=\u0026amp;#34;http://www.w3.org/2001/XMLSchema-instance\u0026amp;#34; xmlns:sofa=\u0026amp;#34;http://sofastack.io/schema/sofaboot\u0026amp;#34; xmlns:context=\u0026amp;#34;http://www.springframework.org/schema/context\u0026amp;#34; xsi:schemaLocation=\u0026amp;#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://sofastack.io/schema/sofaboot http://sofastack.io/schema/sofaboot.xsd\u0026amp;#34; default-autowire=\u0026amp;#34;byName\u0026amp;#34;\u0026amp;gt; 定义服务接口与实现 public interface HelloSyncService { String saySync(String string); } public class HelloSyncServiceImpl implements HelloSyncService { @Override public String saySync(String string) { return string; } } 服务端发布服务 在 xml 文件中编写如下配置。Spring 上下文在刷新时，SOFABoot 就将该服务实现注册到了服务器上，以 bolt 协议与客户端进行通信地址，并将地址等元数据发布到了注册中心(这里默认使用的本地文件作为注册中心)。\n\u0026amp;lt;bean id=\u0026amp;#34;helloSyncServiceImpl\u0026amp;#34; class=\u0026amp;#34;com.alipay.sofa.rpc.samples.invoke.HelloSyncServiceImpl\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;sofa:service ref=\u0026amp;#34;helloSyncServiceImpl\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofa.rpc.samples.invoke.HelloSyncService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt/\u0026amp;gt; \u0026amp;lt;/sofa:service\u0026amp;gt; 客户端引用服务 在 xml 文件中编写如下配置。Spring 上下文刷新时，SOFABoot 会生成一个RPC的代理 bean，即 personReferenceBolt 。这样就可以直接在代码中使用该 bean 进行远程调用了。\n\u0026amp;lt;sofa:reference id=\u0026amp;#34;helloSyncServiceReference\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofa.rpc.samples.invoke.HelloSyncService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt/\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt; 运行 在 SpringBoot 的启动类中编码如下。其中利用 ImportResource 将上述的xml文件加载。\n@ImportResource({ \u0026amp;#34;classpath*:rpc-sofa-boot-starter-samples.xml\u0026amp;#34; }) …","date":-62135596800,"description":"","dir":"projects/sofa-rpc/getting-started-with-sofa-boot/","fuzzywordcount":900,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"0dd5e0e5116473aee630cba38679d493","permalink":"/projects/sofa-rpc/getting-started-with-sofa-boot/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-rpc/getting-started-with-sofa-boot/","summary":"本文档将演示了如何在 SOFABoot 环境下应用 SOFARPC 进行服务的发布和引用。 您可以直接在工程下找到本文档的示例代码。注意,示例代码中需要本地安装 zookeeper 环境,如果没有","tags":null,"title":"SOFABoot 方式快速入门","type":"projects","url":"/projects/sofa-rpc/getting-started-with-sofa-boot/","wordcount":815},{"author":null,"categories":null,"content":"在xml方式中发布和引用服务的方式如下。 sofa:service 元素表示发布服务， sofa:reference 元素表示引用服务。 sofa:binding 表示服务发布或引用的协议。\n\u0026amp;lt;bean id=\u0026amp;#34;personServiceImpl\u0026amp;#34; class=\u0026amp;#34;com.alipay.sofa.boot.examples.demo.rpc.bean.PersonServiceImpl\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;sofa:service ref=\u0026amp;#34;personServiceImpl\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofa.boot.examples.demo.rpc.bean.PersonService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt/\u0026amp;gt; \u0026amp;lt;/sofa:service\u0026amp;gt; 一个服务也可以通过多种协议进行发布，如下：\n\u0026amp;lt;sofa:service ref=\u0026amp;#34;personServiceImpl\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofa.boot.examples.demo.rpc.bean.PersonService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt/\u0026amp;gt; \u0026amp;lt;sofa:binding.rest/\u0026amp;gt; \u0026amp;lt;sofa:binding.dubbo/\u0026amp;gt; \u0026amp;lt;/sofa:service\u0026amp;gt; 服务引用\n\u0026amp;lt;sofa:reference id=\u0026amp;#34;personReferenceBolt\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofa.boot.examples.demo.rpc.bean.PersonService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt/\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt; 也可以是其他的协议\n\u0026amp;lt;sofa:reference id=\u0026amp;#34;personReferenceRest\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofa.boot.examples.demo.rpc.bean.PersonService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.rest/\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt; ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/programing-sofa-boot-xml/","fuzzywordcount":200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"9192a93415bee3070a9be62c0f693949","permalink":"/projects/sofa-rpc/programing-sofa-boot-xml/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/programing-sofa-boot-xml/","summary":"在xml方式中发布和引用服务的方式如下。 sofa:service 元素表示发布服务， sofa:reference 元素表示引用服务。 sofa:binding 表示服务发布或引用的协议。 \u0026lt;bean id=\u0026#34;personServiceImpl\u0026#34; class=\u0026#34;com.alipay.sofa.boot.examples.demo.rpc.bean.PersonServiceImpl\u0026#34;/\u0026gt; \u0026lt;sofa:service ref=\u0026#34;personServiceImpl\u0026#34; interface=\u0026#34;com.alipay.sofa.boot.examples.demo.rpc.bean.PersonService\u0026#34;\u0026gt; \u0026lt;sofa:binding.bolt/\u0026gt; \u0026lt;/sofa:service\u0026gt; 一个服务也可以通","tags":null,"title":"SOFABoot 环境 XML 配置使用","type":"projects","url":"/projects/sofa-rpc/programing-sofa-boot-xml/","wordcount":113},{"author":null,"categories":null,"content":"SOFABoot 为 RPC 服务的发布和引用提供了一套编程 API 方式，方便直接在代码中发布和引用 RPC 服务，与 Spring 的 ApplicationContextAware 类似，为使用编程 API 方式，首先需要实现 ClientFactoryAware 接口获取编程组件 API：\npublic class ClientFactoryBean implements ClientFactoryAware { private ClientFactory clientFactory; @Override public void setClientFactory(ClientFactory clientFactory) { this.clientFactory = clientFactory; } } 以 DirectService 为例，看下如何使用 clientFactory 通过编程 API 方式发布 RPC 服务：\nServiceClient serviceClient = clientFactory.getClient(ServiceClient.class); ServiceParam serviceParam = new ServiceParam(); serviceParam.setInterfaceType(DirectService.class); serviceParam.setInstance(new DirectServiceImpl()); List\u0026amp;lt;BindingParam\u0026amp;gt; params = new ArrayList\u0026amp;lt;BindingParam\u0026amp;gt;(); BindingParam serviceBindingParam = new BoltBindingParam(); params.add(serviceBindingParam); serviceParam.setBindingParams(params); serviceClient.service(serviceParam); 上面的代码中\n 首先通过 clientFactory 获得 ServiceClient 对象 然后构造 ServiceParam 对象，ServiceParam 对象包含发布服务所需参数，通过 setInstance 方法来设置需要被发布成 RPC 服务的对象，setInterfaceType 来设置服务的接口 最后，调用 ServiceClient 的 service 方法，发布一个 RPC 服务  通过编程 API 方式引用 RPC 服务的代码也是类似的：\nReferenceClient referenceClient = clientFactory.getClient(ReferenceClient.class); ReferenceParam\u0026amp;lt;DirectService\u0026amp;gt; referenceParam = new ReferenceParam\u0026amp;lt;DirectService\u0026amp;gt;(); referenceParam.setInterfaceType(DirectService.class); BindingParam refBindingParam = new BoltBindingParam(); referenceParam.setBindingParam(refBindingParam); DirectService proxy = referenceClient.reference(referenceParam); proxy.sayDirect(\u0026amp;#34;hello\u0026amp;#34;); 同样，引用一个 RPC 服务只需从 ClientFactory 中获取一个 ReferenceClient ，然后和发布一个服务类似，构造出一个 ReferenceParam，然后设置好服务的接口，最后调用 ReferenceClient 的 reference 方法即可。\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/programing-sofa-boot-api/","fuzzywordcount":400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"2679388dc3459714f869d8f8a71739d7","permalink":"/projects/sofa-rpc/programing-sofa-boot-api/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/programing-sofa-boot-api/","summary":"SOFABoot 为 RPC 服务的发布和引用提供了一套编程 API 方式，方便直接在代码中发布和引用 RPC 服务，与 Spring 的 ApplicationContextAware 类似，为使用编程 API 方式，首先需要实现 ClientFactoryAware 接口获取编程组件","tags":null,"title":"SOFABoot 环境动态 API 使用","type":"projects","url":"/projects/sofa-rpc/programing-sofa-boot-api/","wordcount":374},{"author":null,"categories":null,"content":"这部分介绍在 SOFABoot 环境下,完整的 SOFARPC 服务发布与引用说明\n发布服务 \u0026amp;lt;bean id=\u0026amp;#34;helloSyncServiceImpl\u0026amp;#34; class=\u0026amp;#34;com.alipay.sofa.rpc.samples.invoke.HelloSyncServiceImpl\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;sofa:service ref=\u0026amp;#34;helloSyncServiceImpl\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofa.rpc.samples.invoke.HelloSyncService\u0026amp;#34; unique-id=\u0026amp;#34;\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;sofa:global-attrs registry=\u0026amp;#34;\u0026amp;#34; serialize-type=\u0026amp;#34;\u0026amp;#34; filter=\u0026amp;#34;\u0026amp;#34; timeout=\u0026amp;#34;3000\u0026amp;#34; thread-pool-ref=\u0026amp;#34;\u0026amp;#34; warm-up-time=\u0026amp;#34;60000\u0026amp;#34; warm-up-weight=\u0026amp;#34;10\u0026amp;#34; weight=\u0026amp;#34;100\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;sofa:binding.rest\u0026amp;gt; \u0026amp;lt;/sofa:binding.rest\u0026amp;gt; \u0026amp;lt;/sofa:service\u0026amp;gt;    属性 名称 默认值 备注     id ID bean名    class 类 无    ref 服务接口实现类     interface 服务接口（唯一标识元素）  不管是普通调用和返回调用，这里都设置实际的接口类   unique-id 服务标签（唯一标识元素）     filter 过滤器配置别名  多个用逗号隔开   registry 服务端注册中心  逗号分隔   timeout 服务端执行超时时间     serialize-type 序列化协议 hessian2,protobuf    thread-pool-ref 服务端当前接口使用的线程池 无     weight 服务静态权重     warm-up-weight 服务预热权重     warm-up-time 服务预热时间  单位毫秒    引用服务 \u0026amp;lt;sofa:reference jvm-first=\u0026amp;#34;false\u0026amp;#34; id=\u0026amp;#34;helloSyncServiceReference\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofa.rpc.samples.invoke.HelloSyncService\u0026amp;#34; unique-id=\u0026amp;#34;\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;sofa:global-attrs type=\u0026amp;#34;sync\u0026amp;#34; timeout=\u0026amp;#34;3000\u0026amp;#34; callback-ref=\u0026amp;#34;\u0026amp;#34; callback-class=\u0026amp;#34;\u0026amp;#34; address-wait-time=\u0026amp;#34;1000\u0026amp;#34; connect.num=\u0026amp;#34;1\u0026amp;#34; check=\u0026amp;#34;false\u0026amp;#34; connect.timeout=\u0026amp;#34;1000\u0026amp;#34; filter=\u0026amp;#34;\u0026amp;#34; generic-interface=\u0026amp;#34;\u0026amp;#34; idle.timeout=\u0026amp;#34;1000\u0026amp;#34; idle.timeout.read=\u0026amp;#34;1000\u0026amp;#34; lazy=\u0026amp;#34;false\u0026amp;#34; loadBalancer=\u0026amp;#34;\u0026amp;#34; registry=\u0026amp;#34;\u0026amp;#34; retries=\u0026amp;#34;1\u0026amp;#34; serialize-type=\u0026amp;#34;\u0026amp;#34; /\u0026amp;gt; \u0026amp;lt;sofa:route target-url=\u0026amp;#34;xxx:12200\u0026amp;#34; /\u0026amp;gt; \u0026amp;lt;sofa:method name=\u0026amp;#34;hello\u0026amp;#34; callback-class=\u0026amp;#34;\u0026amp;#34; callback-ref=\u0026amp;#34;\u0026amp;#34; timeout=\u0026amp;#34;3000\u0026amp;#34; type=\u0026amp;#34;sync\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt;    属性 名称 默认值 备注     id ID 自动生成    jvm-first 是否优先本地 true    interface 服务接口（唯一标识元素）  不管是普通调用和返回调用，这里都设置实际的接口类   unique-id 服务标签（唯一标识元素）     type 调用方式 sync callback,sync,future,oneway   filter 过滤器配置别名  List   registry 服务端注册中心  List   method 方法级配置  说明同上   serialize-type 序列化协议 hessian2    target-url 直连地址  直连后register   generic-interface 泛化接口     connect.timeout 建立连接超时时间 3000(cover 5000)    connect.num 连接数 1    idle.timeout 空闲超时时间     idle.timeout.read 读空闲超时时间     loadBalancer 负载均衡算法 random    lazy 是否延迟建立长连接 false    address-wait-time 等待地址获取时间 -1 取决于实现，可能不生效。   timeout 调用超时时间 3000(cover 5000)    retries 失败后重试次数 0 跟集群模式有关，failover读取此参数。   callback-class callback 回调类 无 callback 才可用   callback-ref callback 回调类 无 callback 才可用    ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/rpc-config-xml-explain/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"4b5110e9eb6cf6c6f287aef0fd210047","permalink":"/projects/sofa-rpc/rpc-config-xml-explain/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-rpc/rpc-config-xml-explain/","summary":"这部分介绍在 SOFABoot 环境下,完整的 SOFARPC 服务发布与引用说明 发布服务 \u0026lt;bean id=\u0026#34;helloSyncServiceImpl\u0026#34; class=\u0026#34;com.alipay.sofa.rpc.samples.invoke.HelloSyncServiceImpl\u0026#34;/\u0026gt; \u0026lt;sofa:service ref=\u0026#34;helloSyncServiceImpl\u0026#34; interface=\u0026#34;com.alipay.sofa.rpc.samples.invoke.HelloSyncService\u0026#34; unique-id=\u0026#34;\u0026#34;\u0026gt; \u0026lt;sofa:binding.bolt\u0026gt; \u0026lt;sofa:global-attrs registry=\u0026#34;\u0026#34; serialize-type=\u0026#34;\u0026#34; filter=\u0026#34;\u0026#34; timeout=\u0026#34;3000\u0026#34; thread-pool-ref=\u0026#34;\u0026#34; warm-up-time=\u0026#34;60000\u0026#34; warm-up-weight=\u0026#34;10\u0026#34; weight=\u0026#34;100\u0026#34;/\u0026gt; \u0026lt;/sofa:binding.bolt\u0026gt; \u0026lt;sofa:binding.rest\u0026gt; \u0026lt;/sofa:binding.rest\u0026gt; \u0026lt;/sofa:service\u0026gt; 属性 名称 默认值 备注 id ID bean名 class 类 无 ref 服","tags":null,"title":"SOFABoot 环境发布订阅说明","type":"projects","url":"/projects/sofa-rpc/rpc-config-xml-explain/","wordcount":518},{"author":null,"categories":null,"content":"注解服务发布与服务引用 除了常规的 xml 方式发布服务外,我们也支持在SOFABoot 环境下,注解方式的发布与引用,同 xml 类似,我们有 @SofaService 和 @SofaReference,同时对于多协议,存在@SofaServiceBinding 和 @SofaReferenceBinding 注解\n服务发布 如果要发布一个 RPC 服务. 我们只需要在 Bean 上面打上@SofaService注解.指定接口和协议类型即可\n@SofaService(interfaceType = AnnotationService.class, bindings = { @SofaServiceBinding(bindingType = \u0026amp;#34;bolt\u0026amp;#34;) }) @Component public class AnnotationServiceImpl implements AnnotationService { @Override public String sayAnnotation(String stirng) { return stirng; } } 服务引用 对于需要引用远程服务的 bean, 只需要在属性,或者方法上,打上Reference 的注解即可，支持 bolt, dubbo, rest 协议。\n@Component public class AnnotationClientImpl { @SofaReference(interfaceType = AnnotationService.class, binding = @SofaReferenceBinding(bindingType = \u0026amp;#34;bolt\u0026amp;#34;)) private AnnotationService annotationService; public String sayClientAnnotation(String str) { String result = annotationService.sayAnnotation(str); return result; } } 使用演示 可以在sample 工程目录的annotation 子项目中进行验证测试.\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/programing-sofa-boot-annotation/","fuzzywordcount":400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"2c3afd33cbce4f5aa2473716b3afe5a6","permalink":"/projects/sofa-rpc/programing-sofa-boot-annotation/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/programing-sofa-boot-annotation/","summary":"注解服务发布与服务引用 除了常规的 xml 方式发布服务外,我们也支持在SOFABoot 环境下,注解方式的发布与引用,同 xml 类似,我们有 @SofaService 和 @SofaR","tags":null,"title":"SOFABoot 环境注解使用","type":"projects","url":"/projects/sofa-rpc/programing-sofa-boot-annotation/","wordcount":313},{"author":null,"categories":null,"content":"SOFADashboard is designed to implement unified management over SOFA framework components, including service governance and SOFAArk control. All technology stacks used by SOFADashboard are developed and constructed based on open-source community products, such as Ant Design Pro, SOFABoot, Spring, and MyBatis.\nCurrently, service governance and SOFAArk control of SOFADashboard are dependent on ZooKeeper. Therefore, you need to ensure the ZooKeeper service is available when you decide to use SOFADashboard. You also need to ensure that MySQL is available, because SOFAArk control and deployment uses MySQL for resource data storage.\nArchitecture Currently, service governance and SOFAArk control of SOFADashboard are implemented upon ZooKeeper-based programming.\n SOFADashboard backend corresponds to the sofa-dashboard-backend project. It is the server end project of SOFADashboard, responsible for data interaction between ZooKeeper and MySQL and for providing the rest API to the SOFADashboard frontend. SOFADashboard frontend corresponds to the sofa-dashboard-frontend project. It is the frontend project of SOFADashboard. It provides UIs for interaction with users. Application  rpc provider: service provider of SOFARPC, which registers services with ZooKeeper. rpc consumer: service consumer of SOFARPC, which subscribes to services on ZooKeeper. client: SOFADashboard client, which is available upon the installation of the sofa-dashboard-client package. Currently, the SOFADashboard client only supports registration of health-check status and port information of applications with ZooKeeper. Later on, it will evolve into SOFABoot client, and report more diversified application data. ark-biz host app: see SOFAArk .    ","date":-62135596800,"description":"","dir":"projects/sofa-dashboard/overview/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"f0664d0ca7fc1fa87e67847525081993","permalink":"/en/projects/sofa-dashboard/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-dashboard/overview/","summary":"SOFADashboard is designed to implement unified management over SOFA framework components, including service governance and SOFAArk control. All technology stacks used by SOFADashboard are developed and constructed based on open-source community products, such as Ant Design Pro, SOFABoot, Spring, and MyBatis.\nCurrently, service governance and SOFAArk control of SOFADashboard are dependent on ZooKeeper. Therefore, you need to ensure the ZooKeeper service is available when you decide to use SOFADashboard. You also need to ensure that MySQL is available, because SOFAArk control and deployment uses MySQL for resource data storage.","tags":null,"title":"SOFADashboard overview","type":"projects","url":"/en/projects/sofa-dashboard/overview/","wordcount":231},{"author":null,"categories":null,"content":"SOFADashboard 致力于对 SOFA 框架中组件进行统一管理，包括服务治理、SOFAArk 管控等。SOFADashboard 本身所用技术栈均基于开源社区产品来开发构建，包括：Ant Design Pro、SOFABoot、Spring、MyBatis 等。\n目前，SOFADashboard 中的服务治理、SOFAArk 管控等需要依赖于 Zookeeper，因此如果您需要使用 SOFADashboard 那么请确保 Zookeeper 服务可用；另外 SOFAArk 管控部署需要依赖 MySQL 进行资源数据存储，因此也需要保证 MySQL 可以正常使用。\n架构简图 SOFADashboard 目前服务治理与 SOFAArk 管控都是面向 Zookeeper 来编程实现的。\n SOFADashboard backend : 对应 sofa-dashboard-backend 工程，是 SOFADashboard 的服务端工程，负责与 Zookeeper 和 MySQL 进行数据交互，并且为 SOFADashboard frontend 提供 rest 接口。 SOFADashboard frontend : 对应 sofa-dashboard-frontend 工程，是 SOFADashboard 的前端工程，用于提供与用户交互的 UI 界面。 app 应用  rpc provider : SOFARPC 的服务提供方，会将服务注册到 Zookeeper 上。 rpc consumer : SOFARPC 的服务消费方，会从 Zookeeper 上订阅服务。 client : SOFADashboard 客户端，引入 sofa-dashboard-client 包即可。目前仅提供将应用的健康检查状态及端口信息注册到 Zookeeper ，后面将会演化成 SOFABoot client，上报更丰富的应用数据。 ark-biz 宿主应用: 参考 SOFAArk 。    ","date":-62135596800,"description":"","dir":"projects/sofa-dashboard/overview/","fuzzywordcount":500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"f0664d0ca7fc1fa87e67847525081993","permalink":"/projects/sofa-dashboard/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-dashboard/overview/","summary":"SOFADashboard 致力于对 SOFA 框架中组件进行统一管理，包括服务治理、SOFAArk 管控等。SOFADashboard 本身所用技术栈均基于开源社区产品来开发构建","tags":null,"title":"SOFADashboard 介绍","type":"projects","url":"/projects/sofa-dashboard/overview/","wordcount":431},{"author":null,"categories":null,"content":"This topic is a part of the Braft document. To read the Braft document, click here. The Raft algorithm and its application are comprehensively described in the Braft document. As JRaft is designed on the basis of Braft, we strongly recommend that you read the Braft document first to understand the basic principles and application of the Raft algorithm.\nDistributed consensus Distributed consensus is a very fundamental problem in a distributed system. Simply put, it is about how to reach a consensus on a specific value among multiple servers, and ensure that the decision is not overthrown regardless of what failures may occur on these servers. Assume that, all processes of a distributed system needs to determine a value V. If the system has the following properties, we consider it solves the problem of distributed consensus:\n Termination: All normal processes will determine the specific value of V, and there is no process that keeps running in a loop. Validity: A value V\u0026#39; determined by normal processes must have been proposed by one of them. For example, a random number generator does not have this property. Agreement: All normal processes choose the same value.  Consensus state machine Assume we have an infinitely incrementing sequence (system) a[1, 2, 3…]. If for any integer i, the value of a[i] meets the distributed consensus requirement, the system meets the requirement of a consensus state machine. Basically, all systems are subject to continuous operations, and reaching consensus on a single value is definitely not enough. To make sure all replicas of a real-life system are consistent, we usually convert the operations into entries of a write-ahead-log(WAL). Then, we make sure all replicas of the system reach a consensus on the WAL entries, so that each process will perform operations corresponding to the WAL entries in order. As a result, the replicas are in consistent states.\nRAFT RAFT is a new and easy-to-understand distributed consensus replication protocol proposed by Diego Ongaro and John Ousterhout of Stanford University as a central coordination component of the RAMCloudproject. Raft is a leader-based multi-Paxos variant that provides a more complete and straightforward protocol description than existing protocols such as Paxos, Zab, and Viewstamped Replication. It also provides a clear description for adding and deleting nodes. In Raft, replicated state machines are the most important and fundamental to distributed systems. Raft allows commands to be replicated and executed in order, and ensures that the states of nodes remain consistent when their initial states are the same. A system is fully functional (available) as long as a majority of nodes function properly. It allows non-Byzantine conditions, including network delays, packet loss, and reordering, but does not allow tampering with any messages.\nRaft can solve the distributed consensus and partitioning problems, but cannot solve the availability problem. Raft covers some …","date":-62135596800,"description":"","dir":"projects/sofa-jraft/overview/","fuzzywordcount":700,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"eff7088d010aefabdffa2858e88d76c0","permalink":"/en/projects/sofa-jraft/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/en/projects/sofa-jraft/overview/","summary":"This topic is a part of the Braft document. To read the Braft document, click here. The Raft algorithm and its application are comprehensively described in the Braft document. As JRaft is designed on the basis of Braft, we strongly recommend that you read the Braft document first to understand the basic principles and application of the Raft algorithm.\nDistributed consensus Distributed consensus is a very fundamental problem in a distributed system.","tags":null,"title":"SOFAJRaft overview","type":"projects","url":"/en/projects/sofa-jraft/overview/","wordcount":645},{"author":null,"categories":null,"content":"本介绍内容来自 braft 文档，原文链接请参见这里。braft 的关于算法和应用本身的文档非常优秀，由于 jraft 脱胎自 braft，我们强烈推荐阅读上述文档以了解 raft 算法的基本原理和应用。\n分布式一致性 分布式一致性 (distributed consensus) 是分布式系统中最基本的问题，用来保证一个分布式系统的可靠性以及容灾能力。简单的来讲，就是如何在多个机器间对某一个值达成一致, 并且当达成一致之后，无论之后这些机器间发生怎样的故障，这个值能保持不变。 抽象定义上， 一个分布式系统里的所有进程要确定一个值 v，如果这个系统满足如下几个性质， 就可以认为它解决了分布式一致性问题, 分别是:\n Termination: 所有正常的进程都会决定 v 具体的值，不会出现一直在循环的进程。 Validity: 任何正常的进程确定的值 v\u0026#39;, 那么 v\u0026#39; 肯定是某个进程提交的。比如随机数生成器就不满足这个性质。 Agreement: 所有正常的进程选择的值都是一样的。  一致性状态机 对于一个无限增长的序列 a[1, 2, 3…], 如果对于任意整数 i, a[i] 的值满足分布式一致性，这个系统就满足一致性状态机的要求。 基本上所有的系统都会有源源不断的操作, 这时候单独对某个特定的值达成一致是不够的。为了真实系统保证所有的副本的一致性，通常会把操作转化为 write-ahead-log(简称WAL)。然后让系统的所有副本对WAL保持一致，这样每个进程按照顺序执行WAL里的操作，就能保证最终的状态是一致的。\nRAFT RAFT 是一种新型易于理解的分布式一致性复制协议，由斯坦福大学的 Diego Ongaro 和 John Ousterhout 提出，作为 RAMCloud 项目中的中心协调组件。Raft 是一种 Leader-Based 的 Multi-Paxos 变种，相比 Paxos、Zab、View Stamped Replication 等协议提供了更完整更清晰的协议描述，并提供了清晰的节点增删描述。 Raft 作为复制状态机，是分布式系统中最核心最基础的组件，提供命令在多个节点之间有序复制和执行，当多个节点初始状态一致的时候，保证节点之间状态一致。系统只要多数节点存活就可以正常处理，它允许消息的延迟、丢弃和乱序，但是不允许消息的篡改（非拜占庭场景）。\nRaft 可以解决分布式理论中的 CP，即一致性和分区容忍性，并不能解决 Available 的问题。其中包含分布式系统中一些通常的功能：\n Leader Election Log Replication Membership Change Log Compaction  RAFT 可以做什么 通过 RAFT 提供的一致性状态机，可以解决复制、修复、节点管理等问题，极大的简化当前分布式系统的设计与实现，让开发者只关注于业务逻辑，将其抽象实现成对应的状态机即可。基于这套框架，可以构建很多分布式应用：\n 分布式锁服务，比如 Zookeeper 分布式存储系统，比如分布式消息队列、分布式块系统、分布式文件系统、分布式表格系统等 高可靠元信息管理，比如各类 Master 模块的 HA  JRAFT 一个纯 Java 的 Raft 算法实现库, 基于百度 braft 实现而来, 使用 Java 重写了所有功能, 支持:\n Leader election and priority-based semi-deterministic leader election. Replication and recovery. Snapshot and log compaction. Read-only member (learner). Membership management. Fully concurrent replication. Fault tolerance. Asymmetric network partition tolerance. Workaround when quorate peers are dead. Replication pipeline optimistic Linearizable read, ReadIndex/LeaseRead.  联系我们 更多讨论欢迎加入钉钉讨论群：30315793\n","date":-62135596800,"description":"","dir":"projects/sofa-jraft/overview/","fuzzywordcount":1200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"eff7088d010aefabdffa2858e88d76c0","permalink":"/projects/sofa-jraft/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/sofa-jraft/overview/","summary":"本介绍内容来自 braft 文档，原文链接请参见这里。braft 的关于算法和应用本身的文档非常优秀，由于 jraft 脱胎自 braft，我们强烈推荐阅读上述文档以了","tags":null,"title":"SOFAJRaft 介绍","type":"projects","url":"/projects/sofa-jraft/overview/","wordcount":1132},{"author":null,"categories":null,"content":"SOFALookout 是蚂蚁金服开源的一款解决系统的度量和监控问题的轻量级中间件服务。它提供的服务包括：Metrics 的埋点、收集、加工、存储与查询等。该开源项目包括了两个独立部分，分别是客户端与服务器端服务。\n1.客户端部分 SOFALookout Client 是一个 Java 的 SDK，可以帮助开发者在项目代码中进行 metrics 埋点。通过它也可以查看该 JAVA 应用的实时的状态信息。\n +------------------+ Reg: API: | dimension meters +--------+ +------------------+ | flatmap +---------------------------+ +-----------\u0026amp;gt; | Default/DropwizardMetrics| | +---------------------------+ | | http +--------------+ +-----------\u0026amp;gt; |Lookout server| | +--------------+ +----------------------+ | add common tags dimension EXTS: | JVM,OS,GC... +----+ +----------------------+ 2.服务器端服务 SOFALookout Server 可以帮助我们解决分布式环境下系统状态度量的问题，它提供丰富的协议接入支持，包括自有SDK（SOFALookout Client）上报协议，还支持 Prometheus 的数据协议（推模式和拉模式），Metricbeat 协议（版本是6），Opentsdb写入协议。 Lookout Server 兼容和增强了 Prometheus 的数据及元数据查询的 RESTful API。同样对应 PromQL 我们也基本实现了兼容和增强（不包括 Alert 相关语法）。\n2.1.Metrics 服务器端主要特性:  适配社区主要 Metrics 数据源协议写入（比如: Prometheus，Metricbeat等）； 数据的存储支持扩展，暂时开源版默认支持 Elasticsearch,并且透明和自动化了相关运维操作； 遵循 Prometheus 查询 API 的标准以及支持 PromQL，并进行了适当改进； 自带数据查询的控制台，并支持 Grafana 进行数据可视化； 使用简单，支持单一进程运行整个服务器端模块。  2.2.Metrics 服务器端工作机制: +----------------+ | Lookout Client +-----+ +----------------+ | +----------------+ | | Prometheus SDK +-----+ +-------------------+ +----------------------+ +------------------+ +-----------+ +----------------+ +--\u0026amp;gt; Lookout Gateway +---\u0026amp;gt; DB(ES/InfluxDB...) \u0026amp;lt;-----+ Lookout Server \u0026amp;lt;----+ Grafana | +----------------+ | +-------------------+ +----------------------+ +------------------+ +-----------+ | Metricbeat +-----+ +----------------+ | +----------------+ | | ... +-----+ +----------------+ ","date":-62135596800,"description":"","dir":"projects/sofa-lookout/overview/","fuzzywordcount":700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"8a8a8ef02ca95d4d11e3e4b195bbae70","permalink":"/projects/sofa-lookout/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-lookout/overview/","summary":"SOFALookout 是蚂蚁金服开源的一款解决系统的度量和监控问题的轻量级中间件服务。它提供的服务包括：Metrics 的埋点、收集、加工、存储与查询等。该开源项","tags":null,"title":"SOFALookout 介绍","type":"projects","url":"/projects/sofa-lookout/overview/","wordcount":602},{"author":null,"categories":null,"content":"1.使用本机 ES 服务  1)本地启动 ES  docker run -d --name es -p 9200:9200 -p 9300:9300 -e \u0026amp;#34;discovery.type=single-node\u0026amp;#34; elasticsearch:5.6 版本：V5，V6\n 2)检查 ES 是否健康  http://localhost:9200/_cat/health?v  3)启动 Lookout 服务  执行 all-in-one-bootstrap 编译后的 fat-jar 包，如何获得，见文末备注部分：\njava -Dcom.alipay.sofa.ark.master.biz=lookoutall -jar lookout-all-in-one-bootstrap-1.6.0-executable-ark.jar   注意 -Dcom.alipay.sofa.ark.master.biz=lookoutall 是必须的, 用于设置 sofa-ark 的 master biz。\n  4)最后进行功能验证\n  查询 （Gateway）的 metrics 作为功能验证，访问“localhost:9090”，在查询框输入：\njvm.memory.heap.used{app=\u0026amp;#34;gateway\u0026amp;#34;} 最后，也可以使用 grafana\n2.使用远程 ES 服务 总体步骤和“使用本机 ES 服务”类似，唯一不同的是，需要指定配置文件。\njava -Dcom.alipay.sofa.ark.master.biz=lookoutall -Dlookoutall.config-file=abc.properties \\ -jar lookout-all-in-one-bootstrap-1.6.0-executable-ark.jar -Dlookoutall.config-file（如果你本地启动 ES 测试的话则该配置项可以忽略！），该配置项制定的文件暂时只能引用文件系统上的 properties 文件(没有像 spring-boot 支持那么丰富），配置项必须以应用名开头，从而提供隔离能力。\n例如：在fat-jar同目录下创建一个abc.properties配置文件, 用于存放存放配置文件(下面列出了必须的配置项,用于指向使用的 ES 服务地址）：\ngateway.metrics.exporter.es.host=localhost gateway.metrics.exporter.es.port=9200 metrics-server.spring.data.jest.uri=http://localhost:9200 备注 如何获得 all-in-one-bootstrap 编译后的 fat-jar。\n方式1：本地编译\n./boot/all-in-one-bootstrap/build.sh  打包结果在boot/all-in-one-bootstrap/target/allinone-executable.jar\n 方式2：发布报告中附件获取\n临时方式（针对 1.6.0）暂时提供一个 v1.6.0的snapshot包，下载后（保证ES服务已经单独启动）运行：\njava -Dcom.alipay.sofa.ark.master.biz=lookoutall -jar lookout-all-1.6.0.snapshot.jar 方式3：使用docker镜像\n服务端默认会连接到 localhost:9200 的ES实例, 而我所用的开发机器是MacOS，无法使用 --net=host 模式启动容器，因此在容器内无法通过 localhost:9200 连接ES，需要使用如下方式绕过去：\n编辑一个配置文件，比如 foo.properties：\ngateway.metrics.exporter.es.host=es metrics-server.spring.data.jest.uri=http://es:9200 在 foo.properties 所在的目录下运行 all-in-one 镜像：\ndocker run -it \\ --name allinone \\ --link es:es \\ -p 7200:7200 \\ -p 9090:9090 \\ -v $PWD/foo.properties:/home/admin/deploy/foo.properties \\ -e JAVA_OPTS=\u0026amp;#34;-Dlookoutall.config-file=/home/admin/deploy/foo.properties\u0026amp;#34; \\ -e JAVA_OPTS=\u0026amp;#34;...定制JVM系统属性...\u0026amp;#34; \\ xzchaoo/lookout-allinone:1.6.0-SNAPSHOT  这里利用了docker的\u0026amp;ndash;link参数使得应用可以访问到ES实例 这里做测试用，所以不用-d参数在后台运行\n ","date":-62135596800,"description":"","dir":"projects/sofa-lookout/quick-start-metrics-server/","fuzzywordcount":900,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"7c12565c66342c2f8e963cf1c1e26db5","permalink":"/projects/sofa-lookout/quick-start-metrics-server/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-lookout/quick-start-metrics-server/","summary":"1.使用本机 ES 服务 1)本地启动 ES docker run -d --name es -p 9200:9200 -p 9300:9300 -e \u0026#34;discovery.type=single-node\u0026#34; elasticsearch:5.6 版本：V5，V6 2)检查 ES 是否健康 http://localhost:9200/_cat/health?v 3)启动 Lookout 服务 执行 all-in-one-bootstrap 编译后的 fat-jar 包，如何获得，见文","tags":null,"title":"SOFALookout 服务端快速开始","type":"projects","url":"/projects/sofa-lookout/quick-start-metrics-server/","wordcount":806},{"author":null,"categories":null,"content":"This repository is deprecated. It will contribute to istio directly instead of developing in a forked repo. Please go to see Istio’s doc.\n SOFAMesh is a large-scale implementation scheme of Service Mesh based on Istio. On the basis of inheriting the powerful functions and rich features of Istio, in order to meet the performance requirements in large-scale deployments and to respond to the actual situation in the implementation, the following improvements are made:\n MOSN written in Golang instead of Envoy Merge Mixer to data plane to resolve performance bottlenecks Enhance Pilot for more flexible service discovery mechanism Added support for SOFA RPC, Dubbo  The initial version was contributed by Ant Financial and Alibaba UC Business Unit.\nThe following figure shows the architectural differences between SOFAMesh and Istio:\nMain components MOSN In SOFAMesh, the data pane adopts Golang to write a module called MOSN (Modular Open Smart Network), and replaces Envoy with MOSN to integrate with Istio to implement the functions of Sidecar. MOSN is fully compatible with Envoy\u0026amp;rsquo;s APIs.\nSOFAMesh Pilot SOFAMesh greatly expands and enhances the Pilot module in Istio:\n Add an Adapter for SOFA Registry to provide solutions for super large-scale service registration and discovery; Add data synchronization modules to enable data exchange between multiple service registry centers; Add Open Service Registry API to provide standardized service registration.  Together with Pilot and MOSN, SOFAMesh provides the ability to enable traditional intrusive frameworks (such as Spring Cloud, Dubbo and SOFARPC) and Service Mesh products to communicate with each other, thus it can smoothly evolve and transit to Service Mesh.\n","date":-62135596800,"description":"","dir":"projects/sofa-mesh/overview/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"e44a7cb73f7b68217663bd75655f43d7","permalink":"/en/projects/sofa-mesh/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-mesh/overview/","summary":"This repository is deprecated. It will contribute to istio directly instead of developing in a forked repo. Please go to see Istio’s doc.\n SOFAMesh is a large-scale implementation scheme of Service Mesh based on Istio. On the basis of inheriting the powerful functions and rich features of Istio, in order to meet the performance requirements in large-scale deployments and to respond to the actual situation in the implementation, the following improvements are made:","tags":null,"title":"SOFAMesh overview","type":"projects","url":"/en/projects/sofa-mesh/overview/","wordcount":260},{"author":null,"categories":null,"content":"该项目仓库已弃用。该项目将直接向 Istio 贡献，不会继续在 fork 的仓库中开发，请转至 Istio 官网。\n SOFAMesh 是基于 Istio 改进和扩展而来的 Service Mesh 大规模落地实践方案。在继承 Istio 强大功能和丰富特性的基础上，为满足大规模部署下的性能要求以及应对落地实践中的实际情况，有如下改进：\n 采用 Golang 编写的 MOSN 取代 Envoy 合并 Mixer 到数据平面以解决性能瓶颈 增强 Pilot 以实现更灵活的服务发现机制 增加对 SOFA RPC、Dubbo 的支持  初始版本由蚂蚁金服和阿里大文娱UC事业部携手贡献。\n下图展示了SOFAMesh 和 Istio 在架构上的不同：\n主要组件 MOSN 在 SOFAMesh 中，数据面我们采用 Golang 语言编写了名为 MOSN（Modular Open Smart Network）的模块来替代 Envoy 与 Istio 集成以实现 Sidecar 的功能，同时 MOSN 完全兼容 Envoy 的 API。\nSOFA Pilot SOFAMesh 中大幅扩展和增强 Istio 中的 Pilot 模块：\n 增加 SOFA Registry 的 Adapter，提供超大规模服务注册和发现的解决方案 增加数据同步模块，以实现多个服务注册中心之间的数据交换 增加 Open Service Registry API，提供标准化的服务注册功能  MOSN 和 Pilot 配合，将可以提供让传统侵入式框架（如 Spring Cloud、Dubbo、SOFARPC 等）和 Service Mesh 产品可以相互通讯的功能，以便可以平滑的向 Service Mesh 产品演进和过渡。\n","date":-62135596800,"description":"","dir":"projects/sofa-mesh/overview/","fuzzywordcount":500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"e44a7cb73f7b68217663bd75655f43d7","permalink":"/projects/sofa-mesh/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-mesh/overview/","summary":"该项目仓库已弃用。该项目将直接向 Istio 贡献，不会继续在 fork 的仓库中开发，请转至 Istio 官网。 SOFAMesh 是基于 Istio 改进和扩展而来的 Service Mesh 大规模落地实践方案。在继承 Istio 强","tags":null,"title":"SOFAMesh 介绍","type":"projects","url":"/projects/sofa-mesh/overview/","wordcount":474},{"author":null,"categories":null,"content":"SOFARPC already supports using SOFARegistry as a service registry. Suppose you have deployed SOFARegistry Server locally according to SOFARegistry\u0026amp;rsquo;s [Quick Start] (https://www.sofastack.tech/sofa-registry/docs/Server-QuickStart), and the service discovery port is set to 9603 by default.\nTo use SOFARegistry as a service registry in SOFARPC, you only need to add the following configuration to application.properties:\ncom.alipay.sofa.rpc.registry.address=sofa://127.0.0.1:9603 The current version of SOFARegistry is supported:\nSOFARPC: 5.5.2, SOFABoot: 2.6.3。\nBecause of the time of SOFABoot, users need to specify the version of rpc starter.\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;rpc-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;5.5.2\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; SOFARPC integration verification SOFARegistry server version: 5.2.0。\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/registry-sofa/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"65085018ce2b2b2ef452993bb79a69de","permalink":"/en/projects/sofa-rpc/registry-sofa/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/registry-sofa/","summary":"SOFARPC already supports using SOFARegistry as a service registry. Suppose you have deployed SOFARegistry Server locally according to SOFARegistry\u0026rsquo;s [Quick Start] (https://www.sofastack.tech/sofa-registry/docs/Server-QuickStart), and the service discovery port is set to 9603 by default.\nTo use SOFARegistry as a service registry in SOFARPC, you only need to add the following configuration to application.properties:\ncom.alipay.sofa.rpc.registry.address=sofa://127.0.0.1:9603 The current version of SOFARegistry is supported:\nSOFARPC: 5.5.2, SOFABoot: 2.6.3。\nBecause of the time of SOFABoot, users need to specify the version of rpc starter.","tags":null,"title":"SOFARegistry","type":"projects","url":"/en/projects/sofa-rpc/registry-sofa/","wordcount":91},{"author":null,"categories":null,"content":"Product introduction SOFARegistry is a production-level, low-latency, and highly available service registry powered by Ant Financial. SOFARegistry was developed on the basis ConfigServer of Taobao. After more than ten years of business development of Ant Financial, SOFARegistry has evolved into the fifth generation architecture. Currently, SOFARegistry not only provides full support to Ant Financial and its numerous partners, but also embraces the open source community. Built on an AP architecture, SOFARegistry support s message push in seconds. It also adopts a layered architecture to support infinite horizontal scaling.\nFeatures High scalability SOFARegistry adopts a layered architecture and partition-based data storage to break the single machine performance and capacity bottleneck, and to support the theoretical \u0026amp;ldquo;infinite horizontal scaling\u0026amp;rdquo;. It has been providing reliable services to the Ant Financial production environment which has a massive number of nodes and services.\nLow latency By virtue of the SOFABolt communication framework, SOFARegistry implements TCP long connection-based heartbeat detection among nodes, and the customized push mode to send service messages between upstream and downstream nodes in seconds.\nHighly available Unlike CP-architecture based registry products such as ZooKeeper, Consul, and Etcd, SOFARegistry adopts the AP architecture based on the service characteristics of service discovery, which significantly improves the availability of the registry in the case of failures caused by network partitioning. SOFARegistry takes many measures, such as multi-replica clusters, to prevent service unavailability arising from node failures.\nArchitecture SOFARegistry has four roles: Client, SessionServer, DataServer, and MetaServer, each with unique capabilities and responsibilities. They are combined to provide external services. The relationships and structures of them are explained as follows.\nClient A client provides basic APIs to allow applications to access SOFARegistry. The client provides JAR packages to application systems, so that they can call the service subscription and publishing features of SOFARegistry.\nSessionServer The SessionServer grants clients access to SessionServer, and accepts service publishing and subscription requests from clients. It also serves as an intermediate layer to forward the published data to DataServer for storage. The SessionServer can be infinitely scaled up to support connection with large amounts of clients.\nDataServer The DataServer is responsible for storing data published by clients. The data is stored by dataId through consistent hashing. DataServer supports multi-replica backup to ensure high availability of the data. The Data can also be infinitely scaled up to support large amounts of data.\nMetaServer The MetaServer is responsible for maintaining the consistency lists of the SessionServer and DataServer within the cluster, and immediately notify other nodes in the …","date":-62135596800,"description":"","dir":"projects/sofa-registry/overview/","fuzzywordcount":500,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"d444761f1ad8b0c52e3505926176b13f","permalink":"/en/projects/sofa-registry/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/en/projects/sofa-registry/overview/","summary":"Product introduction SOFARegistry is a production-level, low-latency, and highly available service registry powered by Ant Financial. SOFARegistry was developed on the basis ConfigServer of Taobao. After more than ten years of business development of Ant Financial, SOFARegistry has evolved into the fifth generation architecture. Currently, SOFARegistry not only provides full support to Ant Financial and its numerous partners, but also embraces the open source community. Built on an AP architecture, SOFARegistry support s message push in seconds.","tags":null,"title":"SOFARegistry overview","type":"projects","url":"/en/projects/sofa-registry/overview/","wordcount":429},{"author":null,"categories":null,"content":"项目简介 SOFARegistry 是蚂蚁金服开源的一个生产级、高时效、高可用的服务注册中心。SOFARegistry 最早源自于淘宝的 ConfigServer，十年来，随着蚂蚁金服的业务发展，注册中心架构已经演进至第五代。目前 SOFARegistry 不仅全面服务于蚂蚁金服的自有业务，还随着蚂蚁金融科技服务众多合作伙伴，同时也兼容开源生态。SOFARegistry 采用 AP 架构，支持秒级时效性推送，同时采用分层架构支持无限水平扩展。\n产品特点 高可扩展性 采用分层架构、数据分片存储等方式，突破单机性能与容量瓶颈，接近理论上的“无限水平扩展”。经受过蚂蚁金服生产环境海量节点数与服务数的考验。\n高时效性 借助 SOFABolt 通信框架，实现基于TCP长连接的节点判活与推模式的变更推送，服务上下线通知时效性在秒级以内。\n高可用性 不同于 Zookeeper、Consul、Etcd 等 CP 架构注册中心产品，SOFARegistry 针对服务发现的业务特点，采用 AP 架构，最大限度地保证网络分区故障下注册中心的可用性。通过集群多副本等方式，应对自身节点故障。\n架构 服务注册中心分为四个角色，客户端（Client）、会话服务器（SessionServer）、数据服务器（DataServer）、元数据服务器（MetaServer），每个角色司职不同能力组合后共同提供对外服务能力，各部分关系和结构如下：\nClient 提供应用接入服务注册中心的基本 API 能力，应用系统通过依赖客户端 JAR 包，通过编程方式调用服务注册中心的服务订阅和服务发布能力。\nSessionServer 会话服务器，提供客户端接入能力，接受客户端的服务发布及服务订阅请求，并作为一个中间层将发布数据转发 DataServer 存储。SessionServer 可无限扩展以支持海量客户端连接。\nDataServer 数据服务器，负责存储客户端发布数据，数据存储按照数据 ID 进行一致性 hash 分片存储，支持多副本备份，保证数据高可用。DataServer 可无限扩展以支持海量数据量。\nMetaServer 元数据服务器，负责维护集群 SessionServer 和 DataServer 的一致列表，在节点变更时及时通知集群内其他节点。MetaServer 通过 SOFAJRaft 保证高可用和一致性。\n","date":-62135596800,"description":"","dir":"projects/sofa-registry/overview/","fuzzywordcount":900,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"d444761f1ad8b0c52e3505926176b13f","permalink":"/projects/sofa-registry/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-registry/overview/","summary":"项目简介 SOFARegistry 是蚂蚁金服开源的一个生产级、高时效、高可用的服务注册中心。SOFARegistry 最早源自于淘宝的 ConfigServer，十年来","tags":null,"title":"SOFARegistry 介绍","type":"projects","url":"/projects/sofa-registry/overview/","wordcount":840},{"author":null,"categories":null,"content":"SOFARPC is divided into two layers from bottom to top:\n Core layer: It contains the core components of RPC (such as various interfaces, APIs and common packages) and some common implementations (such as random load balancing algorithms). Function implementation layer: All users of the function implementation layer are equal, and all functions are implemented based on the extension mechanism.  The internal version specific for Ant Financial just has some internal extension based on the open source version.\nOf course, you can add your own third-party extension. See Extension mechanism for more information.\nModule division The implementation classes of each module only appear in the modules. Generally, the modules don\u0026amp;rsquo;t depend on each other. The modules that require cross dependency have been abstracted into the core or common modules.\nCurrently, SOFARPC is divided into the following modules:\nThe main modules and their corresponding dependencies are as follows:\n   Module Submodule Definition Description Dependency     all  Publish and packing module  All modules that need to be packaged   bom  Dependency control module Control dependency version None   example  Sample module  all   test  Test module Include integration test all   core api API module Include various basic process interfaces, messages, contexts, extension interfaces and others Common   core common Public module Include utils and data structure exception   core exception Exception module Include various exception interfaces and others common   bootstrap  Startup implementation module Include start class, service publish or reference logic, and registry operations core   proxy  Proxy implementation module Generate interface implementation proxy core   Client  Client implementation module Send request, receive response, maintain connections, routing, and implement load balancing, synchronization, asynchronization and other operations    server  Server implementation module Start listening, receive requests, send responses, distribute business threads, and implement other operations    filter  Interceptor implementation module Implement various interceptors for server and client core   codec  Coding and encoding implementation module Implement compression, serialization and other operations core   protocol  Protocol implementation module Package and process protocol and conduct negotiation core   transport  Network transmission implementation module Establish TCP connection, process sticky data packets, and distribute requested response objects    registry  Registry center implementation module Implement registration centers, such as ZooKeeper core    ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/structure-intro/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"1902232a50d57df7ab5b2c7eea1f8caa","permalink":"/en/projects/sofa-rpc/structure-intro/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-rpc/structure-intro/","summary":"SOFARPC is divided into two layers from bottom to top:\n Core layer: It contains the core components of RPC (such as various interfaces, APIs and common packages) and some common implementations (such as random load balancing algorithms). Function implementation layer: All users of the function implementation layer are equal, and all functions are implemented based on the extension mechanism.  The internal version specific for Ant Financial just has some internal extension based on the open source version.","tags":null,"title":"SOFARPC architecture","type":"projects","url":"/en/projects/sofa-rpc/structure-intro/","wordcount":347},{"author":null,"categories":null,"content":"SOFARPC Log Format After SOFARPC (v5.4.0 and above) is integrated in SOFATracer, the link data is output in JSON format by default. Each field meaning is as follows:\nRPC client digest log (rpc-client-digest.log)  Log printing time TraceId SpanId Span type Current appName Protocol type (bolt, rest) Service interface information Method name Current thread name Calling type (sync, callback, oneway, future) Routing record (DIRECT, REGISTRY) Target IP Target appName Local machine IP Return code (00=success; 01=business exception; 02=RPC logic error; 03=timeout failure;04=routing failure) Request serialization time (in ms) Response deserialization time (in ms) Response size (in Byte) Request size (in Byte) Client connection duration (in ms) Total call duration (in ms) Local client port Transparently transmitted baggage data (kv format)  Example:\n{\u0026amp;#34;timestamp\u0026amp;#34;:\u0026amp;#34;2018-05-20 17:03:20.708\u0026amp;#34;,\u0026amp;#34;tracerId\u0026amp;#34;:\u0026amp;#34;1e27326d1526807000498100185597\u0026amp;#34;,\u0026amp;#34;spanId\u0026amp;#34;:\u0026amp;#34;0\u0026amp;#34;,\u0026amp;#34;span.kind\u0026amp;#34;:\u0026amp;#34;client\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;SOFATracerRPC\u0026amp;#34;,\u0026amp;#34;protocol\u0026amp;#34;:\u0026amp;#34;bolt\u0026amp;#34;,\u0026amp;#34;service\u0026amp;#34;:\u0026amp;#34;com.alipay.sofa.tracer.examples.sofarpc.direct.DirectService:1.0\u0026amp;#34;,\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;sayDirect\u0026amp;#34;,\u0026amp;#34;current.thread.name\u0026amp;#34;:\u0026amp;#34;main\u0026amp;#34;,\u0026amp;#34;invoke.type\u0026amp;#34;:\u0026amp;#34;sync\u0026amp;#34;,\u0026amp;#34;router.record\u0026amp;#34;:\u0026amp;#34;DIRECT\u0026amp;#34;,\u0026amp;#34;remote.app\u0026amp;#34;:\u0026amp;#34;samples\u0026amp;#34;,\u0026amp;#34;remote.ip\u0026amp;#34;:\u0026amp;#34;127.0.0.1:12200\u0026amp;#34;,\u0026amp;#34;local.client.ip\u0026amp;#34;:\u0026amp;#34;127.0.0.1\u0026amp;#34;,\u0026amp;#34;result.code\u0026amp;#34;:\u0026amp;#34;00\u0026amp;#34;,\u0026amp;#34;req.serialize.time\u0026amp;#34;:\u0026amp;#34;33\u0026amp;#34;,\u0026amp;#34;resp.deserialize.time\u0026amp;#34;:\u0026amp;#34;39\u0026amp;#34;,\u0026amp;#34;resp.size\u0026amp;#34;:\u0026amp;#34;170\u0026amp;#34;,\u0026amp;#34;req.size\u0026amp;#34;:\u0026amp;#34;582\u0026amp;#34;,\u0026amp;#34;client.conn.time\u0026amp;#34;:\u0026amp;#34;0\u0026amp;#34;,\u0026amp;#34;client.elapse.time\u0026amp;#34;:\u0026amp;#34;155\u0026amp;#34;,\u0026amp;#34;local.client.port\u0026amp;#34;:\u0026amp;#34;59774\u0026amp;#34;,\u0026amp;#34;baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;} RPC server digest log (rpc-server-digest.log)  Log printing time TraceId SpanId Span type Service interface information Method name Source IP Source appName Protocol (bolt, rest) Current appName Current thread name Return code (00=success; 01=business exception; 02=RPC logic error) Server thread pool waiting time (in ms) Business processing duration (in ms) Response serialization time (in ms) Request deserialization time (in ms) Response size (in Byte) Request size (in Byte) Transparently transmitted baggage data (kv format)  Example:\n{\u0026amp;#34;timestamp\u0026amp;#34;:\u0026amp;#34;2018-05-20 …","date":-62135596800,"description":"","dir":"projects/sofa-tracer/log-format-sofarpc/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"ad45177e2719b9a22f4bfb07a0481905","permalink":"/en/projects/sofa-tracer/log-format-sofarpc/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-tracer/log-format-sofarpc/","summary":"SOFARPC Log Format After SOFARPC (v5.4.0 and above) is integrated in SOFATracer, the link data is output in JSON format by default. Each field meaning is as follows:\nRPC client digest log (rpc-client-digest.log)  Log printing time TraceId SpanId Span type Current appName Protocol type (bolt, rest) Service interface information Method name Current thread name Calling type (sync, callback, oneway, future) Routing record (DIRECT, REGISTRY) Target IP Target appName Local machine IP Return code (00=success; 01=business exception; 02=RPC logic error; 03=timeout failure;04=routing failure) Request serialization time (in ms) Response deserialization time (in ms) Response size (in Byte) Request size (in Byte) Client connection duration (in ms) Total call duration (in ms) Local client port Transparently transmitted baggage data (kv format)  Example:","tags":null,"title":"SOFARPC log","type":"projects","url":"/en/projects/sofa-tracer/log-format-sofarpc/","wordcount":259},{"author":null,"categories":null,"content":"SOFARPC Metrics SOFARPC currently measures two metrics.\nServer thread pool    metric name metric tags specification     rpc.bolt.threadpool.config bolt thread pool configuration Mainly includes thread pool configuration information for RPC server   rpc.bolt.threadpool.active.count  Running thread of the current thread pool   rpc.bolt.threadpool.idle.count  Idle thread of the current thread pool   rpc.bolt.threadpool.queue.size  Tasks in the queue of the current thread pool    Client call information    metric name metric tags specification     rpc.consumer.service.stats.fail_count.count app,service,method,protocol,invoke_type,target_app Failure count of a certain interface   rpc.consumer.service.stats.fail_count.rate app,service,method,protocol,invoke_type,target_app Number of failures per second of a certain interface   rpc.consumer.service.stats.fail_time.elapPerExec app,service,method,protocol,invoke_type,target_app Average time per failed execution of a certain interface   rpc.consumer.service.stats.fail_time.max app,service,method,protocol,invoke_type,target_app Maximum failure time of a certain interface   rpc.consumer.service.stats.fail_time.totalTime app,service,method,protocol,invoke_type,target_app Total failure time of a certain interface   rpc.consumer.service.stats.request_size.max app,service,method,protocol,invoke_type,target_app Maximum request size of a certain interface   rpc.consumer.service.stats.request_size.rate app,service,method,protocol,invoke_type,target_app Average request size per second of a certain interface   rpc.consumer.service.stats.request_size.totalAmount app,service,method,protocol,invoke_type,target_app Total request amount of a certain interface   rpc.consumer.service.stats.response_size.max app,service,method,protocol,invoke_type,target_app Maximum response size of a certain interface   rpc.consumer.service.stats.response_size.rate app,service,method,protocol,invoke_type,target_app Average response size per second of a certain interface   rpc.consumer.service.stats.response_size.totalAmount app,service,method,protocol,invoke_type,target_app Total response amount of a certain interface   rpc.consumer.service.stats.total_count.count app,service,method,protocol,invoke_type,target_app Total number of calls of a certain interface   rpc.consumer.service.stats.total_count.count_service_sum_30000 app,service,method,protocol,invoke_type,target_app Total call information of a certain interface   rpc.consumer.service.stats.total_count.rate app,service,method,protocol,invoke_type,target_app Number of calls per second of a certain interface   rpc.consumer.service.stats.total_time.elapPerExec app,service,method,protocol,invoke_type,target_app Average time per execution of a certain interface   rpc.consumer.service.stats.total_time.max app,service,method,protocol,invoke_type,target_app Maximum total time of a certain interface   rpc.consumer.service.stats.total_time.totalTime …","date":-62135596800,"description":"","dir":"projects/sofa-lookout/sofarpc-metrics/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"1f444349855508f4b111d8f2d2b5e43d","permalink":"/en/projects/sofa-lookout/sofarpc-metrics/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-lookout/sofarpc-metrics/","summary":"SOFARPC Metrics SOFARPC currently measures two metrics.\nServer thread pool    metric name metric tags specification     rpc.bolt.threadpool.config bolt thread pool configuration Mainly includes thread pool configuration information for RPC server   rpc.bolt.threadpool.active.count  Running thread of the current thread pool   rpc.bolt.threadpool.idle.count  Idle thread of the current thread pool   rpc.bolt.threadpool.queue.size  Tasks in the queue of the current thread pool    Client call information    metric name metric tags specification     rpc.","tags":null,"title":"SOFARPC Metrics","type":"projects","url":"/en/projects/sofa-lookout/sofarpc-metrics/","wordcount":332},{"author":null,"categories":null,"content":" SOFARPC 目前度量了两个指标。\n 服务端线程池    metric name metric tags specification     rpc.bolt.threadpool.config bolt 线程池配置 主要包括 rpc 服务端的线程池配置信息   rpc.bolt.threadpool.active.count  当前线程池的运行线程   rpc.bolt.threadpool.idle.count  当前线程池的空闲线程   rpc.bolt.threadpool.queue.size  当前线程池的队列中的任务    客户端调用信息    metric name metric tags specification     rpc.consumer.service.stats.fail_count.count app,service,method,protocol,invoke_type,target_app 某个具体接口失败次数   rpc.consumer.service.stats.fail_count.rate app,service,method,protocol,invoke_type,target_app 某个具体接口每秒失败   rpc.consumer.service.stats.fail_time.elapPerExec app,service,method,protocol,invoke_type,target_app 某个具体接口每秒执行时间   rpc.consumer.service.stats.fail_time.max app,service,method,protocol,invoke_type,target_app 某个具体接口失败时间最大值   rpc.consumer.service.stats.fail_time.totalTime app,service,method,protocol,invoke_type,target_app 某个具体接口失败时间总值   rpc.consumer.service.stats.request_size.max app,service,method,protocol,invoke_type,target_app 某个具体接口请求大小最大值   rpc.consumer.service.stats.request_size.rate app,service,method,protocol,invoke_type,target_app 某个具体接口每秒平均请求大小   rpc.consumer.service.stats.request_size.totalAmount app,service,method,protocol,invoke_type,target_app 某个具体接口请求大小总金额   rpc.consumer.service.stats.response_size.max app,service,method,protocol,invoke_type,target_app 某个具体接口响应大小最大值   rpc.consumer.service.stats.response_size.rate app,service,method,protocol,invoke_type,target_app 某个具体接口每秒平均响应大小   rpc.consumer.service.stats.response_size.totalAmount app,service,method,protocol,invoke_type,target_app 某个具体接口响应大小总金额   rpc.consumer.service.stats.total_count.count app,service,method,protocol,invoke_type,target_app 某个具体接口总的调用数目   rpc.consumer.service.stats.total_count.count_service_sum_30000 app,service,method,protocol,invoke_type,target_app 某个具体接口总的调用信息   rpc.consumer.service.stats.total_count.rate app,service,method,protocol,invoke_type,target_app 某个具体接口每秒调用次数   rpc.consumer.service.stats.total_time.elapPerExec app,service,method,protocol,invoke_type,target_app 某个具体接口平均每次指定时间   rpc.consumer.service.stats.total_time.max app,service,method,protocol,invoke_type,target_app 某个具体接口总时间最大值   rpc.consumer.service.stats.total_time.totalTime app,service,method,protocol,invoke_type,target_app 某个具体接口总时间    服务端被调用信息    metric name metric tags specification     rpc.provider.service.stats.fail_count.count app,service,method,protocol,caller_app 某个具体接口总的被调用失败次数   rpc.provider.service.stats.fail_count.rate app,service,method,protocol,caller_app 某个具体接口每秒失败次数   rpc.provider.service.stats.fail_time.elapPerExec app,service,method,protocol,caller_app 某个具体接口每次失败失败   rpc.provider.service.stats.fail_time.max app,service,method,protocol,caller_app 某个具体接口失败次数最大值   rpc.provider.service.stats.fail_time.totalTime app,service,method,protocol,caller_app 某个具体接口失败总时间   rpc.provider.service.stats.total_count.count app,service,method,protocol,caller_app 某个具体接口总的调用次数   rpc.provider.service.stats.total_count.rate app,service,method,protocol,caller_app …","date":-62135596800,"description":"","dir":"projects/sofa-lookout/sofarpc-metrics/","fuzzywordcount":500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"1f444349855508f4b111d8f2d2b5e43d","permalink":"/projects/sofa-lookout/sofarpc-metrics/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-lookout/sofarpc-metrics/","summary":"SOFARPC 目前度量了两个指标。 服务端线程池 metric name metric tags specification rpc.bolt.threadpool.config bolt 线程池配置 主要包括 rpc 服务端的线程池配置信息 rpc.bolt.threadpool.active.count 当前线程池的运行线程 rpc.bolt.threadpool.idle.count 当前线程池的空闲线程 rpc.bolt.threadpool.queue.size 当前","tags":null,"title":"SOFARPC Metrics 指标","type":"projects","url":"/projects/sofa-lookout/sofarpc-metrics/","wordcount":487},{"author":null,"categories":null,"content":"项目简介 SOFARPC 是蚂蚁金服开源的一款基于 Java 实现的 RPC 服务框架，为应用之间提供远程服务调用能力，具有高可伸缩性，高容错性，目前蚂蚁金服所有的业务的相互间的 RPC 调用都是采用 SOFARPC。SOFARPC 为用户提供了负载均衡，流量转发，链路追踪，链路数据透传，故障剔除等功能。\nSOFARPC 还支持不同的协议，目前包括 bolt，RESTful，dubbo，H2C 协议进行通信。其中 bolt 是蚂蚁金融服务集团开放的基于 Netty 开发的网络通信框架。\n基本原理  当一个 SOFARPC 的应用启动的时候，如果发现当前应用需要发布 RPC 服务的话，那么 SOFARPC 会将这些服务注册到服务注册中心上。如图中 Service 指向 Registry。 当引用这个服务的 SOFARPC 应用启动时，会从服务注册中心订阅到相应服务的元数据信息。服务注册中心收到订阅请求后，会将发布方的元数据列表实时推送给服务引用方。如图中 Registry 指向 Reference。 当服务引用方拿到地址以后，就可以从中选取地址发起调用了。如图中 Reference 指向 Service。  ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/overview/","fuzzywordcount":500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"62f0806ad40fcaaeab6a82470b14a2e2","permalink":"/projects/sofa-rpc/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/overview/","summary":"项目简介 SOFARPC 是蚂蚁金服开源的一款基于 Java 实现的 RPC 服务框架，为应用之间提供远程服务调用能力，具有高可伸缩性，高容错性，目前蚂蚁金服所有的业务的相互","tags":null,"title":"SOFARPC 介绍","type":"projects","url":"/projects/sofa-rpc/overview/","wordcount":402},{"author":null,"categories":null,"content":"架构图 SOFARPC 从下到上分为两层：\n 核心层：包含了我们的 RPC 的核心组件（例如我们的各种接口、API、公共包）以及一些通用的实现（例如随机等负载均衡算法）。 功能实现层：所有的功能实现层的用户都是平等的，都是基于扩展机制实现的。  蚂蚁内部使用的版本也只是开源版本上增加一些内部扩展而已。\n当然你也可以增加自己三方扩展，参见：扩展机制\n模块划分 各个模块的实现类都只在自己模块中出现，一般不交叉依赖。需要交叉依赖的全部已经抽象到core或者common模块中。\n目前模块划分如下:\n主要模块及其依赖如下：\n   模块名 子模块名 中文名 说明 依赖     all  发布打包模块  需要打包的全部模块   bom  依赖管控模块 依赖版本管控 无   example  示例模块  all   test  测试模块 包含集成测试 all   core api API模块 各种基本流程接口、消息、上下文、扩展接口等 common   core common 公共模块 utils、数据结构 exception   core exception 异常模块 各种异常接口等 common   bootstrap  启动实现模块 启动类，发布或者引用服务逻辑、以及registry的操作 core   proxy  代理实现模块 接口实现代理生成 core   client  客户端实现模块 发送请求、接收响应、连接维护、路由、负载均衡、同步异步等 core   server  服务端实现模块 启动监听、接收请求，发送响应、业务线程分发等 core   filter  拦截器实现模块 服务端和客户端的各种拦截器实现 core   codec  编解码实现模块 例如压缩，序列化等 core   protocol  协议实现模块 协议的包装处理、协商 core   transport  网络传输实现模块 TCP连接的建立，数据分包粘包处理，请求响应对象分发等 core   registry  注册中心实现模块 实现注册中心，例如zk等 core    ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/structure-intro/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"1902232a50d57df7ab5b2c7eea1f8caa","permalink":"/projects/sofa-rpc/structure-intro/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-rpc/structure-intro/","summary":"架构图 SOFARPC 从下到上分为两层： 核心层：包含了我们的 RPC 的核心组件（例如我们的各种接口、API、公共包）以及一些通用的实现（例如随机等负载均衡算法）","tags":null,"title":"SOFARPC 工程架构介绍","type":"projects","url":"/projects/sofa-rpc/structure-intro/","wordcount":598},{"author":null,"categories":null,"content":"本文档将演示了如何应用 SOFARPC 进行服务的发布和引用。 本例将在本地模拟服务端启动监听一个端口并发布一个服务，客户端引用该服务进行直连调用。\n您可以直接在工程下找到本文档的示例代码。\n创建工程 需要安装 JDK 6 及以上 和 Maven 3 以上.\n我们新建一个 Maven 工程，并引入 SOFARPC 的依赖。\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-rpc-all\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;最新版本\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 注：最新版本可以从 https://github.com/sofastack/sofa-rpc/releases 里找到。\n编写服务端实现 第一步：创建接口\n/** * Quick Start demo interface */ public interface HelloService { String sayHello(String string); } 第二步：创建接口实现\n/** * Quick Start demo implement */ public class HelloServiceImpl implements HelloService { @Override public String sayHello(String string) { System.out.println(\u0026amp;#34;Server receive: \u0026amp;#34; + string); return \u0026amp;#34;hello \u0026amp;#34; + string + \u0026amp;#34; ！\u0026amp;#34;; } } 第三步：编写服务端代码\n/** * Quick Start Server */ public class QuickStartServer { public static void main(String[] args) { ServerConfig serverConfig = new ServerConfig() .setProtocol(\u0026amp;#34;bolt\u0026amp;#34;) // 设置一个协议，默认bolt  .setPort(12200) // 设置一个端口，默认12200  .setDaemon(false); // 非守护线程  ProviderConfig\u0026amp;lt;HelloService\u0026amp;gt; providerConfig = new ProviderConfig\u0026amp;lt;HelloService\u0026amp;gt;() .setInterfaceId(HelloService.class.getName()) // 指定接口  .setRef(new HelloServiceImpl()) // 指定实现  .setServer(serverConfig); // 指定服务端  providerConfig.export(); // 发布服务  } } 编写客户端实现 第一步：拿到服务端接口\n一般服务端会通过jar的形式将接口类提供给客户端。而在本例中，由于服务端和客户端在一个工程所以跳过。\n第二步：编程客户端代码\n/** * Quick Start client */ public class QuickStartClient { public static void main(String[] args) { ConsumerConfig\u0026amp;lt;HelloService\u0026amp;gt; consumerConfig = new ConsumerConfig\u0026amp;lt;HelloService\u0026amp;gt;() .setInterfaceId(HelloService.class.getName()) // 指定接口  .setProtocol(\u0026amp;#34;bolt\u0026amp;#34;) // 指定协议  .setDirectUrl(\u0026amp;#34;bolt://127.0.0.1:12200\u0026amp;#34;); // 指定直连地址  // 生成代理类  HelloService helloService = consumerConfig.refer(); while (true) { System.out.println(helloService.sayHello(\u0026amp;#34;world\u0026amp;#34;)); try { Thread.sleep(2000); } catch (Exception e) { } } } } 运行 分别启动服务端和客户端，观察运行效果。\n服务端将打印：\n Server receive: world\n 客户端将打印：\n hello world ！\n 更多 更多示例请参考：example\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/getting-started-with-rpc/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"192d252b0b36266622284b68d10e9fe4","permalink":"/projects/sofa-rpc/getting-started-with-rpc/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-rpc/getting-started-with-rpc/","summary":"本文档将演示了如何应用 SOFARPC 进行服务的发布和引用。 本例将在本地模拟服务端启动监听一个端口并发布一个服务，客户端引用该服务进行直连调用。 您可以直接","tags":null,"title":"SOFARPC 方式快速入门","type":"projects","url":"/projects/sofa-rpc/getting-started-with-rpc/","wordcount":562},{"author":null,"categories":null,"content":"SOFATracer 集成在 SOFARPC(5.4.0及之后的版本) 后输出链路数据的格式，默认为 JSON 数据格式，具体的字段含义解释如下：\nRPC 客户端 摘要日志（ rpc-client-digest.log）  日志打印时间 TraceId SpanId Span 类型 当前 appName 协议类型(bolt,rest) 服务接口信息 方法名 当前线程名 调用类型(sync,callback,oneway,future) 路由记录(DIRECT,REGISTRY) 目标ip 目标 appName 本机ip 返回码(00=成功/01=业务异常/02=RPC逻辑错误/03=超时失败/04=路由失败) 请求序列化时间(单位ms) 响应反序列化时间(单位ms) 响应大小(单位Byte) 请求大小(单位Byte) 客户端连接耗时(单位ms) 调用总耗时(单位ms) 本地客户端端口 透传的 baggage 数据 (kv 格式)  样例：\n{\u0026amp;#34;timestamp\u0026amp;#34;:\u0026amp;#34;2018-05-20 17:03:20.708\u0026amp;#34;,\u0026amp;#34;tracerId\u0026amp;#34;:\u0026amp;#34;1e27326d1526807000498100185597\u0026amp;#34;,\u0026amp;#34;spanId\u0026amp;#34;:\u0026amp;#34;0\u0026amp;#34;,\u0026amp;#34;span.kind\u0026amp;#34;:\u0026amp;#34;client\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;SOFATracerRPC\u0026amp;#34;,\u0026amp;#34;protocol\u0026amp;#34;:\u0026amp;#34;bolt\u0026amp;#34;,\u0026amp;#34;service\u0026amp;#34;:\u0026amp;#34;com.alipay.sofa.tracer.examples.sofarpc.direct.DirectService:1.0\u0026amp;#34;,\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;sayDirect\u0026amp;#34;,\u0026amp;#34;current.thread.name\u0026amp;#34;:\u0026amp;#34;main\u0026amp;#34;,\u0026amp;#34;invoke.type\u0026amp;#34;:\u0026amp;#34;sync\u0026amp;#34;,\u0026amp;#34;router.record\u0026amp;#34;:\u0026amp;#34;DIRECT\u0026amp;#34;,\u0026amp;#34;remote.app\u0026amp;#34;:\u0026amp;#34;samples\u0026amp;#34;,\u0026amp;#34;remote.ip\u0026amp;#34;:\u0026amp;#34;127.0.0.1:12200\u0026amp;#34;,\u0026amp;#34;local.client.ip\u0026amp;#34;:\u0026amp;#34;127.0.0.1\u0026amp;#34;,\u0026amp;#34;result.code\u0026amp;#34;:\u0026amp;#34;00\u0026amp;#34;,\u0026amp;#34;req.serialize.time\u0026amp;#34;:\u0026amp;#34;33\u0026amp;#34;,\u0026amp;#34;resp.deserialize.time\u0026amp;#34;:\u0026amp;#34;39\u0026amp;#34;,\u0026amp;#34;resp.size\u0026amp;#34;:\u0026amp;#34;170\u0026amp;#34;,\u0026amp;#34;req.size\u0026amp;#34;:\u0026amp;#34;582\u0026amp;#34;,\u0026amp;#34;client.conn.time\u0026amp;#34;:\u0026amp;#34;0\u0026amp;#34;,\u0026amp;#34;client.elapse.time\u0026amp;#34;:\u0026amp;#34;155\u0026amp;#34;,\u0026amp;#34;local.client.port\u0026amp;#34;:\u0026amp;#34;59774\u0026amp;#34;,\u0026amp;#34;baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;} RPC 服务端 摘要日志（ rpc-server-digest.log）  日志打印时间 TraceId SpanId Span 类型 服务接口信息 方法名 来源ip 来源 appName 协议(bolt,rest) 当前 appName 当前线程名 返回码(00=成功/01=业务异常/02=RPC逻辑错误) 服务端线程池等待时间(单位ms) 业务处理耗时(单位ms) 响应序列化时间(单位ms) 请求反序列化时间(单位ms) 响应大小(单位Byte) 请求大小(单位Byte) 透传的 baggage 数据 (kv 格式)  样例：\n{\u0026amp;#34;timestamp\u0026amp;#34;:\u0026amp;#34;2018-05-20 17:00:53.312\u0026amp;#34;,\u0026amp;#34;tracerId\u0026amp;#34;:\u0026amp;#34;1e27326d1526806853032100185011\u0026amp;#34;,\u0026amp;#34;spanId\u0026amp;#34;:\u0026amp;#34;0\u0026amp;#34;,\u0026amp;#34;span.kind\u0026amp;#34;:\u0026amp;#34;server\u0026amp;#34;,\u0026amp;#34;service\u0026amp;#34;:\u0026amp;#34;com.alipay.sofa.tracer.examples.sofarpc.direct.DirectService:1.0\u0026amp;#34;,\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;sayDirect\u0026amp;#34;,\u0026amp;#34;remote.ip\u0026amp;#34;:\u0026amp;#34;127.0.0.1\u0026amp;#34;,\u0026amp;#34;remote.app\u0026amp;#34;:\u0026amp;#34;SOFATracerRPC\u0026amp;#34;,\u0026amp;#34;protocol\u0026amp;#34;:\u0026amp;#34;bolt\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;SOFATracerRPC\u0026amp;#34;,\u0026amp;#34;current.thread.name\u0026amp;#34;:\u0026amp;#34;SOFA-BOLT-BIZ-12200-5-T1\u0026amp;#34;,\u0026amp;#34;result.code\u0026amp;#34;:\u0026amp;#34;00\u0026amp;#34;,\u0026amp;#34;server.pool.wait.time\u0026amp;#34;:\u0026amp;#34;3\u0026amp;#34;,\u0026amp;#34;biz.impl.time\u0026amp;#34;:\u0026amp;#34;0\u0026amp;#34;,\u0026amp;#34;resp.serialize.time\u0026amp;#34;:\u0026amp;#34;4\u0026amp;#34;,\u0026amp;#34;req.deserialize.time\u0026amp;#34;:\u0026amp;#34;38\u0026amp;#34;,\u0026amp;#34;resp.size\u0026amp;#34;:\u0026amp;#34;170\u0026amp;#34;,\u0026amp;#34;req.size\u0026amp;#34;:\u0026amp;#34;582\u0026amp;#34;,\u0026amp;#34;baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;} RPC 客户端 统计日志（ rpc-client-stat.log）  日志打印时间 日志关键key 方法信息 客户端 appName 服务接口信息 调用次数 总耗时(单位ms) 调用结果(Y/N)  样例：\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2018-05-18 07:02:19.717\u0026amp;#34;,\u0026amp;#34;stat.key\u0026amp;#34;:{\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;method\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;client\u0026amp;#34;,\u0026amp;#34;service\u0026amp;#34;:\u0026amp;#34;app.service:1.0\u0026amp;#34;},\u0026amp;#34;count\u0026amp;#34;:10,\u0026amp;#34;total.cost.milliseconds\u0026amp;#34;:17,\u0026amp;#34;success\u0026amp;#34;:\u0026amp;#34;Y\u0026amp;#34;} RPC 服务端 统计日志（ rpc-server-stat.log）  日志打印时间 日志关键key 方法信息 客户端 appName 服务接口信息 调用次数 总耗时(单位ms) 调用结果(Y/N)  样 …","date":-62135596800,"description":"","dir":"projects/sofa-tracer/log-format-sofarpc/","fuzzywordcount":800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"ad45177e2719b9a22f4bfb07a0481905","permalink":"/projects/sofa-tracer/log-format-sofarpc/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-tracer/log-format-sofarpc/","summary":"SOFATracer 集成在 SOFARPC(5.4.0及之后的版本) 后输出链路数据的格式，默认为 JSON 数据格式，具体的字段含义解释如下： RPC 客户端 摘要日志（ rpc-c","tags":null,"title":"SOFARPC 日志","type":"projects","url":"/projects/sofa-tracer/log-format-sofarpc/","wordcount":705},{"author":null,"categories":null,"content":"","date":-62135596800,"description":"本指南为 SOFAStack 多个组件的 Demo 合集。","dir":"guides/sofastack-demos/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"6a1fada81ea88116efa0e30539da60a1","permalink":"/guides/sofastack-demos/","publishdate":"0001-01-01T00:00:00Z","readingtime":0,"relpermalink":"/guides/sofastack-demos/","summary":"","tags":null,"title":"SOFAStack Demos","type":"guides","url":"/guides/sofastack-demos/","wordcount":0},{"author":null,"categories":null,"content":"Since SOFARPC 5.4.0, the SOFATracer function is integrated, which is enabled by default. It can output the data information in the link.\nBy default, the output data is in JSON format. The involved fields are as follows:\nRPC client digest Log (rpc-client-digest.log)  Log printing time TraceId SpanId Span type Current appName Protocol type Service interface information Method name Current thread name Calling type Routing record Target IP Local machine IP Return code Request serialization duration Response deserialization duration Response size (in Byte) Request size (in Byte) Client connection duration Total duration for call Local client port Transparently transmitted baggage data (kv format)  Example:\n{\u0026amp;quot;timestamp\u0026amp;quot;:\u0026amp;quot;2018-05-20 17:03:20.708\u0026amp;quot;,\u0026amp;quot;tracerId\u0026amp;quot;:\u0026amp;quot;1e27326d1526807000498100185597\u0026amp;quot;,\u0026amp;quot;spanId\u0026amp;quot;:\u0026amp;quot;0\u0026amp;quot;,\u0026amp;quot;span.kind\u0026amp;quot;:\u0026amp;quot;client\u0026amp;quot;,\u0026amp;quot;local.app\u0026amp;quot;:\u0026amp;quot;SOFATracerRPC\u0026amp;quot;,\u0026amp;quot;protocol\u0026amp;quot;:\u0026amp;quot;bolt\u0026amp;quot;,\u0026amp;quot;service\u0026amp;quot;:\u0026amp;quot;com.alipay.sofa.tracer.examples.sofarpc.direct.DirectService:1.0\u0026amp;quot;,\u0026amp;quot;method\u0026amp;quot;:\u0026amp;quot;sayDirect\u0026amp;quot;,\u0026amp;quot;current.thread.name\u0026amp;quot;:\u0026amp;quot;main\u0026amp;quot;,\u0026amp;quot;invoke.type\u0026amp;quot;:\u0026amp;quot;sync\u0026amp;quot;,\u0026amp;quot;router.record\u0026amp;quot;:\u0026amp;quot;DIRECT\u0026amp;quot;,\u0026amp;quot;remote.ip\u0026amp;quot;:\u0026amp;quot;127.0.0.1:12200\u0026amp;quot;,\u0026amp;quot;local.client.ip\u0026amp;quot;:\u0026amp;quot;127.0.0.1\u0026amp;quot;,\u0026amp;quot;result.code\u0026amp;quot;:\u0026amp;quot;00\u0026amp;quot;,\u0026amp;quot;req.serialize.time\u0026amp;quot;:\u0026amp;quot;33\u0026amp;quot;,\u0026amp;quot;resp.deserialize.time\u0026amp;quot;:\u0026amp;quot;39\u0026amp;quot;,\u0026amp;quot;resp.size\u0026amp;quot;:\u0026amp;quot;170\u0026amp;quot;,\u0026amp;quot;req.size\u0026amp;quot;:\u0026amp;quot;582\u0026amp;quot;,\u0026amp;quot;client.conn.time\u0026amp;quot;:\u0026amp;quot;0\u0026amp;quot;,\u0026amp;quot;client.elapse.time\u0026amp;quot;:\u0026amp;quot;155\u0026amp;quot;,\u0026amp;quot;local.client.port\u0026amp;quot;:\u0026amp;quot;59774\u0026amp;quot;,\u0026amp;quot;baggage\u0026amp;quot;:\u0026amp;quot;\u0026amp;quot;} RPC server digest log (rpc-server-digest.log)  Log printing time TraceId SpanId Span type Service interface information Method name Source IP Source appName Protocol Local appName Current thread name Return code Server thread pool waiting time Business processing duration Response serialization duration Request deserialization duration Response size (in Byte) Request size (in Byte) Transparently transmitted baggage data (kv format)  Example:\n{\u0026amp;quot;timestamp\u0026amp;quot;:\u0026amp;quot;2018-05-20 …","date":-62135596800,"description":"","dir":"projects/sofa-rpc/sofatracer-usage/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"dde9dc7a759b7c0c272d67bac1b315d4","permalink":"/en/projects/sofa-rpc/sofatracer-usage/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-rpc/sofatracer-usage/","summary":"Since SOFARPC 5.4.0, the SOFATracer function is integrated, which is enabled by default. It can output the data information in the link.\nBy default, the output data is in JSON format. The involved fields are as follows:\nRPC client digest Log (rpc-client-digest.log)  Log printing time TraceId SpanId Span type Current appName Protocol type Service interface information Method name Current thread name Calling type Routing record Target IP Local machine IP Return code Request serialization duration Response deserialization duration Response size (in Byte) Request size (in Byte) Client connection duration Total duration for call Local client port Transparently transmitted baggage data (kv format)  Example:","tags":null,"title":"SOFATracer","type":"projects","url":"/en/projects/sofa-rpc/sofatracer-usage/","wordcount":222},{"author":null,"categories":null,"content":"SOFATracer configuration item After introducing SOFATracer, you can add related configuration items in Spring Boot configuration file application.properties to customize the behaviors of SOFATracer.\nFor SOFATracer log output directory, you can configure logging.path in application.properties, then the log output path is ${logging.path}/tracelog; if logging.path is not configured, the default output path is ${user.home}/logs/tracelog.\n   Configuration item Description Default value     logging.path log output directory SOFATracer output logs to logging.path directory in priority; If the directory is not configured, log will be output to ${user.home} by default.   com.alipay.sofa.tracer.disableDigestLog Disable all integrated SOFATracer summary log printing false   com.alipay.sofa.tracer.disableConfiguration[${logType}] Disable specific SOFATracer summary log printing of ${logType}. ${logType} indicates the log type, such as spring-mvc-digest.log false   com.alipay.sofa.tracer.tracerGlobalRollingPolicy SOFATracer log rolling policy yyyy-MM-dd：roll by day；yyyy-MM-dd_HH：roll by hour;Logs are not rolled by day by default.   com.alipay.sofa.tracer.tracerGlobalLogReserveDay Retention days of SOFATracer logs Retained for 7 days by default.   com.alipay.sofa.tracer.statLogInterval Time interval of statistical logs, unit: second Output statistical logs once every 60 seconds by default   com.alipay.sofa.tracer.baggageMaxLength Maximum length for retaining penetration data Default: 1024   com.alipay.sofa.tracer.zipkin.enabled Whether to enable SOFATracer remote data reporting to Zipkin true: enable; false: disable. Disabled by default.   com.alipay.sofa.tracer.zipkin.baseUrl The address Zipkin address to which SOFATracer remotely reports data, which works only in the case of com.alipay.sofa.tracer.zipkin.enabled=true Format: http: //${host}:${port}   com.alipay.sofa.tracer.springmvc.filterOrder Order validated by SOFATrace Filter intergrated in SpringMVC -2147483647(org.springframework.core.Ordered#HIGHEST_PRECEDENCE + 1)   com.alipay.sofa.tracer.springmvc.urlPatterns URL Pattern paths validated by SOFATrace Filter intergrated in SpringMVC /*: All validated    ","date":-62135596800,"description":"","dir":"projects/sofa-tracer/configuration/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"1a6bf2b7aa168440544f8d0d69358869","permalink":"/en/projects/sofa-tracer/configuration/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-tracer/configuration/","summary":"SOFATracer configuration item After introducing SOFATracer, you can add related configuration items in Spring Boot configuration file application.properties to customize the behaviors of SOFATracer.\nFor SOFATracer log output directory, you can configure logging.path in application.properties, then the log output path is ${logging.path}/tracelog; if logging.path is not configured, the default output path is ${user.home}/logs/tracelog.\n   Configuration item Description Default value     logging.path log output directory SOFATracer output logs to logging.","tags":null,"title":"SOFATracer configuration items","type":"projects","url":"/en/projects/sofa-tracer/configuration/","wordcount":231},{"author":null,"categories":null,"content":"SOFATracer Tools Get Span through SOFATracer context In the process of a distributed link call, the component that integrates SOFATracer generates a Span and caches it in the SOFATracer context. And the context is cached in ThreadLocal. You can get the current SOFATracer context in the following way:\nSofaTraceContext sofaTraceContext = SofaTraceContextHolder.getSofaTraceContext(); Through the SOFATracer context SofaTraceContext, you can add, delete, modify, check, and empty the cached Spans. As the developers responsible for integrating components, we will add, delete, modify and check the SOFATracer context to integrate distributed link tracking. However, as the application developer to directly use SOFATracer, you only need to get the corresponding Span. That is to say, you only need to use the following method after getting the context:\nSofaTracerSpan sofaTracerSpan = sofaTraceContext.getCurrentSpan(); Get information through Span When using the SOFATracer plugin component, such as Spring MVC, the component integrates the capabilities of SOFATracer. So it can get all the information in the Span after getting Span. The specific acquisition method example (it demands that Span is not empty, namely that the corresponding component has integrated SOFATracer) is as follow:\nGet TraceId and SpanId: SofaTracerSpanContext sofaTracerSpanContext = currentSpan.getSofaTracerSpanContext(); String traceId = sofaTracerSpanContext.getTraceId(); String spanId = sofaTracerSpanContext.getSpanId(); Get Tags and Logs in OpenTracing specification Get Tags:\nMap\u0026amp;lt;String, String\u0026amp;gt; tagsStr = sofaTracerSpan.getTagsWithStr(); Map\u0026amp;lt;String, Boolean\u0026amp;gt; tagsBool = sofaTracerSpan.getTagsWithBool(); Map\u0026amp;lt;String, Number\u0026amp;gt; tagsNumber = sofaTracerSpan.getTagsWithNumber(); Get Logs:\nList \u0026amp;lt;LogData\u0026amp;gt; logDataList = sofaTracerSpan.getLogs (); Process transparently transmitted data Baggage element is a collection of key-value pairs that carries data to be transparently transmitted. In SOFATracer, Baggage data is divided into sysBaggage and bizBaggage; sysBaggage mainly refers to transparently transmitted system data, and bizBaggage mainly refers to transparently transmitted business data.\nConfigure and get BaggageItem BaggageItem is a data element in the Baggage collection.\n Configure the corresponding BaggageItem data through the standard interface:  String baggageKey = \u0026amp;#34;key\u0026amp;#34;; String baggageVal = \u0026amp;#34;val\u0026amp;#34;; sofaTracerSpan.setBaggageItem(baggageKey,baggageVal); Get the corresponding BaggageItem data through the standard interface:  String baggageKey = \u0026amp;#34;key\u0026amp;#34;; String baggageValue = sofaTracerSpan.getBaggageItem(baggageKey); Note: Configuring and getting Baggage data through the standard interface is actually operated on bizBaggage.\nConfigure and get \u0026amp;lsquo;Baggage\u0026amp;rsquo; data 1, Configure \u0026amp;lsquo;Baggage\u0026amp;rsquo; data\nSofaTracerSpanContext sofaTracerSpanContext = sofaTracerSpan.getSofaTracerSpanContext(); Map\u0026amp;lt;String, String\u0026amp;gt; bizBaggage = new …","date":-62135596800,"description":"","dir":"projects/sofa-tracer/utils/","fuzzywordcount":500,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"d40318a5bd3ee5e1573f8770ea649dba","permalink":"/en/projects/sofa-tracer/utils/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/en/projects/sofa-tracer/utils/","summary":"SOFATracer Tools Get Span through SOFATracer context In the process of a distributed link call, the component that integrates SOFATracer generates a Span and caches it in the SOFATracer context. And the context is cached in ThreadLocal. You can get the current SOFATracer context in the following way:\nSofaTraceContext sofaTraceContext = SofaTraceContextHolder.getSofaTraceContext(); Through the SOFATracer context SofaTraceContext, you can add, delete, modify, check, and empty the cached Spans. As the developers responsible for integrating components, we will add, delete, modify and check the SOFATracer context to integrate distributed link tracking.","tags":null,"title":"SOFATracer Tools","type":"projects","url":"/en/projects/sofa-tracer/utils/","wordcount":443},{"author":null,"categories":null,"content":"SOFATracer 是蚂蚁金服开发的基于 OpenTracing 规范 的分布式链路跟踪系统，其核心理念就是通过一个全局的 TraceId 将分布在各个服务节点上的同一次请求串联起来。通过统一的 TraceId 将调用链路中的各种网络调用情况以日志的方式记录下来同时也提供远程汇报到 Zipkin 进行展示的能力，以此达到透视化网络调用的目的。\n功能描述 基于 OpenTracing 规范提供分布式链路跟踪解决方案 基于 OpenTracing 规范 并扩展其能力提供链路跟踪的解决方案。各个框架或者组件可以基于此实现，通过在各个组件中埋点的方式来提供链路跟踪的能力。\n提供异步落地磁盘的日志打印能力 基于 Disruptor 高性能无锁循环队列，提供异步打印日志到本地磁盘的能力。框架或者组件能够在接入时，在异步日志打印的前提下可以自定义日志文件的输出格式。SOFATracer 提供两种类似的日志打印类型即摘要日志和统计日志，摘要日志：每一次调用均会落地磁盘的日志；统计日志：每隔一定时间间隔进行统计输出的日志。\n支持日志自清除和滚动能力 异步落地磁盘的 SOFATracer 日志支持自清除和滚动能力，支持按照按照天清除和按照小时或者天滚动的能力\n基于 SLF4J MDC 的扩展能力 SLF4J 提供了 MDC（Mapped Diagnostic Contexts）功能，可以支持用户定义和修改日志的输出格式以及内容。SOFATracer 集成了 SLF4J MDC 功能，方便用户在只简单修改日志配置文件即可输出当前 Tracer 上下文的 TraceId 和 SpanId。\n界面展示能力 SOFATracer 可以将链路跟踪数据远程上报到开源产品 Zipkin 做分布式链路跟踪的展示。\n统一配置能力 配置文件中提供丰富的配置能力以定制化应用的个性需求。\n应用场景 解决在实施大规模微服务架构时的链路跟踪问题，达到透视化网络调用的目的，并可用于故障的快速发现，服务治理等。\n组件埋点 目前 SOFATracer 支持 Spring MVC、标准 JDBC 接口实现的数据库连接池(DBCP、Druid、c3p0、tomcat、HikariCP、BoneCP)、HttpClient、Dubbo、Spring Cloud OpenFeign 等开源组件，其他开源组件（如 MQ、Redis）埋点支持在开发中。\n   支持组件 接入文档 支持版本     Spring MVC doc link 2.1.0   DBCP doc link 2.2.0   Druid doc link 2.2.0   c3p0 doc link 2.2.0   HikariCP doc link 2.2.0   HttpClient doc link 2.2.0   OkHttp doc link 2.3.2   Dubbo doc link 2.4.0   Redis TODO    MQ TODO     ","date":-62135596800,"description":"","dir":"projects/sofa-tracer/overview/","fuzzywordcount":900,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"e8d6bf5eec6c5ce1e41d461743f2c4f1","permalink":"/projects/sofa-tracer/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-tracer/overview/","summary":"SOFATracer 是蚂蚁金服开发的基于 OpenTracing 规范 的分布式链路跟踪系统，其核心理念就是通过一个全局的 TraceId 将分布在各个服务节点上的同一次请求串联起来。通过统一的 TraceId 将调","tags":null,"title":"SOFATracer 介绍","type":"projects","url":"/projects/sofa-tracer/overview/","wordcount":843},{"author":null,"categories":null,"content":"通过 SOFATracer 上下文获取 Span 在一次分布式链路调用过程中，在集成了 SOFATracer 的组件会产生一个 Span 并会缓存到 SOFATracer 的上下文中，这个上下文是缓存在 ThreadLocal 中的，作为使用者可以通过如下的方式随时获取到当前 SOFATracer 的上下文：\nSofaTraceContext sofaTraceContext = SofaTraceContextHolder.getSofaTraceContext(); SOFATracer 上下文 SofaTraceContext 通过这个实例，可以对其缓存的 Span 执行增、删、改、查和清空操作。作为组件集成的同学在集成过程中我们会对 SOFATracer 上下文做增、删、改和查等操作来集成分布式链路跟踪的能力；但是作为直接使用 SOFATracer 的应用开发者，我们只需要能够获取相应的 Span 即可，即只需要在获取上下文后使用如下的方法：\nSofaTracerSpan sofaTracerSpan = sofaTraceContext.getCurrentSpan(); 通过 Span 获取信息 在使用相应的组件如 Spring MVC 时，该组件集成了 SOFATracer 的能力后可以在获取到 Span 后获取到 Span 中的所有信息，具体获取方式示例（前提 Span 不为空即相应组件已经集成 SOFATracer）：\n获取 TraceId 和 SpanId ： SofaTracerSpanContext sofaTracerSpanContext = currentSpan.getSofaTracerSpanContext(); String traceId = sofaTracerSpanContext.getTraceId(); String spanId = sofaTracerSpanContext.getSpanId(); 获取 OpenTracing 规范中的 Tags 和 Logs 获取 Tags:\nMap\u0026amp;lt;String, String\u0026amp;gt; tagsStr = sofaTracerSpan.getTagsWithStr(); Map\u0026amp;lt;String, Boolean\u0026amp;gt; tagsBool = sofaTracerSpan.getTagsWithBool(); Map\u0026amp;lt;String, Number\u0026amp;gt; tagsNumber = sofaTracerSpan.getTagsWithNumber(); 获取 Logs:\nList\u0026amp;lt;LogData\u0026amp;gt; logDataList = sofaTracerSpan.getLogs(); 透传数据处理 Baggage 元素是一个键值对集合，其携带的是需要透传的数据。SOFATracer 中将 Baggage 数据分为 sysBaggage 和 bizBaggage；sysBaggage 主要是指系统维度的透传数据，bizBaggage 主要是指业务的透传数据。\n设置和获取 BaggageItem BaggageItem 是 Baggage集合中的数据元素。\n1、通过标准接口设置相应的 BaggageItem 数据：\nString baggageKey = \u0026amp;#34;key\u0026amp;#34;; String baggageVal = \u0026amp;#34;val\u0026amp;#34;; sofaTracerSpan.setBaggageItem(baggageKey,baggageVal); 2、通过标准接口获取相应的 BaggageItem 数据：\nString baggageKey = \u0026amp;#34;key\u0026amp;#34;; String baggageValue = sofaTracerSpan.getBaggageItem(baggageKey); 注：当通过标准接口进行设置和获取 Baggage 数据时，实际上操作的对象均为 bizBaggage\n设置和获取 \u0026amp;lsquo;Baggage\u0026amp;rsquo; 数据 1、设置 \u0026amp;lsquo;Baggage\u0026amp;rsquo; 数据\nSofaTracerSpanContext sofaTracerSpanContext = sofaTracerSpan.getSofaTracerSpanContext(); Map\u0026amp;lt;String, String\u0026amp;gt; bizBaggage = new HashMap\u0026amp;lt;String, String\u0026amp;gt;(); bizBaggage.put(\u0026amp;#34;bizKey\u0026amp;#34;,\u0026amp;#34;bizVal\u0026amp;#34;); sofaTracerSpanContext.addBizBaggage(bizBaggage); Map\u0026amp;lt;String, String\u0026amp;gt; sysBaggage = new HashMap\u0026amp;lt;String, String\u0026amp;gt;(); sysBaggage.put(\u0026amp;#34;sysKey\u0026amp;#34;,\u0026amp;#34;sysVal\u0026amp;#34;); sofaTracerSpanContext.addSysBaggage(sysBaggage); 2、获取 \u0026amp;lsquo;Baggage\u0026amp;rsquo; 数据\nSofaTracerSpanContext sofaTracerSpanContext = sofaTracerSpan.getSofaTracerSpanContext(); //获取 bizBaggage Map\u0026amp;lt;String, String\u0026amp;gt; bizBaggages = sofaTracerSpanContext.getBizBaggage(); //获取 sysBaggage Map\u0026amp;lt;String, String\u0026amp;gt; sysBaggages = sofaTracerSpanContext.getSysBaggage(); 遍历 Baggage 数据 OpenTracing 规范中 SpanContext 接口提供了 baggageItems() 方法，可以通过这个方法来遍历所有的 baggage 元素。SOFATracer 在 SofaTracerSpanContext 类中对 baggageItems() 方法进行了具体实现。\nIterable\u0026amp;lt;Map.Entry\u0026amp;lt;String, String\u0026amp;gt;\u0026amp;gt; entrySet = sofaTracerSpanContext.baggageItems(); 注：遍历 Baggage 数据返回的是 sysBaggage 和 bizBaggage 的合集。\n","date":-62135596800,"description":"","dir":"projects/sofa-tracer/utils/","fuzzywordcount":800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"d40318a5bd3ee5e1573f8770ea649dba","permalink":"/projects/sofa-tracer/utils/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-tracer/utils/","summary":"通过 SOFATracer 上下文获取 Span 在一次分布式链路调用过程中，在集成了 SOFATracer 的组件会产生一个 Span 并会缓存到 SOFATracer 的上下文中，这个上下文是缓存在 ThreadLocal 中的，作为使用者可以通","tags":null,"title":"SOFATracer 工具类","type":"projects","url":"/projects/sofa-tracer/utils/","wordcount":738},{"author":null,"categories":null,"content":"应用在引入 SOFATracer 后，可以在 Spring Boot 的配置文件 application.properties 中添加相关配置项来定制 SOFATracer 的相关行为。\nSOFATracer 的日志输出目录，可以在 application.properties 中配置 logging.path 的路径，那么其日志输出路径为 ${logging.path}/tracelog；如果没有配置 logging.path，那么 SOFATracer 的默认输出路径为 ${user.home}/logs/tracelog。\nSpringBoot 工程配置    SOFATracer 配置项 说明 默认值     logging.path 日志输出目录 SOFATracer 会优先输出到 logging.path 目录下；如果没有配置日志输出目录，那默认输出到 ${user.home}   com.alipay.sofa.tracer.disableDigestLog 是否关闭所有集成 SOFATracer 组件摘要日志打印 false   com.alipay.sofa.tracer.disableConfiguration[${logType}] 关闭指定 ${logType} 的 SOFATracer 组件摘要日志打印。${logType} 是指具体的日志类型，如：spring-mvc-digest.log false   com.alipay.sofa.tracer.tracerGlobalRollingPolicy SOFATracer 日志的滚动策略 .yyyy-MM-dd：按照天滚动；.yyyy-MM-dd_HH：按照小时滚动。默认不配置按照天滚动   com.alipay.sofa.tracer.tracerGlobalLogReserveDay SOFATracer 日志的保留天数 默认保留 7 天   com.alipay.sofa.tracer.statLogInterval 统计日志的时间间隔，单位：秒 默认 60 秒统计日志输出一次   com.alipay.sofa.tracer.baggageMaxLength 透传数据能够允许存放的最大长度 默认值 1024   com.alipay.sofa.tracer.zipkin.enabled 是否开启 SOFATracer 远程上报数据到 Zipkin true：开启上报；false：关闭上报。默认不上报   com.alipay.sofa.tracer.zipkin.baseUrl SOFATracer 远程上报数据到 Zipkin 的地址，com.alipay.sofa.tracer.zipkin.enabled=true时配置此地址才有意义 格式：http://${host}:${port}   com.alipay.sofa.tracer.springmvc.filterOrder SOFATracer 集成在 SpringMVC 的 Filter 生效的 Order -2147483647（org.springframework.core.Ordered#HIGHEST_PRECEDENCE + 1）   com.alipay.sofa.tracer.springmvc.urlPatterns SOFATracer 集成在 SpringMVC 的 Filter 生效的 URL Pattern 路径 /* 全部生效   com.alipay.sofa.tracer.jsonOutput 是否以json格式输出日志 true，如果期望较少日志空间占用，可以使用非 json 格式输出（日志顺序与JSON 格式顺序一致）    非SpringBoot 工程配置 在非 SpringBoot 工程中，可以通过在 classpath 下新建一个 sofa.tracer.properties 配置文件，配置项如下：\n   SOFATracer 配置项 说明 默认值     disable_middleware_digest_log 是否关闭中间件组件摘要日志打印 false   disable_digest_log 关闭摘要日志打印。 false   tracer_global_rolling_policy SOFATracer 日志的滚动策略 .yyyy-MM-dd：按照天滚动；.yyyy-MM-dd_HH：按照小时滚动。默认不配置按照天滚动   tracer_global_log_reserve_day SOFATracer 日志的保留天数 默认保留 7 天   stat_log_interval 统计日志的时间间隔，单位：秒 默认 60 秒统计日志输出一次   tracer_penetrate_attribute_max_length 透传数据能够允许存放的最大长度 默认值 1024   tracer_async_appender_allow_discard 是否允许丢失日志 false   tracer_async_appender_is_out_discard_number 丢失日志数 0   spring.application.name 应用名 ``   tracer_sampler_strategy_name_key 采样策略名 ``   tracer_sampler_strategy_custom_rule_class_name 采样规则 spi 实现的类的全限定名 ``   tracer_sampler_strategy_percentage_key 采样比率    com.alipay.sofa.tracer.jsonOutput 是否以json格式输出日志 true，如果期望较少日志空间占用，可以使用非 json 格式输出（日志顺序与JSON 格式顺序一致）    ","date":-62135596800,"description":"","dir":"projects/sofa-tracer/configuration/","fuzzywordcount":1100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"1a6bf2b7aa168440544f8d0d69358869","permalink":"/projects/sofa-tracer/configuration/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/sofa-tracer/configuration/","summary":"应用在引入 SOFATracer 后，可以在 Spring Boot 的配置文件 application.properties 中添加相关配置项来定制 SOFATracer 的相关行为。 SOFATracer 的日志输出目录，可以在 application.properties 中配置 logging.path 的路径，那么其日志输出路径为 ${","tags":null,"title":"SOFATracer 配置项","type":"projects","url":"/projects/sofa-tracer/configuration/","wordcount":1004},{"author":null,"categories":null,"content":"在SOFARPC(5.4.0及之后的版本) 后的版本中，我们集成了SOFATracer的功能，默认开启，可以输出链路中的数据信息。\n默认为 JSON 数据格式，具体的字段含义解释如下：\nRPC 客户端 摘要日志（ rpc-client-digest.log）  日志打印时间 TraceId SpanId Span 类型 当前 appName 协议类型 服务接口信息 方法名 当前线程名 调用类型 路由记录 目标ip 本机ip 返回码 请求序列化时间 响应反序列化时间 响应大小(单位Byte) 请求大小(单位Byte) 客户端连接耗时 调用总耗时 本地客户端端口 透传的 baggage 数据 (kv 格式)  样例：\n{\u0026amp;quot;timestamp\u0026amp;quot;:\u0026amp;quot;2018-05-20 17:03:20.708\u0026amp;quot;,\u0026amp;quot;tracerId\u0026amp;quot;:\u0026amp;quot;1e27326d1526807000498100185597\u0026amp;quot;,\u0026amp;quot;spanId\u0026amp;quot;:\u0026amp;quot;0\u0026amp;quot;,\u0026amp;quot;span.kind\u0026amp;quot;:\u0026amp;quot;client\u0026amp;quot;,\u0026amp;quot;local.app\u0026amp;quot;:\u0026amp;quot;SOFATracerRPC\u0026amp;quot;,\u0026amp;quot;protocol\u0026amp;quot;:\u0026amp;quot;bolt\u0026amp;quot;,\u0026amp;quot;service\u0026amp;quot;:\u0026amp;quot;com.alipay.sofa.tracer.examples.sofarpc.direct.DirectService:1.0\u0026amp;quot;,\u0026amp;quot;method\u0026amp;quot;:\u0026amp;quot;sayDirect\u0026amp;quot;,\u0026amp;quot;current.thread.name\u0026amp;quot;:\u0026amp;quot;main\u0026amp;quot;,\u0026amp;quot;invoke.type\u0026amp;quot;:\u0026amp;quot;sync\u0026amp;quot;,\u0026amp;quot;router.record\u0026amp;quot;:\u0026amp;quot;DIRECT\u0026amp;quot;,\u0026amp;quot;remote.ip\u0026amp;quot;:\u0026amp;quot;127.0.0.1:12200\u0026amp;quot;,\u0026amp;quot;local.client.ip\u0026amp;quot;:\u0026amp;quot;127.0.0.1\u0026amp;quot;,\u0026amp;quot;result.code\u0026amp;quot;:\u0026amp;quot;00\u0026amp;quot;,\u0026amp;quot;req.serialize.time\u0026amp;quot;:\u0026amp;quot;33\u0026amp;quot;,\u0026amp;quot;resp.deserialize.time\u0026amp;quot;:\u0026amp;quot;39\u0026amp;quot;,\u0026amp;quot;resp.size\u0026amp;quot;:\u0026amp;quot;170\u0026amp;quot;,\u0026amp;quot;req.size\u0026amp;quot;:\u0026amp;quot;582\u0026amp;quot;,\u0026amp;quot;client.conn.time\u0026amp;quot;:\u0026amp;quot;0\u0026amp;quot;,\u0026amp;quot;client.elapse.time\u0026amp;quot;:\u0026amp;quot;155\u0026amp;quot;,\u0026amp;quot;local.client.port\u0026amp;quot;:\u0026amp;quot;59774\u0026amp;quot;,\u0026amp;quot;baggage\u0026amp;quot;:\u0026amp;quot;\u0026amp;quot;} RPC 服务端 摘要日志（ rpc-server-digest.log）  日志打印时间 TraceId SpanId Span 类型 服务接口信息 方法名 来源ip 来源 appName 协议 本应用 appName 当前线程名 返回码 服务端线程池等待时间 业务处理耗时 响应序列化时间 请求反序列化时间 响应大小(单位Byte) 请求大小(单位Byte) 透传的 baggage 数据 (kv 格式)  样例：\n{\u0026amp;quot;timestamp\u0026amp;quot;:\u0026amp;quot;2018-05-20 17:00:53.312\u0026amp;quot;,\u0026amp;quot;tracerId\u0026amp;quot;:\u0026amp;quot;1e27326d1526806853032100185011\u0026amp;quot;,\u0026amp;quot;spanId\u0026amp;quot;:\u0026amp;quot;0\u0026amp;quot;,\u0026amp;quot;span.kind\u0026amp;quot;:\u0026amp;quot;server\u0026amp;quot;,\u0026amp;quot;service\u0026amp;quot;:\u0026amp;quot;com.alipay.sofa.tracer.examples.sofarpc.direct.DirectService:1.0\u0026amp;quot;,\u0026amp;quot;method\u0026amp;quot;:\u0026amp;quot;sayDirect\u0026amp;quot;,\u0026amp;quot;remote.ip\u0026amp;quot;:\u0026amp;quot;127.0.0.1\u0026amp;quot;,\u0026amp;quot;remote.app\u0026amp;quot;:\u0026amp;quot;SOFATracerRPC\u0026amp;quot;,\u0026amp;quot;protocol\u0026amp;quot;:\u0026amp;quot;bolt\u0026amp;quot;,\u0026amp;quot;local.app\u0026amp;quot;:\u0026amp;quot;SOFATracerRPC\u0026amp;quot;,\u0026amp;quot;current.thread.name\u0026amp;quot;:\u0026amp;quot;SOFA-BOLT-BIZ-12200-5-T1\u0026amp;quot;,\u0026amp;quot;result.code\u0026amp;quot;:\u0026amp;quot;00\u0026amp;quot;,\u0026amp;quot;server.pool.wait.time\u0026amp;quot;:\u0026amp;quot;3\u0026amp;quot;,\u0026amp;quot;biz.impl.time\u0026amp;quot;:\u0026amp;quot;0\u0026amp;quot;,\u0026amp;quot;resp.serialize.time\u0026amp;quot;:\u0026amp;quot;4\u0026amp;quot;,\u0026amp;quot;req.deserialize.time\u0026amp;quot;:\u0026amp;quot;38\u0026amp;quot;,\u0026amp;quot;resp.size\u0026amp;quot;:\u0026amp;quot;170\u0026amp;quot;,\u0026amp;quot;req.size\u0026amp;quot;:\u0026amp;quot;582\u0026amp;quot;,\u0026amp;quot;baggage\u0026amp;quot;:\u0026amp;quot;\u0026amp;quot;,{\u0026amp;quot;timestamp\u0026amp;quot;:\u0026amp;quot;2018-05-20 …","date":-62135596800,"description":"","dir":"projects/sofa-rpc/sofatracer-usage/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"dde9dc7a759b7c0c272d67bac1b315d4","permalink":"/projects/sofa-rpc/sofatracer-usage/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-rpc/sofatracer-usage/","summary":"在SOFARPC(5.4.0及之后的版本) 后的版本中，我们集成了SOFATracer的功能，默认开启，可以输出链路中的数据信息。 默认为 JSON 数据","tags":null,"title":"SOFATracer 链路追踪","type":"projects","url":"/projects/sofa-rpc/sofatracer-usage/","wordcount":529},{"author":null,"categories":null,"content":"SOFATracer is a distributed link tracing system based on OpenTracing specification developed by Ant Financial. Its core concept is to concatenate the same request distributed on each service node with a global TraceId. By the unified TraceId, it can record the various network call information in the call link in logs, and can remotely report the call records to Zipkin for presentation, thus implementing perspective network call.\nFeatures Distributed link tracing solution based on OpenTracing specification SOFATracer is a solution that provides link tracing based on and improved from the OpenTracing specification. Based on this implementation, each framework or component can provide the ability to link tracking by burying points.\nProvide asynchronous log printing to disks Based on high-performance lock-free loop queue of Disruptor, SOFATracer provides the ability to print logs asynchronously to local disk. The introduced framework or component can customize the output format of the log file under the premise of asynchronous log printing. SOFATracer provides two types of logs, digest log and statistical log. Digest log: logs that are printed to disk upon each call. Statistical log: logs that are printed at regular intervals.\nSupport automatic log cleanup and scrolling Asynchronous SOFATracer log supports automatic cleanup and scrolling, and supports cleaning by day and scrolling by hour or day.\nExtended based on SLF4J MDC SLF4J provides MDC (Mapped Diagnostic Contexts), which supports user to define and modify the output log format and content. SOFATracer integrates the SLF4J MDC function, which allows user to output the TraceId and SpanId of the current Tracer context by simply modifying the log configuration file.\nInterface presentation SOFATracer can remotely report link tracing data to the open-source product Zipkin for distributed link tracing presentation.\nUnified configuration The profile file provides various configuration options for you to customize the individual requirements of the application.\nScenario SOFATracer solves the problem of link tracing when implementing large-scale microservice architecture, achieves perspective network call, and can be used to rapidly Failures Discovery, Service Governance, and so on.\nComponent event tracking At present, SOFATracer supports Spring MVC, database connection pool (DBCP, Druid, c3p0, tomcat, HikariCP, BoneCP) acheived by standard JDBC interface, HttpClient and other open-source components. Event tracking for other open-source components (such as MQ, Redis) is still in development.\n   Component Document Version     Spring MVC doc link 2.1.0   DBCP doc link 2.2.0   Druid doc link 2.2.0   C3p0 doc link 2.2.0   HikariCP doc link 2.2.0   HttpClient doc link 2.2.0   RestTemplate doc link 2.3.0   OkHttp doc link 2.3.2   Dubbo doc link 2.4.0   OpenFeign doc link 3.0.4   Redis TODO    MQ TODO     ","date":-62135596800,"description":"","dir":"projects/sofa-tracer/overview/","fuzzywordcount":500,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"e8d6bf5eec6c5ce1e41d461743f2c4f1","permalink":"/en/projects/sofa-tracer/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-tracer/overview/","summary":"SOFATracer is a distributed link tracing system based on OpenTracing specification developed by Ant Financial. Its core concept is to concatenate the same request distributed on each service node with a global TraceId. By the unified TraceId, it can record the various network call information in the call link in logs, and can remotely report the call records to Zipkin for presentation, thus implementing perspective network call.\nFeatures Distributed link tracing solution based on OpenTracing specification SOFATracer is a solution that provides link tracing based on and improved from the OpenTracing specification.","tags":null,"title":"SOFATracker overview","type":"projects","url":"/en/projects/sofa-tracer/overview/","wordcount":421},{"author":null,"categories":null,"content":"SOFABoot 提供了模块并行启动以及 Spring Bean 异步初始化能力，用于加快应用启动速度。本文介绍如何使用 SOFABoot 异步初始化 Spring Bean 能力以提高应用启动速度。\n使用场景 在实际使用 Spring/Spring Boot 开发中，一些 Bean 在初始化过程中执行准备操作，如拉取远程配置、初始化数据源等等。在应用启动期间，这些 Bean 会增加 Spring 上下文刷新时间，导致应用启动耗时变长。\n为了加速应用启动，SOFABoot 通过配置可选项，将 Bean 的初始化方法（init-method）使用单独线程异步执行，加快 Spring 上下文加载过程，提高应用启动速度。\n引入依赖 在工程的 pom.xml 文件中，引入如下 starter：\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;runtime-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 使用方法 异步初始化 Bean 的原理是开启单独线程负责执行 Bean 的初始化方法（init-method）。因此，除了引入上述依赖，还需要在 Bean 的 XML 定义中配置 async-init=\u0026amp;ldquo;true\u0026amp;rdquo; 属性，用于指定是否异步执行该 Bean 的初始化方法，例如：\n\u0026amp;lt;?xml version=\u0026amp;#34;1.0\u0026amp;#34; encoding=\u0026amp;#34;UTF-8\u0026amp;#34;?\u0026amp;gt; \u0026amp;lt;beans xmlns=\u0026amp;#34;http://www.springframework.org/schema/beans\u0026amp;#34; xmlns:xsi=\u0026amp;#34;http://www.w3.org/2001/XMLSchema-instance\u0026amp;#34; xmlns:sofa=\u0026amp;#34;http://sofastack.io/schema/sofaboot\u0026amp;#34; xsi:schemaLocation=\u0026amp;#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://sofastack.io/schema/sofaboot http://sofastack.io/schema/sofaboot.xsd\u0026amp;#34; default-autowire=\u0026amp;#34;byName\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;!-- async init test --\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;#34;testBean\u0026amp;#34; class=\u0026amp;#34;com.alipay.sofa.runtime.beans.TimeWasteBean\u0026amp;#34; init-method=\u0026amp;#34;init\u0026amp;#34; async-init=\u0026amp;#34;true\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/beans\u0026amp;gt; 属性配置 SOFABoot 异步初始化能力提供两个属性配置，用于指定负责异步执行 Bean 初始化方法（init-method）的线程池大小：\n com.alipay.sofa.boot.asyncInitBeanCoreSize：线程池基本大小，默认值为 CPU 核数加一。 com.alipay.sofa.boot.asyncInitBeanMaxSize：线程池中允许的最大线程数大小，默认值为 CPU 核数加一。  此配置可以通过 VM -D 参数或者 Spring Boot 配置文件 application.yml 设置。\n","date":-62135596800,"description":"","dir":"projects/sofa-boot/bean-async-init/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"1b7c2d94076ffb7ac96f64a557067917","permalink":"/projects/sofa-boot/bean-async-init/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-boot/bean-async-init/","summary":"SOFABoot 提供了模块并行启动以及 Spring Bean 异步初始化能力，用于加快应用启动速度。本文介绍如何使用 SOFABoot 异步初始化 Spring Bean 能力以提高应用启动速度。 使用场景 在实际使用","tags":null,"title":"Spring Bean 异步初始化","type":"projects","url":"/projects/sofa-boot/bean-async-init/","wordcount":578},{"author":null,"categories":null,"content":"In this document will demonstrate how to use SOFATracer to track of SpringMVC, this example address.\nAssuming you have built a simple Spring Web project based on SOFABoot, Then you can be operated by the following steps:\nIntroduce dependency \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;tracer-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; Project Configuration Then, add the parameters to be used by SOFATracer in the project\u0026amp;rsquo;s application.properties file, including spring.application.name that indicates the name of the current application and logging.path that specifies the log output directory.\n# Application Name spring.application.name=SOFATracerSpringMVC # logging path logging.path=./logs Add a simple Controller In the project code, add a simple Controller, for example:\n@RestController public class SampleRestController { private static final String TEMPLATE = \u0026amp;#34;Hello, %s!\u0026amp;#34;; private final AtomicLong counter = new AtomicLong(); /** * http://localhost:8080/springmvc * @param name name * @return map */ @RequestMapping(\u0026amp;#34;/springmvc\u0026amp;#34;) public Map\u0026amp;lt;String, Object\u0026amp;gt; springmvc(@RequestParam(value = \u0026amp;#34;name\u0026amp;#34;, defaultValue = \u0026amp;#34;SOFATracer SpringMVC DEMO\u0026amp;#34;) String name) { Map\u0026amp;lt;String, Object\u0026amp;gt; resultMap = new HashMap\u0026amp;lt;String, Object\u0026amp;gt;(); resultMap.put(\u0026amp;#34;success\u0026amp;#34;, true); resultMap.put(\u0026amp;#34;id\u0026amp;#34;, counter.incrementAndGet()); resultMap.put(\u0026amp;#34;content\u0026amp;#34;, String.format(TEMPLATE, name)); return resultMap; } } Run the project Start Current SOFABoot Application. You will see the log about startup in the console:\n2018-05-11 11:55:11.932 INFO 66490 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean : Mapping filter: \u0026#39;SpringMvcOpenTracingFilter\u0026#39; to urls: [/*] 2018-05-11 11:55:13.961 INFO 66490 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http) 2018-05-11 11:55:13.970 INFO 66490 --- [ main] c.a.s.t.e.springmvc.DemoApplication : Started DemoApplication in 8.361 seconds (JVM running for 9.34) You can access the REST service by visiting http://localhost:8080/springmvc in your browser. You can see the result similar to the followings:\n{ content: \u0026amp;#34;Hello, SOFATracer SpringMVC DEMO!\u0026amp;#34;, id: 1, success: true } View log In the application.properties, the log printing directory we configured is ./logs, which is the root directory of the current application (we can configure it based on actual situation). In the root directory, you can see log files in the structure similar to the followings:\n./logs ├── spring.log └── tracelog ├── spring-mvc-digest.log ├── spring-mvc-stat.log ├── static-info.log └── tracer-self.log Every time you visit http://localhost:8080/springmvc, SOFATracer will log the digest log. You can open the spring-mvc-digest.log file to see the specific log content. As for the meaning of each output field, you can refer to here.\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2018-05-17 …","date":-62135596800,"description":"","dir":"projects/sofa-tracer/usage-of-mvc/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"6c6389a6f994f43f08cbdf4a49d1755a","permalink":"/en/projects/sofa-tracer/usage-of-mvc/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-tracer/usage-of-mvc/","summary":"In this document will demonstrate how to use SOFATracer to track of SpringMVC, this example address.\nAssuming you have built a simple Spring Web project based on SOFABoot, Then you can be operated by the following steps:\nIntroduce dependency \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alipay.sofa\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;tracer-sofa-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; Project Configuration Then, add the parameters to be used by SOFATracer in the project\u0026rsquo;s application.properties file, including spring.application.name that indicates the name of the current application and logging.","tags":null,"title":"Spring MVC Integration","type":"projects","url":"/en/projects/sofa-tracer/usage-of-mvc/","wordcount":356},{"author":null,"categories":null,"content":"SpringMVC Log Format After integrating SpringMVC, SOFATracer will output the link data format of the MVC requests, which is JSON by default.\nSpring MVC digest log (spring-mvc-digest.log) Data is ouput in JSON format. The meaning of each key is as follows:\n   Key Meaning     Time Log printing time   Local.app Current application name   traceId TraceId   spanId SpanId   Request.url Request URL   Method Request HTTP method   Result.code HTTP return status code   req.size.bytes Request body size   resp.size.bytes Response body size   Time.cost.milliseconds Request time (ms)   Current.thread.name Current thread name   Baggage Transparently transmitted baggage data    Example:\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2018-06-03 16:44:05.829\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;SpringMvcJsonOutput\u0026amp;#34;,\u0026amp;#34;traceId\u0026amp;#34;:\u0026amp;#34;c0a80d9e1528015445828101064625\u0026amp;#34;,\u0026amp;#34;spanId\u0026amp;#34;:\u0026amp;#34;0\u0026amp;#34;,\u0026amp;#34;request.url\u0026amp;#34;:\u0026amp;#34;http://localhost:63933/greeting\u0026amp;#34;,\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;GET\u0026amp;#34;,\u0026amp;#34;result.code\u0026amp;#34;:\u0026amp;#34;200\u0026amp;#34;,\u0026amp;#34;req.size.bytes\u0026amp;#34;:0,\u0026amp;#34;resp.size.bytes\u0026amp;#34;:50,\u0026amp;#34;time.cost.milliseconds\u0026amp;#34;:1,\u0026amp;#34;current.thread.name\u0026amp;#34;:\u0026amp;#34;http-nio-auto-1-exec-10\u0026amp;#34;,\u0026amp;#34;baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;} Spring MVC statistical log (spring-mvc-stat.log) stat.key is a collection of statistical keywords in this period., which uniquely determines a set of statistical data, including local.app, request.url, and method field.\nExample:\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2018-06-03 16:44:02.473\u0026amp;#34;,\u0026amp;#34;stat.key\u0026amp;#34;:{\u0026amp;#34;request.url\u0026amp;#34;:\u0026amp;#34;http://localhost:63933/greeting\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;SpringMvcJsonOutput\u0026amp;#34;,\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;GET\u0026amp;#34;},\u0026amp;#34;count\u0026amp;#34;:5,\u0026amp;#34;total.cost.milliseconds\u0026amp;#34;:149,\u0026amp;#34;success\u0026amp;#34;:\u0026amp;#34;Y\u0026amp;#34;,\u0026amp;#34;load.test\u0026amp;#34;:\u0026amp;#34;F\u0026amp;#34;} ","date":-62135596800,"description":"","dir":"projects/sofa-tracer/log-format-springmvc/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"af13acf5aee90a32f0fa143996063a91","permalink":"/en/projects/sofa-tracer/log-format-springmvc/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-tracer/log-format-springmvc/","summary":"SpringMVC Log Format After integrating SpringMVC, SOFATracer will output the link data format of the MVC requests, which is JSON by default.\nSpring MVC digest log (spring-mvc-digest.log) Data is ouput in JSON format. The meaning of each key is as follows:\n   Key Meaning     Time Log printing time   Local.app Current application name   traceId TraceId   spanId SpanId   Request.","tags":null,"title":"Spring MVC log","type":"projects","url":"/en/projects/sofa-tracer/log-format-springmvc/","wordcount":123},{"author":null,"categories":null,"content":"在本文档将演示如何使用 SOFATracer 对 SpringMVC 进行埋点，本示例工程地址。\n假设你已经基于 SOFABoot 构建了一个简单的 Spring Web 工程，那么可以通过如下步骤进行操作：\n依赖引入 \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;tracer-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 工程配置 在工程的 application.properties 文件下添加 SOFATracer 要使用的参数，包括spring.application.name 用于标示当前应用的名称；logging.path 用于指定日志的输出目录。\n# Application Name spring.application.name=SOFATracerSpringMVC # logging path logging.path=./logs 添加一个提供 RESTful 服务的 Controller 在工程代码中，添加一个简单的 Controller，例如：\n@RestController public class SampleRestController { private static final String TEMPLATE = \u0026amp;#34;Hello, %s!\u0026amp;#34;; private final AtomicLong counter = new AtomicLong(); /** * http://localhost:8080/springmvc * @param name name * @return map */ @RequestMapping(\u0026amp;#34;/springmvc\u0026amp;#34;) public Map\u0026amp;lt;String, Object\u0026amp;gt; springmvc(@RequestParam(value = \u0026amp;#34;name\u0026amp;#34;, defaultValue = \u0026amp;#34;SOFATracer SpringMVC DEMO\u0026amp;#34;) String name) { Map\u0026amp;lt;String, Object\u0026amp;gt; resultMap = new HashMap\u0026amp;lt;String, Object\u0026amp;gt;(); resultMap.put(\u0026amp;#34;success\u0026amp;#34;, true); resultMap.put(\u0026amp;#34;id\u0026amp;#34;, counter.incrementAndGet()); resultMap.put(\u0026amp;#34;content\u0026amp;#34;, String.format(TEMPLATE, name)); return resultMap; } } 运行 启动 SOFABoot 应用，将会在控制台中看到启动打印的日志：\n2018-05-11 11:55:11.932 INFO 66490 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean : Mapping filter: \u0026amp;#39;SpringMvcOpenTracingFilter\u0026amp;#39; to urls: [/*] 2018-05-11 11:55:13.961 INFO 66490 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http) 2018-05-11 11:55:13.970 INFO 66490 --- [ main] c.a.s.t.e.springmvc.DemoApplication : Started DemoApplication in 8.361 seconds (JVM running for 9.34) 可以通过在浏览器中输入 http://localhost:8080/springmvc 来访问 REST 服务，结果类似如下：\n{ content: \u0026amp;#34;Hello, SOFATracer SpringMVC DEMO!\u0026amp;#34;, id: 1, success: true } 查看日志 在上面的 application.properties 里面，我们配置的日志打印目录是 ./logs 即当前应用的根目录（我们可以根据自己的实践需要配置），在当前工程的根目录下可以看到类似如下结构的日志文件：\n./logs ├── spring.log └── tracelog ├── spring-mvc-digest.log ├── spring-mvc-stat.log ├── static-info.log └── tracer-self.log 通过访问 http://localhost:8080/springmvc SOFATracer 会记录每一次访问的摘要日志，可以打开 spring-mvc-digest.log 看到具体的输出内容。\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2019-09-03 10:33:10.336\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;RestTemplateDemo\u0026amp;#34;,\u0026amp;#34;traceId\u0026amp;#34;:\u0026amp;#34;0a0fe9271567477985327100211176\u0026amp;#34;,\u0026amp;#34;spanId\u0026amp;#34;:\u0026amp;#34;0.1\u0026amp;#34;,\u0026amp;#34;span.kind\u0026amp;#34;:\u0026amp;#34;server\u0026amp;#34;,\u0026amp;#34;result.code\u0026amp;#34;:\u0026amp;#34;200\u0026amp;#34;,\u0026amp;#34;current.thread.name\u0026amp;#34;:\u0026amp;#34;http-nio-8801-exec-2\u0026amp;#34;,\u0026amp;#34;time.cost.milliseconds\u0026amp;#34;:\u0026amp;#34;5006ms\u0026amp;#34;,\u0026amp;#34;request.url\u0026amp;#34;:\u0026amp;#34;http://localhost:8801/asyncrest\u0026amp;#34;,\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;GET\u0026amp;#34;,\u0026amp;#34;req.size.bytes\u0026amp;#34;:-1,\u0026amp;#34;resp.size.bytes\u0026amp;#34;:0,\u0026amp;#34;sys.baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;,\u0026amp;#34;biz.baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;} ","date":-62135596800,"description":"","dir":"projects/sofa-tracer/usage-of-mvc/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"6c6389a6f994f43f08cbdf4a49d1755a","permalink":"/projects/sofa-tracer/usage-of-mvc/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-tracer/usage-of-mvc/","summary":"在本文档将演示如何使用 SOFATracer 对 SpringMVC 进行埋点，本示例工程地址。 假设你已经基于 SOFABoot 构建了一个简单的 Spring Web 工程，那么可以通过如下步骤进行操作： 依赖引入 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alipay.sofa\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;tracer-sofa-boot-starter\u0026lt;/artifactId\u0026gt;","tags":null,"title":"Spring MVC 埋点接入","type":"projects","url":"/projects/sofa-tracer/usage-of-mvc/","wordcount":514},{"author":null,"categories":null,"content":"SOFATracer 集成 SpringMVC 后输出 MVC 请求的链路数据格式，默认为 JSON 数据格式。\nSpring MVC 摘要日志（spring-mvc-digest.log） 以 JSON 格式输出的数据，相应 key 的含义解释如下：\n   key 表达含义     time 日志打印时间   local.app 当前应用名   traceId TraceId   spanId SpanId   span.kind Span 类型   result.code 状态码   current.thread.name 当前线程名   time.cost.milliseconds span 耗时   request.url 请求地址   method http method   req.size.bytes 请求大小   resp.size.bytes 响应大小   sys.baggage 系统透传的 baggage 数据   biz.baggage 业务透传的 baggage 数据    样例：\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2019-09-03 10:33:10.336\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;RestTemplateDemo\u0026amp;#34;,\u0026amp;#34;traceId\u0026amp;#34;:\u0026amp;#34;0a0fe9271567477985327100211176\u0026amp;#34;,\u0026amp;#34;spanId\u0026amp;#34;:\u0026amp;#34;0.1\u0026amp;#34;,\u0026amp;#34;span.kind\u0026amp;#34;:\u0026amp;#34;server\u0026amp;#34;,\u0026amp;#34;result.code\u0026amp;#34;:\u0026amp;#34;200\u0026amp;#34;,\u0026amp;#34;current.thread.name\u0026amp;#34;:\u0026amp;#34;http-nio-8801-exec-2\u0026amp;#34;,\u0026amp;#34;time.cost.milliseconds\u0026amp;#34;:\u0026amp;#34;5006ms\u0026amp;#34;,\u0026amp;#34;request.url\u0026amp;#34;:\u0026amp;#34;http://localhost:8801/asyncrest\u0026amp;#34;,\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;GET\u0026amp;#34;,\u0026amp;#34;req.size.bytes\u0026amp;#34;:-1,\u0026amp;#34;resp.size.bytes\u0026amp;#34;:0,\u0026amp;#34;sys.baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;,\u0026amp;#34;biz.baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;} Spring MVC 统计日志（spring-mvc-stat.log） stat.key 即本段时间内的统计关键字集合，统一关键字集合唯一确定一组统计数据，包含local.app、request.url、和 method 字段.\n样例：\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2019-09-03 10:34:04.129\u0026amp;#34;,\u0026amp;#34;stat.key\u0026amp;#34;:{\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;GET\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;RestTemplateDemo\u0026amp;#34;,\u0026amp;#34;request.url\u0026amp;#34;:\u0026amp;#34;http://localhost:8801/asyncrest\u0026amp;#34;},\u0026amp;#34;count\u0026amp;#34;:1,\u0026amp;#34;total.cost.milliseconds\u0026amp;#34;:5006,\u0026amp;#34;success\u0026amp;#34;:\u0026amp;#34;true\u0026amp;#34;,\u0026amp;#34;load.test\u0026amp;#34;:\u0026amp;#34;F\u0026amp;#34;} ","date":-62135596800,"description":"","dir":"projects/sofa-tracer/log-format-springmvc/","fuzzywordcount":300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"af13acf5aee90a32f0fa143996063a91","permalink":"/projects/sofa-tracer/log-format-springmvc/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-tracer/log-format-springmvc/","summary":"SOFATracer 集成 SpringMVC 后输出 MVC 请求的链路数据格式，默认为 JSON 数据格式。 Spring MVC 摘要日志（spring-mvc-digest.log） 以 JSON 格式输出的数据，相应 key 的","tags":null,"title":"Spring MVC 日志","type":"projects","url":"/projects/sofa-tracer/log-format-springmvc/","wordcount":253},{"author":null,"categories":null,"content":"SOFAArk 容器提供了一个简单的 telnet 服务端小工具，用于运行时查看容器状态，目前支持查看 Plugin 和 Biz 相关信息。\n使用方式 使用 telnet 连接服务端，端口号为 1234， 例如：\n telnet localhost 1234\n 进入交互界面:\n➜ telnet localhost 1234 Trying 127.0.0.1... Connected to localhost. Escape character is \u0026amp;#39;^]\u0026amp;#39;. sofa-ark\u0026amp;gt; sofa-ark\u0026amp;gt; sofa-ark\u0026amp;gt; 目前支持查看 Plugin 和 Biz 相关信息，相关命令可参考提示信息：\nsofa-ark\u0026amp;gt;h Plugin Command Tips: USAGE: plugin [option...] [pluginName...] SAMPLE: plugin -m plugin-A plugin-B -h Shows the help message. -a Shows all plugin name. -m Shows the meta info of specified pluginName. -s Shows the service info of specified pluginName. -d Shows the detail info of specified pluginName. Biz Command Tips: USAGE: biz [option...] [arguments...] SAMPLE: biz -m bizIdentityA bizIdentityB. -h Shows the help message. -a Shows all biz. -m Shows the meta info of specified bizIdentity. -s Shows the service info of specified bizIdentity. -d Shows the detail info of specified bizIdentity. -i Install biz of specified bizIdentity or bizUrl. -u Uninstall biz of specified bizIdentity. -o Switch biz of specified bizIdentity. sofa-ark\u0026amp;gt; Plugin 命令 如提示信息所说，plugin 支持查看插件相关信息，包括类(资源)导入导出配置、插件打包配置等。例如：\nsofa-ark\u0026amp;gt;plugin -md runtime-sofa-boot-plugin PluginName: runtime-sofa-boot-plugin Version: 3.1.3 Priority: 1500 Activator: com.alipay.sofa.runtime.integration.activator.SofaRuntimeActivator Export Packages: com.alipay.sofa.runtime.api.*,com.alipay.sofa.runtime.client.*,com.alipay.sofa.runtime.component.*,com.alipay.sofa.runtime.constants.*,com.alipay.sofa.runtime.integration.*,com.alipay.sofa.runtime.model.*,com.alipay.sofa.runtime.service.component,com.alipay.sofa.runtime.service.helper,com.alipay.sofa.runtime.spi.client,com.alipay.sofa.runtime.spi.component,com.alipay.sofa.runtime.spi.health,com.alipay.sofa.runtime.spi.log,com.alipay.sofa.runtime.spi.binding,com.alipay.sofa.runtime.spi.util,org.aopalliance.aop,org.aopalliance.intercept Import Packages: \\ Export Classes: com.alipay.sofa.runtime.service.binding.JvmBinding,com.alipay.sofa.runtime.SofaFramework,com.alipay.sofa.runtime.SofaRuntimeProperties,com.alipay.sofa.runtime.service.binding.JvmBindingParam,com.alipay.sofa.runtime.spi.service.ServiceProxy Import Classes: \\ Export Resources: \\ Import Resources: \\ GroupId: com.alipay.sofa ArtifactId: runtime-sofa-boot-plugin Version: 3.1.3 URL: jar:file:/Users/qilong.zql/.m2/repository/com/alipay/sofa/runtime-sofa-boot-plugin/3.1.3/runtime-sofa-boot-plugin-3.1.3.jar!/ ClassLoader: com.alipay.sofa.ark.container.service.classloader.PluginClassLoader@420a63fb ClassPath: …","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-ark-telnet/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"f23d585e5439569b47ed83f7bc955b22","permalink":"/projects/sofa-boot/sofa-ark-ark-telnet/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-boot/sofa-ark-ark-telnet/","summary":"SOFAArk 容器提供了一个简单的 telnet 服务端小工具，用于运行时查看容器状态，目前支持查看 Plugin 和 Biz 相关信息。 使用方式 使用 telnet 连接服务端，端口号为 1234， 例如：","tags":null,"title":"Telnet 指令","type":"projects","url":"/projects/sofa-boot/sofa-ark-ark-telnet/","wordcount":513},{"author":null,"categories":null,"content":"Ark package The Executed Fat Jar that meets the specific directory format requirements can use the officially provided Maven plug-in (sofa-Ark-maven-plugin) to package the engineering application into a standard-format Ark package. Start the application on top of the SOFAArk container with the java -jar command. The Ark package usually contains the Ark Container, Ark Plugin dependency (if any), merged deployed Ark Biz (if any), and the Ark Biz of the application itself. For details, refer to the Ark package；\nArk Container The Ark container (Ark Plugin and Ark Biz) runs on top of the SOFAArk container. The container has the ability to manage multiple plug-ins and applications. After successful start, the container will resolve the configuration of Ark Plugin and Ark Biz, complete loading of the isolation and start them in turn based on their priorities. For details, refer to SOFAArk container startup；\nArk Plugin The Ark plug-in, which meets the specific fat jar directory format requirements, can use the officially provided Maven plug-in (sofa-Ark-plugin-maven-plugin) to package one or multiple common Java Jar packages into a standard-format Ark Plugin. Ark Plugin will contain a configuration file that usually contains the import and export configuration of plug-in classes and resources and the priority of plug-in startup. When running, the Ark container will use an independent PluginClassLoader to load the plug-ins, and build the index table for class loading according to the plug-in configuration, so that the plug-ins are isolated from each other and from the applications. For details, refer to Ark Plugin；\nArk Biz The Ark module, which meets the specific fat jar directory format requirements, can use the officially provided Maven plug-in (sofa-Ark-maven-plugin) to package an engineering application into a standard-format Ark Biz package. The Ark Biz package has two roles: one is to be the organizational unit of the engineering application module and its dependent packages, and the other is to be used as a common jar package dependency by other applications to start multiple Ark Biz packages in the same SOFAArk container. Multiple Ark Biz packages share the Ark Container and Ark Plugin. For details, refer to Ark Biz；\n","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-terminology/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"b6d0ed10afe9d04bc00307017ffba7c5","permalink":"/en/projects/sofa-boot/sofa-ark-terminology/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-boot/sofa-ark-terminology/","summary":"Ark package The Executed Fat Jar that meets the specific directory format requirements can use the officially provided Maven plug-in (sofa-Ark-maven-plugin) to package the engineering application into a standard-format Ark package. Start the application on top of the SOFAArk container with the java -jar command. The Ark package usually contains the Ark Container, Ark Plugin dependency (if any), merged deployed Ark Biz (if any), and the Ark Biz of the application itself.","tags":null,"title":"Terminologies","type":"projects","url":"/en/projects/sofa-boot/sofa-ark-terminology/","wordcount":351},{"author":null,"categories":null,"content":"Explanation of Terms    Terminology Description     TraceId TraceId refers to the ID that represents the unique request in SOFATracer. This ID is generally generated by the first system in the cluster that processes the request and is passed over the network to the next requested system in distributed calls.   SpanId SpanId represents the location or level of the request in the entire call link. For example, the system A calls system B, C, and D in sequence when processing a request. Then the SpanId of the three calls are respectively: 0.1, 0.2, 0.3. If system B continues to call system E and F, the SpanIds of the two calls are: 0.1.1, 0.1.2.    For other related terminologies, see OpenTracing specification.\n","date":-62135596800,"description":"","dir":"projects/sofa-tracer/explanation/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"8ba307b0679e918f7ac68c7efb7e53f7","permalink":"/en/projects/sofa-tracer/explanation/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-tracer/explanation/","summary":"Explanation of Terms    Terminology Description     TraceId TraceId refers to the ID that represents the unique request in SOFATracer. This ID is generally generated by the first system in the cluster that processes the request and is passed over the network to the next requested system in distributed calls.   SpanId SpanId represents the location or level of the request in the entire call link.","tags":null,"title":"Terminologies","type":"projects","url":"/en/projects/sofa-tracer/explanation/","wordcount":118},{"author":null,"categories":null,"content":"General terminology    Term Description     Service A software function provided over the network with specific business logic processing capabilities.   Service provider A computer node that provides services over the network.   Service consumer A computer node that receives services through the network. The same computer node can both be the service provider of some services and the service consumer of others.   Service discovery The process in which the service consumer obtains the network address of the service provider.   Service registry A software system that provides service discovery functions to help service consumers obtain network addresses of service providers.   Data center An independent physical area with a fixed physical location, stable power supply, and reliable network. A data center is usually an important factor that you want to consider in high availability design. Generally, deployment in the same data center features higher network quality, lower latency, but limited disaster recovery capability. However, deployment across different data centers features lower network quality, higher latency, but better disaster recovery capability.    SOFARegistry terminology    Terminology Description     SOFARegistry A registry product open sourced by Ant Financial to provide service discovery based on the \u0026amp;ldquo;publishing-subscription\u0026amp;rdquo; mode. In addition to service discovery, SOFARegistry is applicable to more general \u0026amp;ldquo;publishing-subscription\u0026amp;rdquo; scenarios.   Data In the context of service discovery, data specifically refers to the network address and some additional information of the service provider. In other circumstances, it also refers to information published to SOFARegistry.   Zone The key concept of the zone-based architecture. In the context of service discovery, a zone is a collection of publishing and subscription requests. When you publish or subscribe to a service, you need to specify the zone name. For more information, see Active geo-redundant zone-based architecture solution.   Publisher A node that publishes data to SOFARegistry. In the context of service discovery, the service provider is the publisher of the \u0026amp;ldquo;service provider\u0026amp;rsquo;s network address and additional information\u0026amp;rdquo;.   Subscriber A node that subscribes to data from SOFARegistry. In the context of service discovery, the service consumer is the subscriber of the \u0026amp;ldquo;service provider\u0026amp;rsquo;s network address and additional information\u0026amp;rdquo;.   Data ID A string that is used to identify the data. In the context of service discovery, DataId usually consists of the service port name, protocol, and version number. It is used as an identifier of the service.   Group ID A string that is used for grouping data. It can be used in conjunction with DataId and InstanceId as a namespace identifier of data. Two services may be considered one same service only when their DataIds, GroupIds, and InstanceIds are identical.   Instance ID A string …","date":-62135596800,"description":"","dir":"projects/sofa-registry/terminology/","fuzzywordcount":600,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"b678a49547c55f2a70e2d94dbce5b4a2","permalink":"/en/projects/sofa-registry/terminology/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/en/projects/sofa-registry/terminology/","summary":"General terminology    Term Description     Service A software function provided over the network with specific business logic processing capabilities.   Service provider A computer node that provides services over the network.   Service consumer A computer node that receives services through the network. The same computer node can both be the service provider of some services and the service consumer of others.   Service discovery The process in which the service consumer obtains the network address of the service provider.","tags":null,"title":"Terminology","type":"projects","url":"/en/projects/sofa-registry/terminology/","wordcount":508},{"author":null,"categories":null,"content":"Unit test Place the unit test cases in the modules developed by yourself.\nIf the cases rely on a third-party server (such as ZooKeeper), you must manually add the profile. See the registry-zookeeper module code.\nIf the cases rely on other modules and integration test is required, place them in the test/test-intergrated module.\nIf the cases also rely on a third-party server (such as ZooKeeper), place them in the test-intergrated-3rd module.\nPerformance test Close the following projects that are closed by default:\n-Dcontext.attachment.enable=false -Dserialize.blacklist.enable=false -Ddefault.tracer= -Dlogger.impl=com.alipay.sofa.rpc.log.SLF4JLoggerImpl -Dmultiple.classloader.enable=false -Devent.bus .enable=false\nA pressure test on BOLT+hessian has been done.\n  Server: 4C8G virtual machine; gigabit network; jdk1.8.0_111;\n  Client: 50 concurrent requests\n     Protocol Request Response Server TPS Average RT (ms)     bolt+hessian 1KB string 1KB string Directly return 10000 1.93   bolt+hessian 1KB string 1KB string Directly return 20000 4.13   bolt+hessian 1KB string 1KB string Directly return 30000 7.32   bolt+hessian 1KB string 1KB string Directly return 40000 15.78   bolt+hessian 1KB string 1KB string Directly return 50000 (Close to the utmost limit, error rate: 0.3%) 26.51    ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/test/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"ccda7c2372a7f55d61f682b72d3b1dc2","permalink":"/en/projects/sofa-rpc/test/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/test/","summary":"Unit test Place the unit test cases in the modules developed by yourself.\nIf the cases rely on a third-party server (such as ZooKeeper), you must manually add the profile. See the registry-zookeeper module code.\nIf the cases rely on other modules and integration test is required, place them in the test/test-intergrated module.\nIf the cases also rely on a third-party server (such as ZooKeeper), place them in the test-intergrated-3rd module.","tags":null,"title":"Test","type":"projects","url":"/en/projects/sofa-rpc/test/","wordcount":169},{"author":null,"categories":null,"content":"When using the Bolt protocol for communication, invoke timeout defaults is 3 seconds. You can configure the timeout when referencing the service, and can also configure the timeout period from the dimension of service or method respectively. SOFARPC timeout can be set in milliseconds.\nService If you need to set the timeout from the dimension of service when publishing a service, just configure the timeout parameter to the corresponding value.\nUse XML If you reference the service using XML, set the value of the timeout attribute of the \u0026amp;lt;sofa:global-attrs\u0026amp;gt; tag under the \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; tag:\n\u0026amp;lt;sofa:reference interface=\u0026amp;#34;com.example.demo.SampleService\u0026amp;#34; id=\u0026amp;#34;sampleService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;sofa:global-attrs timeout=\u0026amp;#34;2000\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt; Use Annotation If you reference the service using Annotation, set the value of the timeout attribute of @SofaReferenceBinding:\n@SofaReference(binding = @SofaReferenceBinding(bindingType = \u0026amp;#34;bolt\u0026amp;#34;, timeout = 2000)) private SampleService sampleService; Use API in Spring environment If you reference the service in Spring or Spring Boot environment, just set the value of timeout attribute of BoltBindingParam:\nBoltBindingParam boltBindingParam = new BoltBindingParam(); boltBindingParam.setTimeout(2000) Use API in non-Spring environment If you reference service using the bare API of SOFARPC directly in non-Spring environment, just set the timeout attribute of ConsumerConfig:\nConsumerConfig\u0026amp;lt;SampleService\u0026amp;gt; consumerConfig = new ConsumerConfig\u0026amp;lt;SampleService\u0026amp;gt;() .setInterfaceId(SampleService.class.getName()) .setRegistry(registryConfig) .setProtocol(\u0026amp;#34;bolt\u0026amp;#34;) .setTimeout(2000); Method If you want to adjust the timeout for a certain method in a service individually, you can set the timeout period from the dimension of method.\nFor a method, the timeout period of the method is prioritized. If not set, the timeout period of the service will be used.\nUse XML If you reference service using XML, just set the timeout attribute of the corresponding \u0026amp;lt;sofa: method\u0026amp;gt;:\n\u0026amp;lt;Sofa: Reference interface = \u0026amp;#34;com.example.demo .SampleService\u0026amp;#34; id=\u0026amp;#34;sampleService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;sofa:method name=\u0026amp;#34;hello\u0026amp;#34; timeout=\u0026amp;#34;2000\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt; Use Annotation No method is available for setting the method-level timeout with Annotation currenty.\nUse API in Spring environment To reference a service in Spring or Spring Boot environment, you can just set the value of timeout attribute of RpcBindingMethodInfo\nBoltBindingParam boltBindingParam = new BoltBindingParam(); RpcBindingMethodInfo rpcBindingMethodInfo = new RpcBindingMethodInfo(); rpcBindingMethodInfo.setName(\u0026amp;#34;hello\u0026amp;#34;); rpcBindingMethodInfo.setTimeout(2000); List\u0026amp;lt;RpcBindingMethodInfo\u0026amp;gt; rpcBindingMethodInfos = new ArrayList\u0026amp;lt;\u0026amp;gt;(); rpcBindingMethodInfos.add(rpcBindingMethodInfo); …","date":-62135596800,"description":"","dir":"projects/sofa-rpc/bolt-timeout/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"cf14f73dc0c4672a9255ef55b56de419","permalink":"/en/projects/sofa-rpc/bolt-timeout/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-rpc/bolt-timeout/","summary":"When using the Bolt protocol for communication, invoke timeout defaults is 3 seconds. You can configure the timeout when referencing the service, and can also configure the timeout period from the dimension of service or method respectively. SOFARPC timeout can be set in milliseconds.\nService If you need to set the timeout from the dimension of service when publishing a service, just configure the timeout parameter to the corresponding value.","tags":null,"title":"Timeout control","type":"projects","url":"/en/projects/sofa-rpc/bolt-timeout/","wordcount":388},{"author":null,"categories":null,"content":"本文将向您展示 MOSN 的 TLS 安全能力。\n证书方案 MOSN 支持通过 Istio Citadel 的证书签发方案，基于 Istio 社区的 SDS （Secret Discovery Service）方案为 Sidecar 配置证书，支持证书动态发现和热更新能力。为了支持更高级的安全能力，MOSN 没有使用 Citadel 的证书自签发能力，而是通过对接内部 KMS 系统获取证书。同时提供证书缓存和证书推送更新能力。\n我们先来看看 MOSN 证书方案的架构图，如下图所示：\n各组件职能如下：\n Pilot：负责 Policy、SDS 配置下发，为简化复杂度，图中未标出 Citadel：Citadel 作为 Certificate Provider ，同时作为 MCP Server 为 Citadel Agent 提供 Pod、CR等资源 Citadel Agent：提供 SDS Server 服务，为MOSN、DB Sidecar、Security Sidecar 提供Certificate和CR下发能力 KMS：密钥管理系统负责证书签发  证书获取流程 对整体架构有个大致理解后，我们分解下 Sidecar 获取证书的流程，如下图所示：\n补充说明下图中的每一步环节：\n Citadel 与 Citadel agent（nodeagent）组件通过MCP协议（Mesh Configuration Protocol）同步Pod 和 CR 信息，避免 citadel agent 直接请求 API Server 导致 API Server 负载过高 MOSN 通过Unix Domain Socket 方式向 Citadel Agent 发起 SDS 请求 Citadel Agent 会进行防篡改校验，并提取appkey Citadel Agent 携带 appkey 请求 Citadel 签发证书 Citadel 检查证书是否已缓存，如果缓存证书未过期，Citadel 将直接响应缓存证书 证书不在缓存中，Citadel 会基于 appkey 构造证书签发请求，向 KMS 申请签发证书 KMS 会将签发的证书响应回Citadel，另外 KMS 也支持证书过期轮换通知 Citadel 收到证书后，会将证书传递给到对应的 Citadel Agent Citadel Agent 收到证书后，会在内存中缓存证书，并将证书下发给到 MOSN  ","date":-62135596800,"description":"","dir":"projects/mosn/concept/tls/","fuzzywordcount":700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"47ccccf9690bc65fa437463a8f5e55b6","permalink":"/projects/mosn/concept/tls/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/mosn/concept/tls/","summary":"本文将向您展示 MOSN 的 TLS 安全能力。 证书方案 MOSN 支持通过 Istio Citadel 的证书签发方案，基于 Istio 社区的 SDS （Secret Discovery Service）方案为 Sidecar 配置证书，支持证书","tags":null,"title":"TLS 安全链路","type":"projects","url":"/projects/mosn/concept/tls/","wordcount":654},{"author":null,"categories":null,"content":"TraceId generation rule SOFATracer uses TraceId to concatenate the call logs of a request on each server. The TraceId is typically generated by the first server that receives the request. The generation rule is: server IP + generated time + incremental sequence + current process ID, such as:\n0ad1348f1403169275002100356696  The first 8 digits 0ad1348f is the IP of the machine that generates TraceId. This is a hexadecimal number, in which every two digits represents a part of IP. Based on the number, we can get a common IP address like 10.209.52.143 by converting every two digits into a decimal number. According to this rule, you can also figure out the first server that the request goes through. The next 13 digits 1403169275002 is the time to generate the TraceId. The next 4 digits 1003 is an auto-incrementing sequence that increases from 1000 to 9000. After reaching 9000, it returns to 1000 and then restarts to increase. The last 5 digits 56696 is the current process ID. Its role in tracerId is to prevent the TraceId conflicts caused by multiple processes in a single machine.   Currently, TraceId\u0026amp;rsquo;s generated rules refer to Taobao\u0026amp;rsquo;s Hawkeye components.\n SpanId generation rule The SpanId in SOFATracer represents where the current call is in the entire calling link. If a Web system A receives a user request, then in the SOFATracer MVC log of this system, the recorded SpanId is 0, which means the root node of the entire call. If the system A processes this request and needs to call system B, C, and D through RPC, then the SpanIds in the SOFATracer RPC client log of system A are 0.1, 0.2, and 0.3 respectively. And in the SOFATracer RPC server logs of the system B, C, and D, the SpanIds are also 0.1, 0.2 and 0.3 respectively. If system C calls system E and F when processing the request, then in the corresponding SOFATracer RPC client log of system C, the SpanIds are 0.2.1 and 0.2.2. And the SpanIds in the SOFATracer RPC server logs of system E and F are also 0.2.1 and 0.2.2. As we can known from above, if all SpanIds in a call can be collected to compose a complete link tree.\nWe assume that the TraceId generated in a distributed call is 0a1234 (much longer in practice). Then, according to the generation process of SpanId, the call link tree is as shown in the following figure:\n Currently, SpanId\u0026amp;rsquo;s generated rules refer to Taobao\u0026amp;rsquo;s Hawkeye components.\n ","date":-62135596800,"description":"","dir":"projects/sofa-tracer/traceid-generated-rule/","fuzzywordcount":500,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"8f0ef8df65deec2a4fa6591a316aa5e8","permalink":"/en/projects/sofa-tracer/traceid-generated-rule/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-tracer/traceid-generated-rule/","summary":"TraceId generation rule SOFATracer uses TraceId to concatenate the call logs of a request on each server. The TraceId is typically generated by the first server that receives the request. The generation rule is: server IP + generated time + incremental sequence + current process ID, such as:\n0ad1348f1403169275002100356696  The first 8 digits 0ad1348f is the IP of the machine that generates TraceId. This is a hexadecimal number, in which every two digits represents a part of IP.","tags":null,"title":"TraceId and spanId generation rule","type":"projects","url":"/en/projects/sofa-tracer/traceid-generated-rule/","wordcount":415},{"author":null,"categories":null,"content":"TraceId 生成规则 SOFATracer 通过 TraceId 来将一个请求在各个服务器上的调用日志串联起来，TraceId 一般由接收请求经过的第一个服务器产生，产生规则是： 服务器 IP + 产生 ID 时候的时间 + 自增序列 + 当前进程号 ，比如：\n0ad1348f1403169275002100356696 前 8 位 0ad1348f 即产生 TraceId 的机器的 IP，这是一个十六进制的数字，每两位代表 IP 中的一段，我们把这个数字，按每两位转成 10 进制即可得到常见的 IP 地址表示方式 10.209.52.143，大家也可以根据这个规律来查找到请求经过的第一个服务器。 后面的 13 位 1403169275002 是产生 TraceId 的时间。 之后的 4 位 1003 是一个自增的序列，从 1000 涨到 9000，到达 9000 后回到 1000 再开始往上涨。 最后的 5 位 56696 是当前的进程 ID，为了防止单机多进程出现 TraceId 冲突的情况，所以在 TraceId 末尾添加了当前的进程 ID。\n TraceId 目前的生成的规则参考了阿里的鹰眼组件。\n SpanId 生成规则 SOFATracer 中的 SpanId 代表本次调用在整个调用链路树中的位置，假设一个 Web 系统 A 接收了一次用户请求，那么在这个系统的 SOFATracer MVC 日志中，记录下的 SpanId 是 0，代表是整个调用的根节点，如果 A 系统处理这次请求，需要通过 RPC 依次调用 B，C，D 三个系统，那么在 A 系统的 SOFATracer RPC 客户端日志中，SpanId 分别是 0.1，0.2 和 0.3，在 B，C，D 三个系统的 SOFATracer RPC 服务端日志中，SpanId 也分别是 0.1，0.2 和 0.3；如果 C 系统在处理请求的时候又调用了 E，F 两个系统，那么 C 系统中对应的 SOFATracer RPC 客户端日志是 0.2.1 和 0.2.2，E，F 两个系统对应的 SOFATracer RPC 服务端日志也是 0.2.1 和 0.2.2。根据上面的描述，我们可以知道，如果把一次调用中所有的 SpanId 收集起来，可以组成一棵完整的链路树。\n我们假设一次分布式调用中产生的 TraceId 是 0a1234（实际不会这么短），那么根据上文 SpanId 的产生过程，有下图：\n SpanId 目前的生成的规则参考了阿里的鹰眼组件。\n ","date":-62135596800,"description":"","dir":"projects/sofa-tracer/traceid-generated-rule/","fuzzywordcount":800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"8f0ef8df65deec2a4fa6591a316aa5e8","permalink":"/projects/sofa-tracer/traceid-generated-rule/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-tracer/traceid-generated-rule/","summary":"TraceId 生成规则 SOFATracer 通过 TraceId 来将一个请求在各个服务器上的调用日志串联起来，TraceId 一般由接收请求经过的第一个服务器产生，产生规则是： 服务器 IP + 产","tags":null,"title":"TraceId 和 SpanId 生成规则","type":"projects","url":"/projects/sofa-tracer/traceid-generated-rule/","wordcount":707},{"author":null,"categories":null,"content":"By default, SOFARPC has integrated SOFATracer. Also, you can use other APM products, such as Skywalking, to achieve the corresponding functions. For details, see the relevant documents:\n SOFATracer Skywalking  If you want to disable the tracing ability of SOFARPC, you can do it in two ways.\nIf you are using rpc-sofa-boot-starter in SOFABoot or Spring Boot environment, you can add a configuration com.alipay.sofa.rpc.defaultTracer= in application.properties.\nIf you are using sofa-rpc-all directly, you can add the following code in the main method of your application before publish any SOFARPC service or create any SOFARPC reference.\nRpcConfigs.putValue(RpcOptions.DEFAULT_TRACER, \u0026amp;#34;\u0026amp;#34;); ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/tracing-usage/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"5f944f87d827ae060fb0528f6715af97","permalink":"/en/projects/sofa-rpc/tracing-usage/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/tracing-usage/","summary":"By default, SOFARPC has integrated SOFATracer. Also, you can use other APM products, such as Skywalking, to achieve the corresponding functions. For details, see the relevant documents:\n SOFATracer Skywalking  If you want to disable the tracing ability of SOFARPC, you can do it in two ways.\nIf you are using rpc-sofa-boot-starter in SOFABoot or Spring Boot environment, you can add a configuration com.alipay.sofa.rpc.defaultTracer= in application.properties.\nIf you are using sofa-rpc-all directly, you can add the following code in the main method of your application before publish any SOFARPC service or create any SOFARPC reference.","tags":null,"title":"Tracing","type":"projects","url":"/en/projects/sofa-rpc/tracing-usage/","wordcount":96},{"author":null,"categories":null,"content":"Use annotation for service publishing/reference In addition to the regular xml mode, it is also supported to publish and reference services with annotation in the SOFABoot environment. Similar to xml, we provide @SofaService and @SofaReference as well as @SofaServiceBinding and @SofaReferenceBinding annotation for multi-protocol.\nService publishing To publish an RPC service, you only need to add a @SofaService annotation on the bean to specify the interface and protocol type.\n@SofaService(interfaceType = AnnotationService.class, bindings = { @SofaServiceBinding(bindingType = \u0026amp;#34;bolt\u0026amp;#34;) }) @Component public class AnnotationServiceImpl implements AnnotationService { @Override public String sayAnnotation(String stirng) { return stirng; } } Service reference For a bean that needs to reference a remote service, you only need to add the Reference annotation on the attribute or method. This supports the bolt, dubbo, rest protocol.\n@Component public class AnnotationClientImpl { @SofaReference(interfaceType = AnnotationService.class, binding = @SofaReferenceBinding(bindingType = \u0026amp;#34;bolt\u0026amp;#34;)) private AnnotationService annotationService; public String sayClientAnnotation(String str) { String result = annotationService.sayAnnotation(str); return result; } } Use the demo You can test in the annotation subproject of the sample project.\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/programing-sofa-boot-annotation/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"2c3afd33cbce4f5aa2473716b3afe5a6","permalink":"/en/projects/sofa-rpc/programing-sofa-boot-annotation/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/programing-sofa-boot-annotation/","summary":"Use annotation for service publishing/reference In addition to the regular xml mode, it is also supported to publish and reference services with annotation in the SOFABoot environment. Similar to xml, we provide @SofaService and @SofaReference as well as @SofaServiceBinding and @SofaReferenceBinding annotation for multi-protocol.\nService publishing To publish an RPC service, you only need to add a @SofaService annotation on the bean to specify the interface and protocol type.\n@SofaService(interfaceType = AnnotationService.","tags":null,"title":"Use annotation in SOFABoot","type":"projects","url":"/en/projects/sofa-rpc/programing-sofa-boot-annotation/","wordcount":171},{"author":null,"categories":null,"content":"Use client API In the design of SOFALookout client, API is decoupled from the implementation. If you need to log the events based on the SOFALookout API, you only need to add the lookout-api Maven dependency to the pom.xml file in your application/project. If the dependencies (such as client dependencies or SOFABoot (Spring Boot) Starter) do not exist, the API package uses NoopRegistry automatically, to replace all the locations of which the events are logged.\n1.Introduce API dependency \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa.lookout\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;lookout-api\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${lookout.client.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 2.About ID Compared to the traditional metrics library\u0026amp;rsquo;s single-dimensional information description, Lookout metrics provides tag capability that supports multi-dimensional descriptions. ID class, the unique identification of Lookout metrics, consists of name and tags.\nId basicId = registry.createId(\u0026amp;#34;rpc.provider.service.stats\u0026amp;#34;); id = basicId.withTag(\u0026amp;#34;service\u0026amp;#34;, \u0026amp;#34;com.alipay.demo.demoService\u0026amp;#34;) .withTag(\u0026amp;#34;method\u0026amp;#34;, \u0026amp;#34;sayHi\u0026amp;#34;) .withTag(\u0026amp;#34;protocol\u0026amp;#34;, \u0026amp;#34;tr\u0026amp;#34;) .withTag(\u0026amp;#34;alias\u0026amp;#34;, \u0026amp;#34;group1\u0026amp;#34;); The above is a simple example of ID introducing how to create ID and how to tag. Note that every time you tag, a new ID object is generated and returned.\n Do not proactively cache Id or the specific Metric object, since Lookout\u0026amp;rsquo;s Registry has already recorded. When using a same Id (with the same name and tags), the existing Id and its corresponding Metric object will be reused.\n 2.1 Priority tag (optional) PRIORITY enumeration level: HIGH, NORMAL, LOW.\nid.withTag(LookoutConstants.LOW_PRIORITY_TAG); It is recommended that you do not add this tag, the default level will be NORMAL. The level represents the collection interval (HIGH: 2s, NORMAL: 30s, LOW: 1min).\n2.2 About tags  General tags, such as local IP, data center, and other details, will be attached and no need to be specified separately. In a non-SOFABoot project, you must manually add tags to the client, especially the app tag which specifies the app name: app=appName. key contains only lowercase letters, numbers, and underscores. (especially the metrics at runtime, such as Counter, Timer, and DistributeSummary) The values ​​of a tag shall be within a stable finite set. Try to use as few tags as possible to prevent the number of metrics from exceeding the maximum limit. For example: In RPC service, the value of method\u0026amp;rsquo;s two tags shall be as few as possible. The counterexample is that each RPC call has a separate tag-value. Therefore, the overall principle is that there should be as few custom tags as possible, and the number of sets of the values ​​should be as small as possible. Specialized TAG name \u0026amp;ldquo;priority\u0026amp;rdquo; indicates priority. The tag key reserved by the system is _*_. Starting with an underscore and ending with an underscore (eg: …","date":-62135596800,"description":"","dir":"projects/sofa-lookout/use-guide-api/","fuzzywordcount":1000,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"76574f2435a3565fe1fc50831ff9ab0c","permalink":"/en/projects/sofa-lookout/use-guide-api/","publishdate":"0001-01-01T00:00:00Z","readingtime":5,"relpermalink":"/en/projects/sofa-lookout/use-guide-api/","summary":"Use client API In the design of SOFALookout client, API is decoupled from the implementation. If you need to log the events based on the SOFALookout API, you only need to add the lookout-api Maven dependency to the pom.xml file in your application/project. If the dependencies (such as client dependencies or SOFABoot (Spring Boot) Starter) do not exist, the API package uses NoopRegistry automatically, to replace all the locations of which the events are logged.","tags":null,"title":"Use API","type":"projects","url":"/en/projects/sofa-lookout/use-guide-api/","wordcount":911},{"author":null,"categories":null,"content":"SOFARPC Service publishing The process of service publishing involves three classes RegistryConfig, ServerConfig, ProviderConfig.\n RegistryConfig  RegistryConfig registryConfig = new RegistryConfig() .setProtocol(\u0026amp;#34;zookeeper\u0026amp;#34;) .setAddress(\u0026amp;#34;127.0.0.1:2181\u0026amp;#34;) RegistryConfig represents the registry center. As above, the address and port of the service registry center is 127.0.0.1:2181, and the protocol is Zookeeper.\nServerConfig  ServerConfig serverConfig = new ServerConfig() .setPort(8803) .setProtocol(\u0026amp;#34;bolt\u0026amp;#34;); ServerConfig represents the container where service runs. The above declares a server using the 8803 port and the bolt protocol.\nProviderConfig  ProviderConfig\u0026amp;lt;HelloWorldService\u0026amp;gt; providerConfig = new ProviderConfig\u0026amp;lt;HelloWorldService\u0026amp;gt;() .setInterfaceId(HelloWorldService.class.getName()) .setRef(new HelloWorldServiceImpl()) .setServer(serverConfig) .setRegistry(registryConfig); providerConfig.export(); ProviderConfig represents service publishing. The above declares the interface of the service, implements the server running the service, and eventually publishes the service by the export method.\nService reference Service reference involves two classes, namely RegistryConfig and ConsumerConfig.\nConsumerConfig\u0026amp;lt;HelloService\u0026amp;gt; consumerConfig = new ConsumerConfig\u0026amp;lt;HelloService\u0026amp;gt;() .setInterfaceId(HelloService.class.getName()) .setRegistry(registryConfig); HelloService helloService = consumerConfig.refer(); ConsumerConfig represents service reference. The above declares the interface and service registry center of the referenced service interface, and finally references the service by the refer method to get the proxy for the remote call of the service.\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/programing-rpc/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"ee6f74a4974c7abf72322cef108d5ef0","permalink":"/en/projects/sofa-rpc/programing-rpc/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/programing-rpc/","summary":"SOFARPC Service publishing The process of service publishing involves three classes RegistryConfig, ServerConfig, ProviderConfig.\n RegistryConfig  RegistryConfig registryConfig = new RegistryConfig() .setProtocol(\u0026#34;zookeeper\u0026#34;) .setAddress(\u0026#34;127.0.0.1:2181\u0026#34;) RegistryConfig represents the registry center. As above, the address and port of the service registry center is 127.0.0.1:2181, and the protocol is Zookeeper.\nServerConfig  ServerConfig serverConfig = new ServerConfig() .setPort(8803) .setProtocol(\u0026#34;bolt\u0026#34;); ServerConfig represents the container where service runs. The above declares a server using the 8803 port and the bolt protocol.","tags":null,"title":"Use API in non-Spring environment","type":"projects","url":"/en/projects/sofa-rpc/programing-rpc/","wordcount":172},{"author":null,"categories":null,"content":"This topic mainly describes a JRaft-based distributed counter.\nScenario Save a distributed counter in a raft group of multiple nodes (servers). The counter can increment and be called while remaining consistent among all nodes. The counter can normally provide two external services when a minority of nodes fail:\n incrmentAndGet(delta): increments the value of delta and returns the incremented value. get(): gets the latest value.  Remote procedure calls (RPCs) JRaft adopts the Bolt communication framework at the underlayer, and defines two requests:\n IncrementAndGetRequest: used for incrementing the value  public class IncrementAndGetRequest implements Serializable { private static final long serialVersionUID = -5623664785560971849L; private long delta; public long getDelta() { return this.delta; } public void setDelta(long delta) { this.delta = delta; } }  GetValueRequest: used for getting the latest value  public class GetValueRequest implements Serializable { private static final long serialVersionUID = 9218253805003988802L; public GetValueRequest() { super(); } } ValueResponse responses include:\n success: indicates that the request was successful value: the latest value returned by a successful request errorMsg: the error message of a failed request redirect: indicates that a leader election occurred and the request needs to be sent to the new leader node  public class ValueResponse implements Serializable { private static final long serialVersionUID = -4220017686727146773L; private long value; private boolean success; /** * redirect peer id */ private String redirect; private String errorMsg; public String getErrorMsg() { return this.errorMsg; } public void setErrorMsg(String errorMsg) { this.errorMsg = errorMsg; } ...... }  IncrementAndAddClosure: used for receiving requests at the leader node IncrementAndGetRequest: used for handling callbacks of the request  public class IncrementAndAddClosure implements Closure { private CounterServer counterServer; private IncrementAndGetRequest request; private ValueResponse response; private Closure done; // The network response callback  public IncrementAndAddClosure(CounterServer counterServer, IncrementAndGetRequest request, ValueResponse response, Closure done) { super(); this.counterServer = counterServer; this.request = request; this.response = response; this.done = done; } @Override public void run(Status status) { // Return the response to the client  if (this.done != null) { done.run(status); } } public IncrementAndGetRequest getRequest() { return this.request; } public void setRequest(IncrementAndGetRequest request) { this.request = request; } public ValueResponse getResponse() { return this.response; } } Server CounterStateMachine First hold an initial value:\npublic class CounterStateMachine extends StateMachineAdapter { /** * counter value */ private AtomicLong value = new AtomicLong(0); Implement the core onApply(iterator) method, and apply the user request to the state machine:\n@Override …","date":-62135596800,"description":"","dir":"projects/sofa-jraft/counter-example/","fuzzywordcount":1900,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"f9c54b9f7883ccb1d7c259b7101f4674","permalink":"/en/projects/sofa-jraft/counter-example/","publishdate":"0001-01-01T00:00:00Z","readingtime":9,"relpermalink":"/en/projects/sofa-jraft/counter-example/","summary":"This topic mainly describes a JRaft-based distributed counter.\nScenario Save a distributed counter in a raft group of multiple nodes (servers). The counter can increment and be called while remaining consistent among all nodes. The counter can normally provide two external services when a minority of nodes fail:\n incrmentAndGet(delta): increments the value of delta and returns the incremented value. get(): gets the latest value.  Remote procedure calls (RPCs) JRaft adopts the Bolt communication framework at the underlayer, and defines two requests:","tags":null,"title":"Use case of a counter","type":"projects","url":"/en/projects/sofa-jraft/counter-example/","wordcount":1859},{"author":null,"categories":null,"content":"SOFABoot provides a class isolation framework SOFAArk, giving Spring Boot a class isolation ability to resolve class or package conflicts in the development. For detailed information, please refer to:SOFAArk\nTo use this feature in SOFABoot projects, we need only two steps: configure the sofa-ark-maven-plugin plugins for packaging and add sofa-ark-springboot-starter dependencies of the class isolation framework.\nConfigure Maven packaging plugins The Maven plugins - sofa-ark-maven-plugin are available on the Central Repository. Through simple configurations, a SpringBoot project can be wrapped into an executable Ark package in the standard format. The coordinate of sofa-ark-maven-plugin is:\n\u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/plugin\u0026amp;gt; The configuration template is described as follows:\n\u0026amp;lt;build\u0026amp;gt; \u0026amp;lt;plugins\u0026amp;gt; \u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;executions\u0026amp;gt; \u0026amp;lt;execution\u0026amp;gt; \u0026amp;lt;id\u0026amp;gt;default-cli\u0026amp;lt;/id\u0026amp;gt; \u0026amp;lt;!--goal executed to generate executable-ark-jar --\u0026amp;gt; \u0026amp;lt;goals\u0026amp;gt; \u0026amp;lt;goal\u0026amp;gt;repackage\u0026amp;lt;/goal\u0026amp;gt; \u0026amp;lt;/goals\u0026amp;gt; \u0026amp;lt;configuration\u0026amp;gt; \u0026amp;lt;!--specify destination where executable-ark-jar will be saved, default saved to ${project.build.directory}--\u0026amp;gt; \u0026amp;lt;outputDirectory\u0026amp;gt;./target\u0026amp;lt;/outputDirectory\u0026amp;gt; \u0026amp;lt;!--default none--\u0026amp;gt; \u0026amp;lt;arkClassifier\u0026amp;gt;executable-ark\u0026amp;lt;/arkClassifier\u0026amp;gt; \u0026amp;lt;!-- all class exported by ark plugin would be resolved by ark biz in default, if configure denyImportClasses, then it would prefer to load them by ark biz itself --\u0026amp;gt; \u0026amp;lt;denyImportClasses\u0026amp;gt; \u0026amp;lt;class\u0026amp;gt;com.alipay.sofa.SampleClass1\u0026amp;lt;/class\u0026amp;gt; \u0026amp;lt;class\u0026amp;gt;com.alipay.sofa.SampleClass2\u0026amp;lt;/class\u0026amp;gt; \u0026amp;lt;/denyImportClasses\u0026amp;gt; \u0026amp;lt;!-- Corresponding to denyImportClasses, denyImportPackages is package-level --\u0026amp;gt; \u0026amp;lt;denyImportPackages\u0026amp;gt; \u0026amp;lt;package\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/package\u0026amp;gt; \u0026amp;lt;package\u0026amp;gt;org.springframework\u0026amp;lt;/package\u0026amp;gt; \u0026amp;lt;/denyImportPackages\u0026amp;gt; \u0026amp;lt;!-- denyImportResources can prevent resource exported by ark plugin with accurate name to be resolved --\u0026amp;gt; \u0026amp;lt;denyImportResources\u0026amp;gt; \u0026amp;lt;resource\u0026amp;gt;META-INF/spring/test1.xml\u0026amp;lt;/resource\u0026amp;gt; \u0026amp;lt;resource\u0026amp;gt;META-INF/spring/test2.xml\u0026amp;lt;/resource\u0026amp;gt; \u0026amp;lt;/denyImportResources\u0026amp;gt; \u0026amp;lt;/configuration\u0026amp;gt; \u0026amp;lt;/execution\u0026amp;gt; \u0026amp;lt;/executions\u0026amp;gt; \u0026amp;lt;/plugin\u0026amp;gt; \u0026amp;lt;/plugins\u0026amp;gt; \u0026amp;lt;/build\u0026amp;gt; Description of plugin configuration:\n outputDirectory: Execute mvn package and then specify a directory to store the Ark package. The default directory is ${project. Build. Directory}. arkClassifier: Execute mvn docleoy, and then specify the coordinates of Maven repositories to locate the Ark package by setting the classfaulter value (the default is empty). We recommend that you configure this to give a different name from the ordinary Fat jar; denyImportClasses: By default, the application will first load …","date":-62135596800,"description":"","dir":"projects/sofa-boot/classloader-isolation/","fuzzywordcount":1200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"e007416ab008c1dd4b886433dbf8af01","permalink":"/en/projects/sofa-boot/classloader-isolation/","publishdate":"0001-01-01T00:00:00Z","readingtime":6,"relpermalink":"/en/projects/sofa-boot/classloader-isolation/","summary":"SOFABoot provides a class isolation framework SOFAArk, giving Spring Boot a class isolation ability to resolve class or package conflicts in the development. For detailed information, please refer to:SOFAArk\nTo use this feature in SOFABoot projects, we need only two steps: configure the sofa-ark-maven-plugin plugins for packaging and add sofa-ark-springboot-starter dependencies of the class isolation framework.\nConfigure Maven packaging plugins The Maven plugins - sofa-ark-maven-plugin are available on the Central Repository.","tags":null,"title":"Use class isolation in SOFABoot","type":"projects","url":"/en/projects/sofa-boot/classloader-isolation/","wordcount":1129},{"author":null,"categories":null,"content":"This article describes how to quickly start installing and configuring Istio by using Docker Compose.\nSOFAMosn can not only support the standard Istio deployment mode, but also support the unilateral Inbound Sidecar or Outbound Sidecar deployment mode to meet the various requirements of users.\nPrerequisites  Docker Docker Compose  Install Istio   Download the latest release package.\n  Unzip the installation file and go to the decompressed path. The installation path contains:\n Sample application path samples/. The istioctl client executable file which is in the /bin path. The istioctl can be used to create routing rules and policies. Configuration file istion.VERSION.    Add the Istio\u0026amp;rsquo;s bin path to your system\u0026amp;rsquo;s PATH. For example, execute the following command in the MacOS or Linux operating system:\nexport PATH=$PWD/bin;$PATH   Pull up the Istio control plane container:\ndocker-compose -f install/zookeeper/istio.yaml up -d   Ensure that all Docker containers are running:\ndocker ps -a If the Istio pilot container terminates unexpectedly, you can run the istioctl context-create command and re-execute the previous command.\n  Configure istioctl to use the Istio API server:\nistioctl context-create -context istio-local --api-server   Deploy application Now, you can start deploying the SOFABoot demo program. The demo program includes a client and a server, which communicate with each other through Bolt protocol.\ndocker-compose up -f sofa-sample-spec.yaml up -d Uninstall Istio docker-compose up -f install/zookeeper/istio.yaml down ","date":-62135596800,"description":"","dir":"projects/sofa-mesh/pilot-setup-zookeeper-quick-start-docker/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"1de4868fa0e9c73d932343847864d7fb","permalink":"/en/projects/sofa-mesh/pilot-setup-zookeeper-quick-start-docker/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-mesh/pilot-setup-zookeeper-quick-start-docker/","summary":"This article describes how to quickly start installing and configuring Istio by using Docker Compose.\nSOFAMosn can not only support the standard Istio deployment mode, but also support the unilateral Inbound Sidecar or Outbound Sidecar deployment mode to meet the various requirements of users.\nPrerequisites  Docker Docker Compose  Install Istio   Download the latest release package.\n  Unzip the installation file and go to the decompressed path.","tags":null,"title":"Use Docker to get started with Istio","type":"projects","url":"/en/projects/sofa-mesh/pilot-setup-zookeeper-quick-start-docker/","wordcount":217},{"author":null,"categories":null,"content":"Use API SOFABoot provides a set of programming APIs for RPC service publishing and reference. It is convenient to publish and reference RPC services directly in the code. Similar to Spring\u0026amp;rsquo;s ApplicationContextAware, in order to use the programming API, you first need to implement the ClientFactoryAware interface to get the programming component API:\npublic class ClientFactoryBean implements ClientFactoryAware { private ClientFactory clientFactory; @Override public void setClientFactory(ClientFactory clientFactory) { this.clientFactory = clientFactory; } } With DirectService as an example, see how to use the clientFactory to publish an RPC service through the programming API:\nServiceClient serviceClient = clientFactory.getClient(ServiceClient.class); ServiceParam serviceParam = new ServiceParam(); serviceParam.setInterfaceType(DirectService.class); serviceParam.setInstance(new DirectServiceImpl()); List\u0026amp;lt;BindingParam\u0026amp;gt; params = new ArrayList\u0026amp;lt;BindingParam\u0026amp;gt;(); BindingParam serviceBindingParam = new BoltBindingParam(); params.add(serviceBindingParam); serviceParam.setBindingParams(params); serviceClient.service (serviceParam); In the code above:\n First, get the ServiceClient object through the clientFactory. Then, construct the ServiceParam object, which contains the parameters required to publish the service, and use the setInstance method to set the object to be published as an RPC service, setInterfaceType to set the interface of the service. Finally, call the service method of ServiceClient to publish an RPC service.  The code that references the RPC service through the programming API is similar:\nReferenceClient referenceClient = clientFactory.getClient(ReferenceClient.class); ReferenceParam\u0026amp;lt;DirectService\u0026amp;gt; referenceParam = new ReferenceParam\u0026amp;lt;DirectService\u0026amp;gt;(); referenceParam.setInterfaceType(DirectService.class); BindingParam refBindingParam = new BoltBindingParam(); referenceParam.setBindingParam(refBindingParam); DirectService proxy = referenceClient.reference(referenceParam); proxy.sayDirect(\u0026amp;#34;hello\u0026amp;#34;); Likewise, to reference an RPC service, the code simply needs to get a ReferenceClient from the ClientFactory and then construct a ReferenceParam similar to publishing a service, next set up the service interface, and finally call the ReferenceClient\u0026amp;rsquo;s reference method.\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/programing-sofa-boot-api/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"2679388dc3459714f869d8f8a71739d7","permalink":"/en/projects/sofa-rpc/programing-sofa-boot-api/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-rpc/programing-sofa-boot-api/","summary":"Use API SOFABoot provides a set of programming APIs for RPC service publishing and reference. It is convenient to publish and reference RPC services directly in the code. Similar to Spring\u0026rsquo;s ApplicationContextAware, in order to use the programming API, you first need to implement the ClientFactoryAware interface to get the programming component API:\npublic class ClientFactoryBean implements ClientFactoryAware { private ClientFactory clientFactory; @Override public void setClientFactory(ClientFactory clientFactory) { this.clientFactory = clientFactory; } } With DirectService as an example, see how to use the clientFactory to publish an RPC service through the programming API:","tags":null,"title":"Use dynamic API in SOFABoot","type":"projects","url":"/en/projects/sofa-rpc/programing-sofa-boot-api/","wordcount":255},{"author":null,"categories":null,"content":"Introduction This section is intended to demonstrate how to use Jarslink 2.0 to dynamically control the life cycle of the Biz package and to complete its installation, uninstallation, and query.\nDemo With reference to How to reform common Spring Boot applications, the reformed spring-boot-transform-sample project has integrated the Jarslink 2.0 component. By executing the Ark package that the application packaged and generated, you can dynamically install or uninstall the application during its running.\n  java -jar starts the spring-boot-transform-sample application Ark package.\n  telnet localhost 1234 enters the Jarslink 2.0 command interface, as follows:\n telnet localhost 1234 s Trying 127.0.0.1\u0026amp;hellip;\nConnected to localhost.\nEscape character is \u0026amp;lsquo;^]\u0026amp;rsquo;.\nsofa-ark\u0026amp;gt;\n   Execute the check -b query command, and the result is as follows:\n sofa-ark\u0026amp;gt;check -b\nBiz count=1\nbizName=\u0026amp;lsquo;spring-boot-transform-sample\u0026amp;rsquo;, bizVersion=\u0026amp;lsquo;1.0.0\u0026amp;rsquo;, bizState=\u0026amp;lsquo;activated\u0026amp;rsquo;\nsofa-ark\u0026amp;gt;\n   With reference to How to reform a common Spring Boot application, create any SOFABoot application of non-Web type, package it into a Biz package, and execute the install -b installation command, and the result is as follows:\n sofa-ark\u0026amp;gt;install -b file:///Users/qilong.zql/Desktop/test-ark-biz.jar\nBiz:\u0026amp;lsquo;test-biz:1.0.0\u0026amp;rsquo; is installing.\nsofa-ark\u0026amp;gt;\n   Execute the check -b query command again, and the result is as follows:\n sofa-ark\u0026amp;gt;check -b\nBiz count=2\nbizName=\u0026amp;lsquo;test-biz\u0026amp;rsquo;, bizVersion=\u0026amp;lsquo;1.0.0\u0026amp;rsquo;, bizState=\u0026amp;lsquo;activated\u0026amp;rsquo;\nbizName=\u0026amp;lsquo;spring-boot-transform-sample\u0026amp;rsquo;, bizVersion=\u0026amp;lsquo;1.0.0\u0026amp;rsquo;, bizState=\u0026amp;lsquo;activated\u0026amp;rsquo;\nsofa-ark\u0026amp;gt;\n   Execute the uninstall -b -n -v uninstallation command, and the result is as follows:\n sofa-ark\u0026amp;gt;uninstall -b -n test-biz -v 1.0.0\nUninstall biz:\u0026amp;lsquo;test-biz:1.0.0\u0026amp;rsquo; success.\nsofa-ark\u0026amp;gt;\n   Execute the check -b query command again, and the result is as follows:\n sofa-ark\u0026amp;gt;check -b\nBiz count=1\nbizName=\u0026amp;lsquo;spring-boot-transform-sample\u0026amp;rsquo;, bizVersion=\u0026amp;lsquo;1.0.0\u0026amp;rsquo;, bizState=\u0026amp;lsquo;activated\u0026amp;rsquo;\nsofa-ark\u0026amp;gt;\n For use of more commands, refer to Interactive Commands.\n  ","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-jarslink-jarslink-deploy-demo/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"749f6debe73b73b4882477779008bb99","permalink":"/en/projects/sofa-boot/sofa-jarslink-jarslink-deploy-demo/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-boot/sofa-jarslink-jarslink-deploy-demo/","summary":"Introduction This section is intended to demonstrate how to use Jarslink 2.0 to dynamically control the life cycle of the Biz package and to complete its installation, uninstallation, and query.\nDemo With reference to How to reform common Spring Boot applications, the reformed spring-boot-transform-sample project has integrated the Jarslink 2.0 component. By executing the Ark package that the application packaged and generated, you can dynamically install or uninstall the application during its running.","tags":null,"title":"Use Jarslink for multi-application dynamic deployment","type":"projects","url":"/en/projects/sofa-boot/sofa-jarslink-jarslink-deploy-demo/","wordcount":248},{"author":null,"categories":null,"content":"This article introduces how to use MOSN to build the Service Mesh development environment based on SOFAMesh framework, and verify some basic capabilities of MOSN, such as routing and load balancing. This article includes the following content:\n Relationship between MOSN and SOFAMesh Preparations Deploy SOFAMesh with source codes Bookinfo experiment  Relationship between MOSN and SOFAMesh As mentioned in MOSN introduction, MOSN is a Service Mesh data plane agent developed with Golang, and SOFAMesh is a large-scale implementation solution for Service Mesh, which is improved and extended based on Istio. Serving as a critical component of SOFAMesh, MOSN is used to complete data plane forwarding.\nThe following figure shows the workflow chart of MOSN based on the overall SOFAMesh framework.\nNote: Currently, MOSN cannot be directly used in the native Istio.\nPreparations This guide supposes you are using macOS. For other operating systems, you can install the corresponding software.\n1. Install HyperKit Install docker-for-mac, and then install driver.\n1.1 Install Docker Download the Docker software package to install it or run the following command to install it:\n$ brew cask install docker 1.2 Install driver $ curl -LO https://storage.googleapis.com/minikube/releases/latest/docker-machine-driver-hyperkit \\ \u0026amp;amp;\u0026amp;amp; chmod +x docker-machine-driver-hyperkit \\ \u0026amp;amp;\u0026amp;amp; sudo mv docker-machine-driver-hyperkit /usr/local/bin/ \\ \u0026amp;amp;\u0026amp;amp; sudo chown root:wheel /usr/local/bin/docker-machine-driver-hyperkit \\ \u0026amp;amp;\u0026amp;amp; sudo chmod u+s /usr/local/bin/docker-machine-driver-hyperkit 2. Install Minikube (or purchase the commercial version of k8s cluster) It is recommended to use Minikube V0.28 or later, see https://github.com/kubernetes/minikube.\n$ brew cask install minikube 3. Start Minikube Note that Pilot requires at least 2G memory, so you can add resources to Minikube by adding parameters at startup. If your machine has insufficient resources, it is recommended to use the commercial version of the k8s cluster.\n$ minikube start --memory=8192 --cpus=4 --kubernetes-version=v1.15.0 --vm-driver=hyperkit Create Istio namespace\n$ kubectl create namespace istio-system 4. Install kubectl command line tool kubectl is a command line interface used to run commands for k8s cluster. For how to install it, see https://kubernetes.io/docs/tasks/tools/install-kubectl.\n$ brew install kubernetes-cli 5. Install Helm Helm is a package management tool for k8s. For how to install it, see https://docs.helm.sh/using_helm/#installing-helm.\n$ brew install kubernetes-helm Deploy SOFAMesh with source codes 1. Download SOFAMesh source codes $ git clone git@github.com:sofastack/sofa-mesh.git 2. Use Helm to install SOFAMesh You should change directory to sofa-mesh source code, and then use helm template to install isito crd and istio\n``` $ cd sofa-mesh $ helm template install/kubernetes/helm/istio-init --name istio-init --namespace istio-system | kubectl apply -f - $ helm template …","date":-62135596800,"description":"","dir":"projects/mosn/quick-start-run-with-sofamesh/","fuzzywordcount":1100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"9c6461e92180417d3a8ec4f3f2c723fe","permalink":"/en/projects/mosn/quick-start-run-with-sofamesh/","publishdate":"0001-01-01T00:00:00Z","readingtime":6,"relpermalink":"/en/projects/mosn/quick-start-run-with-sofamesh/","summary":"This article introduces how to use MOSN to build the Service Mesh development environment based on SOFAMesh framework, and verify some basic capabilities of MOSN, such as routing and load balancing. This article includes the following content:\n Relationship between MOSN and SOFAMesh Preparations Deploy SOFAMesh with source codes Bookinfo experiment  Relationship between MOSN and SOFAMesh As mentioned in MOSN introduction, MOSN is a Service Mesh data plane agent developed with Golang, and SOFAMesh is a large-scale implementation solution for Service Mesh, which is improved and extended based on Istio.","tags":null,"title":"Use MOSN to build Service Mesh platform","type":"projects","url":"/en/projects/mosn/quick-start-run-with-sofamesh/","wordcount":1078},{"author":null,"categories":null,"content":"This article introduces how to use MOSN to build the Service Mesh development environment based on SOFAMesh framework, and verify some basic capabilities of MOSN, such as routing and load balancing. This article includes the following content:\n Relationship between MOSN and SOFAMesh Preparations Deploy SOFAMesh with source codes Bookinfo experiment  Relationship between MOSN and SOFAMesh As mentioned in MOSN introduction, MOSN is a Service Mesh data plane agent developed with Golang, and SOFAMesh is a large-scale implementation solution for Service Mesh, which is improved and extended based on Istio. Serving as a critical component of SOFAMesh, MOSN is used to complete data plane forwarding.\nThe following figure shows the workflow chart of MOSN based on the overall SOFAMesh framework.\nNote: Currently, MOSN cannot be directly used in the native Istio.\nPreparations This guide supposes you are using macOS. For other operating systems, you can install the corresponding software.\n1. Install HyperKit Install docker-for-mac, and then install driver.\n1.1 Install Docker Download the Docker software package to install it or run the following command to install it:\n$ brew cask install docker 1.2 Install driver $ curl -LO https://storage.googleapis.com/minikube/releases/latest/docker-machine-driver-hyperkit \\ \u0026amp;amp;\u0026amp;amp; chmod +x docker-machine-driver-hyperkit \\ \u0026amp;amp;\u0026amp;amp; sudo mv docker-machine-driver-hyperkit /usr/local/bin/ \\ \u0026amp;amp;\u0026amp;amp; sudo chown root:wheel /usr/local/bin/docker-machine-driver-hyperkit \\ \u0026amp;amp;\u0026amp;amp; sudo chmod u+s /usr/local/bin/docker-machine-driver-hyperkit 2. Install Minikube (or purchase the commercial version of k8s cluster) It is recommended to use Minikube V0.28 or later, see https://github.com/kubernetes/minikube.\n$ brew cask install minikube 3. Start Minikube Note that Pilot requires at least 2G memory, so you can add resources to Minikube by adding parameters at startup. If your machine has insufficient resources, it is recommended to use the commercial version of the k8s cluster.\n$ minikube start --memory=8192 --cpus=4 --kubernetes-version=v1.15.0 --vm-driver=hyperkit Create Istio namespace\n$ kubectl create namespace istio-system 4. Install kubectl command line tool kubectl is a command line interface used to run commands for k8s cluster. For how to install it, see https://kubernetes.io/docs/tasks/tools/install-kubectl.\n$ brew install kubernetes-cli 5. Install Helm Helm is a package management tool for k8s. For how to install it, see https://docs.helm.sh/using_helm/#installing-helm.\n$ brew install kubernetes-helm Deploy SOFAMesh with source codes 1. Download SOFAMesh source codes $ git clone git@github.com:sofastack/sofa-mesh.git 2. Use Helm to install SOFAMesh You should change directory to sofa-mesh source code, and then use helm template to install isito crd and istio\n``` $ cd sofa-mesh $ helm template install/kubernetes/helm/istio-init --name istio-init --namespace istio-system | kubectl apply -f - $ helm template …","date":-62135596800,"description":"","dir":"projects/occlum/quick-start-run-with-sofamesh/","fuzzywordcount":1100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"7353dfd1d668eb3e2a1c8cd26acca372","permalink":"/en/projects/occlum/quick-start-run-with-sofamesh/","publishdate":"0001-01-01T00:00:00Z","readingtime":6,"relpermalink":"/en/projects/occlum/quick-start-run-with-sofamesh/","summary":"This article introduces how to use MOSN to build the Service Mesh development environment based on SOFAMesh framework, and verify some basic capabilities of MOSN, such as routing and load balancing. This article includes the following content:\n Relationship between MOSN and SOFAMesh Preparations Deploy SOFAMesh with source codes Bookinfo experiment  Relationship between MOSN and SOFAMesh As mentioned in MOSN introduction, MOSN is a Service Mesh data plane agent developed with Golang, and SOFAMesh is a large-scale implementation solution for Service Mesh, which is improved and extended based on Istio.","tags":null,"title":"Use MOSN to build Service Mesh platform","type":"projects","url":"/en/projects/occlum/quick-start-run-with-sofamesh/","wordcount":1078},{"author":null,"categories":null,"content":"Use Registry Different Registry integrations provide different ways to access Metrics.\n1. LookoutRegistry Provides the ability to count metrics by a time window. It is divided into two modes: “active” and “passive”. The passive mode is off currently.\n(1) Active mode\n You can specify the IP address of the remote agent through [Client Configuration], that is, check when start reporting, and regularly report data.\n(2) Passive mode\n This mode can be activated through [Client Configuration], and HTTP service is provided on port 19399.\n2. Connect to Prometheus The data of SOFALookout can be shared with Prometheus. In order to connect to Prometheus, you first need to add dependencies to your project:\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa.lookout\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;lookout-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa.lookout\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;lookout-reg-prometheus\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${lookout.client.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; After adding the dependencies, launch the application, and you can see the data by visiting http://localhost:9494, where 9494 is the default port, you can configure com.alipay.sofa.lookout.prometheus-exporter-server-port in application.properties to change the port.\nOnce you have the URL to access the data, you can edit a prometheus.yml to grab the project information. Assuming that the local IP address is 10.15.232.20, you can configure prometheus.yml as follows:\nscrape_configs: - job_name: \u0026amp;#39;lookout-client\u0026amp;#39; scrape_interval: 5s static_configs: - targets: [\u0026amp;#39;10.15.232.20:9494\u0026amp;#39;] With the above configuration file, you can start Prometheus locally via Docker:\ndocker run -d -p 9090:9090 -v $PWD/prometheus.yml:/etc/prometheus/prometheus.yml --name prom prom/prometheus:master Then visit http://localhost:9090 through the browser, and you can query the corresponding Metrics through PromQL.\nAn example of connecting to Prometheus is also available in SOFALookout, so you can go and see it as a reference.\n3. Connect to SpringBoot actuator In addition to Prometheus, SOFALookout can be integrated with the Actuator of SpringBoot 1.x by adding the following dependency:\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-starter-actuator\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; Then, start and visit http://localhost:8080/metrics to see the data of events logged by the SOFALookout API.\n","date":-62135596800,"description":"","dir":"projects/sofa-lookout/use-guide-registry/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"3c51ba6519cee542b459a170dabcf32b","permalink":"/en/projects/sofa-lookout/use-guide-registry/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-lookout/use-guide-registry/","summary":"Use Registry Different Registry integrations provide different ways to access Metrics.\n1. LookoutRegistry Provides the ability to count metrics by a time window. It is divided into two modes: “active” and “passive”. The passive mode is off currently.\n(1) Active mode\n You can specify the IP address of the remote agent through [Client Configuration], that is, check when start reporting, and regularly report data.\n(2) Passive mode\n This mode can be activated through [Client Configuration], and HTTP service is provided on port 19399.","tags":null,"title":"Use Registry","type":"projects","url":"/en/projects/sofa-lookout/use-guide-registry/","wordcount":297},{"author":null,"categories":null,"content":"XML mode The way to publish and reference services in xml mode is as follows. sofa:service represents publishing service, and sofa:reference represents referencing service. sofa:binding indicates the protocol for service publishing or reference.\n\u0026amp;lt;bean id=\u0026amp;#34;personServiceImpl\u0026amp;#34; class=\u0026amp;#34;com.alipay.sofa.boot.examples.demo.rpc.bean.PersonServiceImpl\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;sofa:service ref=\u0026amp;#34;personServiceImpl\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofa.boot.examples.demo.rpc.bean.PersonService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt/\u0026amp;gt; \u0026amp;lt;/sofa:service\u0026amp;gt; A service can also be published through multiple protocols, as follows:\n\u0026amp;lt;sofa:service ref=\u0026amp;#34;personServiceImpl\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofa.boot.examples.demo.rpc.bean.PersonService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt/\u0026amp;gt; \u0026amp;lt;sofa:binding.rest/\u0026amp;gt; \u0026amp;lt;sofa:binding.dubbo/\u0026amp;gt; \u0026amp;lt;/sofa:service\u0026amp;gt; Service reference\n\u0026amp;lt;sofa:reference id=\u0026amp;#34;personReferenceBolt\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofa.boot.examples.demo.rpc.bean.PersonService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt/\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt; A service can also be referenced through other protocols:\n\u0026amp;lt;sofa:reference id=\u0026amp;#34;personReferenceRest\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofa.boot.examples.demo.rpc.bean.PersonService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.rest/\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt; ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/programing-sofa-boot-xml/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"9192a93415bee3070a9be62c0f693949","permalink":"/en/projects/sofa-rpc/programing-sofa-boot-xml/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/programing-sofa-boot-xml/","summary":"XML mode The way to publish and reference services in xml mode is as follows. sofa:service represents publishing service, and sofa:reference represents referencing service. sofa:binding indicates the protocol for service publishing or reference.\n\u0026lt;bean id=\u0026#34;personServiceImpl\u0026#34; class=\u0026#34;com.alipay.sofa.boot.examples.demo.rpc.bean.PersonServiceImpl\u0026#34;/\u0026gt; \u0026lt;sofa:service ref=\u0026#34;personServiceImpl\u0026#34; interface=\u0026#34;com.alipay.sofa.boot.examples.demo.rpc.bean.PersonService\u0026#34;\u0026gt; \u0026lt;sofa:binding.bolt/\u0026gt; \u0026lt;/sofa:service\u0026gt; A service can also be published through multiple protocols, as follows:\n\u0026lt;sofa:service ref=\u0026#34;personServiceImpl\u0026#34; interface=\u0026#34;com.alipay.sofa.boot.examples.demo.rpc.bean.PersonService\u0026#34;\u0026gt; \u0026lt;sofa:binding.bolt/\u0026gt; \u0026lt;sofa:binding.rest/\u0026gt; \u0026lt;sofa:binding.dubbo/\u0026gt; \u0026lt;/sofa:service\u0026gt; Service reference\n\u0026lt;sofa:reference id=\u0026#34;personReferenceBolt\u0026#34; interface=\u0026#34;com.alipay.sofa.boot.examples.demo.rpc.bean.PersonService\u0026#34;\u0026gt; \u0026lt;sofa:binding.bolt/\u0026gt; \u0026lt;/sofa:reference\u0026gt; A service can also be referenced through other protocols:","tags":null,"title":"Use XML in SOFABoot","type":"projects","url":"/en/projects/sofa-rpc/programing-sofa-boot-xml/","wordcount":80},{"author":null,"categories":null,"content":"User guide Maven coordinator \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;bolt\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  Check release notes for the version information.\n 1. Basic functions 1.1. Implement user request processor (UserProcessor) We provide two types of user request processors: SyncUserProcessor and AsyncUserProcessor. The difference between them is that the former returns the processing result in the form of a return value in the current processor thread, while the latter has an AsyncContext stub and can call the sendResponsemethod in the current thread or an asynchronous thread to return the processing result. For examples, refer to the following two types:\n Synchronous request processor Asynchronous request processor  1.2 Implement connection event processor (ConnectionEventProcessor) We provide two connection event processors: ConnectionEventType.CONNECT and ConnectionEventType.CLOSE. You can create your own event processors and register them with the client or the server. The client side and server side can each monitor both of their connection and disconnection events.\n Process connection event Process disconnection event  1.3 Client side and server side initialization (RpcClient, RpcServer) We have provided an RpcClient and RpcServer. They can be used after going through a simple initialization of necessary functions, or after switching on the functions. The most simple example is as follows:\n Client side initialization example Server side initialization example  1.4 Basic communication model We have provided four types of communication models:\n1. Oneway calls\nThe current thread initiates a call that is not interested in the call result and is not subject to timeout control. As long as the request is sent out, the call is completed. Note: Oneway calls are not guaranteed to succeed, and the initiator of the call has no way of knowing its result. For that reason, these calls are usually used in scenarios that can be retried or that have fixed-time notifications. Network problems or machine malfunctions during the call process may result in failure. This kind of call should only be used in business scenarios that accept such exceptions. For more information, see Example.\n2. Sync calls\nThe current thread initiates a call that only completes if it receives a result within the set timeout time. If a result is not received within the timeout time, it will generate a timeout error. This is the most commonly used call type. Ensure that the timeout time is set reasonably in accordance with the opposing terminal\u0026amp;rsquo;s processing capacity. For more information, see Example.\n3. Future calls\nThe current thread initiates a call and can then move onto executing the next call after getting an RpcResponseFuture object. The get() method of the RpcResponseFuture object can be used at any time to get the result. If the response has already been returned, the result …","date":-62135596800,"description":"","dir":"projects/sofa-bolt/sofa-bolt-handbook/","fuzzywordcount":2000,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"2a0a2e3c7749dbcdceea064f6f850e33","permalink":"/en/projects/sofa-bolt/sofa-bolt-handbook/","publishdate":"0001-01-01T00:00:00Z","readingtime":10,"relpermalink":"/en/projects/sofa-bolt/sofa-bolt-handbook/","summary":"User guide Maven coordinator \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alipay.sofa\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;bolt\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;  Check release notes for the version information.\n 1. Basic functions 1.1. Implement user request processor (UserProcessor) We provide two types of user request processors: SyncUserProcessor and AsyncUserProcessor. The difference between them is that the former returns the processing result in the form of a return value in the current processor thread, while the latter has an AsyncContext stub and can call the sendResponsemethod in the current thread or an asynchronous thread to return the processing result.","tags":null,"title":"User guide","type":"projects","url":"/en/projects/sofa-bolt/sofa-bolt-handbook/","wordcount":1988},{"author":null,"categories":null,"content":"﻿## Version release\nVersion No. Major, minor, and revision version numbers are used. For example 2.0.0.\nRefer to: http://semver.org/lang/zh-CN/.\n Major version number: All versions within a major version number must be compatible with each other. They are not necessarily compatible with other major versions. However, it is best to be downward compatible. Minor version number: represents feature enhancement. The larger the version number, more features it has. Revision version number: represents the BugFix version. Such versions are only used for bug fixing. The larger the version number, the more stable the application.  Version maintenance At most two versions can be maintained simultaneously.\nFor example, if the current major version is 2.2.0, the BugFix version 2.1.x will be maintained and bugs in version 2.0.x will no longer be fixed and a version upgrade is recommended.\nRelease process  Daily development uses the SNAPSHOT version, such as 2.0.0-SNAPSHOT. When the modified version is officially released, the version number is revised to a formal version, such as 2.0.0. After release, the next version is pulled up, for example, 2.1.0-SNAPSHOT.  ","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-jarslink-version/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"b82f2d74eff3937e10f15b13cb503751","permalink":"/en/projects/sofa-boot/sofa-jarslink-version/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-boot/sofa-jarslink-version/","summary":"﻿## Version release\nVersion No. Major, minor, and revision version numbers are used. For example 2.0.0.\nRefer to: http://semver.org/lang/zh-CN/.\n Major version number: All versions within a major version number must be compatible with each other. They are not necessarily compatible with other major versions. However, it is best to be downward compatible. Minor version number: represents feature enhancement. The larger the version number, more features it has. Revision version number: represents the BugFix version.","tags":null,"title":"Version release","type":"projects","url":"/en/projects/sofa-boot/sofa-jarslink-version/","wordcount":175},{"author":null,"categories":null,"content":"Version number The system adopts a three-digit versioning scheme. The three digits respectively are major version number, minor version number, and revision number, for example: 5.1.2.\nFor more information, see the http://semver.org/lang/zh-CN/.\n Major version number: All versions in the major version number must be compatible with each other. It is not necessary to be fully compatible with other major version numbers, but it is best to have backward compatibility. Minor version number: Represents new feature enhancements. The larger the version number, the richer the feature. Revision number: Represents the BugFix version. The revision number is only for bug fixes. The larger the version number, the more stable it is.  Version maintenance You can maintain up to two versions at the same time.\nFor example, the current trunk is 5.3.0, then the bugfix branch of 5.2.x will be maintained. When any bugs arise in 5.1.x, users are prompted to upgrade the system.\nRelease process  The daily development branch uses the SNAPSHOT version, for example: 5.3.0-SNAPSHOT. When it comes to official release, you can modify the version to official version, for example: 5.3.0. Pull up the next version after release, for example: 5.3.1-SNAPSHOT.  ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/version-release/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"604f113607e6815757f4d1907190c13c","permalink":"/en/projects/sofa-rpc/version-release/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/version-release/","summary":"Version number The system adopts a three-digit versioning scheme. The three digits respectively are major version number, minor version number, and revision number, for example: 5.1.2.\nFor more information, see the http://semver.org/lang/zh-CN/.\n Major version number: All versions in the major version number must be compatible with each other. It is not necessary to be fully compatible with other major version numbers, but it is best to have backward compatibility. Minor version number: Represents new feature enhancements.","tags":null,"title":"Version release","type":"projects","url":"/en/projects/sofa-rpc/version-release/","wordcount":191},{"author":null,"categories":null,"content":"Version number Major, minor, and revision version numbers are used. For example, 1.0.0.\nFor more information, see https://semver.org/\n Major version number: All versions with the same major version number must be compatible with each other. They are not necessarily fully compatible with other major versions. However, it is best to be downward compatible. Minor version number: represents feature enhancement. The larger the version number, the more features it has. Revision version number: represents the BugFix version. Such versions are only used for bug fixing. The larger the version number, the more stable the application.  Version maintenance Up to two versions can be maintained simultaneously.\nFor example, if the current version of the master branch code is 1.2.0, the BugFix branch 1.1.x will be maintained, but bugs in branch 1.0.x will no longer be fixed. In this case, a version upgrade is recommended.\nRelease process  The develop branches use SNAPSHOT versions, for example, 1.0.0-SNAPSHOT. Upon formal release, the snapshot version is modified to the formal version, for example 1.0.0. After the formal release, the next version is pulled, for example, 1.0.1-SNAPSHOT.  ","date":-62135596800,"description":"","dir":"projects/sofa-dashboard/version-rule/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"a2093bdf478bdff0e15a2de70e522d03","permalink":"/en/projects/sofa-dashboard/version-rule/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-dashboard/version-rule/","summary":"Version number Major, minor, and revision version numbers are used. For example, 1.0.0.\nFor more information, see https://semver.org/\n Major version number: All versions with the same major version number must be compatible with each other. They are not necessarily fully compatible with other major versions. However, it is best to be downward compatible. Minor version number: represents feature enhancement. The larger the version number, the more features it has. Revision version number: represents the BugFix version.","tags":null,"title":"Version rules","type":"projects","url":"/en/projects/sofa-dashboard/version-rule/","wordcount":180},{"author":null,"categories":null,"content":"Version number SOFARegistry uses a three-digit version number in the form of major, minor, and patch. For example, 5.2.0.\nFor more information, see https://semver.org/.\n Major version number: All versions with the same major version number must be compatible with each other. They are not necessarily fully compatible with other major versions. However, it is best to be downward compatible. Minor version number: represents feature enhancement. The larger the version number, the more features it has. Patch number: represents the BugFix version. Such versions are only used for bug fixing. The larger the version number, the more stable the application.  Version maintenance Up to two versions can be maintained simultaneously.\nFor example, if the current version of the master branch code is 5.4.0, the BugFix branch of version 5.3.x will be maintained, but bugs in branch 5.2.x will no longer be fixed. Therefore, a version upgrade for 5.2.x is recommended.\nRelease process  The develop branches use SNAPSHOT versions, for example, 5.3.0-SNAPSHOT. Upon formal release, SNAPSHOT is replaced with a formal version number, for example 5.3.0. After the formal release, the next version is pulled, for example, 5.3.1-SNAPSHOT.  ","date":-62135596800,"description":"","dir":"projects/sofa-registry/release-standard/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"71aad9cbc42aba3d9f875ae9169cf005","permalink":"/en/projects/sofa-registry/release-standard/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-registry/release-standard/","summary":"Version number SOFARegistry uses a three-digit version number in the form of major, minor, and patch. For example, 5.2.0.\nFor more information, see https://semver.org/.\n Major version number: All versions with the same major version number must be compatible with each other. They are not necessarily fully compatible with other major versions. However, it is best to be downward compatible. Minor version number: represents feature enhancement. The larger the version number, the more features it has.","tags":null,"title":"Version rules","type":"projects","url":"/en/projects/sofa-registry/release-standard/","wordcount":186},{"author":null,"categories":null,"content":"﻿With SOFABoot, we can directly view the version of SOFA middleware and other detailed information in the browser.\nIntroducing SOFABoot Infra Dependency To view the version information of the SOFA middleware directly in the browser in SOFABoot, all you need to do is add the following to the Maven dependency:\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;infra-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; Version Information Viewing After an application started successfully, you can visit http://localhost:8080/sofaboot/versions in the browser to view the version information of the SOFA middleware, the response such as:\n[ { GroupId: \u0026amp;#34;com.alipay.sofa\u0026amp;#34;, Doc-Url: \u0026amp;#34;https://github.com/sofastack/sofa-boot\u0026amp;#34;, ArtifactId: \u0026amp;#34;infra-sofa-boot-starter\u0026amp;#34;, Build-Time: \u0026amp;#34;2018-04-05T20:55:22+0800\u0026amp;#34;, Commit-Time: \u0026amp;#34;2018-04-05T20:54:26+0800\u0026amp;#34;, Commit-Id: \u0026amp;#34;049bf890bb468aafe6a3e07b77df45c831076996\u0026amp;#34;, Version: \u0026amp;#34;2.4.0\u0026amp;#34; } ] ** Note: In SOFABoot 3.x, the endpoint path has been changed from sofaboot/versions to actuator/versions**.\n","date":-62135596800,"description":"","dir":"projects/sofa-boot/view-versions/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"c6b6d22e9038aa1f5e4ce74449ba1cda","permalink":"/en/projects/sofa-boot/view-versions/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-boot/view-versions/","summary":"﻿With SOFABoot, we can directly view the version of SOFA middleware and other detailed information in the browser.\nIntroducing SOFABoot Infra Dependency To view the version information of the SOFA middleware directly in the browser in SOFABoot, all you need to do is add the following to the Maven dependency:\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alipay.sofa\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;infra-sofa-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; Version Information Viewing After an application started successfully, you can visit http://localhost:8080/sofaboot/versions in the browser to view the version information of the SOFA middleware, the response such as:","tags":null,"title":"View version","type":"projects","url":"/en/projects/sofa-boot/view-versions/","wordcount":115},{"author":null,"categories":null,"content":"The warm-up weight feature allows the client machine to distribute traffic based on the corresponding weight of the server. This feature is also often used in the scenario where a few machines within a cluster are being started. The server machines can be warmed up in a short time with the traffic weight function, and then continue to receive the normal traffic.\nThe operating mechanism is as follows:   When the server service starts, it pushes its own warm-up duration, weight during warm-up, and normal weight after warm-up to the Service Registry. As shown above, Service B points to Service Registry.\n  When referencing service, the client obtains the warm-up weight information of each service instance. As shown above, Service Registry points to client.\n  When calling service, the client distributes the traffic according to the warm-up weight of the address where the service is located. As shown above, the client points to Service A and Service B. Service A has completed warm-up, and its weight is 100 by default. Service B is in the warm-up period, and its weight is 10. Therefore, their traffic is 100%110 and 10%110 respectively.\n  This feature is used as follows:\nProviderConfig\u0026amp;lt;HelloWordService\u0026amp;gt; providerConfig = new ProviderConfig\u0026amp;lt;HelloWordService\u0026amp;gt;() .setWeight(100) .setParameter(ProviderInfoAttrs.ATTR_WARMUP_WEIGHT,\u0026amp;#34;10\u0026amp;#34;) .setParameter(ProviderInfoAttrs.ATTR_WARM_UP_END_TIME, \u0026amp;#34;12000\u0026amp;#34;); As above, the warm-up duration of the service is 12s, the weight is 10 during warm-up, and the normal weight after warm-up is 100. If the service is published on two machines, such as machine A and B, and the machine A is in the warm-up period with the above configuration, while B has already completed warm-up, and the normal weight is 200, then when the client calls the service, the proportion of traffic distribution is 10:200. After the machine A is warmed up, the traffic distribution ratio is 100:200.\nIn SOFABoot, the warm-up duration and the weight during and after warm-up can be configured as follows:\n\u0026amp;lt;sofa:reference id=\u0026amp;#34;sampleRestFacadeReferenceBolt\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofa.endpoint.facade.SampleFacade\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;sofa:global-attrs weight=\u0026amp;#34;100\u0026amp;#34; warm-up-time=\u0026amp;#34;10000\u0026amp;#34; warm-up-weight=\u0026amp;#34;1000\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt; ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/provider-warmup-weight/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"b9e320dfaa4f9700ecdca67d76e07d54","permalink":"/en/projects/sofa-rpc/provider-warmup-weight/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/en/projects/sofa-rpc/provider-warmup-weight/","summary":"The warm-up weight feature allows the client machine to distribute traffic based on the corresponding weight of the server. This feature is also often used in the scenario where a few machines within a cluster are being started. The server machines can be warmed up in a short time with the traffic weight function, and then continue to receive the normal traffic.\nThe operating mechanism is as follows:   When the server service starts, it pushes its own warm-up duration, weight during warm-up, and normal weight after warm-up to the Service Registry.","tags":null,"title":"Warm-up weight","type":"projects","url":"/en/projects/sofa-rpc/provider-warmup-weight/","wordcount":319},{"author":null,"categories":null,"content":"X-Protocol X-Protocol is a special common protocol supported by SOFAMesh. It can access different RPC protocols in a unified manner. Because it doesn\u0026amp;rsquo;t require to parse protocols, it can not only provide higher performance, but also reduce the development cost of accessing new protocols.\n","date":-62135596800,"description":"","dir":"projects/sofa-mesh/pilot-x-protocol/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"220f4a76b277463bb1f7201519950450","permalink":"/en/projects/sofa-mesh/pilot-x-protocol/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-mesh/pilot-x-protocol/","summary":"X-Protocol X-Protocol is a special common protocol supported by SOFAMesh. It can access different RPC protocols in a unified manner. Because it doesn\u0026rsquo;t require to parse protocols, it can not only provide higher performance, but also reduce the development cost of accessing new protocols.","tags":null,"title":"X-Protocol","type":"projects","url":"/en/projects/sofa-mesh/pilot-x-protocol/","wordcount":44},{"author":null,"categories":null,"content":"X-Protocol 协议是 SOFAMesh 支持的特殊通用协议，能够以统一的方式接入不同的 RPC 协议，因为无需进行协议解析，不仅能够提供更高的性能, 更能降低接入新协议的开发成本。\n","date":-62135596800,"description":"","dir":"projects/sofa-mesh/pilot-x-protocol/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"220f4a76b277463bb1f7201519950450","permalink":"/projects/sofa-mesh/pilot-x-protocol/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-mesh/pilot-x-protocol/","summary":"X-Protocol 协议是 SOFAMesh 支持的特殊通用协议，能够以统一的方式接入不同的 RPC 协议，因为无需进行协议解析，不仅能够提供更高的性能, 更能降低接入新协议的开发成本。","tags":null,"title":"X-Protocol","type":"projects","url":"/projects/sofa-mesh/pilot-x-protocol/","wordcount":70},{"author":null,"categories":null,"content":"To use Zookeeper as service registry center, you only need to configure it in application.properties as follows:\ncom.alipay.sofa.rpc.registry.address=zookeeper://127.0.0.1:2181 Note: Considering the real-time nature of the service, the following features are not supported currently.\nSOFABoot RPC also provides a cache file (not supported currently), which is used for service discovery when ZooKeeper is not available. The way to configure this cache file is as follows:\ncom.alipay.sofa.rpc.registry.address=zookeeper://xxx:2181?file=/home/admin/registry Zookeeper Auth When users need to auth the providers and consumers, they can use a auth key to write or read the dictionary normally, only when they use the same key, zookeeper server will process these requests.\nSOFARPC API Usage If you use SOFARPC API directly, you can add two parameters to registry config.\nparameters.put(\u0026amp;#34;scheme\u0026amp;#34;, \u0026amp;#34;digest\u0026amp;#34;); //if there was multi auth infos, you need to set the value as user1:passwd1,user2:passwd2 parameters.put(\u0026amp;#34;addAuth\u0026amp;#34;, \u0026amp;#34;sofazk:rpc1\u0026amp;#34;); registryConfig = new RegistryConfig() .setProtocol(\u0026amp;#34;zookeeper\u0026amp;#34;) .setAddress(\u0026amp;#34;127.0.0.1:2181/authtest\u0026amp;#34;) .setParameters(parameters); then if another provider or consumer use a different auth info, they will not access these providers or consumers.\nXML Usage You only need to set it in application.properties\ncom.alipay.sofa.rpc.registry.address=zookeeper://xxx:2181?file=/home/admin/registry\u0026amp;amp;scheme=digest\u0026amp;amp;addAuth=sofazk:rpc1 ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/registry-zookeeper/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"71d6486c5577cc85d84c56688cdf2af1","permalink":"/en/projects/sofa-rpc/registry-zookeeper/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-rpc/registry-zookeeper/","summary":"To use Zookeeper as service registry center, you only need to configure it in application.properties as follows:\ncom.alipay.sofa.rpc.registry.address=zookeeper://127.0.0.1:2181 Note: Considering the real-time nature of the service, the following features are not supported currently.\nSOFABoot RPC also provides a cache file (not supported currently), which is used for service discovery when ZooKeeper is not available. The way to configure this cache file is as follows:\ncom.alipay.sofa.rpc.registry.address=zookeeper://xxx:2181?file=/home/admin/registry Zookeeper Auth When users need to auth the providers and consumers, they can use a auth key to write or read the dictionary normally, only when they use the same key, zookeeper server will process these requests.","tags":null,"title":"Zookeeper","type":"projects","url":"/en/projects/sofa-rpc/registry-zookeeper/","wordcount":174},{"author":null,"categories":null,"content":"ZooKeeper Adapter ZooKeeper Adapter is an Adapter plug-in developed in accordance with the Istio registry center extension mechanism. It is used for docking all microservices frameworks that use ZooKeeper as a registry center. Currently, ZooKeeper Adapter supports SOFARPC and will be available for Dubbo soon.\nZooKeeper Adapter uses ZooKeeper\u0026amp;rsquo;s watch mechanism to listen to the change events of service registration information, providing better real-time performance than polling.\n","date":-62135596800,"description":"","dir":"projects/sofa-mesh/pilot-zookeeper-adapter/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1611070649,"objectID":"a174a0de8dd47df7c3043f6d49fa1b07","permalink":"/en/projects/sofa-mesh/pilot-zookeeper-adapter/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/en/projects/sofa-mesh/pilot-zookeeper-adapter/","summary":"ZooKeeper Adapter ZooKeeper Adapter is an Adapter plug-in developed in accordance with the Istio registry center extension mechanism. It is used for docking all microservices frameworks that use ZooKeeper as a registry center. Currently, ZooKeeper Adapter supports SOFARPC and will be available for Dubbo soon.\nZooKeeper Adapter uses ZooKeeper\u0026rsquo;s watch mechanism to listen to the change events of service registration information, providing better real-time performance than polling.","tags":null,"title":"ZooKeeper Adapter","type":"projects","url":"/en/projects/sofa-mesh/pilot-zookeeper-adapter/","wordcount":67},{"author":null,"categories":null,"content":"Zookeeper Adapter 是按照 Istio 注册中心扩展机制开发的一个 Adapter 插件，用于对接所有使用 Zookeeper 作为注册中心的微服务框架。目前已经支持了 SOFARPC，很快将提供对于 Dubbo 的支持。\nZookeeper Adapter 使用 zk 的 watch 机制监听服务注册信息的变化事件，提供了比轮询机制更好的实时性。\n","date":-62135596800,"description":"","dir":"projects/sofa-mesh/pilot-zookeeper-adapter/","fuzzywordcount":200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"a174a0de8dd47df7c3043f6d49fa1b07","permalink":"/projects/sofa-mesh/pilot-zookeeper-adapter/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-mesh/pilot-zookeeper-adapter/","summary":"Zookeeper Adapter 是按照 Istio 注册中心扩展机制开发的一个 Adapter 插件，用于对接所有使用 Zookeeper 作为注册中心的微服务框架。目前已经支持了 SOFARPC，很快将提供对于 Dubbo 的支","tags":null,"title":"Zookeeper Adpater","type":"projects","url":"/projects/sofa-mesh/pilot-zookeeper-adapter/","wordcount":110},{"author":null,"categories":null,"content":"在介绍 Biz 生命周期 时，我们提到了有三种方式控制 Biz 的生命周期，并且介绍了使用客户端 API 实现 Biz 的安装、卸载、激活。在这一章节我们介绍如何使用 SOFAArk 提供的动态配置插件，通过 Zookeeper 下发指令，控制 Biz 的生命周期。\n引入依赖 SOFAArk 提供了 config-ark-plugin 对接 Zookeeper 配置中心，用于运行时接受配置，达到控制 Biz 生命周期，引入如下依赖：\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;config-ark-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${sofa.ark.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 配置 ZK 地址 参考 SOFAArk 配置，在 SOFAArk 配置文件 conf/ark/bootstrap.properties 增加如下配置：\ncom.alipay.sofa.ark.config.address=zookeeper://ip:port 配置维度 SOFAArk 启动后，会在 ZK 注册两个节点配置，分别是宿主应用维度和 IP 维度：\n sofa-ark/${com.alipay.sofa.ark.master.biz}/   宿主应用维度配置，应用启动时，会拉取该维度配置，控制相关 Biz 的部署；应用重启后，配置不会丢失\n  sofa-ark/${com.alipay.sofa.ark.master.biz}/ip/   IP 维度配置，应用重启后丢失，通常用于运行时控制单台机器的 Biz 行为\n 通过写这两个节点的配置，可以控制相关机器和应用的 Biz 运行时状态。\n配置形式 下面介绍配置的形式，动态配置采用状态声明指令，SOFAArk 收到配置后，会根据状态描述解析出具体的指令（包括 install，uninstall, switch），指令格式如下：\nbizName:bizVersion:bizState?k1=v1\u0026amp;amp;k2=v2\n多条指令使用 ; 隔开，单条指令主要由 biz 名称，biz 版本，biz 预期状态及参数组成。简单记住一点，状态配置是描述指令推送之后，所有非宿主 Biz 的状态；\n例如当前 SOFAArk 容器部署了两个应用 A，B，版本均为 1.0，其中 A 应用为宿主应用，因为宿主应用不可卸载，因此不需要考虑宿主应用，可以简单认为当前容器的 Biz 状态声明为：\n B:1.0:Activated\n 如果此时你希望安装 C 应用，版本为 1.0，文件流地址为 urlC，那么推送指令应为：\n B:1.0:Activated;C:1.0:Activated?bizUrl=urlC\n 操作继续，如果你又希望安装安装 B 应用，版本为 2.0，文件流地址为 urlB，且希望 2.0 版本处于激活状态，那么你推送的指令应为：\n B:1.0:Deactivated;B:2.0:Actaivated?bizUrl=urlB;C:1.0:Activated\n  解释下为什么是这样配置指令，因为 SOFAArk 只允许应用一个版本处于激活状态，如果存在其他版本，则应处于非激活状态；所以当希望激活 B 应用 2.0 版本时，B 应用 1.0 版本应该声明为非激活状态。另外你可能注意到了 C 应用参数 urlC 不用声明了，原因是目前只有当安装新 Biz 时，才有可能需要配置参数 bizUrl，用于指定 biz 文件流地址，其他场景下，参数的解析没有意义。\n 操作继续，如果你希望卸载 B 应用 2.0 版本，激活 B 应用 1.0 版本，卸载 C 应用，那么推送的指令声明为：\n B:1.0:Activated\n 从上面的操作描述看，在推送动态配置时，只需要声明期望的 Biz 状态即可，SOFAArk 会根据状态声明推断具体的执行指令，并尽可能保持服务的连续性，以上面最后一步操作为例，SOFAArk 推断的执行指令顺序如下：\n 执行 switch 指令，激活 B 应用 1.0 版本，钝化 B 应用 2.0 版本，保证服务连续性 执行 uninstall 指令，卸载 B 应用 2.0 版本 执行 uninstall 指令，卸载 C 应用 1.0 版本  注意事项 目前只有在安装新 Biz 时才可能使用指令参数 bizUrl，用于指定 Biz 文件流地址。文件流地址字符串是能够直接构建 URL 对象，例如 file://xxx 或者 http://xxx. 安装新 Biz 时，参数 bizUrl 不是必须的，SOFAArk 提供了扩展点：\n@Extensible public interface BizFileGenerator { File createBizFile(String bizName, String bizVersion); } 用于扩展实现，根据 biz 名称和 biz 版本返回 biz 文件。\n","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-zk-config/","fuzzywordcount":1200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"c675734b1cb5fa546f96a31d8b9e3533","permalink":"/projects/sofa-boot/sofa-ark-zk-config/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/sofa-boot/sofa-ark-zk-config/","summary":"在介绍 Biz 生命周期 时，我们提到了有三种方式控制 Biz 的生命周期，并且介绍了使用客户端 API 实现 Biz 的安装、卸载、激活。在这一章节我们介绍如何使用 SOFAArk 提供的","tags":null,"title":"Zookeeper 配置","type":"projects","url":"/projects/sofa-boot/sofa-ark-zk-config/","wordcount":1155},{"author":null,"categories":null,"content":"打开 ACTS IDE 在 Package 视图下，右键含 @Test 注解的函数名，ACTS 功能 -\u0026amp;gt; 修改测试用例，如下图：\n编写测试数据 准备入参 根据被测的接口方法的入参（类型、顺序、数量）正确准备入参数据，简单类型包括 String、Date、Integer、Float、Double、Long、Short、Byte（包含其对应的基本类型，即 int、float 等）；复杂类型为 List、Map、Set、自定义类、Java 定义的类以及前面五者的嵌套等。\n简单入参 入参设置上右键 -\u0026amp;gt; 模版选择 -\u0026amp;gt; 简单入参选择：\n导入简单入参后，值直接在这里填写； 自上而下表示被测接口方法的第1个、第2个和第3个参数，右键可以调节顺序。\n复杂入参 如图27所示，AccountTransRequest 和 BusinessActionContext 类需要生成入参模板，一般情况下，在一键生成测试脚本时会自动生成方法的入参和返回结果的类模板，打开 ACTS IDE 可对其进行编辑，如图28。\nlist map 以示例2为例（Set 与此类似） 图32中，演示示例2的方法入参为 Map\u0026amp;lt;String,Object\u0026amp;gt; 类型。由于 Object 不是具体类型，如果要设置 Object 为复杂对象，则需要去编辑 YAML。例如设置 Object 为 AccountTransResult 类型，则按照如下编辑：\nenum 代码样例：\n 在 ACTS IDE 中编辑如下：   如果枚举嵌套在其他类中，则在该类的 CSV 模版中设置枚举的值为 DEBIT；\n  用例数据 YAML 中，如图37：\n  interestRecoverTypeEnum: !!com.alipay.fc.loancore.common.util.enums.InterestRecoverTypeEnum \u0026amp;#39;ALL\u0026amp;#39; 覆盖 prepare 方法，通过 ActsRuntimeContext 的方法，快速获取和设置用例入参，如图38所示：\n 获取所有入参：List getInputParams() 按位置获取：Object getInputParamByPos(int i) 新增用例参数：void addInputParam(Object obj)  准备 DB 数据-单列场景 如图39，在数据库准备设置位置右键，选择好要插入的 DB 模板（请先确保该DB模板已经生成），图中1、2、3步骤之后点击 OK 即插入 DB 准备模板，如图41，可对要插入 DB 的数据进行编辑：\n选中一列数据，点击复制，按此方法可复制多列数据，然后进行编辑即可：\n数据依赖标记：\nY: 插入 N：不插入 C：以此为where条件对插入后的数据进行清理 F：数据库函数 L: 大字段换行准备，准备方式为A=B;C=D 生成期望结果的对象模型后，在 ACTS IDE 界面中，期望结果设置右键 -\u0026amp;gt; 模版选择，见下图。\nY: 校验 N：不校验 D：时间偏移值比较，如 D200 ME：map 默认全 key 校验，ME则以期望 key 为准，实际值多余期望值的 key 不予校验 对于返回结果的时间 Date 类型字段校验说明：\n Y | null -\u0026amp;gt; 代表期望为 null Y | 2015-01-01 00:00:00 -\u0026amp;gt; 代表期望为 2015-01-01 00:00:00 N | null -\u0026amp;gt; 代表不校验 D200 | 2015-01-01 00:00:00/null -\u0026amp;gt; 代表与 2015-01-01 00:00:00/new Date() 相差 200 秒  编码方式准备期望结果 覆盖 prepare 方法，通过 ActsRuntimeContext 的如下方法，快速获取和设置期望结果。\n 获取期望结果：Object getExpectResult() 设置期望结果：Boolean setExpectResult(Object objToSet)  准备期望 DB 数据 准备期望 DB 数据-单列场景 在数据库期望设置里配置，操作参考准备 DB 数据-单列场景\n准备期望 DB 数据-多列场景 在数据库期望设置里配置，操作参考准备 DB 数据-多列场景\n期望 DB 数据的 flag 说明 数据校验标记：\nY: 校验 N：不校验 C：以此为条件 select 然后比较，如果结果有多个，则返回的结果所有记录都要和当前需要校验的数据进行校验 CN： 这个 flag 表示当前这张表中以 C 和 CN 为条件查询出的结果为空 D200：表示对比时间的时候误差 200s 之内都算通过，日期类型的格式为：today L： 数据库大字段换行数据校验，准备方式为 A=B;C=D P：DB 大字段校验，以期望结果的 kv 为基准，对 DB 大字段里的 kv 进行校验，要求 DB 里的 kv 之间是换行分隔 R：正则匹配校验 准备期望异常数据 编码方式准备期望异常数据 部分系统封装的异常类没有默认构造函数，这样通过模版添加的异常结果在加载 YAML 时会有问题（无默认构造函数无法构造当前类），需要通过代码方式，结合自定义参数编写异常脚本，如下图：\n自定义数据-用途 用户自定义的各类型数据，用于测试过程中自由使用。\n自定义数据-数据类型 数据类型可参考 入参 部分\n编码方式准备自定义数据 快速获取和设置自定义参数：\n 获取全部自定义参数：getParamMap getParamMap() 按 key 获取：Object getParamByName(String paraName) 新增自定义参数：void addOneParam(String paraName, Object paraObj) 替换自定义参数：void setParamMap(Map\u0026amp;lt;String,Object\u0026amp;gt; paramMap) 以范型方式获取自定义参数：T getParamByNameWithGeneric(String paraName)  不同数据类型编辑方式 简单类型编辑 以自定义参数设置添加简单类型数据为例。如图46，自定义参数设置右键 -\u0026amp;gt; 模板选择，弹框填写入参名字：\n以自定义参数设置添加复杂对象数据为例\n参照 简单类型编辑，在弹框填写好入参名字。然后在模板选择列表中（如果找不到想要的复杂对象，请先生成相应的数据模板），选择一个复杂对象，然后 add，点击 OK 确认。\n以自定义参数设置添加 List\u0026amp;lt;String\u0026amp;gt; 为例，模板选择 list 模板：\n可参照入参中有关 map 部分。\nenum 编辑 可参照入参中有关 enum 部分。\n右键功能说明 复制当前节点 在用例名上右键，修改用例名称：\n在用例名上右键，复制当前用例：\n为了提高期望数据值（返回结果和 DB 数据）的快速填写，框架提供了预跑返填功能，一个用例准备好入参、准备数据等，用例执行的基本数据后，可先不必填写期望数据，用例运行起来后，框架可自动捕捉返回结果、DB 变更数据等，运行后打开编辑器点击 预跑返填，可填充指定用例的期望数据。 …","date":-62135596800,"description":"","dir":"projects/sofa-acts/usage-ide/","fuzzywordcount":2100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"697e7e6d35a2e058f3ca8b0a72032690","permalink":"/projects/sofa-acts/usage-ide/","publishdate":"0001-01-01T00:00:00Z","readingtime":5,"relpermalink":"/projects/sofa-acts/usage-ide/","summary":"打开 ACTS IDE 在 Package 视图下，右键含 @Test 注解的函数名，ACTS 功能 -\u0026gt; 修改测试用例，如下图： 编写测试数据 准备入参 根据被测的接口方法的入参（类型、顺序、数量","tags":null,"title":"一站式编辑","type":"projects","url":"/projects/sofa-acts/usage-ide/","wordcount":2065},{"author":null,"categories":null,"content":"快速理解 ACTS 的模型 在写测试用例的过程中，需要预先准备一些 DB 表、方法入参的数据，或者需要校验一些 DB 表、返回结果的数据，这些数据可以以模版的形式保存下来，在编辑用例时，可以方便的导入这些数据到准备数据或者校验数据，实现数据复用。目前 ACTS 模型可以分为 DB 模型和类模型。\n常规的测试用例编写，DB 、方法入参、返回结果等领域模型的数据准备是通过测试代码组织的，随着业务复杂度，领域模型复杂度也在不断增加，尤其在金融级业务用，往往一个类或者数据表有数十个属性或者字段，类与类的嵌套也是随处可见，代码构造复杂对象变得十分困难且容易疏漏，问题频现：\n 表太多容易遗漏，排查时间太长； 表的字段名记不住，时不时写错； 接口入参数量多类型复杂，看见就头疼； 类的属性太多，容易遗漏重要属性； 嵌套构造对象，不断的 new 和 set 赋值； 继承和实现关系复杂，遗漏重要属性；  ACTS 的模版有可以有效应对上述问题，通过将类和表固化为 CSV，类的结构一目了然，通过类、数据表的模版可以快速的模版化地创建对象，并序列化到 YAML 文件中，使用 ACTS IDE 可以方便的管理用例数据。\n模型存储位置 在 test 模块的 resource/model 目录可以查看已经存在的模型。\n数据表模型生成 数据表模型样例 1. 校验 flag 说明\n```plain Y: 插入 N：不插入 C：以此为 where 条件对插入后的数据进行清理 F：数据库函数 L: 大字段换行准备，准备方式为 A=B;C=D ```  2. 用例编辑使用模型快速导入数据\n使用 ACTS IDE 编辑 DB 表数据（包括准备表数据、期望表数据）时，可右键新增指定表的模型，用于直接从表模型的 CSV 中导入表的全部字段和值，以便快速编辑。 DB 模版的使用可参考准备 DB 数据。\n生成表模型 点击 OK 后生成模板，如图9：\n同时支持不配置直连获取表结构的方式生成表模型，即在 DO 类上右键根据类生成表模型： DO 类上右击 -\u0026amp;gt; ACTS 功能 -\u0026amp;gt; 生成 DO 模型：\n对象模型生成 对象模型样例 一个复杂对象是一个闭包，不但包含其自身模型还包含其嵌套对象的模型。\nACTS 使用模型快速导入数据、编辑复杂对象（包括入参、返回结果和异常等），在 ACTS IDE 中可右键选择类模型，用于构建该类的对象并赋值以便快速编辑。\n生成方法 有两种方式： 1.待构建模型的类定义的任意方法上点击； 1.接口定义的方法上点击，详细操作看下图示例。\n使用 IDEA 的同学请注意：请先确保代码已编译，IDEA 不会自动编译而需要手动 mvn clean install 或者打开自动编译 File -\u0026amp;gt; Settings -\u0026amp;gt; Build,Execution,Deployment -\u0026amp;gt; Compiler -\u0026amp;gt; Make project automatically。\nACTS IDE 生成对象模型 （1）待构建模型的类定义的任意方法上点击，生成当前类的模型\n（2）接口定义任意方法上点击，生成当前接口中，所有方法的复杂入参、复杂返回结果的模型\n","date":-62135596800,"description":"","dir":"projects/sofa-acts/usage-model/","fuzzywordcount":1100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"65aaf62462b3b0ea142ca75a5b61eb0d","permalink":"/projects/sofa-acts/usage-model/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/sofa-acts/usage-model/","summary":"快速理解 ACTS 的模型 在写测试用例的过程中，需要预先准备一些 DB 表、方法入参的数据，或者需要校验一些 DB 表、返回结果的数据，这些数据可以以模版的形式保","tags":null,"title":"一键模型化","type":"projects","url":"/projects/sofa-acts/usage-model/","wordcount":1028},{"author":null,"categories":null,"content":"快速理解 ACTS 中的脚本 如果你是一个经常编写测试用例的同学，是不是经常苦于这样的问题：\n 不断的 assertEquals 写得快吐了，重复性编码毫无创意； 少一个 assert 容易假绿，错一个败坏心情； 场景一旦复杂，测试代码比业务代码还要长，写起来痛不欲生； 每换一个应用，之前写的工具类就要搬一次；  左图为 TestNG 用例，右图为 ACTS 用例，重复性代码一去不回，代码体积明显缩小。区别于普通测试脚本，ACTS 脚本继承自 ActsTestBase 类，封装了数据加载、驱动、执行引擎和校验规则，无需用户来组织清理数据、准备数据、执行用例和校验结果，对于简单业务可以做到零编码，极大释放代码编写和后期维护成本。\n测试脚本生成 前提条件：务必 mvn 编译工程和生成对象模型，否则会造成 ACTS IDE 不可预料的错误，如无法编辑、数据不正确等。\n接口定义的方法上点击，选择 ACTS 功能 -\u0026amp;gt; 生成测试用例。\n测试脚本运行 方法：右键 ACTS 脚本中的被测方法，选择 TestNG 来执行测试脚本，如下图：\n指定测试脚本运行   在 src/test/resource/config/acts-config.properties 中配置 test_only＝^T，表示只跑用例名称以 T 开头的用例，^T 也可以换成其他正则表达式；\n  修改要测试的用例名称，在用例名前面加 T，ACTS 运行时时仅执行用例名称以 T 开头的用例。\n  脚本用例拆分功能 默认每个测试脚本的所有用例数据保存在同一个 YAML 中，ACTS 支持用例数据根据开关 spilt_yaml_by_case 来决定同一测试脚本的所有用例数据存储在一个 YAML 中还是每个用例存储为一个 YAML。 开关默认为关闭，即同一测试脚本的所有测试数据存储在一个 YAML 文件中。\n在 acts-config.properities 中设置 spilt_yaml_by_case=true 即可打开开关，之后新生成测试脚本时每个用例对应一个单独的以 caseId 命名的 YAML文件，拆分的方式可以降低多人研发同一接口带来的文件冲突问题。\n此外，为了支持将老的 YAML 文件按用例拆分，ACTS 提供了工具类，如下，支持将指定脚本下，指定路径的 YAML 文件按用例拆分。\n BaseDataUtil.saveYamlDataToCaseByCase\n 注意：拆分后，建议先给原有 YAML 重命名做备份，然后打开用例编辑器检查拆分后的文件内容是否正确，确认无误后可删除原有 YAML 文件，两者不能并存。  编码方式准备数据 ACTS 提供了数据自定义 API 接口，封装于 ActsRuntimeContext 类中，如下：\n  快速获取和设置自定义参数\n获取全部自定义参数：getParamMap getParamMap() 按 key 获取：Object getParamByName(String paraName) 新增自定义参数：void addOneParam(String paraName, Object paraObj) 替换自定义参数：void setParamMap(Map\u0026amp;lt;String, Object\u0026amp;gt; paramMap) 泛型方式获取自定义参数：T getParamByNameWithGeneric(String paraName)\n  快速获取和设置用例入参\n获取所有入参：List getInputParams() 按位置获取：Object getInputParamByPos(int i) 新增用例参数：void addInputParam(Object obj)\n  快速获取和设置期望结果\n获取期望结果：Object getExpectResult() 设置期望结果：Boolean setExpectResult(Object objToSet)\n  Mock 功能使用 Mock 功能目前是采用 Mockito 的方案，具体资料见 Mockito 英文文档和 Mockito 中文文档\n增加依赖 在 test 模块增加如下依赖（如果已经引入 SOFABoot 的测试 starter 则无需重复引入）\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-starter-test\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;scope\u0026amp;gt;test\u0026amp;lt;/scope\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 默认 spring test 依赖的 mockito 版本是 1.x，想要升级的可以排除后再引入相应的版本\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.mockito\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;mockito-core\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.18.3\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; Mockito 用于测试时进行打桩处理，通过它可以指定某个类的某个方法在什么情况下返回什么样的值。Mockito 库能够 Mock 对象、验证结果以及打桩，示例如下：\n@SpringBootTest(classes = SOFABootApplication.class) @TestExecutionListeners(listeners = MockitoTestExecutionListener.class) public class RegisterUserActsTest extends ActsTestBase { @TestBean @Autowired // 这是测试类  public UserService userService; @MockBean // 这是要mock的bean  public AccountManageFacadeClient accountManageFacadeClient; @Test(dataProvider = \u0026amp;#34;ActsDataProvider\u0026amp;#34;) public void registerUser (String caseId, String desc, PrepareData prepareData) { runTest(caseId, prepareData); } @Override public void beforeActsTest(ActsRuntimeContext actsRuntimeContext) { super.beforeActsTest(actsRuntimeContext); AccountManageResult accountManageResult = new AccountManageResult(); …","date":-62135596800,"description":"","dir":"projects/sofa-acts/usage-script/","fuzzywordcount":1300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"0d20739dedad1f11277bd02ed65329c3","permalink":"/projects/sofa-acts/usage-script/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/sofa-acts/usage-script/","summary":"快速理解 ACTS 中的脚本 如果你是一个经常编写测试用例的同学，是不是经常苦于这样的问题： 不断的 assertEquals 写得快吐了，重复性编码毫无创意； 少一个 assert 容易假绿，错","tags":null,"title":"一键脚本化","type":"projects","url":"/projects/sofa-acts/usage-script/","wordcount":1266},{"author":null,"categories":null,"content":"在本文档将演示如何使用 SOFATracer 集成 Zipkin 进行数据上报展示。\n假设你已经基于 SOFABoot 构建了一个简单的 Spring Web 工程，那么可以通过如下步骤进行操作：\n 下面的示例中将分别演示在 SOFABoot/SpringBoot 工程中 以及 非 SOFABoot/SpringBoot 工程中如何使用。\n 依赖引入 添加 SOFATracer 依赖 工程中添加 SOFATracer 依赖：\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;tracer-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 配置 Zipkin 依赖 考虑到 Zipkin 的数据上报能力不是 SOFATracer 默认开启的能力，所以期望使用 SOFATracer 做数据上报时，需要添加如下的 Zipkin 数据汇报的依赖：\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;io.zipkin.zipkin2\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;zipkin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.11.12\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;io.zipkin.reporter2\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;zipkin-reporter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.7.13\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 配置文件 在工程的 application.properties 文件下添加一个 SOFATracer 要使用的参数，包括spring.application.name 用于标示当前应用的名称；logging.path 用于指定日志的输出目录。\n# Application Name spring.application.name=SOFATracerReportZipkin # logging path logging.path=./logs com.alipay.sofa.tracer.zipkin.enabled=true com.alipay.sofa.tracer.zipkin.baseUrl=http://localhost:9411 启动 Zipkin 服务端 启动 Zipkin 服务端用于接收 SOFATracer 汇报的链路数据，并做展示。Zipkin Server 的搭建可以参考此文档进行配置和服务端的搭建。\n运行 可以将工程导入到 IDE 中运行生成的工程里面中的 main 方法启动应用，也可以直接在该工程的根目录下运行 mvn spring-boot:run，将会在控制台中看到启动日志：\n2018-05-12 13:12:05.868 INFO 76572 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean : Mapping filter: \u0026#39;SpringMvcSofaTracerFilter\u0026#39; to urls: [/*] 2018-05-12 13:12:06.543 INFO 76572 --- [ main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped \u0026amp;quot;{[/helloZipkin]}\u0026amp;quot; onto public java.util.Map\u0026amp;lt;java.lang.String, java.lang.Object\u0026amp;gt; com.alipay.sofa.tracer.examples.zipkin.controller.SampleRestController.helloZipkin(java.lang.String) 2018-05-12 13:12:07.164 INFO 76572 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http) 可以通过在浏览器中输入 http://localhost:8080/helloZipkin 来访问 REST 服务，结果类似如下：\n{ content: \u0026amp;#34;Hello, SOFATracer Zipkin Remote Report!\u0026amp;#34;, id: 1, success: true } 查看 Zipkin 服务端展示 打开 Zipkin 服务端界面，假设我们部署的 Zipkin 服务端的地址是 http://localhost:9411，打开 URL 并搜索 helloZipkin(由于我们本地访问的地址是 localhost:8080/helloZipkin)，可以看到展示的链路图。\nSpring 工程运行 对于一般的 Spring 工程，我们通常使用 tomcat/jetty 作为 servlet 容器来启动应用。具体工程参考 在 Spring 工程中使用 SOFATracer\n","date":-62135596800,"description":"","dir":"projects/sofa-tracer/report-to-zipkin/","fuzzywordcount":700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"d28d192386829452262116de9c32b570","permalink":"/projects/sofa-tracer/report-to-zipkin/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-tracer/report-to-zipkin/","summary":"在本文档将演示如何使用 SOFATracer 集成 Zipkin 进行数据上报展示。 假设你已经基于 SOFABoot 构建了一个简单的 Spring Web 工程，那么可以通过如下步骤进行操作： 下面的示例中将分别演","tags":null,"title":"上报数据至 Zipkin","type":"projects","url":"/projects/sofa-tracer/report-to-zipkin/","wordcount":661},{"author":null,"categories":null,"content":"优雅关闭，包括两部分，一个是 RPC 框架作为客户端，一个是 RPC 框架作为服务端。\n作为服务端 作为服务端的时候，RPC 框架在关闭时，不应该直接暴力关闭。在 RPC 框架中\ncom.alipay.sofa.rpc.context.RpcRuntimeContext 在静态初始化块中，添加了一个 ShutdownHook\n// 增加jvm关闭事件  if (RpcConfigs.getOrDefaultValue(RpcOptions.JVM_SHUTDOWN_HOOK, true)) { Runtime.getRuntime().addShutdownHook(new Thread(new Runnable() { @Override public void run() { if (LOGGER.isWarnEnabled()) { LOGGER.warn(\u0026amp;#34;SOFA RPC Framework catch JVM shutdown event, Run shutdown hook now.\u0026amp;#34;); } destroy(false); } }, \u0026amp;#34;SOFA-RPC-ShutdownHook\u0026amp;#34;)); } 这个 ShutdownHook 的作用是当发布平台/用户执行 kill pid 的时候，会先执行 ShutdownHook 中的逻辑。在销毁操作中，RPC 框架会先执行向注册中心取消服务注册、关闭服务端口等动作。\nprivate static void destroy(boolean active) { RpcRunningState.setShuttingDown(true); for (Destroyable.DestroyHook destroyHook : DESTROY_HOOKS) { destroyHook.preDestroy(); } List\u0026amp;lt;ProviderConfig\u0026amp;gt; providerConfigs = new ArrayList\u0026amp;lt;ProviderConfig\u0026amp;gt;(); for (ProviderBootstrap bootstrap : EXPORTED_PROVIDER_CONFIGS) { providerConfigs.add(bootstrap.getProviderConfig()); } // 先反注册服务端  List\u0026amp;lt;Registry\u0026amp;gt; registries = RegistryFactory.getRegistries(); if (CommonUtils.isNotEmpty(registries) \u0026amp;amp;\u0026amp;amp; CommonUtils.isNotEmpty(providerConfigs)) { for (Registry registry : registries) { registry.batchUnRegister(providerConfigs); } } // 关闭启动的端口  ServerFactory.destroyAll(); // 关闭发布的服务  for (ProviderBootstrap bootstrap : EXPORTED_PROVIDER_CONFIGS) { bootstrap.unExport(); } // 关闭调用的服务  for (ConsumerBootstrap bootstrap : REFERRED_CONSUMER_CONFIGS) { ConsumerConfig config = bootstrap.getConsumerConfig(); if (!CommonUtils.isFalse(config.getParameter(RpcConstants.HIDDEN_KEY_DESTROY))) { // 除非不让主动unrefer  bootstrap.unRefer(); } } // 关闭注册中心  RegistryFactory.destroyAll(); // 关闭客户端的一些公共资源  ClientTransportFactory.closeAll(); // 卸载模块  if (!RpcRunningState.isUnitTestMode()) { ModuleFactory.uninstallModules(); } // 卸载钩子  for (Destroyable.DestroyHook destroyHook : DESTROY_HOOKS) { destroyHook.postDestroy(); } // 清理缓存  RpcCacheManager.clearAll(); RpcRunningState.setShuttingDown(false); if (LOGGER.isWarnEnabled()) { LOGGER.warn(\u0026amp;#34;SOFA RPC Framework has been release all resources {}...\u0026amp;#34;, active ? \u0026amp;#34;actively \u0026amp;#34; : \u0026amp;#34;\u0026amp;#34;); } } 其中以 bolt 为例，关闭端口并不是一个立刻执行的动作\n@Override public void destroy() { if (!started) { return; } int stopTimeout = serverConfig.getStopTimeout(); if (stopTimeout \u0026amp;gt; 0) { // 需要等待结束时间  AtomicInteger count = boltServerProcessor.processingCount; // 有正在执行的请求 或者 队列里有请求  if (count.get() \u0026amp;gt; 0 || bizThreadPool.getQueue().size() \u0026amp;gt; 0) { long start = RpcRuntimeContext.now(); if (LOGGER.isInfoEnabled()) { LOGGER.info(\u0026amp;#34;There are {} call in processing and {} call in queue, wait {} ms to end\u0026amp;#34;, count, bizThreadPool.getQueue().size(), stopTimeout); } while ((count.get() \u0026amp;gt; 0 || bizThreadPool.getQueue().size() \u0026amp;gt; 0) \u0026amp;amp;\u0026amp;amp; RpcRuntimeContext.now() - start \u0026amp;lt; stopTimeout) { // 等待返回结果  try { Thread.sleep(10); } catch (InterruptedException ignore) { } } } // 关闭前检查已有请求？  } // 关闭线程池  bizThreadPool.shutdown(); stop(); } 而是会 …","date":-62135596800,"description":"","dir":"projects/sofa-rpc/graceful-shutdown/","fuzzywordcount":900,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"53af179e23ba184b01eb8234c055b15d","permalink":"/projects/sofa-rpc/graceful-shutdown/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-rpc/graceful-shutdown/","summary":"优雅关闭，包括两部分，一个是 RPC 框架作为客户端，一个是 RPC 框架作为服务端。 作为服务端 作为服务端的时候，RPC 框架在关闭时，不应该直接暴力关闭。在","tags":null,"title":"优雅关闭","type":"projects","url":"/projects/sofa-rpc/graceful-shutdown/","wordcount":866},{"author":null,"categories":null,"content":"","date":-62135596800,"description":"使用该指南您可以快速部署应用到 CloudMesh ，对服务进行访问，通过监控查看流量，体验服务治理、Sidecar管理和对服务的新版本进行灰度发布等实用功能。","dir":"guides/kc-cloud-mesh-demo/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"e389a65e6736e909718275cd76505525","permalink":"/guides/kc-cloud-mesh-demo/","publishdate":"0001-01-01T00:00:00Z","readingtime":0,"relpermalink":"/guides/kc-cloud-mesh-demo/","summary":"","tags":null,"title":"使用 CloudMesh 轻松实践 Service Mesh","type":"guides","url":"/guides/kc-cloud-mesh-demo/","wordcount":0},{"author":null,"categories":null,"content":"使用 Consul 作为服务注册中心需要添加如下依赖\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.ecwid.consul\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;consul-api\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;1.4.2\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 然后在 application.properties 中如下配置：\ncom.alipay.sofa.rpc.registry.address=consul://127.0.0.1:8500 其中后面的值为 consul 的连接地址，如果需要设置一些其他参数，也可以通过\ncom.alipay.sofa.rpc.registry.address=consul://127.0.0.1:8500?a=1\u0026amp;amp;b=2 进行设置\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/registry-consul/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"e6b0aa843ea0ad401c3184f6ce87649b","permalink":"/projects/sofa-rpc/registry-consul/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/registry-consul/","summary":"使用 Consul 作为服务注册中心需要添加如下依赖 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.ecwid.consul\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;consul-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.4.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 然后在 application.properties 中如下配置： com.alipay.sofa.rpc.registry.address=consul://127.0.0.1:8500 其中后面的值为 consul 的连接地址，如果需要设置一些其他参数，也可以通过 com.alipay.sofa.rpc.registry.address=consul://127.0.0.1:8500?a=1\u0026amp;b=2 进行","tags":null,"title":"使用 Consul 作为注册中心","type":"projects","url":"/projects/sofa-rpc/registry-consul/","wordcount":72},{"author":null,"categories":null,"content":"本文将介绍如何使用 MOSN 在 SOFAMesh 框架下搭建 Service Mesh 的开发环境，并验证 MOSN 的一些基础路由能力、负载均衡能力等。本文介绍的内容将包括 :\n MOSN 与 SOFAMesh 的关系 准备工作 源码方式部署 SOFAMesh Bookinfo 实验  MOSN 与 SOFAMesh 的关系 我们曾在 MOSN 介绍中介绍过，MOSN 是一款采用 Go 语言开发的 Service Mesh 数据平面代理。而 SOFAMesh 则是基于 Istio 改进和扩展而来的 Service Mesh 大规模落地实践方案，MOSN 作为 SOFAMesh 的关键组件用来完成数据面的转发。\n下图是 SOFAMesh 整体框架下，MOSN 的工作示意图。\n注意：当前 MOSN 不支持在原生的 Istio 中直接使用。\n准备工作 本文以 macOS 为例 ，其他环境可以安装对应版本的软件。\n1. 安装 hyperkit 先安装 docker-for-mac，之后安装驱动\n1.1 安装 docker 下载软件包安装，或者使用如下的命令安装。\n$ brew cask install docker 1.2 安装驱动 $ curl -LO https://storage.googleapis.com/minikube/releases/latest/docker-machine-driver-hyperkit \\ \u0026amp;amp;\u0026amp;amp; chmod +x docker-machine-driver-hyperkit \\ \u0026amp;amp;\u0026amp;amp; sudo mv docker-machine-driver-hyperkit /usr/local/bin/ \\ \u0026amp;amp;\u0026amp;amp; sudo chown root:wheel /usr/local/bin/docker-machine-driver-hyperkit \\ \u0026amp;amp;\u0026amp;amp; sudo chmod u+s /usr/local/bin/docker-machine-driver-hyperkit 2. 安装 Minikube(也可以购买商业 k8s 集群) 推荐使用 Minikube v0.28 以上来体验，请参考 https://github.com/kubernetes/minikube\n$ brew cask install minikube 3. 启动 Minikube 注意，pilot 至少需要 2G 内存，所以在启动的时候，可以通过加参数的方法给 minikube 添加分配的资源，如果你机器的资源不够，推荐使用商业版本的 k8s 集群。\n$ minikube start --memory=8192 --cpus=4 --kubernetes-version=v1.15.0 --vm-driver=hyperkit 创建istio 命名空间\n$ kubectl create namespace istio-system 4. 安装 kubectl 命令行工具 kubectl 是用于针对 k8s 集群运行命令的命令行接口，安装参考 https://kubernetes.io/docs/tasks/tools/install-kubectl。\n$ brew install kubernetes-cli 5. 安装 Helm Helm 是一个 k8s 的包管理工具，安装参考 https://docs.helm.sh/using_helm/#installing-helm\n$ brew install kubernetes-helm 源码方式部署 SOFAMesh 1. 下载 SOFAMesh 源码 $ git clone https://github.com/sofastack/sofa-mesh.git 2. 通过 Helm 安装 SOFAMesh 使用 helm template 安装\n首先需要切换到SOFAMesh源码所在目录，然后使用Helm安装istio CRD以及各个组件\n$ cd sofa-mesh $ helm template install/kubernetes/helm/istio-init --name istio-init --namespace istio-system | kubectl apply -f - $ helm template install/kubernetes/helm/istio --name istio --namespace istio-system | kubectl apply -f - 3. 验证安装 istio-system 命名空间下的 pod 状态都是 Running 时，说明已经部署成功。 如果仅仅是为了运行bookinfo，只需要pilot,injector,citadel这三个pods运行成功就可以满足最低要求\n$ kubectl get pods -n istio-system NAME READY STATUS RESTARTS AGE istio-citadel-6579c78cd9-w57lr 1/1 Running 0 5m istio-egressgateway-7649f76df4-zs8kw 1/1 Running 0 5m istio-galley-c77876cb6-nhczq 1/1 Running 0 5m istio-ingressgateway-5c9c8565d9-d972t 1/1 Running 0 5m istio-pilot-7485f9fb4b-xsvtm 1/1 Running 0 5m istio-policy-5766bc84b9-p2wfj 1/1 Running 0 5m istio-sidecar-injector-7f5f586bc7-2sdx6 1/1 Running 0 5m istio-statsd-prom-bridge-7f44bb5ddb-stcf6 1/1 Running 0 5m istio-telemetry-55ff8c77f4-q8d8q 1/1 Running 0 5m prometheus-84bd4b9796-nq8lg 1/1 Running 0 5m 4. 卸载安装 卸载SOFAMesh\n$ helm template install/kubernetes/helm/istio --name istio --namespace istio-system | kubectl delete -f - $ kubectl delete namespace istio-system BookInfo 实验 BookInfo 是一个类似豆瓣的图书应用，它包含四个基础服务：\n Product Page：主页，由 python 开发，展示所有图书信息，它会调用 Reviews 和 Details 服务 Reviews：评论，由 java 开发，展示图书评论，会调用 Ratings 服务 Ratings：评分服务，由 nodejs 开发 Details：图书详情，由 ruby  …","date":-62135596800,"description":"","dir":"projects/mosn/quick-start-run-with-sofamesh/","fuzzywordcount":1700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"9c6461e92180417d3a8ec4f3f2c723fe","permalink":"/projects/mosn/quick-start-run-with-sofamesh/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/projects/mosn/quick-start-run-with-sofamesh/","summary":"本文将介绍如何使用 MOSN 在 SOFAMesh 框架下搭建 Service Mesh 的开发环境，并验证 MOSN 的一些基础路由能力、负载均衡能力等。本文介绍的内容将包括 : MOSN 与 SOFAMesh 的关系 准备工作 源码","tags":null,"title":"使用 MOSN 搭建 Service Mesh 平台","type":"projects","url":"/projects/mosn/quick-start-run-with-sofamesh/","wordcount":1644},{"author":null,"categories":null,"content":"SOFARPC 已支持使用 Nacos 作为服务注册中心。假设你已经根据 Nacos 的快速开始在本地部署好 Nacos Server，服务发现的端口默认设置在 8848。\n在 SOFARPC 中使用 Nacos 作为服务注册中心只需要在 application.properties 中加入如下配置即可：\ncom.alipay.sofa.rpc.registry.address=nacos://127.0.0.1:8848 如果你直接使用了 SOFARPC，而不是 SOFABoot，需要手动添加 nacos 的依赖，其中 version 为用户想使用的 version。\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alibaba.nacos\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;nacos-client\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 当前支持 Nacos 的版本：\n SOFARPC：5.5.0 支持 Nacos 服务端版本 0.6.0，SOFABoot: 2.5.3。 SOFARPC：5.6.0 支持 Nacos 服务端版本 1.0.0。  ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/registry-nacos/","fuzzywordcount":300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"cc161f22cd2145fe309e63087581adc1","permalink":"/projects/sofa-rpc/registry-nacos/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/registry-nacos/","summary":"SOFARPC 已支持使用 Nacos 作为服务注册中心。假设你已经根据 Nacos 的快速开始在本地部署好 Nacos Server，服务发现的端口默认设置在 8848。 在 SOFARPC 中使用 Nacos 作为服务","tags":null,"title":"使用 Nacos 作为注册中心","type":"projects","url":"/projects/sofa-rpc/registry-nacos/","wordcount":230},{"author":null,"categories":null,"content":"","date":-62135596800,"description":"该指南将向您展示如何使用开源分布式事务框架 Seata 的 AT 模式、TCC 模式解决业务数据的最终一致性问题。 ","dir":"guides/kc-seata-demo/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"60071a0eb44bf0901fb187eefd63ccdb","permalink":"/guides/kc-seata-demo/","publishdate":"0001-01-01T00:00:00Z","readingtime":0,"relpermalink":"/guides/kc-seata-demo/","summary":"","tags":null,"title":"使用 Seata 保障支付一致性","type":"guides","url":"/guides/kc-seata-demo/","wordcount":0},{"author":null,"categories":null,"content":"SOFARPC 已支持使用 SOFARegistry 作为服务注册中心。假设你已经根据 SOFARegistry 的快速开始在本地部署好 SOFARegistry Server，服务发现的端口默认设置在 9603。\n在 SOFARPC 中使用 SOFARegistry 作为服务注册中心首先要添加如下的依赖：\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;registry-client-all\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;5.2.0\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 然后在 application.properties 中加入如下配置即可：\ncom.alipay.sofa.rpc.registry.address=sofa://127.0.0.1:9603 当前支持 SOFARegistry 的版本：\nSOFARPC: 5.5.2, SOFABoot: 2.6.3。\n由于本次发布的时间问题，暂时需要用户指定SOFARPC Starter的版本\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;rpc-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;5.5.2\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; SOFARPC 集成验证 SOFARegistry 服务端版本：5.2.0\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/registry-sofa/","fuzzywordcount":200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"65085018ce2b2b2ef452993bb79a69de","permalink":"/projects/sofa-rpc/registry-sofa/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/registry-sofa/","summary":"SOFARPC 已支持使用 SOFARegistry 作为服务注册中心。假设你已经根据 SOFARegistry 的快速开始在本地部署好 SOFARegistry Server，服务发现的端口默认设置在 9603。 在 SOFARPC 中使用 SOFARegistry 作为服务","tags":null,"title":"使用 SOFARegistry 作为注册中心","type":"projects","url":"/projects/sofa-rpc/registry-sofa/","wordcount":182},{"author":null,"categories":null,"content":"","date":-62135596800,"description":"本指南将基于 SOFAStack 快速构建一个微服务。","dir":"guides/sofastack-quick-start/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"78bfd4806a86dc15ac86eee16fb85c82","permalink":"/guides/sofastack-quick-start/","publishdate":"0001-01-01T00:00:00Z","readingtime":0,"relpermalink":"/guides/sofastack-quick-start/","summary":"","tags":null,"title":"使用 SOFAStack 快速构建微服务","type":"guides","url":"/guides/sofastack-quick-start/","wordcount":0},{"author":null,"categories":null,"content":"使用 Zookeeper 作为服务注册中心只需要在 application.properties 中如下配置即可：\ncom.alipay.sofa.rpc.registry.address=zookeeper://127.0.0.1:2181 注意：考虑掉服务的实时性，以下特性暂不支持\nSOFABoot RPC 也提供一个缓存文件(目前暂不支持)，当 Zookeeper 不可用时，使用该缓存文件进行服务发现。配置该缓存文件的方式如下：\ncom.alipay.sofa.rpc.registry.address=zookeeper://xxx:2181?file=/home/admin/registry Zookeeper Auth 支持 当用户需要对发布和消费服务，进行权限认证的时候，可以通过在操作 zookeeper 时，指定对应的目录和账号密码来进行读写。这样只有使用了相同密码的 服务方或者消费方才能进行读写。\nSOFARPC API 支持 在构造注册中心的时候，将Auth添加上\nparameters.put(\u0026amp;#34;scheme\u0026amp;#34;, \u0026amp;#34;digest\u0026amp;#34;); //如果存在多个认证信息，则在参数形式为为user1:passwd1,user2:passwd2 parameters.put(\u0026amp;#34;addAuth\u0026amp;#34;, \u0026amp;#34;sofazk:rpc1\u0026amp;#34;); registryConfig = new RegistryConfig() .setProtocol(\u0026amp;#34;zookeeper\u0026amp;#34;) .setAddress(\u0026amp;#34;127.0.0.1:2181/authtest\u0026amp;#34;) .setParameters(parameters); 之后其他没有使用正确auth的，将无法访问authtest目录\nXML 方式支持 如下使用即可\ncom.alipay.sofa.rpc.registry.address=zookeeper://xxx:2181?file=/home/admin/registry\u0026amp;amp;scheme=digest\u0026amp;amp;addAuth=sofazk:rpc1 ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/registry-zookeeper/","fuzzywordcount":400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"71d6486c5577cc85d84c56688cdf2af1","permalink":"/projects/sofa-rpc/registry-zookeeper/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/registry-zookeeper/","summary":"使用 Zookeeper 作为服务注册中心只需要在 application.properties 中如下配置即可： com.alipay.sofa.rpc.registry.address=zookeeper://127.0.0.1:2181 注意：考虑掉服务的实时性，以下特性暂不支持 SOFABoot RPC 也提供一个缓存文件(目前暂不支持)，当 Zookeeper 不可","tags":null,"title":"使用 Zookeeper 作为注册中心","type":"projects","url":"/projects/sofa-rpc/registry-zookeeper/","wordcount":309},{"author":null,"categories":null,"content":"使用本地文件作为服务注册中心在 application.properties 中如下配置即可：\ncom.alipay.sofa.rpc.registry.address=local:///home/admin/registry/localRegistry.reg 其中 /home/admin/registry/localRegistry.reg 就是使用的本地文件的目录。\n对于 windows 用户，则以上地址类似：\ncom.alipay.sofa.rpc.registry.address=local://c://users/localRegistry.reg ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/registry-local/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"33bc89393392e21b3917f090313c0df5","permalink":"/projects/sofa-rpc/registry-local/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/registry-local/","summary":"使用本地文件作为服务注册中心在 application.properties 中如下配置即可： com.alipay.sofa.rpc.registry.address=local:///home/admin/registry/localRegistry.reg 其中 /home/admin/registry/localRegistry.reg 就是使用的本地文件的目录。 对于 windows 用户，则以上地址类似： com.alipay.sofa.rpc.registry.address=local://c://users/localRegistry.reg","tags":null,"title":"使用本地文件作为注册中心","type":"projects","url":"/projects/sofa-rpc/registry-local/","wordcount":56},{"author":null,"categories":null,"content":"SOFABoot 是在 Spring Boot 的基础上提供的功能扩展。基于 Spring Boot 的机制，SOFABoot 管理了 SOFA 中间件的依赖，并且提供了 Spring Boot 的 Starter，方便用户在 Spring Boot 中使用 SOFA 中间件。\nSOFABoot 依赖管理 \u0026amp;ndash; Maven 在使用 SOFA 中间件之前，需要引入 SOFABoot 依赖管理。类似 Spring Boot 引入方式，在工程中增加如下 \u0026amp;lt;parent/\u0026amp;gt; 标签配置的方式:\n\u0026amp;lt;parent\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofaboot-dependencies\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${sofa.boot.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/parent\u0026amp;gt; 其中 ${sofa.boot.version} 为具体的 SOFABoot 版本，参考发布历史。\nSOFABoot 依赖管理 \u0026amp;ndash; Gradle 从 SOFABoot 3.1.1 版本开始，SOFABoot 开始支持使用 Gradle 来进行依赖管理，如果要使用 Gradle 来进行依赖管理，需要按照如下的形式来配置 build.gradle：\nbuildscript { ext { sofaBootVersion = \u0026amp;#39;3.1.1\u0026amp;#39; } repositories { mavenLocal() mavenCentral() } dependencies { classpath(\u0026amp;#34;com.alipay.sofa:sofa-boot-gradle-plugin:${sofaBootVersion}\u0026amp;#34;) } } apply plugin: \u0026amp;#39;java\u0026amp;#39; apply plugin: \u0026amp;#39;eclipse\u0026amp;#39; apply plugin: \u0026amp;#39;com.alipay.sofa.boot\u0026amp;#39; apply plugin: \u0026amp;#39;io.spring.dependency-management\u0026amp;#39; group = \u0026amp;#39;com.example\u0026amp;#39; version = \u0026amp;#39;0.0.1-SNAPSHOT\u0026amp;#39; sourceCompatibility = 1.8 repositories { mavenLocal() mavenCentral() } dependencies { implementation(\u0026amp;#39;com.alipay.sofa:rpc-sofa-boot-starter\u0026amp;#39;) implementation(\u0026amp;#39;org.springframework.boot:spring-boot-starter\u0026amp;#39;) testImplementation(\u0026amp;#39;org.springframework.boot:spring-boot-starter-test\u0026amp;#39;) } 主要有几个步骤：\n 添加 buildScript，增加 sofa-boot-gradle-plugin 的依赖，其中版本号为你使用的 SOFABoot 的版本。 添加两个 plugin，分别是 com.alipay.sofa.boot 和 io.spring.dependency-management。  这样，在 dependencies 里面，就可以直接添加 SOFABoot 管理的各种中间件和依赖了，而不用声明版本号。\n引入 SOFA 中间件 SOFABoot 使用一系列后缀为 -sofa-boot-starter 来标示一个中间件组件，如果想要使用某个中间件，直接添加对应的依赖即可。例如，如果期望使用 SOFARPC，只需增加下面的 Maven 依赖即可：\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;rpc-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 注意上面的 Maven 依赖中并没有声明版本，这个是因为版本已经在 sofaboot-dependencies 里面声明好。这样做的好处是对于 SOFA 中间件，用户统一进行升级即可，不需要单独升级一个中间件的版本，防止出现依赖冲突以及兼容性的问题。目前管控的 SOFABoot 中间件列表如下:\n   中间件 starter     SOFARPC rpc-sofa-boot-starter   SOFATracer tracer-sofa-boot-starter   SOFALookout lookout-sofa-boot-starter    引入 SOFABoot 扩展组件 SOFABoot 基于 Spring Boot 提供了健康检查，模块隔离，类隔离等扩展能力。遵循 Spring Boot 依赖即服务的理念，添加相关组件依赖之后，扩展能力即可生效。目前提供的扩展组件如下：\n   扩展组件 starter     健康检查 healthcheck-sofa-boot-starter   模块化隔离 isle-sofa-boot-starter   类隔离 sofa-ark-springboot-starter   测试扩展 test-sofa-boot-starter    引入 SOFA 中间件 ark 插件 SOFABoot 提供了类隔离组件 SOFAArk，借助 SOFAArk 容器，用户可以将依赖冲突的三方包打包成 ark 插件。运行时，ark 插件使用单独的类加载器加载，可以和其他 ark 插件以及业务依赖隔离，解决类冲突问题。SOFABoot 官方提供了 SOFARPC 和 SOFATracer 的 ark 插件，例如在应用中引入 SOFARPC ark 插件依赖替代 SOFARPC starter，从而隔离应用和 SOFARPC 及其间接依赖。目前管控的 ark 插件列表如下:\n   Ark插件 plugin     SOFARPC rpc-sofa-boot-plugin   SOFATracer tracer-sofa-boot-plugin    引入 SOFABoot 命名空间 使用 SOFA 中间件时，需要在 XML 中根据中间件的具体使用方式添加相应的配置，这个时候需要引入 SOFABoot 的命名空间 xmlns:sofa=\u0026amp;quot;http://sofastack.io/schema/sofaboot\u0026amp;quot; 以能够正确解析相应的配置标签，示例：\n\u0026amp;lt;beans xmlns=\u0026amp;#34;http://www.springframework.org/schema/beans\u0026amp;#34; …","date":-62135596800,"description":"","dir":"projects/sofa-boot/dependency-management/","fuzzywordcount":1000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"dabdbd425f20dee4d7ab580d43574456","permalink":"/projects/sofa-boot/dependency-management/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-boot/dependency-management/","summary":"SOFABoot 是在 Spring Boot 的基础上提供的功能扩展。基于 Spring Boot 的机制，SOFABoot 管理了 SOFA 中间件的依赖，并且提供了 Spring Boot 的 Starter，方便用户在 Spring Boot 中使用","tags":null,"title":"依赖管理","type":"projects","url":"/projects/sofa-boot/dependency-management/","wordcount":981},{"author":null,"categories":null,"content":"SOFARPC 使用了一些三方开源组件，他们分别是：\n一些主要依赖：\n Netty under Apache License 2.0 SLF4j under the MIT License SOFA Bolt under Apache License 2.0 Javassist under Apache License 2.0 Resteasy under Apache License 2.0 SOFA Hessian under Apache License 2.0  一些扩展依赖：\n protobuf under New BSD License Snappy under Apache License 2.0 dubbo under Apache License 2.0  \u0026amp;hellip; 其它整理中。\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/notice/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"b6c87388d5c1462f13d92012639a08b2","permalink":"/projects/sofa-rpc/notice/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/notice/","summary":"SOFARPC 使用了一些三方开源组件，他们分别是： 一些主要依赖： Netty under Apache License 2.0 SLF4j under the MIT License SOFA Bolt under Apache License 2.0 Javassist under Apache License 2.0 Resteasy under Apache License 2.0 SOFA Hessian under Apache License 2.0 一些扩展依赖： protobuf under New BSD License","tags":null,"title":"依赖组件版权说明","type":"projects","url":"/projects/sofa-rpc/notice/","wordcount":87},{"author":null,"categories":null,"content":"SOFABoot 为 Spring Boot 的健康检查能力增加了 Readiness Check 的能力。如果你需要使用 SOFA 中间件，那么建议使用 SOFABoot 的健康检查能力的扩展，来更优雅的上线应用实例\n引入健康检查扩展 要引入 SOFABoot 的健康检查能力的扩展，只需要引入以下的 Starter 即可：\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;healthcheck-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 如果不引入 SOFABoot 的健康检查扩展，用户依然可以直接依赖 HealthIndicator 接口进行原生的 Spring Boot Actuator 的 Liveness Check。\n安全提醒 从 SOFABoot 2.3.0 开始，由于健康检查能力依赖于 SpringBoot 1.4.x 里的 Actuator 组件，而 Actuator 会默认开启很多 EndPoint，例如 /dump，/trace 等等，可能存在安全风险，可以参照官方文档里的安全建议进行设置。\n SpringBoot 1.5.x 和 SpringBoot 2.x 已修复了部分安全行为，SOFABoot 将通过升级 SpringBoot 内核进行支持。\n 查看健康检查结果 加入健康检查扩展之后，我们可以直接在浏览器中输入 http://localhost:8080/health/readiness 来查看 Readiness Check 的结果。如果要查看 Liveness Check 的结果，可以直接查看 Spring Boot 的健康检查的 URL http://localhost:8080/health。\n除了通过 URL 来查看健康检查的结果之外，在 SOFABoot 中，还可以通过查看具体的日志来确定健康检查的结果，日志的目录位于 health-check 目录下，日志的内容大概如下：\n2018-04-06 23:29:50,240 INFO main - Readiness check result: success 目前 SOFA 中间件已经通过 SOFABoot 的 Readiness Check 的能力来控制了上游流量的进入，但是一个应用的流量可能并不是全部都是从中间件进入的，比较常见的还有从负载均衡器进入的，为了控制从负载均衡器进入的流量，建议使用者通过 PAAS 来访问 Readiness Check 的结果，根据结果来控制是否要在负载均衡器中上线对应的节点。\n注: 自 SOFABoot 2.x 之后，不再间接引入 spring-boot-starter-web 依赖，如果需要在浏览器中查看健康检查结果，需要额外在工程中引入 web 容器依赖。\n注: 在 SOFABoot 3.x 中调整了 endpoint 路径，health/readiness 更改为 actuator/readiness\n扩展 Readiness Check 能力 在 Readiness Check 的各个阶段，SOFABoot 都提供了扩展的能力，应用可以根据自己的需要进行扩展，在 2.x 版本中，可供扩展的点如下：\n   回调接口 说明     org.springframework.context.ApplicationListener 如果想要在 Readiness Check 之前做一些事情，那么监听这个 Listener 的 SofaBootBeforeHealthCheckEvent 事件。   org.springframework.boot.actuate.health.HealthIndicator 如果想要在 SOFABoot 的 Readiness Check 里面增加一个检查项，那么可以直接扩展 Spring Boot 的这个接口。   com.alipay.sofa.healthcheck.startup.SofaBootAfterReadinessCheckCallback 如果想要在 Readiness Check 之后做一些事情，那么可以扩展 SOFABoot 的这个接口。    在 3.x 版本中，可供扩展点如下：\n   回调接口 说明     com.alipay.sofa.healthcheck.core.HealthChecker 如果想要在 SOFABoot 的 Readiness Check 里面增加一个检查项，可以直接扩展该接口。相较于 Spring Boot 本身的 HealthIndicator 接口，该接口提供了一些额外的参数配置，比如检查失败重试次数等。   org.springframework.boot.actuate.health.HealthIndicator 如果想要在 SOFABoot 的 Readiness Check 里面增加一个检查项，那么可以直接扩展 Spring Boot 的这个接口。   org.springframework.boot.actuate.health.ReactiveHealthIndicator 在 WebFlux 中，如果想要在 SOFABoot 的 Readiness Check 里面增加一个检查项，那么可以直接扩展 Spring Boot 的这个接口。   com.alipay.sofa.healthcheck.startup.ReadinessCheckCallback 如果想要在 Readiness Check 之后做一些事情，那么可以扩展 SOFABoot 的这个接口。    需要指出的是，上述四个扩展接口均可以通过 Spring Boot 标准的 Ordered, PriorityOrdered 和注解 @Order 实现执行顺序的设置。\nReadiness Check 配置项 应用在引入 SOFABoot 的健康检查扩展之后，可以在 Spring Boot 的配置文件 application.properties 中添加相关配置项来定制 Readiness Check 的相关行为。\n   Readiness Check 配置项 说明 默认值 开始支持版本     com.alipay.sofa.healthcheck.skip.all 是否跳过整个 Readiness Check 阶段 false 2.4.0   com.alipay.sofa.healthcheck.skip.component 是否跳过 SOFA 中间件的 Readiness Check false 2.4.0   com.alipay.sofa.healthcheck.skip.indicator 是否跳过 HealthIndicator 的 Readiness Check false 2.4.0 …","date":-62135596800,"description":"","dir":"projects/sofa-boot/health-check/","fuzzywordcount":1300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"a366b25125fa4aedb08a9cef572db1c8","permalink":"/projects/sofa-boot/health-check/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/sofa-boot/health-check/","summary":"SOFABoot 为 Spring Boot 的健康检查能力增加了 Readiness Check 的能力。如果你需要使用 SOFA 中间件，那么建议使用 SOFABoot 的健康检查能力的扩展，来更优雅的上线应用实例 引入健康检查扩展 要","tags":null,"title":"健康检查","type":"projects","url":"/projects/sofa-boot/health-check/","wordcount":1269},{"author":null,"categories":null,"content":" 目前默认生效的的扩展模块是：lookout-ext-jvm， lookout-ext-os(from v1.5.0)。\n JVM 线程    metric name metric tags specification     jvm.threads.totalStarted  \u0026amp;mdash;   jvm.threads.active  \u0026amp;mdash;   jvm.threads.peak  \u0026amp;mdash;   jvm.threads.daemon  \u0026amp;mdash;    JVM 类加载    metric name metric tags specification     jvm.classes.unloaded  \u0026amp;mdash;   jvm.classes.loaded  \u0026amp;mdash;   jvm.classes.total  \u0026amp;mdash;    JVM 内存    metric name metric tags specification     jvm.memory.heap.init  \u0026amp;mdash;   jvm.memory.heap.used  \u0026amp;mdash;   jvm.memory.heap.max  \u0026amp;mdash;   jvm.memory.heap.committed  \u0026amp;mdash;    JVM 垃圾回收    metric name metric tags specification     jvm.gc.young.time  \u0026amp;mdash;   jvm.gc.young.count  \u0026amp;mdash;   jvm.gc.old.time  \u0026amp;mdash;   jvm.gc.old.count  \u0026amp;mdash;    机器文件系统信息    metric name metric tags specification     instance.file.system.free.space root（文件系统根目录名） \u0026amp;mdash;   instance.file.system.total.space root \u0026amp;mdash;   instance.file.system.usabe.space root \u0026amp;mdash;    机器信息    metric name metric tags specification     instance.mem.free  \u0026amp;mdash;   instance.mem.total  \u0026amp;mdash;   instance.processors  \u0026amp;mdash;   instance.uptime  \u0026amp;mdash;   instance.systemload.average  \u0026amp;mdash;    Linux 操作系统信息 （1.5.0版本之后默认启用）    metric name metric tags specification     os.systemload.average.1min  \u0026amp;mdash;   os.systemload.average.5min  \u0026amp;mdash;   os.systemload.average.15min  \u0026amp;mdash;   os.cpu.idle  \u0026amp;mdash;   os.cpu.iowait  \u0026amp;mdash;   os.cpu.irq  \u0026amp;mdash;   os.cpu.nice  \u0026amp;mdash;   os.cpu.softirq  \u0026amp;mdash;   os.cpu.system  \u0026amp;mdash;   os.cpu.user  \u0026amp;mdash;   os.disk.usage.percent.used device,root,type \u0026amp;mdash;   os.disk.usage.total.bytes device,root,type \u0026amp;mdash;   os.disk.usage.used.bytes device,root,type \u0026amp;mdash;   os.net.stats.in.bytes intfc \u0026amp;mdash;   os.net.stats.in.compressed intfc \u0026amp;mdash;   os.net.stats.in.dropped intfc \u0026amp;mdash;   os.net.stats.in.errs intfc \u0026amp;mdash;   os.net.stats.in.fifo.errs intfc \u0026amp;mdash;   os.net.stats.in.frame.errs intfc \u0026amp;mdash;   os.net.stats.in.multicast intfc \u0026amp;mdash;   os.net.stats.in.packets intfc \u0026amp;mdash;   os.net.stats.out.bytes intfc \u0026amp;mdash;   os.net.stats.out.carrier.errs intfc \u0026amp;mdash;   os.net.stats.out.collisions intfc \u0026amp;mdash;   os.net.stats.out.compressed intfc \u0026amp;mdash;   os.net.stats.out.dropped intfc \u0026amp;mdash;   os.net.stats.out.errs intfc \u0026amp;mdash;   os.net.stats.out.fifo.errs intfc \u0026amp;mdash;   os.net.stats.out.packets intfc \u0026amp;mdash;   os.memory.stats.buffers.bytes \u0026amp;mdash; \u0026amp;gt;= 1.5.3   os.memory.stats.cached.bytes \u0026amp;mdash; \u0026amp;gt;= 1.5.3   os.memory.stats.free.bytes \u0026amp;mdash; \u0026amp;gt;= 1.5.3   os.memory.stats.total.bytes \u0026amp;mdash; \u0026amp;gt;= 1.5.3    ","date":-62135596800,"description":"","dir":"projects/sofa-lookout/client-ext-metrics/","fuzzywordcount":300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"c8a4fb3d904e359e99db9d4e81e60812","permalink":"/projects/sofa-lookout/client-ext-metrics/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-lookout/client-ext-metrics/","summary":"目前默认生效的的扩展模块是：lookout-ext-jvm， lookout-ext-os(from v1.5.0)。 JVM 线程 metric name metric tags specification jvm.threads.totalStarted \u0026mdash; jvm.threads.active \u0026mdash; jvm.threads.peak \u0026mdash; jvm.threads.daemon \u0026mdash; JVM 类加载 metric name metric tags specification jvm.classes.unloaded \u0026mdash; jvm.classes.loaded \u0026mdash; jvm.classes.total \u0026mdash;","tags":null,"title":"内置扩展 Metrics 指标","type":"projects","url":"/projects/sofa-lookout/client-ext-metrics/","wordcount":278},{"author":null,"categories":null,"content":"分布式共识算法 (Consensus Algorithm) 如何理解分布式共识?  多个参与者 针对 某一件事 达成完全 一致 ：一件事，一个结论 已达成一致的结论，不可推翻  有哪些分布式共识算法?  Paxos：被认为是分布式共识算法的根本，其他都是其变种，但是 paxos 论文中只给出了单个提案的过程，并没有给出复制状态机中需要的 multi-paxos 的相关细节的描述，实现 paxos 具有很高的工程复杂度（如多点可写，允许日志空洞等） Zab：被应用在 zookeeper 中，业界使用广泛，但没有抽象成通用的 library Raft：以容易理解著称，业界也涌现出很多 raft 实现，比如大名鼎鼎的 etcd, braft, tikv 等  什么是 Raft？ Raft 是一种更易于理解的分布式共识算法，核心协议本质上还是师承 paxos 的精髓，不同的是依靠 raft 模块化的拆分以及更加简化的设计，raft 协议相对更容易实现。\n模块化的拆分主要体现在：Raft 把一致性协议划分为 Leader 选举、MemberShip 变更、日志复制、Snapshot 等几个几乎完全解耦的模块\n更加简化的设计则体现在：Raft 不允许类似 paxos 中的乱序提交、简化系统中的角色状态（只有 Leader、Follower、Candidate三种角色）、限制仅 Leader 可写入、使用随机化的超时时间来设计 Leader Election 等等\n特点：Strong Leader  系统中必须存在且同一时刻只能有一个 leader，只有 leader 可以接受 clients 发过来的请求 Leader 负责主动与所有 followers 通信，负责将\u0026amp;rsquo;提案\u0026amp;rsquo;发送给所有 followers，同时收集多数派的 followers 应答 Leader 还需向所有 followers 主动发送心跳维持领导地位(保持存在感)  一句话总结 Strong Leader: \u0026amp;ldquo;你们不要 BB! 按我说的做，做完了向我汇报!\u0026amp;quot; 另外，身为 leader 必须保持一直 BB(heartbeat) 的状态，否则就会有别人跳出来想要 BB\n复制状态机 对于一个无限增长的序列 a[1, 2, 3…]，如果对于任意整数 i，a[i] 的值满足分布式一致性，这个系统就满足一致性状态机的要求 基本上所有的真实系统都会有源源不断的操作，这时候单独对某个特定的值达成一致显然是不够的。为了让真实系统保证所有的副本的一致性，通常会把操作转化为 write-ahead-log(WAL)。然后让系统中所有副本对 WAL 保持一致，这样每个副本按照顺序执行 WAL 里的操作，就能保证最终的状态是一致的\n Client 向 leader 发送写请求 Leader 把\u0026amp;rsquo;操作\u0026amp;rsquo;转化为 WAL 写本地 log 的同时也将 log 复制到所有 followers Leader 收到多数派应答, 将 log 对应的\u0026amp;rsquo;操作\u0026#39; 应用到状态机 回复 client 处理结果  Raft 中的基本概念 Raft-node 的 3 种角色/状态  Follower：完全被动，不能发送任何请求，只接受并响应来自 leader 和 candidate 的 message，每个节点启动后的初始状态一定是 follower Leader：处理所有来自客户端的请求，以及复制 log 到所有 followers Candidate：用来竞选一个新 leader （candidate 由 follower 触发超时而来）  Message 的 3 种类型  RequestVote RPC：由 candidate 发出，用于发送投票请求 AppendEntries (Heartbeat) RPC：由 leader 发出，用于 leader 向 followers 复制日志条目，也会用作 Heartbeat （日志条目为空即为 Heartbeat） InstallSnapshot RPC：由 leader 发出，用于快照传输，虽然多数情况都是每个服务器独立创建快照，但是leader 有时候必须发送快照给一些落后太多的 follower，这通常发生在 leader 已经丢弃了下一条要发给该follower 的日志条目(Log Compaction 时清除掉了) 的情况下  任期逻辑时钟  时间被划分为一个个任期 (term)，term id 按时间轴单调递增 每一个任期的开始都是 leader 选举，选举成功之后，leader 在任期内管理整个集群，也就是 \u0026amp;lsquo;选举 + 常规操作\u0026amp;rsquo; 每个任期最多一个 leader，可能没有 leader (spilt-vote 导致)  Raft 功能分解 Leader 选举  超时驱动：Heartbeat/Election timeout 随机的超时时间：降低选举碰撞导致选票被瓜分的概率 选举流程：  Follower \u0026amp;ndash;\u0026amp;gt; Candidate (选举超时触发)  赢得选举：Candidate \u0026amp;ndash;\u0026amp;gt; Leader 另一个节点赢得选举：Candidate \u0026amp;ndash;\u0026amp;gt; Follower 一段时间内没有任何节点器赢得选举：Candidate \u0026amp;ndash;\u0026amp;gt; Candidate     选举动作：  Current term++ 发送 RequestVote RPC   New Leader 选取原则 (最大提交原则)  Candidates include log info in RequestVote RPCs(index \u0026amp;amp; term of last log entry) During elections, choose candidate with log most likely to contain all committed entries Voting server V denies vote if its log is “more complete”: (lastTermV \u0026amp;gt; lastTermC) || ((lastTermV == lastTermC) \u0026amp;amp;\u0026amp;amp; (lastIndexV \u0026amp;gt; lastIndexC)) Leader will have “most complete” log among electing majority   安全性：一个 term，最多选出一个 leader，可以没 leader，下一个 term 再选   影响 raft 选举成功率的几个时间参数：  RTT(Round Trip Time)：网络延时 Heartbeat timeout：心跳间隔，通常应该比 election timeout 小一个数量级，目的是让 leader 能够持续发送心跳来阻止 followers 触发选举 Election timeout：Leader 与 followers …","date":-62135596800,"description":"","dir":"projects/sofa-jraft/consistency-raft-jraft/","fuzzywordcount":8000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"a0e98df1bec305cca7db6fc34fc97771","permalink":"/projects/sofa-jraft/consistency-raft-jraft/","publishdate":"0001-01-01T00:00:00Z","readingtime":16,"relpermalink":"/projects/sofa-jraft/consistency-raft-jraft/","summary":"分布式共识算法 (Consensus Algorithm) 如何理解分布式共识? 多个参与者 针对 某一件事 达成完全 一致 ：一件事，一个结论 已达成一致的结论，不可推翻 有哪些分布式共识算法? P","tags":null,"title":"分布式一致性 Raft 与 JRaft","type":"projects","url":"/projects/sofa-jraft/consistency-raft-jraft/","wordcount":7943},{"author":null,"categories":null,"content":"单元测试 单元测试例子放到自己开发的模块下。\n如果依赖了第三方服务端（例如Zookeeper），请手动加入 profile。参考 registry-zookeeper 模块代码。\n如果依赖了其它模块要集成测试，请放到 test/test-intergrated 模块中。\n如果还依赖了第三方服务端（例如Zookeeper），请放到 test-intergrated-3rd 模块中。\n性能测试 关闭了以下默认开启项目：\n-Dcontext.attachment.enable=false -Dserialize.blacklist.enable=false -Ddefault.tracer= -Dlogger.impl=com.alipay.sofa.rpc.log.SLF4JLoggerImpl -Dmultiple.classloader.enable=false -Devent.bus.enable=false\n我们对 BOLT+hessian 进行了压测。\n服务端：4C8G 虚拟机，千M网络，jdk1.8.0_111；\n客户端：50个客户端并发请求。\n   协议 请求 响应 服务端 TPS 平均RT(ms)     bolt+hessian 1K String 1K String 直接返回 10000 1.93   bolt+hessian 1K String 1K String 直接返回 20000 4.13   bolt+hessian 1K String 1K String 直接返回 30000 7.32   bolt+hessian 1K String 1K String 直接返回 40000 15.78   bolt+hessian 1K String 1K String 直接返回 50000(接近极限,错误率0.3%） 26.51    ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/test/","fuzzywordcount":300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"ccda7c2372a7f55d61f682b72d3b1dc2","permalink":"/projects/sofa-rpc/test/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/test/","summary":"单元测试 单元测试例子放到自己开发的模块下。 如果依赖了第三方服务端（例如Zookeeper），请手动加入 profile。参考 registry-zookeeper 模块代码。 如果依","tags":null,"title":"单元测试与性能测试","type":"projects","url":"/projects/sofa-rpc/test/","wordcount":292},{"author":null,"categories":null,"content":"准备工作 贡献代码前需要先了解 git 工具的使用和 GitHub 网站的使用。\n git 工具用法可以查看git 官方书籍,需要阅读前几章来熟悉。 git 协作流程可以查看这篇文章Git 协作流程  GitHub 贡献代码流程 提交 issue 不论您是修复 ACTS 的 bug 还是新增 ACTS 的功能，在您提交代码之前，在 ACTS 的 GitHub 上提交一个 issue，描述您要修复的问题或者要增加的功能。这么做有几个好处:\n 不会与其它开发者或是他们对这个项目的计划发生冲突，产生重复工作. ACTS 的维护人员会对您提的bug或者新增功能进行相关讨论，确定该修改是不是必要，有没有提升的空间或更好的办法。 在达成一致后再开发,并提交代码，减少双方沟通成本，也减少 pull request 被拒绝的情况。  获取源码 要修改或新增功能，在提 issue 后，点击左上角的 fork 按钮，复制一份 ACTS 主干代码到您的代码仓库。\n拉分支 ACTS 所有修改都在分支上进行，修改完后提交 pull request， 在 Code Review 后由项目维护人员 Merge 到主干。 因此，在获取源码步骤介绍后，您需要：\n 下载代码到本地,这一步您可以选择 git/https 方式. git clone https://github.com/您的账号名/acts.git  拉分支准备修改代码 git branch add_xxx_feature 执行完上述命令后，您的代码仓库就切换到相应分支了。执行如下命令可以看到您当前分支：\ngit branch -a 如果您想切换回主干，执行下面命令:\ngit checkout -b master 如果您想切换回分支，执行下面命令：\ngit checkout -b \u0026amp;quot;branchName\u0026amp;quot;   修改代码提交到本地 拉完分支后，就可以修改代码了。\n  修改完代码后，执行如下命令提交所有修改到本地\ngit commit -am \u0026#39;添加xx功能\u0026#39;   修改代码注意事项  代码风格保持一致 ACTS 通过 Maven 插件来保持代码格式一致.在提交代码前,务必本地执行 mvn clean compile  补充单元测试代码 新有修改应该通过已有的单元测试. 应该提供新的单元测试来证明以前的代码存在 bug，而新的代码已经解决了这些 bug 您可以用如下命令运行所有测试 mvn clean test 也可以通过 IDE 来辅助运行。\n  其它注意事项  请保持您编辑的代码的原有风格，尤其是空格换行等. 对于无用的注释，请直接删除 对逻辑和功能不容易被理解的地方添加注释。 及时更新文档  提交代码到远程仓库 在代码提交到本地后，就是与远程仓库同步代码了。\n  执行如下命令提交本地修改到 github 上\ngit push origin \u0026amp;quot;branchname\u0026amp;quot;   如果前面您是通过 fork 来做的,那么这里的 origin 是 push 到您的代码仓库，而不是 ACTS 的代码仓库.\n提交合并代码到主干的请求 在的代码提交到 GitHub 后，您就可以发送请求来把您改好的代码合入 ACTS 主干代码了。此时您需要进入您的 GitHub 上的对应仓库，按右上角的 pull request按钮。选择目标分支,一般就是 master，系统会通知 ACTS 的人员， ACTS 人员会 Review 您的代码，符合要求后就会合入主干，成为 ACTS 的一部分。\n代码 Review 在您提交代码后，您的代码会被指派给维护人员 Review，请耐心等待。如果在数天后，仍然没有人对您的提交给予任何回复，可以在 PR 下面留言，并 @ 对应的人员.\n对于代码 Review 的意见会直接备注到到对应 PR 或者 Issue。如果觉得建议是合理的，也请您把这些建议更新到您的补丁中。\n合并代码到主干 在代码 Review 通过后，就由 ACTS 维护人员操作合入主干了。这一步不用参与，代码合并之后，您会收到合并成功的提示。\n","date":-62135596800,"description":"","dir":"projects/sofa-acts/contributing/","fuzzywordcount":1300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"cd68baede6258921f83665ef0a446f1f","permalink":"/projects/sofa-acts/contributing/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/sofa-acts/contributing/","summary":"准备工作 贡献代码前需要先了解 git 工具的使用和 GitHub 网站的使用。 git 工具用法可以查看git 官方书籍,需要阅读前几章来熟悉。 git 协作流程可以查看这篇文章G","tags":null,"title":"参与贡献","type":"projects","url":"/projects/sofa-acts/contributing/","wordcount":1221},{"author":null,"categories":null,"content":" 可以先去 发展路线 内了解下开发任务及未来规划。\n 准备工作 贡献代码前需要先了解 git 工具的使用和 GitHub 网站的使用。\n git 工具用法可以查看 git官方书籍，需要阅读前几章来熟悉。 git 协作流程可以查看这篇文章 Git协作流程。  GitHub 贡献代码流程 提交issue 不论您是修复 SOFAArk 的 bug 还是新增 SOFAArk 的功能，在您提交代码之前，在 SOFAArk 的 GitHub 地址上提交一个 issue，描述您要修复的问题或者要增加的功能。这么做有几个好处:\n 不会与其它开发者或是他们对这个项目的计划发生冲突，产生重复工作. SOFAArk 的维护人员会对您提的bug或者新增功能进行相关讨论，确定该修改是不是必要，有没有提升的空间或更好的办法。 在达成一致后再开发,并提交代码，减少双方沟通成本，也减少pull request被拒绝的情况。  获取源码 要修改或新增功能，在提 issue 后，点击左上角的fork按钮，复制一份 SOFAArk 主干代码到您的代码仓库。\n拉分支 SOFAArk 所有修改都在分支上进行，修改完后提交 pull request， 在 Code Review 后由项目维护人员 Merge 到主干。\n因此，在获取源码步骤介绍后，您需要：\n  下载代码到本地,这一步您可以选择git/https方式.\ngit clone https://github.com/您的账号名/sofa-ark.git   拉分支准备修改代码\ngit branch add_xxx_feature 执行完上述命令后，您的代码仓库就切换到相应分支了。执行如下命令可以看到您当前分支：\ngit branch -a 如果您想切换回主干，执行下面命令:\ngit checkout -b master 如果您想切换回分支，执行下面命令：\ngit checkout -b \u0026amp;quot;branchName\u0026amp;quot;   修改代码提交到本地 拉完分支后，就可以修改代码了。\n修改代码注意事项   代码风格保持一致\nSOFAArk 通过 Maven 插件来保持代码格式一致.在提交代码前,务必本地执行\nmvn clean compile   补充单元测试代码\n  新有修改应该通过已有的单元测试.\n  应该提供新的单元测试来证明以前的代码存在 bug，而新的代码已经解决了这些 bug\n您可以用如下命令运行所有测试\nmvn clean test 也可以通过IDE来辅助运行。\n  其它注意事项  请保持您编辑的代码的原有风格，尤其是空格换行等. 对于无用的注释，请直接删除 对逻辑和功能不容易被理解的地方添加注释。 及时更新文档  修改完代码后，执行如下命令提交所有修改到本地:\ngit commit -am \u0026#39;添加xx功能\u0026#39; 提交代码到远程仓库 在代码提交到本地后，就是与远程仓库同步代码了。执行如下命令提交本地修改到 github 上：\ngit push origin \u0026amp;quot;branchname\u0026amp;quot; 如果前面您是通过 fork 来做的,那么这里的 origin 是 push 到您的代码仓库，而不是 SOFAArk 的代码仓库.\n提交合并代码到主干的请求 在的代码提交到 GitHub 后，您就可以发送请求来把您改好的代码合入 SOFAArk 主干代码了。此时您需要进入您的 GitHub 上的对应仓库，按右上角的 pull request按钮。选择目标分支,一般就是 master，系统会通知 SOFAArk 的人员， SOFAArk 人员会 Review 您的代码，符合要求后就会合入主干，成为 SOFAArk 的一部分。\n代码 Review 在您提交代码后，您的代码会被指派给维护人员 Review，请耐心等待。如果在数天后，仍然没有人对您的提交给予任何回复，可以在 PR 下面留言，并 @ 对应的人员.\n对于代码 Review 的意见会直接备注到到对应 PR 或者 Issue。如果觉得建议是合理的，也请您把这些建议更新到您的补丁中。\n合并代码到主干 在代码 Review 通过后，就由 SOFAArk 维护人员操作合入主干了。这一步不用参与，代码合并之后，您会收到合并成功的提示。\n","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-contribution/","fuzzywordcount":1300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"dbf77f98884a71c5c7a3fbb4dd189cfe","permalink":"/projects/sofa-boot/sofa-ark-contribution/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/sofa-boot/sofa-ark-contribution/","summary":"可以先去 发展路线 内了解下开发任务及未来规划。 准备工作 贡献代码前需要先了解 git 工具的使用和 GitHub 网站的使用。 git 工具用法可以查看 git官方书籍，需要阅","tags":null,"title":"参与贡献","type":"projects","url":"/projects/sofa-boot/sofa-ark-contribution/","wordcount":1278},{"author":null,"categories":null,"content":" 可以先去 RoadMap 内了解下开发任务及未来规划。\n 准备工作 贡献代码前需要先了解 git 工具的使用和 GitHub 网站的使用。\n git 工具用法可以查看 git官方书籍，需要阅读前几章来熟悉。 git 协作流程可以查看这篇文章 Git协作流程  GitHub 贡献代码流程 提交issue 不论您是修复 SOFADashboard 的 bug 还是新增 SOFADashboard 的功能，在您提交代码之前，在 SOFADashboard 的 GitHub 上提交一个 issue，描述您要修复的问题或者要增加的功能。\n这么做有几个好处:\n 不会与其它开发者或是他们对这个项目的计划发生冲突，产生重复工作. SOFADashboard 的维护人员会对您提的bug或者新增功能进行相关讨论，确定该修改是不是必要，有没有提升的空间或更好的办法。 在达成一致后再开发,并提交代码，减少双方沟通成本，也减少 pull request 被拒绝的情况。  获取源码 要修改或新增功能，在提 issue 后，点击左上角的 fork 按钮，复制一份 SOFADashboard 主干代码到您的代码仓库。\n拉分支 SOFADashboard 所有修改都在分支上进行，修改完后提交 pull request， 在 Code Review 后由项目维护人员 Merge 到主干。 因此，在获取源码步骤介绍后，您需要：\n 下载代码到本地,这一步您可以选择 git/https 方式. git clone https://github.com/您的账号名/sofa-dashboard.git  拉分支准备修改代码 git branch add_xxx_feature  执行完上述命令后，您的代码仓库就切换到相应分支了。执行如下命令可以看到您当前分支： git branch -a  如果您想切换回主干，执行下面命令: git checkout -b master  如果您想切换回分支，执行下面命令： git checkout -b \u0026amp;#34;branchName\u0026amp;#34;   修改代码提交到本地 拉完分支后，就可以修改代码了。\n修改代码注意事项   代码风格保持一致\nSOFADashboard 通过 Maven插件来保持代码格式一致。在提交代码前，务必本地执行\nmvn clean compile   补充单元测试代码\n  新有修改应该通过已有的单元测试.\n  应该提供新的单元测试来证明以前的代码存在 bug，而新的代码已经解决了这些 bug您可以用如下命令运行所有测试\nmvn clean test   也可以通过 IDE 来辅助运行。\n  其它注意事项  请保持您编辑的代码的原有风格，尤其是空格换行等. 对于无用的注释，请直接删除 对逻辑和功能不容易被理解的地方添加注释。 及时更新文档  修改完代码后，执行如下命令提交所有修改到本地：\ngit commit -am \u0026amp;#39;添加xx功能\u0026amp;#39; 提交代码到远程仓库 在代码提交到本地后，就是与远程仓库同步代码了。执行如下命令提交本地修改到 github 上：\ngit push origin \u0026amp;#34;branchname\u0026amp;#34; 如果前面您是通过 fork 来做的,那么这里的 origin 是 push 到您的代码仓库，而不是 SOFADashboard 的代码仓库。\n提交合并代码到主干的请求 在的代码提交到 GitHub 后，您就可以发送请求来把您改好的代码合入 SOFADashboard 主干代码了。此时您需要进入您的 GitHub 上的对应仓库，按右上角的 pull request按钮。选择目标分支,一般就是 master，系统会通知 SOFADashboard 的人员， SOFADashboard 人员会 Review 您的代码，符合要求后就会合入主干，成为 SOFADashboard 的一部分。\n代码 Review 在您提交代码后，您的代码会被指派给维护人员 Review，请耐心等待。如果在数天后，仍然没有人对您的提交给予任何回复，可以在 PR 下面留言，并 @ 对应的人员。 对于代码 Review 的意见会直接备注到到对应 PR 或者 Issue。如果觉得建议是合理的，也请您把这些建议更新到您的补丁中。\n合并代码到主干 在代码 Review 通过后，就由 SOFADashboard 维护人员操作合入主干了。这一步不用参与，代码合并之后，您会收到合并成功的提示。\n","date":-62135596800,"description":"","dir":"projects/sofa-dashboard/contribution/","fuzzywordcount":1300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"584584be9c13f2d36c85890dd192368a","permalink":"/projects/sofa-dashboard/contribution/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/sofa-dashboard/contribution/","summary":"可以先去 RoadMap 内了解下开发任务及未来规划。 准备工作 贡献代码前需要先了解 git 工具的使用和 GitHub 网站的使用。 git 工具用法可以查看 git官方书籍，需要阅读前几","tags":null,"title":"参与贡献","type":"projects","url":"/projects/sofa-dashboard/contribution/","wordcount":1270},{"author":null,"categories":null,"content":" 可以先去 发展路线 \u0026amp;amp; 任务认领 内了解下开发任务及未来规划。\n 准备工作 贡献代码前需要先了解 git 工具的使用和 GitHub 网站的使用。\n git 工具用法可以查看git官方书籍,需要阅读前几章来熟悉。 git 协作流程可以查看这篇文章 Git协作流程  GitHub 贡献代码流程 提交issue 不论您是修复 SOFARegistry 的 bug 还是新增 SOFARegistry 的功能，在您提交代码之前，在 SOFARegistry 的 GitHub 上提交一个 issue，描述您要修复的问题或者要增加的功能。这么做有几个好处:\n 不会与其它开发者或是他们对这个项目的计划发生冲突，产生重复工作. SOFARegistry 的维护人员会对您提的bug或者新增功能进行相关讨论，确定该修改是不是必要，有没有提升的空间或更好的办法。 在达成一致后再开发,并提交代码，减少双方沟通成本，也减少 pull request 被拒绝的情况。  获取源码 要修改或新增功能，在提 issue 后，点击左上角的 fork 按钮，复制一份 SOFARegistry 主干代码到您的代码仓库。\n拉分支 SOFARegistry 所有修改都在分支上进行，修改完后提交 pull request， 在 Code Review 后由项目维护人员 Merge 到主干。\n因此，在获取源码步骤介绍后，您需要：\n 下载代码到本地,这一步您可以选择 git/https 方式.  git clone https://github.com/您的账号名/sofa-registry.git  拉分支准备修改代码  git branch add_xxx_feature 执行完上述命令后，您的代码仓库就切换到相应分支了。执行如下命令可以看到您当前分支：\ngit branch -a 如果您想切换回主干，执行下面命令:\ngit checkout -b master 如果您想切换回分支，执行下面命令：\ngit checkout -b \u0026amp;#34;branchName\u0026amp;#34; 修改代码提交到本地 拉完分支后，就可以修改代码了。\n修改代码注意事项  代码风格保持一致  SOFARegistry 通过 Maven插件来保持代码格式一致.在提交代码前,务必本地执行\nmvn clean compile  补充单元测试代码 新有修改应该通过已有的单元测试. 应该提供新的单元测试来证明以前的代码存在 bug，而新的代码已经解决了这些 bug您可以用如下命令运行所有测试  mvn clean test 也可以通过 IDE 来辅助运行。\n其它注意事项  请保持您编辑的代码的原有风格，尤其是空格换行等. 对于无用的注释，请直接删除 对逻辑和功能不容易被理解的地方添加注释。 及时更新文档  修改完代码后，执行如下命令提交所有修改到本地:\ngit commit -am \u0026amp;#39;添加xx功能\u0026amp;#39; 提交代码到远程仓库 在代码提交到本地后，就是与远程仓库同步代码了。执行如下命令提交本地修改到 github 上：\ngit push origin \u0026amp;#34;branchname\u0026amp;#34; 如果前面您是通过 fork 来做的,那么这里的 origin 是 push 到您的代码仓库，而不是 SOFARegistry 的代码仓库.\n提交合并代码到主干的请求 在您的代码提交到 GitHub 后，您就可以发送请求来把您改好的代码合入 SOFARegistry 主干代码了。此时您需要进入您的 GitHub 上的对应仓库，按右上角的 pull request 按钮。选择目标分支,一般就是 master，系统会通知 SOFARegistry 的人员， SOFARegistry 人员会 Review 您的代码，符合要求后就会合入主干，成为 SOFARegistry 的一部分。\n代码 Review 在您提交代码后，您的代码会被指派给维护人员 Review，请耐心等待。如果在数天后，仍然没有人对您的提交给予任何回复，可以在 PR 下面留言，并 @ 对应的人员。\n对于代码 Review 的意见会直接备注到到对应 PR 或者 Issue。如果觉得建议是合理的，也请您把这些建议更新到您的补丁中。\n合并代码到主干 在代码 Review 通过后，就由 SOFARegistry 维护人员操作合入主干了。这一步不用参与，代码合并之后，您会收到合并成功的提示。\n","date":-62135596800,"description":"","dir":"projects/sofa-registry/contributing/","fuzzywordcount":1300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"c08b5945719137833634c111c43a8d9e","permalink":"/projects/sofa-registry/contributing/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/sofa-registry/contributing/","summary":"可以先去 发展路线 \u0026amp; 任务认领 内了解下开发任务及未来规划。 准备工作 贡献代码前需要先了解 git 工具的使用和 GitHub 网站的使用。 git 工具用法可以查看git官方书","tags":null,"title":"参与贡献","type":"projects","url":"/projects/sofa-registry/contributing/","wordcount":1272},{"author":null,"categories":null,"content":" 可以先去 发展路线 内了解下开发任务及未来规划。\n 准备工作 贡献代码前需要先了解 git 工具的使用和 GitHub 网站的使用。\n git 工具用法可以查看git官方书籍,需要阅读前几章来熟悉。 git 协作流程可以查看这篇文章Git协作流程  GitHub 贡献代码流程 提交issue 不论您是修复 SOFARPC 的 bug 还是新增 SOFARPC 的功能，在您提交代码之前，在 SOFARPC 的GitHub上提交一个 issue，描述您要修复的问题或者要增加的功能。这么做有几个好处:\n 不会与其它开发者或是他们对这个项目的计划发生冲突，产生重复工作. SOFARPC 的维护人员会对您提的bug或者新增功能进行相关讨论，确定该修改是不是必要，有没有提升的空间或更好的办法。 在达成一致后再开发,并提交代码，减少双方沟通成本，也减少pull request被拒绝的情况。  获取源码 要修改或新增功能，在提 issue 后，点击左上角的fork按钮，复制一份 SOFARPC 主干代码到您的代码仓库。\n拉分支 SOFARPC 所有修改都在分支上进行，修改完后提交 pull request， 在 Code Review 后由项目维护人员 Merge 到主干。\n因此，在获取源码步骤介绍后，您需要：\n  下载代码到本地,这一步您可以选择git/https方式.\ngit clone https://github.com/您的账号名/sofa-rpc.git   拉分支准备修改代码\ngit branch add_xxx_feature 执行完上述命令后，您的代码仓库就切换到相应分支了。执行如下命令可以看到您当前分支：\ngit branch -a 如果您想切换回主干，执行下面命令:\ngit checkout -b master 如果您想切换回分支，执行下面命令：\ngit checkout -b \u0026amp;quot;branchName\u0026amp;quot;   修改代码提交到本地 拉完分支后，就可以修改代码了。\n修改代码注意事项   代码风格保持一致\nSOFARPC 通过 Maven插件来保持代码格式一致.在提交代码前,务必本地执行\nmvn clean compile   补充单元测试代码\n  新有修改应该通过已有的单元测试.\n  应该提供新的单元测试来证明以前的代码存在 bug，而新的代码已经解决了这些 bug\n您可以用如下命令运行所有测试\nmvn clean test 也可以通过IDE来辅助运行。\n  其它注意事项  请保持您编辑的代码的原有风格，尤其是空格换行等. 对于无用的注释，请直接删除 对逻辑和功能不容易被理解的地方添加注释。 及时更新文档  修改完代码后，执行如下命令提交所有修改到本地:\ngit commit -am \u0026#39;添加xx功能\u0026#39; 提交代码到远程仓库 在代码提交到本地后，就是与远程仓库同步代码了。执行如下命令提交本地修改到 github 上：\ngit push origin \u0026amp;quot;branchname\u0026amp;quot; 如果前面您是通过 fork 来做的,那么这里的 origin 是 push 到您的代码仓库，而不是 SOFARPC 的代码仓库.\n提交合并代码到主干的请求 在的代码提交到 GitHub 后，您就可以发送请求来把您改好的代码合入 SOFARPC 主干代码了。此时您需要进入您的 GitHub 上的对应仓库，按右上角的 pull request按钮。选择目标分支,一般就是 master，系统会通知 SOFARPC 的人员， SOFARPC 人员会 Review 您的代码，符合要求后就会合入主干，成为 SOFARPC 的一部分。\n代码 Review 在您提交代码后，您的代码会被指派给维护人员 Review，请耐心等待。如果在数天后，仍然没有人对您的提交给予任何回复，可以在 PR 下面留言，并 @ 对应的人员.\n对于代码 Review 的意见会直接备注到到对应 PR 或者 Issue。如果觉得建议是合理的，也请您把这些建议更新到您的补丁中。\n合并代码到主干 在代码 Review 通过后，就由 SOFARPC 维护人员操作合入主干了。这一步不用参与，代码合并之后，您会收到合并成功的提示。\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/contributing/","fuzzywordcount":1300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"448a7b9a949bd2d9e2e71ac6c237f9df","permalink":"/projects/sofa-rpc/contributing/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/sofa-rpc/contributing/","summary":"可以先去 发展路线 内了解下开发任务及未来规划。 准备工作 贡献代码前需要先了解 git 工具的使用和 GitHub 网站的使用。 git 工具用法可以查看git官方书籍,需要阅","tags":null,"title":"参与贡献","type":"projects","url":"/projects/sofa-rpc/contributing/","wordcount":1284},{"author":null,"categories":null,"content":"客户端发展规划  v2.0 ，在基于 Java 8 进行重构，v1.0 为支持 Java 6 做了些设计与性能妥协； 集成更多的开源产品；  ","date":-62135596800,"description":"","dir":"projects/sofa-lookout/plan/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"6153fc1f5e000f195d96dfdb03c5b381","permalink":"/projects/sofa-lookout/plan/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-lookout/plan/","summary":"客户端发展规划 v2.0 ，在基于 Java 8 进行重构，v1.0 为支持 Java 6 做了些设计与性能妥协； 集成更多的开源产品；","tags":null,"title":"发展规划","type":"projects","url":"/projects/sofa-lookout/plan/","wordcount":49},{"author":null,"categories":null,"content":"任务列表 下面表格记录了还没有实现的功能特性，欢迎大家认领任务，参与贡献。\n   类型 任务 困难度 认领人及时间 计划完成时间 进度 相关 Issue     代码 支持多个 Web 应用合并部署，采用多 Host/单 Host 两种模式 难       代码 支持 telnet 指令查看 ark plugin 简单       代码 支持 telnet 指令查看 jvm/rpc 服务 中        版本迭代计划 v0.5.0  支持多个 Web 应用合并部署，采用多 Host/单 Host 两种模式  v0.6.0  支持 telnet 指令查看 ark plugin； 支持 telnet 指令查看 jvm/rpc 服务；  ","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-roadmap/","fuzzywordcount":200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"c4532d11cef15d8fe3ff5e04c7b08f90","permalink":"/projects/sofa-boot/sofa-ark-roadmap/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-boot/sofa-ark-roadmap/","summary":"任务列表 下面表格记录了还没有实现的功能特性，欢迎大家认领任务，参与贡献。 类型 任务 困难度 认领人及时间 计划完成时间 进度 相关 Issue 代码 支持多个 Web 应用合","tags":null,"title":"发展路线","type":"projects","url":"/projects/sofa-boot/sofa-ark-roadmap/","wordcount":175},{"author":null,"categories":null,"content":"任务列表 部分内部已有的功能特性，待内部整理完毕后随各个迭代放出。\n如果还没有实现的功能特性会列在下面的表格中，欢迎大家认领任务，参与贡献。\n   类型 任务 困难度 认领人及时间 计划完成时间 进度 相关Issue     文档 文档翻译 低       代码 弹性长连接管理方式 低    #56   代码 etcd注册中心实现 中 @wynn5a2018-6   #153   代码 eureka注册中心实现 中 @liufeiit2018-4   #52   代码 gRPC 支持 高    #57   代码 CXF 协议 高    #58   代码 TLS 支持 高        版本迭代计划 v5.5.0  JSON 序列化支持 H2的TLS安全支持 弹性连接池 hystrix集成 Consul注册中心支持  v5.6.0  grpc 通讯层支持 etcd注册中心支持 SofaMesh支持 BOLT 版本协商与 CRC 校验  v5.7.0  Telnet 内置指令支持 SpringBoot 2.0 支持 Mock功能支持 加密功能支持  v5.8.0  授权支持 SofaRegistry 支持 Reactive 支持  ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/roadmap/","fuzzywordcount":300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"6064fc180911f520f6d1590b88595693","permalink":"/projects/sofa-rpc/roadmap/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/roadmap/","summary":"任务列表 部分内部已有的功能特性，待内部整理完毕后随各个迭代放出。 如果还没有实现的功能特性会列在下面的表格中，欢迎大家认领任务，参与贡献。 类型","tags":null,"title":"发展路线","type":"projects","url":"/projects/sofa-rpc/roadmap/","wordcount":290},{"author":null,"categories":null,"content":"任务列表 欢迎大家领取任务参与贡献。\n   类型 任务 困难度 认领人及时间 计划发布时间 计划完成时间 进度 相关 issue     代码 SOFATracer 性能优化专题 高     issue 18和 issue 11   代码 SOFATracer 支持 HttpClient 中    已经完成，见 HttpClient 接入文档    代码 SOFATracer 数据汇报能力提供在非 SOFABoot 框架下的运行和配置能力 中    已经完成，见 Spring 工程中使用 SOFATracer issue 32   代码 SOFATracer 提供采样能力 中    已经完成，见使用 SOFATracer 的采样能力 issue 10   代码 SOFATracer 支持 Zipkin 2.X.X 版本 中    已经完成，见使用 SOFATracer 远程汇报数据到 Zipkin issue 23   代码 SOFATracer 支持 Druid 中    已经完成，见 DataSource 接入文档    代码 SOFATracer 支持 c3p0 中    已经完成    代码 SOFATracer 支持 Tomcat-JDBC 中    已经完成    代码 SOFATracer 支持 HikariCP 中    已经完成    代码 SOFATracer 支持 dbcp 中    已经完成，见 DataSource 接入文档    代码 SOFATracer 支持 dbcp2 中    已经完成    代码 SOFATracer 支持 Sharding-JDBC 中        代码 SOFATracer 支持 Mysql JDBC Driver 中        代码 SOFATracer 支持 Oracle JDBC Driver 中        代码 SOFATracer 支持 Dubbo 中        代码 SOFATracer 支持 RestTemplate 和 AsyncRestTemplate 中    已经完成    代码 SOFATracer 支持标准Servlet 中    已经完成，见对于标准 servlet 容器的支持（ tomcat/jetty 等）    代码 SOFATracer 支持单机版链路分析并给用户通过注解使用的埋点方式，数据汇报到 Zipkin 中        代码 SOFATracer 支持 Kafka 中        代码 SOFATracer 支持 Redis 中        代码 SOFATracer 支持 hystrix 中        文档 文档翻译 中         版本迭代计划 2.2.0  SOFATracer 支持 JDBC 数据源  SOFATracer 支持 Mysql Driver SOFATracer 支持 Sharding-JDBC SOFATracer 支持 Mysql-JDBC SOFATracer 支持 Druid SOFATracer 支持 c3p0 SOFATracer 支持 Tomcat-JDBC SOFATracer 支持 HikariCP   SOFATracer 支持 HttpClient SOFATracer 支持 Zipkin 2.X.X 版本，开发验证并测试  2.3.0  SOFATracer 支持RestTemplate 和 AsyncRestTemplate SOFATracer 支持提供采样能力 SOFATracer 支持标准 servlet 容器 SOFATracer 支持 Zipkin UI 中文界面 SOFATracer 支持数据汇报能力提供在非 SOFABoot 框架下的运行和配置能力  2.4.0  SOFATracer 支持 Dubbo SOFATracer 支持 Kafka SOFATracer 性能优化专题  2.5.0  SOFATracer 支持单机版链路分析并给用户通过注解使用的埋点方式，数据汇报到 Zipkin 展示 SOFATracer 支持 manual report SOFATracer 支持 基于 Opentracing API 埋点方式 SOFATracer 支持 Opentracing 0.30.0+ 版本  ","date":-62135596800,"description":"","dir":"projects/sofa-tracer/roadmap/","fuzzywordcount":700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"8b0a6fbe5f6ea5ae789f5186271073c3","permalink":"/projects/sofa-tracer/roadmap/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-tracer/roadmap/","summary":"任务列表 欢迎大家领取任务参与贡献。 类型 任务 困难度 认领人及时间 计划发布时间 计划完成时间 进度 相关 issue 代码 SOFATracer 性能优化专题 高 issue 18和 issue 11 代码 SOFATracer 支持 HttpClient 中","tags":null,"title":"发展路线","type":"projects","url":"/projects/sofa-tracer/roadmap/","wordcount":605},{"author":null,"categories":null,"content":"发展路线 任务列表 部分内部已有的功能特性，待内部整理完毕后随各个迭代放出。\n如果还没有实现的功能特性会列在下面的表格中，欢迎大家认领任务，参与贡献。\n   类型 任务 困难度 认领人及时间 计划完成时间 进度 相关issue     文档 文档翻译 低       代码 支持Spring Cloud 中       代码 数据自检 高       代码 黑名单过滤 中       代码 SOFARegistry Dashboard 高       代码 支持其他微服务框架 中       代码 支持 Docker \u0026amp;amp; Kubernetes 高       代码 多语言客户端支持 高        版本迭代计划 v5.3.0  支持 Spring Cloud 数据自检 黑名单过滤  v5.4.0  SOFARegistry Dashboard 支持其他微服务框架  v5.5.0  支持 Docker \u0026amp;amp; Kubernetes 多语言客户端支持  ","date":-62135596800,"description":"","dir":"projects/sofa-registry/roadmap/","fuzzywordcount":300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"b0ab45d52ba3eb7db590a4f5e4197c9e","permalink":"/projects/sofa-registry/roadmap/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-registry/roadmap/","summary":"发展路线 任务列表 部分内部已有的功能特性，待内部整理完毕后随各个迭代放出。 如果还没有实现的功能特性会列在下面的表格中，欢迎大家认领任务，参与贡","tags":null,"title":"发展路线 \u0026 任务认领","type":"projects","url":"/projects/sofa-registry/roadmap/","wordcount":216},{"author":null,"categories":null,"content":"更多参见：https://github.com/mosn/mosn/blob/master/CHANGELOG_ZH.md\n","date":-62135596800,"description":"","dir":"projects/mosn/release-notes/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"62efb8e40401ab4612bcccaa6e942c97","permalink":"/projects/mosn/release-notes/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/mosn/release-notes/","summary":"更多参见：https://github.com/mosn/mosn/blob/master/CHANGELOG_ZH.md","tags":null,"title":"发布历史","type":"projects","url":"/projects/mosn/release-notes/","wordcount":61},{"author":null,"categories":null,"content":"更多参见：https://github.com/sofastack/sofa-rpc/releases\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/release-notes/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"ab7d46caa6906863103b77b742ec7e84","permalink":"/projects/sofa-rpc/release-notes/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/release-notes/","summary":"更多参见：https://github.com/sofastack/sofa-rpc/releases","tags":null,"title":"发布历史","type":"projects","url":"/projects/sofa-rpc/release-notes/","wordcount":51},{"author":null,"categories":null,"content":"更多参见：https://github.com/sofastack/sofa-ark/releases\n","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-release/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"994c3569ea416ee5b0dea253f08af6be","permalink":"/projects/sofa-boot/sofa-ark-release/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-boot/sofa-ark-release/","summary":"更多参见：https://github.com/sofastack/sofa-ark/releases","tags":null,"title":"发布说明","type":"projects","url":"/projects/sofa-boot/sofa-ark-release/","wordcount":51},{"author":null,"categories":null,"content":"更多参见：https://github.com/sofastack/sofa-dashboard/releases\n","date":-62135596800,"description":"","dir":"projects/sofa-dashboard/release-node/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"3c8e6985123810c9692f47cc56b50081","permalink":"/projects/sofa-dashboard/release-node/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-dashboard/release-node/","summary":"更多参见：https://github.com/sofastack/sofa-dashboard/releases","tags":null,"title":"发布说明","type":"projects","url":"/projects/sofa-dashboard/release-node/","wordcount":57},{"author":null,"categories":null,"content":"更多参见：https://github.com/sofastack/sofa-registry/releases\n","date":-62135596800,"description":"","dir":"projects/sofa-registry/release-notes/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"d92dddf77bbbd6078f3f96ba2224a53d","permalink":"/projects/sofa-registry/release-notes/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-registry/release-notes/","summary":"更多参见：https://github.com/sofastack/sofa-registry/releases","tags":null,"title":"发布说明","type":"projects","url":"/projects/sofa-registry/release-notes/","wordcount":56},{"author":null,"categories":null,"content":"SOFABoot 提供了模块并行加载以及 Spring Bean 异步初始化能力，用于加快应用启动速度。模块并行加载参考相应文档，下面介绍如何使用 SOFABoot 异步初始化 Spring Bean 能力来提高应用启动速度。\n引入依赖 SOFABoot 在 v2.6.0 开始提供异步初始化 Spring Bean 能力，引入如下 Starter 即可：\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;runtime-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 使用场景 在实际使用 Spring/Spring Boot 开发中，会有一些 Bean 在初始化过程中执行准备操作，如拉取远程配置、初始化数据源等等；在应用启动期间，这类 Bean 会增加 Spring 上下文刷新时间，导致应用启动耗时变长。为了加速应用启动，SOFABoot 通过配置可选项，将 Bean 的初始化方法(init-method) 使用单独线程异步执行，加快 Spring 上下文加载过程，提高应用启动速度。\n使用方法 异步初始化 Bean 的原理是开启单独线程负责执行 Bean 的初始化方法(init-method)，因此在使用过程中，除了引入上述依赖管理，还需要在 Bean 的 xml 定义中配置 sofa:async-init=\u0026amp;quot;true\u0026amp;quot; 属性，用于指定是否异步执行该 Bean 的初始化方法，例如：\n\u0026amp;lt;?xml version=\u0026amp;#34;1.0\u0026amp;#34; encoding=\u0026amp;#34;UTF-8\u0026amp;#34;?\u0026amp;gt; \u0026amp;lt;beans xmlns=\u0026amp;#34;http://www.springframework.org/schema/beans\u0026amp;#34; xmlns:xsi=\u0026amp;#34;http://www.w3.org/2001/XMLSchema-instance\u0026amp;#34; xmlns:sofa=\u0026amp;#34;http://sofastack.io/schema/sofaboot\u0026amp;#34; xsi:schemaLocation=\u0026amp;#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://sofastack.io/schema/sofaboot http://sofastack.io/schema/sofaboot.xsd\u0026amp;#34; default-autowire=\u0026amp;#34;byName\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;!-- async init test --\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;#34;testBean\u0026amp;#34; class=\u0026amp;#34;com.alipay.sofa.runtime.beans.TimeWasteBean\u0026amp;#34; init-method=\u0026amp;#34;init\u0026amp;#34; sofa:async-init=\u0026amp;#34;true\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/beans\u0026amp;gt; 配置 SOFABoot 异步初始化能力提供两个属性配置，用于指定负责异步执行 Bean 初始化方法(init-method)的线程池大小：\n com.alipay.sofa.boot.asyncInitBeanCoreSize   线程池基本大小，默认值为 CPU 核数加一\n  com.alipay.sofa.boot.asyncInitBeanMaxSize   线程池中允许的最大线程数大小，默认值为 CPU 核数加一\n 配置可以通过 VM -D 参数或者 Spring Boot 配置文件 application.yml 设置。\n","date":-62135596800,"description":"","dir":"projects/sofa-boot/speed-up-startup/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"ebd933894c7828948b87610d1d0ca020","permalink":"/projects/sofa-boot/speed-up-startup/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-boot/speed-up-startup/","summary":"SOFABoot 提供了模块并行加载以及 Spring Bean 异步初始化能力，用于加快应用启动速度。模块并行加载参考相应文档，下面介绍如何使用 SOFABoot 异步初始化 Spring Bean 能力来提高应用启","tags":null,"title":"启动加速","type":"projects","url":"/projects/sofa-boot/speed-up-startup/","wordcount":515},{"author":null,"categories":null,"content":"本文旨在描述如何在 Kubernetes 快速开始安装和配置 Istio。 SOFA Mosn 不仅可以支持 Istio 标准的部署模式，也能支持单方面的 Inbound Sidecar，Outbound Sidecar的部署模式，满足用户的各种需求。\n前置要求  Docker Docker Compose  安装步骤  下载最新的 release 包 解压安装文件，并且进入解压后的路径，安装路径包含：   示例应用路径 samples/ /bin 路径下应该能找到 istioctl 客户端可执行文件，istioctl 可用于创建路由规则和策略 配置文件 istion.VERSION  把 Istio 的 bin 路径添加到系统的 PATH。比如，在 MacOS 或者 Linux 系统下执行如下命令： export PATH=$PWD/bin;$PATH  安装helm 创建命名空间 kubectl create namespace istio-system  使用helm安装istio CRD helm template install/kubernetes/helm/istio-init --name istio-init --namespace istio-system | kubectl apply -f -  使用helm安装各个组件 helm template install/kubernetes/helm/istio --name istio --namespace istio-system | kubectl apply -f -  确认所有 pod 都在运行中： kubectl get pod -n istio-system 如果 Istio pilot 容器意外终止，确保运行 istioctl context-create 命令，并且重新执行上一个命令。\n  部署应用程序 现在开始部署 Bookinfo 示例程序 为 default 命名空间打上标签 istio-injection=enabled，实现 Sidecar 自动注入\nkubectl label namespace default istio-injection=enabled 使用 kubectl 部署Bookinfo的服务\nkubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml 确认所有的服务和 Pod 都已经正确的定义和启动\nkubectl get services kubectl get pods 卸载 Istio helm template install/kubernetes/helm/istio --name istio --namespace istio-system | kubectl delete -f - kubectl delete namespace istio-system ","date":-62135596800,"description":"","dir":"projects/sofa-mesh/pilot-setup-zookeeper-quick-start-docker/","fuzzywordcount":500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"1de4868fa0e9c73d932343847864d7fb","permalink":"/projects/sofa-mesh/pilot-setup-zookeeper-quick-start-docker/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-mesh/pilot-setup-zookeeper-quick-start-docker/","summary":"本文旨在描述如何在 Kubernetes 快速开始安装和配置 Istio。 SOFA Mosn 不仅可以支持 Istio 标准的部署模式，也能支持单方面的 Inbound Sidecar，Outbound Sid","tags":null,"title":"在 Kubernetes 中快速开始","type":"projects","url":"/projects/sofa-mesh/pilot-setup-zookeeper-quick-start-docker/","wordcount":463},{"author":null,"categories":null,"content":"本文旨在描述如何在 Kubernetes 快速开始安装和配置 Istio。\nSOFA Mosn 不仅可以支持 Istio 标准的部署模式，也能支持单方面的 Inbound Sidecar，Outbound Sidecar的部署模式，满足用户的各种需求。\n前置要求  Kubernetes 安装 Helm  安装步骤 Step 1. 下载最新的 release 包 Step 2. 把 Istio 的 bin 路径添加到系统的 PATH。比如，在 Linux 系统下执行如下命令：\nexport PATH=$PWD/bin;$PATH Step 3. 创建命名空间\nkubectl create namespace istio-system Step 4. 使用helm安装istio CRD\nhelm template install/kubernetes/helm/istio-init --name istio-init --namespace istio-system | kubectl apply -f - Step 5. 使用helm安装各个组件\nhelm template install/kubernetes/helm/istio --name istio --namespace istio-system | kubectl apply -f - Step 6. 确认所有 pod 都在运行中\nkubectl get pod -n istio-system 部署应用程序 现在开始部署 Bookinfo 示例程序。\n为 default 命名空间打上标签 istio-injection=enabled，实现 Sidecar 自动注入：\nkubectl label namespace default istio-injection=enabled 使用 kubectl 部署Bookinfo的服务：\nkubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml 确认所有的服务和 Pod 都已经正确的定义和启动：\nkubectl get services kubectl get pods 卸载 Istio helm template install/kubernetes/helm/istio --name istio --namespace istio-system | kubectl delete -f - kubectl delete namespace istio-system ","date":-62135596800,"description":"","dir":"projects/sofa-mesh/sofa-mesh-setup/","fuzzywordcount":400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"940d012b4883e5c91bf777916cd3c6b3","permalink":"/projects/sofa-mesh/sofa-mesh-setup/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-mesh/sofa-mesh-setup/","summary":"本文旨在描述如何在 Kubernetes 快速开始安装和配置 Istio。 SOFA Mosn 不仅可以支持 Istio 标准的部署模式，也能支持单方面的 Inbound Sidecar，Outbound Sid","tags":null,"title":"在 Kubernetes 中快速开始","type":"projects","url":"/projects/sofa-mesh/sofa-mesh-setup/","wordcount":362},{"author":null,"categories":null,"content":"","date":-62135596800,"description":"使用该指南您可以体验到快速创建 Serveless 应用、根据业务请求秒级 0-1-N 自动伸缩、通过日志查看器快速排错、按时间触发应用等产品新功能。","dir":"guides/kc-serverless-demo/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"f355d1b598fed47b730bd74ad25f3683","permalink":"/guides/kc-serverless-demo/","publishdate":"0001-01-01T00:00:00Z","readingtime":0,"relpermalink":"/guides/kc-serverless-demo/","summary":"","tags":null,"title":"基于 Serverless 轻松构建云上应用","type":"guides","url":"/guides/kc-serverless-demo/","wordcount":0},{"author":null,"categories":null,"content":"Ark 包 SOFAArk 定义特殊格式的可执行 Jar 包，使用官方提供的 Maven 插件 sofa-ark-maven-plugin 可以将工程应用打包成一个标准格式的 Ark 包；使用命令 java -jar 即可在 SOFAArk 容器之上启动应用；Ark 包 通常包含 Ark Container 、Ark Plugin 依赖（如果有）、合并部署的 Ark Biz （如果有）以及应用自身的 Ark Biz；详情可参考 Ark 包；\nArk Container Ark 容器，Ark Plugin 和 Ark Biz 运行在 SOFAArk 容器之上；容器具备管理多插件、多应用的功能；容器启动成功后，会解析 Ark Plugin 和 Ark Biz 配置，完成隔离加载并按优先级依次启动之；Ark Container 一般不会被用户直接感知，由打包插件 sofa-ark-maven-plugin 自动打入。详情可参考 SOFAArk 容器启动；\nArk Plugin Ark 插件，SOFAArk 定义特殊格式的 Fat Jar，使用官方提供的 Maven 插件 sofa-ark-plugin-maven-plugin 可以将一个或多个普通的 Java Jar 包打包成一个标准格式的 Ark Plugin； Ark Plugin 会包含一份配置文件，通常包括插件类和资源的导入导出配置、插件启动优先级等；运行时，Ark 容器会使用独立的 PluginClassLoader 加载插件，并根据插件配置构建类加载索引表，从而使插件与插件、插件与应用之间相互隔离；详情可参考 Ark Plugin；\nArk Biz Ark 模块，SOFAArk 定义特殊格式的 Fat Jar ，使用官方提供的 Maven 插件 sofa-ark-maven-plugin 可以将工程应用打包成一个标准格式的 Ark Biz 包；作用有二点，一、在 Ark 包 中，作为工程应用模块及其依赖包的组织单元；二、可以被其他应用当成普通 Jar 包依赖，用于在同一个 SOFAArk 容器启动多个 Ark Biz；多个 Ark Biz 共享 Ark Container 和 Ark Plugin ；详情可参考 Ark Biz；\n合并部署 SOFAArk 允许将多个应用（Biz 包）合并打入到 Ark 包中，当启动 Ark 包时，会启动所有应用；也支持在运行时通过 API 或者配置中心（例如 Zookeeper）动态的部署和卸载应用，这些应用同时运行在同一个 JVM 中，由独立的 BizClassLoader 加载，各应用之间通过 SofaService/SofaReference 实现交互，称之为多应用的合并部署。\n宿主应用 宿主应用是相对合并部署而言，在打包 Ark 包时，至少有一个 Biz 包被打入，如果应用引入了其他 Biz 包，则 Ark 包中会存在多个 Biz 包。当只有一个 Biz 包时，默认将其设置为宿主应用；如果存在多个 Biz 包，则需要配置指定宿主应用。宿主应用相对其他 Biz 包最大的不同，即不允许被卸载。\n简单总结下，在 SOFAArk 框架中，应用(配置、源码、依赖)被打包成 Biz 包组织在一起，但是特殊的依赖（Ark Plugin 和其他应用 Biz 包）不会被打入 Biz 包中，Biz 包是不可执行的 Fat Jar; Ark Plugin 是特殊的二方包，可以将多个二方依赖打包成 Plugin，运行时由独立的 PluginClassLoader 加载，根据打包时配置的导出导入资源、类，构建运行时类加载模型；Ark 包是可执行 Fat Jar，一般由 Ark Container、Ark Plugin(0个或多个)、Ark Biz(至少一个)。\n","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-terminology/","fuzzywordcount":1100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"b6d0ed10afe9d04bc00307017ffba7c5","permalink":"/projects/sofa-boot/sofa-ark-terminology/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/sofa-boot/sofa-ark-terminology/","summary":"Ark 包 SOFAArk 定义特殊格式的可执行 Jar 包，使用官方提供的 Maven 插件 sofa-ark-maven-plugin 可以将工程应用打包成一个标准格式的 Ark 包；使用命令 java -jar 即可在 SOFAArk 容器之上启动应用；Ark 包","tags":null,"title":"基础术语","type":"projects","url":"/projects/sofa-boot/sofa-ark-terminology/","wordcount":1015},{"author":null,"categories":null,"content":"业界通用术语    术语 说明     服务（Service） 通过网络提供的、具有特定业务逻辑处理能力的软件功能。   服务提供者（Service Provider） 通过网络提供服务的计算机节点。   服务消费者（Service Consumer） 通过网络调用服务的计算机节点。一个计算机节点可以既作为一些服务的提供者，又作为一些服务的消费者。   服务发现（Service Discovery） 服务消费者获取服务提供者的网络地址的过程。   服务注册中心（Service Registry） 一种提供服务发现功能的软件系统，帮助服务消费者获取服务提供者的网络地址。   数据中心（Data Center） 物理位置、供电、网络具备一定独立性的物理区域，通常作为高可用设计的重要考量粒度。一般可认为：同一数据中心内，网络质量较高、网络传输延时较低、同时遇到灾难的概率较大；不同数据中心间，网络质量较低、网络延时较高、同时遇到灾难的概率较小。    SOFARegistry 约定术语    术语 说明     SOFARegistry 蚂蚁金服开源的一款服务注册中心产品，基于“发布-订阅”模式实现服务发现功能。同时它并不假定总是用于服务发现，也可用于其他更一般的“发布-订阅”场景。   数据（Data） 在服务发现场景下，特指服务提供者的网络地址及其它附加信息。其他场景下，也可以表示任意发布到 SOFARegistry 的信息。   单元（Zone） 单元化架构关键概念，在服务发现场景下，单元是一组发布与订阅的集合，发布及订阅服务时需指定单元名，更多内容可参考异地多活单元化架构解决方案。   发布者（Publisher） 发布数据到 SOFARegistry 的节点。在服务发现场景下，服务提供者就是“服务提供者的网络地址及其它附加信息”的发布者。   订阅者（Subscriber） 从 SOFARegistry 订阅数据的节点。在服务发现场景下，服务消费者就是“服务提供者的网络地址及其它附加信息”的订阅者。   数据标识（DataId） 用来标识数据的字符串。在服务发现场景下，通常由服务接口名、协议、版本号等信息组成，作为服务的标识。   分组标识（GroupId） 用于为数据归类的字符串，可以作为数据标识的命名空间，即只有 DataId、GroupId、InstanceId 都相同的服务，才属于同一服务。   实例 ID（InstanceId） 实例 ID，可以作为数据标识的命名空间，即只有DataId、GroupId、InstanceId都相同的服务，才属于同一服务。   会话服务器（SessionServer） SOFARegistry 内部负责跟客户端建立 TCP 长连接、进行数据交互的一种服务器角色。   数据服务器（DataServer） SOFARegistry 内部负责数据存储的一种服务器角色。   元信息服务器（MetaServer） SOFARegistry 内部基于 Raft 协议，负责集群内一致性协调的一种服务器角色。    ","date":-62135596800,"description":"","dir":"projects/sofa-registry/terminology/","fuzzywordcount":1100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"b678a49547c55f2a70e2d94dbce5b4a2","permalink":"/projects/sofa-registry/terminology/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/sofa-registry/terminology/","summary":"业界通用术语 术语 说明 服务（Service） 通过网络提供的、具有特定业务逻辑处理能力的软件功能。 服务提供者（Service Provider） 通","tags":null,"title":"基础术语","type":"projects","url":"/projects/sofa-registry/terminology/","wordcount":1089},{"author":null,"categories":null,"content":"   名词 说明     TraceId TraceId 指的是 SOFATracer 中代表唯一一次请求的 ID，此 ID 一般由集群中第一个处理请求的系统产生，并在分布式调用下通过网络传递到下一个被请求系统。   SpanId SpanId 代表了本次请求在整个调用链路中的位置或者说层次，比如 A 系统在处理一个请求的过程中依次调用了 B，C，D 三个系统，那么这三次调用的的 SpanId 分别是：0.1，0.2，0.3。如果 B 系统继续调用了 E，F 两个系统，那么这两次调用的 SpanId 分别是：0.1.1，0.1.2。    其他相关的名词解释可以参考 OpenTracing 规范。\n","date":-62135596800,"description":"","dir":"projects/sofa-tracer/explanation/","fuzzywordcount":300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"8ba307b0679e918f7ac68c7efb7e53f7","permalink":"/projects/sofa-tracer/explanation/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-tracer/explanation/","summary":"名词 说明 TraceId TraceId 指的是 SOFATracer 中代表唯一一次请求的 ID，此 ID 一般由集群中第一个处理请求的系统产生，并在分布式调用下通过网络传递到下一个被请求系统。 SpanId SpanId","tags":null,"title":"基础术语","type":"projects","url":"/projects/sofa-tracer/explanation/","wordcount":211},{"author":null,"categories":null,"content":"消息 内部全部使用 SofaRequest 和 SofaResponse 进行传递。\n如果需要转换为其它协议，那么在真正调用和收到请求的时候，转换为实际要传输的对象。\n可以对 SofaRequest 和 SofaResponse 进行写操作的模块：\n Invoker Filter ServerHandler Serialization  对消息体是只读的模块：\n Cluster Router LoadBalance  日志 日志的初始化也是基于扩展机制。虽然是扩展，但是由于日志的加载应该是最早的，所以在 rpc-config.json 里有一个单独的 Key。\n{ // 日志实现，日志早于配置加载，所以不能适应Extension机制 \u0026amp;#34;logger.impl\u0026amp;#34;: \u0026amp;#34;com.alipay.sofa.rpc.log.MiddlewareLoggerImpl\u0026amp;#34; } 配置项 使用者的 RPC 配置 用户的配置，例如端口配置（虽然已经开放对象中设置端口的字段，但是sofa默认是从配置文件里取的），线程池大小配置等。\n 通过 SofaConfigs 加载配置，调用 ExternalConfigLoader 读取外部属性。 通过 SofaConfigs 提供的 API 进行获取。 所有内部配置的Key都在 SofaOptions 类 优先级： System.property \u0026amp;gt; sofa-config.properties(每个应用一个) \u0026amp;gt; rpc-config.properties  RPC 框架配置 框架自身的配置，例如默认序列化，默认超时等。 未来要一个ClassLoader一个。\n 通过 RpcConfigs 加载配置文件。 通过 RpcConfigs 其提供的API进行获取和监听数据变化 所有内部配置的Key都在 RpcOptions 类 优先级： System.property \u0026amp;gt; custom rpc-config.json（可能存在多个自定义，会排序） \u0026amp;gt; rpc-config-default.json  常量  全局的基本常量在 RpcConstants 中。例如：  调用方式 sync oneway 协议 bolt/grpc、 序列化 hessian/java/protobuf 上下文的key 等等。   如果扩展实现自身的常量，请自行维护。  例如 BOLT 协议的常量。  SERIALIZE_CODE_HESSIAN = 1 PROTOCOL_TR = 13   例如 DSR 配置中心相关的常量。  _WEIGHT、_CONNECTTIMEOUT 这种 配置中心特有的key      地址  地址信息放到 ProviderInfo 类中 ProviderInfo 的值主要分为三部分  字段，一般是一些必须项目。 例如IP，端口，状态等； 静态字段：例如应用名； 动态字段：例如预热权重等；   字段枚举维护在 ProviderInfoAttrs 类中。  ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/common-model/","fuzzywordcount":700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"b2cc3f7ed134408d6adc25e418e1978b","permalink":"/projects/sofa-rpc/common-model/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-rpc/common-model/","summary":"消息 内部全部使用 SofaRequest 和 SofaResponse 进行传递。 如果需要转换为其它协议，那么在真正调用和收到请求的时候，转换为实际要传输的对象。 可以对 SofaRequest 和 SofaResponse 进行写操作的模块","tags":null,"title":"基础模型","type":"projects","url":"/projects/sofa-rpc/common-model/","wordcount":669},{"author":null,"categories":null,"content":"准备工作 贡献代码前需要先了解 git 工具的使用和 GitHub 网站的使用。\n git 工具用法可以查看 git 官方书籍,需要阅读前几章来熟悉。 git 协作流程可以查看这篇文章 git 协作流程  GitHub 贡献代码流程 提交issue 不论您是修复 SOFAJRaft 的 bug 还是新增 SOFAJRaft 的功能，在您提交代码之前，在 SOFAJRaft 的 GitHub 上提交一个 issue，描述您要修复的问题或者要增加的功能。这么做有几个好处:\n 不会与其它开发者或是他们对这个项目的计划发生冲突，产生重复工作。 SOFAJRaft 的维护人员会对您提的 bug 或者新增功能进行相关讨论，确定该修改是不是必要，有没有提升的空间或更好的办法。 在达成一致后再开发，并提交代码，减少双方沟通成本，也减少 pull request 被拒绝的情况。  获取源码 要修改或新增功能，在提 issue 后，点击左上角的 fork 按钮，复制一份 SOFAJRaft 主干代码到您的代码仓库。\n拉分支 在这之前，可以先看看 SOFAJRaft 的 分支管理策略\nSOFAJRaft 所有修改都在分支上进行，修改完后提交 pull request，在 Code Review 后由项目维护人员 Merge 到主干。 因此，在获取源码步骤介绍后，您需要：\n  下载代码到本地，这一步您可以选择git/https方式。\ngit clone https://github.com/您的账号名/sofa-jraft   拉分支准备修改代码\ngit branch add_xxx_feature   执行完上述命令后，您的代码仓库就切换到相应分支了。执行如下命令可以看到您当前分支：\ngit branch -a   如果您想切换回主干，执行下面命令：\ngit checkout -b master   如果您想切换回分支，执行下面命令：\ngit checkout -b \u0026amp;#34;branchName\u0026amp;#34;   修改代码提交到本地 拉完分支后，就可以修改代码了。\n修改代码注意事项   代码风格保持一致 SOFAJRaft 通过 Maven 插件来保持代码格式一致。在提交代码前，务必本地执行\nmvn clean compile   补充单元测试代码\n  新有修改应该通过已有的单元测试\n  应该提供新的单元测试来证明以前的代码存在 bug，而新的代码已经解决了这些 bug 您可以用如下命令运行所有测试：\nmvn clean test 也可以通过IDE来辅助运行。\n  其它注意事项  请保持您编辑的代码的原有风格，尤其是空格换行等。 对于无用的注释，请直接删除。 对逻辑和功能不容易被理解的地方添加注释。 及时更新文档  修改完代码后，请按照如下格式执行命令提交所有修改到本地:\ngit commit -am \u0026amp;#39;(feat) 添加xx功能\u0026amp;#39; git commit -am \u0026amp;#39;(fix) 修复xx功能\u0026amp;#39; 提交代码到远程仓库 在代码提交到本地后，就是与远程仓库同步代码了。执行如下命令提交本地修改到 github 上：\ngit push origin \u0026amp;#34;branchname\u0026amp;#34; 如果前面您是通过 fork 来做的，那么这里的 origin 是 push 到您的代码仓库，而不是 SOFAJRaft 的代码仓库。\n提交合并代码到主干的请求 在的代码提交到 GitHub 后，您就可以发送请求来把您改好的代码合入 SOFAJRaft 主干代码了。此时您需要进入您的 GitHub 上的对应仓库，按右上角的 pull request 按钮。选择目标分支，一般就是 master，系统会通知 SOFAJRaft 的人员， SOFAJRaft 人员会 Review 您的代码，符合要求后就会合入主干，成为 SOFAJRaft 的一部分。\n代码 Review 在您提交代码后，您的代码会被指派给维护人员 Review，请耐心等待。如果在数天后，仍然没有人对您的提交给予任何回复，可以在 PR 下面留言，并 @ 对应的人员。\n对于代码 Review 的意见会直接备注到到对应 PR 或者 Issue。如果觉得建议是合理的，也请您把这些建议更新到您的补丁中。\n合并代码到主干 在代码 Review 通过后，就由 SOFAJRaft 维护人员操作合入主干了。这一步不用参与，代码合并之后，您会收到合并成功的提示。\n","date":-62135596800,"description":"","dir":"projects/sofa-jraft/how-to-contribute-code-to-sofajraft/","fuzzywordcount":1300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"99034715298f73cd835672b872141609","permalink":"/projects/sofa-jraft/how-to-contribute-code-to-sofajraft/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/sofa-jraft/how-to-contribute-code-to-sofajraft/","summary":"准备工作 贡献代码前需要先了解 git 工具的使用和 GitHub 网站的使用。 git 工具用法可以查看 git 官方书籍,需要阅读前几章来熟悉。 git 协作流程可以查看这篇文章 git 协作","tags":null,"title":"如何参与 SOFAJRaft 代码贡献","type":"projects","url":"/projects/sofa-jraft/how-to-contribute-code-to-sofajraft/","wordcount":1270},{"author":null,"categories":null,"content":"简介 该样例工程演示了如何借助 maven 插件将一个普通的 Java 工程打包成标准格式规范的 Ark Plugin\n背景 现实开发中，常常会遇到依赖包冲突的情况；假设我们开发了一个类库 sample-lib , 业务应用在引入使用时，可能存在跟已有的依赖发生冲突的情况；通常这个时候，我们会希望自己的类库能够和业务其他依赖进行隔离，互不协商双方依赖包版本。 Ark Plugin 正是基于这种需求背景下的实践产物； Ark Plugin 运行在 Ark Container 之上，由容器负责加载启动，任何一个 Ark Plugin 由独立的 ClassLoader 加载，从而做到相互隔离。Ark Plugin 存在四个概念：\n  导入类：插件启动时，优先委托给导出该类的插件负责加载，如果加载不到，才会尝试从本插件内部加载；\n  导出类：其他插件如果导入了该类，优先从本插件加载；\n  导入资源：插件在查找资源时，优先委托给导出该资源的插件负责加载，如果加载不到，才会尝试从本插件内部加载；\n  导出资源：其他插件如果导入了该资源，优先从本插件加载；\n   详细请参考插件规范\n 工具 官方提供了 Maven 插件 - sofa-ark-plugin-maven-plugin ，只需要简单的配置项，即可将普通的 Java 工程打包成标准格式规范的 Ark Plugin ，插件坐标为:\n\u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-plugin-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${sofa.ark.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/plugin\u0026amp;gt;  详细请参考插件配置文档\n 入门 基于该用例工程，我们一步步描述如何构建一个 Ark Plugin\n创建标准 Maven 工程 该用例工程是一个标准的 Maven 工程，一共包含两个模块：\n  common 模块：包含了插件导出类\n  plugin 模块：包含了 com.alipay.sofa.ark.spi.service.PluginActivator 接口实现类和一个插件服务类，插件打包工具 sofa-ark-plugin-maven-plugin 即配置在该模块的 pom.xml 中；\n  配置打包插件 在 plugin 模块的 pom.xml 中按如下配置打包插件：\n\u0026amp;lt;build\u0026amp;gt; \u0026amp;lt;plugins\u0026amp;gt; \u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-plugin-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${project.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;executions\u0026amp;gt; \u0026amp;lt;execution\u0026amp;gt; \u0026amp;lt;id\u0026amp;gt;default-cli\u0026amp;lt;/id\u0026amp;gt; \u0026amp;lt;goals\u0026amp;gt; \u0026amp;lt;goal\u0026amp;gt;ark-plugin\u0026amp;lt;/goal\u0026amp;gt; \u0026amp;lt;/goals\u0026amp;gt; \u0026amp;lt;configuration\u0026amp;gt; \u0026amp;lt;!--can only configure no more than one activator--\u0026amp;gt; \u0026amp;lt;activator\u0026amp;gt;com.alipay.sofa.ark.sample.activator.SamplePluginActivator\u0026amp;lt;/activator\u0026amp;gt; \u0026amp;lt;!-- configure exported class --\u0026amp;gt; \u0026amp;lt;exported\u0026amp;gt; \u0026amp;lt;!-- configure package-level exported class--\u0026amp;gt; \u0026amp;lt;packages\u0026amp;gt; \u0026amp;lt;package\u0026amp;gt;com.alipay.sofa.ark.sample.common\u0026amp;lt;/package\u0026amp;gt; \u0026amp;lt;/packages\u0026amp;gt; \u0026amp;lt;!-- configure class-level exported class --\u0026amp;gt; \u0026amp;lt;classes\u0026amp;gt; \u0026amp;lt;class\u0026amp;gt;com.alipay.sofa.ark.sample.facade.SamplePluginService\u0026amp;lt;/class\u0026amp;gt; \u0026amp;lt;/classes\u0026amp;gt; \u0026amp;lt;/exported\u0026amp;gt; \u0026amp;lt;!--specify destination where ark-plugin will be saved, default saved to ${project.build.directory}--\u0026amp;gt; \u0026amp;lt;outputDirectory\u0026amp;gt;../target\u0026amp;lt;/outputDirectory\u0026amp;gt; \u0026amp;lt;/configuration\u0026amp;gt; \u0026amp;lt;/execution\u0026amp;gt; \u0026amp;lt;/executions\u0026amp;gt; \u0026amp;lt;/plugin\u0026amp;gt; \u0026amp;lt;/plugins\u0026amp;gt; \u0026amp;lt;/build\u0026amp;gt; 在用例工程中，我们只配置了一部分配置项，这已经足够生成一个可用的 Ark Plugin，各配置项含义如下：\n  activator: Ark 容器启动插件的入口类，最多只能配置一个；通常来说，在插件的 activator 会执行一些初始化操作，比如发布插件服务；在本样例工程中，即发布了插件服务。\n  导出包：包级别的导出类配置，插件中所有以导出包名为前缀的类，包括插件的三方依赖包，都会被导出；\n  导出类：精确类名的导出类配置，导出具体的类；\n  outputDirectory： mvn package 打包后，输出的 ark plugin 文件存放目录；\n  需要指出的是，在用例工程中，我们只导出了工程创建的类；实际在使用时，也可以把工程依赖的三方包也导出去。\n打包、安装、发布、引入 和普通的工程操作类似，使用 mvn package , mvn install , mvn deploy 即可完成插件包的安装和发布；需要注意的是，默认发布的 Ark Plugin 其 Maven 坐标会增加 classifier=ark-plugin ；例如在该样例工程中，如果需要使用该 ark plugin，必须如下配置依赖：\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sample-ark-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;classifier\u0026amp;gt;ark-plugin\u0026amp;lt;/classifier\u0026amp;gt; …","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-ark-plugin-demo/","fuzzywordcount":1200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"d8125843ced13352dd228299f222c74d","permalink":"/projects/sofa-boot/sofa-ark-ark-plugin-demo/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/sofa-boot/sofa-ark-ark-plugin-demo/","summary":"简介 该样例工程演示了如何借助 maven 插件将一个普通的 Java 工程打包成标准格式规范的 Ark Plugin 背景 现实开发中，常常会遇到依赖包冲突的情况；假设我们开发了一个类","tags":null,"title":"如何打包 Ark Plugin","type":"projects","url":"/projects/sofa-boot/sofa-ark-ark-plugin-demo/","wordcount":1169},{"author":null,"categories":null,"content":"简介 该样例工程演示了如何借助 Maven 插件将一个 Spring Boot Web 工程打包成标准格式规范的可执行 Ark 包；\n准备 因该样例工程依赖 sample-ark-plugin，因此需要提前在本地安装该 Ark Plugin\n工具 官方提供了 Maven 插件 - sofa-ark-maven-plugin ，只需要简单的配置项，即可将 Spring Boot Web 工程打包成标准格式规范的可执行 Ark 包，插件坐标为：\n\u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${sofa.ark.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/plugin\u0026amp;gt;  详细请参考插件使用文档\n 入门 基于该样例工程，我们一步步描述如何将一个 Spring Boot Web 工程打包成可运行 Ark 包\n创建 SpringBoot Web 工程 在官网 https://start.spring.io/ 下载一个标准的 Spring Boot Web 工程\n引入 sample-ark-plugin 在工程主 pom.xml 中如下配置，添加另一个样例工程打包生成的 Ark Plugin 依赖，参考文档\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sample-ark-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;classifier\u0026amp;gt;ark-plugin\u0026amp;lt;/classifier\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${sofa.ark.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 配置打包插件 在工程主 pom.xml 中如下配置 Maven 插件 sofa-ark-maven-plugin :\n\u0026amp;lt;build\u0026amp;gt; \u0026amp;lt;plugins\u0026amp;gt; \u0026amp;lt;plugin\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-maven-plugin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;executions\u0026amp;gt; \u0026amp;lt;execution\u0026amp;gt; \u0026amp;lt;id\u0026amp;gt;default-cli\u0026amp;lt;/id\u0026amp;gt; \u0026amp;lt;!--goal executed to generate executable-ark-jar --\u0026amp;gt; \u0026amp;lt;goals\u0026amp;gt; \u0026amp;lt;goal\u0026amp;gt;repackage\u0026amp;lt;/goal\u0026amp;gt; \u0026amp;lt;/goals\u0026amp;gt; \u0026amp;lt;configuration\u0026amp;gt; \u0026amp;lt;!--specify destination where executable-ark-jar will be saved, default saved to ${project.build.directory}--\u0026amp;gt; \u0026amp;lt;outputDirectory\u0026amp;gt;./target\u0026amp;lt;/outputDirectory\u0026amp;gt; \u0026amp;lt;!--default none--\u0026amp;gt; \u0026amp;lt;arkClassifier\u0026amp;gt;executable-ark\u0026amp;lt;/arkClassifier\u0026amp;gt; \u0026amp;lt;/configuration\u0026amp;gt; \u0026amp;lt;/execution\u0026amp;gt; \u0026amp;lt;/executions\u0026amp;gt; \u0026amp;lt;/plugin\u0026amp;gt; \u0026amp;lt;/plugins\u0026amp;gt; \u0026amp;lt;/build\u0026amp;gt; 在该样例工程中，我们只配置了一部分配置项，这已经足够生成一个可用的可执行 Ark 包，各配置项含义如下：\n  outputDirectory: mvn package 打包后，输出的 Ark 包文件存放目录；\n  arkClassifier: 指定发布的 Ark 包其 Maven 坐标包含的 classifier 值，默认为空；\n  关于 arkClassifier 配置项需要特别注意下，默认值为空；如果不指定 classifier ，上传到仓库的 Jar 包其实是一个可运行的 Ark 包；如果需要和普通的打包加以区分，需要配置该项值。\n打包、安装、发布 和普通的工程操作类似，使用 mvn package , mvn install , mvn deploy 即可完成插件包的安装和发布；\n运行 我们提供了两种方式在 Ark 容器上启动工程应用，通过命令行启动或者在 IDE 启动；在 IDE 启动时，需要额外添加依赖；使用命令行启动非常简便，直接使用 java -jar 即可启动应用；下面我们说下如何在 IDE 启动 Ark 应用；\n Spring Boot 工程：Spring Boot 工程需要添加如下依赖即可：  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-springboot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${sofa.ark.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  普通 Java 工程： 相较于 SpringBoot 工程，普通的 Java 工程需要添加另一个依赖：  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofa-ark-support-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${sofa.ark.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 除此之外，还需要在工程 main 方法最开始处，执行容器启动，如下：\npublic class Application{ public static void main(String[] args) { SofaArkBootstrap.launch(args); ... } } 运行测试用例 SOFAArk 提供了 org.junit.runner.Runner 的两个实现类，ArkJUnit4Runner 和 ArkBootRunner，分别用于集成 JUnit4 测试框架和 Spring Test；对于 TestNG 测试框架，提供了注解 @TestNGOnArk，对于任何 TestNG 测试用例，只有打有 @TestNGOnArk 的测试用例才会跑在 Ark Container 之上，否则普通用例一样。 …","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofa-ark-ark-demo/","fuzzywordcount":1200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"2c97c409788f41051c79836d277997be","permalink":"/projects/sofa-boot/sofa-ark-ark-demo/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/sofa-boot/sofa-ark-ark-demo/","summary":"简介 该样例工程演示了如何借助 Maven 插件将一个 Spring Boot Web 工程打包成标准格式规范的可执行 Ark 包； 准备 因该样例工程依赖 sample-ark-plugin，因","tags":null,"title":"如何打包 Ark 包","type":"projects","url":"/projects/sofa-boot/sofa-ark-ark-demo/","wordcount":1165},{"author":null,"categories":null,"content":"如何编译  安装 JDK7 及以上，Maven 3.2.5 及以上。\n 直接下载代码，然后执行如下命令：\ncd sofa-rpc mvn clean install 注意：不能在子目录（即子模块）下进行编译。因为 SOFARPC 模块太多，如果每个子模块都会install 和 deploy，仓库内会有较多无用记录。 所以在设计 SOFARPC 工程结构的时候，我们决定各个子模块组件是不需要 install 和 deploy 到仓库里的，我们只会install 和 deploy 一个sofa-rpc-all(all) 模块。\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/how-to-build/","fuzzywordcount":200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"52ad3debb35be8743c97bb4b6b77f22b","permalink":"/projects/sofa-rpc/how-to-build/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/how-to-build/","summary":"如何编译 安装 JDK7 及以上，Maven 3.2.5 及以上。 直接下载代码，然后执行如下命令： cd sofa-rpc mvn clean install 注意：不能在子目录（即子模块）下进行编译。因为 SOFARPC 模块太多","tags":null,"title":"如何编译 SOFARPC 工程","type":"projects","url":"/projects/sofa-rpc/how-to-build/","wordcount":180},{"author":null,"categories":null,"content":"在非 Kubernetes 环境下使用 Istio 需要达成以下的关键任务：\n 为 Istio 控制平面配置 Istio API server，也可以通过 memostore 的方式启动 Pilot 用作演示用途。 给所有微服务实例手工添加 SOFA MOSN，并以 Sidecar 模式启动。 确保请求都通过 SOFA MOSN 进行路由。  设定控制平面 Istio 控制平面由四个主要的服务组成：Pilot、Mixter、Citadel 以及 API server。\nAPI server Istio\u0026amp;rsquo;s API server (基于 kubernetes API server) 提供了配置管理和基于角色的访问控制。API server 需要 etcd 集群作为底层的持久化存储。\n本地安装 使用如下的 docker compose file 安装一个用于 POC 目的的 API server：\nversion: \u0026amp;#39;2\u0026amp;#39; services: etcd: image: quay.io/coreos/etcd:latest networks: default: aliases: - etcd ports: - \u0026amp;#34;4001:4001\u0026amp;#34; - \u0026amp;#34;2380:2380\u0026amp;#34; - \u0026amp;#34;2379:2379\u0026amp;#34; environment: - SERVICE_IGNORE=1 command: [ \u0026amp;#34;/usr/local/bin/etcd\u0026amp;#34;, \u0026amp;#34;-advertise-client-urls=http://0.0.0.0:2379\u0026amp;#34;, \u0026amp;#34;-listen-client-urls=http://0.0.0.0:2379\u0026amp;#34; ] istio-apiserver: image: gcr.io/google_containers/kube-apiserver-amd64:v1.7.3 networks: default: aliases: - apiserver ports: - \u0026amp;#34;8080:8080\u0026amp;#34; privileged: true environment: - SERVICE_IGNORE=1 command: [ \u0026amp;#34;kube-apiserver\u0026amp;#34;, \u0026amp;#34;--etcd-servers\u0026amp;#34;, \u0026amp;#34;http://etcd:2379\u0026amp;#34;, \u0026amp;#34;--service-cluster-ip-range\u0026amp;#34;, \u0026amp;#34;10.99.0.0/16\u0026amp;#34;, \u0026amp;#34;--insecure-port\u0026amp;#34;, \u0026amp;#34;8080\u0026amp;#34;, \u0026amp;#34;-v\u0026amp;#34;, \u0026amp;#34;2\u0026amp;#34;, \u0026amp;#34;--insecure-bind-address\u0026amp;#34;, \u0026amp;#34;0.0.0.0\u0026amp;#34; ] 其他控制平面组件 目前 SOFA MOSN 还没有集成 Pilot 之外的其他组件，因此我们暂时无需安装 Mixer、Citadel 等组件。\n为微服务实例添加 SOFA MOSN Sidecar 微服务应用的每个实例都必须有个伴生的 SOFA MOSN 实例。\n","date":-62135596800,"description":"","dir":"projects/sofa-mesh/pilot-setup-zookeeper-installation/","fuzzywordcount":400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"4c0bd56673dc8aebef9011a22496392d","permalink":"/projects/sofa-mesh/pilot-setup-zookeeper-installation/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-mesh/pilot-setup-zookeeper-installation/","summary":"在非 Kubernetes 环境下使用 Istio 需要达成以下的关键任务： 为 Istio 控制平面配置 Istio API server，也可以通过 memostore 的方式启动 Pilot 用作演示用途。 给所有微服务实例手工添加 SOFA","tags":null,"title":"安装指南","type":"projects","url":"/projects/sofa-mesh/pilot-setup-zookeeper-installation/","wordcount":372},{"author":null,"categories":null,"content":"提供可以允许配置的所有参数。\n 发布订阅配置 预热转发配置 自动故障剔除配置  ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/configuration/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"b1a8a8c426beab292165716f1dff1ae4","permalink":"/projects/sofa-rpc/configuration/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/configuration/","summary":"提供可以允许配置的所有参数。 发布订阅配置 预热转发配置 自动故障剔除配置","tags":null,"title":"完整配置参数","type":"projects","url":"/projects/sofa-rpc/configuration/","wordcount":34},{"author":null,"categories":null,"content":"客户端 API 使用说明 SOFALookout 客户端设计上保持了 API 与实现解耦。如果我们只需要基于 SOFALookout API 进行埋点，那么只需要依赖 API 包即可。在没有依赖具体实现模块依赖时（比如 client 依赖 或 SOFABoot（Spring Boot）Start 依赖），API 包会自动使用 NoopRegistry，使得所有埋点的地方都已空实现替代。\n1.API 依赖引入 \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa.lookout\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;lookout-api\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${lookout.client.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 2.关于 ID Lookout metrics 相比传统的 metrics 库单一维度的信息描述，提供了支持多维度描述的 tags 能力。 Lookout metrics 的唯一标识 Id 类，由 name 和 tags 构成。\nId basicId = registry.createId(\u0026amp;#34;rpc.provider.service.stats\u0026amp;#34;); id = basicId.withTag(\u0026amp;#34;service\u0026amp;#34;, \u0026amp;#34;com.alipay.demo.demoService\u0026amp;#34;) .withTag(\u0026amp;#34;method\u0026amp;#34;, \u0026amp;#34;sayHi\u0026amp;#34;) .withTag(\u0026amp;#34;protocol\u0026amp;#34;, \u0026amp;#34;tr\u0026amp;#34;) .withTag(\u0026amp;#34;alias\u0026amp;#34;, \u0026amp;#34;group1\u0026amp;#34;); 上面是 Id 的简单示例了，如何创建 Id，如何打 tag，（每打一次 tag，都会生成并返回一个新的 Id 对象引用）切记！使用返回新的 Id 对象了哦。\n 不要主动缓存 Id 或具体的 Metric 对象,Lookout 的 Registry 已经登记记录了。相等的 Id （ name 和 tags 一样）会复用已有的Id 对应 Metric 对象。  2.1 Priority tag (不是必须) PRIORITY 枚举级别: HIGH, NORMAL, LOW;\nid.withTag(LookoutConstants.LOW_PRIORITY_TAG); 如果不打该 Tag (建议)，默认是 NORMAL 级别。级别代表了采集间隔周期（HIGH：2s, NORMAL: 30s, LOW: 1min）\n2.2 关于 tags  通用的 tags，比如：本机 ip，机房等详细会统一附上，不需要单独指定。 普通 Java 项目直接 lookout-client 时，tags 需要自己指定，特别记住：appName 别忘啦！tag:app=xx key 必须小写，尽量是字母，数字，下划线； （尤其是运行期的 Counter, Timer, DistributeSummary 这些 metrics）某个类型的 tag 的 values 尽量是稳定不变有限集合，而且 tags 尽量少，防止 metrics 数量超过最大限制！ 比如：rpc 场合 service, method 两个 tag 对应的值是有限较小的； 反例是每次 rpc 调用都有是个独立的 tag-value。 因此，总体原则自定义打 tags 时要尽量少，对应 values 的集合数量尽量小； 专门用途的 TAG 名称: \u0026amp;ldquo;priority\u0026amp;rdquo;: 表示优先级。 系统保留的 tag key 统配格式_*_,以下划线开始，以下划线结束（比如: \u0026amp;ldquo;type\u0026amp;rdquo; ）。 请不要使用这种格式的 key，可能会被系统覆盖或丢弃  3.可接入的统计( Metric )类型API Counter 「计数器」  场景：方法调用次数； 主动汇报的数据包括： count, rate (也就是 qps)； 使用方式  Counter counter=registry.counter(id); counter.inc(); Timer 「耗时统计器」  场景:统计任务，方法耗时，支持分桶统计 主动汇报的数据包括：elapPerExec (单次执行耗时), total 耗时，Max 耗时,（上报单位：秒）； 使用方式  Timer timer=registry.timer(id); timer.record(2, TimeUnit.SECONDS); DistributionSummary 「值分布情况统计器」  场景：比如 io 流量，支持分桶统计 主动汇报的数据包括: count, total(size), max(size)； 使用方式:  DistributionSummary distributionSummary=registry.distributionSummary(id); distributionSummary.record(1024); Gauge 「即时数据观察」  场景：比如线程池，内存值等即时值； 主动汇报的数据包括: value； 往注册表中登记新 gauge 时，ID 值相等，注册表继续使用已有的(忽略新的)；  注意，推荐 gauge 观察的对象尽量是单例的（复用），并且建议在运行时一直活着（而不是作为一个临时的统计）！，如果不是单例或者只存活一段时间，那么一定要从 Registry 中 remove 掉，否则影响 GC（主要是它持有的外部对象引用无法释放，浪费空间）!!\n 使用方式:  registry.gauge(id,new Gauge\u0026amp;lt;Double\u0026amp;gt;() { @Override public Double value() { return 0.1; } }); MixinMetric 「上述基本统计 metrics 的混合管理体」 MixinMetric 是 Lookout 特有的，表示多个基本 metrics 的混合体。引入该 Mixin 目的是优化对「同一度量目标」（即测量目标一致，tags 一致）的多测量指标传输和存储效率，比如：同一线程池的各种指标(线程总数，活跃总数，等待队列大小\u0026amp;hellip;)。\n 使用方式（比如，对一次服务调用，加入多个测量指标：调用耗时，输入字节，调用次数，输出字节等等）  //1. getOrAdd MixinMetric  MixinMetric rpcServiceMetric=registry.minxinMetric(id); //2. getOrAdd basic component metric to use  Timer rpcTimer = rpcServiceMetric.timer(\u0026amp;#34;perf\u0026amp;#34;); DistributionSummary rpcOutSizeMetric = …","date":-62135596800,"description":"","dir":"projects/sofa-lookout/use-guide-api/","fuzzywordcount":1600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"76574f2435a3565fe1fc50831ff9ab0c","permalink":"/projects/sofa-lookout/use-guide-api/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/projects/sofa-lookout/use-guide-api/","summary":"客户端 API 使用说明 SOFALookout 客户端设计上保持了 API 与实现解耦。如果我们只需要基于 SOFALookout API 进行埋点，那么只需要依赖 API 包即可。在没有依赖具体实现模块依赖时（比如","tags":null,"title":"客户端 API 使用指南","type":"projects","url":"/projects/sofa-lookout/use-guide-api/","wordcount":1562},{"author":null,"categories":null,"content":"Registry 的使用 不同的 Registry 的集成提供了不同的访问 Metrics 的方式。\n1. LookoutRegistry 提供按照一定时间窗口统计 metrics 的能力。它又分为“主动推”和“被动拉”两种模式，暂时被动拉取模式处于关闭状态。\n（1）主动推模式\n可以通过【客户端配置】指定远程 Agent 的IP地址，即开始上报检查，和定时上报数据。 （2）被动拉模式\n可以通过【客户端配置】启动该模式，则在 19399 端口提供 HTTP 服务。更多交互细节请参考（待补充） 2. 对接到 Prometheus SOFALookout 的数据可以对接到 Prometheus 上面。为了将数据对接到 Prometheus 上面，首先需要在工程中加入依赖：\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa.lookout\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;lookout-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa.lookout\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;lookout-reg-prometheus\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${lookout.client.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 添加好依赖之后，启动应用，既可以访问 http://localhost:9494 来看到数据，其中 9494 为默认的端口，可以通过在 application.properties 里面配置 com.alipay.sofa.lookout.prometheus-exporter-server-port 来改变端口。\n有了访问数据的 URL 之后，可以编辑一个 prometheus.yml 来抓取该项目信息，假设本机 IP 地址为 10.15.232.20，那么可以配置如下的 prometheus.yml：\nscrape_configs: - job_name: \u0026amp;#39;lookout-client\u0026amp;#39; scrape_interval: 5s static_configs: - targets: [\u0026amp;#39;10.15.232.20:9494\u0026amp;#39;] 有了上面的配置文件之后，可以再到本地通过 Docker 来启动 Prometheus：\ndocker run -d -p 9090:9090 -v $PWD/prometheus.yml:/etc/prometheus/prometheus.yml --name prom prom/prometheus:master 然后通过浏览器访问: http://localhost:9090，再通过 PromQL 查询即可查询到对应的 Metrics。\nSOFALookout 中也提供了一个对接 Prometheus 的样例，大家可以前往自行查看。\n3. 对接 SpringBoot actuator 除了 Prometheus 之外，SOFALookout 可以与 SpringBoot 1.x 的 Actuator 的相集成，只需依赖：\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-starter-actuator\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 然后启动后访问 http://localhost:8080/metrics 既可以看到通过 SOFALookout API 埋点的数据。\nSOFALookout 也提供了集成的样例工程，大家可以前往自行查看。\n","date":-62135596800,"description":"","dir":"projects/sofa-lookout/use-guide-registry/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"3c51ba6519cee542b459a170dabcf32b","permalink":"/projects/sofa-lookout/use-guide-registry/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-lookout/use-guide-registry/","summary":"Registry 的使用 不同的 Registry 的集成提供了不同的访问 Metrics 的方式。 1. LookoutRegistry 提供按照一定时间窗口统计 metrics 的能力。它又分为“主动推”和“被动拉”两种模式，暂时被动拉取模","tags":null,"title":"客户端 Registry 使用指南","type":"projects","url":"/projects/sofa-lookout/use-guide-registry/","wordcount":575},{"author":null,"categories":null,"content":"1. 创建 Maven 工程 服务端部署完毕后，我们可以新建一个 Maven 工程使用 SOFARegistry 提供的服务。首先新建一个 Maven 工程，然后引入如下依赖：\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;registry-client-all\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${registry.client.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 2. 发布数据 // 构建客户端实例 RegistryClientConfig config = DefaultRegistryClientConfigBuilder.start().setRegistryEndpoint(\u0026amp;#34;127.0.0.1\u0026amp;#34;).setRegistryEndpointPort(9603).build(); DefaultRegistryClient registryClient = new DefaultRegistryClient(config); registryClient.init(); // 构造发布者注册表 String dataId = \u0026amp;#34;com.alipay.test.demo.service:1.0@DEFAULT\u0026amp;#34;; PublisherRegistration registration = new PublisherRegistration(dataId); // 将注册表注册进客户端并发布数据 registryClient.register(registration, \u0026amp;#34;10.10.1.1:12200?xx=yy\u0026amp;#34;); 使用 SOFARegistry 发布数据一共包含三个步骤：\n 构建客户端实例; 构造发布者注册表; 将注册表注册进客户端并发布数据。  2.1 构建客户端实例 构建客户端实例的关键是创建 RegistryClientConfig 对象，创建 RegistryClientConfig 对象时需要指定 RegistryEndpoint 和 RegistryEndpointPort:\n RegistryEndpoint：注册中心任一 Session 节点地址； RegistryEndpointPort: Session 节点配置的 session.server.httpServerPort 端口值。  2.2 构造发布者注册表 构造发布注册表只需要创建 PublisherRegistration 并指定 dataId，dataId 是发布服务的唯一标识。\n2.3 发布数据 调用 RegistryClient 的 register 方法可以进行数据发布，该方法需要两个参数，第一个参数是发布注册表，指定了服务的 dataId，第二个参数是数据值，一般是一个字符串类型。\n3. 订阅数据 // 构建客户端实例 RegistryClientConfig config = DefaultRegistryClientConfigBuilder.start().setRegistryEndpoint(\u0026amp;#34;127.0.0.1\u0026amp;#34;).setRegistryEndpointPort(9603).build(); DefaultRegistryClient registryClient = new DefaultRegistryClient(config); registryClient.init(); // 创建 SubscriberDataObserver SubscriberDataObserver subscriberDataObserver = new SubscriberDataObserver() { public void handleData(String dataId, UserData userData) { System.out.println(\u0026amp;#34;receive data success, dataId: \u0026amp;#34; + dataId + \u0026amp;#34;, data: \u0026amp;#34; + userData); } }; // 构造订阅者注册表，设置订阅维度，ScopeEnum 共有三种级别 zone, dataCenter, global String dataId = \u0026amp;#34;com.alipay.test.demo.service:1.0@DEFAULT\u0026amp;#34;; SubscriberRegistration registration = new SubscriberRegistration(dataId, subscriberDataObserver); registration.setScopeEnum(ScopeEnum.global); // 将注册表注册进客户端并订阅数据，订阅到的数据会以回调的方式通知 SubscriberDataObserver registryClient.register(registration); 使用 SOFARegistry 发布数据一共包含三个步骤：\n 构建客户端实例; 创建 SubscriberDataObserver； 构造订阅者注册表； 将注册表注册进客户端并订阅数据。  其中创建客户端实例方式与上文发布数据时创建客户端实例的方法一致。\n3.1 创建 SubscriberDataObserver SubscriberDataObserver 是一个回调接口，该接口定义了 handleData 方法，该方法包含两个参数，分别是 dataId 及最终数据，当客户端收到服务端订阅的数据时会调用该方法。在 SOFARegistry 中，服务端返回数据用 UserData 表示，该类包含以下两个方法：\npublic interface UserData { Map\u0026amp;lt;String, List\u0026amp;lt;String\u0026amp;gt;\u0026amp;gt; getZoneData(); String getLocalZone(); }  getLocalZone: 返回当前zone； getZoneData: 返回以 zone 为 key，每个 zone 的数据为 value 的数据。  3.2 构造订阅者注册表 构造订阅者注册表需要创建 SubscriberRegistration 对象，创建该对象需要指定 dataId 及 SubscriberDataObserver。\n3.3 订阅数据 调用 RegistryClient 的 register 方法可以进行数据订阅，该方法包含一个参数，只需传入 SubscriberRegistration 对象即可。\n如果先运行发布数据的程序，然后再运行订阅数据的程序，那么我们将在控制端看到如下输出：\nreceive data success, dataId: com.alipay.test.demo.service:1.0@DEFAULT, …","date":-62135596800,"description":"","dir":"projects/sofa-registry/client-quick-start/","fuzzywordcount":900,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"66e300d44b2f2a903d976bf83eb7c16e","permalink":"/projects/sofa-registry/client-quick-start/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-registry/client-quick-start/","summary":"1. 创建 Maven 工程 服务端部署完毕后，我们可以新建一个 Maven 工程使用 SOFARegistry 提供的服务。首先新建一个 Maven 工程，然后引入如下依赖： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alipay.sofa\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;registry-client-all\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${registry.client.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2. 发布数据 // 构建客户端","tags":null,"title":"客户端使用","type":"projects","url":"/projects/sofa-registry/client-quick-start/","wordcount":897},{"author":null,"categories":null,"content":"该项目演示了如何在 SOFABoot 中使用 SOFALookout 并且对接到 Spring Boot 的 Actuator 中。如果想要对接到 Prometheus 上或者其他的 Registry 中，请参考 Registry 一节。\n新建 SpringBoot（或 SofaBoot ）项目 新建一个 Spring Boot 的应用（如果是 SOFABoot 工程按照 SOFABoot 文档 - 依赖管理中的方式引入 SOFABoot 即可）。\n引入 Lookout 的 Starter 依赖 在 pom.xml 中引入以下依赖即可：\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa.lookout\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;lookout-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 如果 Spring Boot 项目需指定版本。\n新建一个 Metrics 指标 在完成依赖的引入之后，然后可以在 Spring Boot 中的启动类中，加入如下的方法：\n@Autowired private Registry registry; @PostConstruct public void init() { Counter counter = registry.counter(registry.createId(\u0026amp;#34;http_requests_total\u0026amp;#34;).withTag(\u0026amp;#34;instant\u0026amp;#34;, NetworkUtil.getLocalAddress().getHostName())); counter.inc(); } 上面的代码中直接通过 @Autowired 注入了一个 Registry 的字段，通过这个 Registry 的字段，我们就可以创建对应的 Counter，然后通过修改这个 Counter 的数据来生成 SOFALookout 的 Metrics 的指标。\n添加配置项 在 SOFABoot 项目中，需要增加一个应用名的配置项：spring.application.name=xxx。\n与 Spring Boot Actuator 对接 新增了一个指标之后，我们可以选择对接到 Spring Boot Actuator 上，要对接到 Spring Boot Actuator 上面，需要添加如下的依赖：\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-starter-actuator\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 添加如上的依赖之后，我们在本地启动应用，访问 http://localhost:8080/metrics，就可以看到前面添加的指标，如下：\n\u0026amp;#34;http_requests_total.instant-MacBook-Pro-4.local\u0026amp;#34;: 1, 以上的 QuickStart 的代码在: lookout-client-samples-boot，大家可以下载作为参考。\n","date":-62135596800,"description":"","dir":"projects/sofa-lookout/quick-start-client-boot/","fuzzywordcount":500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"27e057f8a8a4ac97f42ea66ca6a17fdd","permalink":"/projects/sofa-lookout/quick-start-client-boot/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-lookout/quick-start-client-boot/","summary":"该项目演示了如何在 SOFABoot 中使用 SOFALookout 并且对接到 Spring Boot 的 Actuator 中。如果想要对接到 Prometheus 上或者其他的 Registry 中，请参考 Registry 一节。 新建 SpringBoot（或 SofaBoot ）项目 新建一","tags":null,"title":"客户端快速开始 - SOFABoot 项目","type":"projects","url":"/projects/sofa-lookout/quick-start-client-boot/","wordcount":490},{"author":null,"categories":null,"content":"普通 Java 项目 在应用中加入 client 的 Maven 依赖\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa.lookout\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;lookout-client\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${lookout.client.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; lookout-client 默认依赖了 lookout-reg-server 模块（支持向 lookout server 上报 metrics 数据），如果希望使用其他类型注册表(比如 lookout-reg-prometheus)，那么再加上对应依赖即可。\n开始使用 SOFALookout 的 Client 之前，首先需要构建一个全局的客户端实例（ com.alipay.lookout.client.DefaultLookoutClient ）\nLookoutConfig lookoutConfig = new LookoutConfig(); DefaultLookoutClient client = new DefaultLookoutClient(\u0026amp;#34;appName\u0026amp;#34;); //选择构建需要使用的 Registry(如果多个注册表类型，建议使用同一 lookoutConfig 实例，便于集中管理) LookoutRegistry lookoutRegistry = new LookoutRegistry(lookoutConfig); //客户端可以后置添加 registry 实例(至少要加一个) client.addRegistry(lookoutRegistry); //(可选)对已加入或后续加入的客户端的 registry 实例，统一注册扩展模块的 metrics client.registerExtendedMetrics(); 然后通过客户端拿取 Registry 实例，进行使用：\n//该注册表是个“组合”型的注册表 Registry registry = client.getRegistry(); //demo Id id = registry.createId(\u0026amp;#34;http_requests_total\u0026amp;#34;); Counter counter = registry.counter(id); counter.inc(); 客户端的使用，可以详细参考样例工程。\n","date":-62135596800,"description":"","dir":"projects/sofa-lookout/quick-start-client-java/","fuzzywordcount":400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"5dc476aa21ece4789859f1af598d4445","permalink":"/projects/sofa-lookout/quick-start-client-java/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-lookout/quick-start-client-java/","summary":"普通 Java 项目 在应用中加入 client 的 Maven 依赖 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alipay.sofa.lookout\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lookout-client\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${lookout.client.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; lookout-client 默认依赖了 lookout-reg-server 模块（支持向 lookout server 上报 metrics 数据），如果希望使用其他类型注册表(比如 lookout-reg","tags":null,"title":"客户端快速开始 - 普通 Java 项目","type":"projects","url":"/projects/sofa-lookout/quick-start-client-java/","wordcount":311},{"author":null,"categories":null,"content":"客户端模块是一个较复杂的模块，这里包含了集群管理、路由、地址管理器、连接管理器、负载均衡器，还与代理、注册中心等模块交互。\n参见：\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/client-invoke-flow/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"310d99d64b808a3b526563e92c699952","permalink":"/projects/sofa-rpc/client-invoke-flow/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/client-invoke-flow/","summary":"客户端模块是一个较复杂的模块，这里包含了集群管理、路由、地址管理器、连接管理器、负载均衡器，还与代理、注册中心等模块交互。 参见：","tags":null,"title":"客户端调用流程","type":"projects","url":"/projects/sofa-rpc/client-invoke-flow/","wordcount":64},{"author":null,"categories":null,"content":"客户端配置项设置示例 lookoutConfig.setProperty(LookoutConfig.LOOKOUT_AGENT_HOST_ADDRESS,\u0026amp;#34;127.0.0.1\u0026amp;#34;); 客户端配置项说明    配置项 对应 SpringBoot 配置项 默认配置值 说明     lookout.enable com.alipay.sofa.lookout.enable true 功能开关，默认是 true。如果改为 false，那么所有 metrics 就几乎没有内存与计算消耗(空对象与空方法)   lookout.max.metrics.num com.alipay.sofa.lookout.max-metrics-num 5000 metrics 最大数目限制，超过会自动忽略   lookout.prometheus.exporter.server.port com.alipay.sofa.lookout.prometheus-exporter-server-port 9494 prometheus 抓取的端口   lookout.exporter.enable com.alipay.sofa.lookout.exporter-enable false 是否开启支持被动采集的服务   lookout.agent.host.address com.alipay.sofa.lookout.agent-host-address - 主动上报 Agent 服务器的注解地址，支持多个地址以逗号分隔    客户端日志配置说明    系统属性配置项 对应 SpringBoot 配置项 默认配置值 说明     -Dlogging.level.com.alipay.lookout=? logging.level.com.alipay.lookout warn lookout 客户端的日志级别，debug 可以看见汇报数据的详情   -Dlogging.path=? logging.path 当前用户目录 SpringBoot V1的日志目录调整，包括 \u0026amp;ldquo;lookout/\u0026amp;rdquo; 日志子目录    客户端配置自定义(适用于 SpringBoot 技术栈模式) 使用配置定制扩展: MetricConfigCustomizerConfig\n@Configuration public class MetricConfigCustomizerConfig { @Bean public MetricConfigCustomizer metricConfigCustomizer() { return new MetricConfigCustomizer() { @Override public void customize(MetricConfig metricConfig) { metricConfig.addProperty(\u0026amp;quot;testaa\u0026amp;quot;, \u0026amp;quot;testbb\u0026amp;quot;); } }; } } ","date":-62135596800,"description":"","dir":"projects/sofa-lookout/client-configuration/","fuzzywordcount":300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"5fd84950d4d565d3fb20781337792bf1","permalink":"/projects/sofa-lookout/client-configuration/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-lookout/client-configuration/","summary":"客户端配置项设置示例 lookoutConfig.setProperty(LookoutConfig.LOOKOUT_AGENT_HOST_ADDRESS,\u0026#34;127.0.0.1\u0026#34;); 客户端配置项说明 配置项 对应 SpringBoot 配置项 默认配置值 说明 lookout.enable com.alipay.sofa.lookout.enable true 功能开关，默认是 true。如果改为 false，那么所有 metrics 就几乎没","tags":null,"title":"客户端配置","type":"projects","url":"/projects/sofa-lookout/client-configuration/","wordcount":298},{"author":null,"categories":null,"content":"包含单机故障剔除和 Hystrix 熔断。\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/fault/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"e567dc5e291867e92c8dd1c4f953b768","permalink":"/projects/sofa-rpc/fault/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/fault/","summary":"包含单机故障剔除和 Hystrix 熔断。","tags":null,"title":"容灾恢复","type":"projects","url":"/projects/sofa-rpc/fault/","wordcount":13},{"author":null,"categories":null,"content":"本文档中提供了 MOSN 的示例工程。\n使用 MOSN 作为 HTTP 代理 请参考 MOSN 转发 HTTP 的示例工程 http-sample。\n使用 MOSN 作为 SOFARPC 代理 请参考 MOSN 转发 SOFARPC 的示例工程 sofarpc-sample。\n使用 MOSN 作为TCP 代理 请参考 MOSN 作为 TCP Proxy 的示例工程 tcpproxy-sample 。\n","date":-62135596800,"description":"","dir":"projects/mosn/quick-start-run-samples/","fuzzywordcount":200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"600c182fdee786a59e14899ba0fce8a1","permalink":"/projects/mosn/quick-start-run-samples/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/mosn/quick-start-run-samples/","summary":"本文档中提供了 MOSN 的示例工程。 使用 MOSN 作为 HTTP 代理 请参考 MOSN 转发 HTTP 的示例工程 http-sample。 使用 MOSN 作为 SOFARPC 代理 请参考 MOSN 转发 SOFARPC 的示例工程 sofa","tags":null,"title":"工程示例","type":"projects","url":"/projects/mosn/quick-start-run-samples/","wordcount":106},{"author":null,"categories":null,"content":"源码工程中提供了一些样例工程，辅助说明项目的使用。样例工程的 readme 有使用补充说明，另外需要将这些 sample 工程单独的导入 IDE。\n客户端样例工程  lookout-client-samples-java  该样例工程展示了，在普通 Java 项目中,如何以代码形式使用和配置客户端。\n lookout-client-samples-boot  该样例工程展示了，在 SpringBoot(或SofaBoot) 项目中,如何使用和配置客户端。\n lookout-client-samples-prometheus  该样例工程展示了，在 SpringBoot(或SofaBoot) 项目中,如何使用和配置客户端使用 prometheus。\n lookout-samples-prom-push  该样例工程展示了，在 Java 项目中,使用 prometheus 客户端并以push方式（PushGateway）上报数据。\n服务器端样例工程 ","date":-62135596800,"description":"","dir":"projects/sofa-lookout/use-guide-samples/","fuzzywordcount":300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"a8a0fcd3f99ce2fb46e4d543e30797c9","permalink":"/projects/sofa-lookout/use-guide-samples/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-lookout/use-guide-samples/","summary":"源码工程中提供了一些样例工程，辅助说明项目的使用。样例工程的 readme 有使用补充说明，另外需要将这些 sample 工程单独的导入 IDE。 客户端样例工程 lookout-client-samples-java 该样例工","tags":null,"title":"工程示例","type":"projects","url":"/projects/sofa-lookout/use-guide-samples/","wordcount":261},{"author":null,"categories":null,"content":"Q：报错误 NoSuchMethodError 一般情况下该类错误由依赖冲突导致。已知的依赖冲突列举如下，遇到时选择性排除它们。\n日志冲突 commons-logging 冲突 \u0026amp;lt;exclusion\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;commons-logging\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;commons-logging\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;/exclusion\u0026amp;gt; logback-classic 冲突 在冲突位置将 logback-classic 排除，如 spring-boot-starter-logging 和 spring-test 为存在冲突的应用依赖。\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-starter-logging\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;1.4.2.RELEASE\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;exclusions\u0026amp;gt; \u0026amp;lt;exclusion\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;ch.qos.logback\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;logback-classic\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/exclusion\u0026amp;gt; \u0026amp;lt;/exclusions\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-test\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;4.3.4.RELEASE\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;exclusions\u0026amp;gt; \u0026amp;lt;exclusion\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;ch.qos.logback\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;logback-classic\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/exclusion\u0026amp;gt; \u0026amp;lt;/exclusions\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; snakeyaml 冲突 java.lang.NoSuchMethodError: org.yaml.snakeyaml.Yaml.\u0026amp;lt;init\u0026amp;gt;(Lorg/yaml/snakeyaml/constructor/BaseConstructor;)V spring-boot-starter-test 与 org.testng 中引用的 org.yaml 存在冲突。这里以排除 spring-boot-starter-test 中的 org.yaml 为例（也可在 org.testng 等冲突位置排除）\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-starter-test\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;scope\u0026amp;gt;test\u0026amp;lt;/scope\u0026amp;gt; \u0026amp;lt;exclusions\u0026amp;gt; \u0026amp;lt;exclusion\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.yaml\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;snakeyaml\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/exclusion\u0026amp;gt; \u0026amp;lt;/exclusions\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; Q：报错 NoClassDefFoundError 一般情况下依赖缺失或者依赖冲突会导致该类问题。\nMockito 报错找不到类 SOFABoot 使用 Mockito 时，如果已经存在 spring-boot-starter-test 则无需重复引入 Mockito。\nQ：报错 No bean dataAccessConfigManager available ACTS 测试脚本指定的 Application 启动类中缺少 acts-core.xml，如图添加即可。\nQ：No runnable methods 一般是由于选择 Junit 运行 ACTS 测试脚本导致的，ACTS 测试脚本可使用 TestNG 方式运行。\nQ：生成模版异常 有较多情况会导致这一现象，常见的是新编写的类或者对类进行变更后，没有进行 mvn 编译。先执行 mvn clean install -Dmaven.test.skip=true，再进行模版生成。\nQ：编辑器设置入参错误 使用 ACTS IDE 操作入参时，出现无法选中或者设置数值出错等情况，一般是生成测试脚本操作有误，没有生成入参模版而直接生成测试脚本，导致初始生成的 YAML 中入参不正确。\n 解法一：删除测试脚本对应的 YAML 文件，然后打开 ACTS IDE 并右键入参设置 -\u0026amp;gt; 模版选择，编辑后保存则 YAML 文件会自动重建。 解法二：删除生成的测试脚本和 YAML 文件，首先生成入参的模版，再重新生成测试脚本即可，YAML 中会默认带入参设置；  Q：报错 argument type mismatch 该问题一般是被测接口有多个同名重载方法导致的，从而引发反射时参数不匹配错误。\n解决方法 可以在脚本中重写 ACTS 测试基类的 findMethod 方法，返回真正被测的方法对象。下面的方法也适用于获取被测方法失败的情况。\n@Override public void beforeActsTest(ActsRuntimeContext actsRuntimeContext) { Method method =null; try { method = VirtualAssetQueryService.class.getDeclaredMethod (\u0026amp;#34;query\u0026amp;#34;, QueryVirtualAssetListParam.class); } catch (NoSuchMethodException e) { e.printStackTrace(); } catch (SecurityException e) { e.printStackTrace(); } actsRuntimeContext.setTestedMethod(method); } 使用 ACTS IDE 编辑类的属性后保存取值失效 ACTS IDE 默认类是标准的 JavaBean 形式，会调用属性的 set 方法为其赋值，如果不存在 set 方法则无法保存取值。\n","date":-62135596800,"description":"","dir":"projects/sofa-acts/faq/","fuzzywordcount":800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"5f89d1f5695cbe6b669a8738741529bd","permalink":"/projects/sofa-acts/faq/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-acts/faq/","summary":"Q：报错误 NoSuchMethodError 一般情况下该类错误由依赖冲突导致。已知的依赖冲突列举如下，遇到时选择性排除它们。 日志冲突 commons-logging 冲突 \u0026lt;exclusion\u0026gt; \u0026lt;artifactId\u0026gt;commons-logging\u0026lt;/artifactId\u0026gt; \u0026lt;groupId\u0026gt;commons-logging\u0026lt;/groupId\u0026gt; \u0026lt;/exclusion\u0026gt; logback-classic 冲突 在冲突位置将 logback-classic 排除，","tags":null,"title":"常见问题","type":"projects","url":"/projects/sofa-acts/faq/","wordcount":776},{"author":null,"categories":null,"content":"Q: Readiness Check 有啥应用场景？ Liveness Check 和 Readiness Check 概念来自于 Kuberentes，分别代表运行时检查和启动时检查。Spring Boot 提供了 Liveness Check，但是没有提供 Readiness Check。利用 Readiness Check 的能力，SOFA 中间件中的各个组件只有在 Readiness Check 通过之后，才将流量引入到应用的实例中，比如 RPC，只有在 Readiness Check 通过之后，才会向服务注册中心注册，后面来自上游应用的流量才会进入。除了中间件可以利用 Readiness Check 的事件来控制流量，PAAS 系统也可以通过访问 http://localhost:8080/health/readiness 来获取应用的 Readiness Check 的状况，从而控制例如负载均衡设备等等的流量。\nQ: 是否可以在 SOFABoot 模块中定义 Controller 组件？ SOFABoot 模块一般用于封装对外发布服务接口的具体实现，属于业务层，Controller 属于展现层内容，我们不建议也不支持在 SOFABoot 模块中定义 Controller 组件，Controller 组件相关定义建议直接放在 Root Application Context。\nQ: 类隔离在蚂蚁内部使用是否广泛？ 类隔离在蚂蚁内部使用非常广泛，绝大部分业务应用都是运行在蚂蚁中间件自研的类隔离框架之上。主要是为了解决依赖冲突的问题，像蚂蚁金服这种体量的公司，业务线繁杂、基础服务组件众多，很难做到对所有 JAR 包做统一管控。特别涉及到跨团队模块组件相互依赖时，因为各自技术栈历史包袱的存在，难以有效统一冲突包版本。使用类隔离技术解决了实际开发中的很多痛点，业务开发者不需要担心自身依赖冲突的问题，在多团队协作开发中，也有很大的优势。\nQ: SOFABoot类隔离框架（SOFAArk）和 OSGI 容器有哪些差异？ 作为开源界早负盛名的动态模块系统，基于 OSGi 规范的 Equinox、Felix 等同样具备类隔离能力，然而他们更多强调的是一种编程模型，面向模块化开发，有一整套模块生命周期的管理，定义模块通信机制以及复杂的类加载模型。作为专注于解决依赖冲突的隔离框架，SOFAArk 专注于类隔离，简化了类加载模型，因此显得更加轻量。其次在 OSGi 规范中，所有的模块定义成 Bundle 形式，作为应用开发者，他需要了解 OSGi 背后的工作原理，对开发者要求比较高。在 SOFAArk 中，定义了两层模块类型，Ark Plugin 和 Ark Biz，应用开发者只需要添加隔离的 Ark Plugin 依赖，底层的类加载模型对应用开发者俩说是透明的，基本不会带来额外的学习成本。\nQ: SOFAArk 和 Java9 模块化有哪些差异？ Jigsaw 作为 Java9 模块化方案，抛开内部实现细节，在使用规范上和 OSGi 特别相似：模块的依赖、包导入导出、动态导出、可读性传递、模块服务注册与消费、开放模块、可选模块等等若干概念，相对于 SOFAArk 简单的包导入导出显然过于复杂。在实现细节上，考虑到 JDK 代码的兼容性，Jigsaw 没有采用类加载器隔离的方式，不同模块之间仍然可能是同一个类加载器加载。严格上来讲，Jigsaw 并没有解决同一个类多版本的问题，但是因为模块显示的依赖声明，使用纯 Jigsaw 模块化编程，不同版本类冲突的问题在编译期就能被检查或者启动失败，因为不允许不同模块含有相同类名的包。对于在实际开发中遇到的一类情况，例如两个组件依赖不同版本 hessian 包，即使这两个组件定义成了两个模块，运行时也只有一个hessian版本被加载，依然解决不了不同版本类共存的问题。另外，Jigsaw 相对 Ark 或者 OSGi 有一个明显的缺点，Jigsaw 不允许运行时动态发布模块服务，模块间的通信依赖在 module-info.java 中使用 provides 和 uses 静态注册和引用模块服务。当然，Jigsaw 有很多自己的优点，通过引入module-path，在 module 中显示声明模块依赖关系，避免了传统 maven/gradle 中因为间接依赖导致运行时加载类不确定的缺点；其次通过设置模块包的导入导出配置，可以完全做到接口和实现的分离，提升安全性；另外 Java9 本身借助模块化改造，使用jlink工具，开发者可以将自身应用必须的模块聚合，打包一个自定义的jre镜像。\nQ: 为什么使用 SNAPSHOT 版本拉取不到依赖？ 如果需要使用处于研发状态的 SNAPSHOT 版本，有两种方式：\n 拉取 sofa-ark 仓库代码，本地执行 mvn install。 在本地 maven setting.xml 文件增加如下 profile 配置:  \u0026amp;lt;profile\u0026amp;gt; \u0026amp;lt;id\u0026amp;gt;default\u0026amp;lt;/id\u0026amp;gt; \u0026amp;lt;activation\u0026amp;gt; \u0026amp;lt;activeByDefault\u0026amp;gt;true\u0026amp;lt;/activeByDefault\u0026amp;gt; \u0026amp;lt;/activation\u0026amp;gt; \u0026amp;lt;repositories\u0026amp;gt; \u0026amp;lt;repository\u0026amp;gt; \u0026amp;lt;snapshots\u0026amp;gt; \u0026amp;lt;enabled\u0026amp;gt;true\u0026amp;lt;/enabled\u0026amp;gt; \u0026amp;lt;/snapshots\u0026amp;gt; \u0026amp;lt;id\u0026amp;gt;maven-snapshot\u0026amp;lt;/id\u0026amp;gt; \u0026amp;lt;url\u0026amp;gt;https://oss.sonatype.org/content/repositories/snapshots\u0026amp;lt;/url\u0026amp;gt; \u0026amp;lt;/repository\u0026amp;gt; \u0026amp;lt;/repositories\u0026amp;gt; \u0026amp;lt;pluginRepositories\u0026amp;gt; \u0026amp;lt;pluginRepository\u0026amp;gt; \u0026amp;lt;snapshots\u0026amp;gt; \u0026amp;lt;enabled\u0026amp;gt;true\u0026amp;lt;/enabled\u0026amp;gt; \u0026amp;lt;/snapshots\u0026amp;gt; \u0026amp;lt;id\u0026amp;gt;maven-snapshot\u0026amp;lt;/id\u0026amp;gt; \u0026amp;lt;url\u0026amp;gt;https://oss.sonatype.org/content/repositories/snapshots\u0026amp;lt;/url\u0026amp;gt; \u0026amp;lt;/pluginRepository\u0026amp;gt; \u0026amp;lt;/pluginRepositories\u0026amp;gt; \u0026amp;lt;/profile\u0026amp;gt; Q: 为什么使用 java -jar 启动 Spring Boot/SOFABoot 应用 Ark 包时，应用自动退出？ 因为 SOFAArk 容器不会开启任何非 Daemon 线程，如果是非 Web 应用或者应用启动时不会创建非 Daemon 线程，则应用在执行完 main 方法时，会正常退出。判断 Ark 包是否正常启动，可以观察是否有如下日志出现：\nArk container started in …","date":-62135596800,"description":"","dir":"projects/sofa-boot/faq/","fuzzywordcount":2100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"56f06d32d37d8a5947d7c7ee43d6d955","permalink":"/projects/sofa-boot/faq/","publishdate":"0001-01-01T00:00:00Z","readingtime":5,"relpermalink":"/projects/sofa-boot/faq/","summary":"Q: Readiness Check 有啥应用场景？ Liveness Check 和 Readiness Check 概念来自于 Kuberentes，分别代表运行时检查和启动时检查。Spring Boot 提供了 Liveness Check，但是没有提供","tags":null,"title":"常见问题","type":"projects","url":"/projects/sofa-boot/faq/","wordcount":2071},{"author":null,"categories":null,"content":"与 Prometheus的差异 答：主要包括:（1）Lookout metrics server 支持适配更多的协议接入；（2）聚焦在围绕 ES 生态提供易使用和运维的最佳实践；（3）支持计算能力下推；（4）除了 Metrics 后期会有 tracing，eventing等方案； （5）对聚合函数和 REST API 都做了兼容性的扩展和增强；（6）支持分布式集群部署具备高可用能力。\nLookout客户端会提供多语言(c,go,python\u0026amp;hellip;)支持吗 答：暂时不会。因为 Lookout Gateway已经支持很多主流协议的数据上报，同时也支持自定义扩展。 如果非Java技术栈，我们推荐大家使用其他开源主流的sdk库，比如: Prometheus sdk，Metricbeat等\n\u0026amp;ldquo;In order to improve query performance, you need to add tag filtering! realQuery:jvm.classes.loaded\u0026amp;rdquo; 答：只输入metric name查询会影响查询性能，所以我们强制每个查询至少有一个 tag（label）的筛选能力，比如:\u0026amp;ldquo;jvm.classes.loaded{app=\u0026amp;ldquo;lookout-gateway\u0026amp;rdquo;}\u0026amp;quot;。\n","date":-62135596800,"description":"","dir":"projects/sofa-lookout/faq/","fuzzywordcount":500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"f05d40c9d503ad466634f0473a5fac40","permalink":"/projects/sofa-lookout/faq/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-lookout/faq/","summary":"与 Prometheus的差异 答：主要包括:（1）Lookout metrics server 支持适配更多的协议接入；（2）聚焦在围绕 ES 生态提供易使用和运维的最佳实践；","tags":null,"title":"常见问题","type":"projects","url":"/projects/sofa-lookout/faq/","wordcount":429},{"author":null,"categories":null,"content":"咨询 Q: SOFARPC 是蚂蚁金服内部使用的版本吗？ 是的，SOFARPC 有良好的扩展接口，内部使用的版本就是在开源的版本多一些扩展实现。例如我们云上的商业版本集成了蚂蚁金融云的共享版注册中心、链路跟踪等产品；蚂蚁内部的版本集成了蚂蚁内部的注册中心、LDC路由等特性扩展。\nQ: SOFARPC 内部是用 Zookeeper 作为注册中心的吗？可以集成其它 etcd 等注册中心吗？ 在蚂蚁内部使用的是蚂蚁自研的注册中心产品。SOFARPC 的注册中心模块是可扩展的，对内对外使用的都是一套核心接口。目前开源的版本中集成了 Zookeeper，其它的注册中心实现社区已经在集成中。\nQ: 与Dubbo对比？ Dubbo 是阿里集团开源的一款非常优秀的RPC框架，高性能，具有良好的扩展性。Dubbo在国内开源界起步较早，使用者较多，开源生态更加丰富，目前已进入Apache基金会进行孵化。Dubbo最早在阿里巴巴B2B部门广泛使用。更多信息这里就不多介绍了。\nSOFARPC 最早起源于阿里集团内部的 HSF，但是经过了蚂蚁金服集团内部多年的独立发展，目前脱离为一个独立的产品。SOFARPC 在协议，网络，路由，可扩展性等层面都进行了大量的改造和优化的工作，以满足蚂蚁金服大规模金融级的业务场景。在蚂蚁金服内部，SOFARPC 在蚂蚁中间件（SOFAStack）的生态下，有完善的微服务技术栈支持，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics监控度量等等。截止 2019 年双十一，SOFARPC 已经被蚂蚁几千个系统所使用，生产环境发布的接口数量超过了十几万。\n但是在开源领域，SOFARPC 目前还是一个起步阶段，开源生态还在建设当中，随着开源计划的推进，我们会在后续的版本里增加各个周边组件，完善微服务技术栈。同时也欢迎大家来贡献，共同打造 SOFAStack。\n对于性能的对比，类似协议下使用的技术点都是差不多的，所以基本上可比性不高。 对于扩展性的对比，两者都具有良好的扩展性。 对于其它功能差异点的话，这里列一些已经开源或者即将开源的功能点供参考：SOFARPC 协议上将支持 HTTP/2、GRPC，能力上如服务预热权重、自动故障降级、协商机制、CRC数据校验等，结合 SOFABoot 可以实现 RPC 框架与业务的类隔离防止类冲突等等，另外 SOFARPC 在跨单元机房的路由，包括配合服务注册体系实现的对异地多活的支撑也是非常有特色的，期望后面能逐步跟大家分享讨论，甚至形成行业标准。而 SOFARPC 结合内部微服务下做一致性的框架实现的「微交易」架构也是蚂蚁在金融领域非常有价值的沉淀，也是跟 dubbo 体系不一样的地方。\nQ: 对比其他 RPC 框架有何优势？ 作为RPC框架，最基本的能力就是 RPC 调用，其它都是些性能、扩展性、功能性的差异，可能各家的侧重点不一样。\nSOFARPC 在蚂蚁金服内部大规模应用足以证明 SOFARPC 是一款可靠的生产级的 RPC 框架。而蚂蚁金服的金融的属性决定了 SOFARPC 在金融场景下的功能侧重点。\nQ: 和Spring Cloud 的对比？ SOFARPC 定位在 RPC 框架，和 Spring Cloud 的比较不在一个对比维度上面。 Spring Cloud 可对比的是 SOFAStack，SOFAStack 是蚂蚁金服自主研发的金融级分布式中间件，包含了构建金融级云原生架构所需的各个组件，包括微服务研发框架，RPC 框架，服务注册中心，分布式定时任务，限流/熔断框架，动态配置推送，分布式链路追踪，Metrics监控度量，以及分布式高可用消息队列，分布式事务框架，分布式数据库代理层等组件，是一套分布式架构的完整的解决方案。SOFAStack 的各个组件会在未来逐渐开源。\n另外，SOFARPC 的 Starter 是基于 Spring Boot 开发的，Spring Cloud 的各个组件也是基于 Spring Boot 开发的，所以两者并不冲突。\n研发类 Q: 为什么不使用 JDK8 SOFARPC 在蚂蚁金服内部还有JDK6的使用场景，所以编译选择JDK7，而编译级别选择JDK6。\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/faq/","fuzzywordcount":1600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"a6ec77ce5a423c5345394f42c64a416b","permalink":"/projects/sofa-rpc/faq/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/projects/sofa-rpc/faq/","summary":"咨询 Q: SOFARPC 是蚂蚁金服内部使用的版本吗？ 是的，SOFARPC 有良好的扩展接口，内部使用的版本就是在开源的版本多一些扩展实现。例如我们云上的商业版","tags":null,"title":"常见问题","type":"projects","url":"/projects/sofa-rpc/faq/","wordcount":1533},{"author":null,"categories":null,"content":"SOFARPC 可以在使用 Bolt 通信协议的情况下，可以选择不同的序列化协议，目前支持 hessian2 和 protobuf。\n默认的情况下，SOFARPC 使用 hessian2 作为序列化协议，如果需要将序列化协议设置成 protobuf，在发布服务的时候，需要做如下的设置：\n\u0026amp;lt;sofa:service ref=\u0026amp;#34;sampleService\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofarpc.demo.SampleService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;sofa:global-attrs serialize-type=\u0026amp;#34;protobuf\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;/sofa:service\u0026amp;gt; 即在 \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; 标签内增加 \u0026amp;lt;sofa:global-attrs\u0026amp;gt; 标签，并且设置 serialize-type 属性为 protobuf。\n对应的，在引用服务的时候，也需要将序列化协议改成 protobuf，设置方式和发布服务的时候类似：\n\u0026amp;lt;sofa:reference interface=\u0026amp;#34;com.alipay.sofarpc.demo.SampleService\u0026amp;#34; id=\u0026amp;#34;sampleServiceRef\u0026amp;#34; jvm-first=\u0026amp;#34;false\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;sofa:global-attrs serialize-type=\u0026amp;#34;protobuf\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt; 目前，使用注解的方式尚不能支持设置序列化协议，这个将在后续的版本中支持，详见 ISSUE：https://github.com/sofastack/sofa-boot/issues/278\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/serialization/","fuzzywordcount":300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"87e2faa84c2c7a7605243dc096bc4e17","permalink":"/projects/sofa-rpc/serialization/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/serialization/","summary":"SOFARPC 可以在使用 Bolt 通信协议的情况下，可以选择不同的序列化协议，目前支持 hessian2 和 protobuf。 默认的情况下，SOFARPC 使用 hessian2 作为序列化协议，如","tags":null,"title":"序列化协议","type":"projects","url":"/projects/sofa-rpc/serialization/","wordcount":296},{"author":null,"categories":null,"content":"SLF4J 提供了 MDC （Mapped Diagnostic Contexts）功能，可以支持用户定义和修改日志的输出格式以及内容。本文将介绍 SOFATracer 集成的 SLF4J MDC功能，方便用户在只简单修改日志配置文件的前提下输出当前 SOFATracer 上下文 TraceId 以及 SpanId 。\n使用前提 为了在应用中的日志正确打印 TraceId 和 SpanId 参数，我们的日志编程接口需要面向 SLF4J 进行编程，即打印日志的编程接口不要依赖具体的日志实现。\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.slf4j\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;slf4j-api\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 引入依赖 如果是 SOFABoot 或者 Spring Boot 的应用具体的日志实现需要大家去引入，我们推荐的日志打印实现是 Logback 和 Log4j2，不推荐 Log4j，同时日志实现建议只使用一个而不要使用多个实现。\n Logback 实现引入：  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-starter-logging\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  Log4j2 实现引入：  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-starter-log4j2\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;!--SOFABoot 没有管控 log4j2 版本 --\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;1.4.2.RELEASE\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 配置方法 我们基于 SLF4J MDC 的原理打印对应的 TraceId 和 SpanId，首先我们的应用中的日志编程接口应该面向 SLF4J，如通过如下的方式：\n//引入接口 import org.slf4j.Logger; import org.slf4j.LoggerFactory; //构造日志打印实例 private static final Logger logger = LoggerFactory.getLogger(XXX.class); 其次，我们为了正确打印 TraceId 和 SpanId 参数，我们还需要在日志的配置文件中配置 PatternLayout 的额外参数，这两个参数是 %X{SOFA-TraceId} 和 %X{SOFA-SpanId}，参数值我们均是从 MDC 中获取的值。\n以 Logback 为例配置的 pattern 参数：\n\u0026amp;lt;pattern\u0026amp;gt;%d{yyyy-MM-dd HH:mm:ss.SSS} %5p [%X{SOFA-TraceId}, %X{SOFA-SpanId}] ---- %m%n\u0026amp;lt;/pattern\u0026amp;gt;  关键配置项目：[%X{SOFA-TraceId},%X{SOFA-SpanId}] 作为 Logback pattern 的一部分，在对应的 appender 被调用的时候，会根据 pattern 中的占位符替换为当前线程上下文中 TraceId 和 SpanId 的具体值，当前线程中没有对应的 TraceId 和 SpanId 值时，会用“空字符串”替代。  Log4j2 配置 PatternLayout 样例：\n\u0026amp;lt;PatternLayout pattern=\u0026amp;#34;%d{yyyy-MM-dd HH:mm:ss.SSS} %5p [%X{SOFA-TraceId},%X{SOFA-SpanId}] ---- %m%n \u0026amp;#34; /\u0026amp;gt; Log4j 配置 PatternLayout 样例：\n\u0026amp;lt;layout class=\u0026amp;#34;org.apache.log4j.PatternLayout\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;param name=\u0026amp;#34;ConversionPattern\u0026amp;#34; value=\u0026amp;#34;%d %-5p %-32t [%X{SOFA-TraceId},%X{SOFA-SpanId}] - %m%n\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/layout\u0026amp;gt;  需要注意的是：[%X{SOFA-TraceId},%X{SOFA-SpanId}] 使我们推荐的打印格式，用户可以根据自己的实际需求场景进行定制\n 附:基于 Log4j2 示例工程的源代码地址。\n","date":-62135596800,"description":"","dir":"projects/sofa-tracer/print-traceid-spanid/","fuzzywordcount":800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"0d8cc680f811d1db2cffddbba269571c","permalink":"/projects/sofa-tracer/print-traceid-spanid/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-tracer/print-traceid-spanid/","summary":"SLF4J 提供了 MDC （Mapped Diagnostic Contexts）功能，可以支持用户定义和修改日志的输出格式以及内容。本文将介绍 SOFATracer 集成的 SLF4J MDC功能，方便用户在只","tags":null,"title":"应用日志打印 traceId 和 spanId","type":"projects","url":"/projects/sofa-tracer/print-traceid-spanid/","wordcount":701},{"author":null,"categories":null,"content":"SOFADashboard 支持查看应用的IP、端口、健康检查状态等基本信息。此功能依赖 SOFADashboard client ，如果一个应用需要将应用信息展示到 SOFADashboard 管控端，可以通过引入客户端依赖即可：\n\u0026amp;lt;denpendency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;dashboard-client-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/denpendency\u0026amp;gt; 除此之外，SOFADashboard 解耦了类似于 SpringBoot Admin 客户端和服务端直连的模式，引入了第三方的储存，目前默认是 redis，因此如果希望能够监控 更多 actuator 信息，可以添加如下依赖：\n\u0026amp;lt;denpendency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;dashboard-ext-redis-store\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/denpendency\u0026amp;gt; 功能展示 相关数据的展示采用了 react-json-view 组件，是的可以直观的看到原始数据集。\n应用维度展示 应用实例 基础信息 健康检查详细数据 环境变量 loggins mappings 配置 client , prefix : com.alipay.sofa.dashboard.client\n   属性 名称 默认值 备注     enable 是否可用 true 当开启时，dashboard client 的相应功能才会作用   instanceIp 指定当前实例的IP 地址 \u0026amp;quot;\u0026amp;quot; 一般用于测试或者需要指定 IP 的场景   storeInitDelayExp 初始上报延迟 30s Dashboard度量数据存储上报延迟期望(s)   storeUploadPeriodExp 上报周期 60s Dashboard度量数据存储上报周期(s)   virtualHost 虚拟地址 \u0026amp;quot;\u0026amp;quot; 服务发布虚拟host（同SofaRpc中相同定义），可使用-Dcom.alipay.sofa.rpc.virtual.host引入   virutalPort 虚拟端口 \u0026amp;quot;\u0026amp;quot; 服务发布虚拟port（同SofaRpc中相同定义），可使用-Dcom.alipay.sofa.rpc.virtual.port引入   internalHost 内部地址 \u0026amp;quot;\u0026amp;quot; 容器内部地址（例如podIp等)，可使用-Dcom.alipay.sofa.rpc.virtual.internal.host引入   arkEnable 是否启用ark管理 true 当开启时，dashboard client的相应功能才会作用    注：virtualHost，virutalPort 如果通过com.alipay.sofa.rpc指定了相应参数，则不需要通过dashborad再次指定\nzookeeper , prefix : com.alipay.sofa.dashboard.zookeeper\n   属性 名称 默认值 备注     address 地址 true    baseSleepTimeMs 客户端错误重试间隔(ms). 1000    maxRetries 客户端最大重试次数 3    sessionTimeoutMs 客户端会话超时时间(ms) 6000    connectionTimeoutMs 客户端超时时间(ms) 6000     redis , prefix : com.alipay.sofa.dashboard.redis\n   属性 名称 默认值 备注     enble 是否可用 true 当开启时，dashboard会使用redis作为存储   recordTtl 上报周期(ms). 3600    url redis对应url  例如：redis://user:password@example.com:6379   host redis对应host（单实例模式）     port redis对应port（单实例模式）     password redis密码     Sentinel.master Sentinel模式master  master节点名，需参阅集群搭建设置   Sentinel.nodes Sentinel模式节点地址  例如host1:port1;host2:port2;host3:port3   Cluster.nodes Cluster模式节点地址  例如host1:port1;host2:port2;host3:port3   Cluster.maxRedirects Cluster模式重定向次数 0 建议给值，例如10    ","date":-62135596800,"description":"","dir":"projects/sofa-dashboard/dashboard-client/","fuzzywordcount":1100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"60586c6dfee1f2afcdac88cbe7a36b83","permalink":"/projects/sofa-dashboard/dashboard-client/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/sofa-dashboard/dashboard-client/","summary":"SOFADashboard 支持查看应用的IP、端口、健康检查状态等基本信息。此功能依赖 SOFADashboard client ，如果一个应用需要将应用信息展示到 SOFADashboard 管控端，可以通过引入客户端依赖即可： \u0026lt;denpendency\u0026gt;","tags":null,"title":"应用面板","type":"projects","url":"/projects/sofa-dashboard/dashboard-client/","wordcount":1078},{"author":null,"categories":null,"content":"首先参考基本代码贡献需知  注意测试用例覆盖率； 代码格式；  验证 Samples  单独导入 Samples 的 Maven 项目； 修改对应 Pom 文件中依赖版本； 验证 Samples 也能正确工作；  ","date":-62135596800,"description":"","dir":"projects/sofa-lookout/development-use-guide/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"423a54ec3f5fbfc9c0e150eb853738ae","permalink":"/projects/sofa-lookout/development-use-guide/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-lookout/development-use-guide/","summary":"首先参考基本代码贡献需知 注意测试用例覆盖率； 代码格式； 验证 Samples 单独导入 Samples 的 Maven 项目； 修改对应 Pom 文件中依赖版本； 验证 Samples 也能正确工作；","tags":null,"title":"开发指南","type":"projects","url":"/projects/sofa-lookout/development-use-guide/","wordcount":63},{"author":null,"categories":null,"content":"1.如何编译  安装 JDK7 及以上，Maven 3.2.5 及以上。 直接下载代码，然后在代码目录下执行如下命令：\n mvn clean install 2.版本发布 版本号 采用三位版本号，分别是主版本号、次版本号、修订版本号，例如 1.0.1。\n参见: http://semver.org/lang/zh-CN/。\n 主版本号：主版本号内的所有版本必须相互兼容；与其它主版本号不一定完全兼容，尽量向下兼容。 次版本号：代表新特性增强。版本号越大特性越丰富。 修订版本号：代表 BugFix 版本。只做 bug 修复使用，版本号越大越稳定。  版本维护 最多同时维护两个版本。\n例如当前主干为 1.3.0，那么将会维护 1.2.x 的 bugfix 分支，而 1.1.x 遇到 bug 将不再修复，建议升级。\n发布流程  日常开发分支采用 SNAPSHOT 版本，例如 1.3.0-SNAPSHOT。 正式发布时修改版本为正式版本，例如 1.3.0。 发布后拉起下一个版本，例如 1.3.1-SNAPSHOT。  3.测试 单元测试 单元测试例子放到自己开发的模块下，测试类的包名与被测试类所在包相同。\n","date":-62135596800,"description":"","dir":"projects/sofa-acts/developer-guide/","fuzzywordcount":500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"fcacc7e89b979f3aec8dc3333a7a3c37","permalink":"/projects/sofa-acts/developer-guide/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-acts/developer-guide/","summary":"1.如何编译 安装 JDK7 及以上，Maven 3.2.5 及以上。 直接下载代码，然后在代码目录下执行如下命令： mvn clean install 2.版本发布 版本号 采用三位版本号，分别是主版","tags":null,"title":"开发者手册","type":"projects","url":"/projects/sofa-acts/developer-guide/","wordcount":404},{"author":null,"categories":null,"content":"介绍实现架构和相关的细节介绍：\n 如何编译 架构介绍 调用流程 基础模型 扩展点设计 版本发布 测试  ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/developer-guide/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"903b9f3a5372a75d654f8eeaaf750eeb","permalink":"/projects/sofa-rpc/developer-guide/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/developer-guide/","summary":"介绍实现架构和相关的细节介绍： 如何编译 架构介绍 调用流程 基础模型 扩展点设计 版本发布 测试","tags":null,"title":"开发者手册","type":"projects","url":"/projects/sofa-rpc/developer-guide/","wordcount":42},{"author":null,"categories":null,"content":"线程中使用 java.lang.Runnable 如果用户在代码中通过 java.lang.Runnable 新启动了线程或者采用了线程池去异步地处理一些业务，那么需要将 SOFATracer 日志上下文从父线程传递到子线程中去，SOFATracer 提供的 com.alipay.common.tracer.core.async.SofaTracerRunnable 默认完成了此操作，大家可以按照如下的方式使用：\nThread thread = new Thread(new SofaTracerRunnable(new Runnable() { @Override public void run() { //do something your business code  } })); thread.start(); 线程中使用 java.util.concurrent.Callable 如果用户在代码中通过 java.util.concurrent.Callable 新启动线程或者采用了线程池去异步地处理一些业务，那么需要将 SOFATracer 日志上下文从父线程传递到子线程中去，SOFATracer 提供的 com.alipay.common.tracer.core.async.SofaTracerCallable 默认完成了此操作，大家可以按照如下的方式使用：\nExecutorService executor = Executors.newCachedThreadPool(); SofaTracerCallable\u0026amp;lt;Object\u0026amp;gt; sofaTracerSpanSofaTracerCallable = new SofaTracerCallable\u0026amp;lt;Object\u0026amp;gt;(new Callable\u0026amp;lt;Object\u0026amp;gt;() { @Override public Object call() throws Exception { return new Object(); } }); Future\u0026amp;lt;Object\u0026amp;gt; futureResult = executor.submit(sofaTracerSpanSofaTracerCallable); //do something in current thread  Thread.sleep(1000); //another thread execute success and get result  Object objectReturn = futureResult.get(); 这个实例中，假设 java.util.concurrent.Callable 返回结果的对象类型是 java.lang.Object，实际使用时可以根据情况替换为期望的类型。\nSOFATracer 对线程池、异步调用场景下的支持 异步场景  异步调用，以 rpc 调用为例，每次 rpc 调用请求出去之后不会等待到结果返回之后才去发起下一次处理，这里有个时间差，在前一个 rpc 调用的 callback 回来之前，又一个新的 rpc 请求发起，此时当前线程中的 TracerContext 没有被清理，则 spanId 会自增，tracerId 相同。\n 对于上面这种情况，SOFATracer 在对于异步情况处理时，不会等到 callback 回来之后，调用 cr 阶段才会清理，而是提前就会清理当前线程的 tracerContext 上下文，从而来保证链路的正确性。\n线程池 目前来说，不管是 SOFARPC 还是 Dubbo 的埋点实现，在使用单线程或者线程池时，情况是一样的：\n 同步调用，线程池中分配一个线程用于处理 rpc 请求，在请求结束之前会一直占用线程；此种情况下不会造成下一个 rpc 请求错拿上一个请求的 tracerContext 数据问题 异步调用，由于异步回调并非是在 callback 中来清理上下文，而是提前清理的，所以也不会存在数据串用问题。 callback 异步回调，这个本质上就是异步调用，所以处理情况和异步调用相同。  附：案例工程\n","date":-62135596800,"description":"","dir":"projects/sofa-tracer/async/","fuzzywordcount":800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"e755346c441115663c101638667fe4c0","permalink":"/projects/sofa-tracer/async/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-tracer/async/","summary":"线程中使用 java.lang.Runnable 如果用户在代码中通过 java.lang.Runnable 新启动了线程或者采用了线程池去异步地处理一些业务，那么需要将 SOFATracer 日志上下文从父线程传递到子线程中去，SOFA","tags":null,"title":"异步线程处理","type":"projects","url":"/projects/sofa-tracer/async/","wordcount":726},{"author":null,"categories":null,"content":"本文用于帮助初次接触 MOSN 项目的开发人员，快速搭建开发环境，完成构建，测试，打包和示例代码的运行。\n注：MOSN 基于 Go 1.12.7 开发，使用 dep 进行依赖管理。\n准备运行环境  如果您使用容器运行 MOSN，请先 安装 docker 如果您使用本地机器，请使用类 Unix 环境 安装 Go 的编译环境 安装 dep : 参考官方安装文档  获取代码 MOSN 项目的代码托管在 Github，获取方式如下：\ngo get -u mosn.io/mosn 如果您的 go get 下载存在问题，请手动创建项目工程\n# 进入 GOPATH 下的 src 目录 cd $GOPATH/src # 创建 mosn.io 目录 mkdir -p mosn.io cd mosn.io # 克隆 MOSN 代码 git clone git@github.com:mosn/mosn.git cd mosn 最终 MOSN 的源代码代码路径为 $GOPATH/src/mosn.io/mosn\n导入IDE 使用您喜爱的 Go IDE 导入 $GOPATH/src/mosn.io/mosn 项目，推荐 Goland。\n编译代码 在项目根目录下，根据自己机器的类型以及欲执行二进制的环境，选择以下命令编译 MOSN 的二进制文件。\n使用 docker 镜像编译 make build // 编译出 linux 64bit 可运行二进制文件 本地编译 使用下面的命令编译本地可运行二进制文件。\nmake build-local 在非 Linux 机器交叉编译 Linux 64bit 可运行二进制文件。\nmake build-linux64 在非 Linux 机器交叉编译 Linux 32bit 可运行二进制文件。\nmake build-linux32 完成后可以在 build/bundles/${version}/binary 目录下找到编译好的二进制文件。\n打包 在项目根目录下执行如下命令进行打包。\nmake rpm 完成后可以在 build/bundles/${version}/rpm 目录下找到打包好的文件。\n创建镜像 执行如下命令进行镜像创建。\nmake image 运行测试 在项目根目录下执行如下命令运行单元测试：\nmake unit-test 在项目根目录下执行如下命令运行集成测试（较慢）。\nmake integrate 从配置文件启动 MOSN 运行下面的命令使用配置文件启动 MOSN。\n./mosn start -c \u0026amp;#39;$CONFIG_FILE\u0026amp;#39; 开启 MOSN 转发示例程序 参考 examples 目录下的示例工程运行 Samples。\n使用 MOSN 搭建 Service Mesh 平台 请参考与 Istio 集成。\n","date":-62135596800,"description":"","dir":"projects/mosn/quick-start-setup/","fuzzywordcount":700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"d41615315adb522aa4b84762f113a574","permalink":"/projects/mosn/quick-start-setup/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/mosn/quick-start-setup/","summary":"本文用于帮助初次接触 MOSN 项目的开发人员，快速搭建开发环境，完成构建，测试，打包和示例代码的运行。 注：MOSN 基于 Go 1.12.7 开发，使用 dep 进行依赖管理。","tags":null,"title":"快速开始","type":"projects","url":"/projects/mosn/quick-start-setup/","wordcount":614},{"author":null,"categories":null,"content":"本文档共分为四部分：\n 第一部分：在 Intellij IDEA 上安装 ACTS IDE 可视化编辑器； 第二部分：向您介绍如何在多模块工程中引入 ACTS 依赖； 第三部分：测试模块下一键搭建 ACTS 框架以管理后续 ACTS 用例； 第四部分：一键生成 ACTS 测试脚本；  1.安装 ACTS IDE 推荐使用 Intellij IDEA 2017，为了您的安全，请仅从该下载源获取 ACTS IDE 安装包： 点击下载 ACTS IDE，\n本地磁盘安装：Preference -\u0026amp;gt; Plugins -\u0026amp;gt; Install plugin from disk -\u0026amp;gt; Restart IDEA 即可。 2.引入 ACTS 依赖 在引入依赖之前，需要您的应用是一个多模块工程（包含 test 模块），后续 ACTS 会将全部的测试代码放置在 test 模块下以便管理 ACTS 用例。\n您可以依据应用的具体情况，选择性阅读以下内容：\n应用已经是完整的多模块工程，可参考文档 2.1 部分，帮助您引入 ACTS 依赖； 应用是多模块工程但无 test 模块，可参考文档 2.2 部分，帮助您快速添加 test 模块； 应用不是一个多模块工程，可参考文档 2.3 部分，帮助您快速构建多模块工程。 如果还没有创建工程，可参考 SOFABoot 快速开始搭建应用。\n2.1多模块应用-包含 test 模块 只需在 test 模块的 pom.xml 中引入 acts-bom 即可。\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa.acts\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;acts-bom\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${acts.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;type\u0026amp;gt;pom\u0026amp;lt;/type\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 2.2多模块应用-无 test 模块 这里是使用 Intellij IDEA 来创建子模块。\n对着父工程右键 -\u0026amp;gt; New -\u0026amp;gt; Module -\u0026amp;gt; 输入 test 模块名字（一般是 appname-test），分步示例图如下：\n第一步：新建 test 模块 第二步：管理 test 模块 在父工程的 pom.xml 中管理刚刚新建的 test 模块。\n第三步：依赖 ACTS 引入 最后，找到刚刚新建的 test 模块，并在其 pom.xml 中引入 acts-bom 即可。\n\u0026amp;lt;!-- 引入包含 SOFABootApplication 的 pom --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.example\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;example-service\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!-- 引入 ACTS 依赖 --\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa.acts\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;acts-bom\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${acts.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;type\u0026amp;gt;pom\u0026amp;lt;/type\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 2.3非多模块应用 如果你已经有了一个不错的 SOFABoot 应用，但它不是一个多模块应用，下面的内容将帮助你快速地将现有工程构建为多模块工程。\n第一步：新建父工程 创建好一个 SOFABoot 工程，然后删除无关的文件，只需保留 pom.xml 文件。\n第二步：新建子模块 新建子工程模块，将原有应用作为子工程并入父工程下，相关依赖管理提到父工程中。以新建 service 模块和 test 模块为例。\n第三步：管理子模块 第四步：依赖引入 最后，在 test 模块的 pom.xml 文件中引入 acts-bom 即可。\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa.acts\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;acts-bom\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${acts.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;type\u0026amp;gt;pom\u0026amp;lt;/type\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 3.一键初始化 ACTS 测试框架 下面只需要你轻轻动动手指即可完成初始化工作。在图3.2中，您需要正确填写应用名称并选择适合应用的编码格式。\n有关一键初始化生成的文件有何作用，可以参考 ACTS 使用手册的框架准备部分。\n4.一键生成测试脚本 4.1启动类 将 service 模块中的启动类，如 SOFABootApplication 拷贝到 test 模块，并增加需要加载的配置文件：classpath*:META-INF/spring/acts-core.xml\n4.2测试脚本 前提条件：务必 mvn 编译工程和生成对象模型，否则会造成 ACTS IDE 不可预料的错误，如无法编辑、数据不正确等。\n接口定义的方法上点击，选择 ACTS 功能 -\u0026amp;gt; 生成测试用例，并在刚生成的测试脚本中矫正 SOFABoot 启动类的 import 位置。\n","date":-62135596800,"description":"","dir":"projects/sofa-acts/getting-started/","fuzzywordcount":1100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"dfc5fb9b394ea14c280568dcb881a8b0","permalink":"/projects/sofa-acts/getting-started/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/sofa-acts/getting-started/","summary":"本文档共分为四部分： 第一部分：在 Intellij IDEA 上安装 ACTS IDE 可视化编辑器； 第二部分：向您介绍如何在多模块工程中引入 ACTS 依赖； 第三部分：测试模块下一键搭建 ACTS 框","tags":null,"title":"快速开始","type":"projects","url":"/projects/sofa-acts/getting-started/","wordcount":1074},{"author":null,"categories":null,"content":"在本文档中，将创建一个 Spring Boot 的工程，引入 SOFABoot 基础依赖，并且引入 SOFABoot 的健康检查扩展能力，演示如何快速上手 SOFABoot。\n环境准备 要使用 SOFABoot，需要先准备好基础环境，SOFABoot 依赖以下环境：\n JDK7 或 JDK8 需要采用 Apache Maven 3.2.5 或者以上的版本来编译  创建工程 SOFABoot 是直接构建在 Spring Boot 之上，因此可以使用 Spring Boot 的工程生成工具 来生成，在本文档中，我们需要添加一个 Web 的依赖，以便最后在浏览器中查看效果。\n引入 SOFABoot 在创建好一个 Spring Boot 的工程之后，接下来就需要引入 SOFABoot 的依赖，首先，需要将上文中生成的 Spring Boot 工程的 zip 包解压后，修改 maven 项目的配置文件 pom.xml，将\n\u0026amp;lt;parent\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-starter-parent\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${spring.boot.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;relativePath/\u0026amp;gt; \u0026amp;lt;/parent\u0026amp;gt; 替换为：\n\u0026amp;lt;parent\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;sofaboot-dependencies\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${sofa.boot.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/parent\u0026amp;gt; 这里的 ${sofa.boot.version} 指定具体的 SOFABoot 版本，参考发布历史。 然后，添加 SOFABoot 健康检查扩展能力的依赖及 Web 依赖(方便查看健康检查结果)：\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;healthcheck-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-starter-web\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 最后，在工程的 application.properties 文件下添加 SOFABoot 工程常用的参数配置，其中 spring.application.name 是必需的参数，用于标示当前应用的名称；logging path 用于指定日志的输出目录。\n# Application Name spring.application.name=SOFABoot Demo # logging path logging.path=./logs 运行 可以将工程导入到 IDE 中运行生成的工程里面中的 main 方法（一般上在 XXXApplication 这个类中）启动应用，也可以直接在该工程的根目录下运行 mvn spring-boot:run，将会在控制台中看到启动打印的日志：\n2018-04-05 21:36:26.572 INFO ---- Initializing ProtocolHandler [\u0026amp;quot;http-nio-8080\u0026amp;quot;] 2018-04-05 21:36:26.587 INFO ---- Starting ProtocolHandler [http-nio-8080] 2018-04-05 21:36:26.608 INFO ---- Using a shared selector for servlet write/read 2018-04-05 21:36:26.659 INFO ---- Tomcat started on port(s): 8080 (http) 可以通过在浏览器中输入 http://localhost:8080/sofaboot/versions 来查看当前 SOFABoot 中使用 Maven 插件生成的版本信息汇总，结果类似如下：\n[ { GroupId: \u0026amp;#34;com.alipay.sofa\u0026amp;#34;, Doc-Url: \u0026amp;#34;https://github.com/sofastack/sofa-boot\u0026amp;#34;, ArtifactId: \u0026amp;#34;infra-sofa-boot-starter\u0026amp;#34;, Built-Time: \u0026amp;#34;2018-04-05T20:55:26+0800\u0026amp;#34;, Commit-Time: \u0026amp;#34;2018-04-05T20:54:26+0800\u0026amp;#34;, Commit-Id: \u0026amp;#34;049bf890bb468aafe6a3e07b77df45c831076996\u0026amp;#34;, Version: \u0026amp;#34;2.4.4\u0026amp;#34; } ] 注: 在 SOFABoot 3.x 中调整了 endpoint 路径，sofaboot/versions 更改为 actuator/versions\n可以通过在浏览器中输入 http://localhost:8080/health/readiness 查看应用 Readiness Check 的状况，类似如下：\n{ status: \u0026amp;#34;UP\u0026amp;#34;, sofaBootComponentHealthCheckInfo: { status: \u0026amp;#34;UP\u0026amp;#34; }, springContextHealthCheckInfo: { status: \u0026amp;#34;UP\u0026amp;#34; }, DiskSpace: { status: \u0026amp;#34;UP\u0026amp;#34;, total: 250140434432, free: 22845308928, threshold: 10485760 } } 注: 在 SOFABoot 3.x 中调整了 endpoint 路径，health/readiness 更改为 actuator/readiness\nstatus: \u0026amp;quot;UP\u0026amp;quot; 表示应用 Readiness Check 健康的。可以通过在浏览器中输入 http://localhost:8080/health 来查看应用的运行时健康状态（可能会随着时间发生变化）。\n注: 在 SOFABOOT 3.X 中调整了 endpoint 路径，/health 更改为 /actuator/health …","date":-62135596800,"description":"","dir":"projects/sofa-boot/quick-start/","fuzzywordcount":2200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"7f582b905fde4a56791c03d4dd6b5a57","permalink":"/projects/sofa-boot/quick-start/","publishdate":"0001-01-01T00:00:00Z","readingtime":5,"relpermalink":"/projects/sofa-boot/quick-start/","summary":"在本文档中，将创建一个 Spring Boot 的工程，引入 SOFABoot 基础依赖，并且引入 SOFABoot 的健康检查扩展能力，演示如何快速上手 SOFABoot。 环境准备 要使用 SOFABo","tags":null,"title":"快速开始","type":"projects","url":"/projects/sofa-boot/quick-start/","wordcount":2152},{"author":null,"categories":null,"content":"这个快速开始可以帮您快速在您的电脑上，下载、安装并使用 SOFADashboard。\n环境准备 sofa-dashboard-backend 依赖 Java 环境来运行。请确保是在以下运行环境可以正常使用:\n JDK 1.8+；下载 \u0026amp;amp; 配置。 Maven 3.2.5+；下载 \u0026amp;amp; 配置。  sofa-dashboard-frontend 使用了 Ant Design Pro 脚手架，前端环境请参考 Ant Design\n数据库初始化  Mysql 版本：5.6+\n SOFAArk 管控需要依赖 MySQL 进行资源数据存储，工程目录下有一个 SofaDashboardDB.sql 脚本文件，可以通过执行这个脚本文件进行数据库表的初始化。\nZookeeper   ZooKeeper 3.4.x and ZooKeeper 3.5.x\n SOFADashboard 中的服务治理、SOFAArk 管控依赖于 Zookeeper，需要本地启动 Zookeeper 服务： ZooKeeper Document。\n后端运行 \u0026amp;gt; git clone https://github.com/sofastack/sofa-dashboard.git \u0026amp;gt; cd sofa-dashboard \u0026amp;gt; mvn clean package -DskipTests \u0026amp;gt; cd sofa-dashboard-backend/sofa-dashboard-web/target/ \u0026amp;gt; java -jar sofa-dashboard-web-1.0.0-SNAPSHOT.jar 前端运行 sofa-dashboard-front 是 SOFADashboard 的前端代码工程，基于蚂蚁金服开源的前端框架 antd 开发。\n\u0026amp;gt; cd sofa-dashboard-front \u0026amp;gt; npm i \u0026amp;gt; npm run dev 案例工程  sofastack-dashboard-guides  ","date":-62135596800,"description":"","dir":"projects/sofa-dashboard/quick-start/","fuzzywordcount":400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"fa4c5f48810727f71d675255f19617a3","permalink":"/projects/sofa-dashboard/quick-start/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-dashboard/quick-start/","summary":"这个快速开始可以帮您快速在您的电脑上，下载、安装并使用 SOFADashboard。 环境准备 sofa-dashboard-backend 依赖 Java 环境来运行。请确保是在以下运行环境可以正常","tags":null,"title":"快速开始","type":"projects","url":"/projects/sofa-dashboard/quick-start/","wordcount":313},{"author":null,"categories":null,"content":"SOFARPC 有多种编程界面，下面会对各种界面进行举例：\n SOFARPC 方式 SOFABoot 方式  ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/getting-started/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"990bb2211b02b04c3ab6e03f3ba1f74b","permalink":"/projects/sofa-rpc/getting-started/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/getting-started/","summary":"SOFARPC 有多种编程界面，下面会对各种界面进行举例： SOFARPC 方式 SOFABoot 方式","tags":null,"title":"快速开始","type":"projects","url":"/projects/sofa-rpc/getting-started/","wordcount":28},{"author":null,"categories":null,"content":"SOFATracer 接入的组件列表参考：SOFATracer 介绍，在使用时请注意不同组件对应的SOFATracer 版本和 JDK 版本。\n环境准备 要使用 SOFABoot，需要先准备好基础环境，SOFABoot 依赖以下环境：\n JDK7 或 JDK8 需要采用 Apache Maven 3.2.5 或者以上的版本来编译  示例列表 下面所有 Samples 工程均为 SOFABoot 工程(同时支持 SpringBoot 工程中使用)，关于如何创建 SOFABoot 工程请参考 SOFABoot 快速开始。\n 组件接入  Spring MVC 埋点接入 HttpClient 埋点接入 DataSource 埋点接入 RestTemplate 埋点接入 OkHttp 埋点接入 Dubbo 埋点接入   采样 上报数据到 Zipkin  ","date":-62135596800,"description":"","dir":"projects/sofa-tracer/component-access/","fuzzywordcount":300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"143f2b9022161ae5a7b10d261752ae5f","permalink":"/projects/sofa-tracer/component-access/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-tracer/component-access/","summary":"SOFATracer 接入的组件列表参考：SOFATracer 介绍，在使用时请注意不同组件对应的SOFATracer 版本和 JDK 版本。 环境准备 要使用 SOFABoot","tags":null,"title":"快速开始指南","type":"projects","url":"/projects/sofa-tracer/component-access/","wordcount":207},{"author":null,"categories":null,"content":"SOFATracer 此前的埋点均是基于组件维度的埋点，用户很难在自己业务代码中进行埋点操作，或者增加自定义 tag 值来监控一些链路信息。基于此，SOFATracer 从 2.4.1/3.0.6 版本开始支持手动埋点和基于注解的埋点方式，帮助用户解决自定义埋点问题。\n使用方式 自定义埋点提供了两种方式，一种是手动埋点，一种是基于注解方式埋点。\n手动埋点 手动埋点的方式遵循 opentracing 规范，SOFATracer 中通过 beforeInvoke 和 afterInvoke 两个函数封装了 span 的周期，如下：\n// 注入 tracer @Autowired Tracer tracer; private void testManual(){ try { // beforeInvoke 开始  SofaTracerSpan sofaTracerSpan = ((FlexibleTracer) tracer).beforeInvoke(\u0026amp;#34;testManual\u0026amp;#34;); sofaTracerSpan.setTag(\u0026amp;#34;manualKey\u0026amp;#34;,\u0026amp;#34;glmapper\u0026amp;#34;); // do your biz  } catch (Throwable t){ // 异常结束  ((FlexibleTracer) tracer).afterInvoke(t.getMessage()); } finally { // 正常结束  ((FlexibleTracer) tracer).afterInvoke(); } } 这种方式在使用上没有直接使用注解方便，但是可以直观的了解到 span 的生命周期，另外手动埋点也是对基于注解方式埋点的一种补充，下面介绍。\n基于注解方式 SOFATracer 中提供了 @Tracer 注解，其作用域是 method 级别。\n// 在 hello 方法上使用 @Tracer 注解进行埋点 @Tracer public String hello(String word){ // 自定义 tag 数据  SpanTags.putTags(\u0026amp;#34;author\u0026amp;#34;,\u0026amp;#34;glmapper\u0026amp;#34;); // 失效  helloInner(word); return \u0026amp;#34;glmapper : hello \u0026amp;#34; + word; } // 在 hello 方法上使用 @Tracer 注解进行埋点 @Tracer private String helloInner(String word){ return \u0026amp;#34;glmapper : hello \u0026amp;#34; + word; } @Tracer 是基于 Spring Aop 实现，因此一定程度上依赖 Spring 中的代理机制。如代码片段中所示，helloInner 方法由于执行过程中不会使用代理对象，而是 this，所以会导致 helloInner 的注解埋点失效。那么对于此种情况，就可以使用手动埋点的方式来弥补。\nSpanTags 是 SOFATracer 中提供的工具类，在使用注解或者手动埋点的情况下，可以通过此类提供的静态方法来设置 tag 。\n日志格式  json 格式  {\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2019-09-05 10:23:53.549\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;flexible-sample\u0026amp;#34;,\u0026amp;#34;traceId\u0026amp;#34;:\u0026amp;#34;0a0fe9291567650233504100130712\u0026amp;#34;,\u0026amp;#34;spanId\u0026amp;#34;:\u0026amp;#34;0.2\u0026amp;#34;,\u0026amp;#34;span.kind\u0026amp;#34;:\u0026amp;#34;client\u0026amp;#34;,\u0026amp;#34;result.code\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;,\u0026amp;#34;current.thread.name\u0026amp;#34;:\u0026amp;#34;http-nio-8080-exec-1\u0026amp;#34;,\u0026amp;#34;time.cost.milliseconds\u0026amp;#34;:\u0026amp;#34;4ms\u0026amp;#34;,\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;hello\u0026amp;#34;,\u0026amp;#34;param.types\u0026amp;#34;:\u0026amp;#34;java.lang.String\u0026amp;#34;,\u0026amp;#34;author\u0026amp;#34;:\u0026amp;#34;glmapper\u0026amp;#34;,\u0026amp;#34;sys.baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;,\u0026amp;#34;biz.baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;}  非 json 格式   2019-09-05 10:25:50.992,flexible-sample,0a0fe9291567650350953100130778,0.2,client,,http-nio-8080-exec-1,4ms,hello,param.types=java.lang.String\u0026amp;amp;author=glmapper\u0026amp;amp;,,\n ","date":-62135596800,"description":"","dir":"projects/sofa-tracer/flexible/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"5aaadb77e734e58428a0852d14888e92","permalink":"/projects/sofa-tracer/flexible/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-tracer/flexible/","summary":"SOFATracer 此前的埋点均是基于组件维度的埋点，用户很难在自己业务代码中进行埋点操作，或者增加自定义 tag 值来监控一些链路信息。基于此，SOFATracer","tags":null,"title":"手动埋点","type":"projects","url":"/projects/sofa-tracer/flexible/","wordcount":566},{"author":null,"categories":null,"content":"1. 集成部署模式 1.1 扩容 registry-integration 假设目前已经部署了 3 台 registry-integration，分别是 node1/node2/node3，扩容的新节点是 node4。\n操作步骤：\n第一步. 部署新的 registry-integration 节点\n首先参考部署文档，将 registry-integration.tgz 在新节点 node4 上部署起来，值得注意的是，node4 需要将 nodes.metaNode 配置项指定为4台机器的地址列表：\nnodes.metaNode=DefaultDataCenter:\u0026amp;lt;node1\u0026amp;gt;,\u0026amp;lt;node2\u0026amp;gt;,\u0026amp;lt;node3\u0026amp;gt;,\u0026amp;lt;node4\u0026amp;gt; 在这一步中，node4启动完成后，访问 curl http://\u0026amp;lt;node4\u0026amp;gt;:9615/health/check 状态显示是不健康，因为 node4 尚未加入集群，要加入集群，需要做第二步。\n第二步. 调用 changePeer 使新节点加入集群\n对已经存在的 node1/node2/node3 的任意一台，执行“修改节点列表”的运维命令，将原有由 node1/node2/node3 构成的集群，改为 node1/node2/node3/node4 集群：\ncurl -X POST \u0026amp;#34;http://\u0026amp;lt;node1\u0026amp;gt;:9615/manage/changePeer\u0026amp;#34; -d \u0026amp;#34;ipAddressList=\u0026amp;lt;node1\u0026amp;gt;,\u0026amp;lt;node2\u0026amp;gt;,\u0026amp;lt;node3\u0026amp;gt;,\u0026amp;lt;node4\u0026amp;gt;\u0026amp;#34; 做完这一步之后，访问 curl http://\u0026amp;lt;node4\u0026amp;gt;:9615/health/check 状态显示应当是健康。\n1.2 缩容 registry-integration 假设集群目前有3台机器 node1/node2/node3，需要缩容 node3。\n1.2.1 平滑缩容 操作步骤：\n第一步. 调用 changePeer 移除节点\n对 node1/node2 的任意一台，执行“修改节点列表”的运维命令，将集群列表由“node1/node2/node3”改为“node1/node2”，即把node3移除出地址列表：\ncurl -X POST \u0026amp;#34;http://\u0026amp;lt;node1\u0026amp;gt;:9615/manage/changePeer\u0026amp;#34; -d \u0026amp;#34;ipAddressList=\u0026amp;lt;node1\u0026amp;gt;,\u0026amp;lt;node2\u0026amp;gt;\u0026amp;#34; 做完这一步之后，访问 curl http://\u0026amp;lt;node3\u0026amp;gt;:9615/health/check 状态显示应当是不健康的，因为 node3 已经被踢出了集群。\n**第二步.关闭 node3 **\n这一步可选，因为 node3 已经被移除集群了，所以即便 node3 还在运行，也对原集群不影响。\n1.2.2 宕机处理 假设 node3 已经宕机，也需要将 node3 移除出集群\n操作步骤：\n第一步. 调用 changePeer 移除节点\n对 node1/node2 的任意一台，执行“修改节点列表”的运维命令，将集群列表由“node1/node2/node3”改为“node1/node2”，即把 node3 移除出地址列表：\ncurl -X POST \u0026amp;#34;http://\u0026amp;lt;node1\u0026amp;gt;:9615/manage/changePeer\u0026amp;#34; -d \u0026amp;#34;ipAddressList=\u0026amp;lt;node1\u0026amp;gt;,\u0026amp;lt;node2\u0026amp;gt;\u0026amp;#34; 2. 独立部署模式 2.1 扩容 registry-meta 假设目前已经部署了3台 registry-meta ，分别是 metaNode1/metaNode2/metaNode3，扩容的新节点是 metaNode4.\n操作步骤：\n第一步. 部署新的 registry-meta 节点\n首先参考部署文档，将 registry-meta.tgz 在新节点 metaNode4 上部署起来，值得注意的是，metaNode4 需要将 nodes.metaNode 配置项指定为4台机器的地址列表：\nnodes.metaNode=DefaultDataCenter:\u0026amp;lt;metaNode1\u0026amp;gt;,\u0026amp;lt;metaNode2\u0026amp;gt;,\u0026amp;lt;metaNode3\u0026amp;gt;,\u0026amp;lt;metaNode4\u0026amp;gt; 在这一步中，metaNode4 启动完成后，访问 curl http://localhost:9615/health/check 状态显示是不健康，因为 metaNode4 尚未加入集群，要加入集群，需要做第二步。\n第二步. 调用 changePeer 使新节点加入集群\n对已经存在的 metaNode1/metaNode2/metaNode3 的任意一台，执行“修改节点列表”的运维命令，将原有由 metaNode1/metaNode2/metaNode3 构成的集群，改为 metaNode1/metaNode2/metaNode3/metaNode4 集群：\ncurl -X POST \u0026amp;#34;http://\u0026amp;lt;metaNode1\u0026amp;gt;:9615/manage/changePeer\u0026amp;#34; -d \u0026amp;#34;ipAddressList=\u0026amp;lt;metaNode1\u0026amp;gt;,\u0026amp;lt;metaNode2\u0026amp;gt;,\u0026amp;lt;metaNode3\u0026amp;gt;,\u0026amp;lt;metaNode4\u0026amp;gt;\u0026amp;#34; 做完这一步之后，访问 curl http://localhost:9615/health/check 状态显示应当是健康。\n2.2 缩容 registry-meta 假设集群目前有3台机器 metaNode1/metaNode2/metaNode3，需要缩容 metaNode3。\n2.2.1 平滑缩容 操作步骤：\n第一步. 调用 changePeer 移除节点\n对 metaNode1/metaNode2 的任意一台，执行“修改节点列表”的运维命令，将集群列表由“metaNode1/metaNode2/metaNode3”改为“metaNode1/metaNode2”，即把 metaNode3 移除出地址列表：\ncurl -X POST \u0026amp;#34;http://\u0026amp;lt;metaNode1\u0026amp;gt;:9615/manage/changePeer\u0026amp;#34; -d \u0026amp;#34;ipAddressList=\u0026amp;lt;metaNode1\u0026amp;gt;,\u0026amp;lt;metaNode2\u0026amp;gt;\u0026amp;#34; 做完这一步之后，访问 curl http://\u0026amp;lt;metaNode3\u0026amp;gt;:9615/health/check 状态显示应当是不健康的，因为metaNode3已经被踢出了集群。\n第二步. 关闭 metaNode3\n这一步可选，因为 metaNode3 已经被移除集群了，所以即便 metaNode3 还在运行，也对原集群不影响。\n2.2.2 …","date":-62135596800,"description":"","dir":"projects/sofa-registry/scale/","fuzzywordcount":1700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"57de6dc4da1292063ff25ecea9ffbd08","permalink":"/projects/sofa-registry/scale/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/projects/sofa-registry/scale/","summary":"1. 集成部署模式 1.1 扩容 registry-integration 假设目前已经部署了 3 台 registry-integration，分别是 node1/node2/node3，扩容的新节点","tags":null,"title":"扩容与缩容","type":"projects","url":"/projects/sofa-registry/scale/","wordcount":1695},{"author":null,"categories":null,"content":"自定义引擎各个阶段 可以在测试脚本中或者基类中重写 ActsTestBase 提供的 API。\n 重写 prepare，execute，check，clear 等。可以通过在 super.prepare() 之前或者之后进行某些操作。 重写 process 方法，在 super.process() 之前或之后进行操作。可将整个脚本重新编排，例如在现有的清理 -\u0026amp;gt; 准备 -\u0026amp;gt; 执行 -\u0026amp;gt; 校验流程中增加一些个性化的步骤。 重写 beforeActsTest、afterActsTest，可以在每一个用例运行前后做一些个性化的操作，如准备上下文、缓存刷新等。  参数化 在结果期望和数据库期望中可以使用 $变量名 来标识某个值是变量，测试脚本中可以把值设置进去； 支持范围：入参、返回结果、数据库表字段，支持类型：目前仅支持 String 的参数化。\n使用方法：\n（1）界面以 $ 开头定义变量\n（2）代码中给变量赋值\n@Override public void beforeActsTest(ActsRuntimeContext actsRuntimeContext) { actsRuntimeContext.paramMap.put(\u0026amp;#34;roleId\u0026amp;#34;, \u0026amp;#34;123\u0026amp;#34;); actsRuntimeContext.refreshDataParam(); } 在写 DB 数据期望的时候，也可以通过 = 符号来进行赋值，表示这个值来自于查询结果，后面的表就可以使用这个变量作为值。\n假设接口会向 2 张表插入数据。\n   id_A value_A     123 abc       id_B value_B     abc efg    查询的时候要先通过接口返回的 A 表的 id_A 查到 value_A, 然后把 value_A 作为 B 表的查询条件，在插件上面可以这样写：\n   字段 flag 值     id_A C $param1   value_A Y =param2       字段 flag 值     id_B C $param2   value_B Y efg    上面操作说明：\n =param2 和 $param2 的操作，表示框架会先从 A 表查出 value_A 然后 select from B where id_B = value_A，进而得到全部 B 表的属性值； $param1 表示可以在代码中对 id_A 赋值，代码形如：  actsRuntimeContext.paramMap.put(\u0026amp;#34;param1\u0026amp;#34;,\u0026amp;#34;123\u0026amp;#34;); 表示对变量 param1 赋值 123，上述代码可以写到脚本的 beforeActsTest 里面，这样在查询 A 表之前，框架就会将 123 赋值给 id_A。\n参数组件化 目前仅支持 String 的组件化\n如果属性是需要动态生成的字符串，例如某些 ID，可以通过 @ 符号来调用一个组件生成这个属性，组件要放在跟 test 同级的 component 包下，即：com.corpname.appname.acts.component (这里appname是系统名，corpname是公司名，如alipay)。\npublic class MyComponent { @TestComponent(id = \u0026amp;#34;test\u0026amp;#34;) public String test(String param) { return param+\u0026amp;#34;123\u0026amp;#34;; } } 并通过 acts-config.properties 配置指明参数化组件使其生效，多个组件使用英文逗号 , 分隔，末尾注意不必要的空格。\nparam_components=IdGenerateComponent,NoGenerateComponent 如上图 alis_value 值为 @test?param=123 则在用例运行时会自动替换 alis_value 的取值。\n组件的 ID 要保证唯一，否则默认调用第一个，如果声明了一个无参组件方法，调用方式为 @test 即可，同时支持组件化参数通过变量传入：@test?param=$id，实际执行时会替换 $id 的值为实际值。\n脚本中也可以通过代码调用：\nActsComponentUtil.run(\u0026amp;#34;@test?param=123\u0026amp;#34;); 自定义组件多个参数的场景使用 \u0026amp;amp; 分割参数，如 @test?param1=xxx\u0026amp;amp;param2=yyy\nDB 工具类 1. 指定数据源进行 DB 表访问 框架 ActsDBUtils 中提供了 DB 的指定数据源访问，用于个性化 DB 操作。例如某张表的某条纪录不是准备数据也不是校验数据，但是需要在运行后删掉或更新，此时就需要用到该工具操作 DB 数据。\n使用前配置\n使用指定数据源方式需要在 acts-config.properties 文件中首先将要指定的数据源进行配置，配置例子如下：\ndatasource_bean_name_exampleDataSource=com.alipay.example.dal;exampleDataSource #整体配置的格式为：datasource_bean_name_xxx(数据源名字)=yyy(数据源所在 Module);xxx(数据源名字) 指定数据源方法\nActsDBUtils 工具类中指定数据源方法说明：\npublic static int getUpdateResultMap(String sql,String tableName,String dbConfigKey); 该方法用于指定数据源进行表的增、删和改的操作。sql 为标准 sql 语句，tableName 为逻辑表名，dbConfigKey 为该 表所在的逻辑数据源配置，与 acts-config.properties 配置的 xxx（数据源名字）相同。\npublic static List\u0026amp;lt;Map\u0026amp;lt;String, Object\u0026amp;gt;\u0026amp;gt; getQueryResultMap(String sql, String tableName,String dbConfigKey); 该方法用于指定数据源进行表的查询操作，以上两个方法都是原子化的 DB 表的操作，如果有其他的 DB 需求可以在上面进行 封装。\n2. 不指定数据源进行 DB 表访问 该方式下 ACTS 框架默认根据表名搜索数据源，工具方法的使用步骤如下：\n使用前配置\ndatasource_bundle_name=com.alipay.example.common.dal ds_exampleDataSource=table1,tabal2 #整体配置的格式为 #datasource_bundle_name=数据源所在模块名 #ds_数据源名字=该数据源下的逻辑表名 不指定数据源方法\npublic static int getUpdateResultMap(String sql, String tableName);  …","date":-62135596800,"description":"","dir":"projects/sofa-acts/usage-api/","fuzzywordcount":2000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"ce7e264713a6f7a3f0672e2432489f59","permalink":"/projects/sofa-acts/usage-api/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/projects/sofa-acts/usage-api/","summary":"自定义引擎各个阶段 可以在测试脚本中或者基类中重写 ActsTestBase 提供的 API。 重写 prepare，execute，check，clear 等。可以通过在 super.prepare() 之","tags":null,"title":"扩展功能","type":"projects","url":"/projects/sofa-acts/usage-api/","wordcount":1943},{"author":null,"categories":null,"content":"ExtensionLoader 为了对 SOFARPC 各个环节的都有充足的可扩展性，SOFA-RPC定义了一套十分灵活的扩展机制，所有扩展实现都是平等的。\n这套机制不管是对SOFA-RPC本身的开发者其使用者而言都是非常有用的。SOFA-RPC将其自身抽象为了多个模块，各个模块之间无显示依赖，通过SPI的方式进行交互。\n这套扩展机制抽象了这一SPI的交互方式。如果你读了上面文档讲到的 Filter 和 Router，应该已经有所体会。\n这里讲一下如何使方式进行扩展的。\nSOFARPC 提供了 ExtensionLoader 的能力。\n扩展点设计 SOFARPC 定义了一个注解 @Extensible，该注解标识在接口或者抽象类上，标识该类是一个扩展点。即告诉 SOFARPC 该类是可扩展的，需要寻找该扩展点的实现，同时也定义了寻找实现类的文件名称，是否单例。\n@Documented @Retention(RetentionPolicy.RUNTIME) @Target({ ElementType.TYPE }) public @interface Extensible { /** * 指定自定义扩展文件名称，默认就是全类名 * * @return 自定义扩展文件名称 */ String file() default \u0026amp;#34;\u0026amp;#34;; /** * 扩展类是否使用单例，默认使用 * * @return 是否使用单例 */ boolean singleton() default true; /** * 扩展类是否需要编码，默认不需要 * * @return 是否需要编码 */ boolean coded() default false; } SOFARPC 同时定义了 @Extension 注解，标识该类是一个扩展实现类。也定义了扩展点在文件中寻找扩展实现时使用的名字。\n@Documented @Retention(RetentionPolicy.RUNTIME) @Target({ ElementType.TYPE }) public @interface Extension { /** * 扩展点名字 * * @return 扩展点名字 */ String value(); /** * 扩展点编码，默认不需要，当接口需要编码的时候需要 * * @return 扩展点编码 * @see Extensible#coded() */ byte code() default -1; /** * 优先级排序，默认不需要，大的优先级高 * * @return 排序 */ int order() default 0; /** * 是否覆盖其它低{@link #order()}的同名扩展 * * @return 是否覆盖其它低排序的同名扩展 * @since 5.2.0 */ boolean override() default false; /** * 排斥其它扩展，可以排斥掉其它低{@link #order()}的扩展 * * @return 排斥其它扩展 * @since 5.2.0 */ String[] rejection() default {}; } 新增扩展点 1.定义扩展点。\n@Extensible public interface Person { void getName(); } 2.定义扩展实现\n@Extension(\u0026amp;#34;A\u0026amp;#34;) public class PersonA implements Person{ @Override public void getName() { System.out.println(\u0026amp;#34;li wei\u0026amp;#34;); } } 3.编写扩展描述文件：META-INF/services/sofa-rpc/com.alipay.sofa.rpc.extension.Person。文件内容如下：\nA=com.alipay.sofa.rpc.extension.PersonA 4.加载扩展点，获取到扩展实现类使用。\nPerson person = ExtensionLoaderFactory.getExtensionLoader(Person.class).getExtension(\u0026amp;#34;A\u0026amp;#34;); 已有扩展点 如果想对 SOFARPC 的各个内置扩展点进行功能扩展，可直接实现已有扩展，配置扩展模式文件即可。\n目前已有的扩展点如下：\n   接口名 中文名 备注 内置实现     com.alipay.sofa.rpc.client.Client 客户端  Failover、Failfast   com.alipay.sofa.rpc.client.ConnectionHolder 连接管理器  AllConnect（全部连接）   com.alipay.sofa.rpc.client.AddressHolder 地址管理器  单组、多组   com.alipay.sofa.rpc.client.LoadBalancer 负载均衡  随机、轮询、最少并发、一致性hash、本机优先   com.alipay.sofa.rpc.client.Router 路由器     com.alipay.sofa.rpc.codec.Compressor 压缩  snappy、quicklz   com.alipay.sofa.rpc.codec.Serializer 序列化器  java、hessian、pb   com.alipay.sofa.rpc.filter.Filter 拦截器     com.alipay.sofa.rpc.protocol.Protocol 协议  bolt、dubbo、rest   com.alipay.sofa.rpc.protocol.ProtocolDecoder 协议解码  bolt   com.alipay.sofa.rpc.protocol.ProtocolEncoder 协议编码  bolt   com.alipay.sofa.rpc.protocol.TelnetHandler telnet的响应  version、help、ls   com.alipay.sofa.rpc.proxy.Proxy 代理类  java、javassist   com.alipay.sofa.rpc.registry.Registry 注册中心  zookeeper   com.alipay.sofa.rpc.server.Server 服务端实现  bolt、rest   com.alipay.sofa.rpc.transport.ClientTransport 客户端长连接实现  netty   com.alipay.sofa.rpc.transport.ServerTransport 服务端长连接实现  netty    ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/extension-loader/","fuzzywordcount":1200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"acc5628da3a7ea2df5eb68bd8ec17159","permalink":"/projects/sofa-rpc/extension-loader/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/sofa-rpc/extension-loader/","summary":"ExtensionLoader 为了对 SOFARPC 各个环节的都有充足的可扩展性，SOFA-RPC定义了一套十分灵活的扩展机制，所有扩展实现都是平等的。 这套机制不管是对SOFA-RP","tags":null,"title":"扩展点设计","type":"projects","url":"/projects/sofa-rpc/extension-loader/","wordcount":1131},{"author":null,"categories":null,"content":"SOFARPC 的服务发布和引用的基本配置已经在「编程界面」章节中说明，这里主要介绍服务发布和引用的一些特性。\n同一服务发布多种协议 在 SOFARPC 中，可以将同一个服务发布成多个协议，让调用端可以使用不同的协议调用服务提供方。\n如果使用 Java API，可以按照如下的代码构建多个 ServerConfig，不同的 ServerConfig 设置不同的协议，然后将这些 ServerConfig 设置给 ProviderConfig：\nList\u0026amp;lt;ServerConfig\u0026amp;gt; serverConfigs = new ArrayList\u0026amp;lt;ServerConfig\u0026amp;gt;(); serverConfigs.add(serverConfigA); serverConfigs.add(serverConfigB); providerConfig.setServer(serverConfigs); 如果使用 XML 的方式，直接在 \u0026amp;lt;sofa:service\u0026amp;gt; 标签中增加多个 binding 即可：\n\u0026amp;lt;sofa:service ref=\u0026amp;#34;sampleFacadeImpl\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofa.rpc.bean.SampleFacade\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt/\u0026amp;gt; \u0026amp;lt;sofa:binding.rest/\u0026amp;gt; \u0026amp;lt;sofa:binding.dubbo/\u0026amp;gt; \u0026amp;lt;/sofa:service\u0026amp;gt; 如果使用 Annotation 的方式，在 @SofaService 中增加多个 binding 即可：\n@SofaService( interfaceType = SampleService.class, bindings = { @SofaServiceBinding(bindingType = \u0026amp;#34;rest\u0026amp;#34;), @SofaServiceBinding(bindingType = \u0026amp;#34;bolt\u0026amp;#34;) } ) public class SampleServiceImpl implements SampleService { // ... } 同一服务注册多个注册中心 如果使用 API 的方式，构建多个 RegistryConfig 设置给 ProviderConfig 即可：\nList\u0026amp;lt;RegistryConfig\u0026amp;gt; registryConfigs = new ArrayList\u0026amp;lt;RegistryConfig\u0026amp;gt;(); registryConfigs.add(registryA); registryConfigs.add(registryB); providerConfig.setRegistry(registryConfigs); 如果是使用 XML 的方式\n如果使用 Annotation 的方式\n方法级参数设置 在 Java API 方式中，调用 MethodConfig 对象相应的 set 方法即可设置对应的参数，如下所示：\nMethodConfig methodConfigA = new MethodConfig(); MethodConfig methodConfigB = new MethodConfig(); List\u0026amp;lt;MethodConfig\u0026amp;gt; methodConfigs = new ArrayList\u0026amp;lt;MethodConfig\u0026amp;gt;(); methodConfigs.add(methodConfigA); methodConfigs.add(methodConfigB); providerConfig.setMethods(methodConfigs); //服务端设置 consumerConfig.setMethods(methodConfigs); //客户端设置 使用 XML 的方式，在对应的 binding 里面使用 \u0026amp;lt;sofa:method\u0026amp;gt; 标签即可设置对应的参数：\n\u0026amp;lt;sofa:reference id=\u0026amp;#34;personReferenceBolt\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofa.boot.examples.demo.rpc.bean.PersonService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;sofa:global-attrs timeout=\u0026amp;#34;3000\u0026amp;#34; address-wait-time=\u0026amp;#34;2000\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;!-- 调用超时；地址等待时间。 --\u0026amp;gt; \u0026amp;lt;sofa:route target-url=\u0026amp;#34;127.0.0.1:22000\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;!-- 直连地址 --\u0026amp;gt; \u0026amp;lt;sofa:method name=\u0026amp;#34;sayName\u0026amp;#34; timeout=\u0026amp;#34;3000\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;!-- 方法级别配置 --\u0026amp;gt; \u0026amp;lt;/sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt; \u0026amp;lt;sofa:service ref=\u0026amp;#34;sampleFacadeImpl\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofa.rpc.bean.SampleFacade\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;sofa:global-attrs timeout=\u0026amp;#34;3000\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;sofa:method name=\u0026amp;#34;sayName\u0026amp;#34; timeout=\u0026amp;#34;2000\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;/sofa:service\u0026amp;gt; 目前 Annotation 的方式暂不支持设置方法级别的参数，将在后续版本中支持。\n配置覆盖 SOFARPC 里面的某些配置在服务提供方可以设置，在服务调用方也可以设置，比如调用的超时的 timeout 属性，这些配置的优先级为：\n线程调用级别设置 \u0026amp;raquo; 服务调用方方法级别设置 \u0026amp;raquo; 服务调用方 Reference 级别设置 \u0026amp;raquo; 服务提供方方法级别设置 \u0026amp;raquo; 服务提供方 Service 级别设置\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/publish-and-reference/","fuzzywordcount":700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"6a78b8b84b226eaf1e6d2b1ff1d15fee","permalink":"/projects/sofa-rpc/publish-and-reference/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-rpc/publish-and-reference/","summary":"SOFARPC 的服务发布和引用的基本配置已经在「编程界面」章节中说明，这里主要介绍服务发布和引用的一些特性。 同一服务发布多种协议 在 SOFARPC 中，可以将同一个服务","tags":null,"title":"服务发布与引用","type":"projects","url":"/projects/sofa-rpc/publish-and-reference/","wordcount":607},{"author":null,"categories":null,"content":"自动化 推荐版本: ES 5\n自动初始化库 Lookout 服务器端启动时，会自动检查（默认开启，可关闭）所连接的ES机器(或集群)，检查 Metrics 数据存储的 Index和 Mapping 是否已经建立， 如果未初始化则进行初始化工作。默认初始化并产生索引alias: \u0026amp;ldquo;lookout-active-metrics，lookout-search-metrics\u0026amp;rdquo;。\n 看下 Alias 和 Indices  http://localhost:9200/_cat/aliases lookout-active-metrics metrics-2019.05.30-1 - - - lookout-search-metrics metrics-2019.05.30-1 - - -  看下存储 Mapping：  http://localhost:9200/lookout-active-metrics/_mapping { \u0026amp;quot;metrics-2019.05.30-1\u0026amp;quot;: { \u0026amp;quot;mappings\u0026amp;quot;: { \u0026amp;quot;metrics\u0026amp;quot;: { \u0026amp;quot;properties\u0026amp;quot;: { \u0026amp;quot;id\u0026amp;quot;: { \u0026amp;quot;type\u0026amp;quot;: \u0026amp;quot;keyword\u0026amp;quot; }, \u0026amp;quot;tags\u0026amp;quot;: { \u0026amp;quot;type\u0026amp;quot;: \u0026amp;quot;keyword\u0026amp;quot; }, \u0026amp;quot;time\u0026amp;quot;: { \u0026amp;quot;type\u0026amp;quot;: \u0026amp;quot;date\u0026amp;quot; }, \u0026amp;quot;value\u0026amp;quot;: { \u0026amp;quot;type\u0026amp;quot;: \u0026amp;quot;float\u0026amp;quot; } } } } } } 自动运维   自动 Indices Rollover\n 如果超过1天，则切换新索引 如果单个索引的 docs 数目超过: 100000000，则切换新索引；    自动删除过期 Indices\n  默认最多只保留 7 天的数据，过期的 Index 会自动检查并被删除；\n","date":-62135596800,"description":"","dir":"projects/sofa-lookout/use-guide-es/","fuzzywordcount":400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"016a397aa24e885b5aaa32cf1cac3f35","permalink":"/projects/sofa-lookout/use-guide-es/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-lookout/use-guide-es/","summary":"自动化 推荐版本: ES 5 自动初始化库 Lookout 服务器端启动时，会自动检查（默认开启，可关闭）所连接的ES机器(或集群)，检查 Metrics 数据存储的 Index和 Mapping 是","tags":null,"title":"服务器端 ES 存储使用指南","type":"projects","url":"/projects/sofa-lookout/use-guide-es/","wordcount":315},{"author":null,"categories":null,"content":"由于 SOFALookout Metrics Server 兼容 Prometheus API,所以 Grafana 集成 Lookout 很简单，只需要选择 Prometheus 作为数据源协议即可 （注意 Lookout Server 的默认查询端口也是: 9090）。\n下图展示 Grafana 新增数据源配置:\n使用 PromQL 查询展示数据:\n","date":-62135596800,"description":"","dir":"projects/sofa-lookout/use-guide-grafana/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"45b8a5084ac2a151af28ff11413b13cb","permalink":"/projects/sofa-lookout/use-guide-grafana/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-lookout/use-guide-grafana/","summary":"由于 SOFALookout Metrics Server 兼容 Prometheus API,所以 Grafana 集成 Lookout 很简单，只需要选择 Prometheus 作为数据源协议即可 （注意 Lookout Server 的默认查询端口也是: 9090）。 下图展示 Grafana 新增数据源配置","tags":null,"title":"服务器端 Grafana 使用指南","type":"projects","url":"/projects/sofa-lookout/use-guide-grafana/","wordcount":81},{"author":null,"categories":null,"content":"如果需要扩展支持适配一个新的数据存储，可能需要下面的步骤:\n1.写入适配   需要在 gateway/metrics/exporter/ 下面添加新的 exporter;\n参考已有的 \u0026amp;ldquo;gateway/metrics/exporter/elasticsearch\u0026amp;rdquo; 模块；\n  提供个新存储的 MetricExporter\n功能是写入数据到存储中，参考\u0026amp;quot;com.alipay.sofa.lookout.gateway.metrics.exporter.es.ESMetricExporter\u0026amp;quot;，提供个新存储的 MetricExporter；\n  提供个该模块的spring配置类\n参考 \u0026amp;ldquo;com.alipay.sofa.lookout.gateway.metrics.exporter.es.spring.bean.config.EsExporterConfiguration\u0026amp;rdquo;，它包括 ESProperties 的配置描述映射。尤其重要的是带有注解 @ConditionalOnExporterComponent方便该功能开关；\n  在 \u0026amp;ldquo;com.alipay.sofa.lookout.gateway.metrics.starter.MetricPipelineConfiguration\u0026amp;rdquo; 中 @import 上述存储spring配置类；\n  2.查询数据适配   需要在 server/metrics 目录下，添加新 storage 扩展；\n参考 “server/metrics/storage-ext-es” 模块，比如新增“storage-ext-**”\n  提供个新的存储 Storage 实现；\n参考已有 “com.alipay.sofa.lookout.server.storage.ext.es.ElasticSearchStorage”，实现Storage接口。这里也需要ES实现对应的 “QueryStmt”，”LabelValuesStmt“，”LabelNamesStmt“.\n  提供个该模块的spring配置类\n参考\u0026amp;quot;com.alipay.sofa.lookout.server.storage.ext.es.spring.bean.config.ElasticSearchServerConfig\u0026amp;quot;,提供 Storage的实例。 另外参考支持”@ConditionalOnProperty“的功能开关配置；\n  在 \u0026amp;ldquo;com.alipay.sofa.lookout.server.starter.ServerAutoConfiguration\u0026amp;rdquo; 中 @import 上述存储spring配置类；\n  3.最后贡献建议  提issue说明需求，并可以介绍下方案； 保证测试覆盖； fork 代码，编译通过后，提交 PR；  ","date":-62135596800,"description":"","dir":"projects/sofa-lookout/use-guide-storage-ext/","fuzzywordcount":900,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"b990dad82668bc22c24d4ad0468f0535","permalink":"/projects/sofa-lookout/use-guide-storage-ext/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-lookout/use-guide-storage-ext/","summary":"如果需要扩展支持适配一个新的数据存储，可能需要下面的步骤: 1.写入适配 需要在 gateway/metrics/exporter/ 下面添加新的 exporter; 参考已有的 \u0026ldquo;gateway/metrics/exporter/elasticsearch\u0026rdquo; 模块； 提供个新存储的 MetricExporter 功能是写入数据","tags":null,"title":"服务器端 Metrics 存储扩展机制","type":"projects","url":"/projects/sofa-lookout/use-guide-storage-ext/","wordcount":860},{"author":null,"categories":null,"content":"1. Tag选择器的“in”筛选 =~| 将tag符合表达式的提供的值选择出来，类似于SQL中的in语义\n示例\n将app为 foo 或 foo2的应用时序数据查询出来\njvm.memory.heap.used{app=~|\u0026amp;#34;foo|foo2\u0026amp;#34;,instance_id=\u0026amp;#34;xxx\u0026amp;#34;} 2. Tag选择器的\u0026amp;quot;not in\u0026amp;quot;筛选 !~| 将tag不符合表达式提供的值选择出来,类似SQL中的not in语义\n示例\njvm.memory.heap.used{app!~|\u0026amp;#34;foo|foo2\u0026amp;#34;,instance_id=\u0026amp;#34;xxx\u0026amp;#34;} 3. Increase2函数 （类似Increase），适用于Promethues的Counter型指标 increase 会根据根据查询步长，做个时间点上的函数估值（根据既有增长斜率）。所以可能是非整型。 如果你就想返回真实时间点的整数差值，不愿估算目标时刻的近视值。那么推荐使用 Increase2。\n需要组合聚合函数时，记住“Rate then sum, never sum then rate”（这里说的rate 与 increase 函数类似）\nsum by (job)(Increase2(http_requests_total{job=\u0026amp;#34;node\u0026amp;#34;}[5m])) # This is okay 4. \u0026amp;ldquo;histogram_quantile\u0026amp;rdquo; 与(Lookout)自定义 \u0026amp;ldquo;zhistogram_quantile\u0026amp;rdquo; histogram_quantile ，是对使用prometheus client得到的 metrics buckets进行分析；\nzhistogram_quantile，是对使用 lookout sdk的得到的 metrics buckets 进行分析;\n5. Promethues 一些最佳实践总结 rate，increase 函数用于计算指标的速率，在使用时要根据指标数据的采集或上报时间间隔来进行over_time时间的控制。比如metrics数据是1分钟上报一次,如果想获取某个metric指标的1分钟的速率，应该按如下方式写promql语句\nrate(http_requestl{token=\u0026amp;#34;mobile\u0026amp;#34;}[2m] step 表示最终显示的采样（步长），如果和range （比如2m）保持一致，表示原样输出，不采样。 如果想进行采样，step \u0026amp;gt; range 就行了！ 所以总的来说，step \u0026amp;gt;= range.\nrange, 从实际使角度，推荐 range 值要尽量明显大于数据实际的上报时间间隔才有意义，比如上报单位是30秒，那range尽量\u0026amp;gt;= 1分钟。\n","date":-62135596800,"description":"","dir":"projects/sofa-lookout/use-guide-promql-feature-enhancement/","fuzzywordcount":700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"3bd5cd1f9d3ce3f9ba5b503ef0ba9da1","permalink":"/projects/sofa-lookout/use-guide-promql-feature-enhancement/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-lookout/use-guide-promql-feature-enhancement/","summary":"1. Tag选择器的“in”筛选 =~| 将tag符合表达式的提供的值选择出来，类似于SQL中的in语义 示例 将app为 foo 或 foo2的应用时序数据查询出来","tags":null,"title":"服务器端 PromQL 语法特性增强","type":"projects","url":"/projects/sofa-lookout/use-guide-promql-feature-enhancement/","wordcount":689},{"author":null,"categories":null,"content":"使用 Lookout sdk是推荐方式，当然 Lookout gateway 还支持其他协议上报。（但由于属于非标接入，细节可联系我们）\n注意如果使用 非lookout sdk ，自己一定注意控制客户端metrics数量！ [Don\u0026amp;rsquo;t over use labels(tags)]\n1.Promethues Push协议写入支持  Lookout-gateway这里扮演的是一个 prometheus-pushgateway 角色：  echo \u0026amp;quot;some_metric{k1=\u0026amp;quot;v1\u0026amp;quot;} 3.14\u0026amp;quot; | curl --data-binary \\ @- http://localhost:7200/prom/metrics/job/{job}/app/{app}/step/{step}   区别在于：\u0026amp;quot;http://localhost:7200/prom/\u0026amp;quot;，端口为7200，加了级主路径为/prom.\n  【必选】URL路径变量 {app} {job} 和{step}，必须要指定哦。step 单位秒，表示您定时上报的时间间隔（假如10s 上报一次数据，那么 step=10）\n  【可选】如果和lookout gateway间有网络代理，建议URL 里也附带上客户端真实 ip （如 \u0026amp;ldquo;/ip/{ip}\u0026amp;quot;）。\n  上报格式样式: 【 http_requests_total{method=\u0026amp;ldquo;post\u0026amp;rdquo;,code=\u0026amp;ldquo;200\u0026amp;rdquo;} 1027 】，多个以换行符【\u0026#39;\\n\u0026#39;】分割；\n  更多细节可以参考：prometheus-pushgateway ，你可以选择官方对应编程语言的SDKs\n  2. Lookout 自有协议写入支持 默认的收集服务和数据协议标准(即Lookout自有的协议支持标准)\n localhost:7200/lookout/metrics/app/{app}/step/{step}  curl -H \u0026amp;quot;Content-type:text/plain\u0026amp;quot; -X POST -d \u0026#39;xx\u0026#39; \\ localhost:7200/lookout/metrics/app/{app}/step/{step}  请求体是一种批量复合形式。内容是多条 metrics 数据以 \u0026amp;ldquo;\\t\u0026amp;rdquo; 进行连接；  {\u0026amp;quot;time\u0026amp;quot;:\u0026amp;quot;1970-01-01T08:00:00+08:00\u0026amp;quot;,\u0026amp;quot;tags\u0026amp;quot;:{\u0026amp;quot;k1\u0026amp;quot;:\u0026amp;quot;v1\u0026amp;quot;},\u0026amp;quot;m_name\u0026amp;quot;:{\u0026amp;quot;count\u0026amp;quot;:0,\u0026amp;quot;rate\u0026amp;quot;:0.0}} \\t{\u0026amp;quot;time\u0026amp;quot;:\u0026amp;quot;1970-01-01T08:00:00+08:00\u0026amp;quot;,\u0026amp;quot;tags\u0026amp;quot;:{\u0026amp;quot;k1\u0026amp;quot;:\u0026amp;quot;v1\u0026amp;quot;},\u0026amp;quot;m_name\u0026amp;quot;:{\u0026amp;quot;value\u0026amp;quot;:99.0}} \\t{\u0026amp;quot;time\u0026amp;quot;:\u0026amp;quot;1970-01-01T08:00:00+08:00\u0026amp;quot;,\u0026amp;quot;tags\u0026amp;quot;:{\u0026amp;quot;k1\u0026amp;quot;:\u0026amp;quot;v1\u0026amp;quot;},\u0026amp;quot;m_name\u0026amp;quot;:{\u0026amp;quot;elapPerExec\u0026amp;quot;:0.0,\u0026amp;quot;totalTime\u0026amp;quot;:0.0,\u0026amp;quot;max\u0026amp;quot;:0.0}} \\t{\u0026amp;quot;time\u0026amp;quot;:\u0026amp;quot;1970-01-01T08:00:00+08:00\u0026amp;quot;,\u0026amp;quot;tags\u0026amp;quot;:{\u0026amp;quot;k1\u0026amp;quot;:\u0026amp;quot;v1\u0026amp;quot;},\u0026amp;quot;m_name\u0026amp;quot;:{\u0026amp;quot;totalAmount\u0026amp;quot;:0.0,\u0026amp;quot;rate\u0026amp;quot;:0.0,\u0026amp;quot;max\u0026amp;quot;:0}} 上面内容中组成部分分别是：counter型,gauge型,Timer型\n 其中单条数据结构  { \u0026amp;quot;time\u0026amp;quot;: \u0026amp;quot;1970-01-01T08:00:00+08:00\u0026amp;quot;, \u0026amp;quot;tags\u0026amp;quot;: { \u0026amp;quot;k1\u0026amp;quot;: \u0026amp;quot;v1\u0026amp;quot; }, \u0026amp;quot;m_name\u0026amp;quot;: { \u0026amp;quot;count\u0026amp;quot;: 0, \u0026amp;quot;rate\u0026amp;quot;: 0 } }   tag 的 value 需要转义;\n  如果内容由进行了 snappy 压缩，需添加请求头 \u0026amp;ldquo;Content-Encoding:snappy\u0026amp;rdquo;,且\u0026amp;quot;Content-type: application/octet-stream\u0026amp;rdquo;;\n  3.OPEN TSDB 协议写入支持  请求demo  curl -X POST \\ http://localhost:7200/opentsdb/api/put \\ -H \u0026#39;Content-Type: application/json\u0026#39; \\ -H \u0026#39;step: 10000\u0026#39; \\ -H \u0026#39;app: xx\u0026#39; \\ -H \u0026#39;X-Lookout-Token: xx\u0026#39; \\ -d \u0026#39;[{ \u0026amp;quot;metric\u0026amp;quot;: \u0026amp;quot;xzc.cpu\u0026amp;quot;, \u0026amp;quot;timestamp\u0026amp;quot;: 1530624430, \u0026amp;quot;value\u0026amp;quot;: 30, \u0026amp;quot;tags\u0026amp;quot;: { \u0026amp;quot;host\u0026amp;quot;: \u0026amp;quot;web02\u0026amp;quot;, \u0026amp;quot;dc\u0026amp;quot;: \u0026amp;quot;lga\u0026amp;quot; } }]\u0026#39;   注意timestamp的单位是秒(而且尽量是当前时间附近哦，否则不太好查询)\n  post的内容可以是一个json对象或json数组(批量模式)\n  更多细节可以参考 OpenTSDB的 /api/put 接口 http://opentsdb.net/docs/build/html/api_http/put.html\n  4.Metricbeat 写入协议支持 （1）.metricbeat的配置 配置文件 metricbeat.yml\noutput.elasticsearch: hosts: [\u0026#39;10.15.232.67:7200\u0026#39;] path: /beat host 是 lookout-gateway 的地址,端口是7200. 另外加了级主路径/beat;\n(2).为了符合metrics2.0标准，gateway会对数据进行转换 这块后续去时序库查询，你需要关注：\n FROM:  { \u0026amp;quot;@timestamp\u0026amp;quot;: \u0026amp;quot;2018-03-29T08:27:21.200Z\u0026amp;quot;, …","date":-62135596800,"description":"","dir":"projects/sofa-lookout/use-guide-other-metrics-protocol-support/","fuzzywordcount":1000,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"df745d82f3f681cfd94b8187934a8477","permalink":"/projects/sofa-lookout/use-guide-other-metrics-protocol-support/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-lookout/use-guide-other-metrics-protocol-support/","summary":"使用 Lookout sdk是推荐方式，当然 Lookout gateway 还支持其他协议上报。（但由于属于非标接入，细节可联系我们） 注意如果使用 非lookout sdk ，自己一定注意控制客","tags":null,"title":"服务器端常见数据采集协议支持","type":"projects","url":"/projects/sofa-lookout/use-guide-other-metrics-protocol-support/","wordcount":997},{"author":null,"categories":null,"content":"SOFADashboard 服务治理主要是对 SOFARpc 的服务进行管理。 目前已经支持基于 ZK 和 SofaRegistry 两个注册中心。\n功能展示 1、基于服务维度  服务列表   服务提供者详情：  2、基于应用维度  应用列表   应用服务详情  ","date":-62135596800,"description":"","dir":"projects/sofa-dashboard/governance/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"e547baf489fd5d125be9e67a366854b6","permalink":"/projects/sofa-dashboard/governance/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-dashboard/governance/","summary":"SOFADashboard 服务治理主要是对 SOFARpc 的服务进行管理。 目前已经支持基于 ZK 和 SofaRegistry 两个注册中心。 功能展示 1、基于服务维度 服务列表 服务提供者详情： 2、基于应用维度 应用","tags":null,"title":"服务治理","type":"projects","url":"/projects/sofa-dashboard/governance/","wordcount":78},{"author":null,"categories":null,"content":"部署模式 SOFARegistry 支持两种部署模式，分别是集成部署模式及独立部署模式，本文将介绍最简单的单节点集成部署模式，更多更详细的部署模式介绍可以查看 部署文档。\n部署步骤 1. 下载源码或者安装包 下载源码方式 git clone https://github.com/sofastack/sofa-registry.git cd sofa-registry mvn clean package -DskipTests cp server/distribution/integration/target/registry-integration.tgz \u0026amp;lt;somewhere\u0026amp;gt; cd \u0026amp;lt;somewhere\u0026amp;gt; \u0026amp;amp;\u0026amp;amp; mkdir registry-integration tar -zxvf registry-integration.tgz -C registry-integration cd registry-integration 下载安装包方式 您可以从 release 页面 下载最新的 registry-integration-$version.tar.gz 包。\nmkdir registry-integration tar -zxvf registry-integration-$version.tar.gz -C registry-integration cd registry-integration 2. 启动 registry-integration Linux/Unix/Mac 启动命令：sh bin/startup.sh\nWindows 双击 bin 目录下的 startup.bat 运行文件。 3. 确认运行状态 可访问三个角色提供的健康监测 API，或查看日志 logs/registry-startup.log：\n# 查看meta角色的健康检测接口： $ curl http://localhost:9615/health/check {\u0026amp;#34;success\u0026amp;#34;:true,\u0026amp;#34;message\u0026amp;#34;:\u0026amp;#34;... raftStatus:Leader\u0026amp;#34;} # 查看data角色的健康检测接口： $ curl http://localhost:9622/health/check {\u0026amp;#34;success\u0026amp;#34;:true,\u0026amp;#34;message\u0026amp;#34;:\u0026amp;#34;... status:WORKING\u0026amp;#34;} # 查看session角色的健康检测接口： $ curl http://localhost:9603/health/check {\u0026amp;#34;success\u0026amp;#34;:true,\u0026amp;#34;message\u0026amp;#34;:\u0026amp;#34;...\u0026amp;#34;} ","date":-62135596800,"description":"","dir":"projects/sofa-registry/server-quick-start/","fuzzywordcount":300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"b620900b56ba04f4668838846a97698a","permalink":"/projects/sofa-registry/server-quick-start/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-registry/server-quick-start/","summary":"部署模式 SOFARegistry 支持两种部署模式，分别是集成部署模式及独立部署模式，本文将介绍最简单的单节点集成部署模式，更多更详细的部署模式介绍可以查看 部署文档","tags":null,"title":"服务端部署","type":"projects","url":"/projects/sofa-registry/server-quick-start/","wordcount":297},{"author":null,"categories":null,"content":"如图: Node Raft 分组中的一个节点，连接封装底层的所有服务，用户看到的主要服务接口，特别是 apply(task) 用于向 raft group 组成的复制状态机集群提交新任务应用到业务状态机。\n存储  Log 存储，记录 raft 配置变更和用户提交任务的日志，将从 Leader 复制到其他节点上。LogStorage 是存储实现， LogManager 负责对底层存储的调用，对调用做缓存、批量提交、必要的检查和优化。 Meta 存储，元信息存储,记录 raft 实现的内部状态，比如当前 term,、投票给哪个节点等信息。 Snapshot 存储,，用于存放用户的状态机 snapshot 及元信息，可选。 SnapshotStorage 用于 snapshot 存储实现， SnapshotExecutor 用于 snapshot 实际存储、远程安装、复制的管理。  状态机  StateMachine： 用户核心逻辑的实现,核心是 onApply(Iterator) 方法，应用通过 Node#apply(task) 提交的日志到业务状态机。 FSMCaller： 封装对业务 StateMachine 的状态转换的调用以及日志的写入等，一个有限状态机的实现，做必要的检查、请求合并提交和并发处理等。  复制  Replicator： 用于 leader 向 follower 复制日志，也就是 raft 中的 appendEntries 调用，包括心跳存活检查等。 ReplicatorGroup: 用于单个 RAFT Group 管理所有的 replicator，必要的权限检查和派发。  RPC RPC 模块用于节点之间的网络通讯:\n RPC Server: 内置于 Node 内的 RPC 服务器，接收其他节点或者客户端发过来的请求，转交给对应服务处理。 RPC Client: 用于向其他节点发起请求，例如投票、复制日志、心跳等。  ","date":-62135596800,"description":"","dir":"projects/sofa-jraft/engine-architecture/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"d2cc9de133aed20695229d0cde5b6ff9","permalink":"/projects/sofa-jraft/engine-architecture/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-jraft/engine-architecture/","summary":"如图: Node Raft 分组中的一个节点，连接封装底层的所有服务，用户看到的主要服务接口，特别是 apply(task) 用于向 raft group 组成的复制状态机集群提交新任务应用到业务状态机","tags":null,"title":"核心引擎设计","type":"projects","url":"/projects/sofa-jraft/engine-architecture/","wordcount":527},{"author":null,"categories":null,"content":"MOSN 主要划分为如下模块，包括了网络代理具备的基础能力，也包含了 xDS 等云原生能力。\nxDS（UDPA）支持 MOSN 支持云原生统一数据面 API（UDPA），支持全动态配置更新。\nxDS 是 Envoy 创建的一个关键概念，它是一类发现服务的统称，其包括如下几类：\n CDS：Cluster Discovery Service EDS：Endpoint Discovery Service SDS：Secret Discovery Service RDS：Route Discovery Service LDS：Listener Discovery Service  正是通过对 xDS 的请求来动态更新 Envoy 配置，另外还有个 ADS（Aggregated Discovery Service）通过聚合的方式解决以上 xDS 的更新顺序问题。\n业务支持 MOSN 作为底层的高性能安全网络代理，支撑了 RPC、消息（Messaging）、网关（Gateway）等业务场景。\nIO 模型 MOSN 支持以下两种 IO 模型：\n  Golang 经典 netpoll 模型：goroutine-per-connection，适用于在连接数不是瓶颈的情况。\n  RawEpoll 模型：也就是 Reactor 模式，I/O 多路复用（I/O multiplexing）+ 非阻塞 I/O（non-blocking I/O）的模式。对于接入层和网关有大量长链接的场景，更加适合于 RawEpoll 模型。\n  netpoll 模型 MOSN 的 netpoll 模型如上图所示，协程数量与链接数量成正比，大量链接场景下，协程数量过多，存在以下开销：\n Stack 内存开销 Read buffer 开销 Runtime 调度开销  RawEpoll 模型 RawEpoll 模型如上图所示，使用 epoll 感知到可读事件之后，再从协程池中为其分配协程进行处理，步骤如下：\n 链接建立后，向 Epoll 注册 oneshot 可读事件监听；并且此时不允许有协程调用 conn.read，避免与 runtime netpoll 冲突。 可读事件到达，从 goroutine pool 挑选一个协程进行读事件处理；由于使用的是 oneshot 模式，该 fd 后续可读事件不会再触发。 请求处理过程中，协程调度与经典 netpoll 模式一致。 请求处理完成，将协程归还给协程池；同时将 fd 重现添加到 RawEpoll 中。  协程模型 MOSN 的协程模型如下图所示。\n 一条 TCP 连接对应一个 Read 协程，执行收包、协议解析； 一个请求对应一个 worker 协程，执行业务处理，proxy 和 Write 逻辑；  常规模型一个 TCP 连接将有 Read/Write 两个协程，我们取消了单独的 Write 协程，让 workerpool 工作协程代替，减少了调度延迟和内存占用。\n能力扩展 协议扩展 MOSN 通过使用统一的编解码引擎以及编/解码器核心接口，提供协议的 plugin 机制，包括支持：\n SOFARPC HTTP1.x/HTTP2.0 Dubbo  NetworkFilter 扩展 MOSN 通过提供 network filter 注册机制以及统一的 packet read/write filter 接口，实现了 Network filter 扩展机制，当前支持：\n TCP proxy Fault injection  StreamFilter 扩展 MOSN 通过提供 stream filter 注册机制以及统一的 stream send/receive filter 接口，实现了 Stream filter 扩展机制，包括支持：\n 流量镜像 RBAC 鉴权  TLS 安全链路 通过测试，原生的 Go 的 TLS 经过了大量的汇编优化，在性能上是 Nginx（OpenSSL）的80%，Boring 版本的 Go（使用 cgo 调用 BoringSSL）因为 cgo 的性能问题， 并不占优势，所以我们最后选择使用原生 Go 的 TLS，相信 Go Runtime 团队后续会有更多的优化，我们也会有一些优化计划。\nGo vs Nginx 测试结果如下图所示：\n Go 在 RSA 上没有太多优化，go-boring（CGO）的能力是 Go 的两倍。 p256 在 Go 上有汇编优化，ECDSA 优于go-boring。 在 AES-GCM 对称加密上，Go 的能力是 go-boring 的 20 倍。 在 SHA、MD 等 HASH 算法也有对应的汇编优化。  为了满足金融场景的安全合规，我们同时也对国产密码进行了开发支持，这个是 Go Runtime 所没有的。虽然目前的性能相比国际标准 AES-GCM 还是有一些差距，大概是 50%，但是我们已经有了后续的一些优化计划，敬请期待。\n支持国密的性能测试结果如下图所示：\n","date":-62135596800,"description":"","dir":"projects/mosn/concept/core-concept/","fuzzywordcount":1400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"5fd84bf5ceb2a4ab800cd0e2db774731","permalink":"/projects/mosn/concept/core-concept/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/mosn/concept/core-concept/","summary":"MOSN 主要划分为如下模块，包括了网络代理具备的基础能力，也包含了 xDS 等云原生能力。 xDS（UDPA）支持 MOSN 支持云原生统一数据面 API（UDPA），","tags":null,"title":"核心概念","type":"projects","url":"/projects/mosn/concept/core-concept/","wordcount":1332},{"author":null,"categories":null,"content":"框架准备 在阅读前，您可以参考快速开始下载并安装 ACTS IDE 和引入 ACTS 框架.\n本部分主要包含编码说明、数据源配置和一键配置说明，以帮助您使用 ACTS 框架。\n编码说明 请确保 ACTS 的编码与系统代码的编码一致，即确定以下的编码保持一致：生成脚本选择的编码、workspace 的编码应该都与应用代码编码保持一致，不一致时会出现乱码问题。\n生成脚本选择的编码，如下图设置：\nIDEA workspace 的编码：\n数据源配置 ACTS 配置数据源的目的，是为了在数据准备、数据清理、数据校验阶段，能够使用系统的数据源正确的进行 DB 增删改查。\n数据源配置 在 src/test/resource/config/acts-config.properties 中配置 dal 层的 ModuleName、数据源以及表的对应关系，以 ds_ 开头，如下：\ndatasource_bundle_name =com.alipay.testapp.common.dal ds_bean1=table1,table2 ds_bean2=table3,table4 #配置格式 #ds_数据源bean=逻辑表名1,逻辑表名2 其中数据源 bean1、数据源 bean2 是应用代码中 dal 层的数据源 bean 的名称，支持多个数据源。表名支持正则表达式，无需带分库分表后缀，若有多个数据源时请注意，某张表只能属于一个数据源，如下图：\n数据库直连 数据库直连，用于 DB 数据模型的生成。在 src/test/resource/config/dbConf/ 下的 devdb.conf 或 testdb.conf 中配置如下：\nxxx_url = jdbc:oracle:thin:@localhost:1521:cifdb xxx_username = myname xxx_password = mypswd 一键配置的说明 一键配置测试框架主要生成包含两部分，一部分是基础 Java 类，另一类是必须的配置文件，具体生成内容如下：\nJava 类   AppNameActsBaseUtils.java\n测试脚本编写过程中常用的从框架中获取各种数据的工具类，初始化搭建只提供了常用的方法，可自行添加。\n  AppNameActsTestBase.java\n封装后的应用测试基类，业务系统如有特殊需求可在其上自行封装，如果没有则可以忽略此文件。\n  配置文件 ","date":-62135596800,"description":"","dir":"projects/sofa-acts/usage-ready/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"c3a89cbf42d55c98206a08e94d05ffde","permalink":"/projects/sofa-acts/usage-ready/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-acts/usage-ready/","summary":"框架准备 在阅读前，您可以参考快速开始下载并安装 ACTS IDE 和引入 ACTS 框架. 本部分主要包含编码说明、数据源配置和一键配置说明，以帮助您使用 ACTS 框架。 编码说","tags":null,"title":"框架准备","type":"projects","url":"/projects/sofa-acts/usage-ready/","wordcount":593},{"author":null,"categories":null,"content":"SOFABoot 从 2.4.0 版本开始支持基于 Spring 上下文隔离的模块化开发能力。为了更好的理解 SOFABoot 模块化开发的概念，我们来区分几个常见的模块化形式：\n 基于代码组织上的模块化：这是最常见的形式，在开发期，将不同功能的代码放在不同 Java 工程下，在编译期被打进不同 jar 包，在运行期，所有 Java 类都在一个 classpath 下，没做任何隔离； 基于 Spring 上下文隔离的模块化：借用 Spring 上下文来做不同功能模块的隔离，在开发期和编译期，代码和配置也会分在不同 Java 工程中，但在运行期，不同模块间的 Spring Bean 相互不可见，DI 只在同一个上下文内部发生，但是所有的 Java 类还是在同一个 ClassLoader 下； 基于 ClassLoader 隔离的模块化：借用 ClassLoader 来做隔离，每个模块都有独立的 ClassLoader，模块与模块之间的 classpath 不同，SOFAArk 就是这种模块化的实践方式。  SOFABoot 模块化开发属于第二种模块化形式 —— 基于 Spring 上下文隔离的模块化。每个 SOFABoot 模块使用独立的 Spring 上下文，避免不同 SOFABoot 模块间的 BeanId 冲突，有效降低企业级多模块开发时团队间的沟通成本。\n关于 SOFABoot 模块化产生的背景，可参考文章《蚂蚁金服的业务系统模块化 \u0026amp;mdash;- 模块化隔离方案》\n功能简介 依赖引入 使用 SOFABoot 模块化开发方案，需要引入如下依赖：\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;isle-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; SOFABoot 模块 SOFABoot 框架定义了 SOFABoot 模块的概念，一个 SOFABoot 模块是一个包括 Java 代码、Spring 配置文件、SOFABoot 模块标识等信息的普通 Jar 包，一个 SOFABoot 应用可以包含多个 SOFABoot 模块，每个 SOFABoot 模块都含有独立的 Spring 上下文。\n以 SOFABoot 模块为单元的模块化方式为开发者提供了以下功能：\n 运行时，每个 SOFABoot 模块的 Spring 上下文是隔离的，模块间定义的 Bean 不会相互影响； 每个 SOFABoot 模块是功能完备且自包含的，可以很容易在不同的 SOFABoot 应用中进行模块迁移和复用，只需将 SOFABoot 模块整个拷贝过去，调整 Maven 依赖，即可运行。  SOFABoot 模块的格式定义见: 模块配置。\nSOFABoot 模块间通信 上下文隔离后，模块与模块间的 Bean 无法直接注入，模块间需要通过 SOFA 服务进行通信，目前SOFABoot 提供了两种形式的服务发布和引用，用于解决不同级别的模块间调用的问题：\n JVM 服务发布和引用：解决一个 SOFABoot 应用内部各个 SOFABoot 模块之间的调用问题， JVM 服务发布与引用 RPC 服务发布和引用：解决多个 SOFABoot 应用之间的远程调用问题，RPC 服务发布与引用。  模块并行化启动 每个 SOFABoot 模块都是独立的 Spring 上下文，多个 SOFABoot 模块支持并行化启动，与 Spring Boot 的单 Spring 上下文模式相比，模块并行化启动能够加快应用的启动速度。\nRoot Application Context SOFABoot 应用运行时，本身会产生一个 Spring Context，我们把它叫做 Root Application Context，它是每个 SOFABoot 模块创建的 Spring Context 的 Parent。这样设计的目的是为了保证每个 SOFABoot 模块的 Spring Context 都能发现 Root Application Context 中创建的 Bean，这样当应用新增 Starter 时，不仅 Root Application Context 能够使用 Starter 中新增的 Bean，每个 SOFABoot 模块的 Spring Context 也能使用这些 Bean。\n","date":-62135596800,"description":"","dir":"projects/sofa-boot/modular-development/","fuzzywordcount":1100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"95bc080787c3614bfa485d2f3cd0de4c","permalink":"/projects/sofa-boot/modular-development/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/sofa-boot/modular-development/","summary":"SOFABoot 从 2.4.0 版本开始支持基于 Spring 上下文隔离的模块化开发能力。为了更好的理解 SOFABoot 模块化开发的概念，我们来区分几个常见的模块化形式： 基于代码组织上的模块化","tags":null,"title":"模块化开发概述","type":"projects","url":"/projects/sofa-boot/modular-development/","wordcount":1073},{"author":null,"categories":null,"content":"SOFABoot 会根据 Require-Module 计算模块依赖树，例如以下依赖树表示模块B 和模块C 依赖模块A，模块E 依赖模块D，模块F 依赖模块E：\n该依赖树会保证模块A 必定在模块B 和模块C 之前启动，模块D 在模块E 之前启动，模块E 在模块F 之前启动，但是依赖树没有定义模块B 与模块C，模块B、C与模块D、E、F之间的启动顺序，这几个模块之间可以串行启动，也可以并行启动。\nSOFABoot 默认会并行启动模块，在使用过程中，如果希望关闭并行启动，可以在 application.properties 中增加以下参数:\ncom.alipay.sofa.boot.module-start-up-parallel=false ","date":-62135596800,"description":"","dir":"projects/sofa-boot/parallel-start/","fuzzywordcount":300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"a6ef51b78d2a4f9af0debbc25ea45e8a","permalink":"/projects/sofa-boot/parallel-start/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-boot/parallel-start/","summary":"SOFABoot 会根据 Require-Module 计算模块依赖树，例如以下依赖树表示模块B 和模块C 依赖模块A，模块E 依赖模块D，模块F 依赖模块E： 该依赖树会保证模块A 必定在模块B 和","tags":null,"title":"模块并行化启动","type":"projects","url":"/projects/sofa-boot/parallel-start/","wordcount":204},{"author":null,"categories":null,"content":"SOFABoot 模块是一个普通的 Jar 包加上一些 SOFABoot 特有的配置，这些 SOFABoot 特有的配置，让一个 Jar 包能够被 SOFABoot 识别，使之具备模块化的能力。\n一个完整的 SOFABoot 模块和一个普通的 Jar 包有两点区别:\n SOFABoot 模块包含一份 sofa-module.properties 文件，这份文件里面定义了 SOFABoot 模块的名称以及模块之间的依赖关系。 SOFABoot 模块的 META-INF/spring 目录下，可以放置任意多的 Spring 配置文件，SOFABoot 会自动把它们作为本模块的 Spring 配置加载起来。  sofa-module.properties 文件详解 先来看一份完整的 sofa-module.properties 文件（src/main/resources 目录下）：\nModule-Name=com.alipay.test.biz.service.impl Spring-Parent=com.alipay.test.common.dal Require-Module=com.alipay.test.biz.shared Module-Profile=dev Module-Name Module-Name 是 SOFABoot 模块的名称，也是 SOFABoot 模块的唯一标示符。在一个 SOFABoot 应用中，一个 SOFABoot 模块的 Module-Name 必须和其他的 SOFABoot 模块的 Module-Name 不一样。需要注意的一点是，一个 SOFABoot 应用运行时的 SOFABoot 模块，不仅仅只包含本应用的模块，还包括依赖了其他应用的 SOFABoot 模块，确定是否唯一的时候需要把这些 SOFABoot 模块也考虑进去。\nRequire-Module Require-Module 用于定义模块之间的依赖顺序，值是以逗号分隔的 SOFABoot 模块名列表，比如上面的配置中，就表示本模块依赖于 com.alipay.test.biz.shared 模块。对于这种依赖关系的处理，SOFABoot 会将 com.alipay.test.biz.shared 模块在本模块之前启动，即com.alipay.test.biz.shared 模块将先启动 Spring 上下文。\n一般情况下，是不需要为模块定义 Require-Module 的，只有当模块的 Spring 上下文的启动依赖于另一个模块的 Spring 上下文的启动时，才需要定义 Require-Module。举一个例子，如果你在 A 模块中发布了一个 SOFA JVM Service。在 B 模块的某一个 Bean 的 init 方法里面，需要使用 SOFA Reference 调用这个 JVM Service。假设 B 模块在 A 模块之前启动了，那么 B 模块的 Bean 就会因为 A 模块的 JVM Service 没有发布而 init 失败，导致 Spring 上下文启动失败。这个时候，我们就可以使用 Require-Module 来强制 A 模块在 B 模块之前启动。\nSpring-Parent 在 SOFABoot 应用中，每一个 SOFABoot 模块都是一个独立的 Spring 上下文，并且这些 Spring 上下文之间是相互隔离的。虽然这样的模块化方式可以带来诸多好处，但是，在某些场景下还是会有一些不便，这个时候，你可以通过 Spring-Parent 来打通两个 SOFABoot 模块的 Spring 上下文。Spring-Parent 属性可以配置一个模块的名称，比如上面的配置中，就将 com.alipay.test.common.dal 的 Spring 上下文设置为当前模块的 Spring 上下文的父 Spring 上下文。\n由于 Spring 的限制，一个模块的 Spring-Parent 只能有一个模块\n关于 Spring 的父上下文的作用可以看 Spring 的 BeanFactory 的说明：http://docs.spring.io/spring/docs/current/javadoc-api/org/springframework/beans/factory/BeanFactory.html\nModule-Profile 支持 SOFABoot Profile 能力： SOFABoot Profile\nSpring 配置文件 SOFABoot 模块可以包含 Spring 配置文件，配置文件需要放置在 META-INF/spring 目录下，SOFABoot 启动时会自动扫描该目录，并把目录下所有 XML 文件作为本模块的 Spring 配置加载起来。在 Spring 配置文件中，我们可以定义 Bean、发布服务等等。\nSOFABoot 模块一般用于封装对外发布服务接口的具体实现，属于业务层，Controller 属于展现层内容，我们不建议也不支持在 SOFABoot 模块中定义 Controller 组件，Controller 组件相关定义请直接放在 Root Application Context。\n","date":-62135596800,"description":"","dir":"projects/sofa-boot/sofaboot-module/","fuzzywordcount":1200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"2dbb8a536237f21afbee1e3f320b8193","permalink":"/projects/sofa-boot/sofaboot-module/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/sofa-boot/sofaboot-module/","summary":"SOFABoot 模块是一个普通的 Jar 包加上一些 SOFABoot 特有的配置，这些 SOFABoot 特有的配置，让一个 Jar 包能够被 SOFABoot 识别，使之具备模块化的能力。 一个完整的 SOFABoot 模块和一个普通的 Jar 包","tags":null,"title":"模块配置","type":"projects","url":"/projects/sofa-boot/sofaboot-module/","wordcount":1194},{"author":null,"categories":null,"content":"如果你要扩展一个注册中心，我们先看下注册中心的抽象类。\npackage com.alipay.sofa.rpc.registry; @Extensible(singleton = false) public abstract class Registry implements Initializable, Destroyable { public abstract boolean start(); public abstract void register(ProviderConfig config); public abstract void unRegister(ProviderConfig config); public abstract void batchUnRegister(List\u0026amp;lt;ProviderConfig\u0026amp;gt; configs); public abstract List\u0026amp;lt;ProviderGroup\u0026amp;gt; subscribe(ConsumerConfig config); public abstract void unSubscribe(ConsumerConfig config); public abstract void batchUnSubscribe(List\u0026amp;lt;ConsumerConfig\u0026amp;gt; configs); } 可以看到我们需要的主要接口。\n 启动注册中心客户端、维持连接 销毁注册中心客户端、释放资源 发布服务、缓存发布信息 取消发布服务、删除缓存 订阅服务列表、同步或者异步返回数据，有变化接收通知 取消订阅服务列表、删除缓存  其它\n 注册中心节点断连后，不影响本地调用 和一个注册中心节点断连后，可自己切换到其它注册中心节点 注册中心节点切换后，自动恢复注册和订阅信息 注册中心数据缓存到本地文件，就算连不上任何注册中心，服务提供者和服务调用者也能重启并正常调用  ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/registry-extension-guide/","fuzzywordcount":300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"c952ecbea16f7ae68ad095ab8baf0583","permalink":"/projects/sofa-rpc/registry-extension-guide/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/registry-extension-guide/","summary":"如果你要扩展一个注册中心，我们先看下注册中心的抽象类。 package com.alipay.sofa.rpc.registry; @Extensible(singleton = false) public abstract class Registry implements Initializable, Destroyable { public abstract boolean start(); public abstract void register(ProviderConfig config); public abstract void unRegister(ProviderConfig config); public abstract void batchUnRegister(List\u0026lt;ProviderConfig\u0026gt; configs); public abstract List\u0026lt;ProviderGroup\u0026gt; subscribe(ConsumerConfig config); public abstract void unSubscribe(ConsumerConfig config); public","tags":null,"title":"注册中心扩展指南","type":"projects","url":"/projects/sofa-rpc/registry-extension-guide/","wordcount":290},{"author":null,"categories":null,"content":"SOFABoot RPC Starter 为用户提供多种注册中心选择和方便的配置。 目前 bolt ， rest ， dubbo 都支持 Zookeeper 作为注册中心。另外 bolt ， rest 支持本地文件系统作为注册中心，该种模式一般用于测试。\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/registry-usage/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"5a1a4619c8ac4a9fc27b8576472aed9f","permalink":"/projects/sofa-rpc/registry-usage/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/registry-usage/","summary":"SOFABoot RPC Starter 为用户提供多种注册中心选择和方便的配置。 目前 bolt ， rest ， dubbo 都支持 Zookeeper 作为注册中心。另外 bolt ， rest 支持本地文件系统作为注册中心，该种模式一般用于测","tags":null,"title":"注册中心选择","type":"projects","url":"/projects/sofa-rpc/registry-usage/","wordcount":72},{"author":null,"categories":null,"content":"本文描述的是 MOSN 作为 Sidecar 使用时的流量劫持方案。\nMOSN 作为 Sidecar 和业务容器部署在同一个 Pod 中时，需要使得业务应用的 Inbound 和 Outbound 服务请求都能够经过 Sidecar 处理。区别于 Istio 社区使用 iptables 做流量透明劫持，MOSN 目前使用的是流量接管方案，并在积极探索适用于大规模流量下的透明劫持方案。\n流量接管 区别于 Istio 社区的 iptables 流量劫持方案，MOSN 使用的流量接管的方案如下：\n 假设服务端运行在 1.2.3.4 这台机器上，监听 20880 端口，首先服务端会向自己的 Sidecar 发起服务注册请求，告知 Sidecar 需要注册的服务以及 IP + 端口（1.2.3.4:20880） 服务端的 Sidecar 会向服务注册中心（如 SOFA Registry）发起服务注册请求，告知需要注册的服务以及 IP + 端口，不过这里需要注意的是注册上去的并不是业务应用的端口（20880），而是 Sidecar 自己监听的一个端口（例如：20881） 调用端向自己的 Sidecar 发起服务订阅请求，告知需要订阅的服务信息 调用端的 Sidecar 向调用端推送服务地址，这里需要注意的是推送的 IP 是本机，端口是调用端的 Sidecar 监听的端口（例如 20882） 调用端的 Sidecar 会向服务注册中心（如 SOFA Registry）发起服务订阅请求，告知需要订阅的服务信息； 服务注册中心（如 SOFA Registry）向调用端的 Sidecar 推送服务地址（1.2.3.4:20881）  服务调用过程 经过上述的服务发现过程，流量转发过程就显得非常自然了：\n 调用端拿到的服务端地址是 127.0.0.1:20882，所以就会向这个地址发起服务调用 调用端的 Sidecar 接收到请求后，通过解析请求头，可以得知具体要调用的服务信息，然后获取之前从服务注册中心返回的地址后就可以发起真实的调用（1.2.3.4:20881） 服务端的 Sidecar 接收到请求后，经过一系列处理，最终会把请求发送给服务端（127.0.0.1:20880）  透明劫持 上文通过在服务注册过程中把服务端地址替换成本机监听端口实现了轻量级的“流量劫持”，在存在注册中心，且调用端和服务端同时使用特定SDK的场景中可以很好的工作，如果不满足这两个条件，则无法流量劫持。为了降低对于应用程序的要求，需要引入透明劫持。\n使用 iptables 做流量劫持 iptables 通过 NAT 表的 redirect 动作执行流量重定向，通过 syn 包触发新建 nefilter 层的连接，后续报文到来时查找连接转换目的地址与端口。新建连接时同时会记录下原始目的地址，应用程序可以通过(SOL_IP、SO_ORIGINAL_DST)获取到真实的目的地址。\niptables 劫持原理如下图所示：\n使用 iptables 做流量劫持时存在的问题 目前 Istio 使用 iptables 实现透明劫持，主要存在以下三个问题：\n 需要借助于 conntrack 模块实现连接跟踪，在连接数较多的情况下，会造成较大的消耗，同时可能会造成 track 表满的情况，为了避免这个问题，业内有关闭 conntrack 的做法，比如阿里巴巴就关闭了这个模块。 iptables 属于常用模块，全局生效，不能显式的禁止相关联的修改，可管控性比较差。 iptables 重定向流量本质上是通过 loopback 交换数据，outbond 流量将两次穿越协议栈，在大并发场景下会损失转发性能。  上述几个问题并非在所有场景中都存在，比方说某些场景下，连接数并不多，且 NAT 表未被使用到的情况下，iptables 是一个满足要求的简单方案。为了适配更加广泛的场景，透明劫持需要解决上述三个问题。\n透明劫持方案优化 使用 tproxy 处理 inbound 流量\ntproxy 可以用于 inbound 流量的重定向，且无需改变报文中的目的 IP/端口，不需要执行连接跟踪，不会出现 conntrack 模块创建大量连接的问题。受限于内核版本，tproxy 应用于 outbound 存在一定缺陷。目前 Istio 支持通过 tproxy 处理 inbound 流量。\n使用 hook connect 处理 outbound 流量\n为了适配更多应用场景，outbound 方向通过 hook connect 来实现，实现原理如下：\n无论采用哪种透明劫持方案，均需要解决获取真实目的 IP/端口的问题，使用 iptables 方案通过 getsockopt 方式获取，tproxy 可以直接读取目的地址，通过修改调用接口，hook connect 方案读取方式类似于tproxy。\n实现透明劫持后，在内核版本满足要求（4.16以上）的前提下，通过 sockmap 可以缩短报文穿越路径，进而改善 outbound 方向的转发性能。\n总结 总结来看，如果应用程序通过注册中心发布/订阅服务时，可以结合注册中心劫持流量；在需要用到透明劫持的场景，如果性能压力不大，使用 iptables redirect 即可，大并发压力下使用 tproxy 与hook connect 结合的方案。\n","date":-62135596800,"description":"","dir":"projects/mosn/concept/traffic-hijack/","fuzzywordcount":1700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"5845d8478a48fcddc74f0b9d28ede2c2","permalink":"/projects/mosn/concept/traffic-hijack/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/projects/mosn/concept/traffic-hijack/","summary":"本文描述的是 MOSN 作为 Sidecar 使用时的流量劫持方案。 MOSN 作为 Sidecar 和业务容器部署在同一个 Pod 中时，需要使得业务应用的 Inbound 和 Outbound 服务请求都能够经过 Sidecar 处理。区别于 Istio 社","tags":null,"title":"流量劫持","type":"projects","url":"/projects/mosn/concept/traffic-hijack/","wordcount":1668},{"author":null,"categories":null,"content":"版本号 采用三位版本号，分别是主版本号、次版本号、修订版本号。例如 5.1.2。\n参见: http://semver.org/lang/zh-CN/。\n 主版本号：主版本号内的所有版本必须相互兼容；与其它主版本号不一定完全兼容，尽量向下兼容。 次版本号：代表新特性增强。版本号越大特性越丰富。 修订版本号：代表BugFix版本。只做bug修复使用，版本号越大越稳定。  版本维护 最多同时维护两个版本。\n例如当前主干为 5.3.0，那么将会维护 5.2.x 的 bugfix 分支，而 5.1.x 遇到 bug 将不再修复，建议升级。\n发布流程  日常开发分支采用 SNAPSHOT 版本，例如 5.3.0-SNAPSHOT。 正式发布时修改版本为正式版本，例如 5.3.0。 发布后拉起下一个版本，例如 5.3.1-SNAPSHOT。  ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/version-release/","fuzzywordcount":400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"604f113607e6815757f4d1907190c13c","permalink":"/projects/sofa-rpc/version-release/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/version-release/","summary":"版本号 采用三位版本号，分别是主版本号、次版本号、修订版本号。例如 5.1.2。 参见: http://semver.org/lang/zh-CN/","tags":null,"title":"版本发布","type":"projects","url":"/projects/sofa-rpc/version-release/","wordcount":315},{"author":null,"categories":null,"content":" 1.3.2 2020-06-19\n Bug Fixes  移除对 bolt address parser 的扩展，避免 check connection 返回结果不符合预期 SPI 组件 JRaftServiceLoader 改为延迟加载策略规避多余对象的创建 几个 corner case 修复，比如 replicate logs 如果比 appliedIndex（follower）更小，那么可以认为是成功的 关闭 Recyclers 时的 IndexOutOfBoundsException 问题修复   Features  抽象出网络通信层，增加 GRPC 实现并支持 Replication Pipeline，用户亦可自行对通信层进行其他实现的扩展 RheaKV 增加 reverseScan API 提供 Replicator 与 RPC 的线程池隔离，避免相互影响 read-index 线性一致读请求提供请求超时（timeout）配置   Breaking Changes  无   致谢（排名不分先后）  @shibd @SteNicholas @killme2008 @zongtanghu     1.3.1 2020-04-17\n Bug Fixes  修复 bolt rpc callback 默认的任务饱和丢弃策略，改为抛出异常 修复 learner 启动晚于 leader 选举成功时无法复制日志的 bug   Features  multi raft group 之间共享 timer 和 scheduler 等较重的线程资源，优化 multi group 场景中的多余资源占用 提供 RPC adapter，用户可基于 SPI 扩展不同的 RPC 实现 正式提供稳定的 RocksDBSegmentLogStorage，适合 value 较大的数据存储 sofa-bolt 升级到 1.6.1，支持 SSL 以及具有更好的小数据包传输能力 引入一个新的数据结构 segment list 来解决 LogManager 中过多的 log memory copy 采纳 nacos 的建议，对 raft Task 增加 join API   Breaking Changes  无   致谢（排名不分先后）  @jovany-wang @SteNicholas @zongtanghu @OpenOpened     1.3.0 2019-11-29\n Bug Fixes  删除数据并重启且期间没有新的 task 提交的情况下 prev log index 紊乱的修复 修复一些选举和线性一致读相关的 corner case Recyclers 多个线程 recycle 资源时的 NPE 修复   Features  新增 Read-only member(learner) 角色，支持 learner 节点上的线性一致读 实现优先级选举 在 multi raft group 的场景中，随机打散每个 group 的第一次 snapshot timeout 时间，避免一个进程内多个 group 同时 snapshot RheaKV 新增 containsKey API RheaKV 实现 snapshot checksum 以及异步 snapshot 新增 replicator 的 state 监听器： ReplicatorStateListener RepeatedTimer 的默认实现替换为 HashedWheelTimer 修复 windows 上定时器 CPU 消耗偏高的问题 kill -s SIGUSR2 pid 中增加打印 rocksdb stats 和所有 ThreadPool 指标统计信息 升级 rocksdb 版本到 5.18.3 新增实验性质的 RocksDBSegmentLogStorage，适合 value 较大的数据存储 Counter 例子改进，演示 ReadIndex 线性一致读 当优化 checksum 中多余的 mem copy   Breaking Changes  无   致谢（排名不分先后）  @zongtanghu @devYun @masaimu @SteNicholas @yetingsky     1.2.6 2019-08-15\n Bug Fixes  修复 ReadIndex 并发情况下可能出现的读超时 保存 raft meta 失败后终止状态机 修复 windows 环境中无法原子 move 文件的问题 当 RheaKV apply 失败时终止状态机避免出现数据不一致情况   Features  增加 LogEntry checksum validation 优化 log replication 线程模型减少锁竞争 优化 RheaKV multi group snapshot 对于 multi-raft-group 场景，提供 manual rebalance API 在无 PD 模式手动平衡各节点 leader 数量 CliService 提供获取存活 follower 节点的 API 引入 SPI 扩展机制，LogStorage、SnapshotStorage、RaftMetaStorage、LogEntryCodec 均可基于 SPI 扩展 Linux 平台 SIGUSR2 信号输出节点状态以及 metric 信息 RheaKV 增加 CompareAndPut 原子更新 API 新增 pooled buf allocator 解决 log replication 时大量分配 byte[] 频繁触发 fullgc 默认关闭 RheaKV rocksdb 的 fsync 和 WAL，依靠 raft log 和 snapshot 确保数据一致性 当 raft node 过载时拒绝新的请求   Breaking Changes  无   致谢（排名不分先后）  @SteNicholas @zongtanghu     1.2.5 2019-04-01\n Bug Fixes  修复 jmh 与 unit test 代码冲突问题 修复 snapshot 过大引起的安装失败 bug，会影响新增节点的加入   Features  LogManagerImpl 中耗费 cpu 部分的代码优化 修正一些单词拼写错误   Breaking Changes  无    此版本强烈推荐升级\n 1.2.4 2019-03-20\n Bug Fixes  修复一种情况下 lease read 的 stale read 部分 timestamp 修改为 monotonic time 修复一种情况下 replicator 被 block 住的问题 解决 windows 平台下某些单测无法创建目录 解决 windows 平台下某些 rocksdb options 设置不当导致进程 crash   Features  开放 RocksDB options 的设置给用户层 Pre-vote 优化，启用 lease 机制来规避网络分区+集群长时间无写入的情况下，游离节点回归后打断 …","date":-62135596800,"description":"","dir":"projects/sofa-jraft/release-log/","fuzzywordcount":2400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"9e24fb74a3cda6a600252b01f8a85db9","permalink":"/projects/sofa-jraft/release-log/","publishdate":"0001-01-01T00:00:00Z","readingtime":5,"relpermalink":"/projects/sofa-jraft/release-log/","summary":"1.3.2 2020-06-19 Bug Fixes 移除对 bolt address parser 的扩展，避免 check connection 返回结果不符合预期 SPI 组件 JRaftServiceLoader 改为延迟加载策略规避多余对象的创建 几个 corner case 修复，比如 replicate logs 如果比 appliedI","tags":null,"title":"版本发行日志","type":"projects","url":"/projects/sofa-jraft/release-log/","wordcount":2302},{"author":null,"categories":null,"content":"通过 SOFABoot，我们可以直接在浏览器中就可以查看 SOFA 中间件的版本等详细信息。\n引入 SOFABoot Infra 依赖 要在 SOFABoot 中直接通过浏览器查看 SOFA 中间件的版本信息，只需要在 Maven 依赖中增加如下的内容即可：\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alipay.sofa\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;infra-sofa-boot-starter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 版本信息查看 在应用启动成功后，可以在浏览器中输入 http://localhost:8080/sofaboot/versions 查看 SOFA 中间件的版本信息，如：\n[ { GroupId: \u0026amp;#34;com.alipay.sofa\u0026amp;#34;, Doc-Url: \u0026amp;#34;https://github.com/sofastack/sofa-boot\u0026amp;#34;, ArtifactId: \u0026amp;#34;infra-sofa-boot-starter\u0026amp;#34;, Built-Time: \u0026amp;#34;2018-04-05T20:55:22+0800\u0026amp;#34;, Commit-Time: \u0026amp;#34;2018-04-05T20:54:26+0800\u0026amp;#34;, Commit-Id: \u0026amp;#34;049bf890bb468aafe6a3e07b77df45c831076996\u0026amp;#34;, Version: \u0026amp;#34;2.4.0\u0026amp;#34; } ] 注: 在 SOFABoot 3.x 中调整了 endpoint 路径，sofaboot/versions 更改为 actuator/versions\n","date":-62135596800,"description":"","dir":"projects/sofa-boot/view-versions/","fuzzywordcount":200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"c6b6d22e9038aa1f5e4ce74449ba1cda","permalink":"/projects/sofa-boot/view-versions/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-boot/view-versions/","summary":"通过 SOFABoot，我们可以直接在浏览器中就可以查看 SOFA 中间件的版本等详细信息。 引入 SOFABoot Infra 依赖 要在 SOFABoot 中直接通过浏览器查看 SOFA 中间件的版本信息，只","tags":null,"title":"版本查看","type":"projects","url":"/projects/sofa-boot/view-versions/","wordcount":182},{"author":null,"categories":null,"content":"版本号 采用三位版本号，分别是主版本号、次版本号、修订版本号。例如 1.0.0。\n参见: http://semver.org/lang/zh-CN/\n 主版本号：主版本号内的所有版本必须相互兼容；与其它主版本号不一定完全兼容，尽量向下兼容。 次版本号：代表新特性增强。版本号越大特性越丰富。 修订版本号：代表BugFix版本。只做bug修复使用，版本号越大越稳定。  版本维护 最多同时维护两个版本。\n例如当前主干为 1.2.0，那么将会维护 1.1.x 的 bugfix 分支，而 1.0.x 遇到 bug 将不再修复，建议升级。\n发布流程  日常开发分支采用 SNAPSHOT 版本，例如 1.0.0-SNAPSHOT。 正式发布时修改版本为正式版本，例如 1.0.0。 发布后拉起下一个版本，例如 1.0.1-SNAPSHOT。  ","date":-62135596800,"description":"","dir":"projects/sofa-dashboard/version-rule/","fuzzywordcount":300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"a2093bdf478bdff0e15a2de70e522d03","permalink":"/projects/sofa-dashboard/version-rule/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-dashboard/version-rule/","summary":"版本号 采用三位版本号，分别是主版本号、次版本号、修订版本号。例如 1.0.0。 参见: http://semver.org/lang/zh-CN/ 主版本号：主版本号内的所有版本必须相互兼容；与其它主版本","tags":null,"title":"版本规范","type":"projects","url":"/projects/sofa-dashboard/version-rule/","wordcount":286},{"author":null,"categories":null,"content":"版本号 采用三位版本号，分别是主版本号、次版本号、修订版本号。例如 5.2.0。\n参见: http://semver.org/lang/zh-CN/\n 主版本号：主版本号内的所有版本必须相互兼容；与其它主版本号不一定完全兼容，尽量向下兼容。 次版本号：代表新特性增强。版本号越大特性越丰富。 修订版本号：代表BugFix版本。只做bug修复使用，版本号越大越稳定。  版本维护 最多同时维护两个版本。\n例如当前主干为 5.4.0，那么将会维护 5.3.x 的 bugfix 分支，而 5.2.x 遇到 bug 将不再修复，建议升级。\n发布流程  日常开发分支采用 SNAPSHOT 版本，例如 5.3.0-SNAPSHOT。 正式发布时修改版本为正式版本，例如 5.3.0。 发布后拉起下一个版本，例如 5.3.1-SNAPSHOT。  ","date":-62135596800,"description":"","dir":"projects/sofa-registry/release-standard/","fuzzywordcount":300,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"71aad9cbc42aba3d9f875ae9169cf005","permalink":"/projects/sofa-registry/release-standard/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-registry/release-standard/","summary":"版本号 采用三位版本号，分别是主版本号、次版本号、修订版本号。例如 5.2.0。 参见: http://semver.org/lang/zh-CN/ 主版本号：主版本号内的所有版本必须相互兼容；与其它主版本","tags":null,"title":"版本规范","type":"projects","url":"/projects/sofa-registry/release-standard/","wordcount":286},{"author":null,"categories":null,"content":"SOFABoot 使用了一些三方开源组件，他们分别是：\n一些主要依赖：\n Spring under Apache 2.0 license Spring Boot under Apache 2.0 license SLF4j under the MIT License sofa-common-tools under Apache 2.0 license  一些扩展依赖：\n nuxeo under Apache License, Version 2.0  \u0026amp;hellip; 其它整理中。\n","date":-62135596800,"description":"","dir":"projects/sofa-boot/notice/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"11f073a7a9965ab5690ed166fe319bbd","permalink":"/projects/sofa-boot/notice/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-boot/notice/","summary":"SOFABoot 使用了一些三方开源组件，他们分别是： 一些主要依赖： Spring under Apache 2.0 license Spring Boot under Apache 2.0 license SLF4j under the MIT License sofa-common-tools under Apache 2.0 license 一些扩展依赖： nuxeo under Apache License, Version 2.0 \u0026hellip; 其它整理中。","tags":null,"title":"版权声明","type":"projects","url":"/projects/sofa-boot/notice/","wordcount":67},{"author":null,"categories":null,"content":"依赖组件版权说明 SOFADashboard 使用了一些三方开源组件，他们分别是：\n Spring under Apache 2.0 license Spring Boot under Apache 2.0 license SLF4j under the MIT License SOFA Bolt under Apache License 2.0 SOFA Bolt under Apache License 2.0 Curator under Apache License 2.0  \u0026amp;hellip; 其它整理中。\n","date":-62135596800,"description":"","dir":"projects/sofa-dashboard/notice/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"a9ebe38d245302f94ab7bfa793329926","permalink":"/projects/sofa-dashboard/notice/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-dashboard/notice/","summary":"依赖组件版权说明 SOFADashboard 使用了一些三方开源组件，他们分别是： Spring under Apache 2.0 license Spring Boot under Apache 2.0 license SLF4j under the MIT License SOFA Bolt under Apache License 2.0 SOFA Bolt under Apache License 2.0 Curator under Apache License 2.0 \u0026hellip; 其它整理中。","tags":null,"title":"版权声明","type":"projects","url":"/projects/sofa-dashboard/notice/","wordcount":67},{"author":null,"categories":null,"content":"依赖组件版权说明 SOFARegistry 使用了一些三方开源组件，他们分别是：\n Spring under Apache 2.0 license Spring Boot under Apache 2.0 license Netty under Apache License 2.0 SLF4j under the MIT License jersey under CDDL Version 1.1  SOFAJRaft under Apache License 2.0 SOFABolt under Apache License 2.0 SOFAHessian under Apache License 2.0  \u0026amp;hellip; 其它整理中，如若发现遗漏，还请主动告知。\n","date":-62135596800,"description":"","dir":"projects/sofa-registry/notice/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"c40263ffd56a2f1292756c9fafea55e2","permalink":"/projects/sofa-registry/notice/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-registry/notice/","summary":"依赖组件版权说明 SOFARegistry 使用了一些三方开源组件，他们分别是： Spring under Apache 2.0 license Spring Boot under Apache 2.0 license Netty under Apache License 2.0 SLF4j under the MIT License jersey under CDDL Version 1.1 SOFAJRaft under Apache License 2.0 SOFABolt under Apache License 2.0 SOFAHessian under Apache License 2.0 \u0026hellip; 其","tags":null,"title":"版权声明","type":"projects","url":"/projects/sofa-registry/notice/","wordcount":89},{"author":null,"categories":null,"content":" RheaKV：基于 JRaft 和 RocksDB 实现的嵌入式、分布式、高可用、强一致的 KV 存储类库。 AntQ Streams QCoordinator： 使用 JRaft 在 coordinator 集群内做选举、元信息存储等功能。 SOFA 服务注册中心元信息管理模块：IP 数据信息注册，要求写数据达到各个节点一致，并且在不小于一半节点挂掉，保证不影响数据正常存储。 AntQ NameServer 选主  ","date":-62135596800,"description":"","dir":"projects/sofa-jraft/user-stories/","fuzzywordcount":200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"b233be7d9eed33645945293e637e28ea","permalink":"/projects/sofa-jraft/user-stories/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-jraft/user-stories/","summary":"RheaKV：基于 JRaft 和 RocksDB 实现的嵌入式、分布式、高可用、强一致的 KV 存储类库。 AntQ Streams QCoordinator： 使用 JRaft 在 coordinator 集群内做选举、元信息存储等","tags":null,"title":"用户案例","type":"projects","url":"/projects/sofa-jraft/user-stories/","wordcount":140},{"author":null,"categories":null,"content":"SOFARPC 支持指定地址进行调用的场景。用 Java API 的使用方式如下，设置直连地址即可：\nConsumerConfig\u0026amp;lt;HelloService\u0026amp;gt; consumer = new ConsumerConfig\u0026amp;lt;HelloService\u0026amp;gt;() .setInterfaceId(HelloService.class.getName()) .setRegistry(registryConfig) .setDirectUrl(\u0026amp;#34;bolt://127.0.0.1:12201\u0026amp;#34;); 用 XML 的使用方式如下：\n\u0026amp;lt;sofa:reference interface=\u0026amp;#34;com.alipay.sample.HelloService\u0026amp;#34; id=\u0026amp;#34;helloService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;sofa:route target-url=\u0026amp;#34;127.0.0.1:12200\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt; 用 Annotation 的使用方式如下：\n@SofaReference(binding = @SofaReferenceBinding(bindingType = \u0026amp;#34;bolt\u0026amp;#34;, directUrl = \u0026amp;#34;127.0.0.1:12220\u0026amp;#34;)) private SampleService sampleService; ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/peer-to-peer/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"b1815c322f5dc9528f6429d1d5e38369","permalink":"/projects/sofa-rpc/peer-to-peer/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/peer-to-peer/","summary":"SOFARPC 支持指定地址进行调用的场景。用 Java API 的使用方式如下，设置直连地址即可： ConsumerConfig\u0026lt;HelloService\u0026gt; consumer = new ConsumerConfig\u0026lt;HelloService\u0026gt;() .setInterfaceId(HelloService.class.getName()) .setRegistry(registryConfig) .setDirectUrl(\u0026#34;bolt://127.0.0.1:12201\u0026#34;); 用 XML 的使用方式如下： \u0026lt;sofa:reference interface=\u0026#34;com.alipay.sample.HelloService\u0026#34; id=\u0026#34;helloService\u0026#34;\u0026gt; \u0026lt;sofa:binding.bolt\u0026gt; \u0026lt;sofa:route target-url=\u0026#34;127.0.0.1:12200\u0026#34;/\u0026gt; \u0026lt;/sofa:binding.bolt\u0026gt; \u0026lt;/sofa:reference\u0026gt; 用 Annotation 的使用方式如下","tags":null,"title":"直连调用","type":"projects","url":"/projects/sofa-rpc/peer-to-peer/","wordcount":82},{"author":null,"categories":null,"content":"介绍几种 SOFARPC 在不同环境下的使用方式\n 非 Spring 环境 API 使用 SOFABoot 环境 XML 配置使用 SOFABoot 环境注解使用 SOFABoot 环境动态 API 使用  ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/programming/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"9a947dae761c84aa4d95121c076ac552","permalink":"/projects/sofa-rpc/programming/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/programming/","summary":"介绍几种 SOFARPC 在不同环境下的使用方式 非 Spring 环境 API 使用 SOFABoot 环境 XML 配置使用 SOFABoot 环境注解使用 SOFABoot 环境动态 API 使用","tags":null,"title":"编程界面","type":"projects","url":"/projects/sofa-rpc/programming/","wordcount":46},{"author":null,"categories":null,"content":"自动故障剔除会自动监控 RPC 调用的情况，对故障节点进行权重降级，并在节点恢复健康时进行权重恢复。目前支持 bolt 协议。\n在 SOFABoot 中，只需要配置自动故障剔除的参数到 application.properties 即可。可以不完全配置，只配置自己关心的参数，其余参数会取默认值。需要注意的是 com.alipay.sofa.rpc.aft.regulation.effective 是该功能的全局开关，如果关闭则该功能不会运行，其他参数也都不生效。\n   属性 描述 默认值     timeWindow 时间窗口大小：对统计信息计算的周期。 10s   leastWindowCount 时间窗口内最少调用数：只有在时间窗口内达到了该最低值的数据才会被加入到计算和调控中。 10次   leastWindowExceptionRateMultiple 时间窗口内异常率与服务平均异常率的降级比值：在对统计信息进行计算的时候，会计算出该服务所有有效调用ip的平均异常率，如果某个ip的异常率大于等于了这个最低比值，则会被降级。 6倍   weightDegradeRate 降级比率：地址在进行权重降级时的降级比率。 1/20   weightRecoverRate 恢复比率：地址在进行权重恢复时的恢复比率。 2倍   degradeEffective 降级开关：如果应用打开了这个开关，则会对符合降级的地址进行降级，否则只会进行日志打印。 false(关闭)   degradeLeastWeight 降级最小权重：地址权重被降级后的值如果小于这个最小权重，则会以该最小权重作为降级后的值。 1   degradeMaxIpCount 降级的最大ip数：同一个服务被降级的ip数不能超过该值。 2   regulationEffective 全局开关：如果应用打开了这个开关，则会开启整个单点故障自动剔除摘除功能，否则完全不进入该功能的逻辑。 false(关闭)     示例  com.alipay.sofa.rpc.aft.time.window=20 com.alipay.sofa.rpc.aft.least.window.count=30 com.alipay.sofa.rpc.aft.least.window.exception.rate.multiple=1.4 com.alipay.sofa.rpc.aft.weight.degrade.rate=0.5 com.alipay.sofa.rpc.aft.weight.recover.rate=1.2 com.alipay.sofa.rpc.aft.degrade.effective=true com.alipay.sofa.rpc.aft.degrade.least.weight=1 com.alipay.sofa.rpc.aft.degrade.max.ip.count=2 com.alipay.sofa.rpc.aft.regulation.effective=true 如上配置，打开了自动故障剔除功能和降级开关，当节点出现故障时会被进行权重降级，在恢复时会被进行权重恢复。每隔 20s 进行一次节点健康状态的度量，20s 内调用次数超过 30 次的节点才被作为计算数据，如果单个节点的异常率超过了所有节点的平均异常率的 1.4 倍则对该节点进行权重降级，降级的比率为 0.5 。权重最小降级到 1 。如果单个节点的异常率低于了平均异常率的 1.4 倍则对该节点进行权重恢复，恢复的比率为1.2 。单个服务最多降级 2 个ip。\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/configuration-fault-tolerance/","fuzzywordcount":800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"a132b54b2398534d1773489e2b0db166","permalink":"/projects/sofa-rpc/configuration-fault-tolerance/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-rpc/configuration-fault-tolerance/","summary":"自动故障剔除会自动监控 RPC 调用的情况，对故障节点进行权重降级，并在节点恢复健康时进行权重恢复。目前支持 bolt 协议。 在 SOFABoot 中，只需要配置自动故障剔除的","tags":null,"title":"自动故障剔除","type":"projects","url":"/projects/sofa-rpc/configuration-fault-tolerance/","wordcount":759},{"author":null,"categories":null,"content":"集群中通常一个服务有多个服务提供者。其中部分服务提供者可能由于网络，配置，长时间 fullgc ，线程池满，硬件故障等导致长连接还存活但是程序已经无法正常响应。单机故障剔除功能会将这部分异常的服务提供者进行降级，使得客户端的请求更多地指向健康节点。当异常节点的表现正常后，单机故障剔除功能会对该节点进行恢复，使得客户端请求逐渐将流量分发到该节点。单机故障剔除功能解决了服务故障持续影响业务的问题，避免了雪崩效应。可以减少人工干预需要的较长的响应时间，提高系统可用率。\n运行机制：\n 单机故障剔除会统计一个时间窗口内的调用次数和异常次数，并计算每个服务对应ip的异常率和该服务的平均异常率。 当达到ip异常率大于服务平均异常率到一定比例时，会对该服务+ip的维度进行权重降级。 如果该服务+ip维度的权重并没有降为0，那么当该服务+ip维度的调用情况正常时，则会对其进行权重恢复。 整个计算和调控过程异步进行，不会阻塞调用。  单机故障剔除的使用方式如下：\nFaultToleranceConfig faultToleranceConfig = new FaultToleranceConfig(); faultToleranceConfig.setRegulationEffective(true); faultToleranceConfig.setDegradeEffective(true); faultToleranceConfig.setTimeWindow(20); faultToleranceConfig.setWeightDegradeRate(0.5); FaultToleranceConfigManager.putAppConfig(\u0026amp;#34;appName\u0026amp;#34;, faultToleranceConfig); 如上，该应用会在打开了单机故障剔除开关，每20s的时间窗口进行一次异常情况的计算，如果某个服务+ip的调用维度被判定为故障节点，则会进行将该服务+ip的权重降级为0.5倍。\n更加详细的参数请参考单机故障剔除参数。\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/fault-tolerance/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"7501b0fac1d1d89c61de0d591e29e1d0","permalink":"/projects/sofa-rpc/fault-tolerance/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-rpc/fault-tolerance/","summary":"集群中通常一个服务有多个服务提供者。其中部分服务提供者可能由于网络，配置，长时间 fullgc ，线程池满，硬件故障等导致长连接还存活但是程序已经无法正常","tags":null,"title":"自动故障剔除","type":"projects","url":"/projects/sofa-rpc/fault-tolerance/","wordcount":528},{"author":null,"categories":null,"content":"在使用自定义埋点组件的情况下，用户可以选择自定义 Reporter。\n自定义 Reporter 实现 public class MyReporter implements Reporter { @Override public String getReporterType() { return \u0026amp;#34;myReporter\u0026amp;#34;; } @Override public void report(SofaTracerSpan sofaTracerSpan) { // System.out 输出  System.out.println(\u0026amp;#34;this is my custom reporter\u0026amp;#34;); } @Override public void close() { // ignore  } } 配置 com.alipay.sofa.tracer.reporter-name=com.glmapper.bridge.boot.flexible.MyReporter 自定义实现 Reporter 可以将业务埋点的日志输出到任何期望的地方。\n","date":-62135596800,"description":"","dir":"projects/sofa-tracer/reporter-custom/","fuzzywordcount":200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"521206c7f4051c1cc8ec8232c20bab6d","permalink":"/projects/sofa-tracer/reporter-custom/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-tracer/reporter-custom/","summary":"在使用自定义埋点组件的情况下，用户可以选择自定义 Reporter。 自定义 Reporter 实现 public class MyReporter implements Reporter { @Override public String getReporterType() { return \u0026#34;myReporter\u0026#34;; } @Override public void report(SofaTracerSpan sofaTracerSpan) { // System.out 输出 System.out.println(\u0026#34;this is my custom reporter\u0026#34;); } @Override","tags":null,"title":"自定义 Reporter","type":"projects","url":"/projects/sofa-tracer/reporter-custom/","wordcount":108},{"author":null,"categories":null,"content":"SOFARPC 支持自定义业务线程池。可以为指定服务设置一个独立的业务线程池，和 SOFARPC 自身的业务线程池是隔离的。多个服务可以共用一个独立的线程池。\nSOFARPC 要求自定义线程池的类型必须是 com.alipay.sofa.rpc.server.UserThreadPool。\nXML 方式 如果采用 XML 的方式发布服务，可以先设定一个 class 为 com.alipay.sofa.rpc.server.UserThreadPool 的线程池的 Bean，然后设置到 \u0026amp;lt;sofa:global-attrs\u0026amp;gt; 标签的 thread-pool-ref 属性中：\n\u0026amp;lt;bean id=\u0026amp;#34;helloService\u0026amp;#34; class=\u0026amp;#34;com.alipay.sofa.rpc.quickstart.HelloService\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;!-- 自定义一个线程池 --\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;#34;customExecutor\u0026amp;#34; class=\u0026amp;#34;com.alipay.sofa.rpc.server.UserThreadPool\u0026amp;#34; init-method=\u0026amp;#34;init\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;#34;corePoolSize\u0026amp;#34; value=\u0026amp;#34;10\u0026amp;#34; /\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;#34;maximumPoolSize\u0026amp;#34; value=\u0026amp;#34;10\u0026amp;#34; /\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;#34;queueSize\u0026amp;#34; value=\u0026amp;#34;0\u0026amp;#34; /\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt; \u0026amp;lt;sofa:service ref=\u0026amp;#34;helloService\u0026amp;#34; interface=\u0026amp;#34;XXXService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;!-- 将线程池设置给一个 Service --\u0026amp;gt; \u0026amp;lt;sofa:global-attrs thread-pool-ref=\u0026amp;#34;customExecutor\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;/sofa:service\u0026amp;gt; Annotation 方式 如果是采用 Annotation 的方式发布服务，可以通过设置 @SofaServiceBinding 的 userThreadPool 属性来设置自定义线程池的 Bean：\n@SofaService(bindings = {@SofaServiceBinding(bindingType = \u0026amp;#34;bolt\u0026amp;#34;, userThreadPool = \u0026amp;#34;customThreadPool\u0026amp;#34;)}) public class SampleServiceImpl implements SampleService { } 在 Spring 环境使用 API 方式 如果是在 Spring 环境下使用 API 的方式发布服务，可以通过调用 BoltBindingParam 的 setUserThreadPool 方法来设置自定义线程池：\nBoltBindingParam boltBindingParam = new BoltBindingParam(); boltBindingParam.setUserThreadPool(new UserThreadPool()); 在非 Spring 环境下使用 API 方式 如果是在非 Spring 环境下使用 API 的方式，可以通过如下的方式来设置自定义线程池：\nUserThreadPool threadPool = new UserThreadPool(); threadPool.setCorePoolSize(10); threadPool.setMaximumPoolSize(100); threadPool.setKeepAliveTime(200); threadPool.setPrestartAllCoreThreads(false); threadPool.setAllowCoreThreadTimeOut(false); threadPool.setQueueSize(200); UserThreadPoolManager.registerUserThread(ConfigUniqueNameGenerator.getUniqueName(providerConfig), threadPool); 如上为 HelloService 服务设置了一个自定义线程池。\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/custom-threadpool/","fuzzywordcount":500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"3f05f154bcb2b653ebeebb35b84d5ae1","permalink":"/projects/sofa-rpc/custom-threadpool/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/custom-threadpool/","summary":"SOFARPC 支持自定义业务线程池。可以为指定服务设置一个独立的业务线程池，和 SOFARPC 自身的业务线程池是隔离的。多个服务可以共用一个独立的线程池。 SOFARPC 要求自定义","tags":null,"title":"自定义线程池","type":"projects","url":"/projects/sofa-rpc/custom-threadpool/","wordcount":412},{"author":null,"categories":null,"content":"SOFARPC 中对服务地址的选择也抽象为了一条处理链，由每一个 Router 进行处理。同 Filter 一样， SOFARPC 对 Router 提供了同样的扩展能力。\n@Extension(value = \u0026amp;#34;customerRouter\u0026amp;#34;) @AutoActive(consumerSide = true) public class CustomerRouter extends Router { @Override public void init(ConsumerBootstrap consumerBootstrap) { } @Override public boolean needToLoad(ConsumerBootstrap consumerBootstrap) { return true; } @Override public List\u0026amp;lt;ProviderInfo\u0026amp;gt; route(SofaRequest request, List\u0026amp;lt;ProviderInfo\u0026amp;gt; providerInfos) { return providerInfos; } 新建扩展文件 META-INF/services/sofa-rpc/com.alipay.sofa.rpc.client.Router 。内容如下：\ncustomerRouter=com.alipay.sofa.rpc.custom.CustomRouter 如上自定义了一个 CustomerRouter ，生效于所有消费者。其中 init 参数 ConsumerBootstrap 是引用服务的包装类，能够拿到 ConsumerConfig ，代理类，服务地址池等对象。 needToLoad 表示是否生效该 Router ， route 方法即筛选地址的方法。\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/custom-router/","fuzzywordcount":200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"236e8d4bda3e856267a3575853aa900c","permalink":"/projects/sofa-rpc/custom-router/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/custom-router/","summary":"SOFARPC 中对服务地址的选择也抽象为了一条处理链，由每一个 Router 进行处理。同 Filter 一样， SOFARPC 对 Router 提供了同样的扩展能力。 @Extension(value = \u0026#34;customerRouter\u0026#34;) @AutoActive(consumerSide = true) public class CustomerRouter extends Router { @Override public void init(ConsumerBootstrap consumerBootstrap) { } @Override","tags":null,"title":"自定义路由寻址","type":"projects","url":"/projects/sofa-rpc/custom-router/","wordcount":179},{"author":null,"categories":null,"content":"SOFARPC 提供了一套良好的可扩展性机制，为各个模块提供 SPI 的能力。 SOFARPC 对请求与响应的过滤链处理方式是通过多个过滤器 Filter 来进行具体的拦截处理，该部分可由用户自定义 Filter 扩展，自定义 Filter 的执行顺序在内置 Filter 之后。具体方式如下：\nBolt Filter  新建自定义 Filter 。  public class CustomFilter extends Filter { @Override public boolean needToLoad(FilterInvoker invoker) { return true; } @Override public SofaResponse invoke(FilterInvoker invoker, SofaRequest request) throws SofaRpcException { SofaResponse response = invoker.invoke(request); return response; } } 生效该自定义 Filter 到拦截器链中。这一步具体方式有三种。 方式1：API方式。该种方式能够生效到指定的 provider 或 consumer 。  // 服务提供者 providerConfig.setFilterRef(Arrays.asList(new CustomFilter())); // 服务调用者 consumerConfig.setFilterRef(Arrays.asList(new CustomFilter())); 方式2：在类上加上 @Extension 注解+配置扩展文件方式。\n@Extension(\u0026amp;#34;customer\u0026amp;#34;) public class CustomFilter extends Filter { @Override public boolean needToLoad(FilterInvoker invoker) { return true; } @Override public SofaResponse invoke(FilterInvoker invoker, SofaRequest request) throws SofaRpcException { SofaResponse response = invoker.invoke(request); return response; } } 新建扩展文件 META-INF/services/sofa-rpc/com.alipay.sofa.rpc.filter.Filter 。内容如下：\ncustomer=com.alipay.sofa.rpc.custom.CustomFilter 编码注入。\n// 服务提供者 providerConfig.setFilter(Arrays.asList(\u0026amp;#34;customer\u0026amp;#34;)); // 服务调用者 consumerConfig.setFilter(Arrays.asList(\u0026amp;#34;customer\u0026amp;#34;)); 方式三：在类上加上 @Extension 注解+ @AutoActive 注解方式+配扩展文件方式。该种方式利用 @AutoActive 注解代替了上述第二中方式的编码注入步骤，能够生效于所有 provider 或 consumer 。其中 providerSide 参数表示是否生效于服务端， consumerSide 参数表示是否生效于客户端。\n@Extension(\u0026amp;#34;customer\u0026amp;#34;) @AutoActive(providerSide = true, consumerSide = true) public class customerFilter extends Filter { // ... } ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/custom-filter/","fuzzywordcount":500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"30ff5937b52a7c2dd8028e878979a33d","permalink":"/projects/sofa-rpc/custom-filter/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/custom-filter/","summary":"SOFARPC 提供了一套良好的可扩展性机制，为各个模块提供 SPI 的能力。 SOFARPC 对请求与响应的过滤链处理方式是通过多个过滤器 Filter 来进行具体的拦截处理，该部分可由用户","tags":null,"title":"自定义过滤器","type":"projects","url":"/projects/sofa-rpc/custom-filter/","wordcount":409},{"author":null,"categories":null,"content":"本文是对 MOSN 自定义配置的说明。\nDuration String  字符串，由一个十进制数字和一个时间单位后缀组成，有效的时间单位为 ns、us（或µs）、ms、s、m、h，例如 1h、3s、500ms。  metadata metadata 用于 MOSN 路由和 Cluster Host 之间的匹配。\n{ \u0026amp;#34;filter_metadata\u0026amp;#34;:{ \u0026amp;#34;mosn.lb\u0026amp;#34;:{} } } mosn.lb 可对应任意的 string-string 的内容。\ntls_context { \u0026amp;#34;status\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;type\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;server_name\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;ca_cert\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;cert_chain\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;private_key\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;verify_client\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;require_client_cert\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;insecure_skip\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;cipher_suites\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;ecdh_curves\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;min_version\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;max_version\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;alpn\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;fall_back\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;extend_verify\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;sds_source\u0026amp;#34;:{} }  status，bool类型，表示是否开启 TLS，默认是 false。 type，字符串类型，描述 tls_context 的类型。tls_context 支持扩展实现，不同的 type 对应不同的实现方式，默认实现方式对应的 type 是空字符串。 server_name，当没有配置 insecure_skip 时，用于校验服务端返回证书的 hostname。作为Cluster配置时有效。 ca_cert，证书签发的根 CA 证书。 cert_chain，TLS 证书链配置。 private_key，证书私钥配置。 verify_client，bool 类型，作为 Listener 配置时有效，表示是否要校验 Client 端证书 require_client_cert，bool 类型，表示是否强制 Client 端必须携带证书。 insecure_skip，bool 类型，作为 Cluster 配置时有效，表示是否要忽略 Server 端的证书校验。 cipher_suites，如果配置了该配置，那么 TLS 连接将只支持配置了的密码套件，并且会按照配置的顺序作为优先级使用，支持的套件类型如下：  ECDHE-ECDSA-AES256-GCM-SHA384 ECDHE-RSA-AES256-GCM-SHA384 ECDHE-ECDSA-AES128-GCM-SHA256 ECDHE-RSA-AES128-GCM-SHA256 ECDHE-ECDSA-WITH-CHACHA20-POLY1305 ECDHE-RSA-WITH-CHACHA20-POLY1305 ECDHE-RSA-AES256-CBC-SHA ECDHE-RSA-AES128-CBC-SHA ECDHE-ECDSA-AES256-CBC-SHA ECDHE-ECDSA-AES128-CBC-SHA RSA-AES256-CBC-SHA RSA-AES128-CBC-SHA ECDHE-RSA-3DES-EDE-CBC-SHA RSA-3DES-EDE-CBC-SHA ECDHE-RSA-SM4-SM3 ECDHE-ECDSA-SM4-SM3   ecdh_curves，如果配置了该配置，那么 TLS 连接将只支持配置了的曲线。\n   支持 x25519、p256、p384、p521。    min_version，最低的 TLS 协议版本，默认是 TLS1.0。\n   支持 TLS1.0、TLS1.1、TLS1.2。 默认会自动识别可用的 TLS 协议版本。    max_version，最高的 TLS 协议版本，默认是 TLS1.2。\n   支持 TLS1.0、TLS1.1、TLS1.2。 默认会自动识别可用的 TLS 协议版本。    alpn，TLS 的 ALPN 配置。\n   支持 h2、http/1.1、 sofa。    fall_back，bool类型，当配置为 true 时，如果证书解析失败，不会报错而是相当于没有开启 TLS。\n  extend_verify，任意 json 类型，当 type 为非空时，作为扩展的配置参数。\n  sds_source，访问 SDS API 的配置，如果配置了这个配置，ca_cert、cert_chain 和 private_key 都会被忽略，但是其余的配置依然有效。\n  sds_source { \u0026amp;#34;CertificateConfig\u0026amp;#34;:{}, \u0026amp;#34;ValidationConfig\u0026amp;#34;:{} }  CertificateConfig 描述了如何获取 cert_chain 和 private_key 的配置。 ValidationConfig 描述了如何获取 ca_cert 的配置。 详细的 Config 内容参考 envoy: sdssecretconfig。  ","date":-62135596800,"description":"","dir":"projects/mosn/configuration/custom/","fuzzywordcount":1100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"cdad467fd3551e47a7585511278767cd","permalink":"/projects/mosn/configuration/custom/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/mosn/configuration/custom/","summary":"本文是对 MOSN 自定义配置的说明。 Duration String 字符串，由一个十进制数字和一个时间单位后缀组成，有效的时间单位为 ns、us（或µs）、ms、s、m、h，例如","tags":null,"title":"自定义配置说明","type":"projects","url":"/projects/mosn/configuration/custom/","wordcount":1005},{"author":null,"categories":null,"content":"SOFARPC 支持进行框架层面的重试策略，前提是集群模式为 FailOver（SOFARPC 默认即为 FailOver 模式）。重试只有在发生服务端的框架层面异常或者是超时异常才会发起。如果是业务抛出异常，是不会重试的。默认情况下 SOFARPC 不进行任何重试。\n 请注意：超时异常虽然可以重试，但是需要服务端保证业务的幂等性，否则可能会有风险\n XML 方式 如果使用 XML 方式订阅服务，可以设置 sofa:global-attrs 的 retries 参数来设置重试次数：\n\u0026amp;lt;sofa:reference jvm-first=\u0026amp;#34;false\u0026amp;#34; id=\u0026amp;#34;retriesServiceReferenceBolt\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofa.rpc.samples.retries.RetriesService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;sofa:global-attrs retries=\u0026amp;#34;2\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt; Annotation 方式 如果是使用 Annotation 的方式，可以通过设置 @SofaReferenceBinding 注解的 retries 属性来设置：\n@SofaReference(binding = @SofaReferenceBinding(bindingType = \u0026amp;#34;bolt\u0026amp;#34;, retries = 2)) private SampleService sampleService; Spring 环境下 API 方式 如果是在 Spring 环境下用 API 的方式，可以调用 BoltBindingParam 的 setRetries 方法来设置：\nBoltBindingParam boltBindingParam = new BoltBindingParam(); boltBindingParam.setRetries(2); 非 Spring 环境下 API 方式 如果是在非 Spring 环境下直接使用 SOFARPC 的裸 API 的方式，可以通过调用 ConsumerConfig 的 setRetries 方法来设置：\nConsumerConfig\u0026amp;lt;RetriesService\u0026amp;gt; consumerConfig = new ConsumerConfig\u0026amp;lt;RetriesService\u0026amp;gt;(); consumerConfig.setRetries(2); ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/retry-invoke/","fuzzywordcount":400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"d60b44aa8f1b49ab6c1bbc55593a91da","permalink":"/projects/sofa-rpc/retry-invoke/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/retry-invoke/","summary":"SOFARPC 支持进行框架层面的重试策略，前提是集群模式为 FailOver（SOFARPC 默认即为 FailOver 模式）。重试只有在发生服务端的框架层面异常或者是超时","tags":null,"title":"调用重试","type":"projects","url":"/projects/sofa-rpc/retry-invoke/","wordcount":319},{"author":null,"categories":null,"content":"SOFARPC 提供多种负载均衡算法，目前支持以下五种：\n   类型 名称 描述     random 随机算法 默认负载均衡算法。   localPref 本地优先算法 优先发现是否本机发布了该服务，如果没有再采用随机算法。   roundRobin 轮询算法 方法级别的轮询，各个方法间各自轮询，互不影响。   consistentHash 一致性hash算法 同样的方法级别的请求会路由到同样的节点。   weightRoundRobin 按权重负载均衡轮询算法 按照权重对节点进行轮询。性能较差，不推荐使用。    要使用某种特定的负载均衡算法，可以按照以下的方式进行设置：\nXML 方式 如果使用 XML 的方式引用服务，可以通过设置 sofa:global-attrs 标签的 loadBalancer 属性来设置：\n\u0026amp;lt;sofa:reference interface=\u0026amp;#34;com.example.demo.SampleService\u0026amp;#34; id=\u0026amp;#34;sampleService\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;sofa:global-attrs loadBalancer=\u0026amp;#34;roundRobin\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt; Annotation 方式 Annotation 方式目前暂未提供设置某一个 Reference 的负载均衡算法的方式。将在后续的版本中提供。\n在 Spring 环境下 API 方式 如果在 Spring 或者 Spring Boot 的环境下使用 API，可以通过调用 BoltBindingParam 的 setLoadBalancer 方法来设置：\nBoltBindingParam boltBindingParam = new BoltBindingParam(); boltBindingParam.setLoadBalancer(\u0026amp;#34;roundRobin\u0026amp;#34;); 非 Spring 环境下 API 方式 如果在非 Spring 环境下直接使用 SOFARPC 提供的裸 API，可以通过调用 ConsumerConfig 的 setLoadBalancer 方法来设置：\nConsumerConfig consumerConfig = new ConsumerConfig(); consumerConfig.setLoadbalancer(\u0026amp;#34;random\u0026amp;#34;); ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/load-balance/","fuzzywordcount":400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"739984ca9a414429304f85010fd73ad0","permalink":"/projects/sofa-rpc/load-balance/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/load-balance/","summary":"SOFARPC 提供多种负载均衡算法，目前支持以下五种： 类型 名称 描述 random 随机算法 默认负载均衡算法。 localPref 本地优先算法 优先发现是否本机发布了该服务，如果没有再采用","tags":null,"title":"负载均衡","type":"projects","url":"/projects/sofa-rpc/load-balance/","wordcount":375},{"author":null,"categories":null,"content":"任务列表 下面表格记录了还没有实现的功能特性，欢迎大家认领任务，参与贡献。\n   类型 任务 困难度 认领人及时间 计划完成时间 进度 相关 Issue     文档 SOFADashboard 配置参数文档 简单       代码 支持 SOFARegistry 中       代码 支持 Docker 中       代码 支持 Kubernetes 中       代码 支持 Apollo 中       代码 优化前端 中        ","date":-62135596800,"description":"","dir":"projects/sofa-dashboard/roadmap/","fuzzywordcount":200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"a740c874742b504de9011b07f3a4ddb5","permalink":"/projects/sofa-dashboard/roadmap/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-dashboard/roadmap/","summary":"任务列表 下面表格记录了还没有实现的功能特性，欢迎大家认领任务，参与贡献。 类型 任务 困难度 认领人及时间 计划完成时间 进度 相关 Issue 文档 SOFADashboard 配置参数文档 简","tags":null,"title":"路线图及任务认领","type":"projects","url":"/projects/sofa-dashboard/roadmap/","wordcount":102},{"author":null,"categories":null,"content":"1. registry-meta 1.1 推送开关 在注册中心新版本发布的过程中为了把对业务的影响减少到最小，避免服务端重启动引发大规模服务地址信息变更产生大量推送，我们提供运维层面暂时关闭推送的能力。在服务端完成发布后，可以打开推送恢复正常工作状态，在关闭期间的数据订阅和服务发布信息会再次进行全局推送进行补偿。\n打开推送：\ncurl \u0026amp;#34;http://\u0026amp;lt;meta_ip\u0026amp;gt;:9615/stopPushDataSwitch/close\u0026amp;#34; 关闭推送：\ncurl \u0026amp;#34;http://\u0026amp;lt;meta_ip\u0026amp;gt;:9615/stopPushDataSwitch/open\u0026amp;#34; 1.2 查询地址列表 查看 meta 集群的地址列表：\ncurl \u0026amp;#34;http://\u0026amp;lt;meta_ip\u0026amp;gt;:9615/digest/META/node/query\u0026amp;#34; 查看 data 集群的地址列表：\ncurl \u0026amp;#34;http://\u0026amp;lt;meta_ip\u0026amp;gt;:9615/digest/DATA/node/query\u0026amp;#34; 查看 session 集群的地址列表：\ncurl \u0026amp;#34;http://\u0026amp;lt;meta_ip\u0026amp;gt;:9615/digest/SESSION/node/query\u0026amp;#34; 1.3 meta 集群扩缩容 1.3.1 修改集群：changePeer 修改 raft 集群列表，当有扩容或缩容时，可以调用该 API，对集群列表进行修改，这样才能将扩容节点或缩容节点，正确地添加到或移除出集群：\ncurl -X POST \u0026amp;#34;http://\u0026amp;lt;meta_ip\u0026amp;gt;:9615/manage/changePeer\u0026amp;#34; -d \u0026amp;#34;ipAddressList=\u0026amp;lt;ip1\u0026amp;gt;,\u0026amp;lt;ip2\u0026amp;gt;,\u0026amp;lt;ip3\u0026amp;gt;\u0026amp;#34; 1.3.2 重置集群：resetPeer 当集群不可用时，例如 3 台机器，宕机 2 台，集群将无法选举。此时可以使用该 API 强制地重置集群列表，比如可以将集群重置为1台机器(唯一可用的那台)，这样可以恢复选举，集群可恢复可用：\ncurl -X POST \u0026amp;#34;http://\u0026amp;lt;meta_ip\u0026amp;gt;:9615/manage/resetPeer\u0026amp;#34; -d \u0026amp;#34;ipAddressList=\u0026amp;lt;ip1\u0026amp;gt;,\u0026amp;lt;ip2\u0026amp;gt;,\u0026amp;lt;ip3\u0026amp;gt;\u0026amp;#34; 2. registry-data 2.1 查询数据 查看 pub 数量：\ncurl \u0026amp;#34;http://\u0026amp;lt;data_ip\u0026amp;gt;:9622/digest/datum/count\u0026amp;#34; 根据客户端的 ip\u0026amp;amp;port 查询其发布的数据：\ncurl -X POST \u0026amp;#34;http://\u0026amp;lt;data_ip\u0026amp;gt;:9622/digest/connect/query\u0026amp;#34; -H \u0026amp;#34;Content-Type: application/json\u0026amp;#34; -d \u0026amp;#39;{\u0026amp;#34;\u0026amp;lt;clientIP\u0026amp;gt;\u0026amp;#34;:\u0026amp;#34;\u0026amp;lt;client端口\u0026amp;gt;\u0026amp;#34;}\u0026amp;#39; 3. registry-session 3.1 查询数据 根据客户端的 ip\u0026amp;amp;port 查询其发布的数据：\ncurl -X POST \u0026amp;#34;http://\u0026amp;lt;session_ip\u0026amp;gt;:9603/digest/pub/connect/query\u0026amp;#34; -H \u0026amp;#34;Content-Type: application/json\u0026amp;#34; -d \u0026amp;#39;[\u0026amp;#34;\u0026amp;lt;clientIP\u0026amp;gt;:\u0026amp;lt;client端口\u0026amp;gt;\u0026amp;#34;]\u0026amp;#39; 根据客户端的 ip\u0026amp;amp;port 查询其订阅的数据：\ncurl -X POST \u0026amp;#34;http://\u0026amp;lt;session_ip\u0026amp;gt;:9603/digest/sub/connect/query\u0026amp;#34; -H \u0026amp;#34;Content-Type: application/json\u0026amp;#34; -d \u0026amp;#39;[\u0026amp;#34;\u0026amp;lt;clientIP\u0026amp;gt;:\u0026amp;lt;client端口\u0026amp;gt;\u0026amp;#34;]\u0026amp;#39; 3.2 断开客户端链接：clientOff 根据客户端的 ip\u0026amp;amp;port 强制删除其所有 sub\u0026amp;amp;pub 数据（但不会断开连接）：\ncurl -X POST \u0026amp;#34;http://\u0026amp;lt;session_ip\u0026amp;gt;:9603/api/clients/off\u0026amp;#34; -H \u0026amp;#34;Content-Type: application/json\u0026amp;#34; -d \u0026amp;#39;{\u0026amp;#34;connectIds\u0026amp;#34;: [\u0026amp;#34;\u0026amp;lt;clientIP\u0026amp;gt;:\u0026amp;lt;client端口\u0026amp;gt;\u0026amp;#34;]}\u0026amp;#39; ","date":-62135596800,"description":"","dir":"projects/sofa-registry/management-api/","fuzzywordcount":800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"2cf59ac422c84c279d73c1f7f1cd0902","permalink":"/projects/sofa-registry/management-api/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-registry/management-api/","summary":"1. registry-meta 1.1 推送开关 在注册中心新版本发布的过程中为了把对业务的影响减少到最小，避免服务端重启动引发大规模服务地址信息变更产生大量推送，我们提供运维","tags":null,"title":"运维命令","type":"projects","url":"/projects/sofa-registry/management-api/","wordcount":773},{"author":null,"categories":null,"content":"SOFARPC 支持不同的通信协议，目前支持 Bolt, RESTful 和 Dubbo，详细的事情请参考各个协议对应的文档：\n Bolt 协议  基本使用 调用方式 超时控制 泛化调用 序列化协议 自定义线程池   RESTful  基本使用 自定义 Filter 集成 Swagger   Dubbo  基本使用   H2C  基本使用    ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/protocol/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"18f51cb12f7a0384a71ab22349292a08","permalink":"/projects/sofa-rpc/protocol/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/protocol/","summary":"SOFARPC 支持不同的通信协议，目前支持 Bolt, RESTful 和 Dubbo，详细的事情请参考各个协议对应的文档： Bolt 协议 基本使用 调用方式 超时控制 泛化调用 序列化协议 自定义线","tags":null,"title":"通信协议","type":"projects","url":"/projects/sofa-rpc/protocol/","wordcount":94},{"author":null,"categories":null,"content":"环境准备 要使用 SOFARegistry，需要先准备好基础环境，SOFARegistry 依赖以下环境：\n Linux/Unix/Mac/Windows JDK8 需要采用 Apache Maven 3.2.5 或者以上的版本来编译  两种部署模式  集成部署模式  将 meta/data/session 三个角色打包集成在一个 jvm 里运行，可单机或集群部署，部署简单。   独立部署模式  将 meta/data/session 三个角色分开部署，每个角色都可以单机或集群部署，可根据实际情况为每个角色部署不同的数量。 生产环境建议使用这种部署模式。    部署步骤 1. 下载源码和编译打包 1.1 下载源码 git clone https://github.com/sofastack/sofa-registry.git cd sofa-registry 1.2 编译打包 mvn clean package -DskipTests 2. 部署注册中心 2.1 集成部署模式 集成部署模式，是将 meta/data/session 三个角色打包集成在一个 JVM 里运行，可单机或集群部署。\n2.1.1 单机部署 集成部署的单机部署模式可以直接参考快速开始-服务端部署部分。\n2.1.2 集群部署  解压 registry-integration.tgz，并修改配置文件  集群部署，即搭建2台以上的集群，建议至少使用3台（注意：目前不支持在同一台机器部署多个 SOFARegistry，因此您必须有3台不同的机器）。在每一台机器上的部署方法同上：\ncp server/distribution/integration/target/registry-integration.tgz \u0026amp;lt;somewhere\u0026amp;gt; cd \u0026amp;lt;somewhere\u0026amp;gt; \u0026amp;amp;\u0026amp;amp; mkdir registry-integration tar -zxvf registry-integration.tgz -C registry-integration 区别是每台机器在部署时需要修改 conf/application.properties 配置：\n# 将3台机器的ip或hostname配置到下方(填入的hostname会被内部解析为ip地址) nodes.metaNode=DefaultDataCenter:\u0026amp;lt;hostname1\u0026amp;gt;,\u0026amp;lt;hostname2\u0026amp;gt;,\u0026amp;lt;hostname3\u0026amp;gt; nodes.localDataCenter=DefaultDataCenter nodes.localRegion=DefaultZone  启动 registry-integration  每台机器都修改以上配置文件后，按照“单机部署”的步骤去启动 registry-integration 即可。\n Linux/Unix/Mac：sh bin/startup.sh。 Windows: 双击 bin 目录下的 startup.bat 运行文件。  确认运行状态：对每一台机器，都可访问三个角色提供的健康监测api，或查看日志 logs/registry-startup.log  # 查看meta角色的健康检测接口：(3台机器，有1台是Leader，其他2台是Follower) $ curl http://localhost:9615/health/check {\u0026amp;#34;success\u0026amp;#34;:true,\u0026amp;#34;message\u0026amp;#34;:\u0026amp;#34;... raftStatus:Leader\u0026amp;#34;} # 查看data角色的健康检测接口： $ curl http://localhost:9622/health/check {\u0026amp;#34;success\u0026amp;#34;:true,\u0026amp;#34;message\u0026amp;#34;:\u0026amp;#34;... status:WORKING\u0026amp;#34;} # 查看session角色的健康检测接口： $ curl http://localhost:9603/health/check {\u0026amp;#34;success\u0026amp;#34;:true,\u0026amp;#34;message\u0026amp;#34;:\u0026amp;#34;...\u0026amp;#34;} 2.2 独立部署模式 独立部署模式，是将 meta/data/session 三个角色分开部署，每个角色都可以单机或集群部署，可根据实际情况为每个角色部署不同的数量，生产环境推荐使用这种部署模式。\n以下介绍 332 模式（即 3 台 meta + 3 台 data + 2 台 session）的部署步骤。\n2.2.1 部署meta  解压 registry-meta.tgz，并修改配置文件  在3台机器上部署 meta 角色。在每一台机器上的部署方法如下：\ncp server/distribution/meta/target/registry-meta.tgz \u0026amp;lt;somewhere\u0026amp;gt; cd \u0026amp;lt;somewhere\u0026amp;gt; \u0026amp;amp;\u0026amp;amp; mkdir registry-meta tar -zxvf registry-meta.tgz -C registry-meta 每台机器在部署时需要修改 conf/application.properties 配置：\n# 将3台meta机器的ip或hostname配置到下方(填入的hostname会被内部解析为ip地址) nodes.metaNode=DefaultDataCenter:\u0026amp;lt;meta_hostname1\u0026amp;gt;,\u0026amp;lt;meta_hostname2\u0026amp;gt;,\u0026amp;lt;meta_hostname3\u0026amp;gt; nodes.localDataCenter=DefaultDataCenter  启动 registry-meta  Linux/Unix/Mac：sh bin/startup.sh。 Windows: 双击 bin 目录下的 startup.bat 运行文件。    确认运行状态：对每一台机器，都可访问meta提供的健康监测api，或查看日志 logs/registry-startup.log  # 查看 meta 角色的健康检测接口：(3台机器，有1台是 Leader，其他2台是 Follower) $ curl http://localhost:9615/health/check {\u0026amp;#34;success\u0026amp;#34;:true,\u0026amp;#34;message\u0026amp;#34;:\u0026amp;#34;... raftStatus:Leader\u0026amp;#34;} 2.2.2 部署data  解压 registry-data.tgz，并修改配置文件  在3台机器上部署 data 角色。在每一台机器上的部署方法如下：\ncp server/distribution/data/target/registry-data.tgz \u0026amp;lt;somewhere\u0026amp;gt; cd \u0026amp;lt;somewhere\u0026amp;gt; \u0026amp;amp;\u0026amp;amp; mkdir registry-data tar -zxvf registry-data.tgz -C registry-data 每台 …","date":-62135596800,"description":"","dir":"projects/sofa-registry/deployment/","fuzzywordcount":1600,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"7e28583bc38be66af8d704d7fbcd9dd4","permalink":"/projects/sofa-registry/deployment/","publishdate":"0001-01-01T00:00:00Z","readingtime":4,"relpermalink":"/projects/sofa-registry/deployment/","summary":"环境准备 要使用 SOFARegistry，需要先准备好基础环境，SOFARegistry 依赖以下环境： Linux/Unix/Mac/Windows JDK8 需要采用 Apache Maven 3.2.5 或者以上的版本来编译 两","tags":null,"title":"部署","type":"projects","url":"/projects/sofa-registry/deployment/","wordcount":1578},{"author":null,"categories":null,"content":"MOSN 的配置文件可以分为以下四大部分：\n Servers 配置，目前仅支持最多 1 个 Server 的配置，Server 中包含一些基础配置以及对应的 Listener 配置 ClusterManager 配置，包含 MOSN 的 Upstream 详细信息 对接控制平面（Pilot）的 xDS 相关配置 其他配置  Trace、Metrics、Debug、Admin API 相关配置 扩展配置，提供自定义配置扩展需求    配置文件概览\nMOSN 的基本配置部分如下所示：\n{ \u0026amp;#34;servers\u0026amp;#34;: [], \u0026amp;#34;cluster_manager\u0026amp;#34;: {}, \u0026amp;#34;dynamic_resources\u0026amp;#34;: {}, \u0026amp;#34;static_resources\u0026amp;#34;: {}, \u0026amp;#34;admin\u0026amp;#34;:{}, \u0026amp;#34;pprof\u0026amp;#34;:{}, \u0026amp;#34;tracing\u0026amp;#34;:{}, \u0026amp;#34;metrics\u0026amp;#34;:{} } 配置类型 MOSN 的配置包括以下几种类型：\n 静态配置 动态配置 混合模式  静态配置  静态配置是指 MOSN 启动时，不对接控制平面 Pilot 的配置，用于一些相对固定的简单场景（如 MOSN 的示例）。 使用静态配置启动的 MOSN，也可以通过扩展代码，调用动态更新配置的接口实现动态修改。 静态配置启动时必须包含一个 Server 以及至少一个 Cluster。  动态配置   动态配置是指 MOSN 启动时，只有访问控制平面相关的配置，没有 MOSN 运行时所需要的配置。\n  使用动态配置启动的 MOSN，会向管控面请求获取运行时所需要的配置，管控面也可能在运行时推送更新 MOSN 运行配置。\n  动态配置启动时必须包含 DynamicResources 和 StaticResources 配置。\n  混合模式 MOSN 启动时的配置可以同时包含静态模式与动态模式，以混合模式启动的 MOSN 会先以静态配置完成初始化，随后可能由控制平面获取配置更新。\n配置示例 静态配置示例 动态配置的示例如下所示。\n{ \u0026amp;#34;servers\u0026amp;#34;: [ { \u0026amp;#34;default_log_path\u0026amp;#34;: \u0026amp;#34;/home/admin/logs/mosn/default.log\u0026amp;#34;, \u0026amp;#34;default_log_level\u0026amp;#34;: \u0026amp;#34;DEBUG\u0026amp;#34;, \u0026amp;#34;processor\u0026amp;#34;: 4, \u0026amp;#34;listeners\u0026amp;#34;: [ { \u0026amp;#34;address\u0026amp;#34;: \u0026amp;#34;0.0.0.0:12220\u0026amp;#34;, \u0026amp;#34;bind_port\u0026amp;#34;: true, \u0026amp;#34;filter_chains\u0026amp;#34;: [ { \u0026amp;#34;filters\u0026amp;#34;: [ { \u0026amp;#34;type\u0026amp;#34;: \u0026amp;#34;proxy\u0026amp;#34;, \u0026amp;#34;config\u0026amp;#34;: { \u0026amp;#34;downstream_protocol\u0026amp;#34;: \u0026amp;#34;SofaRpc\u0026amp;#34;, \u0026amp;#34;upstream_protocol\u0026amp;#34;: \u0026amp;#34;SofaRpc\u0026amp;#34;, \u0026amp;#34;router_config_name\u0026amp;#34;: \u0026amp;#34;test_router\u0026amp;#34; } }, { \u0026amp;#34;type\u0026amp;#34;: \u0026amp;#34;connection_manager\u0026amp;#34;, \u0026amp;#34;config\u0026amp;#34;: { \u0026amp;#34;router_config_name\u0026amp;#34;: \u0026amp;#34;test_router\u0026amp;#34;, \u0026amp;#34;virtual_hosts\u0026amp;#34;: [] } } ] } ] } ] } ], \u0026amp;#34;cluster_manager\u0026amp;#34;: { \u0026amp;#34;clusters\u0026amp;#34;: [ { \u0026amp;#34;name\u0026amp;#34;:\u0026amp;#34;example\u0026amp;#34;, \u0026amp;#34;lb_type\u0026amp;#34;: \u0026amp;#34;LB_ROUNDROBIN\u0026amp;#34;, \u0026amp;#34;hosts\u0026amp;#34;: [ {\u0026amp;#34;address\u0026amp;#34;: \u0026amp;#34;127.0.0.1:12200\u0026amp;#34;} ] } ] } } 动态配置示例 静态配置的示例如下所示。\n{ \u0026amp;#34;dynamic_resources\u0026amp;#34;: { \u0026amp;#34;ads_config\u0026amp;#34;: { \u0026amp;#34;api_type\u0026amp;#34;: \u0026amp;#34;GRPC\u0026amp;#34;, \u0026amp;#34;grpc_services\u0026amp;#34;: [ { \u0026amp;#34;envoy_grpc\u0026amp;#34;: {\u0026amp;#34;cluster_name\u0026amp;#34;: \u0026amp;#34;xds-grpc\u0026amp;#34;} } ] } } }, \u0026amp;#34;static_resources\u0026amp;#34;: { \u0026amp;#34;clusters\u0026amp;#34;: [ { \u0026amp;#34;name\u0026amp;#34;: \u0026amp;#34;xds-grpc\u0026amp;#34;, \u0026amp;#34;type\u0026amp;#34;: \u0026amp;#34;STRICT_DNS\u0026amp;#34;, \u0026amp;#34;connect_timeout\u0026amp;#34;: \u0026amp;#34;10s\u0026amp;#34;, \u0026amp;#34;lb_policy\u0026amp;#34;: \u0026amp;#34;ROUND_ROBIN\u0026amp;#34;, \u0026amp;#34;hosts\u0026amp;#34;: [ { \u0026amp;#34;socket_address\u0026amp;#34;: {\u0026amp;#34;address\u0026amp;#34;: \u0026amp;#34;pilot\u0026amp;#34;, \u0026amp;#34;port_value\u0026amp;#34;: 15010} } ], \u0026amp;#34;upstream_connection_options\u0026amp;#34;: { \u0026amp;#34;tcp_keepalive\u0026amp;#34;: { \u0026amp;#34;keepalive_time\u0026amp;#34;: 300 } }, \u0026amp;#34;http2_protocol_options\u0026amp;#34;: { } } ] } } ","date":-62135596800,"description":"","dir":"projects/mosn/configuration/overview/","fuzzywordcount":700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"0aa65950d2c24e8ce86d265bea275e2a","permalink":"/projects/mosn/configuration/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/mosn/configuration/overview/","summary":"MOSN 的配置文件可以分为以下四大部分： Servers 配置，目前仅支持最多 1 个 Server 的配置，Server 中包含一些基础配置以及对应的 Listener 配置 ClusterManager 配置，包含 MOSN 的 Upstream 详细信","tags":null,"title":"配置概览","type":"projects","url":"/projects/mosn/configuration/overview/","wordcount":663},{"author":null,"categories":null,"content":"目前 SOFATracer 提供了两种采样模式，一种是基于 BitSet 实现的基于固定采样率的采样模式；另外一种是提供给用户自定义实现采样的采样模式。下面通过案例来演示如何使用。\n本示例基于 tracer-sample-with-springmvc 工程；除 application.properties 之外，其他均相同。\n基于固定采样率的采样模式 在 application.properties 中增加采样相关配置项 #采样率 0~100 com.alipay.sofa.tracer.samplerPercentage=100 #采样模式类型名称 com.alipay.sofa.tracer.samplerName=PercentageBasedSampler 验证方式  当采样率设置为100时，每次都会打印摘要日志。 当采样率设置为0时，不打印 当采样率设置为0~100之间时，按概率打印  以请求 10 次来验证下结果。\n1、当采样率设置为100时，每次都会打印摘要日志\n启动工程，浏览器中输入：http://localhost:8080/springmvc ；并且刷新地址10次，查看日志如下：\n{\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2018-11-09 11:54:47.643\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;SOFATracerSpringMVC\u0026amp;#34;,\u0026amp;#34;traceId\u0026amp;#34;:\u0026amp;#34;0a0fe8ec154173568757510019269\u0026amp;#34;,\u0026amp;#34;spanId\u0026amp;#34;:\u0026amp;#34;0.1\u0026amp;#34;,\u0026amp;#34;request.url\u0026amp;#34;:\u0026amp;#34;http://localhost:8080/springmvc\u0026amp;#34;,\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;GET\u0026amp;#34;,\u0026amp;#34;result.code\u0026amp;#34;:\u0026amp;#34;200\u0026amp;#34;,\u0026amp;#34;req.size.bytes\u0026amp;#34;:-1,\u0026amp;#34;resp.size.bytes\u0026amp;#34;:0,\u0026amp;#34;time.cost.milliseconds\u0026amp;#34;:68,\u0026amp;#34;current.thread.name\u0026amp;#34;:\u0026amp;#34;http-nio-8080-exec-1\u0026amp;#34;,\u0026amp;#34;baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;} {\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2018-11-09 11:54:50.980\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;SOFATracerSpringMVC\u0026amp;#34;,\u0026amp;#34;traceId\u0026amp;#34;:\u0026amp;#34;0a0fe8ec154173569097710029269\u0026amp;#34;,\u0026amp;#34;spanId\u0026amp;#34;:\u0026amp;#34;0.1\u0026amp;#34;,\u0026amp;#34;request.url\u0026amp;#34;:\u0026amp;#34;http://localhost:8080/springmvc\u0026amp;#34;,\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;GET\u0026amp;#34;,\u0026amp;#34;result.code\u0026amp;#34;:\u0026amp;#34;200\u0026amp;#34;,\u0026amp;#34;req.size.bytes\u0026amp;#34;:-1,\u0026amp;#34;resp.size.bytes\u0026amp;#34;:0,\u0026amp;#34;time.cost.milliseconds\u0026amp;#34;:3,\u0026amp;#34;current.thread.name\u0026amp;#34;:\u0026amp;#34;http-nio-8080-exec-2\u0026amp;#34;,\u0026amp;#34;baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;} {\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2018-11-09 11:54:51.542\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;SOFATracerSpringMVC\u0026amp;#34;,\u0026amp;#34;traceId\u0026amp;#34;:\u0026amp;#34;0a0fe8ec154173569153910049269\u0026amp;#34;,\u0026amp;#34;spanId\u0026amp;#34;:\u0026amp;#34;0.1\u0026amp;#34;,\u0026amp;#34;request.url\u0026amp;#34;:\u0026amp;#34;http://localhost:8080/springmvc\u0026amp;#34;,\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;GET\u0026amp;#34;,\u0026amp;#34;result.code\u0026amp;#34;:\u0026amp;#34;200\u0026amp;#34;,\u0026amp;#34;req.size.bytes\u0026amp;#34;:-1,\u0026amp;#34;resp.size.bytes\u0026amp;#34;:0,\u0026amp;#34;time.cost.milliseconds\u0026amp;#34;:3,\u0026amp;#34;current.thread.name\u0026amp;#34;:\u0026amp;#34;http-nio-8080-exec-4\u0026amp;#34;,\u0026amp;#34;baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;} {\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2018-11-09 11:54:52.061\u0026amp;#34;,\u0026amp;#34;local.app\u0026amp;#34;:\u0026amp;#34;SOFATracerSpringMVC\u0026amp;#34;,\u0026amp;#34;traceId\u0026amp;#34;:\u0026amp;#34;0a0fe8ec154173569205910069269\u0026amp;#34;,\u0026amp;#34;spanId\u0026amp;#34;:\u0026amp;#34;0.1\u0026amp;#34;,\u0026amp;#34;request.url\u0026amp;#34;:\u0026amp;#34;http://localhost:8080/springmvc\u0026amp;#34;,\u0026amp;#34;method\u0026amp;#34;:\u0026amp;#34;GET\u0026amp;#34;,\u0026amp;#34;result.code\u0026amp;#34;:\u0026amp;#34;200\u0026amp;#34;,\u0026amp;#34;req.size.bytes\u0026amp;#34;:-1,\u0026amp;#34;resp.size.bytes\u0026amp;#34;:0,\u0026amp;#34;time.cost.milliseconds\u0026amp;#34;:2,\u0026amp;#34;current.thread.name\u0026amp;#34;:\u0026amp;#34;http-nio-8080-exec-6\u0026amp;#34;,\u0026amp;#34;baggage\u0026amp;#34;:\u0026amp;#34;\u0026amp;#34;} {\u0026amp;#34;time\u0026amp;#34;:\u0026amp;#34;2018-11-09 …","date":-62135596800,"description":"","dir":"projects/sofa-tracer/sampler/","fuzzywordcount":800,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"48856a040da01abc84213934c1c5fce4","permalink":"/projects/sofa-tracer/sampler/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-tracer/sampler/","summary":"目前 SOFATracer 提供了两种采样模式，一种是基于 BitSet 实现的基于固定采样率的采样模式；另外一种是提供给用户自定义实现采样的采样模式。下面通过案例来演示如何使","tags":null,"title":"采样模式","type":"projects","url":"/projects/sofa-tracer/sampler/","wordcount":718},{"author":null,"categories":null,"content":"链路数据透传 链路数据透传功能支持应用向调用上下文中存放数据，达到整个链路上的应用都可以操作该数据。 使用方式如下，可分别向链路的 request 和 response 中放入数据进行透传，并可获取到链路中相应的数据。\nRpcInvokeContext.getContext().putRequestBaggage(\u0026amp;#34;key_request\u0026amp;#34;,\u0026amp;#34;value_request\u0026amp;#34;); RpcInvokeContext.getContext().putResponseBaggage(\u0026amp;#34;key_response\u0026amp;#34;,\u0026amp;#34;value_response\u0026amp;#34;); String requestValue=RpcInvokeContext.getContext().getRequestBaggage(\u0026amp;#34;key_request\u0026amp;#34;); String responseValue=RpcInvokeContext.getContext().getResponseBaggage(\u0026amp;#34;key_response\u0026amp;#34;); 使用示例 例如 A -\u0026amp;gt; B -\u0026amp;gt; C 的场景中，将 A 设置的请求隐式传参数据传递给 B 和 C。在返回的时候，将 C 和 B 的响应隐式传参数据传递给 A。\nA 请求方设置的时候：\n// 调用前设置请求透传的值 RpcInvokeContext context = RpcInvokeContext.getContext(); context.putRequestBaggage(\u0026amp;#34;reqBaggageB\u0026amp;#34;, \u0026amp;#34;a2bbb\u0026amp;#34;); // 调用 String result = service.hello(); // 拿到结果透传的值 context.getResponseBaggage(\u0026amp;#34;respBaggageB\u0026amp;#34;); B 业务代码中：\npublic String hello() { // 拿到请求透传的值  RpcInvokeContext context = RpcInvokeContext.getContext(); String reqBaggage = context.getRequestBaggage(\u0026amp;#34;reqBaggageB\u0026amp;#34;); //  doSomthing(); // 结果透传一个值  context.putResponseBaggage(\u0026amp;#34;respBaggageB\u0026amp;#34;, \u0026amp;#34;b2aaa\u0026amp;#34;); return result; } 如果中途自己启动了子线程，则需要设置子线程的上下文：\nCountDownLatch latch = new CountDownLatch(1); final RpcInvokeContext parentContext = RpcInvokeContext.peekContext(); Thread thread = new Thread(new Runnable(){ public void run(){ try { RpcInvokeContext.setContext(parentContext); // 调一个远程服务 \txxxService.sayHello(); latch.countDown(); } finally { RpcInvokeContext.removeContext(); } } }, \u0026amp;#34;new-thread\u0026amp;#34;); thread.start(); // 此时拿不到返回值透传的数据的 latch.await(); //等待 // 此时返回结束，能拿到返回透传的值 和 SOFATracer 的比较 SOFATracer 是蚂蚁开源的一个分布式链路追踪系统,RPC 目前已经和 Tracer 做了集成,默认开启. 和 Tracer 进行数据传递不同的是\n RPC的数据透传更偏向业务使用,而且可以在全链路中进行双向传递,调用方可以传给服务方,服务方也可以传递信息给调用方,SOFATracer 更加偏向于中间件和业务无感知的数据的传递,只能进行单向传递. RPC的透传可以选择性地不在全链路中透传,而Tracer 中如果传递大量信息,会在整个链路中传递.可能对下游业务会有影响.  所以整体来看,两个信息各有利弊,在有一些和业务相关的透传数据的情况下,可以选择 RPC 的透传.\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/invoke-chain-pass-data/","fuzzywordcount":700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"96cfb41f07a6a2ad979b53093ff5eee9","permalink":"/projects/sofa-rpc/invoke-chain-pass-data/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-rpc/invoke-chain-pass-data/","summary":"链路数据透传 链路数据透传功能支持应用向调用上下文中存放数据，达到整个链路上的应用都可以操作该数据。 使用方式如下，可分别向链路的 request 和 response 中放入数","tags":null,"title":"链路数据透传","type":"projects","url":"/projects/sofa-rpc/invoke-chain-pass-data/","wordcount":606},{"author":null,"categories":null,"content":"默认 SOFARPC 已经集成了 SOFATracer，用户也可以使用其他的 APM 产品，如 Skywalking来实现相应的功能。详见文档：\n SOFATracer Skywalking  如果想要关闭 SOFARPC 的链路追踪能力的话，在使用了 rpc-sofa-boot-starter 的情况下，可以在 application.properties 配置文件中配置 com.alipay.sofa.rpc.defaultTracer=。\n在直接使用 sofa-rpc-all 的情况下，可以在 main 函数里面加上如下的代码来关闭 SOFARPC 的链路追踪的能力（在发布任何 SOFARPC 的服务或者引用任何 SOFARPC 的服务之前）：\nRpcConfigs.putValue(RpcOptions.DEFAULT_TRACER, \u0026amp;#34;\u0026amp;#34;); ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/tracing-usage/","fuzzywordcount":200,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"5f944f87d827ae060fb0528f6715af97","permalink":"/projects/sofa-rpc/tracing-usage/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/tracing-usage/","summary":"默认 SOFARPC 已经集成了 SOFATracer，用户也可以使用其他的 APM 产品，如 Skywalking来实现相应的功能。详见文档： SOFATracer Skywalking 如果想要关闭 SOFARPC 的链路","tags":null,"title":"链路追踪","type":"projects","url":"/projects/sofa-rpc/tracing-usage/","wordcount":197},{"author":null,"categories":null,"content":"从 rpc-sofa-boot-starter 6.0.1 版本开始，SOFARPC 提供了 RESTful 服务和 Swagger 的一键集成的能力。\n在使用了 rpc-sofa-boot-starter 的情况下，如果想要开启 swagger 的能力，首先需要在 pom.xml 中增加 Swagger 的依赖：\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;io.swagger.core.v3\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;swagger-jaxrs2\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.0.0\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.google.guava\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;guava\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;20.0\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 然后在 application.properties 里面增加 com.alipay.sofa.rpc.restSwagger=true。\n最后，访问 http://localhost:8341/swagger/openapi 就可以拿到 SOFARPC 的 RESTful 的 Swagger OpenAPI 内容。\n如果没有使用 rpc-sofa-boot-starter 或者在 rpc-sofa-boot-starter 的版本低于 6.0.1，可以采用如下的方式集成 Swagger。\n首先，需要在应用中引入 Swagger 相关的依赖，由于 SOFARPC 的 RESTful 协议走的是 JAXRS 标准，因此我们引入 Swagger 的 JAXRS 依赖即可：\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;io.swagger.core.v3\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;swagger-jaxrs2\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.0.0\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.google.guava\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;guava\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;20.0\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 上面引入 Guava 的 20.0 的版本是为了解决 Guava 的版本冲突。\n增加一个 Swagger 的 RESTful 服务 为了能够让 Swagger 将 SOFARPC 的 RESTful 的服务通过 Swagger OpenAPI 暴露出去，我们可以反过来用 SOFARPC 的 RESTful 的服务提供 Swagger 的 OpenAPI 服务。首先，需要新建一个接口：\n@Path(\u0026amp;#34;swagger\u0026amp;#34;) public interface OpenApiService { @GET @Path(\u0026amp;#34;openapi\u0026amp;#34;) @Produces(\u0026amp;#34;application/json\u0026amp;#34;) String openApi(); } 然后提供一个实现类，并且发布成 SOFARPC 的 RESTful 的服务：\n@Service @SofaService(bindings = {@SofaServiceBinding(bindingType = \u0026amp;#34;rest\u0026amp;#34;)}, interfaceType = OpenApiService.class) public class OpenApiServiceImpl implements OpenApiService, InitializingBean { private OpenAPI openAPI; @Override public String openApi() { return Json.pretty(openAPI); } @Override public void afterPropertiesSet() { List\u0026amp;lt;Package\u0026amp;gt; resources = new ArrayList\u0026amp;lt;\u0026amp;gt;(); resources.add(this.getClass().getPackage()); // 扫描当前类所在的 Package，也可以扫描其他的 SOFARPC RESTful 服务接口所在的 Package  if (!resources.isEmpty()) { // init context  try { SwaggerConfiguration oasConfig = new SwaggerConfiguration() .resourcePackages(resources.stream().map(Package::getName).collect(Collectors.toSet())); OpenApiContext oac = new JaxrsOpenApiContextBuilder() .openApiConfiguration(oasConfig) .buildContext(true); openAPI = oac.read(); } catch (OpenApiConfigurationException e) { throw new RuntimeException(e.getMessage(), e); } } } } 这样，应用启动后，访问 http://localhost:8341/swagger/openapi 即可得到当前的应用发布的所有的 RESTful 的服务的信息。\n解决跨域问题 如果用户在另外一个端口中启动了一个 Swagger UI，并且希望通过 Swagger UI 来访问 http://localhost:8341/swagger/openapi 查看 API 定义，发起调用，那么可能需要解决访问跨域的问题，要解决 SOFARPC RESTful 服务访问跨域的问题，可以在应用启动前增加如下的代码：\nimport org.jboss.resteasy.plugins.interceptors.CorsFilter; public static void main(String[] args) { CorsFilter corsFilter = new CorsFilter(); corsFilter.getAllowedOrigins().add(\u0026amp;#34;*\u0026amp;#34;); …","date":-62135596800,"description":"","dir":"projects/sofa-rpc/restful-swagger/","fuzzywordcount":700,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"d068767fe0dd2922eecef69736684be8","permalink":"/projects/sofa-rpc/restful-swagger/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/sofa-rpc/restful-swagger/","summary":"从 rpc-sofa-boot-starter 6.0.1 版本开始，SOFARPC 提供了 RESTful 服务和 Swagger 的一键集成的能力。 在使用了 rpc-sofa-boot-starter 的情况下，如果想要开启 swagger 的能力，首先需要在 pom.xml 中增加 Swagger 的依赖： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.swagger.core.v3\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;swagger-jaxrs2\u0026lt;/artifactId\u0026gt;","tags":null,"title":"集成 SOFARPC RESTful 服务和 Swagger","type":"projects","url":"/projects/sofa-rpc/restful-swagger/","wordcount":646},{"author":null,"categories":null,"content":"服务发布 服务发布过程涉及到三个类 RegistryConfig ，ServerConfig ，ProviderConfig 。\n1. RegistryConfig\nRegistryConfig registryConfig = new RegistryConfig() .setProtocol(\u0026amp;#34;zookeeper\u0026amp;#34;) .setAddress(\u0026amp;#34;127.0.0.1:2181\u0026amp;#34;) RegistryConfig 表示注册中心。如上声明了服务注册中心的地址和端口是127.0.0.1:2181，协议是 Zookeeper。\n2. ServerConfig\nServerConfig serverConfig = new ServerConfig() .setPort(8803) .setProtocol(\u0026amp;#34;bolt\u0026amp;#34;); ServerConfig 表示服务运行容器。如上声明了一个使用8803端口和 bolt 协议的 server 。\n3. ProviderConfig\nProviderConfig\u0026amp;lt;HelloWorldService\u0026amp;gt; providerConfig = new ProviderConfig\u0026amp;lt;HelloWorldService\u0026amp;gt;() .setInterfaceId(HelloWorldService.class.getName()) .setRef(new HelloWorldServiceImpl()) .setServer(serverConfig) .setRegistry(registryConfig); providerConfig.export(); ProviderConfig 表示服务发布。如上声明了服务的接口，实现和该服务运行的 server 。 最终通过 export 方法将这个服务发布出去了。\n服务引用 服务引用涉及到两个类， RegistryConfig 和 ConsumerConfig 。\nConsumerConfig\u0026amp;lt;HelloService\u0026amp;gt; consumerConfig = new ConsumerConfig\u0026amp;lt;HelloService\u0026amp;gt;() .setInterfaceId(HelloService.class.getName()) .setRegistry(registryConfig); HelloService helloService = consumerConfig.refer(); ConsumerConfig 表示服务引用，如上声明了所引用服务的接口和服务注册中心。 最终通过 refer 方法将这个服务引用，获取到该服务的远程调用的代理。\n","date":-62135596800,"description":"","dir":"projects/sofa-rpc/programing-rpc/","fuzzywordcount":400,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"ee6f74a4974c7abf72322cef108d5ef0","permalink":"/projects/sofa-rpc/programing-rpc/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/programing-rpc/","summary":"服务发布 服务发布过程涉及到三个类 RegistryConfig ，ServerConfig ，ProviderConfig 。 1. RegistryConfig RegistryConfig registryConfig = new RegistryConfig() .setProtocol(\u0026#34;zookeeper\u0026#34;) .setAddress(\u0026#34;127.0.0.1:2181\u0026#34;) RegistryConfig 表示注册中心。如上声明了服务","tags":null,"title":"非 Spring 环境 API 使用","type":"projects","url":"/projects/sofa-rpc/programing-rpc/","wordcount":300},{"author":null,"categories":null,"content":"预热权重功能让客户端机器能够根据服务端的相应权重进行流量的分发。该功能也常被用于集群内少数机器的启动场景。利用流量权重功能在短时间内对服务端机器进行预热，然后再接收正常的流量比重。 运行机制如下： 1.服务端服务在启动时会将自身的预热时间，预热期内权重，预热完成后的正常权重推送给服务注册中心。如上图 ServiceB 指向 Service Registry 。\n2.客户端在引用服务的时候会获得每个服务实例的预热权重信息。如上图 Service Registry 指向 client 。\n3.客户端在进行调用的时候会根据服务所在地址的预热时期所对应的权重进行流量分发。如上图 client 指向 ServiceA 和 ServiceB 。 ServiceA 预热完毕，权重默认 100 ， ServiceB 处于预热期，权重为 10，因此所承受流量分别为 100%110 和 10%110 。\n该功能使用方式如下。\nProviderConfig\u0026amp;lt;HelloWordService\u0026amp;gt; providerConfig = new ProviderConfig\u0026amp;lt;HelloWordService\u0026amp;gt;() .setWeight(100) .setParameter(ProviderInfoAttrs.ATTR_WARMUP_WEIGHT,\u0026amp;#34;10\u0026amp;#34;) .setParameter(ProviderInfoAttrs.ATTR_WARM_UP_END_TIME,\u0026amp;#34;12000\u0026amp;#34;); 如上，该服务的预热期为12s，在预热期内权重为10，预热期结束后的正常权重为100。如果该服务一共发布在两个机器A,B上，A机器正处于预热期内，并使用上述配置，B已经完成预热，正常权重为200。那么客户端在调用的时候，此时流量分发的比重为10：200，A机器预热结束后，流量分发比重为100：200。 在SOFABoot中，如下配置预热时间，预热期间权重和预热完后的权重即可。\n\u0026amp;lt;sofa:reference id=\u0026amp;#34;sampleRestFacadeReferenceBolt\u0026amp;#34; interface=\u0026amp;#34;com.alipay.sofa.endpoint.facade.SampleFacade\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;sofa:global-attrs weight=\u0026amp;#34;100\u0026amp;#34; warm-up-time=\u0026amp;#34;10000\u0026amp;#34; warm-up-weight=\u0026amp;#34;1000\u0026amp;#34;/\u0026amp;gt; \u0026amp;lt;/sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt; ","date":-62135596800,"description":"","dir":"projects/sofa-rpc/provider-warmup-weight/","fuzzywordcount":500,"kind":"page","lang":"zh","lastmod":1611070649,"objectID":"b9e320dfaa4f9700ecdca67d76e07d54","permalink":"/projects/sofa-rpc/provider-warmup-weight/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/sofa-rpc/provider-warmup-weight/","summary":"预热权重功能让客户端机器能够根据服务端的相应权重进行流量的分发。该功能也常被用于集群内少数机器的启动场景。利用流量权重功能在短时间内对服务端","tags":null,"title":"预热权重","type":"projects","url":"/projects/sofa-rpc/provider-warmup-weight/","wordcount":497}]