[{"author":"nuo-promise","categories":"Soul","content":" 目标  Apache Dubbo 插件介绍  元数据介绍  Apache Dubbo 插件配置  Bootstrap pom 配置 soul-admin 配置 dubbo服务pom配置  Apache Dubbo 泛化调用介绍  通过API方式使用泛化调用 通过spring使用泛化调用 泛化调用实现流程  Soul Dubbo 插件调用解析  ApachDubboPlugin泛化调用准备 ApacheDubboProxySerivce DubboResponsePlugin WebFluxResultUtils返回结果  Dubbo泛化调用介绍 总结 参考\nApache Dubbo 插件介绍 Apache Dubbo 是一款高性能、轻量级的开源Java服务框架,主要提供了六大核心能力,面向接口代理的高性能RPC调用,智能容错和负载均衡,服务自动注册与发现,高度可扩展能力,运行期流量调度,可视化的服务治理与运维。 网关中Dubbo插件主要是将 Http协议 转换成 Dubbo协议 ,也是网关实现Dubbo泛化调用的关键。而Dubbo插件需要配合 元数据 才能实现Dubbo调用。\n元数据介绍 元数据作用就是在进行协议转换时候要获取真实的请求 path 、methodName 、 parameterTypes 为泛化调用做好准备\n   在数据库中,我们有一张表单独存储Dubbo元信息，通过数据同步方案,会把这张表的数据同步到网关的JVM内存中 表结构如下\nCREATE TABLE IF NOT EXISTS `meta_data` ( `id` varchar(128) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NOT NULL COMMENT \u0026#39;id\u0026#39;, `app_name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NOT NULL COMMENT \u0026#39;应用名称\u0026#39;, `path` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NOT NULL COMMENT \u0026#39;路径,不能重复\u0026#39;, `path_desc` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NOT NULL COMMENT \u0026#39;路径描述\u0026#39;, `rpc_type` varchar(64) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NOT NULL COMMENT \u0026#39;rpc类型\u0026#39;, `service_name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NULL DEFAULT NULL COMMENT \u0026#39;服务名称\u0026#39;, `method_name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NULL DEFAULT NULL COMMENT \u0026#39;方法名称\u0026#39;, `parameter_types` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NULL DEFAULT NULL COMMENT \u0026#39;参数类型 多个参数类型 逗号隔开\u0026#39;, `rpc_ext` varchar(1024) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NULL DEFAULT NULL COMMENT \u0026#39;rpc的扩展信息，json格式\u0026#39;, `date_created` datetime(0) NOT NULL COMMENT \u0026#39;创建时间\u0026#39;, `date_updated` datetime(0) NOT NULL ON UPDATE CURRENT_TIMESTAMP(0) COMMENT \u0026#39;更新时间\u0026#39;, `enabled` tinyint(4) NOT NULL DEFAULT 0 COMMENT \u0026#39;启用状态\u0026#39;, PRIMARY KEY (`id`) USING BTREE ) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_unicode_ci ROW_FORMAT = Dynamic;   path 字段主要是在请求网关的时候,会根据你的 path 字段来匹配到一条数据,然后进行后续的处理流程 rpc_ext 字段如果代理的接口是 Dubbo 类型的服务接口,同时设置了 group version 字段时候,那么信息就会存储到 rpc_ext 中  每一个 Dubbo 接口方法会应对一条元数据,对比SpringCloud、http分别是只存储一条/contextPath/** 和不存储  Apache Dubbo 插件配置 soul-bootstrap pom 配置 \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;soul-spring-boot-starter-plugin-apache-dubbo\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${project.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.apache.dubbo\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;dubbo\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.7.5\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.apache.curator\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;curator-client\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${curator.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.apache.curator\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;curator-framework\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${curator.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; …","date":1616457600,"description":"Soul Gateway Learning Apache Dubbo Plugin","dir":"blog/soul_source_learning_22_apache_dubbo/","fuzzywordcount":3800,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"32e8ad6a16f6faa8b54ff8dfbcbc7932c7361d1f","permalink":"/blog/soul_source_learning_22_apache_dubbo/","publishdate":"2021-03-23T00:00:00Z","readingtime":8,"relpermalink":"/blog/soul_source_learning_22_apache_dubbo/","summary":"目标 Apache Dubbo 插件介绍 元数据介绍 Apache Dubbo 插件配置 Bootstrap pom 配置 soul-admin 配置 dubbo服务pom配置 Apache Dubbo 泛化调用介绍 通过API方式使用泛化调用 通过spring使用泛","tags":["Soul"],"title":"Soul Gateway Learning Apache Dubbo Plugin","type":"blog","url":"/blog/soul_source_learning_22_apache_dubbo/","wordcount":3745},{"author":"nuo-promise","categories":"Soul","content":" 目标  Apache Dubbo 插件介绍  元数据介绍  Apache Dubbo 插件配置  Bootstrap pom 配置 soul-admin 配置 dubbo服务pom配置  Apache Dubbo 泛化调用介绍  通过API方式使用泛化调用 通过spring使用泛化调用 泛化调用实现流程  Soul Dubbo 插件调用解析  ApachDubboPlugin泛化调用准备 ApacheDubboProxySerivce DubboResponsePlugin WebFluxResultUtils返回结果  Dubbo泛化调用介绍 总结 参考\nApache Dubbo 插件介绍 Apache Dubbo 是一款高性能、轻量级的开源Java服务框架,主要提供了六大核心能力,面向接口代理的高性能RPC调用,智能容错和负载均衡,服务自动注册与发现,高度可扩展能力,运行期流量调度,可视化的服务治理与运维。 网关中Dubbo插件主要是将 Http协议 转换成 Dubbo协议 ,也是网关实现Dubbo泛化调用的关键。而Dubbo插件需要配合 元数据 才能实现Dubbo调用。\n元数据介绍 元数据作用就是在进行协议转换时候要获取真实的请求 path 、methodName 、 parameterTypes 为泛化调用做好准备\n   在数据库中,我们有一张表单独存储Dubbo元信息，通过数据同步方案,会把这张表的数据同步到网关的JVM内存中 表结构如下\nCREATE TABLE IF NOT EXISTS `meta_data` ( `id` varchar(128) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NOT NULL COMMENT \u0026#39;id\u0026#39;, `app_name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NOT NULL COMMENT \u0026#39;应用名称\u0026#39;, `path` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NOT NULL COMMENT \u0026#39;路径,不能重复\u0026#39;, `path_desc` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NOT NULL COMMENT \u0026#39;路径描述\u0026#39;, `rpc_type` varchar(64) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NOT NULL COMMENT \u0026#39;rpc类型\u0026#39;, `service_name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NULL DEFAULT NULL COMMENT \u0026#39;服务名称\u0026#39;, `method_name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NULL DEFAULT NULL COMMENT \u0026#39;方法名称\u0026#39;, `parameter_types` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NULL DEFAULT NULL COMMENT \u0026#39;参数类型 多个参数类型 逗号隔开\u0026#39;, `rpc_ext` varchar(1024) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NULL DEFAULT NULL COMMENT \u0026#39;rpc的扩展信息，json格式\u0026#39;, `date_created` datetime(0) NOT NULL COMMENT \u0026#39;创建时间\u0026#39;, `date_updated` datetime(0) NOT NULL ON UPDATE CURRENT_TIMESTAMP(0) COMMENT \u0026#39;更新时间\u0026#39;, `enabled` tinyint(4) NOT NULL DEFAULT 0 COMMENT \u0026#39;启用状态\u0026#39;, PRIMARY KEY (`id`) USING BTREE ) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_unicode_ci ROW_FORMAT = Dynamic;   path 字段主要是在请求网关的时候,会根据你的 path 字段来匹配到一条数据,然后进行后续的处理流程 rpc_ext 字段如果代理的接口是 Dubbo 类型的服务接口,同时设置了 group version 字段时候,那么信息就会存储到 rpc_ext 中  每一个 Dubbo 接口方法会应对一条元数据,对比SpringCloud、http分别是只存储一条/contextPath/** 和不存储  Apache Dubbo 插件配置 soul-bootstrap pom 配置 \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;soul-spring-boot-starter-plugin-apache-dubbo\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${project.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.apache.dubbo\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;dubbo\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.7.5\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.apache.curator\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;curator-client\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${curator.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.apache.curator\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;curator-framework\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${curator.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; …","date":1616457600,"description":"Soul网关学习Apache Dubbo插件原理解析","dir":"blog/soul_source_learning_22_apache_dubbo/","fuzzywordcount":3800,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"e2589bf0b4b6a8a4a17086247c1cd15db70e800d","permalink":"/zh/blog/soul_source_learning_22_apache_dubbo/","publishdate":"2021-03-23T00:00:00Z","readingtime":8,"relpermalink":"/zh/blog/soul_source_learning_22_apache_dubbo/","summary":"目标 Apache Dubbo 插件介绍 元数据介绍 Apache Dubbo 插件配置 Bootstrap pom 配置 soul-admin 配置 dubbo服务pom配置 Apache Dubbo 泛化调用介绍 通过API方式使用泛化调用 通过spring使用泛","tags":["Soul"],"title":"Soul网关学习Apache Dubbo插件原理解析","type":"blog","url":"/zh/blog/soul_source_learning_22_apache_dubbo/","wordcount":3745},{"author":"yanbing","categories":"Soul","content":" 目标  什么是Resilience4J soul的Resilience4j体验  限流 熔断  Resilience4J插件源码解读  什么是Resilience4j  Resilience4J是Spring Cloud Gateway推荐的容错方案，它是一个轻量级的容错库 借鉴了Hystrix而设计，并且采用JDK8 这个函数式编程，即lambda表达式 相比之下， Netflix Hystrix 对Archaius 具有编译依赖性，Resilience4j你无需引用全部依赖，可以根据自己需要的功能引用相关的模块即可 Hystrix不更新了，Spring提供Netflix Hystrix的替换方案，即Resilence4J Resilience4J 提供了一系列增强微服务的可用性功能：\n 断路器 CircuitBreaker 限流 RateLimiter 基于信号量的隔离 缓存 限时 Timelimiter 请求重启 Retry  官方提供的依赖包\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;io.github.resilience4j\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;resilience4j-circuitbreaker\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${resilience.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  soul的Resilience4j体验  首先在soul-admin控制台插件管理开启Resilience4j  在soul网关添加依赖\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;soul-spring-boot-starter-plugin-ratelimiter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${project.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   启动三个服务,分别是一个soul-admin，一个soul-bootstrap，一个soul-examples-http\n 在soul-admin控制台找到插件列表的Resilience4j，自定义配置，如下图，  soul官网的配置介绍\n* Resilience4j处理详解： * timeoutDurationRate：等待获取令牌的超时时间，单位ms，默认值：5000。 * limitRefreshPeriod：刷新令牌的时间间隔，单位ms，默认值：500。 * limitForPeriod：每次刷新令牌的数量，默认值：50。 * circuitEnable：是否开启熔断，0：关闭，1：开启，默认值：0。 * timeoutDuration：熔断超时时间，单位ms，默认值：30000。 * fallbackUri：降级处理的uri。 * slidingWindowSize：滑动窗口大小，默认值：100。 * slidingWindowType：滑动窗口类型，0：基于计数，1：基于时间，默认值：0。 * minimumNumberOfCalls：开启熔断的最小请求数，超过这个请求数才开启熔断统计，默认值：100。 * waitIntervalFunctionInOpenState：熔断器开启持续时间，单位ms，默认值：10。 * permittedNumberOfCallsInHalfOpenState：半开状态下的环形缓冲区大小，必须达到此数量才会计算失败率，默认值：10。 * failureRateThreshold：错误率百分比，达到这个阈值，熔断器才会开启，默认值50。 * automaticTransitionFromOpenToHalfOpenEnabled：是否自动从open状态转换为half-open状态，,true：是，false：否，默认值：false。   限流  参数配置 如下是参数配置校验，参数值小于默认值，会直接赋值默认值，因此方便测试效果直接修改源码的配置 ： 每次刷新令牌的数量为2 ，刷新令牌的时间间隔为1s，超时时间为1s  /** * check filed default value. * * @param resilience4JHandle {@linkplain Resilience4JHandle} * @return {@linkplain Resilience4JHandle} */ public Resilience4JHandle checkData(final Resilience4JHandle resilience4JHandle) { resilience4JHandle.setTimeoutDurationRate(Math.max(resilience4JHandle.getTimeoutDurationRate(), Constants.TIMEOUT_DURATION_RATE)); //resilience4JHandle.setLimitRefreshPeriod(Math.max(resilience4JHandle.getLimitRefreshPeriod(), Constants.LIMIT_REFRESH_PERIOD)); //resilience4JHandle.setLimitForPeriod(Math.max(resilience4JHandle.getLimitForPeriod(), Constants.LIMIT_FOR_PERIOD)); //每次刷新令牌的数量为2 ，刷新令牌的时间间隔为1s resilience4JHandle.setLimitRefreshPeriod(1000); resilience4JHandle.setLimitForPeriod(2); resilience4JHandle.setTimeoutDuration(1000); resilience4JHandle.setCircuitEnable(Math.max(resilience4JHandle.getCircuitEnable(), Constants.CIRCUIT_ENABLE)); //resilience4JHandle.setTimeoutDuration(Math.max(resilience4JHandle.getTimeoutDuration(), Constants.TIMEOUT_DURATION)); resilience4JHandle.setFallbackUri(!\u0026amp;quot;0\u0026amp;quot;.equals(resilience4JHandle.getFallbackUri()) ? resilience4JHandle.getFallbackUri() : \u0026amp;quot;\u0026amp;quot;); …","date":1616371200,"description":"Soul Gateway Learning Resilience4j Plugin","dir":"blog/soul_source_learning_21_resilience4j/","fuzzywordcount":2600,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"e0a8ab49fa2593188f17d2b3fced004722d2ed14","permalink":"/blog/soul_source_learning_21_resilience4j/","publishdate":"2021-03-22T00:00:00Z","readingtime":6,"relpermalink":"/blog/soul_source_learning_21_resilience4j/","summary":"目标 什么是Resilience4J soul的Resilience4j体验 限流 熔断 Resilience4J插件源码解读 什么是Resilienc","tags":["Soul"],"title":"Soul Gateway Learning Resilience4j Plugin","type":"blog","url":"/blog/soul_source_learning_21_resilience4j/","wordcount":2581},{"author":"闫兵","categories":"Soul","content":" 目标  什么是Resilience4J soul的Resilience4j体验  限流 熔断  Resilience4J插件源码解读  什么是Resilience4j  Resilience4J是Spring Cloud Gateway推荐的容错方案，它是一个轻量级的容错库 借鉴了Hystrix而设计，并且采用JDK8 这个函数式编程，即lambda表达式 相比之下， Netflix Hystrix 对Archaius 具有编译依赖性，Resilience4j你无需引用全部依赖，可以根据自己需要的功能引用相关的模块即可 Hystrix不更新了，Spring提供Netflix Hystrix的替换方案，即Resilence4J Resilience4J 提供了一系列增强微服务的可用性功能：\n 断路器 CircuitBreaker 限流 RateLimiter 基于信号量的隔离 缓存 限时 Timelimiter 请求重启 Retry  官方提供的依赖包\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;io.github.resilience4j\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;resilience4j-circuitbreaker\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${resilience.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  soul的Resilience4j体验  首先在soul-admin控制台插件管理开启Resilience4j  在soul网关添加依赖\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;soul-spring-boot-starter-plugin-ratelimiter\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${project.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   启动三个服务,分别是一个soul-admin，一个soul-bootstrap，一个soul-examples-http\n 在soul-admin控制台找到插件列表的Resilience4j，自定义配置，如下图，  soul官网的配置介绍\n* Resilience4j处理详解： * timeoutDurationRate：等待获取令牌的超时时间，单位ms，默认值：5000。 * limitRefreshPeriod：刷新令牌的时间间隔，单位ms，默认值：500。 * limitForPeriod：每次刷新令牌的数量，默认值：50。 * circuitEnable：是否开启熔断，0：关闭，1：开启，默认值：0。 * timeoutDuration：熔断超时时间，单位ms，默认值：30000。 * fallbackUri：降级处理的uri。 * slidingWindowSize：滑动窗口大小，默认值：100。 * slidingWindowType：滑动窗口类型，0：基于计数，1：基于时间，默认值：0。 * minimumNumberOfCalls：开启熔断的最小请求数，超过这个请求数才开启熔断统计，默认值：100。 * waitIntervalFunctionInOpenState：熔断器开启持续时间，单位ms，默认值：10。 * permittedNumberOfCallsInHalfOpenState：半开状态下的环形缓冲区大小，必须达到此数量才会计算失败率，默认值：10。 * failureRateThreshold：错误率百分比，达到这个阈值，熔断器才会开启，默认值50。 * automaticTransitionFromOpenToHalfOpenEnabled：是否自动从open状态转换为half-open状态，,true：是，false：否，默认值：false。   限流  参数配置 如下是参数配置校验，参数值小于默认值，会直接赋值默认值，因此方便测试效果直接修改源码的配置 ： 每次刷新令牌的数量为2 ，刷新令牌的时间间隔为1s，超时时间为1s  /** * check filed default value. * * @param resilience4JHandle {@linkplain Resilience4JHandle} * @return {@linkplain Resilience4JHandle} */ public Resilience4JHandle checkData(final Resilience4JHandle resilience4JHandle) { resilience4JHandle.setTimeoutDurationRate(Math.max(resilience4JHandle.getTimeoutDurationRate(), Constants.TIMEOUT_DURATION_RATE)); //resilience4JHandle.setLimitRefreshPeriod(Math.max(resilience4JHandle.getLimitRefreshPeriod(), Constants.LIMIT_REFRESH_PERIOD)); //resilience4JHandle.setLimitForPeriod(Math.max(resilience4JHandle.getLimitForPeriod(), Constants.LIMIT_FOR_PERIOD)); //每次刷新令牌的数量为2 ，刷新令牌的时间间隔为1s resilience4JHandle.setLimitRefreshPeriod(1000); resilience4JHandle.setLimitForPeriod(2); resilience4JHandle.setTimeoutDuration(1000); resilience4JHandle.setCircuitEnable(Math.max(resilience4JHandle.getCircuitEnable(), Constants.CIRCUIT_ENABLE)); //resilience4JHandle.setTimeoutDuration(Math.max(resilience4JHandle.getTimeoutDuration(), Constants.TIMEOUT_DURATION)); resilience4JHandle.setFallbackUri(!\u0026amp;quot;0\u0026amp;quot;.equals(resilience4JHandle.getFallbackUri()) ? resilience4JHandle.getFallbackUri() : \u0026amp;quot;\u0026amp;quot;); …","date":1616371200,"description":"Soul网关学习Resilience4j插件原理解析","dir":"blog/soul_source_learning_21_resilience4j/","fuzzywordcount":2600,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"48aec55a741081b39b052ecd0ff8f33d942b3703","permalink":"/zh/blog/soul_source_learning_21_resilience4j/","publishdate":"2021-03-22T00:00:00Z","readingtime":6,"relpermalink":"/zh/blog/soul_source_learning_21_resilience4j/","summary":"目标 什么是Resilience4J soul的Resilience4j体验 限流 熔断 Resilience4J插件源码解读 什么是Resilienc","tags":["Soul"],"title":"Soul网关学习Resilience4j插件原理解析","type":"blog","url":"/zh/blog/soul_source_learning_21_resilience4j/","wordcount":2581},{"author":"luoxiaolong","categories":"Soul","content":" 概述 在业务网关中熔断和流量控制都是非常必要的功能。soul在实现这部分功能时使用了不同的成熟组件，用户可以根据自己的喜好选择。本文将介绍如何在soul中使用阿里的Sentinel组件实现熔断及流控功能。本文首先会介绍熔断和流控的场景及意义。然后介绍如何在soul上配置使用sentinel插件做流控和熔断。最后从源码的层面简略分析soul是如何使用Sentinel组件的。\n熔断和流量控制 场景描述 业务网关作为流量的入口，有保护后继服务的职责。以下两个对服务有严重危害的场景在生产中经常会遇到，也是业务网关必须要关注处理的问题。一种情况是在比如双11或双12这些大型促销时，接口的请求量是平时是数倍，如果没有评估好容量，这种激增的请求很容易导致整个服务完全不可用。这种宕机往往不是因为业务逻辑的漏洞而是因为请求过多资源不够导致的。另一种情况是在整个服务体系中有一些核心服务，多个业务流程都依赖该服务。然而是服务都有出现处理不稳定或者服务损坏的情况，导致请求处理时间长或者老是频繁抛出异常。排除业务BUG的情况，可能就是突发的非常随机的阻塞，一般减缓请求量就会自动修复，但是如果不加保护就有出现多米诺效应导致整个服务不可用。此场景和第一种场景有略微不同，第一种场景是实际流量确实出现了不可处理的峰值，而第二种场景主要考虑的是服务本身出现了不可避免、不可预测的抖动而引发的连锁反应。\n流量控制 针对第一种场景我们通常的做法是进行流量控制，核心思路是业务网关保证打到后面的请求是业务可以承受的量，多余的请求直接拒绝或者加入等待队列，保证服务不会宕掉，大部分请求还是可以正常处理。在考虑流量控制的策略时，我们应该主要思考以下几个问题：\n 通过什么角度控制流量？ 阈值是多少？ 流量控制的策略是什么？  对于第一个问题，正常思路是通过QPS来监控流量，即每秒钟请求的数量超过某限额时进行流控。但其实还有一种思路是从并发数来监控流量。这种控制场景也是非常有意义的，例如当下游应用由于某种原因导致服务不稳定、响应延迟增加，对于网关来说，意味着吞吐量下降和更多的线程数占用，极端情况下甚至导致线程池耗尽。从某种意义上讲通过并发进行流控可以一定程度上保护网关服务本身。对于第二个问题阈值来说比较好理解，就是触发流控的边界，如果从QPS来考虑就是每秒达到多少时开始流控，从并发数来考量的话就是请求上下文的线程数目超过多少进行流控。对于第三个问题，我们一般有以下3中处理方案：\n 直接拒绝，这种策略非常好理解就是当QPS高于阈值时直接拒接服务，不把请求传输到后面的服务中。 预热启动，这个策略所针对的场景是系统长期处于低水位的情况下，可能出现流量突然增加时，而直接把系统拉升到高水位可能瞬间把系统压垮。预热启动的方式是让阈值缓慢增加，在一定时间内逐渐增加阈值直至达到设置，给冷系统一个预热的时间，避免冷系统被压垮。对于超出阈值的请求也是触发拒绝。 匀速排队，此策略核心思路是以固定间隔时间让请求通过。当请求到来的时候，如果当前请求距离上个通过的请求通过的时间间隔不小于预设值，则让当前请求通过；否则，计算当前请求的预期通过时间，如果该请求的预期通过时间小于规则预设的 timeout 时间，则该请求会等待直到预设时间到来通过（排队等待处理）；若预期的通过时间超出最大排队时长，则直接拒接这个请求。  熔断 针对第二种场景通常的处理方式是设置服务熔断。简单的说就是当我们探测的一个服务出现了异常，则不再访问它以免更多的请求对它造成更大的压力。一段时间后如果探测到服务恢复了再将流量发送过去。我们首先需要判断出这个服务是否出现了不稳定\\抖动的情况。然后思考如果发现了抖动的服务我们应该怎么办。如何判断服务是否恢复正常了。对于服务是否不稳定这一点我们一般可以通过一下3个方式进行判断。\n 慢调用比例：当单位统计时长内请求数目大于设置的最小请求数目，并且超过最大忍受时间的请求大于阈值，则判断服务异常，触发熔断； 异常比例：当单位统计时长内异常请求的比例大于阈值则我们判定服务异常，触发熔断； 异常数：当单位时长内出现异常的请求的数量的达到阈值则判定服务异常，触发熔断；  当我们通过以上3个指标判断服务为异常并熔断服务后，对于一定时间内（熔断时长内）的请求我们可以选择直接报错，不阻塞上游服务，让请求方来自行决定如何处理。或者直接触发服务降级。服务降级粗略的可以理解为请求此业务的简版，该简版省掉了很多非核心流程，并且只是最终保证流程处理完（最终一致性）。和现实中的熔断一样服务熔断是会自动恢复的。一般是触发熔断后的一段时间内服务处于熔断状态不提供服务，然后进入半开状态，若接下来的少量请求没有报错且响应时间合理则服务恢复，如果还是异常则继续熔断。\nsoul中的Sentinel插件 Sentinel是阿里开源的面向分布式服务架构的流量控制组件，主要以流量为切入点，从流量控制、熔断降级、系统自适应保护等多个维度来帮助您保障微服务的稳定性。Soul作为国内优秀的开源网关，将Sentinel整合为插件融入了自己的体系中，使用户通过简单的配置就可以使用Sentinel提供的流量控制和服务熔断功能。下面将简要介绍在soul中如何配置使用sentinel插件。\n首先登陆soul管理平台在\u0026amp;rdquo;插件列表\u0026amp;rdquo; \u0026amp;ndash;\u0026amp;gt; \u0026amp;ldquo;sentinel\u0026amp;rdquo;中配置插件。其中\u0026amp;rdquo;选择器\u0026amp;rdquo;的配置不是本文的重点不再介绍，点击\u0026amp;rdquo;增加规则\u0026amp;rdquo;来进行具体设置如下图。\n在这个配置页面中\u0026amp;rdquo;名称\u0026amp;rdquo;、\u0026amp;rdquo;匹配方式\u0026amp;rdquo;、\u0026amp;rdquo;条件\u0026amp;rdquo;、\u0026amp;rdquo;日志打印\u0026amp;rdquo;、\u0026amp;rdquo;是否开启\u0026amp;rdquo;、\u0026amp;rdquo;执行顺序\u0026amp;rdquo;属于soul插件的常规配置这里也不再赘述。我们重点需要关注的是\u0026amp;rdquo;处理\u0026amp;rdquo;中的配置项。这些配置项主要可以分为2组，前4个选项是关于熔断的配置，后4个选项是关于流量控制的配置。在soul中我们可以针对某一组请求同时设置它的流量控制和熔断策略。下面来重点分析下各个配置项如何使用。\n熔断 首先来看熔断相关的配置，它有四个配置项\u0026amp;rdquo;熔断阈值\u0026amp;rdquo;、\u0026amp;rdquo;是否开启熔断\u0026amp;rdquo;、\u0026amp;rdquo;熔断窗口大小\u0026amp;rdquo;以及没有注名字的是服务异常判断方式。熔断开关表示是否开启熔断（1开\\0不开）。熔断窗口大小指的是触发熔断后经过多少秒后进入半开状态，在半开状态如果请求正常则会进入正常状态如果请求依然不正常则继续熔断。熔断判定方式和熔断阈值需要结合来看。soul中使用了sentinel的3种服务异常判定方式。分别是：\n 慢调用比例，在此模式下阈值指的是判定为慢调用的毫秒数。慢调用的比例默认是1不能更改即单位统计时长内全部超过阈值则触发熔断。该模式是sentinel的默认模式。 异常比例，在此模式下阈值指的是单位统计时长内异常请求的比例上限，需要填写1个[0.0, 1.0]的数，表示0%-100% 异常数策略，在该模式下阈值指的是单位统计时间内异常请求个数的上限。  需要注意的是soul对于单位统计时 …","date":1616112000,"description":"Soul Gateway Learning Sentinel Plugin","dir":"blog/soul_source_learning_20_sentinel/","fuzzywordcount":5500,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"9d29b4ca51ed84f71e7e6e810e8a0126fef76476","permalink":"/blog/soul_source_learning_20_sentinel/","publishdate":"2021-03-19T00:00:00Z","readingtime":11,"relpermalink":"/blog/soul_source_learning_20_sentinel/","summary":"概述 在业务网关中熔断和流量控制都是非常必要的功能。soul在实现这部分功能时使用了不同的成熟组件，用户可以根据自己的喜好选择。本文将介绍如何","tags":["Soul"],"title":"Soul Gateway Learning Sentinel Plugin","type":"blog","url":"/blog/soul_source_learning_20_sentinel/","wordcount":5435},{"author":"骆潇龙","categories":"Soul","content":" 概述 在业务网关中熔断和流量控制都是非常必要的功能。soul在实现这部分功能时使用了不同的成熟组件，用户可以根据自己的喜好选择。本文将介绍如何在soul中使用阿里的Sentinel组件实现熔断及流控功能。本文首先会介绍熔断和流控的场景及意义。然后介绍如何在soul上配置使用sentinel插件做流控和熔断。最后从源码的层面简略分析soul是如何使用Sentinel组件的。\n熔断和流量控制 场景描述 业务网关作为流量的入口，有保护后继服务的职责。以下两个对服务有严重危害的场景在生产中经常会遇到，也是业务网关必须要关注处理的问题。一种情况是在比如双11或双12这些大型促销时，接口的请求量是平时是数倍，如果没有评估好容量，这种激增的请求很容易导致整个服务完全不可用。这种宕机往往不是因为业务逻辑的漏洞而是因为请求过多资源不够导致的。另一种情况是在整个服务体系中有一些核心服务，多个业务流程都依赖该服务。然而是服务都有出现处理不稳定或者服务损坏的情况，导致请求处理时间长或者老是频繁抛出异常。排除业务BUG的情况，可能就是突发的非常随机的阻塞，一般减缓请求量就会自动修复，但是如果不加保护就有出现多米诺效应导致整个服务不可用。此场景和第一种场景有略微不同，第一种场景是实际流量确实出现了不可处理的峰值，而第二种场景主要考虑的是服务本身出现了不可避免、不可预测的抖动而引发的连锁反应。\n流量控制 针对第一种场景我们通常的做法是进行流量控制，核心思路是业务网关保证打到后面的请求是业务可以承受的量，多余的请求直接拒绝或者加入等待队列，保证服务不会宕掉，大部分请求还是可以正常处理。在考虑流量控制的策略时，我们应该主要思考以下几个问题：\n 通过什么角度控制流量？ 阈值是多少？ 流量控制的策略是什么？  对于第一个问题，正常思路是通过QPS来监控流量，即每秒钟请求的数量超过某限额时进行流控。但其实还有一种思路是从并发数来监控流量。这种控制场景也是非常有意义的，例如当下游应用由于某种原因导致服务不稳定、响应延迟增加，对于网关来说，意味着吞吐量下降和更多的线程数占用，极端情况下甚至导致线程池耗尽。从某种意义上讲通过并发进行流控可以一定程度上保护网关服务本身。对于第二个问题阈值来说比较好理解，就是触发流控的边界，如果从QPS来考虑就是每秒达到多少时开始流控，从并发数来考量的话就是请求上下文的线程数目超过多少进行流控。对于第三个问题，我们一般有以下3中处理方案：\n 直接拒绝，这种策略非常好理解就是当QPS高于阈值时直接拒接服务，不把请求传输到后面的服务中。 预热启动，这个策略所针对的场景是系统长期处于低水位的情况下，可能出现流量突然增加时，而直接把系统拉升到高水位可能瞬间把系统压垮。预热启动的方式是让阈值缓慢增加，在一定时间内逐渐增加阈值直至达到设置，给冷系统一个预热的时间，避免冷系统被压垮。对于超出阈值的请求也是触发拒绝。 匀速排队，此策略核心思路是以固定间隔时间让请求通过。当请求到来的时候，如果当前请求距离上个通过的请求通过的时间间隔不小于预设值，则让当前请求通过；否则，计算当前请求的预期通过时间，如果该请求的预期通过时间小于规则预设的 timeout 时间，则该请求会等待直到预设时间到来通过（排队等待处理）；若预期的通过时间超出最大排队时长，则直接拒接这个请求。  熔断 针对第二种场景通常的处理方式是设置服务熔断。简单的说就是当我们探测的一个服务出现了异常，则不再访问它以免更多的请求对它造成更大的压力。一段时间后如果探测到服务恢复了再将流量发送过去。我们首先需要判断出这个服务是否出现了不稳定\\抖动的情况。然后思考如果发现了抖动的服务我们应该怎么办。如何判断服务是否恢复正常了。对于服务是否不稳定这一点我们一般可以通过一下3个方式进行判断。\n 慢调用比例：当单位统计时长内请求数目大于设置的最小请求数目，并且超过最大忍受时间的请求大于阈值，则判断服务异常，触发熔断； 异常比例：当单位统计时长内异常请求的比例大于阈值则我们判定服务异常，触发熔断； 异常数：当单位时长内出现异常的请求的数量的达到阈值则判定服务异常，触发熔断；  当我们通过以上3个指标判断服务为异常并熔断服务后，对于一定时间内（熔断时长内）的请求我们可以选择直接报错，不阻塞上游服务，让请求方来自行决定如何处理。或者直接触发服务降级。服务降级粗略的可以理解为请求此业务的简版，该简版省掉了很多非核心流程，并且只是最终保证流程处理完（最终一致性）。和现实中的熔断一样服务熔断是会自动恢复的。一般是触发熔断后的一段时间内服务处于熔断状态不提供服务，然后进入半开状态，若接下来的少量请求没有报错且响应时间合理则服务恢复，如果还是异常则继续熔断。\nsoul中的Sentinel插件 Sentinel是阿里开源的面向分布式服务架构的流量控制组件，主要以流量为切入点，从流量控制、熔断降级、系统自适应保护等多个维度来帮助您保障微服务的稳定性。Soul作为国内优秀的开源网关，将Sentinel整合为插件融入了自己的体系中，使用户通过简单的配置就可以使用Sentinel提供的流量控制和服务熔断功能。下面将简要介绍在soul中如何配置使用sentinel插件。\n首先登陆soul管理平台在\u0026amp;rdquo;插件列表\u0026amp;rdquo; \u0026amp;ndash;\u0026amp;gt; \u0026amp;ldquo;sentinel\u0026amp;rdquo;中配置插件。其中\u0026amp;rdquo;选择器\u0026amp;rdquo;的配置不是本文的重点不再介绍，点击\u0026amp;rdquo;增加规则\u0026amp;rdquo;来进行具体设置如下图。\n在这个配置页面中\u0026amp;rdquo;名称\u0026amp;rdquo;、\u0026amp;rdquo;匹配方式\u0026amp;rdquo;、\u0026amp;rdquo;条件\u0026amp;rdquo;、\u0026amp;rdquo;日志打印\u0026amp;rdquo;、\u0026amp;rdquo;是否开启\u0026amp;rdquo;、\u0026amp;rdquo;执行顺序\u0026amp;rdquo;属于soul插件的常规配置这里也不再赘述。我们重点需要关注的是\u0026amp;rdquo;处理\u0026amp;rdquo;中的配置项。这些配置项主要可以分为2组，前4个选项是关于熔断的配置，后4个选项是关于流量控制的配置。在soul中我们可以针对某一组请求同时设置它的流量控制和熔断策略。下面来重点分析下各个配置项如何使用。\n熔断 首先来看熔断相关的配置，它有四个配置项\u0026amp;rdquo;熔断阈值\u0026amp;rdquo;、\u0026amp;rdquo;是否开启熔断\u0026amp;rdquo;、\u0026amp;rdquo;熔断窗口大小\u0026amp;rdquo;以及没有注名字的是服务异常判断方式。熔断开关表示是否开启熔断（1开\\0不开）。熔断窗口大小指的是触发熔断后经过多少秒后进入半开状态，在半开状态如果请求正常则会进入正常状态如果请求依然不正常则继续熔断。熔断判定方式和熔断阈值需要结合来看。soul中使用了sentinel的3种服务异常判定方式。分别是：\n 慢调用比例，在此模式下阈值指的是判定为慢调用的毫秒数。慢调用的比例默认是1不能更改即单位统计时长内全部超过阈值则触发熔断。该模式是sentinel的默认模式。 异常比例，在此模式下阈值指的是单位统计时长内异常请求的比例上限，需要填写1个[0.0, 1.0]的数，表示0%-100% 异常数策略，在该模式下阈值指的是单位统计时间内异常请求个数的上限。  需要注意的是soul对于单位统计时 …","date":1616112000,"description":"Soul网关学习Sentinel插件原理解析","dir":"blog/soul_source_learning_20_sentinel/","fuzzywordcount":5500,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"1c40490975310b56e4a167899f109da010538b6f","permalink":"/zh/blog/soul_source_learning_20_sentinel/","publishdate":"2021-03-19T00:00:00Z","readingtime":11,"relpermalink":"/zh/blog/soul_source_learning_20_sentinel/","summary":"概述 在业务网关中熔断和流量控制都是非常必要的功能。soul在实现这部分功能时使用了不同的成熟组件，用户可以根据自己的喜好选择。本文将介绍如何","tags":["Soul"],"title":"Soul网关学习Sentinel插件原理解析","type":"blog","url":"/zh/blog/soul_source_learning_20_sentinel/","wordcount":5435},{"author":"axing","categories":"Soul","content":" 介绍 Soul 网关在对目标服务进行代理调用的时候，可以使用 redirect 插件来重定向请求。其中包含两种场景：一种把 redirectUrl 配置为第三方URL 地址，直接使用 308 进行转发跳转，另一种是把 redirectUrl 配置以 / 开头的转发到网关自身。\n插件配置  在 soul-admin –\u0026amp;gt; 插件管理 –\u0026amp;gt; redirect，设置为开启。 在 soul-bootstrap 项目的 pom.xml 文件中添加 redirect 的 maven 依赖。 在 soul- admin 后台设置选择器规则，只有匹配的请求，才会进行转发和重定向，请详细看：选择器规则。  Maven 依赖 在 soul-bootstrap 工程的 pom.xml 文件中添加插件依赖。\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;soul-spring-boot-starter-plugin-redirect\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  场景  顾名思义，redirect 插件就是对 uri 的重新转发和重定向。\n 重定向  我们在 Rule 配置自定义路径时，应该为一个可达的服务路径。 当匹配到请求后，根据自定义的路径，Soul 网关会进行 308 服务跳转。  网关自身接口转发  当满足匹配规则时，服务内部会使用 DispatcherHandler 内部接口转发。 要实现网关自身接口转发，我们需要在配置路径使用 / 作为前缀开始，具体配置如下图。  源码解析 在解析 redirect 重定向源码之前，有必要说一些大前提，我们明白 Soul 网关基于 SpringBoot WebFlux 实现，其中对于 WebFlux 如果默认什么都不配置，请求会默认执行 DispatcherHandler 处理，这个是响应式 MVC 的处理核心，可以看一下初始化：\nprotected void initStrategies(ApplicationContext context) { Map\u0026amp;lt;String, HandlerMapping\u0026amp;gt; mappingBeans = BeanFactoryUtils.beansOfTypeIncludingAncestors(context, HandlerMapping.class, true, false); ArrayList\u0026amp;lt;HandlerMapping\u0026amp;gt; mappings = new ArrayList(mappingBeans.values()); AnnotationAwareOrderComparator.sort(mappings); // handlerMapping 相关 this.handlerMappings = Collections.unmodifiableList(mappings); Map\u0026amp;lt;String, HandlerAdapter\u0026amp;gt; adapterBeans = BeanFactoryUtils.beansOfTypeIncludingAncestors(context, HandlerAdapter.class, true, false); // handlerAdapter 相关 this.handlerAdapters = new ArrayList(adapterBeans.values()); AnnotationAwareOrderComparator.sort(this.handlerAdapters); Map\u0026amp;lt;String, HandlerResultHandler\u0026amp;gt; beans = BeanFactoryUtils.beansOfTypeIncludingAncestors(context, HandlerResultHandler.class, true, false); // resultHandler 相关 this.resultHandlers = new ArrayList(beans.values()); AnnotationAwareOrderComparator.sort(this.resultHandlers); }  再之后就是我们熟悉的 MVC 核心处理 DispatcherHandler#handle 方法\npublic Mono\u0026amp;lt;Void\u0026amp;gt; handle(ServerWebExchange exchange) { return this.handlerMappings == null ? this.createNotFoundError() : Flux.fromIterable(this.handlerMappings).concatMap((mapping) -\u0026amp;gt; { return mapping.getHandler(exchange); }).next().switchIfEmpty(this.createNotFoundError()).flatMap((handler) -\u0026amp;gt; { return this.invokeHandler(exchange, handler); }).flatMap((result) -\u0026amp;gt; { return this.handleResult(exchange, result); }); }  搞清楚默认 DispatcherHandler 如何处理，我们再来说一下 Soul 网关，SoulWebHandler 实现了 WebHandler 接口，再把 BeanName 声明为 webHandler 替代了之前 DispatcherHandler 注册成默认处理 handler。\n@Bean(\u0026amp;quot;webHandler\u0026amp;quot;) public SoulWebHandler soulWebHandler(final ObjectProvider\u0026amp;lt;List\u0026amp;lt;SoulPlugin\u0026amp;gt;\u0026amp;gt; plugins) { List\u0026amp;lt;SoulPlugin\u0026amp;gt; pluginList = plugins.getIfAvailable(Collections::emptyList); List\u0026amp;lt;SoulPlugin\u0026amp;gt; soulPlugins = pluginList.stream() .sorted(Comparator.comparingInt(SoulPlugin::getOrder)).collect(Collectors.toList()); soulPlugins.forEach(soulPlugin -\u0026amp;gt; log.info(\u0026amp;quot;load plugin:[{}] [{}]\u0026amp;quot;, soulPlugin.named(), …","date":1615852800,"description":"Soul Gateway Learning Redirect Plugin","dir":"blog/soul_source_learning_19_redirect/","fuzzywordcount":900,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"d97dadaae76c59dac2fdf3f2964e32fd5da61ab6","permalink":"/blog/soul_source_learning_19_redirect/","publishdate":"2021-03-16T00:00:00Z","readingtime":2,"relpermalink":"/blog/soul_source_learning_19_redirect/","summary":"介绍 Soul 网关在对目标服务进行代理调用的时候，可以使用 redirect 插件来重定向请求。其中包含两种场景：一种把 redirectUrl 配置为第三方URL 地址，直接使用 308 进行转发跳","tags":["Soul"],"title":"Soul Gateway Learning Redirect Plugin","type":"blog","url":"/blog/soul_source_learning_19_redirect/","wordcount":876},{"author":"阿行","categories":"Soul","content":" 介绍 Soul 网关在对目标服务进行代理调用的时候，可以使用 redirect 插件来重定向请求。其中包含两种场景：一种把 redirectUrl 配置为第三方URL 地址，直接使用 308 进行转发跳转，另一种是把 redirectUrl 配置以 / 开头的转发到网关自身。\n插件配置  在 soul-admin –\u0026amp;gt; 插件管理 –\u0026amp;gt; redirect，设置为开启。 在 soul-bootstrap 项目的 pom.xml 文件中添加 redirect 的 maven 依赖。 在 soul- admin 后台设置选择器规则，只有匹配的请求，才会进行转发和重定向，请详细看：选择器规则。  Maven 依赖 在 soul-bootstrap 工程的 pom.xml 文件中添加插件依赖。\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;soul-spring-boot-starter-plugin-redirect\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  场景  顾名思义，redirect 插件就是对 uri 的重新转发和重定向。\n 重定向  我们在 Rule 配置自定义路径时，应该为一个可达的服务路径。 当匹配到请求后，根据自定义的路径，Soul 网关会进行 308 服务跳转。  网关自身接口转发  当满足匹配规则时，服务内部会使用 DispatcherHandler 内部接口转发。 要实现网关自身接口转发，我们需要在配置路径使用 / 作为前缀开始，具体配置如下图。  源码解析 在解析 redirect 重定向源码之前，有必要说一些大前提，我们明白 Soul 网关基于 SpringBoot WebFlux 实现，其中对于 WebFlux 如果默认什么都不配置，请求会默认执行 DispatcherHandler 处理，这个是响应式 MVC 的处理核心，可以看一下初始化：\nprotected void initStrategies(ApplicationContext context) { Map\u0026amp;lt;String, HandlerMapping\u0026amp;gt; mappingBeans = BeanFactoryUtils.beansOfTypeIncludingAncestors(context, HandlerMapping.class, true, false); ArrayList\u0026amp;lt;HandlerMapping\u0026amp;gt; mappings = new ArrayList(mappingBeans.values()); AnnotationAwareOrderComparator.sort(mappings); // handlerMapping 相关 this.handlerMappings = Collections.unmodifiableList(mappings); Map\u0026amp;lt;String, HandlerAdapter\u0026amp;gt; adapterBeans = BeanFactoryUtils.beansOfTypeIncludingAncestors(context, HandlerAdapter.class, true, false); // handlerAdapter 相关 this.handlerAdapters = new ArrayList(adapterBeans.values()); AnnotationAwareOrderComparator.sort(this.handlerAdapters); Map\u0026amp;lt;String, HandlerResultHandler\u0026amp;gt; beans = BeanFactoryUtils.beansOfTypeIncludingAncestors(context, HandlerResultHandler.class, true, false); // resultHandler 相关 this.resultHandlers = new ArrayList(beans.values()); AnnotationAwareOrderComparator.sort(this.resultHandlers); }  再之后就是我们熟悉的 MVC 核心处理 DispatcherHandler#handle 方法\npublic Mono\u0026amp;lt;Void\u0026amp;gt; handle(ServerWebExchange exchange) { return this.handlerMappings == null ? this.createNotFoundError() : Flux.fromIterable(this.handlerMappings).concatMap((mapping) -\u0026amp;gt; { return mapping.getHandler(exchange); }).next().switchIfEmpty(this.createNotFoundError()).flatMap((handler) -\u0026amp;gt; { return this.invokeHandler(exchange, handler); }).flatMap((result) -\u0026amp;gt; { return this.handleResult(exchange, result); }); }  搞清楚默认 DispatcherHandler 如何处理，我们再来说一下 Soul 网关，SoulWebHandler 实现了 WebHandler 接口，再把 BeanName 声明为 webHandler 替代了之前 DispatcherHandler 注册成默认处理 handler。\n@Bean(\u0026amp;quot;webHandler\u0026amp;quot;) public SoulWebHandler soulWebHandler(final ObjectProvider\u0026amp;lt;List\u0026amp;lt;SoulPlugin\u0026amp;gt;\u0026amp;gt; plugins) { List\u0026amp;lt;SoulPlugin\u0026amp;gt; pluginList = plugins.getIfAvailable(Collections::emptyList); List\u0026amp;lt;SoulPlugin\u0026amp;gt; soulPlugins = pluginList.stream() .sorted(Comparator.comparingInt(SoulPlugin::getOrder)).collect(Collectors.toList()); soulPlugins.forEach(soulPlugin -\u0026amp;gt; log.info(\u0026amp;quot;load plugin:[{}] [{}]\u0026amp;quot;, soulPlugin.named(), …","date":1615852800,"description":"Soul网关学习Redirect插件原理解析","dir":"blog/soul_source_learning_19_redirect/","fuzzywordcount":900,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"95ec347c061082c903d0c509f993e4cfe530c54a","permalink":"/zh/blog/soul_source_learning_19_redirect/","publishdate":"2021-03-16T00:00:00Z","readingtime":2,"relpermalink":"/zh/blog/soul_source_learning_19_redirect/","summary":"介绍 Soul 网关在对目标服务进行代理调用的时候，可以使用 redirect 插件来重定向请求。其中包含两种场景：一种把 redirectUrl 配置为第三方URL 地址，直接使用 308 进行转发跳","tags":["Soul"],"title":"Soul网关学习Redirect插件原理解析","type":"blog","url":"/zh/blog/soul_source_learning_19_redirect/","wordcount":876},{"author":"xiaoyu","categories":null,"content":" Dromara source code reading (Soul 2021 first activity)  Date: Sunday, February 6, 2021 Time：20:00 – 23:00 Location: Tencent Meeting  Activity Details 20:00 - 20:10 The opening introduces the recent dream code sharing situation by kimming \u0026amp;amp; 崔\n20:10 - 20:25 Introduction to SPI and how Soul SPI is enhanced by zhuming\n20:25 - 20:50 Introduction to Reactive Programming by Ztzzz\n20:50 - 21:10 Soul Unit Test by yangze\n21:10 - 21:25 Fault-tolerant design by jiangwenbo\n21:25 - 21:40 Soul Web Flux loading process and processing request analysis by rwby\n21:40 - 21:55 Soul current limiting and fusing analysis by liupenghui\n21:55 - 22:05 Summary of common Java problems by muou\n22:05 - 22:20 How to open a social interface by weikai\n22:20 - 22:30 Summary and Community Development Prospects by Xiaoyu\n","date":1612623600,"description":"","dir":"activities/dromara-cloud-native-meet-02/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"faab4b595dfdc1ef36894292b9b6e3f94fe7dd93","permalink":"/activities/dromara-cloud-native-meet-02/","publishdate":"2021-02-06T15:00:00Z","readingtime":1,"relpermalink":"/activities/dromara-cloud-native-meet-02/","summary":"Dromara source code reading (Soul 2021 first activity) Date: Sunday, February 6, 2021 Time：20:00 – 23:00 Location: Tencent Meeting Activity Details 20:00 - 20:10 The opening introduces the recent dream code sharing situation by kimming \u0026amp; 崔 20:10 - 20:25 Introduction to SPI and how Soul SPI is enhanced by zhuming 20:25 - 20:50 Introduction to Reactive Programming by Ztzzz 20:50","tags":["Soul","Dromara","Reactor"],"title":"Dromara Soul Source Code 01 Reading Sharing Session 02","type":"activities","url":"/activities/dromara-cloud-native-meet-02/","wordcount":140},{"author":"xiaoyu","categories":null,"content":" Dromara 源码阅读（Soul 2021 首次活动）  日期：2021年2月6日，星期日 时间：20:00 – 23:00 地点：线上腾讯会议室  活动详情 20:00 - 20:10 开场介绍近期梦码分享情况 by kimming \u0026amp;amp; 崔\n20:10 - 20:25 SPI 介绍以及Soul SPI 如何增强实现 by 朱明\n20:25 - 20:50 响应式编程介绍 by Ztzzz\n20:50 - 21:10 Soul单测小结 by 阿行\n21:10 - 21:25 容错设计 by 蒋文博\n21:25 - 21:40 Soul WebFlux加载流程以及处理请求分析 by rwby\n21:40 - 21:55 Soul限流和熔断分析 by 刘鹏辉\n21:55 - 22:05 Java常见问题总结 by 木偶\n22:05 - 22:20 如何打开社交面 by 伟楷\n22:20 - 22:30 Soul 作者 猫大人 总结与 展望 by 猫大人\n","date":1612623600,"description":"","dir":"activities/dromara-cloud-native-meet-02/","fuzzywordcount":300,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"d826e2bfc7d2e798952b6db25fd4b739d2c6ef30","permalink":"/zh/activities/dromara-cloud-native-meet-02/","publishdate":"2021-02-06T15:00:00Z","readingtime":1,"relpermalink":"/zh/activities/dromara-cloud-native-meet-02/","summary":"Dromara 源码阅读（Soul 2021 首次活动） 日期：2021年2月6日，星期日 时间：20:00 – 23:00 地点：线上腾讯会议室 活动详情 20:00 - 20:10 开场介绍近期梦码分享情","tags":["Soul","Dromara","Reactor"],"title":"Dromara Soul 源码01期阅读分享会02","type":"activities","url":"/zh/activities/dromara-cloud-native-meet-02/","wordcount":224},{"author":"shenxiangjun","categories":"Soul","content":" 插件概述 插件定位\ndivide 插件是一个 http 正向代理插件，所有的 http 请求都由该插件进行负载均衡处理（具体的负载均衡策略在规则中指定）。\n生效时机\n当请求头的 rpcType = http 且插件开启时，它将根据请求参数匹配规则，最终交由下游插件进行响应式代理调用。\n插件处理流程 1）先回顾下请求处理类插件的通用流程（AbstractSoulPlugin # execute）：\npublic Mono\u0026amp;lt;Void\u0026amp;gt; execute(final ServerWebExchange exchange, final SoulPluginChain chain) { // 获取插件数据 String pluginName = named(); final PluginData pluginData = BaseDataCache.getInstance().obtainPluginData(pluginName); if (pluginData != null \u0026amp;amp;\u0026amp;amp; pluginData.getEnabled()) { // 获取选择器数据 final Collection\u0026amp;lt;SelectorData\u0026amp;gt; selectors = BaseDataCache.getInstance().obtainSelectorData(pluginName); ... // 匹配选择器 final SelectorData selectorData = matchSelector(exchange, selectors); ... // 获取规则数据 final List\u0026amp;lt;RuleData\u0026amp;gt; rules = BaseDataCache.getInstance().obtainRuleData(selectorData.getId()); ... // 匹配规则 RuleData rule; if (selectorData.getType() == SelectorTypeEnum.FULL_FLOW.getCode()) { //get last rule = rules.get(rules.size() - 1); } else { rule = matchRule(exchange, rules); } ... // 执行自定义处理 return doExecute(exchange, chain, selectorData, rule); } // 继续执行插件链处理 return chain.execute(exchange); }  AbstractSoulPlugin 先匹配到对应的选择器和规则，匹配通过则执行插件的自定义处理。\n2）再来看看 divide 插件的自定义处理流程（DividePlugin # doExecute）：\nprotected Mono\u0026amp;lt;Void\u0026amp;gt; doExecute(final ServerWebExchange exchange, final SoulPluginChain chain, final SelectorData selector, final RuleData rule) { ... // 准备规则处理对象（内部持有：负载均衡算法名、重试次数以及超时时间） final DivideRuleHandle ruleHandle = GsonUtils.getInstance().fromJson(rule.getHandle(), DivideRuleHandle.class); // 获取选择器对应的可用服务列表 final List\u0026amp;lt;DivideUpstream\u0026amp;gt; upstreamList = UpstreamCacheManager.getInstance().findUpstreamListBySelectorId(selector.getId()); ... // 选择具体分发的服务实例ip（负载均衡） final String ip = Objects.requireNonNull(exchange.getRequest().getRemoteAddress()).getAddress().getHostAddress(); DivideUpstream divideUpstream = LoadBalanceUtils.selector(upstreamList, ruleHandle.getLoadBalance(), ip); ... //设置 http url、超时时间以及重试次数 String domain = buildDomain(divideUpstream); String realURL = buildRealURL(domain, soulContext, exchange); exchange.getAttributes().put(Constants.HTTP_URL, realURL); exchange.getAttributes().put(Constants.HTTP_TIME_OUT, ruleHandle.getTimeout()); exchange.getAttributes().put(Constants.HTTP_RETRY, ruleHandle.getRetry()); // 继续执行插件链处理 return chain.execute(exchange); }  DividePlugin 先获取到选择器对应的可用服务列表，然后进行负载均衡选择即将分发的目标服务器实例ip，最后设置最终的 url、超时时间以及重试次数并交由插件链下游进行处理。\n注意：\ndivide 插件自身只是负责根据选择器、规则和负载均衡策略选出待分发的服务器实例，并不直接向后端服务发起 http 请求。\n主机探活 上面提到，divide 需要获取服务列表，看下获取的实现（UpstreamCacheManager # findUpstreamListBySelectorId）：\npublic List\u0026amp;lt;DivideUpstream\u0026amp;gt; findUpstreamListBySelectorId(final String selectorId) { return UPSTREAM_MAP_TEMP.get(selectorId); }  内部通过 UPSTREAM_MAP_TEMP 获取存活服务列表。\nUpstreamCacheManager 内部维护了两份散列表：\n UPSTREAM_MAP：  全量服务散列表，负责存放全量的上游服务信息，key 为 选择器 id，value 为使用相同选择器的服务列表。\n UPSTREAM_MAP_TEMP：  临时服务散列表，负责存放活动的上游服务信息，key 为 选择器 id，value 为使用相同选择器的服务列表。\n前面章节我们提到，数据同步时，submit 方法同时更新了 UPSTREAM_MAP 和 UPSTREAM_MAP_TEMP， …","date":1612137600,"description":"Soul Gateway Learning Divide Plugin Source Code Interpretation","dir":"blog/soul_source_learning_16_divide_sxj/","fuzzywordcount":2500,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"b3d4d8488eec7a36af4a06ef0bf4a4c3bba065b9","permalink":"/blog/soul_source_learning_16_divide_sxj/","publishdate":"2021-02-01T00:00:00Z","readingtime":5,"relpermalink":"/blog/soul_source_learning_16_divide_sxj/","summary":"插件概述 插件定位 divide 插件是一个 http 正向代理插件，所有的 http 请求都由该插件进行负载均衡处理（具体的负载均衡策略在规则中指定）。 生效时机 当请求头的 rpcType =","tags":["Soul"],"title":"Soul Gateway Learning Divide Plugin Source Code Interpretation","type":"blog","url":"/blog/soul_source_learning_16_divide_sxj/","wordcount":2408},{"author":"沈祥俊","categories":"Soul","content":" 插件概述 插件定位\ndivide 插件是一个 http 正向代理插件，所有的 http 请求都由该插件进行负载均衡处理（具体的负载均衡策略在规则中指定）。\n生效时机\n当请求头的 rpcType = http 且插件开启时，它将根据请求参数匹配规则，最终交由下游插件进行响应式代理调用。\n插件处理流程 1）先回顾下请求处理类插件的通用流程（AbstractSoulPlugin # execute）：\npublic Mono\u0026amp;lt;Void\u0026amp;gt; execute(final ServerWebExchange exchange, final SoulPluginChain chain) { // 获取插件数据 String pluginName = named(); final PluginData pluginData = BaseDataCache.getInstance().obtainPluginData(pluginName); if (pluginData != null \u0026amp;amp;\u0026amp;amp; pluginData.getEnabled()) { // 获取选择器数据 final Collection\u0026amp;lt;SelectorData\u0026amp;gt; selectors = BaseDataCache.getInstance().obtainSelectorData(pluginName); ... // 匹配选择器 final SelectorData selectorData = matchSelector(exchange, selectors); ... // 获取规则数据 final List\u0026amp;lt;RuleData\u0026amp;gt; rules = BaseDataCache.getInstance().obtainRuleData(selectorData.getId()); ... // 匹配规则 RuleData rule; if (selectorData.getType() == SelectorTypeEnum.FULL_FLOW.getCode()) { //get last rule = rules.get(rules.size() - 1); } else { rule = matchRule(exchange, rules); } ... // 执行自定义处理 return doExecute(exchange, chain, selectorData, rule); } // 继续执行插件链处理 return chain.execute(exchange); }  AbstractSoulPlugin 先匹配到对应的选择器和规则，匹配通过则执行插件的自定义处理。\n2）再来看看 divide 插件的自定义处理流程（DividePlugin # doExecute）：\nprotected Mono\u0026amp;lt;Void\u0026amp;gt; doExecute(final ServerWebExchange exchange, final SoulPluginChain chain, final SelectorData selector, final RuleData rule) { ... // 准备规则处理对象（内部持有：负载均衡算法名、重试次数以及超时时间） final DivideRuleHandle ruleHandle = GsonUtils.getInstance().fromJson(rule.getHandle(), DivideRuleHandle.class); // 获取选择器对应的可用服务列表 final List\u0026amp;lt;DivideUpstream\u0026amp;gt; upstreamList = UpstreamCacheManager.getInstance().findUpstreamListBySelectorId(selector.getId()); ... // 选择具体分发的服务实例ip（负载均衡） final String ip = Objects.requireNonNull(exchange.getRequest().getRemoteAddress()).getAddress().getHostAddress(); DivideUpstream divideUpstream = LoadBalanceUtils.selector(upstreamList, ruleHandle.getLoadBalance(), ip); ... //设置 http url、超时时间以及重试次数 String domain = buildDomain(divideUpstream); String realURL = buildRealURL(domain, soulContext, exchange); exchange.getAttributes().put(Constants.HTTP_URL, realURL); exchange.getAttributes().put(Constants.HTTP_TIME_OUT, ruleHandle.getTimeout()); exchange.getAttributes().put(Constants.HTTP_RETRY, ruleHandle.getRetry()); // 继续执行插件链处理 return chain.execute(exchange); }  DividePlugin 先获取到选择器对应的可用服务列表，然后进行负载均衡选择即将分发的目标服务器实例ip，最后设置最终的 url、超时时间以及重试次数并交由插件链下游进行处理。\n注意：\ndivide 插件自身只是负责根据选择器、规则和负载均衡策略选出待分发的服务器实例，并不直接向后端服务发起 http 请求。\n主机探活 上面提到，divide 需要获取服务列表，看下获取的实现（UpstreamCacheManager # findUpstreamListBySelectorId）：\npublic List\u0026amp;lt;DivideUpstream\u0026amp;gt; findUpstreamListBySelectorId(final String selectorId) { return UPSTREAM_MAP_TEMP.get(selectorId); }  内部通过 UPSTREAM_MAP_TEMP 获取存活服务列表。\nUpstreamCacheManager 内部维护了两份散列表：\n UPSTREAM_MAP：  全量服务散列表，负责存放全量的上游服务信息，key 为 选择器 id，value 为使用相同选择器的服务列表。\n UPSTREAM_MAP_TEMP：  临时服务散列表，负责存放活动的上游服务信息，key 为 选择器 id，value 为使用相同选择器的服务列表。\n前面章节我们提到，数据同步时，submit 方法同时更新了 UPSTREAM_MAP 和 UPSTREAM_MAP_TEMP， …","date":1612137600,"description":"Soul网关学习divide插件源码解读","dir":"blog/soul_source_learning_16_divide_sxj/","fuzzywordcount":2500,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"701ca7bf27aab96487e8d559a3b555cfa3b49182","permalink":"/zh/blog/soul_source_learning_16_divide_sxj/","publishdate":"2021-02-01T00:00:00Z","readingtime":5,"relpermalink":"/zh/blog/soul_source_learning_16_divide_sxj/","summary":"插件概述 插件定位 divide 插件是一个 http 正向代理插件，所有的 http 请求都由该插件进行负载均衡处理（具体的负载均衡策略在规则中指定）。 生效时机 当请求头的 rpcType =","tags":["Soul"],"title":"Soul网关学习divide插件源码解读","type":"blog","url":"/zh/blog/soul_source_learning_16_divide_sxj/","wordcount":2408},{"author":"baiyu","categories":"Soul","content":" 回顾 在之前的HTTP请求初探的文章中，大体梳理了Soul插件的处理流程，也得知了DividePlugin、GlobalPlugin，WebClientPlugin，WebCilentResponsePlugin插件的具体作用，在梳理流程中，发现Soul的插件是有先后顺序的，在DividePlugin插件之前做了很多前置插件的操作，其中包含了我们本章分析的主题RateLimiterPlugin 限流插件（其中一种）。\n学习使用 阅读官方文档 对其有大概认知 rateLimiter插件\n通过官方文档的阅读我们得知了RateLimiterPlugin的两个核心点速率、容量\n以下讲解来源于官方文档\n 容量：是允许用户在一秒钟内执行的最大请求数。这是令牌桶可以保存的令牌数。 速率：是你允许用户每秒执行多少请求，而丢弃任何请求。这是令牌桶的填充速率。  可以看出RateLimiterPlugin限流核心在于令牌桶算法的实现。\nps：关于限流算法常见的有四种实现令牌桶算法，漏斗算法，计数器（固定窗口）算法，滑动窗口算法，详情看对应博客介绍\n初步使用 启用对应插件 在Soul网关系统管理-插件管理处，将状态更改为启用状态，注意此处需要填写redis相关配置，Soul令牌桶基于Redis。\n为什么Soul的令牌桶算法要基于redis？\n在集群部署情况下单机的令牌桶算法无法满足集群状态下的限流功能。\n添加限流选择器、规则 在Soul网关插件列表处，选择rate_limiter处添加规则及选择器配置，不懂如何添加的可以先阅读选择器\\规则的匹配逻辑. 在此处添加的容量及速率都为1 主要为了验证插件是否启用。\n接口对应访问 调用http://127.0.0.1:9195/http/test/findByUserId?userId=10 进行访问，速率高于1的情况下出现如下接口返回结果，代表插件成功使用。\n{ \u0026amp;quot;code\u0026amp;quot;: 429, \u0026amp;quot;message\u0026amp;quot;: \u0026amp;quot;You have been restricted, please try again later!\u0026amp;quot;, \u0026amp;quot;data\u0026amp;quot;: null }  源码阅读 带着问题读源码 如何保证在页面修改redis配置后立即生效的，后台对应的redis连接立马变更的。 答案自然数据同步脱不了干系。\n在修改插件的配置时，也发布了一个插件数据变更的事件通知，在之前梳理Soul网关同步数据整体流程时,已经得知修改的插件数据除了更改了JVM缓存内的数据外，还对对应的插件进行下发操作，如下图 而针对于RateLimiterPlugin而言，其主要实现了handlePlugin的接口，那这个对应的实现到底做了哪些事呢？\n具体的方法为RateLimiterPluginDataHandler的handlerPlugin。\npublic void handlerPlugin(final PluginData pluginData) { if (Objects.nonNull(pluginData) \u0026amp;amp;\u0026amp;amp; pluginData.getEnabled()) { //加载限流插件配置 RateLimiterConfig rateLimiterConfig = GsonUtils.getInstance().fromJson(pluginData.getConfig(), RateLimiterConfig.class); //判断是否需要重新加载redis连接值 if (Objects.isNull(Singleton.INST.get(ReactiveRedisTemplate.class)) || Objects.isNull(Singleton.INST.get(RateLimiterConfig.class)) || !rateLimiterConfig.equals(Singleton.INST.get(RateLimiterConfig.class))) { LettuceConnectionFactory lettuceConnectionFactory = createLettuceConnectionFactory(rateLimiterConfig); lettuceConnectionFactory.afterPropertiesSet(); RedisSerializer\u0026amp;lt;String\u0026amp;gt; serializer = new StringRedisSerializer(); RedisSerializationContext\u0026amp;lt;String, String\u0026amp;gt; serializationContext = RedisSerializationContext.\u0026amp;lt;String, String\u0026amp;gt;newSerializationContext().key(serializer).value(serializer).hashKey(serializer).hashValue(serializer).build(); ReactiveRedisTemplate\u0026amp;lt;String, String\u0026amp;gt; reactiveRedisTemplate = new ReactiveRedisTemplate\u0026amp;lt;\u0026amp;gt;(lettuceConnectionFactory, serializationContext); Singleton.INST.single(ReactiveRedisTemplate.class, reactiveRedisTemplate); Singleton.INST.single(RateLimiterConfig.class, rateLimiterConfig); } } }  上述代码有几个较为关键的点：\n在上述代码中将限流插件的配置和对应的redisTemplate实例放入了Singleton.INST对应map中。\n在插件数据过来时，判断是否存在redis连接实例，是否存在限流配置实例，判断当前的限流配置实例是否和传递的限流实例一致，不一致就认为配置是有更改的，就重新初始化限流实例和连接池实例放入Singleton.INST的map中，由此而言就保证了更改redis配置的热部署。\nif判断中的代码就是基于SpringDataRedis封装成一个对应redis连接池。\nps：Singleton.INST是枚举实现的单例模式。\n限流插件是底层是如何实现的呢？ Debug 调用链 RateLimiterPlugin由于需要对特定规则进行限流，所以依旧实现了AbstractSoulPlugin，之前依旧梳理过AbstractSoulPlugin的excute的方法和作用了，所以这里不重复解释，可观看Http 调用流程梳理，加深对该类的印象。\n本节重点还是看具体的doexcute方法做了哪些事。\nprotected Mono\u0026amp;lt;Void\u0026amp;gt; doExecute(final ServerWebExchange exchange, final …","date":1611964800,"description":"Soul Gateway Learning RateLimiter Plugin","dir":"blog/soul_source_learning_18_ratelimiter/","fuzzywordcount":2900,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"db0951d342de017007813dee74f0f9db075775b9","permalink":"/blog/soul_source_learning_18_ratelimiter/","publishdate":"2021-01-30T00:00:00Z","readingtime":6,"relpermalink":"/blog/soul_source_learning_18_ratelimiter/","summary":"回顾 在之前的HTTP请求初探的文章中，大体梳理了Soul插件的处理流程，也得知了DividePlugin、GlobalPlugin，WebC","tags":["Soul"],"title":"Soul Gateway Learning RateLimiter Plugin","type":"blog","url":"/blog/soul_source_learning_18_ratelimiter/","wordcount":2829},{"author":"zhuming","categories":"Soul","content":" SOUL 中 SPI 的使用 在之前分析 divide 插件的负载均衡策略时, 有看到过一行代码:\nDivideUpstream divideUpstream = LoadBalanceUtils.selector(upstreamList, ruleHandle.getLoadBalance(), ip);  当时很简单的略过了它的实现, 它的作用很容易分析, 调用一个看似工具类的方法, 传入多个节点组成的集群, 返回一个节点. 这是一个负载均衡器.\n但是细节却非常多, 最重要的一点是使用 SPI 来选择具体的实现类. 看看这个方法的代码:\npublic class LoadBalanceUtils { public static DivideUpstream selector(final List\u0026amp;lt;DivideUpstream\u0026amp;gt; upstreamList, final String algorithm, final String ip) { // 调用自定义的 SPI 得到一个子类 LoadBalance loadBalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getJoin(algorithm); return loadBalance.select(upstreamList, ip); } }  后面的是调用具体子类的 select() 方法, 根据子类的不同实现, 最终会表现出各种形式. 目前的子类实现有:\n HashLoadBalance RandomLoadBalance RoundRobinLoadBalance  关键就在于 ExtensionLoader.getExtensionLoader(LoadBalance.class).getJoin(algorithm); 这行.\n在研究它之前, 我们先不妨研究下 Java 提供的 SPI 机制.\nJava SPI \u0026amp;lt;\u0026amp;lt;高可用可伸缩微服务架构\u0026amp;gt;\u0026amp;gt; 第3章 Apache Dubbo 框架的原理与实现 中有这样的一句定义.\n SPI 全称为 Service Provider Interface, 是 JDK 内置的一种服务提供发现功能, 一种动态替换发现的机制. 举个例子, 要想在运行时动态地给一个接口添加实现, 只需要添加一个实现即可.\n 书中也有个非常形象的脑图, 展示了 SPI 的使用:\n也就是说在我们代码中的实现里, 无需去写入一个 Factory 工厂, 用 MAP 去包装一些子类, 最终返回的类型是父接口. 只需要定义好资源文件, 让父接口与它的子类在文件中写明, 即可通过设置好的方式拿到所有定义的子类对象:\nServiceLoader\u0026amp;lt;Interface\u0026amp;gt; loaders = ServiceLoader.load(Interface.class) for(Interface interface : loaders){ System.out.println(interface.toString()); }  这种方式相比与普通的工厂模式, 肯定是更符合开闭原则, 新加入一个子类不用去修改工厂方法, 而是编辑资源文件.\n从一个 Demo 开始 按照 SPI 的规范, 我建了一个 demo, 看看具体的实现效果\nAnimal 中定义一个 run() 方法, 而子类实现它.\npublic interface Animal { void run(); } public class Dog implements Animal { @Override public void run() { System.out.println(\u0026amp;quot;狗在跑\u0026amp;quot;); } } public class Horse implements Animal { @Override public void run() { System.out.println(\u0026amp;quot;马在跑\u0026amp;quot;); } }  使用 SPI 的加载类, 得到子类的执行结果:\nprivate static void test() { final ServiceLoader\u0026amp;lt;Animal\u0026amp;gt; load = ServiceLoader.load(Animal.class); for (Animal animal : load) { System.out.println(animal); animal.run(); } }  在调用后我们得到之前在资源文件中写入的实现类, 并成功调取它们各自的 run() 方法.\n到这里我产生一个疑问, 是否每次调用 ServiceLoader.load(Animal.class) 返回的都是同一个对象? 如果是我猜测它是在启动时加载到缓存了, 如果不是, 可能就是在底层用了反射, 每次调用都有一定消耗. 我们看看下面的实验:\npublic static void main(String[] args) { for (int i = 0; i \u0026amp;lt; 2; i++) { test(); System.out.println(\u0026amp;quot;----------\u0026amp;quot;); } } private static void test() { final ServiceLoader\u0026amp;lt;Animal\u0026amp;gt; load = ServiceLoader.load(Animal.class); for (Animal animal : load) { System.out.println(animal); animal.run(); } }  两次调用出现的对象却不一样, 不由让我替其性能揪心一下, 所以我们先分析下它的代码, 看看到底怎么实现.\nSPI 的实现 找到 java.util,ServiceLoaders 这个类, 入眼最醒目的就是之前我们按照规范放置资源文件的目录\npublic final class ServiceLoader\u0026amp;lt;S\u0026amp;gt; implements Iterable\u0026amp;lt;S\u0026amp;gt; { private static final String PREFIX = \u0026amp;quot;META-INF/services/\u0026amp;quot;; }  在 debug PREFIX 属性的被调用处时, 发现 ServiceLoader.load 实际是使用懒加载的方式, 并没有在调用它的时候, 找寻到实际返回类, 而是在遍历时查找.\n它的懒加载具体实现在如下代码:\npublic final class ServiceLoader\u0026amp;lt;S\u0026amp;gt; implements Iterable\u0026amp;lt;S\u0026amp;gt; { public static \u0026amp;lt;S\u0026amp;gt; ServiceLoader\u0026amp;lt;S\u0026amp;gt; load(Class\u0026amp;lt;S\u0026amp;gt; service) { // 获取当前的类加载器 (我们自己的通常是弟中弟 AppClassLoader ) ClassLoader cl = …","date":1611964800,"description":"Soul Gateway Learning SPI","dir":"blog/soul_source_learning_11_SPI/","fuzzywordcount":5500,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"8c7be975f6b6695eae8651599bb6c5897e045ced","permalink":"/blog/soul_source_learning_11_spi/","publishdate":"2021-01-30T00:00:00Z","readingtime":11,"relpermalink":"/blog/soul_source_learning_11_spi/","summary":"SOUL 中 SPI 的使用 在之前分析 divide 插件的负载均衡策略时, 有看到过一行代码: DivideUpstream divideUpstream = LoadBalanceUtils.selector(upstreamList, ruleHandle.getLoadBalance(), ip); 当时很简单的略过了它的实现, 它的作用很容易分析, 调用一个看似工具","tags":["Soul"],"title":"Soul Gateway Learning SPI","type":"blog","url":"/blog/soul_source_learning_11_spi/","wordcount":5445},{"author":"百钰","categories":"Soul","content":" 回顾 在之前的HTTP请求初探的文章中，大体梳理了Soul插件的处理流程，也得知了DividePlugin、GlobalPlugin，WebClientPlugin，WebCilentResponsePlugin插件的具体作用，在梳理流程中，发现Soul的插件是有先后顺序的，在DividePlugin插件之前做了很多前置插件的操作，其中包含了我们本章分析的主题RateLimiterPlugin 限流插件（其中一种）。\n学习使用 阅读官方文档 对其有大概认知 rateLimiter插件\n通过官方文档的阅读我们得知了RateLimiterPlugin的两个核心点速率、容量\n以下讲解来源于官方文档\n 容量：是允许用户在一秒钟内执行的最大请求数。这是令牌桶可以保存的令牌数。 速率：是你允许用户每秒执行多少请求，而丢弃任何请求。这是令牌桶的填充速率。  可以看出RateLimiterPlugin限流核心在于令牌桶算法的实现。\nps：关于限流算法常见的有四种实现令牌桶算法，漏斗算法，计数器（固定窗口）算法，滑动窗口算法，详情看对应博客介绍\n初步使用 启用对应插件 在Soul网关系统管理-插件管理处，将状态更改为启用状态，注意此处需要填写redis相关配置，Soul令牌桶基于Redis。\n为什么Soul的令牌桶算法要基于redis？\n在集群部署情况下单机的令牌桶算法无法满足集群状态下的限流功能。\n添加限流选择器、规则 在Soul网关插件列表处，选择rate_limiter处添加规则及选择器配置，不懂如何添加的可以先阅读选择器\\规则的匹配逻辑. 在此处添加的容量及速率都为1 主要为了验证插件是否启用。\n接口对应访问 调用http://127.0.0.1:9195/http/test/findByUserId?userId=10 进行访问，速率高于1的情况下出现如下接口返回结果，代表插件成功使用。\n{ \u0026amp;quot;code\u0026amp;quot;: 429, \u0026amp;quot;message\u0026amp;quot;: \u0026amp;quot;You have been restricted, please try again later!\u0026amp;quot;, \u0026amp;quot;data\u0026amp;quot;: null }  源码阅读 带着问题读源码 如何保证在页面修改redis配置后立即生效的，后台对应的redis连接立马变更的。 答案自然数据同步脱不了干系。\n在修改插件的配置时，也发布了一个插件数据变更的事件通知，在之前梳理Soul网关同步数据整体流程时,已经得知修改的插件数据除了更改了JVM缓存内的数据外，还对对应的插件进行下发操作，如下图 而针对于RateLimiterPlugin而言，其主要实现了handlePlugin的接口，那这个对应的实现到底做了哪些事呢？\n具体的方法为RateLimiterPluginDataHandler的handlerPlugin。\npublic void handlerPlugin(final PluginData pluginData) { if (Objects.nonNull(pluginData) \u0026amp;amp;\u0026amp;amp; pluginData.getEnabled()) { //加载限流插件配置 RateLimiterConfig rateLimiterConfig = GsonUtils.getInstance().fromJson(pluginData.getConfig(), RateLimiterConfig.class); //判断是否需要重新加载redis连接值 if (Objects.isNull(Singleton.INST.get(ReactiveRedisTemplate.class)) || Objects.isNull(Singleton.INST.get(RateLimiterConfig.class)) || !rateLimiterConfig.equals(Singleton.INST.get(RateLimiterConfig.class))) { LettuceConnectionFactory lettuceConnectionFactory = createLettuceConnectionFactory(rateLimiterConfig); lettuceConnectionFactory.afterPropertiesSet(); RedisSerializer\u0026amp;lt;String\u0026amp;gt; serializer = new StringRedisSerializer(); RedisSerializationContext\u0026amp;lt;String, String\u0026amp;gt; serializationContext = RedisSerializationContext.\u0026amp;lt;String, String\u0026amp;gt;newSerializationContext().key(serializer).value(serializer).hashKey(serializer).hashValue(serializer).build(); ReactiveRedisTemplate\u0026amp;lt;String, String\u0026amp;gt; reactiveRedisTemplate = new ReactiveRedisTemplate\u0026amp;lt;\u0026amp;gt;(lettuceConnectionFactory, serializationContext); Singleton.INST.single(ReactiveRedisTemplate.class, reactiveRedisTemplate); Singleton.INST.single(RateLimiterConfig.class, rateLimiterConfig); } } }  上述代码有几个较为关键的点：\n在上述代码中将限流插件的配置和对应的redisTemplate实例放入了Singleton.INST对应map中。\n在插件数据过来时，判断是否存在redis连接实例，是否存在限流配置实例，判断当前的限流配置实例是否和传递的限流实例一致，不一致就认为配置是有更改的，就重新初始化限流实例和连接池实例放入Singleton.INST的map中，由此而言就保证了更改redis配置的热部署。\nif判断中的代码就是基于SpringDataRedis封装成一个对应redis连接池。\nps：Singleton.INST是枚举实现的单例模式。\n限流插件是底层是如何实现的呢？ Debug 调用链 RateLimiterPlugin由于需要对特定规则进行限流，所以依旧实现了AbstractSoulPlugin，之前依旧梳理过AbstractSoulPlugin的excute的方法和作用了，所以这里不重复解释，可观看Http 调用流程梳理，加深对该类的印象。\n本节重点还是看具体的doexcute方法做了哪些事。\nprotected Mono\u0026amp;lt;Void\u0026amp;gt; doExecute(final ServerWebExchange exchange, final …","date":1611964800,"description":"Soul网关学习RateLimiter插件原理解析","dir":"blog/soul_source_learning_18_ratelimiter/","fuzzywordcount":2900,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"8321e00db2250fb31e2ca9fe5378a4053db58e15","permalink":"/zh/blog/soul_source_learning_18_ratelimiter/","publishdate":"2021-01-30T00:00:00Z","readingtime":6,"relpermalink":"/zh/blog/soul_source_learning_18_ratelimiter/","summary":"回顾 在之前的HTTP请求初探的文章中，大体梳理了Soul插件的处理流程，也得知了DividePlugin、GlobalPlugin，WebC","tags":["Soul"],"title":"Soul网关学习RateLimiter插件原理解析","type":"blog","url":"/zh/blog/soul_source_learning_18_ratelimiter/","wordcount":2829},{"author":"朱明","categories":"Soul","content":" SOUL 中 SPI 的使用 在之前分析 divide 插件的负载均衡策略时, 有看到过一行代码:\nDivideUpstream divideUpstream = LoadBalanceUtils.selector(upstreamList, ruleHandle.getLoadBalance(), ip);  当时很简单的略过了它的实现, 它的作用很容易分析, 调用一个看似工具类的方法, 传入多个节点组成的集群, 返回一个节点. 这是一个负载均衡器.\n但是细节却非常多, 最重要的一点是使用 SPI 来选择具体的实现类. 看看这个方法的代码:\npublic class LoadBalanceUtils { public static DivideUpstream selector(final List\u0026amp;lt;DivideUpstream\u0026amp;gt; upstreamList, final String algorithm, final String ip) { // 调用自定义的 SPI 得到一个子类 LoadBalance loadBalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getJoin(algorithm); return loadBalance.select(upstreamList, ip); } }  后面的是调用具体子类的 select() 方法, 根据子类的不同实现, 最终会表现出各种形式. 目前的子类实现有:\n HashLoadBalance RandomLoadBalance RoundRobinLoadBalance  关键就在于 ExtensionLoader.getExtensionLoader(LoadBalance.class).getJoin(algorithm); 这行.\n在研究它之前, 我们先不妨研究下 Java 提供的 SPI 机制.\nJava SPI \u0026amp;lt;\u0026amp;lt;高可用可伸缩微服务架构\u0026amp;gt;\u0026amp;gt; 第3章 Apache Dubbo 框架的原理与实现 中有这样的一句定义.\n SPI 全称为 Service Provider Interface, 是 JDK 内置的一种服务提供发现功能, 一种动态替换发现的机制. 举个例子, 要想在运行时动态地给一个接口添加实现, 只需要添加一个实现即可.\n 书中也有个非常形象的脑图, 展示了 SPI 的使用:\n也就是说在我们代码中的实现里, 无需去写入一个 Factory 工厂, 用 MAP 去包装一些子类, 最终返回的类型是父接口. 只需要定义好资源文件, 让父接口与它的子类在文件中写明, 即可通过设置好的方式拿到所有定义的子类对象:\nServiceLoader\u0026amp;lt;Interface\u0026amp;gt; loaders = ServiceLoader.load(Interface.class) for(Interface interface : loaders){ System.out.println(interface.toString()); }  这种方式相比与普通的工厂模式, 肯定是更符合开闭原则, 新加入一个子类不用去修改工厂方法, 而是编辑资源文件.\n从一个 Demo 开始 按照 SPI 的规范, 我建了一个 demo, 看看具体的实现效果\nAnimal 中定义一个 run() 方法, 而子类实现它.\npublic interface Animal { void run(); } public class Dog implements Animal { @Override public void run() { System.out.println(\u0026amp;quot;狗在跑\u0026amp;quot;); } } public class Horse implements Animal { @Override public void run() { System.out.println(\u0026amp;quot;马在跑\u0026amp;quot;); } }  使用 SPI 的加载类, 得到子类的执行结果:\nprivate static void test() { final ServiceLoader\u0026amp;lt;Animal\u0026amp;gt; load = ServiceLoader.load(Animal.class); for (Animal animal : load) { System.out.println(animal); animal.run(); } }  在调用后我们得到之前在资源文件中写入的实现类, 并成功调取它们各自的 run() 方法.\n到这里我产生一个疑问, 是否每次调用 ServiceLoader.load(Animal.class) 返回的都是同一个对象? 如果是我猜测它是在启动时加载到缓存了, 如果不是, 可能就是在底层用了反射, 每次调用都有一定消耗. 我们看看下面的实验:\npublic static void main(String[] args) { for (int i = 0; i \u0026amp;lt; 2; i++) { test(); System.out.println(\u0026amp;quot;----------\u0026amp;quot;); } } private static void test() { final ServiceLoader\u0026amp;lt;Animal\u0026amp;gt; load = ServiceLoader.load(Animal.class); for (Animal animal : load) { System.out.println(animal); animal.run(); } }  两次调用出现的对象却不一样, 不由让我替其性能揪心一下, 所以我们先分析下它的代码, 看看到底怎么实现.\nSPI 的实现 找到 java.util,ServiceLoaders 这个类, 入眼最醒目的就是之前我们按照规范放置资源文件的目录\npublic final class ServiceLoader\u0026amp;lt;S\u0026amp;gt; implements Iterable\u0026amp;lt;S\u0026amp;gt; { private static final String PREFIX = \u0026amp;quot;META-INF/services/\u0026amp;quot;; }  在 debug PREFIX 属性的被调用处时, 发现 ServiceLoader.load 实际是使用懒加载的方式, 并没有在调用它的时候, 找寻到实际返回类, 而是在遍历时查找.\n它的懒加载具体实现在如下代码:\npublic final class ServiceLoader\u0026amp;lt;S\u0026amp;gt; implements Iterable\u0026amp;lt;S\u0026amp;gt; { public static \u0026amp;lt;S\u0026amp;gt; ServiceLoader\u0026amp;lt;S\u0026amp;gt; load(Class\u0026amp;lt;S\u0026amp;gt; service) { // 获取当前的类加载器 (我们自己的通常是弟中弟 AppClassLoader ) ClassLoader cl = …","date":1611964800,"description":"Soul网关学习SPI学习使用","dir":"blog/soul_source_learning_11_SPI/","fuzzywordcount":5500,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"4abb2d54aa86524080a944e2d4b948bdaa0edd36","permalink":"/zh/blog/soul_source_learning_11_spi/","publishdate":"2021-01-30T00:00:00Z","readingtime":11,"relpermalink":"/zh/blog/soul_source_learning_11_spi/","summary":"SOUL 中 SPI 的使用 在之前分析 divide 插件的负载均衡策略时, 有看到过一行代码: DivideUpstream divideUpstream = LoadBalanceUtils.selector(upstreamList, ruleHandle.getLoadBalance(), ip); 当时很简单的略过了它的实现, 它的作用很容易分析, 调用一个看似工具","tags":["Soul"],"title":"Soul网关学习SPI学习使用","type":"blog","url":"/zh/blog/soul_source_learning_11_spi/","wordcount":5445},{"author":"tangtian","categories":"Soul","content":" 介绍 sign插件用来对请求进行签名认证的插件\nAK/SK 介绍 AK/SK（Access Key ID/Secret Access Key）即访问密钥，包含访问密钥ID（AK）和秘密访问密钥（SK）两部分，主要用于对用户的调用行为进行鉴权和认证。\n插件使用-以（/dubbo/findAll）为例 在SoulBootstrap的 pom.xml 文件中添加 sign 的支持 \u0026amp;lt;!-- soul sign plugin start--\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;soul-spring-boot-starter-plugin-sign\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!-- soul sign plugin end--\u0026amp;gt;  新增appKey，secretKey 配置选择器和规则器 添加选择器 添加规则器 增加获取鉴权服务 在自己服务中增加一个对外访问的方法\n@GetMapping(\u0026amp;quot;/authUrl\u0026amp;quot;) public String authUrl() { Map\u0026amp;lt;String, String\u0026amp;gt; map = Maps.newHashMapWithExpectedSize(2); //timestamp为毫秒数的字符串形式 String.valueOf(LocalDateTime.now().toInstant(ZoneOffset.of(\u0026amp;quot;+8\u0026amp;quot;)).toEpochMilli()) String timetamp = String.valueOf(LocalDateTime.now().toInstant(ZoneOffset.of(\u0026amp;quot;+8\u0026amp;quot;)).toEpochMilli()) ; System.out.println(timetamp); map.put(\u0026amp;quot;timestamp\u0026amp;quot;,timetamp); //值应该为毫秒数的字符串形式 map.put(\u0026amp;quot;path\u0026amp;quot;, \u0026amp;quot;/dubbo/findAll\u0026amp;quot;); map.put(\u0026amp;quot;version\u0026amp;quot;, \u0026amp;quot;1.0.0\u0026amp;quot;); List\u0026amp;lt;String\u0026amp;gt; storedKeys = Arrays.stream(map.keySet() .toArray(new String[]{})) .sorted(Comparator.naturalOrder()) .collect(Collectors.toList()); final String sign = storedKeys.stream() .map(key -\u0026amp;gt; String.join(\u0026amp;quot;\u0026amp;quot;, key, map.get(key))) .collect(Collectors.joining()).trim() .concat(\u0026amp;quot;D19CF79F647A465AB9C5C66F430CAD28\u0026amp;quot;);//SECRETkey return DigestUtils.md5DigestAsHex(sign.getBytes()).toUpperCase(); }  下面需要注意的 在网关中增加鉴权头信息 请求的结果演示 通过的返回 5min超时的返回 appKey填写错误的返回 签名错误的返回 禁用sign插件的返回 sign插件的实现分析 java中Pair 简单的说就是pair保存的是一对key value，而map可以保存多对key value。 SignPlugin插件调用DefaultSignService中signVerify方法 判断sign 插件是否可用，如果可用获取在global 插件存入的soulContext并调用verify方法\nif (signData != null \u0026amp;amp;\u0026amp;amp; signData.getEnabled()) { final SoulContext soulContext = exchange.getAttribute(Constants.CONTEXT); assert soulContext != null; return verify(soulContext, exchange); }  verify方法中 判断请求头信息是否正确 如果不正确就抛出 log.error(\u0026amp;ldquo;sign parameters are incomplete,{}\u0026amp;rdquo;, soulContext)异常\nif (StringUtils.isBlank(soulContext.getAppKey()) || StringUtils.isBlank(soulContext.getSign()) || StringUtils.isBlank(soulContext.getTimestamp())) { log.error(\u0026amp;quot;sign parameters are incomplete,{}\u0026amp;quot;, soulContext); return Pair.of(Boolean.FALSE, Constants.SIGN_PARAMS_ERROR); }  判断请求时间是否超时\nif (between \u0026amp;gt; delay) { return Pair.of(Boolean.FALSE, String.format(SoulResultEnum.SING_TIME_IS_TIMEOUT.getMsg(), delay)); }  没有超时继续调用sign方法 获取认证数据，这个数据在soulAdmin 中配置\nAppAuthData appAuthData = SignAuthDataCache.getInstance().obtainAuthData(soulContext.getAppKey());  后面对appAuthData数据进行判断，数据有错误就不通过 对获取的参数再次签名，判断传入的和再次签名的是否一样\nString sigKey = SignUtils.generateSign(appAuthData.getAppSecret(), buildParamsMap(soulContext));  如果都校验都通过就完成认证 访问请求。\n","date":1611878400,"description":"Soul Gateway Learning Sign Plugin","dir":"blog/soul_source_learning_12_sign/","fuzzywordcount":800,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"626af87e520b8608a9d11d3e8b55029bba37fd88","permalink":"/blog/soul_source_learning_12_sign/","publishdate":"2021-01-29T00:00:00Z","readingtime":2,"relpermalink":"/blog/soul_source_learning_12_sign/","summary":"介绍 sign插件用来对请求进行签名认证的插件 AK/SK 介绍 AK/SK（Access Key ID/Secret Access Key）即访问密钥，包含访问密钥ID（AK）和秘密访问密钥（","tags":["Soul"],"title":"Soul Gateway Learning Sign Plugin","type":"blog","url":"/blog/soul_source_learning_12_sign/","wordcount":759},{"author":"唐甜","categories":"Soul","content":" 介绍 sign插件用来对请求进行签名认证的插件\nAK/SK 介绍 AK/SK（Access Key ID/Secret Access Key）即访问密钥，包含访问密钥ID（AK）和秘密访问密钥（SK）两部分，主要用于对用户的调用行为进行鉴权和认证。\n插件使用-以（/dubbo/findAll）为例 在SoulBootstrap的 pom.xml 文件中添加 sign 的支持 \u0026amp;lt;!-- soul sign plugin start--\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;soul-spring-boot-starter-plugin-sign\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!-- soul sign plugin end--\u0026amp;gt;  新增appKey，secretKey 配置选择器和规则器 添加选择器 添加规则器 增加获取鉴权服务 在自己服务中增加一个对外访问的方法\n@GetMapping(\u0026amp;quot;/authUrl\u0026amp;quot;) public String authUrl() { Map\u0026amp;lt;String, String\u0026amp;gt; map = Maps.newHashMapWithExpectedSize(2); //timestamp为毫秒数的字符串形式 String.valueOf(LocalDateTime.now().toInstant(ZoneOffset.of(\u0026amp;quot;+8\u0026amp;quot;)).toEpochMilli()) String timetamp = String.valueOf(LocalDateTime.now().toInstant(ZoneOffset.of(\u0026amp;quot;+8\u0026amp;quot;)).toEpochMilli()) ; System.out.println(timetamp); map.put(\u0026amp;quot;timestamp\u0026amp;quot;,timetamp); //值应该为毫秒数的字符串形式 map.put(\u0026amp;quot;path\u0026amp;quot;, \u0026amp;quot;/dubbo/findAll\u0026amp;quot;); map.put(\u0026amp;quot;version\u0026amp;quot;, \u0026amp;quot;1.0.0\u0026amp;quot;); List\u0026amp;lt;String\u0026amp;gt; storedKeys = Arrays.stream(map.keySet() .toArray(new String[]{})) .sorted(Comparator.naturalOrder()) .collect(Collectors.toList()); final String sign = storedKeys.stream() .map(key -\u0026amp;gt; String.join(\u0026amp;quot;\u0026amp;quot;, key, map.get(key))) .collect(Collectors.joining()).trim() .concat(\u0026amp;quot;D19CF79F647A465AB9C5C66F430CAD28\u0026amp;quot;);//SECRETkey return DigestUtils.md5DigestAsHex(sign.getBytes()).toUpperCase(); }  下面需要注意的 在网关中增加鉴权头信息 请求的结果演示 通过的返回 5min超时的返回 appKey填写错误的返回 签名错误的返回 禁用sign插件的返回 sign插件的实现分析 java中Pair 简单的说就是pair保存的是一对key value，而map可以保存多对key value。 SignPlugin插件调用DefaultSignService中signVerify方法 判断sign 插件是否可用，如果可用获取在global 插件存入的soulContext并调用verify方法\nif (signData != null \u0026amp;amp;\u0026amp;amp; signData.getEnabled()) { final SoulContext soulContext = exchange.getAttribute(Constants.CONTEXT); assert soulContext != null; return verify(soulContext, exchange); }  verify方法中 判断请求头信息是否正确 如果不正确就抛出 log.error(\u0026amp;ldquo;sign parameters are incomplete,{}\u0026amp;rdquo;, soulContext)异常\nif (StringUtils.isBlank(soulContext.getAppKey()) || StringUtils.isBlank(soulContext.getSign()) || StringUtils.isBlank(soulContext.getTimestamp())) { log.error(\u0026amp;quot;sign parameters are incomplete,{}\u0026amp;quot;, soulContext); return Pair.of(Boolean.FALSE, Constants.SIGN_PARAMS_ERROR); }  判断请求时间是否超时\nif (between \u0026amp;gt; delay) { return Pair.of(Boolean.FALSE, String.format(SoulResultEnum.SING_TIME_IS_TIMEOUT.getMsg(), delay)); }  没有超时继续调用sign方法 获取认证数据，这个数据在soulAdmin 中配置\nAppAuthData appAuthData = SignAuthDataCache.getInstance().obtainAuthData(soulContext.getAppKey());  后面对appAuthData数据进行判断，数据有错误就不通过 对获取的参数再次签名，判断传入的和再次签名的是否一样\nString sigKey = SignUtils.generateSign(appAuthData.getAppSecret(), buildParamsMap(soulContext));  如果都校验都通过就完成认证 访问请求。\n","date":1611878400,"description":"Soul网关学习Sign插件","dir":"blog/soul_source_learning_12_sign/","fuzzywordcount":800,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"d15d11bc3b2a87978e028733b64e43d034741847","permalink":"/zh/blog/soul_source_learning_12_sign/","publishdate":"2021-01-29T00:00:00Z","readingtime":2,"relpermalink":"/zh/blog/soul_source_learning_12_sign/","summary":"介绍 sign插件用来对请求进行签名认证的插件 AK/SK 介绍 AK/SK（Access Key ID/Secret Access Key）即访问密钥，包含访问密钥ID（AK）和秘密访问密钥（","tags":["Soul"],"title":"Soul网关学习Sign插件","type":"blog","url":"/zh/blog/soul_source_learning_12_sign/","wordcount":759},{"author":"zhuming","categories":"Soul","content":" 后台与网关数据同步 (Http长轮询篇) 长轮询分析的最后一篇, 总结网关端的长轮询的实现, 以及数据流动方式.\n网关端长轮询的流程总体也分两个模块: 一是启动时拉取, 二是轮询监听变化\n网关启动时拉取数据 网关启动后, 会调用后台提供的接口拉取数据, 并将数据发送到各个插件的数据处理类中\n下面展示下网关启动拉取数据的处理流程: 这几个处理步骤被分散到下面这些类的方法协作中:\nHttpSyncDataService#start: 网关启动时, HttpSyncDataService 初始化会调用 start() 方法, 该方法会调用后台拉取数据, 并开启多个线程进行轮询监听 (这块在下个模块分析)\npublic class HttpSyncDataService implements SyncDataService, AutoCloseable { private void start() { // 防止二次调用的CAS操作 if (RUNNING.compareAndSet(false, true)) { // 这里是本次流程的重点, 调用拉取数据的方法 this.fetchGroupConfig(ConfigGroupEnum.values()); int threadSize = serverList.size(); // 这里将在下个模块分析, 会根据后台集群开启线程轮询监听 this.executor = new ThreadPoolExecutor(threadSize, threadSize, 60L, TimeUnit.SECONDS, new LinkedBlockingQueue\u0026amp;lt;\u0026amp;gt;(), SoulThreadFactory.create(\u0026amp;quot;http-long-polling\u0026amp;quot;, true)); this.serverList.forEach(server -\u0026amp;gt; this.executor.execute(new HttpLongPollingTask(server))); } else { log.info(\u0026amp;quot;soul http long polling was started, executor=[{}]\u0026amp;quot;, executor); } } }  HttpSyncDataService#fetchGroupConfig: 作用仅是根据数据类型, 循环多次调用拉取数据方法(针对同一个后台会请求多次, 每次拉取某一种数据类型的信息), 这里的数据类型指的是 plugin、rule、selector 等\nprivate void fetchGroupConfig(final ConfigGroupEnum... groups) throws SoulException { for (int index = 0; index \u0026amp;lt; this.serverList.size(); index++) { String server = serverList.get(index); try { // 根据传入的数据类型枚举, 多次调用拉取数据方法 this.doFetchGroupConfig(server, groups); break; } catch (SoulException e) { if (index \u0026amp;gt;= serverList.size() - 1) { throw e; } log.warn(\u0026amp;quot;fetch config fail, try another one: {}\u0026amp;quot;, serverList.get(index + 1)); } } }  HttpSyncDataService#doFetchGroupConfig: 请求后台的 /configs/fetch 接口, 拿到某个类型的数据, 并更新缓存. 更新缓存前会检测是否变动, 如果变动则结束, 数据未发生变动则睡眠30s (由于是第一次启动, 数据为空的情况下肯定会更新缓存, 所以会直接结束)\nprivate void doFetchGroupConfig(final String server, final ConfigGroupEnum... groups) { StringBuilder params = new StringBuilder(); for (ConfigGroupEnum groupKey : groups) { params.append(\u0026amp;quot;groupKeys\u0026amp;quot;).append(\u0026amp;quot;=\u0026amp;quot;).append(groupKey.name()).append(\u0026amp;quot;\u0026amp;amp;\u0026amp;quot;); } // 具体请求路径, 拉取后台数据 String url = server + \u0026amp;quot;/configs/fetch?\u0026amp;quot; + StringUtils.removeEnd(params.toString(), \u0026amp;quot;\u0026amp;amp;\u0026amp;quot;); log.info(\u0026amp;quot;request configs: [{}]\u0026amp;quot;, url); String json = null; try { json = this.httpClient.getForObject(url, String.class); } catch (RestClientException e) { String message = String.format(\u0026amp;quot;fetch config fail from server[%s], %s\u0026amp;quot;, url, e.getMessage()); log.warn(message); throw new SoulException(message, e); } // 修改缓存信息 boolean updated = this.updateCacheWithJson(json); // 判断是否修改, 修改则直接结束 if (updated) { log.info(\u0026amp;quot;get latest configs: [{}]\u0026amp;quot;, json); return; } log.info(\u0026amp;quot;The config of the server[{}] has not been updated or is out of date. Wait for 30s to listen for changes again.\u0026amp;quot;, server); ThreadUtils.sleep(TimeUnit.SECONDS, 30); }  HttpSyncDataService#updateCacheWithJson: 取出响应信息中的 data , 即变化的数据信息, 传给数据刷新工厂 DataRefreshFactory\nprivate DataRefreshFactory factory; public HttpSyncDataService(...){ this.factory = new …","date":1611705600,"description":"Soul Gateway Learns Http Long Polling Analysis","dir":"blog/soul_source_learning_09_httplongpolling_02/","fuzzywordcount":1800,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"1d07994f587748cdd801d4de94abcb2cf808e183","permalink":"/blog/soul_source_learning_09_httplongpolling_02/","publishdate":"2021-01-27T00:00:00Z","readingtime":4,"relpermalink":"/blog/soul_source_learning_09_httplongpolling_02/","summary":"后台与网关数据同步 (Http长轮询篇) 长轮询分析的最后一篇, 总结网关端的长轮询的实现, 以及数据流动方式. 网关端长轮询的流程总体也分两个模块:","tags":["Soul"],"title":"Soul Gateway Learns Http Long Polling Analysis 02","type":"blog","url":"/blog/soul_source_learning_09_httplongpolling_02/","wordcount":1750},{"author":"朱明","categories":"Soul","content":" 后台与网关数据同步 (Http长轮询篇) 长轮询分析的最后一篇, 总结网关端的长轮询的实现, 以及数据流动方式.\n网关端长轮询的流程总体也分两个模块: 一是启动时拉取, 二是轮询监听变化\n网关启动时拉取数据 网关启动后, 会调用后台提供的接口拉取数据, 并将数据发送到各个插件的数据处理类中\n下面展示下网关启动拉取数据的处理流程: 这几个处理步骤被分散到下面这些类的方法协作中:\nHttpSyncDataService#start: 网关启动时, HttpSyncDataService 初始化会调用 start() 方法, 该方法会调用后台拉取数据, 并开启多个线程进行轮询监听 (这块在下个模块分析)\npublic class HttpSyncDataService implements SyncDataService, AutoCloseable { private void start() { // 防止二次调用的CAS操作 if (RUNNING.compareAndSet(false, true)) { // 这里是本次流程的重点, 调用拉取数据的方法 this.fetchGroupConfig(ConfigGroupEnum.values()); int threadSize = serverList.size(); // 这里将在下个模块分析, 会根据后台集群开启线程轮询监听 this.executor = new ThreadPoolExecutor(threadSize, threadSize, 60L, TimeUnit.SECONDS, new LinkedBlockingQueue\u0026amp;lt;\u0026amp;gt;(), SoulThreadFactory.create(\u0026amp;quot;http-long-polling\u0026amp;quot;, true)); this.serverList.forEach(server -\u0026amp;gt; this.executor.execute(new HttpLongPollingTask(server))); } else { log.info(\u0026amp;quot;soul http long polling was started, executor=[{}]\u0026amp;quot;, executor); } } }  HttpSyncDataService#fetchGroupConfig: 作用仅是根据数据类型, 循环多次调用拉取数据方法(针对同一个后台会请求多次, 每次拉取某一种数据类型的信息), 这里的数据类型指的是 plugin、rule、selector 等\nprivate void fetchGroupConfig(final ConfigGroupEnum... groups) throws SoulException { for (int index = 0; index \u0026amp;lt; this.serverList.size(); index++) { String server = serverList.get(index); try { // 根据传入的数据类型枚举, 多次调用拉取数据方法 this.doFetchGroupConfig(server, groups); break; } catch (SoulException e) { if (index \u0026amp;gt;= serverList.size() - 1) { throw e; } log.warn(\u0026amp;quot;fetch config fail, try another one: {}\u0026amp;quot;, serverList.get(index + 1)); } } }  HttpSyncDataService#doFetchGroupConfig: 请求后台的 /configs/fetch 接口, 拿到某个类型的数据, 并更新缓存. 更新缓存前会检测是否变动, 如果变动则结束, 数据未发生变动则睡眠30s (由于是第一次启动, 数据为空的情况下肯定会更新缓存, 所以会直接结束)\nprivate void doFetchGroupConfig(final String server, final ConfigGroupEnum... groups) { StringBuilder params = new StringBuilder(); for (ConfigGroupEnum groupKey : groups) { params.append(\u0026amp;quot;groupKeys\u0026amp;quot;).append(\u0026amp;quot;=\u0026amp;quot;).append(groupKey.name()).append(\u0026amp;quot;\u0026amp;amp;\u0026amp;quot;); } // 具体请求路径, 拉取后台数据 String url = server + \u0026amp;quot;/configs/fetch?\u0026amp;quot; + StringUtils.removeEnd(params.toString(), \u0026amp;quot;\u0026amp;amp;\u0026amp;quot;); log.info(\u0026amp;quot;request configs: [{}]\u0026amp;quot;, url); String json = null; try { json = this.httpClient.getForObject(url, String.class); } catch (RestClientException e) { String message = String.format(\u0026amp;quot;fetch config fail from server[%s], %s\u0026amp;quot;, url, e.getMessage()); log.warn(message); throw new SoulException(message, e); } // 修改缓存信息 boolean updated = this.updateCacheWithJson(json); // 判断是否修改, 修改则直接结束 if (updated) { log.info(\u0026amp;quot;get latest configs: [{}]\u0026amp;quot;, json); return; } log.info(\u0026amp;quot;The config of the server[{}] has not been updated or is out of date. Wait for 30s to listen for changes again.\u0026amp;quot;, server); ThreadUtils.sleep(TimeUnit.SECONDS, 30); }  HttpSyncDataService#updateCacheWithJson: 取出响应信息中的 data , 即变化的数据信息, 传给数据刷新工厂 DataRefreshFactory\nprivate DataRefreshFactory factory; public HttpSyncDataService(...){ this.factory = new …","date":1611705600,"description":"Soul网关学习Http长轮询解析","dir":"blog/soul_source_learning_09_httplongpolling_02/","fuzzywordcount":1800,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"a5fcdafb18322dfc55162766558e42b1ac259f36","permalink":"/zh/blog/soul_source_learning_09_httplongpolling_02/","publishdate":"2021-01-27T00:00:00Z","readingtime":4,"relpermalink":"/zh/blog/soul_source_learning_09_httplongpolling_02/","summary":"后台与网关数据同步 (Http长轮询篇) 长轮询分析的最后一篇, 总结网关端的长轮询的实现, 以及数据流动方式. 网关端长轮询的流程总体也分两个模块:","tags":["Soul"],"title":"Soul网关学习Http长轮询解析02","type":"blog","url":"/zh/blog/soul_source_learning_09_httplongpolling_02/","wordcount":1750},{"author":"baiyu","categories":"Soul","content":" 回顾 在Soul 请求处理概览概览这篇文章中，我们已经知晓了Soul针对于请求的处理入库在DefaultSoulPluginChain的excute，其中执行了一个插件链的模式来完成了请求的处理。\n我们大体梳理了注入到plugins的插件，但是即使这样依然不能纵观全局，对此特地对soul插件所涉及的类进行了相关梳理，整体梳理结果如下图。\n在梳理文章中可以看到核心类是SoulPlugin、PluginEnum、PluginDataHandler、MetaDataSubscriber，在梳理请求的相关文章中我们目前只需要重点关注SoulPlugin与PluginEnum类。\nSoulPlugin类我们已经有了一定的理解，那PluginEnum枚举类的主要作用是什么呢？\nPluginEnum:插件的枚举类\n   属性 作用     code 插件的执行顺序 越小越先执行   role 角色 暂时未发现实际引用地址   name 插件名称    其实我们不难发现在DefaultSoulPluginChain的plugins的插件都是有固定的执行顺序的，那这个插件的执行顺序是在哪定义的呢？\n最终可以追溯到SoulConfiguration类下\npublic SoulWebHandler soulWebHandler(final ObjectProvider\u0026amp;lt;List\u0026amp;lt;SoulPlugin\u0026amp;gt;\u0026amp;gt; plugins) { //省略 final List\u0026amp;lt;SoulPlugin\u0026amp;gt; soulPlugins = pluginList.stream() .sorted(Comparator.comparingInt(SoulPlugin::getOrder)).collect(Collectors.toList()); return new SoulWebHandler(soulPlugins); }  整理整个PluginEnum类相关引用，整理出如下表格，不难看出插件与插件之间的顺序关系    等级 作用     第一等级 只有GlobalPlugin 全局插件   第二等级到第八等级 可以理解为在请求发起前的前置处理插件   第九等级到第十一等级 可以理解为针对调用方的方式所针对的不同调用处理   第十二等级 只有MonitorPlugin 监控插件   第十三等级 是针对于各个调用方返回结果处理的Response相关插件    在刚才的回顾中我们已经明白soul处理请求的大体流程 - 1.GloBalPlugin插件 进行全局的初始化 - 2.部分插件根据鉴权、限流、熔断等规则对请求进行处理 - 3.选择适合自己的调用方式进行拼装参数，发起调用。 - 4.进行监控 - 5.对调用的结果进行处理\n请求流程梳理  以下演示代码截图来自于soul-examples下的http demo，调用的接口地址为http://127.0.0.1:9195/http/test/findByUserId?userId=10\n 在DefaultSoulPluginChain的excute方法进行埋点，查看一次http请求调用经过了哪些类？\npublic Mono\u0026amp;lt;Void\u0026amp;gt; execute(final ServerWebExchange exchange) { return Mono.defer(() -\u0026amp;gt; { if (this.index \u0026amp;lt; plugins.size()) { SoulPlugin plugin = plugins.get(this.index++); Boolean skip = plugin.skip(exchange); if (skip) { System.out.println(\u0026amp;quot;跳过的插件为\u0026amp;quot;+plugin.getClass().getName().replace(\u0026amp;quot;org.dromara.soul.plugin.\u0026amp;quot;,\u0026amp;quot;\u0026amp;quot;)); return this.execute(exchange); } System.out.println(\u0026amp;quot;未跳过的插件为\u0026amp;quot;+plugin.getClass().getName().replace(\u0026amp;quot;org.dromara.soul.plugin.\u0026amp;quot;,\u0026amp;quot;\u0026amp;quot;)); return plugin.execute(exchange, this); } return Mono.empty(); }); }  最终输出的未跳过的插件如下：\n未跳过的插件为global.GlobalPlugin\n未跳过的插件为sign.SignPlugin\n未跳过的插件为waf.WafPlugin\n未跳过的插件为ratelimiter.RateLimiterPlugin\n未跳过的插件为hystrix.HystrixPlugin\n未跳过的插件为resilience4j.Resilience4JPlugin\n未跳过的插件为divide.DividePlugin\n未跳过的插件为httpclient.WebClientPlugin\n未跳过的插件为alibaba.dubbo.param.BodyParamPlugin\n未跳过的插件为monitor.MonitorPlugin\n未跳过的插件为httpclient.response.WebClientResponsePlugin\n 这里有个小疑惑，为啥这个alibaba.dubbo.param.BodyParamPlugin插件会被执行，暂时忽略，后期跟踪。\n 我们发现一次针对于http请求的网关调用 所执行的插件的大体流程与我们猜想的处理流程一致。\n目前我们只挑重点来讲，即GlobalPlugin、DividePlugin、WebClientPlugin、WebClientResponsePlugin。\n发起Debug调用依次追踪上述四个插件的作用。\nGlobalPlugin SoulContext对象封装插件 GlobalPlugin的插件的excute方法如下所示\npublic Mono\u0026amp;lt;Void\u0026amp;gt; execute(final ServerWebExchange exchange, final SoulPluginChain chain) { final ServerHttpRequest request = exchange.getRequest(); final HttpHeaders headers = request.getHeaders(); final String upgrade = headers.getFirst(\u0026amp;quot;Upgrade\u0026amp;quot;); SoulContext soulContext; if (StringUtils.isBlank(upgrade) || !\u0026amp;quot;websocket\u0026amp;quot;.equals(upgrade)) { soulContext = builder.build(exchange); } else { …","date":1611619200,"description":"Soul Gateway Learning Http Request Adventure","dir":"blog/soul_source_learning_17_http/","fuzzywordcount":5100,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"afc456b32a536ba6818ee74ad25ce07f62385f53","permalink":"/blog/soul_source_learning_17_http/","publishdate":"2021-01-26T00:00:00Z","readingtime":11,"relpermalink":"/blog/soul_source_learning_17_http/","summary":"回顾 在Soul 请求处理概览概览这篇文章中，我们已经知晓了Soul针对于请求的处理入库在DefaultSoulPluginChain的excu","tags":["Soul"],"title":"Soul Gateway Learning Http Request Adventure","type":"blog","url":"/blog/soul_source_learning_17_http/","wordcount":5079},{"author":"liquan","categories":"Soul","content":" 本篇分析一下Nacos同步数据原理\n1、先配置一下环境 * soul-admin soul-admin/src/main/resources/application.yml\nsoul: sync: nacos: url: localhost:8848 namespace: 1c10d748-af86-43b9-8265-75f487d20c6c # acm: # enabled: false # endpoint: acm.aliyun.com # namespace: # accessKey: # secretKey:  soul-admin/pom.xml，这里默认配置是有的\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alibaba.nacos\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;nacos-client\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${nacos-client.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   soul-bootstrap soul-bootstrap/src/main/resources/application-local.yml\nsoul : sync: nacos: url: localhost:8848 namespace: 1c10d748-af86-43b9-8265-75f487d20c6c # acm: # enabled: false # endpoint: acm.aliyun.com # namespace: # accessKey: # secretKey:  soul-bootstrap/pom.xml，下面的配置默认是没有的，需要手动添加\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;soul-spring-boot-starter-sync-data-nacos\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${project.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  启动服务\n1、启动 nacos 2、启动 soul-admin 3、启动 soul-bootstrap  2、上面看着挺顺利，这个过程遇到了坑，soul-bootstrap 启动不起来报空指针异常，下面详细记录一下。 首先soul-admin启动后不会主动向nacos同步网关数据，需要手动同步，官网这一点没有提到。这个问题绊了我好久，最后是看到了群里其他同学遇到了同样的问题，参考了他们的文章才解决，下面记录一下解决过程。\n  1）soul-bootstrap 启动的时候遇到了如下的错误，NullPointerException。\nsoul-bootstrap 启动的时候会去，nacos获取网关数据，看到下面的断点，拿到的是空数据。\nError starting ApplicationContext. To display the conditions report re-run your application with \u0026#39;debug\u0026#39; enabled. 2021-01-25 16:49:06.052 ERROR 5273 --- [ main] o.s.boot.SpringApplication : Application run failed org.springframework.beans.factory.BeanCreationException: Error creating bean with name \u0026#39;nacosSyncDataService\u0026#39; defined in class path resource [org/dromara/soul/springboot/starter/sync/data/nacos/NacosSyncDataConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.dromara.soul.sync.data.api.SyncDataService]: Factory method \u0026#39;nacosSyncDataService\u0026#39; threw exception; nested exception is java.lang.NullPointerException ...... at org.dromara.soul.bootstrap.SoulBootstrapApplication.main(SoulBootstrapApplication.java:37) [classes/:na] Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.dromara.soul.sync.data.api.SyncDataService]: Factory method \u0026#39;nacosSyncDataService\u0026#39; threw exception; nested exception is java.lang.NullPointerException at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185) ~[spring-beans-5.2.2.RELEASE.jar:5.2.2.RELEASE] at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:651) ~[spring-beans-5.2.2.RELEASE.jar:5.2.2.RELEASE] ... 19 common frames omitted Caused by: java.lang.NullPointerException: null at org.dromara.soul.sync.data.nacos.handler.NacosCacheHandler.updateMetaDataMap(NacosCacheHandler.java:128) ~[classes/:na] at …","date":1611619200,"description":"Soul Gateway Learns Nacos Data Synchronization","dir":"blog/soul_source_learning_14_nacos/","fuzzywordcount":2800,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"e34d995ddb946554b19fbcbf33a5846ca2cea03b","permalink":"/blog/soul_source_learning_14_nacos/","publishdate":"2021-01-26T00:00:00Z","readingtime":6,"relpermalink":"/blog/soul_source_learning_14_nacos/","summary":"本篇分析一下Nacos同步数据原理 1、先配置一下环境 * soul-admin soul-admin/src/main/resources/application.yml soul: sync: nacos: url: localhost:8848 namespace: 1c10d748-af86-43b9-8265-75f487d20c6c # acm: # enabled: false # endpoint: acm.aliyun.com # namespace: # accessKey: # secretKey: soul-admin/pom.xml，这","tags":["Soul"],"title":"Soul Gateway Learns Nacos Data Synchronization","type":"blog","url":"/blog/soul_source_learning_14_nacos/","wordcount":2768},{"author":"百钰","categories":"Soul","content":" 回顾 在Soul 请求处理概览概览这篇文章中，我们已经知晓了Soul针对于请求的处理入库在DefaultSoulPluginChain的excute，其中执行了一个插件链的模式来完成了请求的处理。\n我们大体梳理了注入到plugins的插件，但是即使这样依然不能纵观全局，对此特地对soul插件所涉及的类进行了相关梳理，整体梳理结果如下图。\n在梳理文章中可以看到核心类是SoulPlugin、PluginEnum、PluginDataHandler、MetaDataSubscriber，在梳理请求的相关文章中我们目前只需要重点关注SoulPlugin与PluginEnum类。\nSoulPlugin类我们已经有了一定的理解，那PluginEnum枚举类的主要作用是什么呢？\nPluginEnum:插件的枚举类\n   属性 作用     code 插件的执行顺序 越小越先执行   role 角色 暂时未发现实际引用地址   name 插件名称    其实我们不难发现在DefaultSoulPluginChain的plugins的插件都是有固定的执行顺序的，那这个插件的执行顺序是在哪定义的呢？\n最终可以追溯到SoulConfiguration类下\npublic SoulWebHandler soulWebHandler(final ObjectProvider\u0026amp;lt;List\u0026amp;lt;SoulPlugin\u0026amp;gt;\u0026amp;gt; plugins) { //省略 final List\u0026amp;lt;SoulPlugin\u0026amp;gt; soulPlugins = pluginList.stream() .sorted(Comparator.comparingInt(SoulPlugin::getOrder)).collect(Collectors.toList()); return new SoulWebHandler(soulPlugins); }  整理整个PluginEnum类相关引用，整理出如下表格，不难看出插件与插件之间的顺序关系    等级 作用     第一等级 只有GlobalPlugin 全局插件   第二等级到第八等级 可以理解为在请求发起前的前置处理插件   第九等级到第十一等级 可以理解为针对调用方的方式所针对的不同调用处理   第十二等级 只有MonitorPlugin 监控插件   第十三等级 是针对于各个调用方返回结果处理的Response相关插件    在刚才的回顾中我们已经明白soul处理请求的大体流程 - 1.GloBalPlugin插件 进行全局的初始化 - 2.部分插件根据鉴权、限流、熔断等规则对请求进行处理 - 3.选择适合自己的调用方式进行拼装参数，发起调用。 - 4.进行监控 - 5.对调用的结果进行处理\n请求流程梳理  以下演示代码截图来自于soul-examples下的http demo，调用的接口地址为http://127.0.0.1:9195/http/test/findByUserId?userId=10\n 在DefaultSoulPluginChain的excute方法进行埋点，查看一次http请求调用经过了哪些类？\npublic Mono\u0026amp;lt;Void\u0026amp;gt; execute(final ServerWebExchange exchange) { return Mono.defer(() -\u0026amp;gt; { if (this.index \u0026amp;lt; plugins.size()) { SoulPlugin plugin = plugins.get(this.index++); Boolean skip = plugin.skip(exchange); if (skip) { System.out.println(\u0026amp;quot;跳过的插件为\u0026amp;quot;+plugin.getClass().getName().replace(\u0026amp;quot;org.dromara.soul.plugin.\u0026amp;quot;,\u0026amp;quot;\u0026amp;quot;)); return this.execute(exchange); } System.out.println(\u0026amp;quot;未跳过的插件为\u0026amp;quot;+plugin.getClass().getName().replace(\u0026amp;quot;org.dromara.soul.plugin.\u0026amp;quot;,\u0026amp;quot;\u0026amp;quot;)); return plugin.execute(exchange, this); } return Mono.empty(); }); }  最终输出的未跳过的插件如下：\n未跳过的插件为global.GlobalPlugin\n未跳过的插件为sign.SignPlugin\n未跳过的插件为waf.WafPlugin\n未跳过的插件为ratelimiter.RateLimiterPlugin\n未跳过的插件为hystrix.HystrixPlugin\n未跳过的插件为resilience4j.Resilience4JPlugin\n未跳过的插件为divide.DividePlugin\n未跳过的插件为httpclient.WebClientPlugin\n未跳过的插件为alibaba.dubbo.param.BodyParamPlugin\n未跳过的插件为monitor.MonitorPlugin\n未跳过的插件为httpclient.response.WebClientResponsePlugin\n 这里有个小疑惑，为啥这个alibaba.dubbo.param.BodyParamPlugin插件会被执行，暂时忽略，后期跟踪。\n 我们发现一次针对于http请求的网关调用 所执行的插件的大体流程与我们猜想的处理流程一致。\n目前我们只挑重点来讲，即GlobalPlugin、DividePlugin、WebClientPlugin、WebClientResponsePlugin。\n发起Debug调用依次追踪上述四个插件的作用。\nGlobalPlugin SoulContext对象封装插件 GlobalPlugin的插件的excute方法如下所示\npublic Mono\u0026amp;lt;Void\u0026amp;gt; execute(final ServerWebExchange exchange, final SoulPluginChain chain) { final ServerHttpRequest request = exchange.getRequest(); final HttpHeaders headers = request.getHeaders(); final String upgrade = headers.getFirst(\u0026amp;quot;Upgrade\u0026amp;quot;); SoulContext soulContext; if (StringUtils.isBlank(upgrade) || !\u0026amp;quot;websocket\u0026amp;quot;.equals(upgrade)) { soulContext = builder.build(exchange); } else { …","date":1611619200,"description":"Soul网关学习Http请求探险","dir":"blog/soul_source_learning_17_http/","fuzzywordcount":5100,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"78916eebf4d043e978af9c39f43c6265aad84155","permalink":"/zh/blog/soul_source_learning_17_http/","publishdate":"2021-01-26T00:00:00Z","readingtime":11,"relpermalink":"/zh/blog/soul_source_learning_17_http/","summary":"回顾 在Soul 请求处理概览概览这篇文章中，我们已经知晓了Soul针对于请求的处理入库在DefaultSoulPluginChain的excu","tags":["Soul"],"title":"Soul网关学习Http请求探险","type":"blog","url":"/zh/blog/soul_source_learning_17_http/","wordcount":5079},{"author":"李权","categories":"Soul","content":" 本篇分析一下Nacos同步数据原理\n1、先配置一下环境 * soul-admin soul-admin/src/main/resources/application.yml\nsoul: sync: nacos: url: localhost:8848 namespace: 1c10d748-af86-43b9-8265-75f487d20c6c # acm: # enabled: false # endpoint: acm.aliyun.com # namespace: # accessKey: # secretKey:  soul-admin/pom.xml，这里默认配置是有的\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alibaba.nacos\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;nacos-client\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${nacos-client.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   soul-bootstrap soul-bootstrap/src/main/resources/application-local.yml\nsoul : sync: nacos: url: localhost:8848 namespace: 1c10d748-af86-43b9-8265-75f487d20c6c # acm: # enabled: false # endpoint: acm.aliyun.com # namespace: # accessKey: # secretKey:  soul-bootstrap/pom.xml，下面的配置默认是没有的，需要手动添加\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;soul-spring-boot-starter-sync-data-nacos\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${project.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  启动服务\n1、启动 nacos 2、启动 soul-admin 3、启动 soul-bootstrap  2、上面看着挺顺利，这个过程遇到了坑，soul-bootstrap 启动不起来报空指针异常，下面详细记录一下。 首先soul-admin启动后不会主动向nacos同步网关数据，需要手动同步，官网这一点没有提到。这个问题绊了我好久，最后是看到了群里其他同学遇到了同样的问题，参考了他们的文章才解决，下面记录一下解决过程。\n  1）soul-bootstrap 启动的时候遇到了如下的错误，NullPointerException。\nsoul-bootstrap 启动的时候会去，nacos获取网关数据，看到下面的断点，拿到的是空数据。\nError starting ApplicationContext. To display the conditions report re-run your application with \u0026#39;debug\u0026#39; enabled. 2021-01-25 16:49:06.052 ERROR 5273 --- [ main] o.s.boot.SpringApplication : Application run failed org.springframework.beans.factory.BeanCreationException: Error creating bean with name \u0026#39;nacosSyncDataService\u0026#39; defined in class path resource [org/dromara/soul/springboot/starter/sync/data/nacos/NacosSyncDataConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.dromara.soul.sync.data.api.SyncDataService]: Factory method \u0026#39;nacosSyncDataService\u0026#39; threw exception; nested exception is java.lang.NullPointerException ...... at org.dromara.soul.bootstrap.SoulBootstrapApplication.main(SoulBootstrapApplication.java:37) [classes/:na] Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.dromara.soul.sync.data.api.SyncDataService]: Factory method \u0026#39;nacosSyncDataService\u0026#39; threw exception; nested exception is java.lang.NullPointerException at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185) ~[spring-beans-5.2.2.RELEASE.jar:5.2.2.RELEASE] at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:651) ~[spring-beans-5.2.2.RELEASE.jar:5.2.2.RELEASE] ... 19 common frames omitted Caused by: java.lang.NullPointerException: null at org.dromara.soul.sync.data.nacos.handler.NacosCacheHandler.updateMetaDataMap(NacosCacheHandler.java:128) ~[classes/:na] at …","date":1611619200,"description":"Soul网关学习Nacos数据同步","dir":"blog/soul_source_learning_14_nacos/","fuzzywordcount":2800,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"aa3ccbe40bb0ac41704dfadf42e095c55d8303c8","permalink":"/zh/blog/soul_source_learning_14_nacos/","publishdate":"2021-01-26T00:00:00Z","readingtime":6,"relpermalink":"/zh/blog/soul_source_learning_14_nacos/","summary":"本篇分析一下Nacos同步数据原理 1、先配置一下环境 * soul-admin soul-admin/src/main/resources/application.yml soul: sync: nacos: url: localhost:8848 namespace: 1c10d748-af86-43b9-8265-75f487d20c6c # acm: # enabled: false # endpoint: acm.aliyun.com # namespace: # accessKey: # secretKey: soul-admin/pom.xml，这","tags":["Soul"],"title":"Soul网关学习Nacos数据同步","type":"blog","url":"/zh/blog/soul_source_learning_14_nacos/","wordcount":2768},{"author":"zhuming","categories":"Soul","content":" 后台与网关数据同步 (Http长轮询篇) 配置 后台信息模式切换\n在上篇分析 Zookeeper 同步的文章 (Soul网关源码分析-11期) 中, 我们通过 DataSyncConfiguration 这个配置类做的切换, 这次有了经验, 直接贴配置\nsoul: sync: websocket: enabled: false http: enabled: true  网关信息模式切换\n后台模式切换完成, 接下来就是网关, 继续照葫芦画瓢找到关键配置类上的参数设置. 这里也直接贴网关配置\nsoul: sync: #\twebsocket: #\turls: ws://localhost:9095/websocket http: url: http://localhost:9095  DataChangedListener 体系 后台数据初始化 DataSyncConfiguration 配置关键 Bean , 看看这里关于 Http 长轮询的 Bean\n@Configuration public class DataSyncConfiguration { @Configuration @ConditionalOnProperty(name = \u0026amp;quot;soul.sync.http.enabled\u0026amp;quot;, havingValue = \u0026amp;quot;true\u0026amp;quot;) @EnableConfigurationProperties(HttpSyncProperties.class) static class HttpLongPollingListener { @Bean @ConditionalOnMissingBean(HttpLongPollingDataChangedListener.class) public HttpLongPollingDataChangedListener httpLongPollingDataChangedListener(final HttpSyncProperties httpSyncProperties) { return new HttpLongPollingDataChangedListener(httpSyncProperties); } } }  HttpLongPollingDataChangedListener 继承自 AbstractDataChangedListener, 他们都实现自接口 DataChangedListener.\nDataChangedListener 这个接口我们应该非常熟悉了, 它提供了众多不同数据类型变动的方法, 供 DataChangedEventDispatcher 调用, 这个类更是一个 \u0026amp;ldquo;老朋友\u0026amp;rdquo; 了, 作为一个中转站, 辛勤的处理数据同步的事件分类及分发\npublic class DataChangedEventDispatcher implements ApplicationListener\u0026amp;lt;DataChangedEvent\u0026amp;gt;, InitializingBean { // 持有 DataChangedListener 集合 private List\u0026amp;lt;DataChangedListener\u0026amp;gt; listeners; // 事件变动时, 通知 DataChangedListener 的不同事件类型的方法 public void onApplicationEvent(final DataChangedEvent event) { for (DataChangedListener listener : listeners) { switch (event.getGroupKey()) { case APP_AUTH: listener.onAppAuthChanged((List\u0026amp;lt;AppAuthData\u0026amp;gt;) event.getSource(), event.getEventType()); break; case PLUGIN: listener.onPluginChanged((List\u0026amp;lt;PluginData\u0026amp;gt;) event.getSource(), event.getEventType()); break; case RULE: listener.onRuleChanged((List\u0026amp;lt;RuleData\u0026amp;gt;) event.getSource(), event.getEventType()); break; case SELECTOR: listener.onSelectorChanged((List\u0026amp;lt;SelectorData\u0026amp;gt;) event.getSource(), event.getEventType()); break; case META_DATA: listener.onMetaDataChanged((List\u0026amp;lt;MetaData\u0026amp;gt;) event.getSource(), event.getEventType()); break; default: throw new IllegalStateException(\u0026amp;quot;Unexpected value: \u0026amp;quot; + event.getGroupKey()); } } } }  public interface DataChangedListener { default void onAppAuthChanged(List\u0026amp;lt;AppAuthData\u0026amp;gt; changed, DataEventTypeEnum eventType) {} default void onPluginChanged(List\u0026amp;lt;PluginData\u0026amp;gt; changed, DataEventTypeEnum eventType) {} default void onSelectorChanged(List\u0026amp;lt;SelectorData\u0026amp;gt; changed, DataEventTypeEnum eventType) {} default void onMetaDataChanged(List\u0026amp;lt;MetaData\u0026amp;gt; changed, DataEventTypeEnum eventType) {} default void onRuleChanged(List\u0026amp;lt;RuleData\u0026amp;gt; changed, DataEventTypeEnum eventType) {} }  这两个的作用了解了, 那 AbstractDataChangedListener 又做了什么事情? 举个 onPluginChanged() 的例子:\npublic abstract class AbstractDataChangedListener implements DataChangedListener, InitializingBean { protected static final ConcurrentMap\u0026amp;lt;String, …","date":1611532800,"description":"Soul Gateway Learns Http Long Polling Analysis","dir":"blog/soul_source_learning_08_httplongpolling_01/","fuzzywordcount":2800,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"f85e7838d0c019ab0972e3005d3d4f37fb544e7e","permalink":"/blog/soul_source_learning_08_httplongpolling_01/","publishdate":"2021-01-25T00:00:00Z","readingtime":6,"relpermalink":"/blog/soul_source_learning_08_httplongpolling_01/","summary":"后台与网关数据同步 (Http长轮询篇) 配置 后台信息模式切换 在上篇分析 Zookeeper 同步的文章 (Soul网关源码分析-11期) 中, 我们通过 DataSyncConfiguration 这个配置类做的","tags":["Soul"],"title":"Soul Gateway Learns Http Long Polling Analysis 01","type":"blog","url":"/blog/soul_source_learning_08_httplongpolling_01/","wordcount":2736},{"author":"朱明","categories":"Soul","content":" 后台与网关数据同步 (Http长轮询篇) 配置 后台信息模式切换\n在上篇分析 Zookeeper 同步的文章 (Soul网关源码分析-11期) 中, 我们通过 DataSyncConfiguration 这个配置类做的切换, 这次有了经验, 直接贴配置\nsoul: sync: websocket: enabled: false http: enabled: true  网关信息模式切换\n后台模式切换完成, 接下来就是网关, 继续照葫芦画瓢找到关键配置类上的参数设置. 这里也直接贴网关配置\nsoul: sync: #\twebsocket: #\turls: ws://localhost:9095/websocket http: url: http://localhost:9095  DataChangedListener 体系 后台数据初始化 DataSyncConfiguration 配置关键 Bean , 看看这里关于 Http 长轮询的 Bean\n@Configuration public class DataSyncConfiguration { @Configuration @ConditionalOnProperty(name = \u0026amp;quot;soul.sync.http.enabled\u0026amp;quot;, havingValue = \u0026amp;quot;true\u0026amp;quot;) @EnableConfigurationProperties(HttpSyncProperties.class) static class HttpLongPollingListener { @Bean @ConditionalOnMissingBean(HttpLongPollingDataChangedListener.class) public HttpLongPollingDataChangedListener httpLongPollingDataChangedListener(final HttpSyncProperties httpSyncProperties) { return new HttpLongPollingDataChangedListener(httpSyncProperties); } } }  HttpLongPollingDataChangedListener 继承自 AbstractDataChangedListener, 他们都实现自接口 DataChangedListener.\nDataChangedListener 这个接口我们应该非常熟悉了, 它提供了众多不同数据类型变动的方法, 供 DataChangedEventDispatcher 调用, 这个类更是一个 \u0026amp;ldquo;老朋友\u0026amp;rdquo; 了, 作为一个中转站, 辛勤的处理数据同步的事件分类及分发\npublic class DataChangedEventDispatcher implements ApplicationListener\u0026amp;lt;DataChangedEvent\u0026amp;gt;, InitializingBean { // 持有 DataChangedListener 集合 private List\u0026amp;lt;DataChangedListener\u0026amp;gt; listeners; // 事件变动时, 通知 DataChangedListener 的不同事件类型的方法 public void onApplicationEvent(final DataChangedEvent event) { for (DataChangedListener listener : listeners) { switch (event.getGroupKey()) { case APP_AUTH: listener.onAppAuthChanged((List\u0026amp;lt;AppAuthData\u0026amp;gt;) event.getSource(), event.getEventType()); break; case PLUGIN: listener.onPluginChanged((List\u0026amp;lt;PluginData\u0026amp;gt;) event.getSource(), event.getEventType()); break; case RULE: listener.onRuleChanged((List\u0026amp;lt;RuleData\u0026amp;gt;) event.getSource(), event.getEventType()); break; case SELECTOR: listener.onSelectorChanged((List\u0026amp;lt;SelectorData\u0026amp;gt;) event.getSource(), event.getEventType()); break; case META_DATA: listener.onMetaDataChanged((List\u0026amp;lt;MetaData\u0026amp;gt;) event.getSource(), event.getEventType()); break; default: throw new IllegalStateException(\u0026amp;quot;Unexpected value: \u0026amp;quot; + event.getGroupKey()); } } } }  public interface DataChangedListener { default void onAppAuthChanged(List\u0026amp;lt;AppAuthData\u0026amp;gt; changed, DataEventTypeEnum eventType) {} default void onPluginChanged(List\u0026amp;lt;PluginData\u0026amp;gt; changed, DataEventTypeEnum eventType) {} default void onSelectorChanged(List\u0026amp;lt;SelectorData\u0026amp;gt; changed, DataEventTypeEnum eventType) {} default void onMetaDataChanged(List\u0026amp;lt;MetaData\u0026amp;gt; changed, DataEventTypeEnum eventType) {} default void onRuleChanged(List\u0026amp;lt;RuleData\u0026amp;gt; changed, DataEventTypeEnum eventType) {} }  这两个的作用了解了, 那 AbstractDataChangedListener 又做了什么事情? 举个 onPluginChanged() 的例子:\npublic abstract class AbstractDataChangedListener implements DataChangedListener, InitializingBean { protected static final ConcurrentMap\u0026amp;lt;String, …","date":1611532800,"description":"Soul网关学习Http长轮询解析","dir":"blog/soul_source_learning_08_httplongpolling_01/","fuzzywordcount":2800,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"7cba2fe17b603e2305687a5d274fcbacd850b1b4","permalink":"/zh/blog/soul_source_learning_08_httplongpolling_01/","publishdate":"2021-01-25T00:00:00Z","readingtime":6,"relpermalink":"/zh/blog/soul_source_learning_08_httplongpolling_01/","summary":"后台与网关数据同步 (Http长轮询篇) 配置 后台信息模式切换 在上篇分析 Zookeeper 同步的文章 (Soul网关源码分析-11期) 中, 我们通过 DataSyncConfiguration 这个配置类做的","tags":["Soul"],"title":"Soul网关学习Http长轮询解析01","type":"blog","url":"/zh/blog/soul_source_learning_08_httplongpolling_01/","wordcount":2736},{"author":"fanjinpeng,zhuming","categories":"Soul","content":"  Fanjinpeng\n 1.前情回顾 在第4篇中，我们分析了 HTTP 用户业务系统接入 Soul 网关后，会调用 soul-admin 的注册接口，把需要网关代理的接口信息全部注册到 soul-admin 上，在最后，会通过 websocket 长连接，将soul-admin 接收到的接口信息同步给 Soul 网关（即 soul-bootstrap），今天就来接着继续分析，数据是怎么同步到 soul-bootstrap 的。\n不清楚流程的可以出门左转看下第4篇文章 【Soul源码阅读】4.HTTP 用户接入 Soul 调用 /soul-client/springmvc-register 接口逻辑分析\n2.soul-admin 与 soul-bootstrap 数据同步 这里为了验证数据同步流程，其实也没必要非得启动业务系统，完全可以只启动 soul-admin 和 soul-bootstrap 两个系统即可，可以在页面打开或关闭插件，看看这个流程是怎么实现的。\n数据同步策略官网链接 https://dromara.org/zh-cn/docs/soul/user-dataSync.html\n2.1 启动2个系统 都是按照项目默认启动的，无需修改任何配置文件。\n2.2 页面操作查找接口 这里把 divide 插件启动，F12，看下前台会调用 soul-admin 哪个接口。\n可以看到前台向后台发送了一个 PUT 请求：http://localhost:9095/plugin/5\n2.3 后台接口 在项目中搜索这个接口\n// PluginController.java @RestController @RequestMapping(\u0026amp;quot;/plugin\u0026amp;quot;) public class PluginController { ... /** * update plugin. * * @param id primary key. * @param pluginDTO plugin. * @return {@linkplain SoulAdminResult} */ @PutMapping(\u0026amp;quot;/{id}\u0026amp;quot;) public SoulAdminResult updatePlugin(@PathVariable(\u0026amp;quot;id\u0026amp;quot;) final String id, @RequestBody final PluginDTO pluginDTO) { Objects.requireNonNull(pluginDTO); pluginDTO.setId(id); final String result = pluginService.createOrUpdate(pluginDTO); if (StringUtils.isNoneBlank(result)) { return SoulAdminResult.error(result); } return SoulAdminResult.success(SoulResultMessage.UPDATE_SUCCESS); } ... }  进到实现类里\n// PluginServiceImpl.java /** * create or update plugin. * * @param pluginDTO {@linkplain PluginDTO} * @return rows */ @Override @Transactional(rollbackFor = Exception.class) public String createOrUpdate(final PluginDTO pluginDTO) { final String msg = checkData(pluginDTO); if (StringUtils.isNoneBlank(msg)) { return msg; } PluginDO pluginDO = PluginDO.buildPluginDO(pluginDTO); DataEventTypeEnum eventType = DataEventTypeEnum.CREATE; if (StringUtils.isBlank(pluginDTO.getId())) { pluginMapper.insertSelective(pluginDO); } else { eventType = DataEventTypeEnum.UPDATE; pluginMapper.updateSelective(pluginDO); } // publish change event. eventPublisher.publishEvent(new DataChangedEvent(ConfigGroupEnum.PLUGIN, eventType, Collections.singletonList(PluginTransfer.INSTANCE.mapToData(pluginDO)))); return StringUtils.EMPTY; }  这里可以看出来，前半部分都是在操作数据库，把相关信息持久化；后半部分是发布了一个事件。\n2.4 发布事件 这里发布的事件用 DataChangedEvent 封装了一层，再看里面有1个枚举，这里有很多种类型：\n/** * configuration group. * * @author huangxiaofeng */ public enum ConfigGroupEnum { APP_AUTH, PLUGIN, RULE, SELECTOR, META_DATA; ... }  看到这几种类型，如果对第4篇还有印象的话，可以看出当时发送事件的类型就是 SELECTOR 和 RULE，现在是 PLUGIN，虽然类型不同，但不影响我们继续分析后面的逻辑，我们继续。\n另外一个 eventType 也是枚举，这里有 DELETE、CREATE、UPDATE、REFRESH、MYSELF 5种类型，此时是 UPDATE。\n/** * The enum Data event type. * * @author xiaoyu */ public enum DataEventTypeEnum { /** * delete event. */ DELETE, /** * insert event. */ CREATE, /** * update event. */ UPDATE, /** * REFRESH data event type enum. */ REFRESH, /** * Myself data event type enum. */ MYSELF; ... }  2.5 监听事件 找到监听事件的代码：\n// DataChangedEventDispatcher.java @Component public class DataChangedEventDispatcher implements …","date":1611273600,"description":"Soul Gateway Learns WebSocket Data Synchronization Analysis","dir":"blog/soul_source_learning_10_websocket/","fuzzywordcount":3900,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"e31b1cdbf9ba2ec728420037cb89c0c8115357b6","permalink":"/blog/soul_source_learning_10_websocket/","publishdate":"2021-01-22T00:00:00Z","readingtime":8,"relpermalink":"/blog/soul_source_learning_10_websocket/","summary":"Fanjinpeng 1.前情回顾 在第4篇中，我们分析了 HTTP 用户业务系统接入 Soul 网关后，会调用 soul-admin 的注册接口，把需要网关代理的接口信息全部注册到 soul-admin 上，在最后，会通过 websocket","tags":["Soul"],"title":"Soul Gateway Learns WebSocket Data Synchronization Analysis","type":"blog","url":"/blog/soul_source_learning_10_websocket/","wordcount":3859},{"author":"范金鹏,朱明","categories":"Soul","content":"  范金鹏\n 1.前情回顾 在第4篇中，我们分析了 HTTP 用户业务系统接入 Soul 网关后，会调用 soul-admin 的注册接口，把需要网关代理的接口信息全部注册到 soul-admin 上，在最后，会通过 websocket 长连接，将soul-admin 接收到的接口信息同步给 Soul 网关（即 soul-bootstrap），今天就来接着继续分析，数据是怎么同步到 soul-bootstrap 的。\n不清楚流程的可以出门左转看下第4篇文章 【Soul源码阅读】4.HTTP 用户接入 Soul 调用 /soul-client/springmvc-register 接口逻辑分析\n2.soul-admin 与 soul-bootstrap 数据同步 这里为了验证数据同步流程，其实也没必要非得启动业务系统，完全可以只启动 soul-admin 和 soul-bootstrap 两个系统即可，可以在页面打开或关闭插件，看看这个流程是怎么实现的。\n数据同步策略官网链接 https://dromara.org/zh-cn/docs/soul/user-dataSync.html\n2.1 启动2个系统 都是按照项目默认启动的，无需修改任何配置文件。\n2.2 页面操作查找接口 这里把 divide 插件启动，F12，看下前台会调用 soul-admin 哪个接口。\n可以看到前台向后台发送了一个 PUT 请求：http://localhost:9095/plugin/5\n2.3 后台接口 在项目中搜索这个接口\n// PluginController.java @RestController @RequestMapping(\u0026amp;quot;/plugin\u0026amp;quot;) public class PluginController { ... /** * update plugin. * * @param id primary key. * @param pluginDTO plugin. * @return {@linkplain SoulAdminResult} */ @PutMapping(\u0026amp;quot;/{id}\u0026amp;quot;) public SoulAdminResult updatePlugin(@PathVariable(\u0026amp;quot;id\u0026amp;quot;) final String id, @RequestBody final PluginDTO pluginDTO) { Objects.requireNonNull(pluginDTO); pluginDTO.setId(id); final String result = pluginService.createOrUpdate(pluginDTO); if (StringUtils.isNoneBlank(result)) { return SoulAdminResult.error(result); } return SoulAdminResult.success(SoulResultMessage.UPDATE_SUCCESS); } ... }  进到实现类里\n// PluginServiceImpl.java /** * create or update plugin. * * @param pluginDTO {@linkplain PluginDTO} * @return rows */ @Override @Transactional(rollbackFor = Exception.class) public String createOrUpdate(final PluginDTO pluginDTO) { final String msg = checkData(pluginDTO); if (StringUtils.isNoneBlank(msg)) { return msg; } PluginDO pluginDO = PluginDO.buildPluginDO(pluginDTO); DataEventTypeEnum eventType = DataEventTypeEnum.CREATE; if (StringUtils.isBlank(pluginDTO.getId())) { pluginMapper.insertSelective(pluginDO); } else { eventType = DataEventTypeEnum.UPDATE; pluginMapper.updateSelective(pluginDO); } // publish change event. eventPublisher.publishEvent(new DataChangedEvent(ConfigGroupEnum.PLUGIN, eventType, Collections.singletonList(PluginTransfer.INSTANCE.mapToData(pluginDO)))); return StringUtils.EMPTY; }  这里可以看出来，前半部分都是在操作数据库，把相关信息持久化；后半部分是发布了一个事件。\n2.4 发布事件 这里发布的事件用 DataChangedEvent 封装了一层，再看里面有1个枚举，这里有很多种类型：\n/** * configuration group. * * @author huangxiaofeng */ public enum ConfigGroupEnum { APP_AUTH, PLUGIN, RULE, SELECTOR, META_DATA; ... }  看到这几种类型，如果对第4篇还有印象的话，可以看出当时发送事件的类型就是 SELECTOR 和 RULE，现在是 PLUGIN，虽然类型不同，但不影响我们继续分析后面的逻辑，我们继续。\n另外一个 eventType 也是枚举，这里有 DELETE、CREATE、UPDATE、REFRESH、MYSELF 5种类型，此时是 UPDATE。\n/** * The enum Data event type. * * @author xiaoyu */ public enum DataEventTypeEnum { /** * delete event. */ DELETE, /** * insert event. */ CREATE, /** * update event. */ UPDATE, /** * REFRESH data event type enum. */ REFRESH, /** * Myself data event type enum. */ MYSELF; ... }  2.5 监听事件 找到监听事件的代码：\n// DataChangedEventDispatcher.java @Component public class DataChangedEventDispatcher implements …","date":1611273600,"description":"Soul网关学习WebSocket数据同步解析","dir":"blog/soul_source_learning_10_websocket/","fuzzywordcount":3900,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"3e5ede2711e7ce17eb0a4eb355f7b0bfcb01bcc1","permalink":"/zh/blog/soul_source_learning_10_websocket/","publishdate":"2021-01-22T00:00:00Z","readingtime":8,"relpermalink":"/zh/blog/soul_source_learning_10_websocket/","summary":"范金鹏 1.前情回顾 在第4篇中，我们分析了 HTTP 用户业务系统接入 Soul 网关后，会调用 soul-admin 的注册接口，把需要网关代理的接口信息全部注册到 soul-admin 上，在最后，会通","tags":["Soul"],"title":"Soul网关学习WebSocket数据同步解析","type":"blog","url":"/zh/blog/soul_source_learning_10_websocket/","wordcount":3862},{"author":"xiaoyu","categories":null,"content":" Dromara source code reading (Soul 2021 first activity)  Date: Sunday, January 24, 2021 Time: 15:00 – 17:00 Location: Tencent Meeting  Activity Details 15:00-15:10 Opening introduction of dream code sharing process by kimming \u0026amp;amp; Cui\n15:10-15:25 Soul data synchronization websocket by Ting\n15:25-15:50 Http Discovery Sharing by Zhu Ming\n15:50-16:10 Analysis based on the Sofa-Rpc protocol by Dongdong\n16:10-16:25 Metrics Monitoring by Ge Tianye\n16:25-16:40 Http Long Polling Sharing by Du Yuhang\n16:40-16:55 Sharing and introducing the overall architecture of data synchronization by Wentao Xia\n16:55-17:05 Microkernel Architecture Sharing by Shen Xiangjun\n17:05-17:20 Sharing the experience and insights of reading source code by JinZe\n17:20-17:30 Summary and Community Development Prospects by Xiaoyu\n","date":1611241200,"description":"","dir":"activities/dromara-cloud-native-meet/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"6621205eab5fe3cdb55359700b30ee0b52cc0aec","permalink":"/activities/dromara-cloud-native-meet/","publishdate":"2021-01-21T15:00:00Z","readingtime":1,"relpermalink":"/activities/dromara-cloud-native-meet/","summary":"Dromara source code reading (Soul 2021 first activity)  Date: Sunday, January 24, 2021 Time: 15:00 – 17:00 Location: Tencent Meeting  Activity Details 15:00-15:10 Opening introduction of dream code sharing process by kimming \u0026amp; Cui\n15:10-15:25 Soul data synchronization websocket by Ting\n15:25-15:50 Http Discovery Sharing by Zhu Ming\n15:50-16:10 Analysis based on the Sofa-Rpc protocol by Dongdong\n16:10-16:25 Metrics Monitoring by Ge Tianye\n16:25-16:40 Http Long Polling Sharing by Du Yuhang","tags":["Soul","Dromara","Reactor"],"title":"Dromara Soul source code 01 reading sharing session 01","type":"activities","url":"/activities/dromara-cloud-native-meet/","wordcount":111},{"author":"xiaoyu","categories":null,"content":" Dromara 源码阅读（Soul 2021 首次活动）  日期：2021年1月24日，星期日 时间：15:00 – 17:00 地点：线上腾讯会议室  活动详情 15:00 - 15:10 开场介绍梦码分享流程 by kimming \u0026amp;amp; 崔\n15:10 - 15:25 Soul 数据同步之websocket by 婷\n15:25 - 15:50 Http 探活分享 by 朱明\n15:50 - 16:10 基于Sofa-Rpc协议的分析 by 东东\n16:10 - 16:25 Metrics 监控 by 葛天野\n16:25 - 16:40 Http 长轮询分享 by 杜宇航\n16:40 - 16:55 数据同步整体架构分享与介绍 by 夏文涛\n16:55 - 17:05 微内核架构分享 by 沈祥俊\n17:05 - 17:20 分享读源码的心得与感悟 by 金泽\n17:20 - 17:30 Soul 作者 猫大人 总结与 社区发展 展望 by 猫大人\n","date":1611241200,"description":"","dir":"activities/dromara-cloud-native-meet/","fuzzywordcount":300,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"1abf0fe2c1c6bfcfcaa12cfd2186b38c4d33d790","permalink":"/zh/activities/dromara-cloud-native-meet/","publishdate":"2021-01-21T15:00:00Z","readingtime":1,"relpermalink":"/zh/activities/dromara-cloud-native-meet/","summary":"Dromara 源码阅读（Soul 2021 首次活动） 日期：2021年1月24日，星期日 时间：15:00 – 17:00 地点：线上腾讯会议室 活动详情 15:00 - 15:10 开场介绍梦码分享流程","tags":["Soul","Dromara","Reactor"],"title":"Dromara Soul 源码01期阅读分享会01","type":"activities","url":"/zh/activities/dromara-cloud-native-meet/","wordcount":222},{"author":"shenxiangjun","categories":"Soul","content":" 一、引言 插件是 Soul 的灵魂。\nSoul 使用了插件化设计思想，实现了插件的热插拔，且极易扩展。内置丰富的插件支持，鉴权，限流，熔断，防火墙等等。\nSoul 是如何实现插件化设计的呢？\n在探究插件化设计之前，我们需要先了解下微内核架构（又称插件化架构）。\n二、微内核架构 1、架构释义 微内核架构也被称为插件化架构，是一种面向功能进行拆分的可扩展性架构，通常用于实现基于产品的应用。\n应用逻辑被分割为独立的插件模块和核心系统，提供了可扩展性、灵活性、功能隔离和自定义处理逻辑的特性。\n微内核架构的本质，是将变化封装在插件里面，从而达到快速灵活扩展的目的，而又不影响整体系统的稳定。\n2、设计关键点 核心系统设计的关键技术：\n 插件管理：当前有哪些插件可用？如何加载这些插件？什么时候加载插件？  常见的实现方法是插件注册表机制。\n 插件连接：插件如何连接到核心系统？  通常由核心系统制定连接规范，然后插件按照规范实现，核心系统按照规范加载即可。\n常见连接机制主要有：OSGi（Eclipse使用）、消息模式、依赖注入（Spring使用）。\n 插件通信：插件与插件、插件与核心系统如何通信？  通信必须经过核心系统，因此通常由核心系统提供插件通信机制。\n三、Soul 的插件化设计 参照微内核架构来看，Soul 的 soul-web 模块相当于核心系统，soul-plugin 下的子模块相当于插件模块。\n插件管理方面：\nsoul-bootstrap 模块的 pom 文件充当插件列表， 以硬编码的方式引入各插件。\n在容器启动阶段，借助 springboot 的 starter 机制自动扫描并注册插件 bean 到 Spring 容器。\n插件连接方面：\n借助 springboot 支持的多实例自动注入能力（ObjectProvider plugins），将插件 Bean 列表注入到网关的插件链，实现插件与网关的连接。\n插件通信方面：\n先在插件链初始化阶段完成插件排序，然后在插件处理时，借助贯穿整个插件链的 ServerWebExchange 完成向下游插件的定向传参，即某种意义上的插件通信机制。\n四、Soul 的插件化实现 Soul 网关中定义了一条插件链，所有的插件都在这条链上依次处理。\n在探究插件链之前，我们先来看看插件实现。\n1、插件实现 Soul 中所有插件最终均继承自 SoulPlugin，其完整继承关系如下所示：\n可以看到，Soul 的插件生态极其丰富，正是如此丰富的插件支撑起了 Soul 网关强大的扩展能力。\n我们以常用的 DividePlugin 为例，分析插件内部所做工作。\nDividePlugin 继承结构：\nDividePlugin 继承自 AbstractSoulPlugin，最终实现了 SoulPlugin 接口。\n1）先关注 SoulPlugin，该插件接口结构如下：\n execute 方法：处理方法，需要传入 exchange交换区 和 SoulPluginChain插件链 getOrder 方法：取得序号，用作插件排序 named 方法：获得插件名 skip 方法：判断是否跳过本次处理  每次处理时，将先进行 skip 判断，不跳过则执行 excute 处理方法。\n2）再来看下 AbstractSoulPlugin，该抽象类结构如下：\n重点关注 execute 方法，其核心代码如下：\nif (pluginData.getEnable()){ // 获取插件数据 final PluginData pluginData = BaseDataCache.getInstance().obtainPluginData(pluginName); // 获取选择器数据 final Collection\u0026amp;lt;SelectorData\u0026amp;gt; selectors = BaseDataCache.getInstance().obtainSelectorData(pluginName); final SelectorData selectorData = matchSelector(exchange, selectors); // 获取规则 final List\u0026amp;lt;RuleData\u0026amp;gt; rules = BaseDataCache.getInstance().obtainRuleData(selectorData.getId()); RuleData rule; if (selectorData.getType() == SelectorTypeEnum.FULL_FLOW.getCode()) { //get last rule = rules.get(rules.size() - 1); } else { rule = matchRule(exchange, rules); } // 执行具体处理 return doExecute(exchange, chain, selectorData, rule); } // 继续执行后续插件处理 return chain.execute(exchange);  获取选择器数据和规则，然后传入 doExecute 方法进行具体处理，doExecute 方法为抽象方法，交由子类具体实现。\n3）查看插件子类 DividePlugin，其结构如下：\n重点关注 doExecute 方法，以下是核心代码：\n// 获取网关上下文和规则处理器 final SoulContext soulContext = exchange.getAttribute(Constants.CONTEXT); final DivideRuleHandle ruleHandle = GsonUtils.getInstance().fromJson(rule.getHandle(), DivideRuleHandle.class); // 获取上游列表 final List\u0026amp;lt;DivideUpstream\u0026amp;gt; upstreamList = UpstreamCacheManager.getInstance().findUpstreamListBySelectorId(selector.getId()); // 选择待分发的目标上游 final String ip = Objects.requireNonNull(exchange.getRequest().getRemoteAddress()).getAddress().getHostAddress(); DivideUpstream divideUpstream = LoadBalanceUtils.selector(upstreamList, ruleHandle.getLoadBalance(), ip); // 设置 http url String domain = buildDomain(divideUpstream); String realURL = buildRealURL(domain, soulContext, exchange); …","date":1611187200,"description":"Soul Gateway Learning Plugin Chain Implementation","dir":"blog/soul_source_learning_15_plugin_chain/","fuzzywordcount":2500,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"2ff88d047ecdebcbf4d44344a9b0fc763341410c","permalink":"/blog/soul_source_learning_15_plugin_chain/","publishdate":"2021-01-21T00:00:00Z","readingtime":5,"relpermalink":"/blog/soul_source_learning_15_plugin_chain/","summary":"一、引言 插件是 Soul 的灵魂。 Soul 使用了插件化设计思想，实现了插件的热插拔，且极易扩展。内置丰富的插件支持，鉴权，限流，熔断，防火墙等等。 Soul 是如何实","tags":["Soul"],"title":"Soul Gateway Learning Plugin Chain Implementation","type":"blog","url":"/blog/soul_source_learning_15_plugin_chain/","wordcount":2408},{"author":"liquan","categories":"Soul","content":" 启动admin，与网关。 admin操作，使用zookeeper同步数据到网关 上一篇，通过soul-admin启动过程为入口，分析了soul-admin 启动就会同步网关数据 rule、metaData、selector、plugin 等到 zookeeper。\n数据变化会发布 DataChangedEvent事件，监听事件将数据同步至zookeeper。 本篇接着上一篇继续跟踪源码分析zookeeper同步数据到网关原理：\n soul-admin 变更网关数据，跟踪数据同步过程。 soul-bootstrap 如何获取zookeeper数据的，如何感知网关数据变化的。  一、soul-admin 变更网关数据，跟踪数据同步过程 1、在网关后台尝试更改divide插件状态，debug跟踪。\n2、插件更新后会发布一个DataChangedEvent事件\n3、org.dromara.soul.admin.listener.DataChangedEventDispatcher \u0026amp;ndash;\u0026amp;gt; onApplicationEvent() 负责监听事件\n4、org.dromara.soul.admin.listener.zookeeper.ZookeeperDataChangedListener 负责同步数据至zookeeper\n二、soul-bootstrap 如何获取zookeeper数据的，如何感知网关数据变化的。 1、soul-bootstrap 依赖\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;soul-spring-boot-starter-sync-data-zookeeper\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${project.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  2、soul-bootstrap 启动后会自动注入org.dromara.soul.spring.boot.sync.data.zookeeper.ZookeeperSyncDataConfiguration\n读取Zookeeper配置向容器中注入ZkClient。\nSyncDataService 向容器注入数据同步服务bean，从Spring容器中获取，ZkClient（zookeeper客户端）， pluginSubscriber（插件数据订阅）、metaSubscribers （元数据订阅）、authSubscribers（权限订阅）。\npublic class ZookeeperSyncDataConfiguration { /** * Sync data service sync data service. * @param zkClient the zk client * @param pluginSubscriber the plugin subscriber * @param metaSubscribers the meta subscribers * @param authSubscribers the auth subscribers * @return the sync data service */ @Bean public SyncDataService syncDataService(final ObjectProvider\u0026amp;lt;ZkClient\u0026amp;gt; zkClient, final ObjectProvider\u0026amp;lt;PluginDataSubscriber\u0026amp;gt; pluginSubscriber, final ObjectProvider\u0026amp;lt;List\u0026amp;lt;MetaDataSubscriber\u0026amp;gt;\u0026amp;gt; metaSubscribers, final ObjectProvider\u0026amp;lt;List\u0026amp;lt;AuthDataSubscriber\u0026amp;gt;\u0026amp;gt; authSubscribers) { log.info(\u0026amp;quot;you use zookeeper sync soul data.......\u0026amp;quot;); return new ZookeeperSyncDataService(zkClient.getIfAvailable(), pluginSubscriber.getIfAvailable(), metaSubscribers.getIfAvailable(Collections::emptyList), authSubscribers.getIfAvailable(Collections::emptyList)); } /** * register zkClient in spring ioc. * @param zookeeperConfig the zookeeper configuration * @return ZkClient {@linkplain ZkClient} */ @Bean public ZkClient zkClient(final ZookeeperConfig zookeeperConfig) { return new ZkClient(zookeeperConfig.getUrl(), zookeeperConfig.getSessionTimeout(), zookeeperConfig.getConnectionTimeout()); } }  3、org.dromara.soul.sync.data.zookeeper.ZookeeperSyncDataService 初始化，也就是soul-bootstrap启动后就会从zookeeper获取数据，同步至内存。 * watcherData()\u0026amp;ndash;\u0026amp;gt; watcherAll() \u0026amp;ndash;\u0026amp;gt; watcherPlugin() \u0026amp;ndash;\u0026amp;gt; cachePluginData()。 * zkClient.subscribeDataChanges() 监听 当前节点和子节点的内容修改、删除。\npublic class ZookeeperSyncDataService implements SyncDataService, AutoCloseable { private final ZkClient zkClient; private final PluginDataSubscriber pluginDataSubscriber; private final List\u0026amp;lt;MetaDataSubscriber\u0026amp;gt; metaDataSubscribers; private final List\u0026amp;lt;AuthDataSubscriber\u0026amp;gt; authDataSubscribers; /** * Instantiates a new Zookeeper cache manager. * @param zkClient the zk …","date":1611187200,"description":"Soul Gateway Learns Zookeeper Data Synchronization","dir":"blog/soul_source_learning_13_zookeeper_02/","fuzzywordcount":1700,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"874b3f2bba51baf972b4ded6859998dc1f52848c","permalink":"/blog/soul_source_learning_13_zookeeper_02/","publishdate":"2021-01-21T00:00:00Z","readingtime":4,"relpermalink":"/blog/soul_source_learning_13_zookeeper_02/","summary":"启动admin，与网关。 admin操作，使用zookeeper同步数据到网关 上一篇，通过soul-admin启动过程为入口，分析了soul-","tags":["Soul"],"title":"Soul Gateway Learns Zookeeper Data Synchronization 02","type":"blog","url":"/blog/soul_source_learning_13_zookeeper_02/","wordcount":1620},{"author":"李权","categories":"Soul","content":" 启动admin，与网关。 admin操作，使用zookeeper同步数据到网关 上一篇，通过soul-admin启动过程为入口，分析了soul-admin 启动就会同步网关数据 rule、metaData、selector、plugin 等到 zookeeper。\n数据变化会发布 DataChangedEvent事件，监听事件将数据同步至zookeeper。 本篇接着上一篇继续跟踪源码分析zookeeper同步数据到网关原理：\n soul-admin 变更网关数据，跟踪数据同步过程。 soul-bootstrap 如何获取zookeeper数据的，如何感知网关数据变化的。  一、soul-admin 变更网关数据，跟踪数据同步过程 1、在网关后台尝试更改divide插件状态，debug跟踪。\n2、插件更新后会发布一个DataChangedEvent事件\n3、org.dromara.soul.admin.listener.DataChangedEventDispatcher \u0026amp;ndash;\u0026amp;gt; onApplicationEvent() 负责监听事件\n4、org.dromara.soul.admin.listener.zookeeper.ZookeeperDataChangedListener 负责同步数据至zookeeper\n二、soul-bootstrap 如何获取zookeeper数据的，如何感知网关数据变化的。 1、soul-bootstrap 依赖\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;soul-spring-boot-starter-sync-data-zookeeper\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${project.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  2、soul-bootstrap 启动后会自动注入org.dromara.soul.spring.boot.sync.data.zookeeper.ZookeeperSyncDataConfiguration\n读取Zookeeper配置向容器中注入ZkClient。\nSyncDataService 向容器注入数据同步服务bean，从Spring容器中获取，ZkClient（zookeeper客户端）， pluginSubscriber（插件数据订阅）、metaSubscribers （元数据订阅）、authSubscribers（权限订阅）。\npublic class ZookeeperSyncDataConfiguration { /** * Sync data service sync data service. * @param zkClient the zk client * @param pluginSubscriber the plugin subscriber * @param metaSubscribers the meta subscribers * @param authSubscribers the auth subscribers * @return the sync data service */ @Bean public SyncDataService syncDataService(final ObjectProvider\u0026amp;lt;ZkClient\u0026amp;gt; zkClient, final ObjectProvider\u0026amp;lt;PluginDataSubscriber\u0026amp;gt; pluginSubscriber, final ObjectProvider\u0026amp;lt;List\u0026amp;lt;MetaDataSubscriber\u0026amp;gt;\u0026amp;gt; metaSubscribers, final ObjectProvider\u0026amp;lt;List\u0026amp;lt;AuthDataSubscriber\u0026amp;gt;\u0026amp;gt; authSubscribers) { log.info(\u0026amp;quot;you use zookeeper sync soul data.......\u0026amp;quot;); return new ZookeeperSyncDataService(zkClient.getIfAvailable(), pluginSubscriber.getIfAvailable(), metaSubscribers.getIfAvailable(Collections::emptyList), authSubscribers.getIfAvailable(Collections::emptyList)); } /** * register zkClient in spring ioc. * @param zookeeperConfig the zookeeper configuration * @return ZkClient {@linkplain ZkClient} */ @Bean public ZkClient zkClient(final ZookeeperConfig zookeeperConfig) { return new ZkClient(zookeeperConfig.getUrl(), zookeeperConfig.getSessionTimeout(), zookeeperConfig.getConnectionTimeout()); } }  3、org.dromara.soul.sync.data.zookeeper.ZookeeperSyncDataService 初始化，也就是soul-bootstrap启动后就会从zookeeper获取数据，同步至内存。 * watcherData()\u0026amp;ndash;\u0026amp;gt; watcherAll() \u0026amp;ndash;\u0026amp;gt; watcherPlugin() \u0026amp;ndash;\u0026amp;gt; cachePluginData()。 * zkClient.subscribeDataChanges() 监听 当前节点和子节点的内容修改、删除。\npublic class ZookeeperSyncDataService implements SyncDataService, AutoCloseable { private final ZkClient zkClient; private final PluginDataSubscriber pluginDataSubscriber; private final List\u0026amp;lt;MetaDataSubscriber\u0026amp;gt; metaDataSubscribers; private final List\u0026amp;lt;AuthDataSubscriber\u0026amp;gt; authDataSubscribers; /** * Instantiates a new Zookeeper cache manager. * @param zkClient the zk …","date":1611187200,"description":"Soul网关学习Zookeeper数据同步","dir":"blog/soul_source_learning_13_zookeeper_02/","fuzzywordcount":1700,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"af25cd6245d77500860b0eeb83d13c329839ecca","permalink":"/zh/blog/soul_source_learning_13_zookeeper_02/","publishdate":"2021-01-21T00:00:00Z","readingtime":4,"relpermalink":"/zh/blog/soul_source_learning_13_zookeeper_02/","summary":"启动admin，与网关。 admin操作，使用zookeeper同步数据到网关 上一篇，通过soul-admin启动过程为入口，分析了soul-","tags":["Soul"],"title":"Soul网关学习Zookeeper数据同步02","type":"blog","url":"/zh/blog/soul_source_learning_13_zookeeper_02/","wordcount":1620},{"author":"沈祥俊","categories":"Soul","content":" 一、引言 插件是 Soul 的灵魂。\nSoul 使用了插件化设计思想，实现了插件的热插拔，且极易扩展。内置丰富的插件支持，鉴权，限流，熔断，防火墙等等。\nSoul 是如何实现插件化设计的呢？\n在探究插件化设计之前，我们需要先了解下微内核架构（又称插件化架构）。\n二、微内核架构 1、架构释义 微内核架构也被称为插件化架构，是一种面向功能进行拆分的可扩展性架构，通常用于实现基于产品的应用。\n应用逻辑被分割为独立的插件模块和核心系统，提供了可扩展性、灵活性、功能隔离和自定义处理逻辑的特性。\n微内核架构的本质，是将变化封装在插件里面，从而达到快速灵活扩展的目的，而又不影响整体系统的稳定。\n2、设计关键点 核心系统设计的关键技术：\n 插件管理：当前有哪些插件可用？如何加载这些插件？什么时候加载插件？  常见的实现方法是插件注册表机制。\n 插件连接：插件如何连接到核心系统？  通常由核心系统制定连接规范，然后插件按照规范实现，核心系统按照规范加载即可。\n常见连接机制主要有：OSGi（Eclipse使用）、消息模式、依赖注入（Spring使用）。\n 插件通信：插件与插件、插件与核心系统如何通信？  通信必须经过核心系统，因此通常由核心系统提供插件通信机制。\n三、Soul 的插件化设计 参照微内核架构来看，Soul 的 soul-web 模块相当于核心系统，soul-plugin 下的子模块相当于插件模块。\n插件管理方面：\nsoul-bootstrap 模块的 pom 文件充当插件列表， 以硬编码的方式引入各插件。\n在容器启动阶段，借助 springboot 的 starter 机制自动扫描并注册插件 bean 到 Spring 容器。\n插件连接方面：\n借助 springboot 支持的多实例自动注入能力（ObjectProvider plugins），将插件 Bean 列表注入到网关的插件链，实现插件与网关的连接。\n插件通信方面：\n先在插件链初始化阶段完成插件排序，然后在插件处理时，借助贯穿整个插件链的 ServerWebExchange 完成向下游插件的定向传参，即某种意义上的插件通信机制。\n四、Soul 的插件化实现 Soul 网关中定义了一条插件链，所有的插件都在这条链上依次处理。\n在探究插件链之前，我们先来看看插件实现。\n1、插件实现 Soul 中所有插件最终均继承自 SoulPlugin，其完整继承关系如下所示：\n可以看到，Soul 的插件生态极其丰富，正是如此丰富的插件支撑起了 Soul 网关强大的扩展能力。\n我们以常用的 DividePlugin 为例，分析插件内部所做工作。\nDividePlugin 继承结构：\nDividePlugin 继承自 AbstractSoulPlugin，最终实现了 SoulPlugin 接口。\n1）先关注 SoulPlugin，该插件接口结构如下：\n execute 方法：处理方法，需要传入 exchange交换区 和 SoulPluginChain插件链 getOrder 方法：取得序号，用作插件排序 named 方法：获得插件名 skip 方法：判断是否跳过本次处理  每次处理时，将先进行 skip 判断，不跳过则执行 excute 处理方法。\n2）再来看下 AbstractSoulPlugin，该抽象类结构如下：\n重点关注 execute 方法，其核心代码如下：\nif (pluginData.getEnable()){ // 获取插件数据 final PluginData pluginData = BaseDataCache.getInstance().obtainPluginData(pluginName); // 获取选择器数据 final Collection\u0026amp;lt;SelectorData\u0026amp;gt; selectors = BaseDataCache.getInstance().obtainSelectorData(pluginName); final SelectorData selectorData = matchSelector(exchange, selectors); // 获取规则 final List\u0026amp;lt;RuleData\u0026amp;gt; rules = BaseDataCache.getInstance().obtainRuleData(selectorData.getId()); RuleData rule; if (selectorData.getType() == SelectorTypeEnum.FULL_FLOW.getCode()) { //get last rule = rules.get(rules.size() - 1); } else { rule = matchRule(exchange, rules); } // 执行具体处理 return doExecute(exchange, chain, selectorData, rule); } // 继续执行后续插件处理 return chain.execute(exchange);  获取选择器数据和规则，然后传入 doExecute 方法进行具体处理，doExecute 方法为抽象方法，交由子类具体实现。\n3）查看插件子类 DividePlugin，其结构如下：\n重点关注 doExecute 方法，以下是核心代码：\n// 获取网关上下文和规则处理器 final SoulContext soulContext = exchange.getAttribute(Constants.CONTEXT); final DivideRuleHandle ruleHandle = GsonUtils.getInstance().fromJson(rule.getHandle(), DivideRuleHandle.class); // 获取上游列表 final List\u0026amp;lt;DivideUpstream\u0026amp;gt; upstreamList = UpstreamCacheManager.getInstance().findUpstreamListBySelectorId(selector.getId()); // 选择待分发的目标上游 final String ip = Objects.requireNonNull(exchange.getRequest().getRemoteAddress()).getAddress().getHostAddress(); DivideUpstream divideUpstream = LoadBalanceUtils.selector(upstreamList, ruleHandle.getLoadBalance(), ip); // 设置 http url String domain = buildDomain(divideUpstream); String realURL = buildRealURL(domain, soulContext, exchange); …","date":1611187200,"description":"Soul网关学习插件链实现","dir":"blog/soul_source_learning_15_plugin_chain/","fuzzywordcount":2500,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"7bc696547a5cbee1f64d8b70668c3f9208bd3c8c","permalink":"/zh/blog/soul_source_learning_15_plugin_chain/","publishdate":"2021-01-21T00:00:00Z","readingtime":5,"relpermalink":"/zh/blog/soul_source_learning_15_plugin_chain/","summary":"一、引言 插件是 Soul 的灵魂。 Soul 使用了插件化设计思想，实现了插件的热插拔，且极易扩展。内置丰富的插件支持，鉴权，限流，熔断，防火墙等等。 Soul 是如何实","tags":["Soul"],"title":"Soul网关学习插件链实现","type":"blog","url":"/zh/blog/soul_source_learning_15_plugin_chain/","wordcount":2408},{"author":"zenglinhui","categories":"Soul","content":" 源码分析  页面操作源码分析  在分析源码之前，先看下图，页面显示加载的插件列表会对应后端的请求，根据后端请求，找到对应的controller类 然后找到对应的方法，在上图可以看到这里是访问 plugin 中默认为空的 mapping，传入到分页相关的参数，然后去查询数据库中对应的插件记录 数据库中对应的表为下图所示，divide 状态是启用，在上一篇中，就是用这个插件来测试网关 同时请求的还有选择器，请求的 controller 见下图。在上篇的演示中，我们直接在页面把选择器中的条件 CRUD，可以实时反应到网关中去，而不需要重启网关，所以这里除了query方法中，增加、删除、和修改方法中,在保存到数据库之后都有一个 publishEvent 方法。就是这个事件方法，可以让用户直接在 soul 后台配置规则，从而达到时时生效的目地 public int createOrUpdate(final SelectorDTO selectorDTO) { int selectorCount; SelectorDO selectorDO = SelectorDO.buildSelectorDO(selectorDTO); List\u0026amp;lt;SelectorConditionDTO\u0026amp;gt; selectorConditionDTOs = selectorDTO.getSelectorConditions(); if (StringUtils.isEmpty(selectorDTO.getId())) { selectorCount = selectorMapper.insertSelective(selectorDO); selectorConditionDTOs.forEach(selectorConditionDTO -\u0026amp;gt; { selectorConditionDTO.setSelectorId(selectorDO.getId()); selectorConditionMapper.insertSelective(SelectorConditionDO.buildSelectorConditionDO(selectorConditionDTO)); }); } else { selectorCount = selectorMapper.updateSelective(selectorDO); //delete rule condition then add selectorConditionMapper.deleteByQuery(new SelectorConditionQuery(selectorDO.getId())); selectorConditionDTOs.forEach(selectorConditionDTO -\u0026amp;gt; { selectorConditionDTO.setSelectorId(selectorDO.getId()); SelectorConditionDO selectorConditionDO = SelectorConditionDO.buildSelectorConditionDO(selectorConditionDTO); selectorConditionMapper.insertSelective(selectorConditionDO); }); } publishEvent(selectorDO, selectorConditionDTOs); return selectorCount; }   与soul-bootstrap 数据同步(websocket)源码分析  之前介绍了 admin 页面操作之后把数据保存数据库，然后用了 spring 自带的响应式编程把数据同步到 bootstrap 项目，以达到动态刷新网关规则及插件，而不用添加配置后去重启网关。 当 soul-bootstrap 启动时，看日志会打出来这么一段\n2021-01-21 00:33:39.620 INFO 14276 --- [0.0-9095-exec-5] o.d.s.a.l.websocket.WebsocketCollector : websocket on open successful....  那么问题来了，它用 websocket 和谁连接了，又是怎么连接的？下面通过找到打日志的代码，再通过打断点的方式来调试一下，这里是打日志出来的地方 先来分析一下这个代码： - 从 websocketConfig 这个配置里面拿到配的请求地址，这个配置文件当然是在下图的这个地方配的 - 拿到这个配置地址后，创建了一个定时的线程池，线程池大小为 urls.length，线程名称前缀为\u0026amp;rdquo;websocket-connect\u0026amp;rdquo;的守护线程。这里为什么要创建守护线程，因为这只是为了保证 bootstrap 和 admin 的 websocket 连接不断，类似于心跳的作用，所以用守护线程是最好的 - 根据创建的 client 端，一个一个的去请求配置文件配的地址，然后打印之前所找到的日志 - 后面就启动线程去判断 client 是否关闭，如果关闭就会去重新连接(初始间隔10秒，然后每30秒去执行一次检查，所以如果你看到控制台有时会打印多个连接成功的日志，说明重连了) - 我们再来看看在 admin 后台操作的数据是怎么同步到 bootstrap 中的呢，之前有说过，在后台保存或者更新数据之后，会调用 publishEvent 方法，这个是 spring 自带响应式编程的方法，既然是响应式，那就是基于事件的，那就得有 listener 一找果不其然，上图画红框的地方是不是很眼熟，没错，监听器，和websocket相关的监听器，如果还是有点看不明白监听和之前的 publishEvent 有什么关系，那就把监听器里的代码打上断点，调试一把。我这里为了方便，就点了这个同步所有数据 这里进的是 DataChangedEventDispatcher 这个类，调用了event 相关的方法，在左下角这个地方，是不是看到了熟悉了方法了，没错就是上面说的 publishEvent  然后会跳转到 WebsocketDataChangedListener 这个类中，这里重点看一下在调试方法中 send 方法  这里通过 send 方法把更新的数据发到 bootstrap 中，到此 admin 怎么同步数据到 bootstrap 中就真相大白了  与soul-bootstrap 数据同步(zookeeper)源码分析 话不多说，先上图，把 websocket 的配置先注释掉，打开 zookeeper 的配置，前提是把本地或者远程的 zookeeper 服务打开，然后启动 soul-admin 首先进入了 ZookeeperDataInit 类的 run 方法，这个方法执行完之后，奇怪的一点是跳到了 WebsocketDataChangedListener 类中去了 这一点没弄明白，等这个类里面的 onPluginChanged 方法执行完了之后， …","date":1611100800,"description":"Soul Gateway Learning Admin Source Code Analysis","dir":"blog/soul_resource_learning_07_admin/","fuzzywordcount":2300,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"87d6eb1e421e5713d332bfdff2c1e5d85bd8c2e9","permalink":"/blog/soul_resource_learning_07_admin/","publishdate":"2021-01-20T00:00:00Z","readingtime":5,"relpermalink":"/blog/soul_resource_learning_07_admin/","summary":"源码分析 页面操作源码分析 在分析源码之前，先看下图，页面显示加载的插件列表会对应后端的请求，根据后端请求，找到对应的controller类 然后","tags":["Soul"],"title":"Soul Gateway Learning Admin Source Code Analysis","type":"blog","url":"/blog/soul_resource_learning_07_admin/","wordcount":2262},{"author":"liquan","categories":"Soul","content":" 启动 soul-admin、soul-bootstrap， 使用zookeeper同步数据到网关 一、配置环境 1、soul-admin 服务配置，需要重启服务\nsoul-admin/src/main/resources/application.yml\nsoul: sync: zookeeper: url: localhost:2181 sessionTimeout: 5000 connectionTimeout: 2000  2、soul-bootstrap 网关服务配置，需要重启\nsoul-bootstrap/pom.xml\n\u0026amp;lt;!--soul data sync start use zookeeper--\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;soul-spring-boot-starter-sync-data-zookeeper\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${project.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  soul-bootstrap/src/main/resources/application-local.yml\nsoul : sync: zookeeper: url: localhost:2181 sessionTimeout: 5000 connectionTimeout: 2000  二、启动服务 1、 启动 zookeeper\nzookeeper ./bin/zkServer.sh start /usr/bin/java ZooKeeper JMX enabled by default Using config: /Documents/soft/zookeeper/bin/../conf/zoo.cfg Starting zookeeper ... STARTED  2、soul-admin 网关后台服务启动，服务启动后可以看到发起的ZooKeeper请求调用\n 2021-01-20 17:34:48.752 INFO 64500 --- [-localhost:2181] org.I0Itec.zkclient.ZkEventThread : Starting ZkClient event thread. 2021-01-20 17:34:48.761 INFO 64500 --- [ main] org.apache.zookeeper.ZooKeeper : Client environment:zookeeper.version=3.5.6-c11b7e26bc554b8523dc929761dd28808913f091, built on 10/08/2019 20:18 GMT 2021-01-20 17:34:48.761 INFO 64500 --- [ main] org.apache.zookeeper.ZooKeeper : Client environment:host.name=10.7.254.31 2021-01-20 17:34:48.761 INFO 64500 --- [ main] org.apache.zookeeper.ZooKeeper : Client environment:java.version=1.8.0_261 2021-01-20 17:34:48.761 INFO 64500 --- [ main] org.apache.zookeeper.ZooKeeper : Client environment:java.vendor=Oracle Corporation ...... 2021-01-20 17:34:48.806 INFO 64500 --- [localhost:2181)] org.apache.zookeeper.ClientCnxn : Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) 2021-01-20 17:34:48.826 INFO 64500 --- [localhost:2181)] org.apache.zookeeper.ClientCnxn : Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:58214, server: localhost/0:0:0:0:0:0:0:1:2181 2021-01-20 17:34:48.857 INFO 64500 --- [localhost:2181)] org.apache.zookeeper.ClientCnxn : Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1000b5e22f50001, negotiated timeout = 5000 2021-01-20 17:34:48.861 INFO 64500 --- [ain-EventThread] org.I0Itec.zkclient.ZkClient : zookeeper state changed (SyncConnected)  3、soul-bootstrap 网关服务启动，服务启动后可以看到发起的ZooKeeper请求调用\n2021-01-20 17:35:58.996 INFO 64583 --- [ main] s.b.s.d.z.ZookeeperSyncDataConfiguration : you use zookeeper sync soul data....... 2021-01-20 17:35:59.003 INFO 64583 --- [-localhost:2181] org.I0Itec.zkclient.ZkEventThread : Starting ZkClient event thread. ...... 2021-01-20 17:35:59.012 INFO 64583 --- [ main] org.apache.zookeeper.ZooKeeper : Client environment:user.home=/Users/liquan 2021-01-20 17:35:59.012 INFO 64583 --- [ main] org.apache.zookeeper.ZooKeeper : Client environment:os.memory.total=310MB 2021-01-20 17:35:59.018 INFO 64583 --- …","date":1611100800,"description":"Soul Gateway Learns Zookeeper Data Synchronization","dir":"blog/soul_source_learning_13_zookeeper_01/","fuzzywordcount":2200,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"3a690ab14c2f6bc9417522c4f69594fb7674eba4","permalink":"/blog/soul_source_learning_13_zookeeper_01/","publishdate":"2021-01-20T00:00:00Z","readingtime":5,"relpermalink":"/blog/soul_source_learning_13_zookeeper_01/","summary":"启动 soul-admin、soul-bootstrap， 使用zookeeper同步数据到网关 一、配置环境 1、soul-admin 服务配置，需","tags":["Soul"],"title":"Soul Gateway Learns Zookeeper Data Synchronization 01","type":"blog","url":"/blog/soul_source_learning_13_zookeeper_01/","wordcount":2181},{"author":"曾林辉","categories":"Soul","content":" 源码分析  页面操作源码分析  在分析源码之前，先看下图，页面显示加载的插件列表会对应后端的请求，根据后端请求，找到对应的controller类 然后找到对应的方法，在上图可以看到这里是访问 plugin 中默认为空的 mapping，传入到分页相关的参数，然后去查询数据库中对应的插件记录 数据库中对应的表为下图所示，divide 状态是启用，在上一篇中，就是用这个插件来测试网关 同时请求的还有选择器，请求的 controller 见下图。在上篇的演示中，我们直接在页面把选择器中的条件 CRUD，可以实时反应到网关中去，而不需要重启网关，所以这里除了query方法中，增加、删除、和修改方法中,在保存到数据库之后都有一个 publishEvent 方法。就是这个事件方法，可以让用户直接在 soul 后台配置规则，从而达到时时生效的目地 public int createOrUpdate(final SelectorDTO selectorDTO) { int selectorCount; SelectorDO selectorDO = SelectorDO.buildSelectorDO(selectorDTO); List\u0026amp;lt;SelectorConditionDTO\u0026amp;gt; selectorConditionDTOs = selectorDTO.getSelectorConditions(); if (StringUtils.isEmpty(selectorDTO.getId())) { selectorCount = selectorMapper.insertSelective(selectorDO); selectorConditionDTOs.forEach(selectorConditionDTO -\u0026amp;gt; { selectorConditionDTO.setSelectorId(selectorDO.getId()); selectorConditionMapper.insertSelective(SelectorConditionDO.buildSelectorConditionDO(selectorConditionDTO)); }); } else { selectorCount = selectorMapper.updateSelective(selectorDO); //delete rule condition then add selectorConditionMapper.deleteByQuery(new SelectorConditionQuery(selectorDO.getId())); selectorConditionDTOs.forEach(selectorConditionDTO -\u0026amp;gt; { selectorConditionDTO.setSelectorId(selectorDO.getId()); SelectorConditionDO selectorConditionDO = SelectorConditionDO.buildSelectorConditionDO(selectorConditionDTO); selectorConditionMapper.insertSelective(selectorConditionDO); }); } publishEvent(selectorDO, selectorConditionDTOs); return selectorCount; }   与soul-bootstrap 数据同步(websocket)源码分析  之前介绍了 admin 页面操作之后把数据保存数据库，然后用了 spring 自带的响应式编程把数据同步到 bootstrap 项目，以达到动态刷新网关规则及插件，而不用添加配置后去重启网关。 当 soul-bootstrap 启动时，看日志会打出来这么一段\n2021-01-21 00:33:39.620 INFO 14276 --- [0.0-9095-exec-5] o.d.s.a.l.websocket.WebsocketCollector : websocket on open successful....  那么问题来了，它用 websocket 和谁连接了，又是怎么连接的？下面通过找到打日志的代码，再通过打断点的方式来调试一下，这里是打日志出来的地方 先来分析一下这个代码： - 从 websocketConfig 这个配置里面拿到配的请求地址，这个配置文件当然是在下图的这个地方配的 - 拿到这个配置地址后，创建了一个定时的线程池，线程池大小为 urls.length，线程名称前缀为\u0026amp;rdquo;websocket-connect\u0026amp;rdquo;的守护线程。这里为什么要创建守护线程，因为这只是为了保证 bootstrap 和 admin 的 websocket 连接不断，类似于心跳的作用，所以用守护线程是最好的 - 根据创建的 client 端，一个一个的去请求配置文件配的地址，然后打印之前所找到的日志 - 后面就启动线程去判断 client 是否关闭，如果关闭就会去重新连接(初始间隔10秒，然后每30秒去执行一次检查，所以如果你看到控制台有时会打印多个连接成功的日志，说明重连了) - 我们再来看看在 admin 后台操作的数据是怎么同步到 bootstrap 中的呢，之前有说过，在后台保存或者更新数据之后，会调用 publishEvent 方法，这个是 spring 自带响应式编程的方法，既然是响应式，那就是基于事件的，那就得有 listener 一找果不其然，上图画红框的地方是不是很眼熟，没错，监听器，和websocket相关的监听器，如果还是有点看不明白监听和之前的 publishEvent 有什么关系，那就把监听器里的代码打上断点，调试一把。我这里为了方便，就点了这个同步所有数据 这里进的是 DataChangedEventDispatcher 这个类，调用了event 相关的方法，在左下角这个地方，是不是看到了熟悉了方法了，没错就是上面说的 publishEvent  然后会跳转到 WebsocketDataChangedListener 这个类中，这里重点看一下在调试方法中 send 方法  这里通过 send 方法把更新的数据发到 bootstrap 中，到此 admin 怎么同步数据到 bootstrap 中就真相大白了  与soul-bootstrap 数据同步(zookeeper)源码分析 话不多说，先上图，把 websocket 的配置先注释掉，打开 zookeeper 的配置，前提是把本地或者远程的 zookeeper 服务打开，然后启动 soul-admin 首先进入了 ZookeeperDataInit 类的 run 方法，这个方法执行完之后，奇怪的一点是跳到了 WebsocketDataChangedListener 类中去了 这一点没弄明白，等这个类里面的 onPluginChanged 方法执行完了之后， …","date":1611100800,"description":"Soul网关学习Admin源码分析","dir":"blog/soul_resource_learning_07_admin/","fuzzywordcount":2300,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"f45e2aa4ddf421cbb8a3e1a6fb52518a8b35fb47","permalink":"/zh/blog/soul_resource_learning_07_admin/","publishdate":"2021-01-20T00:00:00Z","readingtime":5,"relpermalink":"/zh/blog/soul_resource_learning_07_admin/","summary":"源码分析 页面操作源码分析 在分析源码之前，先看下图，页面显示加载的插件列表会对应后端的请求，根据后端请求，找到对应的controller类 然后","tags":["Soul"],"title":"Soul网关学习Admin源码分析","type":"blog","url":"/zh/blog/soul_resource_learning_07_admin/","wordcount":2262},{"author":"李权","categories":"Soul","content":" 启动 soul-admin、soul-bootstrap， 使用zookeeper同步数据到网关 一、配置环境 1、soul-admin 服务配置，需要重启服务\nsoul-admin/src/main/resources/application.yml\nsoul: sync: zookeeper: url: localhost:2181 sessionTimeout: 5000 connectionTimeout: 2000  2、soul-bootstrap 网关服务配置，需要重启\nsoul-bootstrap/pom.xml\n\u0026amp;lt;!--soul data sync start use zookeeper--\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;soul-spring-boot-starter-sync-data-zookeeper\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${project.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  soul-bootstrap/src/main/resources/application-local.yml\nsoul : sync: zookeeper: url: localhost:2181 sessionTimeout: 5000 connectionTimeout: 2000  二、启动服务 1、 启动 zookeeper\nzookeeper ./bin/zkServer.sh start /usr/bin/java ZooKeeper JMX enabled by default Using config: /Documents/soft/zookeeper/bin/../conf/zoo.cfg Starting zookeeper ... STARTED  2、soul-admin 网关后台服务启动，服务启动后可以看到发起的ZooKeeper请求调用\n 2021-01-20 17:34:48.752 INFO 64500 --- [-localhost:2181] org.I0Itec.zkclient.ZkEventThread : Starting ZkClient event thread. 2021-01-20 17:34:48.761 INFO 64500 --- [ main] org.apache.zookeeper.ZooKeeper : Client environment:zookeeper.version=3.5.6-c11b7e26bc554b8523dc929761dd28808913f091, built on 10/08/2019 20:18 GMT 2021-01-20 17:34:48.761 INFO 64500 --- [ main] org.apache.zookeeper.ZooKeeper : Client environment:host.name=10.7.254.31 2021-01-20 17:34:48.761 INFO 64500 --- [ main] org.apache.zookeeper.ZooKeeper : Client environment:java.version=1.8.0_261 2021-01-20 17:34:48.761 INFO 64500 --- [ main] org.apache.zookeeper.ZooKeeper : Client environment:java.vendor=Oracle Corporation ...... 2021-01-20 17:34:48.806 INFO 64500 --- [localhost:2181)] org.apache.zookeeper.ClientCnxn : Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) 2021-01-20 17:34:48.826 INFO 64500 --- [localhost:2181)] org.apache.zookeeper.ClientCnxn : Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:58214, server: localhost/0:0:0:0:0:0:0:1:2181 2021-01-20 17:34:48.857 INFO 64500 --- [localhost:2181)] org.apache.zookeeper.ClientCnxn : Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1000b5e22f50001, negotiated timeout = 5000 2021-01-20 17:34:48.861 INFO 64500 --- [ain-EventThread] org.I0Itec.zkclient.ZkClient : zookeeper state changed (SyncConnected)  3、soul-bootstrap 网关服务启动，服务启动后可以看到发起的ZooKeeper请求调用\n2021-01-20 17:35:58.996 INFO 64583 --- [ main] s.b.s.d.z.ZookeeperSyncDataConfiguration : you use zookeeper sync soul data....... 2021-01-20 17:35:59.003 INFO 64583 --- [-localhost:2181] org.I0Itec.zkclient.ZkEventThread : Starting ZkClient event thread. ...... 2021-01-20 17:35:59.012 INFO 64583 --- [ main] org.apache.zookeeper.ZooKeeper : Client environment:user.home=/Users/liquan 2021-01-20 17:35:59.012 INFO 64583 --- [ main] org.apache.zookeeper.ZooKeeper : Client environment:os.memory.total=310MB 2021-01-20 17:35:59.018 INFO 64583 --- …","date":1611100800,"description":"Soul网关学习Zookeeper数据同步","dir":"blog/soul_source_learning_13_zookeeper_01/","fuzzywordcount":2200,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"9674c2034bd28a675fe6ae6e8c71f825d09fdd66","permalink":"/zh/blog/soul_source_learning_13_zookeeper_01/","publishdate":"2021-01-20T00:00:00Z","readingtime":5,"relpermalink":"/zh/blog/soul_source_learning_13_zookeeper_01/","summary":"启动 soul-admin、soul-bootstrap， 使用zookeeper同步数据到网关 一、配置环境 1、soul-admin 服务配置，需","tags":["Soul"],"title":"Soul网关学习Zookeeper数据同步01","type":"blog","url":"/zh/blog/soul_source_learning_13_zookeeper_01/","wordcount":2181},{"author":"fanjinpeng","categories":"Soul","content":" HTTP 用户接入 Soul 网关注册逻辑分析 1. 注册入口 HTTP 用户接入 Soul 网关时，会调用 soul-admin 一个接口，把需要 Soul 网关管理的接口注册，今天就具体看看到底干了点儿啥。\n先看下调用的接口信息如下：\n// SpringMvcClientBeanPostProcessor.java /** * Instantiates a new Soul client bean post processor. * * @param soulSpringMvcConfig the soul spring mvc config */ public SpringMvcClientBeanPostProcessor(final SoulSpringMvcConfig soulSpringMvcConfig) { ValidateUtils.validate(soulSpringMvcConfig); this.soulSpringMvcConfig = soulSpringMvcConfig; url = soulSpringMvcConfig.getAdminUrl() + \u0026amp;quot;/soul-client/springmvc-register\u0026amp;quot;; executorService = new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026amp;lt;\u0026amp;gt;()); }  2. springmvc-register 接口逻辑 全局搜索 \u0026amp;ldquo;springmvc-register\u0026amp;rdquo;，找到 soul-admin 模块下的 SoulClientController，看到这里，对于经常写 CRUD 的我们是不是很熟悉？哈哈~\n// SoulClientController.java /** * Register spring mvc string. * * @param springMvcRegisterDTO the spring mvc register dto * @return the string */ @PostMapping(\u0026amp;quot;/springmvc-register\u0026amp;quot;) public String registerSpringMvc(@RequestBody final SpringMvcRegisterDTO springMvcRegisterDTO) { return soulClientRegisterService.registerSpringMvc(springMvcRegisterDTO); }  Service 层实现类：\n// SoulClientRegisterServiceImpl.java @Override @Transactional public String registerSpringMvc(final SpringMvcRegisterDTO dto) { if (dto.isRegisterMetaData()) { MetaDataDO exist = metaDataMapper.findByPath(dto.getPath()); if (Objects.isNull(exist)) { saveSpringMvcMetaData(dto); } } String selectorId = handlerSpringMvcSelector(dto); handlerSpringMvcRule(selectorId, dto); return SoulResultMessage.SUCCESS; }  dto.isRegisterMetaData() 这个是否注册元数据信息的判断，不知道什么时候用，存疑 //TODO，先往下走。\n2.1 先看看这个方法 handlerSpringMvcSelector，处理 Selector。 // SoulClientRegisterServiceImpl.java private String handlerSpringMvcSelector(final SpringMvcRegisterDTO dto) { String contextPath = dto.getContext(); // 根据 contextPath 到数据库里查询，是否已经注册过。 SelectorDO selectorDO = selectorService.findByName(contextPath); String selectorId; String uri = String.join(\u0026amp;quot;:\u0026amp;quot;, dto.getHost(), String.valueOf(dto.getPort())); if (Objects.isNull(selectorDO)) { // 还没有注册过 selectorId = registerSelector(contextPath, dto.getRpcType(), dto.getAppName(), uri); } else { // 已经注册过，业务系统重启了会到这里 selectorId = selectorDO.getId(); //update upstream String handle = selectorDO.getHandle(); String handleAdd; DivideUpstream addDivideUpstream = buildDivideUpstream(uri); SelectorData selectorData = selectorService.buildByName(contextPath); if (StringUtils.isBlank(handle)) { handleAdd = GsonUtils.getInstance().toJson(Collections.singletonList(addDivideUpstream)); } else { List\u0026amp;lt;DivideUpstream\u0026amp;gt; exist = GsonUtils.getInstance().fromList(handle, DivideUpstream.class); for (DivideUpstream upstream : exist) { if (upstream.getUpstreamUrl().equals(addDivideUpstream.getUpstreamUrl())) { return selectorId; } } exist.add(addDivideUpstream); handleAdd = GsonUtils.getInstance().toJson(exist); } selectorDO.setHandle(handleAdd); selectorData.setHandle(handleAdd); // update db …","date":1610928000,"description":"Soul Learning (2) HTTP Client Access Source Code Parsing","dir":"blog/soul_source_learning_02_http_client_register/","fuzzywordcount":2600,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"a3c0ba501d97f125dada6e0ea2d5b56e5536ba9f","permalink":"/blog/soul_source_learning_02_http_client_register/","publishdate":"2021-01-18T00:00:00Z","readingtime":6,"relpermalink":"/blog/soul_source_learning_02_http_client_register/","summary":"HTTP 用户接入 Soul 网关注册逻辑分析 1. 注册入口 HTTP 用户接入 Soul 网关时，会调用 soul-admin 一个接口，把需要 Soul 网关管理的接口注册，今天就具体看看到底干了点儿啥。 先看下","tags":["Soul"],"title":"Soul Gateway Learning (2) HTTP Client Access Source Code Parsing","type":"blog","url":"/blog/soul_source_learning_02_http_client_register/","wordcount":2520},{"author":"范金鹏","categories":"Soul","content":" HTTP 用户接入 Soul 网关注册逻辑分析 1. 注册入口 HTTP 用户接入 Soul 网关时，会调用 soul-admin 一个接口，把需要 Soul 网关管理的接口注册，今天就具体看看到底干了点儿啥。\n先看下调用的接口信息如下：\n// SpringMvcClientBeanPostProcessor.java /** * Instantiates a new Soul client bean post processor. * * @param soulSpringMvcConfig the soul spring mvc config */ public SpringMvcClientBeanPostProcessor(final SoulSpringMvcConfig soulSpringMvcConfig) { ValidateUtils.validate(soulSpringMvcConfig); this.soulSpringMvcConfig = soulSpringMvcConfig; url = soulSpringMvcConfig.getAdminUrl() + \u0026amp;quot;/soul-client/springmvc-register\u0026amp;quot;; executorService = new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026amp;lt;\u0026amp;gt;()); }  2. springmvc-register 接口逻辑 全局搜索 \u0026amp;ldquo;springmvc-register\u0026amp;rdquo;，找到 soul-admin 模块下的 SoulClientController，看到这里，对于经常写 CRUD 的我们是不是很熟悉？哈哈~\n// SoulClientController.java /** * Register spring mvc string. * * @param springMvcRegisterDTO the spring mvc register dto * @return the string */ @PostMapping(\u0026amp;quot;/springmvc-register\u0026amp;quot;) public String registerSpringMvc(@RequestBody final SpringMvcRegisterDTO springMvcRegisterDTO) { return soulClientRegisterService.registerSpringMvc(springMvcRegisterDTO); }  Service 层实现类：\n// SoulClientRegisterServiceImpl.java @Override @Transactional public String registerSpringMvc(final SpringMvcRegisterDTO dto) { if (dto.isRegisterMetaData()) { MetaDataDO exist = metaDataMapper.findByPath(dto.getPath()); if (Objects.isNull(exist)) { saveSpringMvcMetaData(dto); } } String selectorId = handlerSpringMvcSelector(dto); handlerSpringMvcRule(selectorId, dto); return SoulResultMessage.SUCCESS; }  dto.isRegisterMetaData() 这个是否注册元数据信息的判断，不知道什么时候用，存疑 //TODO，先往下走。\n2.1 先看看这个方法 handlerSpringMvcSelector，处理 Selector。 // SoulClientRegisterServiceImpl.java private String handlerSpringMvcSelector(final SpringMvcRegisterDTO dto) { String contextPath = dto.getContext(); // 根据 contextPath 到数据库里查询，是否已经注册过。 SelectorDO selectorDO = selectorService.findByName(contextPath); String selectorId; String uri = String.join(\u0026amp;quot;:\u0026amp;quot;, dto.getHost(), String.valueOf(dto.getPort())); if (Objects.isNull(selectorDO)) { // 还没有注册过 selectorId = registerSelector(contextPath, dto.getRpcType(), dto.getAppName(), uri); } else { // 已经注册过，业务系统重启了会到这里 selectorId = selectorDO.getId(); //update upstream String handle = selectorDO.getHandle(); String handleAdd; DivideUpstream addDivideUpstream = buildDivideUpstream(uri); SelectorData selectorData = selectorService.buildByName(contextPath); if (StringUtils.isBlank(handle)) { handleAdd = GsonUtils.getInstance().toJson(Collections.singletonList(addDivideUpstream)); } else { List\u0026amp;lt;DivideUpstream\u0026amp;gt; exist = GsonUtils.getInstance().fromList(handle, DivideUpstream.class); for (DivideUpstream upstream : exist) { if (upstream.getUpstreamUrl().equals(addDivideUpstream.getUpstreamUrl())) { return selectorId; } } exist.add(addDivideUpstream); handleAdd = GsonUtils.getInstance().toJson(exist); } selectorDO.setHandle(handleAdd); selectorData.setHandle(handleAdd); // update db …","date":1610928000,"description":"Soul网关学习(2-3)Http客户端接入源码解析","dir":"blog/soul_source_learning_02_http_client_register/","fuzzywordcount":2600,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"2c483a5594990ffd04046345c06c86cb3f66c113","permalink":"/zh/blog/soul_source_learning_02_http_client_register/","publishdate":"2021-01-18T00:00:00Z","readingtime":6,"relpermalink":"/zh/blog/soul_source_learning_02_http_client_register/","summary":"HTTP 用户接入 Soul 网关注册逻辑分析 1. 注册入口 HTTP 用户接入 Soul 网关时，会调用 soul-admin 一个接口，把需要 Soul 网关管理的接口注册，今天就具体看看到底干了点儿啥。 先看下","tags":["Soul"],"title":"Soul网关学习(2-3)Http客户端接入源码解析","type":"blog","url":"/zh/blog/soul_source_learning_02_http_client_register/","wordcount":2520},{"author":"jipeng","categories":"Soul","content":" Divide 插件如何转发http请求 先来设想一下，网关如果收到了一个请求http://xxx.com/openapi/appname/order/findById?id=3，那么怎么将请求转发给对应的业务？\n可以想象一下大概是这几个步骤：\n 1.解析url 2.查看配置文件，看这个url是对应于哪个业务线 3.读配置文件，获取该业务线在网关注册的所有api列表 4.判断该用户的这个api请求在不在业务的api列表里面 5.进行相关的鉴权操作（用户AK/SK鉴权、用户Quota/QPS有没有超） 6.如果网关有负载均衡功能，那么需要获取业务具体给API配置的负载均衡策略 7.网关向具体的业务API发起请求 8.网关将收到的业务API的response发送给用户  这篇笔记主要来学习一下suol网关是怎么转发http请求的。\n先看一下官方文档的相关介绍http用户、Divide插件\n官方文档里面介绍到，如果网关需要支持http转发，那么需要在网关的pom里面有以下依赖：\n \u0026amp;lt;!--if you use http proxy start this--\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;soul-spring-boot-starter-plugin-divide\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${project.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;soul-spring-boot-starter-plugin-httpclient\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${project.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!--if you use http proxy end this--\u0026amp;gt;  那么可以知道http请求的代理与plugin-divide,plugin-httpclient这两个插件有关。\n插件链 官方文档中说到divide这个插件是实现http请求代理的核心，下面看一下soul-plugin/soul-plugin-divide这个模块的代码，可以看到有一个DividePlugin类，继承自AbstractPlugin，而AbstractPlugin实现了SoulPlugin接口\n可以看到SoulPlugin是DividePlugin的父类，那么猜测一下SoulPlugin是所有插件的父类。全局搜索一下SoulPlugin果然如此，它是诸多插件的父类。\n在全局搜索SoulPlugin的时候，发现soul-web/src/main/java/org/dromara/soul/web/handler里有一个类SoulWebHandler里面有一个属性是List\u0026amp;lt;SoulPlugin\u0026amp;gt;，猜测SoulWebHandler可以操作多个插件。\n看一下SoulWebHandler的继承关系图，发现它是继承了WebHandler，而WebHandler是spring框架里面的一个接口。\n由于对WebFlux不了解，上网快速搜索了一下WebHandler，得知这是WebFlux里面一个很重要的东西，它提供了一套通用的http请求处理方案。\n而soul网关的源码里面，自己实现了一个实现了WebHandler接口的SoulWebHandler类，无疑是希望框架使用soul实现的这套东西来处理请求。\n在soul-web/src/main/java/org/dromara/soul/web/configuration里的SoulConfiguration类，它在类头上声明了注解@Configuration，表明它是一个配置。SoulConfiguration类里面向spring容器注入了一个名为webHandler的bean，该bean是SoulWebHandler类型的。Application会在启动的时候扫描被@Configuration注解的类，所以通过以下代码，SoulWebHandler就被注入到spring容器中去了。\n @Bean(\u0026amp;quot;webHandler\u0026amp;quot;) public SoulWebHandler soulWebHandler(final ObjectProvider\u0026amp;lt;List\u0026amp;lt;SoulPlugin\u0026amp;gt;\u0026amp;gt; plugins) { List\u0026amp;lt;SoulPlugin\u0026amp;gt; pluginList = plugins.getIfAvailable(Collections::emptyList); final List\u0026amp;lt;SoulPlugin\u0026amp;gt; soulPlugins = pluginList.stream() .sorted(Comparator.comparingInt(SoulPlugin::getOrder)).collect(Collectors.toList()); soulPlugins.forEach(soulPlugin -\u0026amp;gt; log.info(\u0026amp;quot;load plugin:[{}] [{}]\u0026amp;quot;, soulPlugin.named(), soulPlugin.getClass().getName())); return new SoulWebHandler(soulPlugins); }  初始化SoulWebHandler的时候，将排好序的插件传入其构造函数中。各个插件都有一个order属性，可以根据这个属性来对插件进行优先级排序。以DividePlugin为例，看下它的order属性是从一个枚举类里面来的。\n @Override public int getOrder() { return PluginEnum.DIVIDE.getCode(); }  而各个插件的order的具体值是在soul-common/src/main/java/org/dromara/soul/common/enums/PluginEnums这个枚举类里面定义的。PluginEnum的code即为各个插件的order。\n插件的顺序为：global -\u0026amp;gt; sign -\u0026amp;gt; waf -\u0026amp;gt; rate-limiter -\u0026amp;gt; hystrix -\u0026amp;gt; resilience4j -\u0026amp;gt; divide -\u0026amp;gt; webClient -\u0026amp;gt; …………\n每次有一个请求的时候，WebHandler即SoulWebHandler的handle方法都会被调用，该方法里面最主要的就是初始化了一个插件链DefaultSoulPluginChain，并执行该插件链。\n看一下DefaultSoulPluginChain …","date":1610841600,"description":"How Does The Divide Plugin Forward HTTP Requests","dir":"blog/soul_source_larning_02_divide_plugin_source/","fuzzywordcount":3100,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"87582eba66f445601b6bc4d76ad5b35970a253df","permalink":"/blog/soul_source_larning_02_divide_plugin_source/","publishdate":"2021-01-17T00:00:00Z","readingtime":7,"relpermalink":"/blog/soul_source_larning_02_divide_plugin_source/","summary":"Divide 插件如何转发http请求 先来设想一下，网关如果收到了一个请求http://xxx.com/openapi/appname/order/fi","tags":["Soul"],"title":"Soul Learning(2) How Does The Divide Plugin Forward Http Requests","type":"blog","url":"/blog/soul_source_larning_02_divide_plugin_source/","wordcount":3042},{"author":"季鹏","categories":"Soul","content":" Divide 插件如何转发http请求 先来设想一下，网关如果收到了一个请求http://xxx.com/openapi/appname/order/findById?id=3，那么怎么将请求转发给对应的业务？\n可以想象一下大概是这几个步骤：\n 1.解析url 2.查看配置文件，看这个url是对应于哪个业务线 3.读配置文件，获取该业务线在网关注册的所有api列表 4.判断该用户的这个api请求在不在业务的api列表里面 5.进行相关的鉴权操作（用户AK/SK鉴权、用户Quota/QPS有没有超） 6.如果网关有负载均衡功能，那么需要获取业务具体给API配置的负载均衡策略 7.网关向具体的业务API发起请求 8.网关将收到的业务API的response发送给用户  这篇笔记主要来学习一下suol网关是怎么转发http请求的。\n先看一下官方文档的相关介绍http用户、Divide插件\n官方文档里面介绍到，如果网关需要支持http转发，那么需要在网关的pom里面有以下依赖：\n \u0026amp;lt;!--if you use http proxy start this--\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;soul-spring-boot-starter-plugin-divide\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${project.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;soul-spring-boot-starter-plugin-httpclient\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${project.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!--if you use http proxy end this--\u0026amp;gt;  那么可以知道http请求的代理与plugin-divide,plugin-httpclient这两个插件有关。\n插件链 官方文档中说到divide这个插件是实现http请求代理的核心，下面看一下soul-plugin/soul-plugin-divide这个模块的代码，可以看到有一个DividePlugin类，继承自AbstractPlugin，而AbstractPlugin实现了SoulPlugin接口\n可以看到SoulPlugin是DividePlugin的父类，那么猜测一下SoulPlugin是所有插件的父类。全局搜索一下SoulPlugin果然如此，它是诸多插件的父类。\n在全局搜索SoulPlugin的时候，发现soul-web/src/main/java/org/dromara/soul/web/handler里有一个类SoulWebHandler里面有一个属性是List\u0026amp;lt;SoulPlugin\u0026amp;gt;，猜测SoulWebHandler可以操作多个插件。\n看一下SoulWebHandler的继承关系图，发现它是继承了WebHandler，而WebHandler是spring框架里面的一个接口。\n由于对WebFlux不了解，上网快速搜索了一下WebHandler，得知这是WebFlux里面一个很重要的东西，它提供了一套通用的http请求处理方案。\n而soul网关的源码里面，自己实现了一个实现了WebHandler接口的SoulWebHandler类，无疑是希望框架使用soul实现的这套东西来处理请求。\n在soul-web/src/main/java/org/dromara/soul/web/configuration里的SoulConfiguration类，它在类头上声明了注解@Configuration，表明它是一个配置。SoulConfiguration类里面向spring容器注入了一个名为webHandler的bean，该bean是SoulWebHandler类型的。Application会在启动的时候扫描被@Configuration注解的类，所以通过以下代码，SoulWebHandler就被注入到spring容器中去了。\n @Bean(\u0026amp;quot;webHandler\u0026amp;quot;) public SoulWebHandler soulWebHandler(final ObjectProvider\u0026amp;lt;List\u0026amp;lt;SoulPlugin\u0026amp;gt;\u0026amp;gt; plugins) { List\u0026amp;lt;SoulPlugin\u0026amp;gt; pluginList = plugins.getIfAvailable(Collections::emptyList); final List\u0026amp;lt;SoulPlugin\u0026amp;gt; soulPlugins = pluginList.stream() .sorted(Comparator.comparingInt(SoulPlugin::getOrder)).collect(Collectors.toList()); soulPlugins.forEach(soulPlugin -\u0026amp;gt; log.info(\u0026amp;quot;load plugin:[{}] [{}]\u0026amp;quot;, soulPlugin.named(), soulPlugin.getClass().getName())); return new SoulWebHandler(soulPlugins); }  初始化SoulWebHandler的时候，将排好序的插件传入其构造函数中。各个插件都有一个order属性，可以根据这个属性来对插件进行优先级排序。以DividePlugin为例，看下它的order属性是从一个枚举类里面来的。\n @Override public int getOrder() { return PluginEnum.DIVIDE.getCode(); }  而各个插件的order的具体值是在soul-common/src/main/java/org/dromara/soul/common/enums/PluginEnums这个枚举类里面定义的。PluginEnum的code即为各个插件的order。\n插件的顺序为：global -\u0026amp;gt; sign -\u0026amp;gt; waf -\u0026amp;gt; rate-limiter -\u0026amp;gt; hystrix -\u0026amp;gt; resilience4j -\u0026amp;gt; divide -\u0026amp;gt; webClient -\u0026amp;gt; …………\n每次有一个请求的时候，WebHandler即SoulWebHandler的handle方法都会被调用，该方法里面最主要的就是初始化了一个插件链DefaultSoulPluginChain，并执行该插件链。\n看一下DefaultSoulPluginChain …","date":1610841600,"description":"Soul网关学习(2-2)divide插件源码解析","dir":"blog/soul_source_learning_02_divide_plugin_source/","fuzzywordcount":3100,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"523ea346c1dea626e3fc7a9cc1f57d2d3a63d612","permalink":"/zh/blog/soul_source_learning_02_divide_plugin_source/","publishdate":"2021-01-17T00:00:00Z","readingtime":7,"relpermalink":"/zh/blog/soul_source_learning_02_divide_plugin_source/","summary":"Divide 插件如何转发http请求 先来设想一下，网关如果收到了一个请求http://xxx.com/openapi/appname/order/fi","tags":["Soul"],"title":"Soul网关学习(2-2)Http代理之divide插件源码解析","type":"blog","url":"/zh/blog/soul_source_learning_02_divide_plugin_source/","wordcount":3042},{"author":"yuanjie","categories":"Soul","content":" Divide 插件使用 一、启动项目 先启动soul-bootstrap（9195）、soul-admin（9095）两个模块，我们通过bootstrap配置文件可以看到，两者是通过WebSocket协议进行数据同步：\n通过bootstrap日志也可以看到：\n所谓的数据同步是指将soul-admin中配置的数据，同步到soul集群中的JVM内存里面，是网关高性能的关键。\n我们启动两个项目之后就可以通过后台管理系统测试divide插件了。\n二、divide插件介绍 divide插件是网关处理http协议请求的核心处理插件，也是soul唯一默认开启的插件：\n我们可以想象一下网关到底是做什么的，去猜测一下处理http请求的divide插件可能具备哪些功能呢？\n首先，作为微服务网关，它的背后一定存在多条业务线的分布式微服务集群，而网关作为所有服务的统一入口，必须具备的能力就是流量分发/路由/负载均衡等，而divide这个单词顾名思义就是分配、分发的意思，所以我们可以猜测divide插件就是对http请求进行各种规则的路由转发，这也是网关最基础的能力。\n我们打开管理界面上的插件列表，可以看到所有插件都是由两部分组成：选择器（selector）和选择器规则。\n插件化设计思想是soul网关最核心的设计思想，而选择器和规则这两个概念也是soul网关的灵魂所在，理论上来说，我们掌握好它，就能对任何接入网关的流量进行管理。\n一个插件有多个选择器，一个选择器对应多种规则。选择器相当于是对流量的第一次筛选，规则就是最终的筛选。\n选择器  名称：为你的选择器起一个容易分辨的名字 类型：custom flow 是自定义流量。full flow 是全流量。自定义流量就是请求会走你下面的匹配方式与条件。全流量则不走。 匹配方式：and 或者or 是指下面多个条件是按照and 还是or的方式来组合。 条件：\n uri：是指你根据uri的方式来筛选流量，match的方式支持模糊匹配（/**） header：是指根据请求头里面的字段来筛选流量。 query：是指根据uri的查询条件来进行筛选流量。 ip：是指根据你请求的真实ip，来筛选流量。 host：是指根据你请求的真实host，来筛选流量。 post：建议不要使用。 条件匹配：  match : 模糊匹配，建议和uri条件搭配，支持 restful风格的匹配。（/test/**） = : 前后值相等，才能匹配。 regEx : 正则匹配，表示前面一个值去匹配后面的正则表达式。 like ：字符串模糊匹配。  是否开启：打开才会生效 打印日志：打开的时候，当匹配上的时候，会打印匹配日志。 执行顺序：当多个选择器的时候，执行顺序小的优先执行。\n选择器规则   可以看到，规则的配置和选择器类似，可以理解为更细粒度的自定义配置。\n三、divide插件使用 废话少说，我们直接运行soul提供的examples模块来演示divide插件。\n注意，我们最终运行的是soul-examples-http模块。配置文件可以使用默认的，也可以自定义contextPath和appName，如上图。\n我们需要注意，contextPath这个属性非常重要，相当于是我们所有http请求的namespace，和选择器一一对齐。一般来说，我们可以配置一个业务对应一个contextPath，一个业务下面配置相同contextPath的多个服务实例会自动映射到同一个选择器进行负载均衡。\n我们启动端口为8188的这个进程后，可以发现管理控制台divide插件列表中自动配置了这个实例对应的选择器、规则：\n可以看到我启动的这个8188项目地址自动注册上去了：\n测试网关路由 通过postman先测试不经过网关转发：\nhttp://localhost:8188/order/findById?id=1  然后再测试通过网关转发到这个接口：\nhttp://localhost:9195/my-http/order/findById?id=1  看日志发现确实经过了网关转发到了8188接口地址：\n测试负载均衡 我们修改端口为8189，启动第二个进程。\n注意IDEA需要取消 Single instance only 的限制：\n我们再进入管理控制台，发现my-http选择器下出现两个配置地址：\n此时我们继续测试，发现负载均衡策略确实生效了：\n今天只是演示了divide插件最基础的配置，还有其他各种规则配置后面都可以试一试~\n","date":1610755200,"description":"Soul Learning(2) Use Divide Plugin","dir":"blog/soul_source_learning_02_divide_plugin/","fuzzywordcount":1700,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"6140e42808a6873cd47e1b7d8c5a120eabe87b7c","permalink":"/blog/soul_source_learning_02_divide_plugin/","publishdate":"2021-01-16T00:00:00Z","readingtime":4,"relpermalink":"/blog/soul_source_learning_02_divide_plugin/","summary":"Divide 插件使用 一、启动项目 先启动soul-bootstrap（9195）、soul-admin（9095）两个模块，我们通过bootstrap配","tags":["Soul"],"title":"Soul Learning(2) Use Divide Plugin","type":"blog","url":"/blog/soul_source_learning_02_divide_plugin/","wordcount":1671},{"author":"袁杰","categories":"Soul","content":" Divide 插件使用 一、启动项目 先启动soul-bootstrap（9195）、soul-admin（9095）两个模块，我们通过bootstrap配置文件可以看到，两者是通过WebSocket协议进行数据同步：\n通过bootstrap日志也可以看到：\n所谓的数据同步是指将soul-admin中配置的数据，同步到soul集群中的JVM内存里面，是网关高性能的关键。\n我们启动两个项目之后就可以通过后台管理系统测试divide插件了。\n二、divide插件介绍 divide插件是网关处理http协议请求的核心处理插件，也是soul唯一默认开启的插件：\n我们可以想象一下网关到底是做什么的，去猜测一下处理http请求的divide插件可能具备哪些功能呢？\n首先，作为微服务网关，它的背后一定存在多条业务线的分布式微服务集群，而网关作为所有服务的统一入口，必须具备的能力就是流量分发/路由/负载均衡等，而divide这个单词顾名思义就是分配、分发的意思，所以我们可以猜测divide插件就是对http请求进行各种规则的路由转发，这也是网关最基础的能力。\n我们打开管理界面上的插件列表，可以看到所有插件都是由两部分组成：选择器（selector）和选择器规则。\n插件化设计思想是soul网关最核心的设计思想，而选择器和规则这两个概念也是soul网关的灵魂所在，理论上来说，我们掌握好它，就能对任何接入网关的流量进行管理。\n一个插件有多个选择器，一个选择器对应多种规则。选择器相当于是对流量的第一次筛选，规则就是最终的筛选。\n选择器 * **名称**：为你的选择器起一个容易分辨的名字 * **类型**：custom flow 是自定义流量。full flow 是全流量。自定义流量就是请求会走你下面的匹配方式与条件。全流量则不走。 * **匹配方式**：and 或者or 是指下面多个条件是按照and 还是or的方式来组合。 * **条件**： * uri：是指你根据uri的方式来筛选流量，match的方式支持模糊匹配（/**） * header：是指根据请求头里面的字段来筛选流量。 * query：是指根据uri的查询条件来进行筛选流量。 * ip：是指根据你请求的真实ip，来筛选流量。 * host：是指根据你请求的真实host，来筛选流量。 * post：建议不要使用。 * 条件匹配： * match : 模糊匹配，建议和uri条件搭配，支持 restful风格的匹配。（/test/**） * = : 前后值相等，才能匹配。 * regEx : 正则匹配，表示前面一个值去匹配后面的正则表达式。 * like ：字符串模糊匹配。 * **是否开启**：打开才会生效 * **打印日志**：打开的时候，当匹配上的时候，会打印匹配日志。 * **执行顺序**：当多个选择器的时候，执行顺序小的优先执行。  选择器规则 可以看到，规则的配置和选择器类似，可以理解为更细粒度的自定义配置。\n三、divide插件使用 废话少说，我们直接运行soul提供的examples模块来演示divide插件。\n注意，我们最终运行的是soul-examples-http模块。配置文件可以使用默认的，也可以自定义contextPath和appName，如上图。\n我们需要注意，contextPath这个属性非常重要，相当于是我们所有http请求的namespace，和选择器一一对齐。一般来说，我们可以配置一个业务对应一个contextPath，一个业务下面配置相同contextPath的多个服务实例会自动映射到同一个选择器进行负载均衡。\n我们启动端口为8188的这个进程后，可以发现管理控制台divide插件列表中自动配置了这个实例对应的选择器、规则：\n可以看到我启动的这个8188项目地址自动注册上去了：\n测试网关路由 通过postman先测试不经过网关转发：\nhttp://localhost:8188/order/findById?id=1  然后再测试通过网关转发到这个接口：\nhttp://localhost:9195/my-http/order/findById?id=1  看日志发现确实经过了网关转发到了8188接口地址：\n测试负载均衡 我们修改端口为8189，启动第二个进程。\n注意IDEA需要取消 Single instance only 的限制：\n我们再进入管理控制台，发现my-http选择器下出现两个配置地址：\n此时我们继续测试，发现负载均衡策略确实生效了：\n今天只是演示了divide插件最基础的配置，还有其他各种规则配置后面都可以试一试~\n","date":1610755200,"description":"Soul网关学习(2-1)divide插件使用","dir":"blog/soul_source_learning_02_divide_plugin/","fuzzywordcount":1800,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"08e6332a7fda52e8db34c6dc66ff7a3534020ef7","permalink":"/zh/blog/soul_source_learning_02_divide_plugin/","publishdate":"2021-01-16T00:00:00Z","readingtime":4,"relpermalink":"/zh/blog/soul_source_learning_02_divide_plugin/","summary":"Divide 插件使用 一、启动项目 先启动soul-bootstrap（9195）、soul-admin（9095）两个模块，我们通过bootstrap配","tags":["Soul"],"title":"Soul网关学习(2-1)Http代理之divide插件使用","type":"blog","url":"/zh/blog/soul_source_learning_02_divide_plugin/","wordcount":1717},{"author":"zhuming","categories":"Soul","content":" 插件链总结 从一个类关系图说起:\n其中两个最基本的插件类:\n SoulPlugin: 定义插件职责的接口, 重点方法execute() 被上层调用, skip() 方法可以使某些插件在某些请求中被跳过.\n AbstractPlugin: 抽象类, 实现接口的 execute(), 定义一套通用的执行流程, 并使用模板方法的设计模式, 提供doExecute()抽象方法供实现类写自己的逻辑.\n  AbstractSoulPlugin 具体分析下 AbstractSoulPlugin 类的 execute():\npublic Mono\u0026amp;lt;Void\u0026amp;gt; execute(final ServerWebExchange exchange, final SoulPluginChain chain) { String pluginName = named(); final PluginData pluginData = BaseDataCache.getInstance().obtainPluginData(pluginName); // 如果 pluginData.getEnabled() 为 false, 会直接跳到下个插件, 仅有为数不多的插件会进入这个条件判断 (DividePlugin、AlibabaDubboPlugin等) if (pluginData != null \u0026amp;amp;\u0026amp;amp; pluginData.getEnabled()) { // 获得插件上的所有选择器 final Collection\u0026amp;lt;SelectorData\u0026amp;gt; selectors = BaseDataCache.getInstance().obtainSelectorData(pluginName); if (CollectionUtils.isEmpty(selectors)) { return CheckUtils.checkSelector(pluginName, exchange, chain); } // 检查上下文中的请求路径, 是否与选择器匹配, 并得到唯一一个匹配的选择器数据 final SelectorData selectorData = matchSelector(exchange, selectors); if (Objects.isNull(selectorData)) { if (PluginEnum.WAF.getName().equals(pluginName)) { return doExecute(exchange, chain, null, null); } return CheckUtils.checkSelector(pluginName, exchange, chain); } if (selectorData.getLoged()) { log.info(\u0026amp;quot;{} selector success match , selector name :{}\u0026amp;quot;, pluginName, selectorData.getName()); } // 获得选择器中的各个资源规则 final List\u0026amp;lt;RuleData\u0026amp;gt; rules = BaseDataCache.getInstance().obtainRuleData(selectorData.getId()); if (CollectionUtils.isEmpty(rules)) { if (PluginEnum.WAF.getName().equals(pluginName)) { return doExecute(exchange, chain, null, null); } return CheckUtils.checkRule(pluginName, exchange, chain); } RuleData rule; if (selectorData.getType() == SelectorTypeEnum.FULL_FLOW.getCode()) { rule = rules.get(rules.size() - 1); } else { // 匹配路径, 获得唯一一个规则 rule = matchRule(exchange, rules); } if (Objects.isNull(rule)) { return CheckUtils.checkRule(pluginName, exchange, chain); } if (rule.getLoged()) { log.info(\u0026amp;quot;{} rule success match ,rule name :{}\u0026amp;quot;, pluginName, rule.getName()); } // 执行子类的方法 return doExecute(exchange, chain, selectorData, rule); } // 执行插件链上的下个插件 return chain.execute(exchange); }  通过代码分析, 可以得到一些结论:\n execute() 有两个逻辑: 一是请求路径与选择器和规则的匹配, 最终确认一个唯一规则, 并调用子类 doExecute(); 二是执行插件链上的下个插件. execute() 实际抽象了一套规则匹配逻辑, 供所有\u0026amp;rdquo;转发类型\u0026amp;rdquo;的插件使用的, 转发类型的插件目前我了解的有 DividePlugin (http请求) 和 AlibabaDubboPlugin (dubbo请求), 其他类型的插件如果不重写 execute() 的方法, 会直接走入下个插件.  SoulPluginChain 这里还有个点, 就是插件链的形成与链式调用, 我们来分析下 SoulPluginChain 这块:\nSoulPluginChain 接口同样定义了 execute() 方法供调用者使用, 它的唯一子类 DefaultSoulPluginChain 实现了链式调用:\npublic Mono\u0026amp;lt;Void\u0026amp;gt; execute(final ServerWebExchange exchange) { return Mono.defer(() -\u0026amp;gt; { // plugins 中包含所有网关加载的插件 if (this.index \u0026amp;lt; plugins.size()) { // 每次调用execute()方法, index索引自增, 会调用到下一个插件 SoulPlugin plugin = plugins.get(this.index++); // 结合上下文判断当前插件是否需要跳过 Boolean skip = plugin.skip(exchange); if (skip) { return this.execute(exchange); } else { return plugin.execute(exchange, this); } } else { return Mono.empty(); } }); } …","date":1610668800,"description":"Soul Gateway learning plugin chain and load balancing analysis","dir":"blog/soul_source_learning_05_plugin/","fuzzywordcount":3600,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"6a9a3a7e8b883a4038e351e7f4d883834cf4ca7f","permalink":"/blog/soul_source_learning_05_plugin/","publishdate":"2021-01-15T00:00:00Z","readingtime":8,"relpermalink":"/blog/soul_source_learning_05_plugin/","summary":"插件链总结 从一个类关系图说起: 其中两个最基本的插件类: SoulPlugin: 定义插件职责的接口, 重点方法execute() 被上层调用, skip() 方法可以使某些插件在某些","tags":["Soul"],"title":"Soul Gateway learning plugin chain and load balancing analysis","type":"blog","url":"/blog/soul_source_learning_05_plugin/","wordcount":3567},{"author":"chenxi","categories":"Soul","content":" Analysis of soul (1) Set up soul environment  soul is a High-Performance Java API Gateway\nGitHub：https://github.com/dromara/soul\ndocument：https://dromara.org/zh-cn/docs/soul/soul.html\n 1. Prepare source code 1.1. Fork dromara/soul repository to my github cchenxi/soul 1.2. Clone the repository git clone https://github.com/cchenxi/soul.git  1.3.Open the source code with idea 1.4. Compile the soul source code You can compile the project as follows.\nmvn clean package install -Dmaven.test.skip=true -Dmaven.javadoc.skip=true -Drat.skip=true -Dcheckstyle.skip=true  2. Startup soul 2.1. Startup soul-admin module  soul-admin is the management system for soul.\n Choose to use MySQL to storage gateway data and modify the datasource config.\nRun org.dromara.soul.admin.SoulAdminBootstrap.\nWhen success, please visit the website http://localhost:9095/, then jump to the login page, and input the corresponding user name and password to log in.\nThe user name is admin and the password is 123456.\n2.2. Startup soul-bootstrap module  soul-bootstrap is the core of soul.\n Check the configuration of soul-bootstrap.\nPlease make sure the ip and the port has been configured for soul-admin.\nIf the console output as follows, it means the startup is successful.\n2021-01-14 15:01:15.832 INFO 17943 --- [ main] b.s.s.d.w.WebsocketSyncDataConfiguration : you use websocket sync soul data....... 2021-01-14 15:01:15.924 INFO 17943 --- [ main] o.d.s.p.s.d.w.WebsocketSyncDataService : websocket connection is successful..... 2021-01-14 15:01:16.113 INFO 17943 --- [ main] o.s.b.a.e.web.EndpointLinksResolver : Exposing 2 endpoint(s) beneath base path \u0026#39;/actuator\u0026#39; log4j:WARN No appenders could be found for logger (com.alibaba.dubbo.common.logger.LoggerFactory). log4j:WARN Please initialize the log4j system properly. log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info. 2021-01-14 15:01:17.150 INFO 17943 --- [ main] o.s.b.web.embedded.netty.NettyWebServer : Netty started on port(s): 9195 2021-01-14 15:01:17.154 INFO 17943 --- [ main] o.d.s.b.SoulBootstrapApplication : Started SoulBootstrapApplication in 5.508 seconds (JVM running for 6.762)  3. Test  Add the soul-examples module to soul\u0026amp;rsquo;s pom.xml for test.\n 3.1. Startup an HTTP backend service Startup soul-examples-http\nYou can see the dependency in soul-examples-http\u0026amp;rsquo;s pom.xml.\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;soul-spring-boot-starter-client-springmvc\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${soul.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  Configure the application.yml\nsoul: http: adminUrl: http://localhost:9095 port: 8188 contextPath: /http appName: http full: false  If soul.http.full=false, you need to add the @SoulSpringMvcClient annotation in controller or controller method.\n3.1.1. Test the service Visit http://localhost:8188/test/findByUserId?userId=1 and the result as follows.\n3.1.2. Test forward HTTP request Visit …","date":1610668800,"description":"Soul Learning(1) Environment Configuration","dir":"blog/soul_source_learning_01/","fuzzywordcount":1000,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"60087a4153a0bad904e416d6a73991a1d730ac31","permalink":"/blog/soul_source_learning_01/","publishdate":"2021-01-15T00:00:00Z","readingtime":5,"relpermalink":"/blog/soul_source_learning_01/","summary":"Analysis of soul (1) Set up soul environment  soul is a High-Performance Java API Gateway\nGitHub：https://github.com/dromara/soul\ndocument：https://dromara.org/zh-cn/docs/soul/soul.html\n 1. Prepare source code 1.1. Fork dromara/soul repository to my github cchenxi/soul 1.2. Clone the repository git clone https://github.com/cchenxi/soul.git  1.3.Open the source code with idea 1.4. Compile the soul source code You can compile the project as follows.\nmvn clean package install -Dmaven.test.skip=true -Dmaven.javadoc.skip=true -Drat.skip=true -Dcheckstyle.skip=true  2. Startup soul 2.","tags":["Soul"],"title":"Soul Learning(1) Environment Configuration","type":"blog","url":"/blog/soul_source_learning_01/","wordcount":933},{"author":"陈曦","categories":"Soul","content":" Soul源码分析（1） 环境配置  soul is a High-Performance Java API Gateway\nGitHub：https://github.com/dromara/soul\n官方文档：https://dromara.org/zh-cn/docs/soul/soul.html\n 1. 源代码准备 1.1. fork dromara/soul源代码至自己的仓库cchenxi/soul 1.2. clone自己仓库中的soul源代码至本地 git clone https://github.com/cchenxi/soul.git  1.3.使用idea打开soul源代码 1.4.编译soul源代码 执行以下maven命令，等待编译完成\nmvn clean package install -Dmaven.test.skip=true -Dmaven.javadoc.skip=true -Drat.skip=true -Dcheckstyle.skip=true  2. 启动 soul 2.1. 启动soul-admin模块  soul-admin是soul网关的后台管理系统\n 选择使用MySQL数据库存储网关数据，修改数据源配置为自己的数据库配置。\n运行启动类 org.dromara.soul.admin.SoulAdminBootstrap。\n启动成功后，访问地址 http://localhost:9095/ ，跳转到登录页↓\n使用用户名admin，密码 123456 登录。\n2.2. 启动soul-bootstrap模块  soul-bootstrap是网关系统的核心\n 检查soul-bootstrap的配置\n这里需要配置成 soul-admin的ip和端口\n控制台输出如下内容表示 soul-bootstrap启动成功\n2021-01-14 15:01:15.832 INFO 17943 --- [ main] b.s.s.d.w.WebsocketSyncDataConfiguration : you use websocket sync soul data....... 2021-01-14 15:01:15.924 INFO 17943 --- [ main] o.d.s.p.s.d.w.WebsocketSyncDataService : websocket connection is successful..... 2021-01-14 15:01:16.113 INFO 17943 --- [ main] o.s.b.a.e.web.EndpointLinksResolver : Exposing 2 endpoint(s) beneath base path \u0026#39;/actuator\u0026#39; log4j:WARN No appenders could be found for logger (com.alibaba.dubbo.common.logger.LoggerFactory). log4j:WARN Please initialize the log4j system properly. log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info. 2021-01-14 15:01:17.150 INFO 17943 --- [ main] o.s.b.web.embedded.netty.NettyWebServer : Netty started on port(s): 9195 2021-01-14 15:01:17.154 INFO 17943 --- [ main] o.d.s.b.SoulBootstrapApplication : Started SoulBootstrapApplication in 5.508 seconds (JVM running for 6.762)  3. 测试http请求转发  为了方便测试，把soul-examples模块添加到soul的pom里\n 3.1. 启动一个服务 启动soul-examples-http项目\nsoul-examples-http的pom中引入了依赖\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;soul-spring-boot-starter-client-springmvc\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;${soul.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  在 application.yml中配置\nsoul: http: adminUrl: http://localhost:9095 port: 8188 contextPath: /http appName: http full: false  如果soul.http.full=false，则需要在具体的http接口上配置 @SoulSpringMvcClient 注解\n3.1.1. 测试http服务 执行http请求 http://localhost:8188/test/findByUserId?userId=1 结果如下图\n3.1.2. 测试网关转发 执行http请求 http://localhost:9195/http/test/findByUserId?userId=1 结果如下图\n在soul-bootstrap的控制台中输出如下信息\n2021-01-14 20:42:57.123 INFO 29812 --- [work-threads-11] o.d.soul.plugin.base.AbstractSoulPlugin : divide selector success match , selector name :/http 2021-01-14 20:42:57.125 INFO 29812 --- [work-threads-11] o.d.soul.plugin.base.AbstractSoulPlugin : divide selector success match , selector name :/http/test/** 2021-01-14 20:42:57.126 INFO 29812 --- [work-threads-11] o.d.s.plugin.httpclient.WebClientPlugin : The request urlPath is http://172.27.121.155:8188/test/findByUserId?userId=1, retryTimes is 0  可以观察到网关可以将请求正常转发。\n3.2. 启动两个服务模拟负载均衡 勾选 Allow parallel run，修改端口为8189，再次启动soul-examples-http …","date":1610668800,"description":"Soul网关学习(1)环境配置","dir":"blog/soul_source_learning_01/","fuzzywordcount":1700,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"3a96524fdc06f3631dc2c569c3b39263f136a2c7","permalink":"/zh/blog/soul_source_learning_01/","publishdate":"2021-01-15T00:00:00Z","readingtime":4,"relpermalink":"/zh/blog/soul_source_learning_01/","summary":"Soul源码分析（1） 环境配置 soul is a High-Performance Java API Gateway GitHub：https://github.com/dromara/soul 官方文档：https","tags":["Soul"],"title":"Soul网关学习(1)环境配置","type":"blog","url":"/zh/blog/soul_source_learning_01/","wordcount":1625},{"author":"朱明","categories":"Soul","content":" 插件链总结 从一个类关系图说起:\n其中两个最基本的插件类:\n SoulPlugin: 定义插件职责的接口, 重点方法execute() 被上层调用, skip() 方法可以使某些插件在某些请求中被跳过.\n AbstractPlugin: 抽象类, 实现接口的 execute(), 定义一套通用的执行流程, 并使用模板方法的设计模式, 提供doExecute()抽象方法供实现类写自己的逻辑.\n  AbstractSoulPlugin 具体分析下 AbstractSoulPlugin 类的 execute():\npublic Mono\u0026amp;lt;Void\u0026amp;gt; execute(final ServerWebExchange exchange, final SoulPluginChain chain) { String pluginName = named(); final PluginData pluginData = BaseDataCache.getInstance().obtainPluginData(pluginName); // 如果 pluginData.getEnabled() 为 false, 会直接跳到下个插件, 仅有为数不多的插件会进入这个条件判断 (DividePlugin、AlibabaDubboPlugin等) if (pluginData != null \u0026amp;amp;\u0026amp;amp; pluginData.getEnabled()) { // 获得插件上的所有选择器 final Collection\u0026amp;lt;SelectorData\u0026amp;gt; selectors = BaseDataCache.getInstance().obtainSelectorData(pluginName); if (CollectionUtils.isEmpty(selectors)) { return CheckUtils.checkSelector(pluginName, exchange, chain); } // 检查上下文中的请求路径, 是否与选择器匹配, 并得到唯一一个匹配的选择器数据 final SelectorData selectorData = matchSelector(exchange, selectors); if (Objects.isNull(selectorData)) { if (PluginEnum.WAF.getName().equals(pluginName)) { return doExecute(exchange, chain, null, null); } return CheckUtils.checkSelector(pluginName, exchange, chain); } if (selectorData.getLoged()) { log.info(\u0026amp;quot;{} selector success match , selector name :{}\u0026amp;quot;, pluginName, selectorData.getName()); } // 获得选择器中的各个资源规则 final List\u0026amp;lt;RuleData\u0026amp;gt; rules = BaseDataCache.getInstance().obtainRuleData(selectorData.getId()); if (CollectionUtils.isEmpty(rules)) { if (PluginEnum.WAF.getName().equals(pluginName)) { return doExecute(exchange, chain, null, null); } return CheckUtils.checkRule(pluginName, exchange, chain); } RuleData rule; if (selectorData.getType() == SelectorTypeEnum.FULL_FLOW.getCode()) { rule = rules.get(rules.size() - 1); } else { // 匹配路径, 获得唯一一个规则 rule = matchRule(exchange, rules); } if (Objects.isNull(rule)) { return CheckUtils.checkRule(pluginName, exchange, chain); } if (rule.getLoged()) { log.info(\u0026amp;quot;{} rule success match ,rule name :{}\u0026amp;quot;, pluginName, rule.getName()); } // 执行子类的方法 return doExecute(exchange, chain, selectorData, rule); } // 执行插件链上的下个插件 return chain.execute(exchange); }  通过代码分析, 可以得到一些结论:\n execute() 有两个逻辑: 一是请求路径与选择器和规则的匹配, 最终确认一个唯一规则, 并调用子类 doExecute(); 二是执行插件链上的下个插件. execute() 实际抽象了一套规则匹配逻辑, 供所有\u0026amp;rdquo;转发类型\u0026amp;rdquo;的插件使用的, 转发类型的插件目前我了解的有 DividePlugin (http请求) 和 AlibabaDubboPlugin (dubbo请求), 其他类型的插件如果不重写 execute() 的方法, 会直接走入下个插件.  SoulPluginChain 这里还有个点, 就是插件链的形成与链式调用, 我们来分析下 SoulPluginChain 这块:\nSoulPluginChain 接口同样定义了 execute() 方法供调用者使用, 它的唯一子类 DefaultSoulPluginChain 实现了链式调用:\npublic Mono\u0026amp;lt;Void\u0026amp;gt; execute(final ServerWebExchange exchange) { return Mono.defer(() -\u0026amp;gt; { // plugins 中包含所有网关加载的插件 if (this.index \u0026amp;lt; plugins.size()) { // 每次调用execute()方法, index索引自增, 会调用到下一个插件 SoulPlugin plugin = plugins.get(this.index++); // 结合上下文判断当前插件是否需要跳过 Boolean skip = plugin.skip(exchange); if (skip) { return this.execute(exchange); } else { return plugin.execute(exchange, this); } } else { return Mono.empty(); } }); } …","date":1610668800,"description":"Soul网关学习插件链与负载均衡解析","dir":"blog/soul_source_learning_05_plugin/","fuzzywordcount":3600,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"25cc244bdfddbfa28fa87d24664e43e9b8b038d9","permalink":"/zh/blog/soul_source_learning_05_plugin/","publishdate":"2021-01-15T00:00:00Z","readingtime":8,"relpermalink":"/zh/blog/soul_source_learning_05_plugin/","summary":"插件链总结 从一个类关系图说起: 其中两个最基本的插件类: SoulPlugin: 定义插件职责的接口, 重点方法execute() 被上层调用, skip() 方法可以使某些插件在某些","tags":["Soul"],"title":"Soul网关学习插件链与负载均衡解析","type":"blog","url":"/zh/blog/soul_source_learning_05_plugin/","wordcount":3567},{"author":"xiaoyu","categories":null,"content":" Dromara Dream Code Book Club（Dromara 2020 event introduction）  Date: Sunday, December 27, 2020  Activity background  In order to increase the enthusiasm of community participants, promote the construction of the Dromara community, exercise everyone\u0026amp;rsquo;s expressive ability and improve the core strength of technology, the community organized this event in the form of source code reading.  Activity purpose, meaning and goal  Increase motivation Improve technical strength and expand everyone\u0026amp;rsquo;s horizons Exercise language skills Promote the harmony, unity and progress of the community Make the Dromara community bigger and bigger  Activity development  The activity is divided into multiple phases. First, twelve members are selected for a 12-day source code reading, and two online sharing is carried out during the period. In order to improve everyone\u0026amp;rsquo;s consciousness, we have set up a punishment system. First hand over 500 yuan to the administrator. If homework is not submitted at 8 am the next day, 100 yuan will be deducted for sharing latecomers. Those who ask for leave in advance do not need to be punished. Each person writes to their homework submission area in text based on the content they read every day.  Activity leader and main participants Principal  Cui, Kimming, Xiaoyu  The main participants  Dromara community member  ","date":1609081200,"description":"","dir":"activities/dromara-activites-introduce/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"21669328acddbabb03e5769e3c12694bf479bfca","permalink":"/activities/dromara-activites-introduce/","publishdate":"2020-12-27T15:00:00Z","readingtime":1,"relpermalink":"/activities/dromara-activites-introduce/","summary":"Dromara Dream Code Book Club（Dromara 2020 event introduction）  Date: Sunday, December 27, 2020  Activity background  In order to increase the enthusiasm of community participants, promote the construction of the Dromara community, exercise everyone\u0026rsquo;s expressive ability and improve the core strength of technology, the community organized this event in the form of source code reading.  Activity purpose, meaning and goal  Increase motivation Improve technical strength and expand everyone\u0026rsquo;s horizons Exercise language skills Promote the harmony, unity and progress of the community Make the Dromara community bigger and bigger  Activity development  The activity is divided into multiple phases.","tags":["DreamCode","Dromara","GateWay"],"title":"Dromara Dream Code Book Club Introduction","type":"activities","url":"/activities/dromara-activites-introduce/","wordcount":203},{"author":"xiaoyu","categories":null,"content":" Dromara 梦码读书会（Dromara 2020 活动介绍）  日期：2020年12月27日，星期日  活动背景  为了提高社区参与者的积极性, 促进Dromara社区的建设, 锻炼大家的表达能力和提升技术核心力量, 社区以源码阅读形式自发行的组织本次活动  活动目的,意义和目标  提高积极性 提升技术力量,扩展大家视野 锻炼语言表达能力 促进社区的和谐、团结、共进 将Dromara社区做的越来越大  活动开展  活动分多期,先是挑选十二位组员进行为期12天的源码阅读,期间进行两次线上分享 为了提高大家的自觉性我们设立了惩罚制度,先交出500元/人给管理员,隔天的早上8点作业未提交,分享迟到者扣100元/次,提前请假者无需惩罚 每人根据每天阅读的内容,以文字形式写到各自的作业提交区  活动负责人以及主要参与者 负责人  崔,kimming,猫大人  主要参与者  Dromara 社区组员  ","date":1609081200,"description":"","dir":"activities/dromara-activites-introduce/","fuzzywordcount":400,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"a68ba03bdf8cf3038db5f04101e13d8a85be879f","permalink":"/zh/activities/dromara-activites-introduce/","publishdate":"2020-12-27T15:00:00Z","readingtime":1,"relpermalink":"/zh/activities/dromara-activites-introduce/","summary":"Dromara 梦码读书会（Dromara 2020 活动介绍） 日期：2020年12月27日，星期日 活动背景 为了提高社区参与者的积极性, 促进Dromara社区的建设","tags":["DreamCode","Dromara","GateWay"],"title":"Dromara 梦码读书会介绍","type":"activities","url":"/zh/activities/dromara-activites-introduce/","wordcount":350},{"author":"xiaoyu","categories":"hmily","content":" Thank you guys for your support all the way, and keep everyone waiting. In this version, our team refactored the entire project, reasonably divided functional modules, added configuration centers, adjusted the underlying storage structure, solved difficult bugs, and supported other new features, and absorbed more outstanding open source community members to join in.\nArchitecture Features  High availability·: Supports abnormal transaction rollback and overtime transaction recovery in distributed scenarios to prevent transaction suspension. Ease of use: Provide zero-invasive Spring-Boot, Spring-Namespace to quickly integrate with business systems. High performance: Decentralized design, fully integrated with business systems, naturally supports cluster deployment. Observability: Performance monitoring of multiple metrics by Metrics, as well as admin management UI . Multiple RPCs: support Dubbo, SpringCloud, Motan, Sofa-rpc and other well-known RPC frameworks. Log storage: Support Mysql, Oracle, Mongodb, Redis, Zookeeper, etc. Complex scenarios: Support RPC nested call transactions.  Refactoring part  Module division:\n Extract the SPI custom module and It\u0026amp;rsquo;s open-the-box.\n SPI module that defines multiple storage methods for transaction logs.\n SPI module that defines multiple serialization methods for transaction logs.\n Add configuration center, support various mainstream configuration centers (Nacos, Apollo, Zookeeper, etc.), and support dynamic refresh of configuration.\n Add metrics module to monitor various information at runtime.\n Remove the core transaction execution module.\n Extract multiple RPC support modules.\n Extract the Spring and Spring Boot support modules.\n  On the dependent package version:\n Guava upgraded to 2.9.0. Curator upgraded to 5.1.0.   Code quality:\n Strict check-style code inspection, adhering to the principle of elegance and simplicity (talk is cheap, show you code).   openness :\n The community pursues the basic principles of simplicity, happiness, and harmony.   Goal:\n Create a high-availability, high-performance, easy-to-use financial-level distributed transaction solution.   Solve bugs:  The Dubbo framework does not support the use of annotations (spring-boot-starter-dubbo). The Motan framework does not support the use of annotations. If Spring Cloud users use Feign and Hystrix to integrate Hmily, the thread switching problem occurs. In extreme cases, the transaction log serialization is abnormal. If timeout happen in try, It will cause the transaction suspension bug. When the confirm and cancel phases are abnormal, the transaction fails to rollback. In the transaction log storage, two modes of synchronous and asynchronous are supported for users to choose.  User guide For Hmily users, it only takes three steps to achieve the BASE transaction between RPC service calls\n Add the maven dependencies supported by Hmily for various RPC. Add Hmily configuration. Add @Hmily annotation to RPC interface method.  Dependency …","date":1601251200,"description":"One year later, Hmily released version 2.1.1 of the new architecture","dir":"community/hmily-2.1.1/","fuzzywordcount":1100,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"6c1b3b22d093bff01211673cf107296299f3b698","permalink":"/community/hmily-2.1.1/","publishdate":"2020-09-28T00:00:00Z","readingtime":3,"relpermalink":"/community/hmily-2.1.1/","summary":"Thank you guys for your support all the way, and keep everyone waiting. In this version, our team refactored the entire project, reasonably divided functional modules, added configuration centers, adjusted the underlying storage structure, solved difficult bugs, and supported other new features, and absorbed more outstanding open source community members to join in. Architecture Features High availability·:","tags":["hmily"],"title":"One year later, the dromara team released version 2.1.1 of the new architecture Hmily distributed transaction framework ","type":"community","url":"/community/hmily-2.1.1/","wordcount":1070},{"author":"xiaoyu","categories":"hmily","content":" 感谢朋友们一路以来的支持，让大家久等了。在这一个版本中，我们团队重构了整个项目，合理的划分功能模块，新增配置中心，调整底层存储结构，解决疑难bug，以及其他新功能的支持，也吸收了更多开源社区的优秀人才的加入。\n架构全景图 功能  高可靠性 ：支持分布式场景下，事务异常回滚，超时异常恢复，防止事务悬挂。 易用性 ：提供零侵入性式的 Spring-Boot, Spring-Namespace 快速与业务系统集成。 高性能 ：去中心化设计，与业务系统完全融合，天然支持集群部署。 可观测性 ：Metrics多项指标性能监控，以及admin管理后台UI展示。 多种RPC ：支持 Dubbo, SpringCloud,Montan ,sofa-rpc等知名RPC框架。 日志存储 ：支持 mysql, oracle, mongodb, redis, zookeeper 等方式。 复杂场景 ：支持RPC嵌套调用事务。  重构部分  在模块划分上：\n 抽离出开箱即用的SPI自定义模块。 定义事务日志多种存储方式的SPI模块。 定义事务日志多种序列化方式的SPI模块。 新增配置中心，支持各种主流的配置中心（nacos，apollo,zookeeper等），并支持配置的动态刷新。 新增metrics模块，用来监控运行时候的各种信息。 抽离出核心的事务执行模块。 抽离出多种RPC支持模块。 抽离出spring与spring boot 支持模块。  在依赖包版本上：\n guava升级到29.0 curator 升级到5.1.0  在代码质量上：\n 严格的check-style代码检查，秉承优雅，简单易懂原则（talk is cheap ,show you code）。  在开放性上：\n 社区奉行简单，快乐，和谐基本原则  在目标上：\n 打造一款高可用，高性能，简单易用金融级的分布式事务解决方案。   解决疑难bug：  dubbo框架不支持注解方式的使用（spring-boot-starter-dubbo)。 motan框架不支持注解方式的使用。 spring-cloud用户如果使用feign与hystrix整合hmily时候的线程切换问题。 极端情况下事务日志序列化异常。 try阶段超时异常，导致事务悬挂bug。 confirm与cancel阶段异常时候，事务未能正确恢复bug。 在事务日志存储上，支持同步与异步2种模式，供用户选择。  用户使用与升级指南 对于hmily用户来说，只需三个步骤，即可解决RPC服务调用之间的柔性事务\n 引用hmily对各种rpc支持的jar包。 添加hmily配置。 在rpc接口方法上添加 @Hmily注解。  依赖的变更\n用户依赖的方式没有更改，只需要将版本升级到2.1.0。下面举dubbo微服务列子\ndubbo rpc微服务\n dubbo接口服务依赖\n \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-annotation\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.1.0\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  dubbo服务提供者依赖（\u0026amp;lt;2.7）\n \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-dubbo\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.1.0\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; or \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-spring-boot-starter-dubbo\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.1.0\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   hmily配置的变更\n在新版2.1.0中，新增了hmily-config模块，支持本地与注册中心模式。用户首先需要在项目resouce文件下新建一个名称为hmily.yml的文件。默认路径为项目的 resource目录下，也可以使用 -Dhmily.conf 指定，也可以把配置放在 user.dir 目录下。优先级别 -Dhmily.conf \u0026amp;gt; user.dir \u0026amp;gt;resource。文件格式如下（一部分，以下是配置成本地模式):\n server: configMode: local appName: account-dubbo # 如果server.configMode eq local 的时候才会读取到这里的配置信息. config: appName: account-dubbo serializer: kryo contextTransmittalMode: threadLocal scheduledThreadMax: 16 scheduledRecoveryDelay: 60 scheduledCleanDelay: 60 scheduledPhyDeletedDelay: 600 scheduledInitDelay: 30 recoverDelayTime: 60 cleanDelayTime: 180 limit: 200 retryMax: 10 bufferSize: 8192 consumerThreads: 16 asyncRepository: true autoSql: true phyDeleted: true storeDays: 3 repository: mysql repository: database: driverClassName: com.mysql.jdbc.Driver url : jdbc:mysql://127.0.0.1:3306/hmily?useUnicode=true\u0026amp;amp;characterEncoding=utf8 username: root password: maxActive: 20 minIdle: 10 connectionTimeout: 30000 idleTimeout: 600000 maxLifetime: 1800000  如果你想将配置文件放在Nacos配置中心：\n 第一步：\nhmily: server: configMode: nacos appName: xxxxx # 如果server.configMode eq local 的时候才会读取到这里的配置信息. remote: nacos: server: 192.168.3.22:8848 dataId: hmily.properties group: DEFAULT_GROUP timeoutMs: 6000 fileExtension: yml passive: …","date":1601251200,"description":"时隔一年，Hmily发布全新架构的2.1.1版本","dir":"community/hmily-2.1.1/","fuzzywordcount":2400,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"d640e2f630861e00dd4dcb0871a759259789499d","permalink":"/zh/community/hmily-2.1.1/","publishdate":"2020-09-28T00:00:00Z","readingtime":5,"relpermalink":"/zh/community/hmily-2.1.1/","summary":"感谢朋友们一路以来的支持，让大家久等了。在这一个版本中，我们团队重构了整个项目，合理的划分功能模块，新增配置中心，调整底层存储结构，解决疑难","tags":["hmily"],"title":"时隔一年，dromara团队发布全新架构Hmily分布式事务的2.1.1版本","type":"community","url":"/zh/community/hmily-2.1.1/","wordcount":2338},{"author":"xiaoyu","categories":"hmily","content":" Hmily is a flexible distributed transaction architecture with high performance, high avalibility and ease to use. At present, it provides support for Dubbo, Spring-Cloud, Motan, GRPC and other RPC frameworks. In terms of ease of use, it provides zero-intrusive rapid integration of Spring-Boot and Spring-Namespace, with the goal of building a distributed transaction solution of financial level.\nAdjust Hmily architecture with more reasonable module partition Architecture:\nArchitecture adjustment:\n Pull out the core execution module, support a variety of transaction mode and mixed use of TCC mode, TAC mode. The core module removes dependencies on Spring. Define implementations of various SPI interfaces. New hmily-rpc : aggregates support for various RPC frameworks. Added hmily-spi : Hmily framework custom SPI mechanism implementation. New hmily-bom : resolves version dependency management conflicts. Added hmily-metrics: monitoring JVM, thread, transaction health, time, etc. New hmily-TCC : Core implementation of TCC pattern. Added hmily-TCC : Core implementation of TAC mode.  **SPI module partition: **\n Added hmily-repository: transaction log storage module with support (MySQL, Oracle, PostgreSQL, SQL Server, ZooKeeper, Redis, MongoDB, File). Added hmily-serializer: transaction log serializer module, support (Hessian, JDK, Kryo, Protobuf) Added hmily-config: config module to support (local mode, Zookeeper, Nacos, Apollo, Etcd). Added hmily-tac-SQLParser: SQL parsing module under TAC mode  Gather the Hmily Community Issue and solve bugs. For example, in the community, it is gather the problems reported by the community, as well as to cooperate with the community for developing new version.\n**Solve bug: **\n Dubbo framework does not support annotation (spring-boot-starter-dubbo) The Motan framework does not support the use of annotations Exceptions in Spring-Cloud users when integrating Hmily with Hystrix using Feign. Transaction log serialization exception. Timeout exception transaction suspension bug. Transaction timing recovers bugs.  **Added function: **\n build: Added travis-ci feature Transaction log support: Oracle, PostgreSQL, Sqlsever, Mongo, Zookeeper, File, Redis. Configuration module: new configuration center support for Apollo, ETCD, and Nacos Demo: Added Motan-RPC to use Hmily distributed transaction.  Community building  The community adheres to the principles of simplicity, pleasure, elegance, and harmony.\n Code guidelines: The code follows the HMILY-CHECKSTYLE standard, and there is plenty of room for flexibility. Talk is cheap,show you code. Open rule: I hope everyone here can offer good ideas, we can discuss together, review code repeatedly, think about solving bugs, grow happily.   Recently Hmily-2.1.0 of the latest architecture will be released (TCC mode only will be supported).\nConfiguration module\n Configuration dynamic refresh function, support all configuration centers.  TAC mode:\n sql-parser: accessing Apache-Shardingsphere, …","date":1599523200,"description":"Monthly report after Hmily restart","dir":"community/hmily-restart/","fuzzywordcount":500,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"897c67b206e4ae828013661149fa196aa60d0219","permalink":"/community/hmily-restart/","publishdate":"2020-09-08T00:00:00Z","readingtime":1,"relpermalink":"/community/hmily-restart/","summary":"Hmily is a flexible distributed transaction architecture with high performance, high avalibility and ease to use. At present, it provides support for Dubbo, Spring-Cloud, Motan, GRPC and other RPC frameworks. In terms of ease of use, it provides zero-intrusive rapid integration of Spring-Boot and Spring-Namespace, with the goal of building a distributed transaction solution of financial level. Adjust Hmily architecture with more reasonable module partition Architecture: Architecture adjustment: Pull out","tags":["hmily"],"title":"Hmily distributed transaction restart monthly report","type":"community","url":"/community/hmily-restart/","wordcount":494},{"author":"xiaoyu","categories":"hmily","content":" Hmily是一款高性能，高可靠，易使用的柔性分布式事务解决方案，目前提供了对dubbo，spring-cloud，motan，grpc等rpc框架的支持，在易用性上提供零侵入性式的 Spring-Boot, Spring-Namespace 快速集成，目标是打造金融级的一体系分布式事务解决方案。\n调整Hmily架构，更合理的模块划分 全景图：\n架构调整：\n 抽离核心执行模块，支持多种事务模式以及混合使用（TCC模式，TAC模式） 核心模块去除对spring的依赖 定义多种SPI接口的实现 新增 hmily-rpc : 聚合多种rpc框架的支持 新增 hmily-spi : hmily框架自定义spi机制实现 新增 hmily-bom : 解决版本依赖管理冲突的问题 新增 hmily-metrics : 监控JVM，线程，事务运行状态，耗时等信息 新增 hmily-tcc : tcc模式的核心实现 新增 hmily-tac : tac模式的核心实现  SPI模块划分：\n 新增 hmily-repository: 事务日志存储模块，支持（mysql，oracle，postgresql，sqlserver，zookeeper，redis，mongodb，file） 新增 hmily-serializer: 事务日志序列化模块, 支持 （hessian，jdk，kryo，protobuf） 新增 hmily-config：配置模块，支持（本地模式，zookeeper，nacos，apollo，etcd） 新增 hmily-tac-sqlparser ：tac模式下，sql解析模块  梳理Hmily社区issue，解决bug。 如上图：在社区中，主要是梳理和解决之前社区反馈的问题，以及社区合作进行新的开发。\n解决bug（列举几个）：\n dubbo框架不支持注解方式的使用（spring-boot-starter-dubbo） motan框架不支持注解方式的使用 spring-cloud用户如果使用feign与hystrix整合hmily时候的异常问题 事务日志序列化异常 超时异常事务悬挂bug 事务定时恢复bug  社区完成功能（列举几个）：\n build：新增travis-ci功能 事务日志支持：oracle, postgresql,sqlsever,mongo,zookeeper,file,redis 配置模块：新增apollo,etcd,nacos配置中心支持 demo：新增motan-rpc方式使用hmily分布式事务demo  社区共建 社区奉行简单，快乐，优雅，和谐基本原则。\n 代码准则：代码遵循hmily-checkstyle标准，也有很多灵活自由的空间。（talk is cheap ,show you code） 开放准则：希望在这里每个人都有好的思想和观点，大家一起讨论，反复review代码，思考解决bug，快乐成长，绝不搞一言堂。  最近 会发布最新架构的hmily-2.1.0版本（只会支持TCC模式）\n配置模块\n 配置动态刷新功能，支持所有的配置中心  TAC模式:\n SQL-parser: 正在接入apache-shardingsphere,apache-calcite SQL-revert：正在开发  大约在冬季 很高兴来了这里季节，在这个时间点，会发布hmily-2.2.0版本，这个版本将完全支持TAC,TCC模式。 TAC(transaction auto rollback) ：有了这个模式，用户再也不用担心像TCC那样去写反向的cancel方法了。大大减少了使用成本以及学习成本。 TCC: 稳定性，可靠性得到大大加强，彻底解决事务悬挂问题。\n以后的以后  更多RPC框架的支持：brpc等等。 支持 XA模式。  \u0026amp;hellip;\u0026amp;hellip;这里空起来，很多多的规划，希望你来参与建设。\n github：https://github.com/dromara/hmily gitee：https://github.com/shuaiqiyu/hmily qq群: 162614487  ","date":1599523200,"description":"​Hmily重启后月度报告","dir":"community/hmily-restart/","fuzzywordcount":1400,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"81b13b18953b5d05a7a14ddc9b79f730cb50e0ca","permalink":"/zh/community/hmily-restart/","publishdate":"2020-09-08T00:00:00Z","readingtime":3,"relpermalink":"/zh/community/hmily-restart/","summary":"Hmily是一款高性能，高可靠，易使用的柔性分布式事务解决方案，目前提供了对dubbo，spring-cloud，motan，grpc等rp","tags":["hmily"],"title":"Hmily分布式事务重启月度报告","type":"community","url":"/zh/community/hmily-restart/","wordcount":1387},{"author":"xiaoyu","categories":"Soul","content":" Let\u0026amp;rsquo;s take a look at the new features first, and then I would like to share my story.\n Completely pluggable architecture design, plug-in hot swap. Fully supports all versions of Dubbo, Alibaba-Dubbo, Apache-Dubbo. Support Dubbo generalization call, multi-parameter, complex parameter interface. Enhance the monitor plug-in and remove the Influxdb, add metrics such as memory, CPU, QPS, TPS, response delay, and support access to Prometheus. The SpringCloud plugin supports Eureka and Nacos two registration centers. The waf plugin is enhanced to support black or white lists and mixed modes. Remove the Hystrix circuit breaker to be an independent plug-in. Fix the Zookeeper data synchronization bug, and add the data synchronization method implemented by Nacos. Support multiple kinds of soul-client, such as traditional Spring and Springboot. Optimize the soul-admin user interface. Fix load balancing algorithm bug. Fix uploading large files bug. etc.  Experience the new architecture and get a high-availability and high-performance gateway in 10 minutes! Bootstrap soul-admin  Please download soul-admin.jar, and bootstrap it. Please access http://localhost:9095/index.html , and the default user name is admin, password is 123456。\n\u0026amp;gt; wget https://yu199195.github.io/jar/soul-admin.jar \u0026amp;gt; java -jar soul-admin.jar --spring.datasource.url=\u0026amp;quot;jdbc:mysql://你的url:3306/soul?useUnicode=true\u0026amp;amp;characterEncoding=utf-8\u0026amp;amp;useSSL=false\u0026amp;quot; --spring.datasource.username=\u0026#39;you username\u0026#39; --spring.datasource.password=\u0026#39;you password\u0026#39;  Build your own gateway  Firstly, you should create an empty Springboot project, please refer to soul-bootstrap. You can also visit the Spring official website :[https://spring.io/quickstart] Secondly, please add Maven dependency like follows：  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-starter-webflux\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.2.2-RELEASE\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-starter-actuator\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.2.2-RELEASE\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!--soul gateway start--\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;soul-spring-boot-starter-gateway\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.2.0\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!--soul data sync start use websocket--\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;soul-spring-boot-starter-sync-data-websocket\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.2.0\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  Please add the following configuration to your application.yaml:\nspring: main: allow-bean-definition-overriding: true management: health: defaults: enabled: false soul : sync: websocket : urls: ws://localhost:9095/websocket //Set to youe soul-admin address.   Experience plug-in hot swap under the new architecture  Q: If I want …","date":1592352000,"description":"Soul released version 2.2.0 with new architecture that makes gateways so easy. ","dir":"community/soul-2.2.0/","fuzzywordcount":1700,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"a3c966cfbcd9bfe9cc33114ec2c82d9f160db20d","permalink":"/community/soul-2.2.0/","publishdate":"2020-06-17T00:00:00Z","readingtime":4,"relpermalink":"/community/soul-2.2.0/","summary":"Let\u0026rsquo;s take a look at the new features first, and then I would like to share my story. Completely pluggable architecture design, plug-in hot swap. Fully supports all versions of Dubbo, Alibaba-Dubbo, Apache-Dubbo. Support Dubbo generalization call, multi-parameter, complex parameter interface. Enhance the monitor plug-in and remove the Influxdb, add metrics such as memory, CPU, QPS, TPS, response delay, and support access to Prometheus. The SpringCloud plugin supports Eureka and","tags":["Soul"],"title":"【Soul gateway version2.2.0 release】Make high-performance gateways so easy!","type":"community","url":"/community/soul-2.2.0/","wordcount":1648},{"author":"xiaoyu","categories":"Soul","content":" 我们还是先来看看新增功能，然后再讲故事。\n 完全的插件化架构设计，插件热插拔。 完整支持dubbo所有版本，alibaba-dubbo ，apache-dubbo。 支持dubbo泛化调用，多参数，复杂参数接口。 增强monitor插件，移除influxdb支持，新增内存，CPU，QPS，TPS，响应迟延等metrics，支持接入Prometheus。 springCloud插件支持eureka与nacos二种注册中心。 waf插件增强,支持黑白名单，以及混合模式。 抽离Hystrix熔断功能，独立成插件支持。 修护Zookeeper数据同步方式bug，新增nacos同步数据方式。 多种soul-client支持，提供传统spring，以及springboot等方式接入。 优化 soul-admin后台控制界面。 负载均衡算法bug修护。 修护大文件上传时候的bug。 …….太多了不一一列举了。  体验新架构，10分钟搞定一个高可用高性能网关。 启动 soul-admin - 下载soul-admin.jar包，并启动.\n\u0026amp;gt; wget https://yu199195.github.io/jar/soul-admin.jar \u0026amp;gt; java -jar soul-admin.jar --spring.datasource.url=\u0026amp;quot;jdbc:mysql://你的url:3306/soul?useUnicode=true\u0026amp;amp;characterEncoding=utf-8\u0026amp;amp;useSSL=false\u0026amp;quot; --spring.datasource.username=\u0026#39;you username\u0026#39; --spring.datasource.password=\u0026#39;you password\u0026#39;   访问 http://localhost:9095/index.html 默认的用户名：admin 密码:123456。  搭建属于你的网关\n 首先你新建一个空的springboot项目，可以参考 soul-bootstrap. 也可以在spring官网:[https://spring.io/quickstart] 引入如下jar包：\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-starter-webflux\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.2.2-RELEASE\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.springframework.boot\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;spring-boot-starter-actuator\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.2.2-RELEASE\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!--soul gateway start--\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;soul-spring-boot-starter-gateway\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.2.0\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!--soul data sync start use websocket--\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;soul-spring-boot-starter-sync-data-websocket\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.2.0\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  在你的 application.yaml 文件中加上如下配置：\nspring: main: allow-bean-definition-overriding: true management: health: defaults: enabled: false soul : sync: websocket : urls: ws://localhost:9095/websocket //设置成你的soul-admin地址  这样网关的环境就已经搭建完成。\n  体验新架构下的插件热插拔  问：我想使用熔断功能，应该如何做呢？\n 答：你可以在pom.xml文件 引入以下依赖,更多的还请看：https://dromara.org/zh-cn/docs/soul/soul.html\n\u0026amp;lt;!-- soul hystrix plugin start--\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;soul-spring-boot-starter-plugin-hystrix\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.2.0\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!-- soul hystrix plugin end--\u0026amp;gt;  问:我怎么接入dubbo服务呢？\n 答： 1）如果你使用的是alibaba-dubbo，那么你应该引入如下：\n\u0026amp;lt;!--soul alibaba dubbo plugin start--\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;soul-spring-boot-starter-plugin-alibaba-dubbo\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.2.0\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;!-- soul alibaba dubbo plugin end--\u0026amp;gt;  2） 如果你使用apache-dubbo，那么你应该引入如下：\n\u0026amp;lt;!--soul apache dubbo plugin start--\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; …","date":1592352000,"description":"Soul发布全新的架构2.2.0版本 让网关变得如此简单","dir":"community/soul-2.2.0/","fuzzywordcount":3400,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"f996e5c754a818485b528f84778ebb9fa9589e8f","permalink":"/zh/community/soul-2.2.0/","publishdate":"2020-06-17T00:00:00Z","readingtime":7,"relpermalink":"/zh/community/soul-2.2.0/","summary":"我们还是先来看看新增功能，然后再讲故事。 完全的插件化架构设计，插件热插拔。 完整支持dubbo所有版本，alibaba-dubbo ，apach","tags":["Soul"],"title":"【Soul网关发布2.2.0】让高性能网关变得如此简单！","type":"community","url":"/zh/community/soul-2.2.0/","wordcount":3306},{"author":"xiaoyu","categories":"Soul","content":" It has been a year since I open sourced Soul gateway in October last year, and received many suggestions from you guys in community. It has provided very rich functions after optimization, many of functions are highly cusmized, visualized, and highly extensible, now let\u0026amp;rsquo;s make a summary.\nPlugin  Provides various plug-ins, such as signature, monitoring, rate limiting, circuit breaker, Http proxy, Dubbo proxy, Websocket, etc.\n Support users to quickly develop plug-ins.\n All plug-in data and switch state support dynamic changes.\n  Data Synchronization  Provides three different data synchronization strategies: Http long polling, Zookeeper, and Websocket, allowing users to choose freely. It is recommended to use Websocket, which is the lightest and more efficient in a cluster environment.  For Users  First of all, we provide a client package that is convenient for users to access. Users can quickly register their projects to the Soul gateway. By default, users don\u0026amp;rsquo;t need to care about Soul Gateway\u0026amp;rsquo;s selectors, rules and other configurations. The user\u0026amp;rsquo;s previous interface is completely zero intrusion, It is only need to change to the domain name of the Soul gateway. For Dubbo users, the conversion from Http protocol to Dubbo protocol is almost completed by Http. Soul gataway uses the Http protocol, so it is destined to be cross-language, It is feasible for .Net programmers, PHP programmers to interact with Java program.  For example, if you have a Dubbo interface, the parameter definition is a java bean,\npublic void insert(final DubboTest dubboTest) { } public class DubboTest implements Serializable { private String id; private String name; }  If you use the Soul gateway to call this method, your Http parameter is to pass a json string in the body, which is no different from a normal http call.\n{\u0026amp;quot;id\u0026amp;quot;:\u0026amp;quot;123\u0026amp;quot;,\u0026amp;quot;name\u0026amp;quot;:\u0026amp;quot;xiaoyu\u0026amp;quot;}  For Developers  With more and more users, the situation of each company is different. Soul gateway in 2.1.X version are more extensible, making it convenient for developers . For example, there are may things could be extensible, such as Plug-ins, Filters, Dubbo parameter parser, iphost parser, return results, etc. We know that the default return result of the soul gateway is:  {\u0026amp;quot;code\u0026amp;quot;:200, \u0026amp;quot;message \u0026amp;quot;: \u0026amp;quot;成功!\u0026amp;quot;,\u0026amp;quot;data\u0026amp;quot; :\u0026amp;quot;helloWorld!\u0026amp;quot;}  However, when using the Soul gateway to call your business system, your business system may define the result that is not confirm the above structure. Maybe your field is called msg, which will cause a different structure and bring confusion to the front-end processing. We have noticed this thing: https://github.com/Dromara/soul/issues/109, now it has been optimized, users can customize the return results to define, the specifics depend on the Soul document.\nWhat scenarios of Soul gateway are suitable, and what should you pay attention to? First of all, I think we should follow pragmatism, …","date":1576108800,"description":"How convenient is the 2.1.X version of Soul Gateway?","dir":"community/soul-2.1.x/","fuzzywordcount":1000,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"bbb59a239d65554ff0eb71d47e85dc82220725e3","permalink":"/community/soul-2.1.x/","publishdate":"2019-12-12T00:00:00Z","readingtime":2,"relpermalink":"/community/soul-2.1.x/","summary":"It has been a year since I open sourced Soul gateway in October last year, and received many suggestions from you guys in community. It has provided very rich functions after optimization, many of functions are highly cusmized, visualized, and highly extensible, now let\u0026rsquo;s make a summary. Plugin Provides various plug-ins, such as signature, monitoring, rate limiting, circuit breaker, Http proxy, Dubbo proxy, Websocket, etc. Support users to quickly develop","tags":["Soul"],"title":"How convenient is the 2.1.X version of Soul Gateway?","type":"community","url":"/community/soul-2.1.x/","wordcount":966},{"author":"xiaoyu","categories":"Soul","content":" Soul 网关自从去年10月我开源以来，经历了一年的事情，接受到了来自社区很多朋友的建议，并进行持续不断的优化，已经提供了非常丰富的功能，很多功能都是高度自定义，可视化，高度可扩展的，现在做一个归纳总结。\n插件\n- 提供了系统自带的各种插件，比如签名，监控，限流，熔断，http代理，dubbo代理，websocket等等。\n 支持用户快速的进行插件的自定义开发。\n 插件的所有数据，开关状态支持动态变更。\n  数据同步 - 提供了 http长轮询，zookeeper，websocket 三种不同的数据同步策略，让用户自由选择。 - 推荐用户使用websocket方式，最轻量，在集群环境下，效率更高。\n对于用户 - 首先我们提供了便于用户接入的 client包，用户可以把快速的把自己的项目接入到soul 网关。 - 默认情况下，用户完全不用关心 soul网关的选择器，规则等配置。 - 用户之前的接口完全是零侵入，不需要任何更改，只是需要把访问域名改成网关的域名即可。 - 比如 dubbo用户，几乎就是http的方式完成了 http协议到 dubbo协议的互相转换。 - soul 使用的是http协议，那么注定它就是跨语言的，net程序员，php程序员等等，要和java进行数据交互，那么就大大的可行了。\n举个列子 ，比如你有一个 dubbo接口 参数定义是一个java bean,\npublic void insert(final DubboTest dubboTest) { } public class DubboTest implements Serializable { private String id; private String name; }  如果你使用 soul网关要发起对它的调用，你的http传参数 就是在 body 里面 传一个json字符串 ，和普通的http调用无差别。\n{\u0026amp;quot;id\u0026amp;quot;:\u0026amp;quot;123\u0026amp;quot;,\u0026amp;quot;name\u0026amp;quot;:\u0026amp;quot;xiaoyu\u0026amp;quot;}  对于开发者(程序员)\n 随着使用者越来越多，每个公司使用情况又不一样,soul 网关在2.1.X版本，处处留出来更多的高度自定义扩展性，让开发者，更加方便或者有信心融入进来。 比如，自定义插件，过滤器，dubbo参数解析器，iphost解析器，返回结果等等。。这里我着重说一下自定义返回结果。 我们知道，soul 网关默认的返回结果是：\n{\u0026amp;quot;code\u0026amp;quot;:200, \u0026amp;quot;message \u0026amp;quot;: \u0026amp;quot;成功!\u0026amp;quot;,\u0026amp;quot;data\u0026amp;quot; :\u0026amp;quot;helloWorld!\u0026amp;quot;}   但是，在运用 soul 网关对你的业务系统进行调用的时候，你的业务系统可能定义的结果并不是上述结构，可能你的 字段叫 msg,这样就会造成结构不一样，给前端处理带来了困扰。我们注意到了这个事情 ：https://github.com/Dromara/soul/issues/109 , 现在已经优化，用户可以定制化的来定义返回结果,具体的要看 soul 文档。\n说了这么多，吹了这么多牛逼，那么我们来看看 soul网关到底可以在什么场景下能发挥大作用。\n后台管理web\n 首先随便微服务的流行，我们的后台都划分成很多的微服务，我相信你们每个公司都有一个后台管理系统吧，如果我没猜错的话，他们大体上是如下架构。   很简单对吧，就是有个运营管理平台的web项目，去调用每个微服务，来进行后台的查看等等。随着你们业务需要的加大，可能这里需要调用的微服务越来越多，你的 controller越来越多，现在比如你修改了 商品模块的 接口，你要发版会造成所有其他的模块也操作不了（就是你发版影响了其他模块的使用，别杠这里只是比方，不要整蓝绿发版啥的，明白意思吧）。 如果有运营人员在操作其他模块，会不会吐槽你？  假如你是公司架构师，我说的是假如，那么你要怎么解决这个问题呢？当然，我们把这样一个大的web系统，拆分成很多小web系统，单独的进行发布，但是这样会引入一个问题，怎么统一登陆，鉴权？（很多后台管理系统还有权限的划分） ，这个时候，soul 网关 就能发挥重要的作用了，下面我只是列举了一下简单的调用图。\n这样多方便，集成了网关，每个微服务注册到网关，网关根据路由规则来进行调用。自动发现服务，连运维配置 nginx的工作都省了，把运维的工资给你，美滋滋。\n公司入口网关（开放平台）  如果一个公司要做开放平台或者入口网关，鉴权，限流，监控，熔断肯定少不了。\n 如果贵公司是dubbo体系，开发人员写了dubbo服务后，还要傻乎乎的新增一个web项目，来提供接口给别人调用吗？\n 如果一个接口被攻击，你怎么处理呢？如果被大流量攻击，你怎么处理呢？\n 不巧，soul 在设计之初就是来干这种事情的，我们来看一下整体的架构图。\n  零零总总还有很多其他功能  比如支持 websocket 代理。 比如支持文件上传下载。\n 比如你可以自定义的开发你的插件啊。\n  最后最后  github地址 ：https://github.com/Dromara/soul\n gitee地址 ：https://gitee.com/dromara/soul\n 文档：https://dromara.org/zh-cn/docs/soul/soul.html\n 欢迎大家关注，如果贵公司有使用到，或者需要学习交流，或者提供代码参与开发的朋友也可以加群来进行讨论 ，qq群（429951241）\n 最后 3.0 已经在进行开源了，3.0是经历过2年双11大并发场景验证过的，现在一步一步将它开源出来，希望给大家带来帮助.\n  ","date":1576108800,"description":"​Soul网关发布2.1.X之后，它到底有多方便？","dir":"community/soul-2.1.x/","fuzzywordcount":2000,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"63553c4bfe2f18da1e6e15f45c9e1ffbd3845ea5","permalink":"/zh/community/soul-2.1.x/","publishdate":"2019-12-12T00:00:00Z","readingtime":4,"relpermalink":"/zh/community/soul-2.1.x/","summary":"Soul 网关自从去年10月我开源以来，经历了一年的事情，接受到了来自社区很多朋友的建议，并进行持续不断的优化，已经提供了非常丰富的功能，很多功能都","tags":["Soul"],"title":"Soul网关发布的2.1.X版本，到底有多方便？","type":"community","url":"/zh/community/soul-2.1.x/","wordcount":1992},{"author":"xiaoyu","categories":"Soul","content":" Soul Gateway released version 1.0.4-RELEASE  Fix the bug that appeared in the Soul-admin of version 1.0.3. The serialization method supports custom extensions. The default serialization method has been changed from Kroy to Java serialization method. Dubbo support.  Changes Dubbo usage  In the previous version (1.0.2 or 1.0.3), the parameters of Dubbo are passed through the header, and in the 1.0.4 version it is passed through the body.\n Relevant document information has been updated.\n  Recommendations on using version 1.0.4  Version 1.0.4 supports user-defined plug-in, and supports regular expression matching.\n The change of Dubbo parameter transfer and it would be more friendly to use.\n  If you used version 1.0.2 before and want to update to version 1.0.4.  Add role field in the plug-in table.\n Restart the Soul-admin of version 1.0.4.\n Perform synchronization of all plug-ins (because of serialization changes)\n Start the soul-web service of version 1.0.4.\n  For more information  QQ group: 429951241\n Official website document: https://dromara.org/website/zh-cn/docs/soul/soul.html\n Github: https://github.com/Dromara/soul\n Gitee: https://gitee.com/dromara/soul\n  ","date":1554768000,"description":"Soul Gateway released version 1.0.4-RELEASE","dir":"community/soul-1.0.4/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"7949c80c769c885bd142edd4105de9f81b198c3f","permalink":"/community/soul-1.0.4/","publishdate":"2019-04-09T00:00:00Z","readingtime":1,"relpermalink":"/community/soul-1.0.4/","summary":"Soul Gateway released version 1.0.4-RELEASE  Fix the bug that appeared in the Soul-admin of version 1.0.3. The serialization method supports custom extensions. The default serialization method has been changed from Kroy to Java serialization method. Dubbo support.  Changes Dubbo usage  In the previous version (1.0.2 or 1.0.3), the parameters of Dubbo are passed through the header, and in the 1.0.4 version it is passed through the body.","tags":["Soul"],"title":"Soul Gateway released version 1.0.4-RELEASE","type":"community","url":"/community/soul-1.0.4/","wordcount":158},{"author":"xiaoyu","categories":"Soul","content":" Soul网关发布1.0.4-RELEASE版本  修复在1.0.3版本的后台管理中，出现的bug。 配置信息序列化方式支持自定义扩展。默认的序列化方式由kroy 改为了java序列化方式。 dubbo框架支持的更改。  对dubbo用户使用的更改。  在以前的版本中（1.0.2 or 1.0.3），dubbo的参数是通过header头上传递，在1.0.4版本中是通过body传递\n 更新了相关的文档信息。\n  关于使用1.0.4版本的建议。  1.0.4 版本支持用户自定义插件开发，支持正则表达式的匹配。\n dubbo参数传递的更改，我觉得这样会更加友好。\n  如果您之前使用的1.0.2版本，想要更新到1.0.4版本。  在插件表新增role字段。\n 重新启动1.0.4版本的管理后台。\n 执行同步所有插件（因为序列化方式的更改）\n 启动1.0.4版本的soul-web服务。\n  遇到问题？  添加qq群（429951241）\n 官网文档：https://dromara.org/website/zh-cn/docs/soul/soul.html\n github地址: https://github.com/Dromara/soul\n gitee地址： https://gitee.com/dromara/soul\n  ","date":1554768000,"description":"Soul网关发布1.0.4-RELEASE版本","dir":"community/soul-1.0.4/","fuzzywordcount":500,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"81e460f518d6e8f1651b4de4816341372eaeb619","permalink":"/zh/community/soul-1.0.4/","publishdate":"2019-04-09T00:00:00Z","readingtime":1,"relpermalink":"/zh/community/soul-1.0.4/","summary":"Soul网关发布1.0.4-RELEASE版本 修复在1.0.3版本的后台管理中，出现的bug。 配置信息序列化方式支持自定义扩展。默认的序列化","tags":["Soul"],"title":"Soul网关发布1.0.4-RELEASE版本","type":"community","url":"/zh/community/soul-1.0.4/","wordcount":452},{"author":"xiaoyu","categories":"hmily","content":" Hmily released 2.0.2-Release  Resolved the issue of SpringCloud using Hystrix to configure thread pool. New issue with SpringCloud embedded transaction calls.\n Added Hmily load balancing strategy.\n Other bug fixes and code optimizations.\n Remove unnecessary third-party JAR packages.\n Introduction of zero intrusion mode.\n  Hmily\u0026amp;rsquo;s support for the popular RPC framework and Spring.  Dubbo 2.7.0 for all versions below. SpringCloud Dalston and above, including support for Finchley and Greenwich\n All versions of Motan.\n All Spring versions up to 3.0.\n  Hmily has a load-balancing policy for user RPC clusters in version 2.0.2.  Hmily provides its own implementation of the load-balancing strategy, only for interfaces with @Hmily added  Dubbo cluster configuration with loadbalance=\u0026amp;ldquo;hmily\u0026amp;rdquo;\n\u0026amp;lt;dubbo:reference timeout=\u0026amp;quot;50000\u0026amp;quot; interface=\u0026amp;quot;org.dromara.hmily.demo.dubbo.account.api.service.AccountService\u0026amp;quot; id=\u0026amp;quot;accountService\u0026amp;quot; retries=\u0026amp;quot;0\u0026amp;quot; check=\u0026amp;quot;false\u0026amp;quot; actives=\u0026amp;quot;20\u0026amp;quot; loadbalance=\u0026amp;quot;hmily\u0026amp;quot;/\u0026amp;gt;  Spring Cloud added to the caller\u0026amp;rsquo;s YML configuration file:\nhmily ： ribbon: rule enabled : true  Documents  Official document: https://dromara.org/website/zh-cn/docs/hmily/index.html\n Github: https://github.com/yu199195/hmily\n Gitee: https://gitee.com/dromara/hmily\n  Welcome to Star Fork, provide excellent code and suggestions.\n","date":1554422400,"description":"Hmily released 2.0.2-Release","dir":"community/hmily-2.0.2/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"63b9799a6f8166c12b76bce655175f69a925057b","permalink":"/community/hmily-2.0.2/","publishdate":"2019-04-05T00:00:00Z","readingtime":1,"relpermalink":"/community/hmily-2.0.2/","summary":"Hmily released 2.0.2-Release  Resolved the issue of SpringCloud using Hystrix to configure thread pool. New issue with SpringCloud embedded transaction calls.\n Added Hmily load balancing strategy.\n Other bug fixes and code optimizations.\n Remove unnecessary third-party JAR packages.\n Introduction of zero intrusion mode.\n  Hmily\u0026rsquo;s support for the popular RPC framework and Spring.  Dubbo 2.7.0 for all versions below. SpringCloud Dalston and above, including support for Finchley and Greenwich","tags":["hmily"],"title":"Hmily released 2.0.2-Release","type":"community","url":"/community/hmily-2.0.2/","wordcount":150},{"author":"xiaoyu","categories":"hmily","content":" Hmily 发布2.0.2-RELEASE 版本  解决SpringCloud 使用hystrix 配置线程池策略的问题。\n 新增对springcloud 内嵌事务调用的问题。\n 新增Hmily负载均衡策略。\n 其他bug的修护，与代码的优化。\n 去除不必须的第三方jar包。\n 零侵入方式的引入。\n  Hmily对现在流行RPC框架以及Spring的支持情况。  dubbo 2.7.0以下所有版本。\n Springcloud Dalston以上版本，包括支持现在的Finchley 与 Greenwich\n Motan 所有版本。\n 3.0以上所有Spring版本。\n  Hmily 在2.0.2版本对使用者RPC集群时候负载均衡策略。  hmily提供了自己实现的负载均衡策略，只是针对加了@Hmily的接口  dubbo 集群配置,配置负载方式为：loadbalance=\u0026amp;ldquo;hmily\u0026amp;rdquo;\n\u0026amp;lt;dubbo:reference timeout=\u0026amp;quot;50000\u0026amp;quot; interface=\u0026amp;quot;org.dromara.hmily.demo.dubbo.account.api.service.AccountService\u0026amp;quot; id=\u0026amp;quot;accountService\u0026amp;quot; retries=\u0026amp;quot;0\u0026amp;quot; check=\u0026amp;quot;false\u0026amp;quot; actives=\u0026amp;quot;20\u0026amp;quot; loadbalance=\u0026amp;quot;hmily\u0026amp;quot;/\u0026amp;gt;  Springcloud 在调用方的yml配置文件中新增：\nhmily ： ribbon: rule enabled : true  Hmily的具体使用文档：  官网文档 ：https://dromara.org/website/zh-cn/docs/hmily/index.html\n github地址: https://github.com/yu199195/hmily\n gitee地址： https://gitee.com/dromara/hmily\n 欢迎大家star fork ，提供优秀的代码与建议。\n  ","date":1554422400,"description":"Hmily发布2.0.2-RELEASE版本","dir":"community/hmily-2.0.2/","fuzzywordcount":500,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"16c3ba810bac7a102748180493562f2e1ce13371","permalink":"/zh/community/hmily-2.0.2/","publishdate":"2019-04-05T00:00:00Z","readingtime":1,"relpermalink":"/zh/community/hmily-2.0.2/","summary":"Hmily 发布2.0.2-RELEASE 版本 解决SpringCloud 使用hystrix 配置线程池策略的问题。 新增对springcloud 内嵌事务调","tags":["hmily"],"title":"Hmily发布2.0.2-RELEASE版本","type":"community","url":"/zh/community/hmily-2.0.2/","wordcount":474},{"author":"xiaoyu","categories":"hmily","content":" Hmily高并发事务处理 开始先打个小小的广告 Hmily在参开源中国年度受欢迎投票 https://www.oschina.net/project/top_cn_2018?origin=zhzd 点击链接，搜索Hmily帮忙投下票,在第11横排第二个，感谢大家！ 也欢迎大家关注，或者提交pr，让Hmily变的更好，更完美。 gitHub: [https://github.com/yu199195/hmily] gitee: [https://gitee.com/dromara/hmily]\n接下来回答一下 社区的一些问题，和大家一些疑惑的地方！\n1. Hmily的性能问题？ 答：Hmily是采用AOP切面的方式与你的RPC方法绑定，无非就是在你RPC调用的时候，保存了日志（通过异步disruptor），传递了一些参数。现在confrim，cancel也都为异步的调用，因此其性能与你的rpc性能一样。记住Hmily不生产事务，Hmily只是分布式事务的搬运工。之前Hmily在AOP切面加了一把锁，导致了性能下降，也就是Spring cloud 中国社区做的那篇文章。现在已经全部修复，并且全部异步化。其实那么测试时不合理的，因为是压测的demo，都是默认的配置。下文我会讲解，怎么样才能提高Hmiy性能。\n2. 关于RPC调用超时Hmily是怎么处理的？ 答： 我们支持在分布式环境中调用一个RPC方法，如果超时了。比如dubbo设置的超时时间是100ms,可能你的方法用了140ms,但是你的方法是执行成功了的。但是对调用方来说，你是失败的。这个时候需要回滚。所以Hmily的做法是。调用者认为你是失败的，不会将加入的回滚调用链条中。因此超时的rpc接口方，进行自身的回滚。会有一个定时任务来进行回滚，因为日志状态是try阶段，会调用cancel方法进行回滚，从而到达最终一致性！\n3.Hmily支持集群部署的问题？以及集群环境中，定时任务日志恢复的问题？ 答：Hmily是和你的应用AOP切面绑定在一起的，天然支持集群。集群环境中定时恢复问题，其实几乎没有，除非你的集群同时一下挂掉，才会有这个问题。当你集群同时挂掉，在恢复的时候，日志会有一个version字段，更新成功的，才会去进行恢复。\n4.Hmily是异步保存日志的，那么很极端情况下（代码刚好执行到这一行,然后jvm退出，断电啦什么的），日志还没保存那怎么处理呢？ 答:这种想法的，肯定是没看源码，或者是看了没怎么看懂。在AOP切面中，会先进行日志的异步保存，注意状态是PRE_TRY。在try执行完成后，更新为try。就算存在可能你说的什么断电，什么你在打断电调试，然后kill服务之类的。（Mysql我都可以让他事务失效，你信不信？）我只能说，不要花大力气去解决那些偶然的事情，最好的解决办法是不解决它。 Hmily针对高并发时候的参数配置调优。 可能这部门内容针对熟悉Hmily的人来说，不熟悉的也没关系。直接上github上看相关文档就好。 hmily支持Spring bean xml 方式的配置，同时也支持spring boot start yml方式的配置。\n\u0026amp;lt;bean id=\u0026amp;quot;hmilyTransactionBootstrap\u0026amp;quot; class=\u0026amp;quot;com.hmily.tcc.core.bootstrap.HmilyTransactionBootstrap\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;serializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;recoverDelayTime\u0026amp;quot; value=\u0026amp;quot;120\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;retryMax\u0026amp;quot; value=\u0026amp;quot;3\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;loadFactor\u0026amp;quot; value=\u0026amp;quot;2\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;scheduledDelay\u0026amp;quot; value=\u0026amp;quot;120\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;scheduledThreadMax\u0026amp;quot; value=\u0026amp;quot;4\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;bufferSize\u0026amp;quot; value=\u0026amp;quot;4096\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;consumerThreads\u0026amp;quot; value=\u0026amp;quot;32\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;started\u0026amp;quot; value=\u0026amp;quot;false\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;asyncThreads\u0026amp;quot; value=\u0026amp;quot;32\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;repositorySupport\u0026amp;quot; value=\u0026amp;quot;db\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;tccDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;bean class=\u0026amp;quot;com.hmily.tcc.common.config.TccDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;url\u0026amp;quot; value=\u0026amp;quot;jdbc:mysql://192.168.1.98:3306/tcc?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;driverClassName\u0026amp;quot; value=\u0026amp;quot;com.mysql.jdbc.Driver\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;username\u0026amp;quot; value=\u0026amp;quot;root\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;password\u0026amp;quot; value=\u0026amp;quot;123456\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt; \u0026amp;lt;/property\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt;   serializer :这里我推荐使用是kroy。当然hmily也支持hessian,protostuff,jdk。在我们测试中表现为: kroy\u0026amp;gt;hessian\u0026amp;gt;protostuff\u0026amp;gt;jdk\n recoverDelayTime :定时任务延迟时间（单位是秒，默认120。这个参数只是要大于你的rpc调用的超时时间设置。\n retryMax : 最大重复次数，默认3次。当你的服务down机，定时任务会执行retryMax次数去执行你的cancel还是confrim。 …","date":1542153600,"description":"Hmily Configuration Optimization For High Concurrent Transactions","dir":"blog/hmily_current/","fuzzywordcount":1900,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"fb9a120decfa23beef7c28949e3a54748f40bbab","permalink":"/blog/hmily_current/","publishdate":"2018-11-14T00:00:00Z","readingtime":4,"relpermalink":"/blog/hmily_current/","summary":"Hmily高并发事务处理 开始先打个小小的广告 Hmily在参开源中国年度受欢迎投票 https://www.oschina.net/project/top_cn_2018?origin=zhzd 点击链接，搜索Hmily帮忙投下票,在第11横排第二个，感","tags":["hmily"],"title":"Hmily: Easy Handle Highly Concurrent Distributed Transactions","type":"blog","url":"/blog/hmily_current/","wordcount":1864},{"author":"xiaoyu","categories":"hmily","content":" Hmily高并发事务处理 开始先打个小小的广告 Hmily在参开源中国年度受欢迎投票 https://www.oschina.net/project/top_cn_2018?origin=zhzd 点击链接，搜索Hmily帮忙投下票,在第11横排第二个，感谢大家！ 也欢迎大家关注，或者提交pr，让Hmily变的更好，更完美。 gitHub: [https://github.com/yu199195/hmily] gitee: [https://gitee.com/dromara/hmily]\n接下来回答一下 社区的一些问题，和大家一些疑惑的地方！\n1. Hmily的性能问题？ 答：Hmily是采用AOP切面的方式与你的RPC方法绑定，无非就是在你RPC调用的时候，保存了日志（通过异步disruptor），传递了一些参数。现在confrim，cancel也都为异步的调用，因此其性能与你的rpc性能一样。记住Hmily不生产事务，Hmily只是分布式事务的搬运工。之前Hmily在AOP切面加了一把锁，导致了性能下降，也就是Spring cloud 中国社区做的那篇文章。现在已经全部修复，并且全部异步化。其实那么测试时不合理的，因为是压测的demo，都是默认的配置。下文我会讲解，怎么样才能提高Hmiy性能。\n2. 关于RPC调用超时Hmily是怎么处理的？ 答： 我们支持在分布式环境中调用一个RPC方法，如果超时了。比如dubbo设置的超时时间是100ms,可能你的方法用了140ms,但是你的方法是执行成功了的。但是对调用方来说，你是失败的。这个时候需要回滚。所以Hmily的做法是。调用者认为你是失败的，不会将加入的回滚调用链条中。因此超时的rpc接口方，进行自身的回滚。会有一个定时任务来进行回滚，因为日志状态是try阶段，会调用cancel方法进行回滚，从而到达最终一致性！\n3.Hmily支持集群部署的问题？以及集群环境中，定时任务日志恢复的问题？ 答：Hmily是和你的应用AOP切面绑定在一起的，天然支持集群。集群环境中定时恢复问题，其实几乎没有，除非你的集群同时一下挂掉，才会有这个问题。当你集群同时挂掉，在恢复的时候，日志会有一个version字段，更新成功的，才会去进行恢复。\n4.Hmily是异步保存日志的，那么很极端情况下（代码刚好执行到这一行,然后jvm退出，断电啦什么的），日志还没保存那怎么处理呢？ 答:这种想法的，肯定是没看源码，或者是看了没怎么看懂。在AOP切面中，会先进行日志的异步保存，注意状态是PRE_TRY。在try执行完成后，更新为try。就算存在可能你说的什么断电，什么你在打断电调试，然后kill服务之类的。（Mysql我都可以让他事务失效，你信不信？）我只能说，不要花大力气去解决那些偶然的事情，最好的解决办法是不解决它。 Hmily针对高并发时候的参数配置调优。 可能这部门内容针对熟悉Hmily的人来说，不熟悉的也没关系。直接上github上看相关文档就好。 hmily支持Spring bean xml 方式的配置，同时也支持spring boot start yml方式的配置。\n\u0026amp;lt;bean id=\u0026amp;quot;hmilyTransactionBootstrap\u0026amp;quot; class=\u0026amp;quot;com.hmily.tcc.core.bootstrap.HmilyTransactionBootstrap\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;serializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;recoverDelayTime\u0026amp;quot; value=\u0026amp;quot;120\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;retryMax\u0026amp;quot; value=\u0026amp;quot;3\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;loadFactor\u0026amp;quot; value=\u0026amp;quot;2\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;scheduledDelay\u0026amp;quot; value=\u0026amp;quot;120\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;scheduledThreadMax\u0026amp;quot; value=\u0026amp;quot;4\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;bufferSize\u0026amp;quot; value=\u0026amp;quot;4096\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;consumerThreads\u0026amp;quot; value=\u0026amp;quot;32\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;started\u0026amp;quot; value=\u0026amp;quot;false\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;asyncThreads\u0026amp;quot; value=\u0026amp;quot;32\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;repositorySupport\u0026amp;quot; value=\u0026amp;quot;db\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;tccDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;bean class=\u0026amp;quot;com.hmily.tcc.common.config.TccDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;url\u0026amp;quot; value=\u0026amp;quot;jdbc:mysql://192.168.1.98:3306/tcc?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;driverClassName\u0026amp;quot; value=\u0026amp;quot;com.mysql.jdbc.Driver\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;username\u0026amp;quot; value=\u0026amp;quot;root\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;password\u0026amp;quot; value=\u0026amp;quot;123456\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt; \u0026amp;lt;/property\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt;   serializer :这里我推荐使用是kroy。当然hmily也支持hessian,protostuff,jdk。在我们测试中表现为: kroy\u0026amp;gt;hessian\u0026amp;gt;protostuff\u0026amp;gt;jdk\n recoverDelayTime :定时任务延迟时间（单位是秒，默认120。这个参数只是要大于你的rpc调用的超时时间设置。\n retryMax : 最大重复次数，默认3次。当你的服务down机，定时任务会执行retryMax次数去执行你的cancel还是confrim。 …","date":1542153600,"description":"Hmily针对高并发事务的配置优化","dir":"blog/hmily_current/","fuzzywordcount":1900,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"6cc88ad873f48c3f5810fc5a3e3bcb9edd25c2d2","permalink":"/zh/blog/hmily_current/","publishdate":"2018-11-14T00:00:00Z","readingtime":4,"relpermalink":"/zh/blog/hmily_current/","summary":"Hmily高并发事务处理 开始先打个小小的广告 Hmily在参开源中国年度受欢迎投票 https://www.oschina.net/project/top_cn_2018?origin=zhzd 点击链接，搜索Hmily帮忙投下票,在第11横排第二个，感","tags":["hmily"],"title":"Hmily: 轻松搞定高并发分布式事务","type":"blog","url":"/zh/blog/hmily_current/","wordcount":1864},{"author":"xiaoyu","categories":"hmily","content":" Hmily框架特性[https://github.com/yu199195/hmily]  无缝集成Spring,Spring boot start。\n 无缝集成Dubbo,SpringCloud,Motan等rpc框架。\n 多种事务日志的存储方式（redis，mongdb,mysql等）。\n 多种不同日志序列化方式（Kryo,protostuff,hession）。\n 事务自动恢复。\n 支持内嵌事务的依赖传递。\n 代码零侵入,配置简单灵活。   Hmily为什么这么高性能？ 1.采用disruptor进行事务日志的异步读写（disruptor是一个无锁，无GC的并发编程框架） package com.hmily.tcc.core.disruptor.publisher; import com.hmily.tcc.common.bean.entity.TccTransaction; import com.hmily.tcc.common.enums.EventTypeEnum; import com.hmily.tcc.core.concurrent.threadpool.HmilyThreadFactory; import com.hmily.tcc.core.coordinator.CoordinatorService; import com.hmily.tcc.core.disruptor.event.HmilyTransactionEvent; import com.hmily.tcc.core.disruptor.factory.HmilyTransactionEventFactory; import com.hmily.tcc.core.disruptor.handler.HmilyConsumerDataHandler; import com.hmily.tcc.core.disruptor.translator.HmilyTransactionEventTranslator; import com.lmax.disruptor.BlockingWaitStrategy; import com.lmax.disruptor.IgnoreExceptionHandler; import com.lmax.disruptor.RingBuffer; import com.lmax.disruptor.dsl.Disruptor; import com.lmax.disruptor.dsl.ProducerType; import org.springframework.beans.factory.DisposableBean; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Component; import java.util.concurrent.Executor; import java.util.concurrent.LinkedBlockingQueue; import java.util.concurrent.ThreadPoolExecutor; import java.util.concurrent.TimeUnit; import java.util.concurrent.atomic.AtomicInteger; /** * event publisher. * * @author xiaoyu(Myth) */ @Component public class HmilyTransactionEventPublisher implements DisposableBean { private Disruptor\u0026amp;lt;HmilyTransactionEvent\u0026amp;gt; disruptor; private final CoordinatorService coordinatorService; @Autowired public HmilyTransactionEventPublisher(final CoordinatorService coordinatorService) { this.coordinatorService = coordinatorService; } /** * disruptor start. * * @param bufferSize this is disruptor buffer size. * @param threadSize this is disruptor consumer thread size. */ public void start(final int bufferSize, final int threadSize) { disruptor = new Disruptor\u0026amp;lt;\u0026amp;gt;(new HmilyTransactionEventFactory(), bufferSize, r -\u0026amp;gt; { AtomicInteger index = new AtomicInteger(1); return new Thread(null, r, \u0026amp;quot;disruptor-thread-\u0026amp;quot; + index.getAndIncrement()); }, ProducerType.MULTI, new BlockingWaitStrategy()); final Executor executor = new ThreadPoolExecutor(threadSize, threadSize, 0, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026amp;lt;\u0026amp;gt;(), HmilyThreadFactory.create(\u0026amp;quot;hmily-log-disruptor\u0026amp;quot;, false), new ThreadPoolExecutor.AbortPolicy()); HmilyConsumerDataHandler[] consumers = new HmilyConsumerDataHandler[threadSize]; for (int i = 0; i \u0026amp;lt; threadSize; i++) { consumers[i] = new HmilyConsumerDataHandler(executor, coordinatorService); } disruptor.handleEventsWithWorkerPool(consumers); disruptor.setDefaultExceptionHandler(new IgnoreExceptionHandler()); disruptor.start(); } /** * publish disruptor event. * * @param tccTransaction {@linkplain …","date":1537833600,"description":"High-Performance Asynchronous Distributed Transaction TCC Framework","dir":"blog/hmily_introduction/","fuzzywordcount":2700,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"b7b689726bd3d6d352d1283a04d1013b7cf80530","permalink":"/blog/hmily_introduction/","publishdate":"2018-09-25T00:00:00Z","readingtime":6,"relpermalink":"/blog/hmily_introduction/","summary":"Hmily框架特性[https://github.com/yu199195/hmily] 无缝集成Spring,Spring boot start。 无缝","tags":["hmily","TCC"],"title":"Hmily: High-Performance Asynchronous Distributed Transaction TCC Framework","type":"blog","url":"/blog/hmily_introduction/","wordcount":2682},{"author":"xiaoyu","categories":"hmily","content":" Hmily框架特性[https://github.com/yu199195/hmily]  无缝集成Spring,Spring boot start。\n 无缝集成Dubbo,SpringCloud,Motan等rpc框架。\n 多种事务日志的存储方式（redis，mongdb,mysql等）。\n 多种不同日志序列化方式（Kryo,protostuff,hession）。\n 事务自动恢复。\n 支持内嵌事务的依赖传递。\n 代码零侵入,配置简单灵活。   Hmily为什么这么高性能？ 1.采用disruptor进行事务日志的异步读写（disruptor是一个无锁，无GC的并发编程框架） package com.hmily.tcc.core.disruptor.publisher; import com.hmily.tcc.common.bean.entity.TccTransaction; import com.hmily.tcc.common.enums.EventTypeEnum; import com.hmily.tcc.core.concurrent.threadpool.HmilyThreadFactory; import com.hmily.tcc.core.coordinator.CoordinatorService; import com.hmily.tcc.core.disruptor.event.HmilyTransactionEvent; import com.hmily.tcc.core.disruptor.factory.HmilyTransactionEventFactory; import com.hmily.tcc.core.disruptor.handler.HmilyConsumerDataHandler; import com.hmily.tcc.core.disruptor.translator.HmilyTransactionEventTranslator; import com.lmax.disruptor.BlockingWaitStrategy; import com.lmax.disruptor.IgnoreExceptionHandler; import com.lmax.disruptor.RingBuffer; import com.lmax.disruptor.dsl.Disruptor; import com.lmax.disruptor.dsl.ProducerType; import org.springframework.beans.factory.DisposableBean; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Component; import java.util.concurrent.Executor; import java.util.concurrent.LinkedBlockingQueue; import java.util.concurrent.ThreadPoolExecutor; import java.util.concurrent.TimeUnit; import java.util.concurrent.atomic.AtomicInteger; /** * event publisher. * * @author xiaoyu(Myth) */ @Component public class HmilyTransactionEventPublisher implements DisposableBean { private Disruptor\u0026amp;lt;HmilyTransactionEvent\u0026amp;gt; disruptor; private final CoordinatorService coordinatorService; @Autowired public HmilyTransactionEventPublisher(final CoordinatorService coordinatorService) { this.coordinatorService = coordinatorService; } /** * disruptor start. * * @param bufferSize this is disruptor buffer size. * @param threadSize this is disruptor consumer thread size. */ public void start(final int bufferSize, final int threadSize) { disruptor = new Disruptor\u0026amp;lt;\u0026amp;gt;(new HmilyTransactionEventFactory(), bufferSize, r -\u0026amp;gt; { AtomicInteger index = new AtomicInteger(1); return new Thread(null, r, \u0026amp;quot;disruptor-thread-\u0026amp;quot; + index.getAndIncrement()); }, ProducerType.MULTI, new BlockingWaitStrategy()); final Executor executor = new ThreadPoolExecutor(threadSize, threadSize, 0, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026amp;lt;\u0026amp;gt;(), HmilyThreadFactory.create(\u0026amp;quot;hmily-log-disruptor\u0026amp;quot;, false), new ThreadPoolExecutor.AbortPolicy()); HmilyConsumerDataHandler[] consumers = new HmilyConsumerDataHandler[threadSize]; for (int i = 0; i \u0026amp;lt; threadSize; i++) { consumers[i] = new HmilyConsumerDataHandler(executor, coordinatorService); } disruptor.handleEventsWithWorkerPool(consumers); disruptor.setDefaultExceptionHandler(new IgnoreExceptionHandler()); disruptor.start(); } /** * publish disruptor event. * * @param tccTransaction {@linkplain …","date":1537833600,"description":"高性能一部分不是事务TCC框架","dir":"blog/hmily_introduction/","fuzzywordcount":2700,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"a651c37edc73a29abc85340ce541f54e6537d351","permalink":"/zh/blog/hmily_introduction/","publishdate":"2018-09-25T00:00:00Z","readingtime":6,"relpermalink":"/zh/blog/hmily_introduction/","summary":"Hmily框架特性[https://github.com/yu199195/hmily] 无缝集成Spring,Spring boot start。 无缝","tags":["hmily","TCC"],"title":"Hmily: 高性能异步分布式事务TCC框架","type":"blog","url":"/zh/blog/hmily_introduction/","wordcount":2682},{"author":null,"categories":null,"content":" The document is improving ","date":-62135596800,"description":"Distributed scheduling framework.","dir":"projects/athena/overview/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"195010e1f6c2a0da3ec7b0c23dfb7cbbeed976fa","permalink":"/projects/athena/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/athena/overview/","summary":" The document is improving ","tags":null,"title":"Athena Introduction","type":"projects","url":"/projects/athena/overview/","wordcount":4},{"author":null,"categories":null,"content":" 文档完善中，敬请期待 ","date":-62135596800,"description":"metrics 字节码工具.","dir":"projects/athena/overview/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"4c83aee1b2ebbc3c9a378d9610c24ac660306438","permalink":"/zh/projects/athena/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/zh/projects/athena/overview/","summary":"文档完善中，敬请期待","tags":null,"title":"Athena介绍","type":"projects","url":"/zh/projects/athena/overview/","wordcount":10},{"author":null,"categories":null,"content":" Bootstrap raincat-admin Prerequisite of bootstrap: The distributed transaction has been deployed and in running. You can choose RPC framework in follows whatever you want.\n Dubbo user Springcloud user  Bootstrap method Method1: Package and deploy by yourself  First of all, the JDK version must be 1.8+ and Git and Maven are installed locally, then execute the following commands.  git clone https://github.com/yu199195/Raincat.git maven clean install   Secondly, please use your dev tool to open the project, such as IDEA, Eclipse. Please modify your application.yml as follows.  userName，password are the login user name and password. Redis configuration is consistent with your txManager. spring.profiles.active is the way you store the log, please modify the corresponding yml file. For example, the following code snippet shows how to configure application-db.yml when use DB as storage.   server: port: 8888 context-path: /admin spring: application: name: raincat-admin profiles: active: db tx: admin : userName : admin password : admin redis: hostName: localhost port : 6379 #password: cluster : false # nodes: 127.0.0.1:70001;127.0.1:7002 # redirects: 20   Thirdly, application.list is your applicationName of your micro service, and separated with commas.  serializer : The way to serialize the transaction log. retry.max: The maximum retry time.   recover: application: list : alipay-service,wechat-service,pay-service serializer : support: kryo retry : max: 10 db: driver : com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/tx?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8 username: root password: 123456   Finally, please modify your index.html, and run the main() method in AdminApplication, then visit http://ip:port/admin in the browser, enter the user name and password to log in.  \u0026amp;lt;!--Modify your ip port in href--\u0026amp;gt; \u0026amp;lt;a id=\u0026amp;quot;serverIpAddress\u0026amp;quot; style=\u0026amp;quot;display: none\u0026amp;quot; href=\u0026amp;quot;http://192.168.1.132:8888/admin\u0026amp;quot;\u0026amp;gt;  Method2: Obtain the admin jar package from the maven central warehouse. \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;raincat-admin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.0.0-RELEASE\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   Please create a config directory and application.yml, etc. Then modify the yml file and start up the application.  ","date":-62135596800,"description":"Bootstrap raincat-admin","dir":"projects/raincat/admin-starter/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"bdd08f2ca383462c4ac181c91b3d76bcd91f72ed","permalink":"/projects/raincat/admin-starter/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/raincat/admin-starter/","summary":"Bootstrap raincat-admin Prerequisite of bootstrap: The distributed transaction has been deployed and in running. You can choose RPC framework in follows whatever you want.\n Dubbo user Springcloud user  Bootstrap method Method1: Package and deploy by yourself  First of all, the JDK version must be 1.8+ and Git and Maven are installed locally, then execute the following commands.  git clone https://github.com/yu199195/Raincat.git maven clean install   Secondly, please use your dev tool to open the project, such as IDEA, Eclipse.","tags":null,"title":"Bootstrap raincat-admin","type":"projects","url":"/projects/raincat/admin-starter/","wordcount":287},{"author":null,"categories":null,"content":" Bootstrap raincat-manager Bootstrap method Method 1: Pull the code from github and compile it by yourself: https://github.com/yu199195/Raincat  Modify the Redis configuration in application.yml.  transactionWaitMaxTime: 500 redisSaveMaxTime: 3000 tx: manager: netty : port: 9998 serialize: kryo maxConnection: 100 maxThreads : 16 delayTime : 5 heartTime : 20 redis : cluster : false hostName : 192.168.1.91 port: 6379 password : foobaredbbexONE123   transactionWaitMaxTime is the transaction maximum waiting time.\n redisSaveMaxTime is the Redis maximum waiting time.\n tx:manager:netty\n port is the Netty port for long connections which you can modify by yourself.   serialize is the Netty serialization protocol (Kroy in recommended), and it should be consistent with the serialization protocol at client.\n maxConnection is the maximum number of long connections.\n maxThreads is the number of Netty worker thread.\n heartTime is the heartbeat interval (seconds).\n  Method 2: Obtain the raincat-manager jar from the maven central warehouse.  Please create a config directory, and configure application.yml. Then modify the yml file and start up the application. If you want to know more details, please refer to the springboot configuration file.  ","date":-62135596800,"description":"Bootstrap raincat-manager","dir":"projects/raincat/raincat-manager-starter/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"dbb2bd8f4ef36e38a5b2f2c972dc033abb80a567","permalink":"/projects/raincat/raincat-manager-starter/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/raincat/raincat-manager-starter/","summary":"Bootstrap raincat-manager Bootstrap method Method 1: Pull the code from github and compile it by yourself: https://github.com/yu199195/Raincat  Modify the Redis configuration in application.yml.  transactionWaitMaxTime: 500 redisSaveMaxTime: 3000 tx: manager: netty : port: 9998 serialize: kryo maxConnection: 100 maxThreads : 16 delayTime : 5 heartTime : 20 redis : cluster : false hostName : 192.168.1.91 port: 6379 password : foobaredbbexONE123   transactionWaitMaxTime is the transaction maximum waiting time.","tags":null,"title":"Bootstrap raincat-manager","type":"projects","url":"/projects/raincat/raincat-manager-starter/","wordcount":173},{"author":null,"categories":null,"content":" Prerequisites  JDK 1.8+ Maven 3.2.x Git Zookeeper  Cloning the GitHub Repository and Quick Installation  \u0026amp;gt; git clone https://github.com/dromara/hmily.git \u0026amp;gt; cd hmily \u0026amp;gt; mvn -DskipTests clean install -U  Executing SQL(s) in Demo Module sql\nOpen with Your Favourite Editor (IDEA) and Locate on hmily-demo-dubbo Module Configuring（hmily-demo-dubbo-account module for instance）  Configure with your business database (account module for instance)  spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://\u0026amp;lt;db_host_ip\u0026amp;gt;:\u0026amp;lt;db_host_port\u0026amp;gt;/hmily_account?useUnicode=true\u0026amp;amp;characterEncoding=utf8 # replace with your db_host_ip and db_host_port username: root # replace with your db username password: your_password # replace with your db user password   Modify hmily.yml, with mysql persistence backend  repository: database: driverClassName: com.mysql.jdbc.Driver url: jdbc:mysql://\u0026amp;lt;db_host_ip\u0026amp;gt;:\u0026amp;lt;db_host_port\u0026amp;gt;/hmily?useUnicode=true\u0026amp;amp;characterEncoding=utf8 # replace with your db_host_ip and db_host_port username: root # replace with your db username password: your_password # replace with your db user password   Configure with your zookeeper address(es)(can run one locally)  \u0026amp;lt;dubbo:registry protocol=\u0026amp;quot;zookeeper\u0026amp;quot; address=\u0026amp;quot;localhost:2181\u0026amp;quot;/\u0026amp;gt;   run DubboHmilyAccountApplication.java  Run hmily-demo-dubbo-inventory(refer to simillar instructions above). Run hmily-demo-dubbo-order(refer to simillar instructions above). Access on http://127.0.0.1:8087/swagger-ui.html for more. ","date":-62135596800,"description":"Dubbo Quick Start","dir":"projects/hmily/quick-start-dubbo/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"8e82dd39d7b359defe77f7ffb27e68b120875d46","permalink":"/projects/hmily/quick-start-dubbo/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/hmily/quick-start-dubbo/","summary":"Prerequisites  JDK 1.8+ Maven 3.2.x Git Zookeeper  Cloning the GitHub Repository and Quick Installation  \u0026gt; git clone https://github.com/dromara/hmily.git \u0026gt; cd hmily \u0026gt; mvn -DskipTests clean install -U  Executing SQL(s) in Demo Module sql\nOpen with Your Favourite Editor (IDEA) and Locate on hmily-demo-dubbo Module Configuring（hmily-demo-dubbo-account module for instance）  Configure with your business database (account module for instance)  spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://\u0026lt;db_host_ip\u0026gt;:\u0026lt;db_host_port\u0026gt;/hmily_account?useUnicode=true\u0026amp;characterEncoding=utf8 # replace with your db_host_ip and db_host_port username: root # replace with your db username password: your_password # replace with your db user password   Modify hmily.","tags":null,"title":"Dubbo Quick Start","type":"projects","url":"/projects/hmily/quick-start-dubbo/","wordcount":153},{"author":null,"categories":null,"content":" Add myth-annotation dependency to Dubbo api project.  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.github.myth\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;myth-annotation\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   Add the @Myth annotation to the Dubbo Interface method and set the name of the message queue, which is the queue from which the messaging middleware sends messages.  @Myth(destination = \u0026amp;quot;account\u0026amp;quot;) boolean payment(AccountDTO accountDTO);   In the Dubbo service provider (the participating method of the transaction, the callee ).\n add myth-dubbo dependency\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.github.myth\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;myth-dubbo\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   The MythTransactionBootstrap startup class can be configured in xml or @Bean. Please refer to the specific configuration:configuration for details  \u0026amp;lt;context:component-scan base-package=\u0026amp;quot;com.github.myth.*\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;mythTransactionBootstrap\u0026amp;quot; class=\u0026amp;quot;com.github.myth.core.bootstrap.MythTransactionBootstrap\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;repositorySuffix\u0026amp;quot; value=\u0026amp;quot;account-service\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;serializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;coordinatorQueueMax\u0026amp;quot; value=\u0026amp;quot;5000\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;coordinatorThreadMax\u0026amp;quot; value=\u0026amp;quot;8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;rejectPolicy\u0026amp;quot; value=\u0026amp;quot;Abort\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;blockingQueueType\u0026amp;quot; value=\u0026amp;quot;Linked\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;repositorySupport\u0026amp;quot; value=\u0026amp;quot;db\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;mythDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;bean class=\u0026amp;quot;com.github.myth.common.config.MythDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;url\u0026amp;quot; value=\u0026amp;quot;jdbc:mysql://192.168.1.68:3306/myth?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;driverClassName\u0026amp;quot; value=\u0026amp;quot;com.mysql.jdbc.Driver\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;password\u0026amp;quot; value=\u0026amp;quot;Wgj@555888\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;username\u0026amp;quot; value=\u0026amp;quot;xiaoyu\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt; \u0026amp;lt;/property\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt;   Add @Myth to the implementation of your interface\n Listen to the message queue (message queue name written in the annotations method), invoke the framework provides MythMqReceiveService.processMessage() method. If you use JMS, you can refer to the Demo project for details.\n@JmsListener(destination = \u0026amp;quot;account\u0026amp;quot;,containerFactory = \u0026amp;quot;queueListenerContainerFactory\u0026amp;quot;) public void receiveQueue(byte[] message) { LOGGER.info(\u0026amp;quot;=========Deducting the account information to receive Myth framework incoming information==========\u0026amp;quot;); final Boolean success = mythMqReceiveService.processMessage(message); if(success){ //If the consumption is successful, the message is out of the queue, otherwise it is not consumed. } }   In the Dubbo consumer (the invoker of the transaction, the caller)\n add …","date":-62135596800,"description":"Myth Dubbo User","dir":"projects/myth/dubbo-user/","fuzzywordcount":500,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"433f36fa4db03e976d642f353cf822978b1636ac","permalink":"/projects/myth/dubbo-user/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/myth/dubbo-user/","summary":"Add myth-annotation dependency to Dubbo api project.  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.myth\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;myth-annotation\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt;   Add the @Myth annotation to the Dubbo Interface method and set the name of the message queue, which is the queue from which the messaging middleware sends messages.  @Myth(destination = \u0026quot;account\u0026quot;) boolean payment(AccountDTO accountDTO);   In the Dubbo service provider (the participating method of the transaction, the callee ).\n add myth-dubbo dependency","tags":null,"title":"Dubbo User","type":"projects","url":"/projects/myth/dubbo-user/","wordcount":464},{"author":null,"categories":null,"content":" Firstly, you should bootstrap raincat-manager, please refer to how to bootstrap Txmanager for details. Then, please add dependency in maven at your Dubbo service, and add @TxTransaction annotation in your distributed transaction method. \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;raincat-dubbo\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.0.0-RELEASE\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  Configure TxTransactionBootstrap by Spring XML \u0026amp;lt;context:component-scan base-package=\u0026amp;quot;org.dromara.*\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;txTransactionBootstrap\u0026amp;quot; class=\u0026amp;quot;org.dromara.raincat.core.bootstrap.TxTransactionBootstrap\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;txManagerUrl\u0026amp;quot; value=\u0026amp;quot;http://localhost:8761\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;serializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;nettySerializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;compensation\u0026amp;quot; value=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;compensationCacheType\u0026amp;quot; value=\u0026amp;quot;db\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;txDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;bean class=\u0026amp;quot;org.dromara.raincat.common.config.TxDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;url\u0026amp;quot; value=\u0026amp;quot;jdbc:mysql://192.168.1.98:3306/tx?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;driverClassName\u0026amp;quot; value=\u0026amp;quot;com.mysql.jdbc.Driver\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;username\u0026amp;quot; value=\u0026amp;quot;root\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;password\u0026amp;quot; value=\u0026amp;quot;123456\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt; \u0026amp;lt;/property\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt;  Configure TxTransactionBootstrap by spring boot starter  Firstly, please add maven dependency raincat-spring-boot-starter-dubbo provided by Raincat.\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;raincat-spring-boot-starter-dubbo\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.0.0-RELEASE\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   Secondly, configure the application.yml like follows.  org: dromara: raincat: txManagerUrl: http://localhost:8761 serializer: kroy nettySerializer: kroy compensation: true compensationCacheType : db txDbConfig : driverClassName : com.mysql.jdbc.Driver url : jdbc:mysql://192.168.1.98:3306/tx?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8 username : root password : 123456  txManagerUrl is the ip and port that you bootstrap txManager . Please add http:// at head.\n serializer is the way of transaction log serialization.\n nettySerializer is the serialization way of how to communicate with txManager. Please be caution that It should be consistent with the configuration in txManager.\n compensation is the property whether the compensation is required or not, the service will compensate itself in some extreme cases.\n compensationCacheType is the storage log types, and support Redis, Mongodb, Zookeeper, etc. For details, please refer to the config.\n  NOTICE：You need to open AOP when you want to use XML to …","date":-62135596800,"description":"dubbo user configuration","dir":"projects/raincat/dubbo-user/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"4eaf23e6604a9b217319619ace1eabbe00725e82","permalink":"/projects/raincat/dubbo-user/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/raincat/dubbo-user/","summary":"Firstly, you should bootstrap raincat-manager, please refer to how to bootstrap Txmanager for details. Then, please add dependency in maven at your Dubbo service, and add @TxTransaction annotation in your distributed transaction method. \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.dromara\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;raincat-dubbo\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.0.0-RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;  Configure TxTransactionBootstrap by Spring XML \u0026lt;context:component-scan base-package=\u0026quot;org.dromara.*\u0026quot;/\u0026gt; \u0026lt;aop:aspectj-autoproxy expose-proxy=\u0026quot;true\u0026quot;/\u0026gt; \u0026lt;bean id=\u0026quot;txTransactionBootstrap\u0026quot; class=\u0026quot;org.dromara.raincat.core.bootstrap.TxTransactionBootstrap\u0026quot;\u0026gt; \u0026lt;property name=\u0026quot;txManagerUrl\u0026quot; value=\u0026quot;http://localhost:8761\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;serializer\u0026quot; value=\u0026quot;kryo\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;nettySerializer\u0026quot; value=\u0026quot;kryo\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;compensation\u0026quot; value=\u0026quot;true\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;compensationCacheType\u0026quot; value=\u0026quot;db\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;txDbConfig\u0026quot;\u0026gt; \u0026lt;bean class=\u0026quot;org.","tags":null,"title":"Dubbo user configuration","type":"projects","url":"/projects/raincat/dubbo-user/","wordcount":246},{"author":null,"categories":null,"content":" The Dubbo Interface Sectioon  Introduce the jar packages into your interface project.  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-annotation\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   Add the @Hmily annotation on the interface method in which you need to perform Hmily distributed transactions.\npublic interface HelloService { @Hmily void say(String hello); }  The project with Dubbo implementation  Step 1 ： Introduce the jar package of the hmily dependency\n Step 2 ： Add Hmily configuration\n Step 3 ： Add the specific annotation to the implementation method. you need to complete the development of confirm and cancel method, if in TCC mode.\n  Introduce The Maven dependency Spring-Namespace  for Alibaba-Dubbo Users  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-dubbo\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  for Aapche-Dubbo Users\n  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-apache-dubbo\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   the configuration should be made in the xml file like below  \u0026amp;lt;!-- set up to enable the aspectj-autoproxy --\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id = \u0026amp;quot;hmilyTransactionAspect\u0026amp;quot; class=\u0026amp;quot;org.dromara.hmily.spring.aop.SpringHmilyTransactionAspect\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id = \u0026amp;quot;hmilyApplicationContextAware\u0026amp;quot; class=\u0026amp;quot;org.dromara.hmily.spring.HmilyApplicationContextAware\u0026amp;quot;/\u0026amp;gt;  Spring-Boot  for Alibaba-Dubbo Users  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-spring-boot-starter-dubbo\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   for Aapche-Dubbo Users  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-spring-boot-starter-apache-dubbo\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  Introduce the Hmily configuration  new a configuration file named hmily.yml under the resource directory of the current project\n the specific parameter configuration can refer to configuration detail,Local configuration mode, Zookeeper configuration mode, nacos configuration mode,apollo configuration mode\n  Add annotations on the implementation interface We have completed the integration described above,and the next we will talk about the specific implementation.\nTCC Mode  Add @HmilyTCC (confirmMethod = \u0026amp;quot;confirm\u0026amp;quot;, cancelMethod = \u0026amp;quot;cancel\u0026amp;quot;) annotation to the concrete implementation of the interface method identified by \u0026amp;lsquo;@Hmily\u0026amp;rsquo;.\n confirmMethod : the method name for confirm，The method parameter list and return type should be consistent with the identification method.\n cancelMethod : the method for cancel，The method parameter list and return type should be …","date":-62135596800,"description":"Dubbo user guide","dir":"projects/hmily/user-dubbo/","fuzzywordcount":700,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"c94d387240bfe786b4fcf14640a25be402c2773a","permalink":"/projects/hmily/user-dubbo/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/hmily/user-dubbo/","summary":"The Dubbo Interface Sectioon  Introduce the jar packages into your interface project.  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.dromara\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;hmily-annotation\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;{last.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   Add the @Hmily annotation on the interface method in which you need to perform Hmily distributed transactions.\npublic interface HelloService { @Hmily void say(String hello); }  The project with Dubbo implementation  Step 1 ： Introduce the jar package of the hmily dependency\n Step 2 ： Add Hmily configuration","tags":null,"title":"Dubbo user guide","type":"projects","url":"/projects/hmily/user-dubbo/","wordcount":630},{"author":null,"categories":null,"content":" cd https://github.com/yu199195/myth/tree/master/myth-demo/myth-demo-dubbo\n Modifiy application.yml on Indicator Item And Modifiy you jdbc url And choose you Message Oriented Middleware\nspring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://192.168.1.68:3306/myth_account?useUnicode=true\u0026amp;amp;characterEncoding=utf8 username: xiaoyu password: Wgj@555888 #activemq: # broker-url: tcp://120.76.52.162:61616 # user: happylife # password: happylifeplat01 # trust-all: true #rabbitmq: # host: localhost # port: 5672 # username: guest # password: guest rocketmq: namesrvAddr: 192.168.1.148:9876 consumerGroupName: account instanceName: account #kafka: # consumer: # bootstrap-servers: localhost:9092 # group-id: test # auto-offset-reset: earliest # enable-auto-commit: true # auto-commit-interval: 100 # key-deserializer: org.apache.kafka.common.serialization.StringDeserializer # value-deserializer: org.apache.kafka.common.serialization.ByteArrayDeserializer   Modifiy applicationContext.xml on Indicator Item And choose repositorySupport and modifiy it If you use database compensation , You have to create a new database for example：myth xml \u0026amp;lt;context:component-scan base-package=\u0026amp;quot;com.github.myth.*\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;mythTransactionBootstrap\u0026amp;quot; class=\u0026amp;quot;com.github.myth.core.bootstrap.MythTransactionBootstrap\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;repositorySuffix\u0026amp;quot; value=\u0026amp;quot;account-service\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;serializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;coordinatorQueueMax\u0026amp;quot; value=\u0026amp;quot;5000\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;coordinatorThreadMax\u0026amp;quot; value=\u0026amp;quot;8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;rejectPolicy\u0026amp;quot; value=\u0026amp;quot;Abort\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;blockingQueueType\u0026amp;quot; value=\u0026amp;quot;Linked\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;repositorySupport\u0026amp;quot; value=\u0026amp;quot;db\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;mythDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;bean class=\u0026amp;quot;com.github.myth.common.config.MythDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;url\u0026amp;quot; value=\u0026amp;quot;jdbc:mysql://192.168.1.68:3306/myth?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;driverClassName\u0026amp;quot; value=\u0026amp;quot;com.mysql.jdbc.Driver\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;password\u0026amp;quot; value=\u0026amp;quot;Wgj@555888\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;username\u0026amp;quot; value=\u0026amp;quot;xiaoyu\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt; \u0026amp;lt;/property\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt;   Modifiy spring-dubbo.xml on Indicator Item And modifiy zookeeper url\n```xml   ``` * run DubboAccountApplication.java\n run DubboInventoryApplication.java\n run DubboOrderApplication.java\nthis mq sender so befer:\n in applicationContext.xml choose import you mq sender config\n  \u0026amp;lt;import resource=\u0026amp;quot;spring-rocketmq.xml\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;!--\u0026amp;lt;import resource=\u0026amp;quot;spring-rabbitmq.xml\u0026amp;quot;/\u0026amp;gt;--\u0026amp;gt; \u0026amp;lt;!--\u0026amp;lt;import resource=\u0026amp;quot;spring-kafka.xml\u0026amp;quot;/\u0026amp;gt;--\u0026amp;gt; \u0026amp;lt;!--\u0026amp;lt;import …","date":-62135596800,"description":"Dubbo 快速开始","dir":"projects/myth/quick-start-dubbo/","fuzzywordcount":300,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"f0a917e50c4b779e355f66b2b35f98912ef27a02","permalink":"/zh/projects/myth/quick-start-dubbo/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/zh/projects/myth/quick-start-dubbo/","summary":"cd https://github.com/yu199195/myth/tree/master/myth-demo/myth-demo-dubbo Modifiy application.yml on Indicator Item And Modifiy you jdbc url And choose you Message Oriented Middleware spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://192.168.1.68:3306/myth_account?useUnicode=true\u0026amp;characterEncoding=utf8 username: xiaoyu password: Wgj@555888 #activemq: # broker-url: tcp://120.76.52.162:61616 # user: happylife # password: happylifeplat01 # trust-all: true #rabbitmq: # host: localhost # port: 5672 # username: guest # password: guest rocketmq: namesrvAddr: 192.168.1.148:9876 consumerGroupName: account instanceName: account #kafka: # consumer: # bootstrap-servers: localhost:9092 # group-id: test","tags":null,"title":"Dubbo 快速开始","type":"projects","url":"/zh/projects/myth/quick-start-dubbo/","wordcount":241},{"author":null,"categories":null,"content":" 在dubbo api 项目引入myth-annotation jar包  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.github.myth\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;myth-annotation\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   在dubbo interface 方法上加上@Myth注解 ,并设置消息队列名称,此队列就是消息中间件发消息的队列：  @Myth(destination = \u0026amp;quot;account\u0026amp;quot;) boolean payment(AccountDTO accountDTO);   在dubbo 服务提供方（事务的参与方法，被调用方）\n 引入myth-dubbo 包\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.github.myth\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;myth-dubbo\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   配置 MythTransactionBootstrap启动类,可以采用xml方式，或者@Bean的方式,具体配置可以参考:配置详解  \u0026amp;lt;context:component-scan base-package=\u0026amp;quot;com.github.myth.*\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;mythTransactionBootstrap\u0026amp;quot; class=\u0026amp;quot;com.github.myth.core.bootstrap.MythTransactionBootstrap\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;repositorySuffix\u0026amp;quot; value=\u0026amp;quot;account-service\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;serializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;coordinatorQueueMax\u0026amp;quot; value=\u0026amp;quot;5000\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;coordinatorThreadMax\u0026amp;quot; value=\u0026amp;quot;8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;rejectPolicy\u0026amp;quot; value=\u0026amp;quot;Abort\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;blockingQueueType\u0026amp;quot; value=\u0026amp;quot;Linked\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;repositorySupport\u0026amp;quot; value=\u0026amp;quot;db\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;mythDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;bean class=\u0026amp;quot;com.github.myth.common.config.MythDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;url\u0026amp;quot; value=\u0026amp;quot;jdbc:mysql://192.168.1.68:3306/myth?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;driverClassName\u0026amp;quot; value=\u0026amp;quot;com.mysql.jdbc.Driver\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;password\u0026amp;quot; value=\u0026amp;quot;Wgj@555888\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;username\u0026amp;quot; value=\u0026amp;quot;xiaoyu\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt; \u0026amp;lt;/property\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt;   在你接口的实现方法上加上@Myth\n 监听消息队列（注解方法上写的消息队列名称),调用框架提供 的MythMqReceiveService.processMessage方法。列如使用jms，具体可以参考demo工程。\n@JmsListener(destination = \u0026amp;quot;account\u0026amp;quot;,containerFactory = \u0026amp;quot;queueListenerContainerFactory\u0026amp;quot;) public void receiveQueue(byte[] message) { LOGGER.info(\u0026amp;quot;=========扣减账户信息接收到Myth框架传入的信息==========\u0026amp;quot;); final Boolean success = mythMqReceiveService.processMessage(message); if(success){ //消费成功，消息出队列，否则不消费 } }   在dubbo 消费方（事务的发起者，调用方）\n 引入myth-dubbo 包\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.github.myth\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;myth-dubbo\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;    配置 MythTransactionBootstrap启动类,可以采用xml方式，或者@Bean的方式,具体配置可以参考:配置详解\n\u0026amp;lt;context:component-scan base-package=\u0026amp;quot;com.github.myth.*\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;mythTransactionBootstrap\u0026amp;quot; class=\u0026amp;quot;com.github.myth.core.bootstrap.MythTransactionBootstrap\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;repositorySuffix\u0026amp;quot; value=\u0026amp;quot;account-service\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;serializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; …","date":-62135596800,"description":"Myth Dubbo User","dir":"projects/myth/dubbo-user/","fuzzywordcount":1000,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"e30f0aee67968b85591e7c33da466fdfea0ac0a6","permalink":"/zh/projects/myth/dubbo-user/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/zh/projects/myth/dubbo-user/","summary":"在dubbo api 项目引入myth-annotation jar包 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.myth\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;myth-annotation\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 在dubbo interface 方法上加上@Myth注解 ,并设置消息队列名称,此队列就是消","tags":null,"title":"Dubbo 用户","type":"projects","url":"/zh/projects/myth/dubbo-user/","wordcount":978},{"author":null,"categories":null,"content":" 环境准备  JDK 1.8+ Maven 3.2.x Git Zookeeper  代码拉取  \u0026amp;gt; git clone https://github.com/dromara/hmily.git \u0026amp;gt; cd hmily \u0026amp;gt; mvn -DskipTests clean install -U  执行demo 模块的sql语句。 sql语句\n使用你的工具 idea 打开项目，找到hmily-demo-dubbo项目。 修改项目配置（hmily-demo-dubbo-account为列子）  修改业务数据库(account项目为列子)  spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://改成你的ip+端口/hmily_account?useUnicode=true\u0026amp;amp;characterEncoding=utf8 username: #改成你的用户名 password: #改成你的密码   修改 hmily.yml,这里使用mysql来存储  repository: database: driverClassName: com.mysql.jdbc.Driver url : jdbc:mysql://改成你的ip+端口/hmily?useUnicode=true\u0026amp;amp;characterEncoding=utf8 username: root #改成你的用户名 password: #改成你的密码   在spring-dubbo中修改你的zookeeper地址（可以在自己电脑本地启动一个zookeeper服务）  \u0026amp;lt;dubbo:registry protocol=\u0026amp;quot;zookeeper\u0026amp;quot; address=\u0026amp;quot;localhost:2181\u0026amp;quot;/\u0026amp;gt;   run DubboHmilyAccountApplication.java  启动hmily-demo-dubbo-inventory 参考上述。 启动hmily-demo-dubbo-order 参考上述。 访问：http://127.0.0.1:8087/swagger-ui.html。 ","date":-62135596800,"description":"Dubbo快速体验","dir":"projects/hmily/quick-start-dubbo/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"fbf8a182b96b41e4b4e6402081e7b6ff371e3ef7","permalink":"/zh/projects/hmily/quick-start-dubbo/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/zh/projects/hmily/quick-start-dubbo/","summary":"环境准备 JDK 1.8+ Maven 3.2.x Git Zookeeper 代码拉取 \u0026gt; git clone https://github.com/dromara/hmily.git \u0026gt; cd hmily \u0026gt; mvn -DskipTests clean install -U 执行demo 模块的sql语句。 sql语句 使用你的工具 idea 打开项目，找到hmily-dem","tags":null,"title":"Dubbo快速体验","type":"projects","url":"/zh/projects/hmily/quick-start-dubbo/","wordcount":519},{"author":null,"categories":null,"content":" Prerequisites  JDK 1.8+ Maven 3.2.x Git Zookeeper  Cloning the GitHub Repository and Quick Installation  \u0026amp;gt; git clone https://github.com/dromara/hmily.git \u0026amp;gt; cd hmily \u0026amp;gt; mvn -DskipTests clean install -U  Executing SQL(s) in Demo Module sql\nOpen with Your Favourite Editor (IDEA) and Locate on hmily-demo-grpc Module Configuring（hmily-demo-grpc-accoun module for instance）  Configure with your business database (account module for instance)  spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://\u0026amp;lt;db_host_ip\u0026amp;gt;:\u0026amp;lt;db_host_port\u0026amp;gt;/hmily_account?useUnicode=true\u0026amp;amp;characterEncoding=utf8 # replace with your db_host_ip and db_host_port username: root # replace with your db username password: your_password # replace with your db user password   Modify hmily.yml, with mysql persistence backend  repository: database: driverClassName: com.mysql.jdbc.Driver url: jdbc:mysql://\u0026amp;lt;db_host_ip\u0026amp;gt;:\u0026amp;lt;db_host_port\u0026amp;gt;/hmily?useUnicode=true\u0026amp;amp;characterEncoding=utf8 # replace with your db_host_ip and db_host_port username: root # replace with your db username password: your_password # replace with your db user password   run GrpcHmilyAccountApplication.java  Run hmily-demo-tars-springboot-inventory(refer to simillar instructions above). Run hmily-demo-tars-springboot-order(refer to simillar instructions above). Access on http://127.0.0.1:28087/swagger-ui.html for more. ","date":-62135596800,"description":"Grpc Quick Start","dir":"projects/hmily/quick-start-grpc/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"a7d431f965718f2bfc8527a881562e9c0e65ecf4","permalink":"/projects/hmily/quick-start-grpc/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/hmily/quick-start-grpc/","summary":"Prerequisites  JDK 1.8+ Maven 3.2.x Git Zookeeper  Cloning the GitHub Repository and Quick Installation  \u0026gt; git clone https://github.com/dromara/hmily.git \u0026gt; cd hmily \u0026gt; mvn -DskipTests clean install -U  Executing SQL(s) in Demo Module sql\nOpen with Your Favourite Editor (IDEA) and Locate on hmily-demo-grpc Module Configuring（hmily-demo-grpc-accoun module for instance）  Configure with your business database (account module for instance)  spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://\u0026lt;db_host_ip\u0026gt;:\u0026lt;db_host_port\u0026gt;/hmily_account?useUnicode=true\u0026amp;characterEncoding=utf8 # replace with your db_host_ip and db_host_port username: root # replace with your db username password: your_password # replace with your db user password   Modify hmily.","tags":null,"title":"Grpc Quick Start","type":"projects","url":"/projects/hmily/quick-start-grpc/","wordcount":142},{"author":null,"categories":null,"content":" Grpc User Guide  Unary synchronous calls to GRPC are supported only at present.\n Introduce the jar packages\n Introduce the Hmily configuration\n Add @HmilyTCC or @HmilyTAC annotation on the concrete implementation method(Service provider).\n  Introduce The Maven dependency Spring-Namespace\n Introduce the hmily-grpc dependency   \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-grpc\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   make the configuration in the XML configuration file as below:\n\u0026amp;lt;!--Configure the base packages that the Hmily framework need to scan --\u0026amp;gt; \u0026amp;lt;context:component-scan base-package=\u0026amp;quot;org.dromara.hmily.*\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;!-- set up to enable the aspectj-autoproxy --\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;!-- Configure the bean parameters for Hmily startup --\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;hmilyApplicationContextAware\u0026amp;quot; class=\u0026amp;quot;org.dromara.hmily.spring.HmilyApplicationContextAware\u0026amp;quot;/\u0026amp;gt;  Spring-Boot\n Introduce the hmily-spring-boot-starter-grpc dependency\nxml \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-spring-boot-starter-grpc\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;    Introduce the Hmily configuration  new a configuration file named hmily.yml under the resource directory of the current project\n the specific parameter configuration can refer to configuration detail,Local configuration mode, Zookeeper configuration mode, nacos configuration mode,apollo configuration mode\n  Grpc Filter configuration  Add filter GrpcHmilyTransactionFilter to GRPC client. Add filter GrpcHmilyServerFilter to GRPC server.  Grpc client call  Use the GrpcHmilyClient to make the remote call instead of the original call.  AccountResponse response = GrpcHmilyClient.syncInvoke(accountServiceBlockingStub, \u0026amp;quot;payment\u0026amp;quot;, request, AccountResponse.class);  The input parameters are the called AbstratcSub, the method name, the specific parameter, and the return value type,respectively.\nTCC Mode  Add the @HmilyTCC(confirmMethod = \u0026amp;quot;confirm\u0026amp;quot;, cancelMethod = \u0026amp;quot;cancel\u0026amp;quot;) annotation on the concrete implementation of the transaction method on the server side.\n confirmMethod : the method name for confirm，The method parameter list and return type should be consistent with the identification method.\n cancelMethod : the method for cancel，The method parameter list and return type should be consistent with the identification method.\n The TCC mode should ensure the idempotence of the confirm and cancel methods,Users need to develop these two methods by themselves,The confirmation and rollback behavior of all transactions are completely up tp users.The Hmily framework is just responsible for making calls.\n  public class HelloServiceImpl implements HelloService { @HmilyTCC(confirmMethod = \u0026amp;quot;sayConfrim\u0026amp;quot;, cancelMethod = \u0026amp;quot;sayCancel\u0026amp;quot;) …","date":-62135596800,"description":"Grpc User Guide","dir":"projects/hmily/user-grpc/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"3578f82c9fb122accb2754db4c234a34fcf63750","permalink":"/projects/hmily/user-grpc/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/hmily/user-grpc/","summary":"Grpc User Guide  Unary synchronous calls to GRPC are supported only at present.\n Introduce the jar packages\n Introduce the Hmily configuration\n Add @HmilyTCC or @HmilyTAC annotation on the concrete implementation method(Service provider).\n  Introduce The Maven dependency Spring-Namespace\n Introduce the hmily-grpc dependency   \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.dromara\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;hmily-grpc\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;{last.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   make the configuration in the XML configuration file as below:\n\u0026lt;!--Configure the base packages that the Hmily framework need to scan --\u0026gt; \u0026lt;context:component-scan base-package=\u0026quot;org.","tags":null,"title":"Grpc User Guide","type":"projects","url":"/projects/hmily/user-grpc/","wordcount":367},{"author":null,"categories":null,"content":" 环境准备  JDK 1.8+ Maven 3.2.x Git Zookeeper  代码拉取  \u0026amp;gt; git clone https://github.com/dromara/hmily.git \u0026amp;gt; cd hmily \u0026amp;gt; mvn -DskipTests clean install -U  执行demo 模块的sql语句。 sql语句\n使用你的工具 idea 打开项目，找到hmily-demo-grpc项目。 修改项目配置（hmily-demo-grpc-account为列子）  修改业务数据库(account项目为列子)  spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://改成你的ip+端口/hmily_account?useUnicode=true\u0026amp;amp;characterEncoding=utf8 username: #改成你的用户名 password: #改成你的密码   修改 hmily.yml,这里使用mysql来存储  repository: database: driverClassName: com.mysql.jdbc.Driver url : jdbc:mysql://改成你的ip+端口/hmily?useUnicode=true\u0026amp;amp;characterEncoding=utf8 username: root #改成你的用户名 password: #改成你的密码   run GrpcHmilyAccountApplication.java  启动hmily-demo-tars-springboot-inventory 参考上述。 启动hmily-demo-tars-springboot-order 参考上述。 访问：http://127.0.0.1:28087/swagger-ui.html。 ","date":-62135596800,"description":"Grpc快速体验","dir":"projects/hmily/quick-start-grpc/","fuzzywordcount":500,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"57d54c4ad341cae42b985a81991921c0c9518d4b","permalink":"/zh/projects/hmily/quick-start-grpc/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/zh/projects/hmily/quick-start-grpc/","summary":"环境准备 JDK 1.8+ Maven 3.2.x Git Zookeeper 代码拉取 \u0026gt; git clone https://github.com/dromara/hmily.git \u0026gt; cd hmily \u0026gt; mvn -DskipTests clean install -U 执行demo 模块的sql语句。 sql语句 使用你的工具 idea 打开项目，找到hmily-dem","tags":null,"title":"Grpc快速体验","type":"projects","url":"/zh/projects/hmily/quick-start-grpc/","wordcount":480},{"author":null,"categories":null,"content":" Grpc用户指南  目前只支持grpc的一元同步调用\n 引入jar包\n 引入hmily配置\n 在具体的实现方法上（服务提供端），加上@HmilyTCC or HmilyTAC 注解\n  引入依赖 Spring-Namespace\n 引入依赖\n  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-grpc\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   在xml中进行如下配置\n\u0026amp;lt;!--配置扫码hmily框架的包--\u0026amp;gt; \u0026amp;lt;context:component-scan base-package=\u0026amp;quot;org.dromara.hmily.*\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;!--设置开启aspectj-autoproxy--\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;!--配置Hmily启动的bean参数--\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;hmilyApplicationContextAware\u0026amp;quot; class=\u0026amp;quot;org.dromara.hmily.spring.HmilyApplicationContextAware\u0026amp;quot;/\u0026amp;gt;  Spring-Boot\n 引入依赖\nxml \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-spring-boot-starter-grpc\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;    引入Hmily配置  在项目的 resource 新建文件名为: hmily.ym 配置文件。\n 具体的参数配置可以参考配置详解,本地配置模式, zookeeper配置模式, nacos配置模式,apollo配置模式\n  Grpc拦截器配置  在 grpc客户端中添加拦截器 GrpcHmilyTransactionFilter。 在 grpc服务端中添加拦截器 GrpcHmilyServerFilter。  Grpc客户端调用  使用GrpcHmilyClient代替原来的调用方式来进行远程调用。  AccountResponse response = GrpcHmilyClient.syncInvoke(accountServiceBlockingStub, \u0026amp;quot;payment\u0026amp;quot;, request, AccountResponse.class);  入参分别为被调用的AbstratcSub,方法名,具体的参数以及返回值类型\nTCC模式  对服务端事务方法的具体实现,加上@HmilyTCC(confirmMethod = \u0026amp;quot;confirm\u0026amp;quot;, cancelMethod = \u0026amp;quot;cancel\u0026amp;quot;)\n confirmMethod : 确认方法名称，该方法参数列表与返回类型应与标识方法一致。\n cancelMethod : 回滚方法名称，该方法参数列表与返回类型应与标识方法一致。\n TCC模式应该保证 confirm 和 cancel 方法的幂等性，用户需要自行去开发这个2个方法，所有的事务的确认与回滚，完全由用户决定。Hmily框架只是负责来进行调用\n  public class HelloServiceImpl implements HelloService { @HmilyTCC(confirmMethod = \u0026amp;quot;sayConfrim\u0026amp;quot;, cancelMethod = \u0026amp;quot;sayCancel\u0026amp;quot;) public void say(String hello) { System.out.println(\u0026amp;quot;hello world\u0026amp;quot;); } public void sayConfrim(String hello) { System.out.println(\u0026amp;quot; confirm hello world\u0026amp;quot;); } public void sayCancel(String hello) { System.out.println(\u0026amp;quot; cancel hello world\u0026amp;quot;); } }  重要注意事项 异常  try, confirm, cancel 方法的所有异常不要自行catch 任何异常都应该抛出给 Hmily框架处理。  ","date":-62135596800,"description":"Grpc用户指南","dir":"projects/hmily/user-grpc/","fuzzywordcount":800,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"7afe11acd39e52424c40f3d69baaee5b64d1b260","permalink":"/zh/projects/hmily/user-grpc/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/zh/projects/hmily/user-grpc/","summary":"Grpc用户指南 目前只支持grpc的一元同步调用 引入jar包 引入hmily配置 在具体的实现方法上（服务提供端），加上@HmilyTCC or HmilyTAC 注","tags":null,"title":"Grpc用户指南","type":"projects","url":"/zh/projects/hmily/user-grpc/","wordcount":728},{"author":null,"categories":null,"content":" @Hmily /** * The annotation Hmily. * * @author xiaoyu */ @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD) public @interface Hmily { }   This annotation is the interface identification of Hmily Distributed Transaction,it indicated that the interface participates in Hmily Distributed Transaction.  @HmilyTCC @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD) public @interface HmilyTCC { /** * Confirm method string. * * @return the string */ String confirmMethod() default \u0026amp;quot;\u0026amp;quot;; /** * Cancel method string. * * @return the string */ String cancelMethod() default \u0026amp;quot;\u0026amp;quot;; /** * Pattern pattern enum. * * @return the pattern enum */ TransTypeEnum pattern() default TransTypeEnum.TCC; }   This annotation is the AOP point of TCC Mode of Hmily Distributed Transaction,it can add on your local concrete implementation method.\n confirmMethod : to annotate the identification method,it is the method name for confirm,the method parameter list and return type should be consistent with the identification method.\n cancelMethod : to annotate the identification method,it is the method name for rollback,the method parameter list and return type should be consistent with the identification method.\n  @HmilyTAC /** * The annotation HmilyTAC. * * @author xiaoyu */ @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD) public @interface HmilyTAC { }   This annotation is the AOP point of TAC Mode of Hmily Distributed Transaction,it can add on your local concrete implementation method.  ","date":-62135596800,"description":"Hmily Annotation","dir":"projects/hmily/annotation/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"cc378a311c21863212efc93a2a93bd057682dc4d","permalink":"/projects/hmily/annotation/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/hmily/annotation/","summary":"@Hmily /** * The annotation Hmily. * * @author xiaoyu */ @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD) public @interface Hmily { }   This annotation is the interface identification of Hmily Distributed Transaction,it indicated that the interface participates in Hmily Distributed Transaction.  @HmilyTCC @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD) public @interface HmilyTCC { /** * Confirm method string. * * @return the string */ String confirmMethod() default \u0026quot;\u0026quot;; /** * Cancel method string. * * @return the string */ String cancelMethod() default \u0026quot;\u0026quot;; /** * Pattern pattern enum.","tags":null,"title":"Hmily Annotation","type":"projects","url":"/projects/hmily/annotation/","wordcount":203},{"author":null,"categories":null,"content":" What\u0026amp;rsquo;s Hmily？ Hmily is a high-performance, zero penetration, financial-level distributed transactions solution. At present, it mainly provides support for flexible transactions, including TCC, TAC (in which, it will automatically generate rollback SQL) schemes, and XA and more schemes will be supported in the future.\nFeatures  High reliability : It supports abnormal transaction rollback and transaction overtime abnormal recovery to prevent transaction suspension in distributed scenarios.\n Ease of use : It provides zero penetration Spring-Boot and Spring-Namespace schemes to integrate with business systems quickly.\n High performance : Decentralized design, fully integrated with business systems, and naturally supports cluster deployment.\n Observability : Performance monitoring of multiple metrics will be collected by Metrics, performance metrics is able to display in admin management system.\n Multiple RPC Framework support : It supports well-known RPC frameworks such as Dubbo, SpringCloud, Motan, brpc, tars, etc.\n Multiple log store medium support : It supports many mediums as log store, such as mysql, oracle, mongodb, redis, zookeeper, etc.\n Complex business scene : It supports transaction around nested RPC calls.\n  Requirements  The JDK version must be JDK8 or later.\n In TCC mode, you must use a RPC framework, such as: Dubbo, SpringCloud, Motan\n In TAC mode, you must use relational databases, such as: mysql, oracle, sqlsever\n  TCC Mode When using the TCC mode, you should provide three methods: try, confirm, and cancel according to your business requirements, and the confirm and cancel methods should be implemented by yourselves, the framework is only responsible for calling them to achieve transaction consistency.\nTAC Mode When using the TAC mode, you must use a relational database for business operations, and the framework will automatically generate a rollback SQL. When the business is abnormal, the rollback SQL will be executed to achieve transaction consistency\nAbout Hmily is a flexible distributed transaction solution that provides TCC and TAC modes.\nIt can be easily integrated by business with zero intrusion and rapid integration.\nIn terms of performance, log storage is asynchronous (optional) and uses asynchronous execution, without sacrificing business methods.\nIt was previously developed by myself personally, and it is currently restarted at JD Digital Technique Group, and it will become JD Digital Technique Group\u0026amp;rsquo;s distributed transaction solution in the future.\nSupport  If you have any questions, please join the QQ group for discussion  WeChat public account   ","date":-62135596800,"description":"Hmily is Finance-level distributed transaction solutions, Supports multiple RPC frameworks, such as Dubbo, SpringCloud, Motan, GRPC, BRPC, Tars.","dir":"projects/hmily/overview/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"fec43e953cf408372fd38c1ac35fe28e03498a87","permalink":"/projects/hmily/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/hmily/overview/","summary":"What\u0026rsquo;s Hmily？ Hmily is a high-performance, zero penetration, financial-level distributed transactions solution. At present, it mainly provides support for flexible transactions, including TCC, TAC (in which, it will automatically generate rollback SQL) schemes, and XA and more schemes will be supported in the future.\nFeatures  High reliability : It supports abnormal transaction rollback and transaction overtime abnormal recovery to prevent transaction suspension in distributed scenarios.\n Ease of use : It provides zero penetration Spring-Boot and Spring-Namespace schemes to integrate with business systems quickly.","tags":null,"title":"Hmily Introduction","type":"projects","url":"/projects/hmily/overview/","wordcount":381},{"author":null,"categories":null,"content":" Hmily Metrics At present,Prometheus is used to collect metrics in hmily\u0026amp;rsquo;s metrics module, and the pull mode is used to expose metrics information interface.\nThe metrics collected fall into two fundamental categories:\n JVM information to application: Memory, CPU, Thread Usage, etc.\n Transaction information: including the transactions total, the transaction latency, the transaction status, the transaction role.\n  Hmily Metrics in detail How to show  You can pull the metrics information from the metrics configuration of application via Grafana.  ","date":-62135596800,"description":"Hmily Metrics","dir":"projects/hmily/metrics/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"4c4b6e65e14fd62e4d5f788da6b34fd1ea415797","permalink":"/projects/hmily/metrics/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/hmily/metrics/","summary":"Hmily Metrics At present,Prometheus is used to collect metrics in hmily\u0026rsquo;s metrics module, and the pull mode is used to expose metrics information interface.\nThe metrics collected fall into two fundamental categories:\n JVM information to application: Memory, CPU, Thread Usage, etc.\n Transaction information: including the transactions total, the transaction latency, the transaction status, the transaction role.\n  Hmily Metrics in detail How to show  You can pull the metrics information from the metrics configuration of application via Grafana.","tags":null,"title":"Hmily Metrics","type":"projects","url":"/projects/hmily/metrics/","wordcount":77},{"author":null,"categories":null,"content":" Project members (the names not listed in order)    Name github Role Company     Xiao Yu yu199195 VP JD   Zhang Yong Lun tuohai666 committer JD   Zhao Jun cherrylzhao committer China Unicom   Chen Bin prFor committer A startup company   Jiang Xiao Feng SteNicholas committer Alibaba Cloud   Li Lang cysy-lli committer Ctrip   Tang Yu Dong tydhot committer perfma    ","date":-62135596800,"description":"Hmily Team","dir":"projects/hmily/team/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"4afc3096b5e7ebfbbce534349181a2684741f599","permalink":"/projects/hmily/team/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/hmily/team/","summary":" Project members (the names not listed in order)    Name github Role Company     Xiao Yu yu199195 VP JD   Zhang Yong Lun tuohai666 committer JD   Zhao Jun cherrylzhao committer China Unicom   Chen Bin prFor committer A startup company   Jiang Xiao Feng SteNicholas committer Alibaba Cloud   Li Lang cysy-lli committer Ctrip   Tang Yu Dong tydhot committer perfma    ","tags":null,"title":"Hmily Team","type":"projects","url":"/projects/hmily/team/","wordcount":54},{"author":null,"categories":null,"content":" Term  Initiator: The initiator of a global transaction, the first place where transactions need to be performed on distributed resources in a request link resource method. In the Hmily framework, it can be expressed as: a request first encounters @HmilyTCC or @HmilyTAC annotated method, the method which application belongs to is called the initiator.\n Participants: Distributed services or resources that need to participate in a distributed transaction scenario together with other services. In the Hmily framework, it\u0026amp;rsquo;s showed as an interface that appears as an RPC framework is annotated with @Hmily.\n Coordinator: The role used to coordinate distributed transactions is commit or rollback. It can be remote, local, centralized, or decentralized. The coordinator in the Hmily framework is a local decentralized role.\n TCC ：Abbreviation for the three stages of Try, Confirm, and Cancel.\n TAC ：Short for Try Auto Cancel. Hmily framework will automatically generate the reverse operation resource behavior after the resources are reserved in the Try stage.\n  ","date":-62135596800,"description":"Hmily Term","dir":"projects/hmily/term/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"8a2effa12db4953b22240e6ed435c0ca65d53304","permalink":"/projects/hmily/term/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/hmily/term/","summary":"Term  Initiator: The initiator of a global transaction, the first place where transactions need to be performed on distributed resources in a request link resource method. In the Hmily framework, it can be expressed as: a request first encounters @HmilyTCC or @HmilyTAC annotated method, the method which application belongs to is called the initiator.\n Participants: Distributed services or resources that need to participate in a distributed transaction scenario together with other services.","tags":null,"title":"Hmily Term","type":"projects","url":"/projects/hmily/term/","wordcount":158},{"author":null,"categories":null,"content":" Hmily Transaction Context @Data public class HmilyTransactionContext { /** * transId. */ private Long transId; /** * participant id. */ private Long participantId; /** * participant ref id. */ private Long participantRefId; /** * this hmily action. */ private int action; /** * Transaction Participant Role. */ private int role; /** * transType. */ private String transType; }  HmilyTransactionContext is the core class used by the Hmily distributed transaction framework to pass the transaction context when making RPC calls. it was stored in \u0026amp;lsquo;ThreadLocal\u0026amp;rsquo; by default and then do RPC parameter passing. You can also configure it to the scenarios that use thread context switching. the contextTransmittalMode = transmittable should be specified in the configuration at this point, then the Alibaba opensource library will be used.\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alibaba\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;transmittable-thread-local\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.11.5\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  Passing Transaction Context with Dubbo The concrete implementation class was in the org.dromara.hmily.dubbo.filter.DubboHmilyTransactionFilter class.， Please do RPC parameter passing through the RpcContext.getContext().setAttachment(String key, String value).\nPassing Transaction Context with Motan The concrete implementation class was in the org.dromara.hmily.motan.filter.MotanHmilyTransactionFilter class.， Please do RPC parameter passing through the Request.setAttachment(String key, String value).\nPassing Transaction Context with Spring Cloud The concrete implementation class was in the org.dromara.hmily.springcloud.feign.HmilyFeignInterceptor class.， Please do RPC parameter passing through the RequestTemplate.header(String name, String... values).\n","date":-62135596800,"description":"Hmily Transaction Context","dir":"projects/hmily/context/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"9acd1a365b116843583b688e98935383cb7e4b01","permalink":"/projects/hmily/context/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/hmily/context/","summary":"Hmily Transaction Context @Data public class HmilyTransactionContext { /** * transId. */ private Long transId; /** * participant id. */ private Long participantId; /** * participant ref id. */ private Long participantRefId; /** * this hmily action. */ private int action; /** * Transaction Participant Role. */ private int role; /** * transType. */ private String transType; }  HmilyTransactionContext is the core class used by the Hmily distributed transaction framework to pass the transaction context when making RPC calls.","tags":null,"title":"Hmily Transaction Context","type":"projects","url":"/projects/hmily/context/","wordcount":207},{"author":null,"categories":null,"content":" Hmily是什么？ Hmily是一款高性能，零侵入，金融级分布式事务解决方案，目前主要提供柔性事务的支持，包含 TCC, TAC(自动生成回滚SQL) 方案，未来还会支持 XA 等方案。\n功能  高可靠性 ：支持分布式场景下，事务异常回滚，超时异常恢复，防止事务悬挂。\n 易用性 ：提供零侵入性式的 Spring-Boot, Spring-Namespace 快速与业务系统集成。\n 高性能 ：去中心化设计，与业务系统完全融合，天然支持集群部署。\n 可观测性 ：Metrics多项指标性能监控，以及admin管理后台UI展示。\n 多种RPC ： 支持 Dubbo, SpringCloud,Motan, brpc, tars 等知名RPC框架。\n 日志存储 ： 支持 mysql, oracle, mongodb, redis, zookeeper 等方式。\n 复杂场景 ： 支持RPC嵌套调用事务。\n  必要前提  必须使用 JDK8+\n TCC模式下，用户必须要使用一款 RPC 框架, 比如 : Dubbo, SpringCloud,Motan\n TAC模式下，用户必须使用关系型数据库, 比如：mysql, oracle, sqlsever\n  TCC模式 当使用TCC模式的时候,用户根据自身业务需求提供 try, confirm, cancel 等三个方法， 并且 confirm, cancel 方法由自身完成实现，框架只是负责来调用，来达到事务的一致性。\nTAC模式 当用户使用TAC模式的时候，用户必须使用关系型数据库来进行业务操作，框架会自动生成回滚SQL, 当业务异常的时候，会执行回滚SQL来达到事务的一致性\n关于Hmily Hmily是柔性分布式事务解决方案，提供了TCC 与 TAC 模式。\n它以零侵入以及快速集成方式能够方便的被业务进行整合。\n在性能上，日志存储异步（可选）以及使用异步执行的方式，不损耗业务方法方法。\n之前是由我个人开发，目前在京东数科重启，未来会成为京东数科的分布式事务解决方案。\n技术支持  如有任何问题欢迎加入QQ群进行讨论  微信公众号   ","date":-62135596800,"description":"Hmily是一款高性能，零侵入，柔性分布式事务解决方案，目前主要提供柔性事务的支持，包含 TCC, TAC(自动生成回滚SQL) 方案，未来还会支持 XA 等方案。","dir":"projects/hmily/overview/","fuzzywordcount":700,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"46a4aceb75e37af1f4a763b390695a17c3117b9c","permalink":"/zh/projects/hmily/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/zh/projects/hmily/overview/","summary":"Hmily是什么？ Hmily是一款高性能，零侵入，金融级分布式事务解决方案，目前主要提供柔性事务的支持，包含 TCC, TAC(自动生成回滚SQL) 方","tags":null,"title":"Hmily 介绍","type":"projects","url":"/zh/projects/hmily/overview/","wordcount":645},{"author":null,"categories":null,"content":" Hmily-Admin startup tutorial (not completed）:  Admin is the background management system for viewing transaction logs in Hmily. It has many features, Such as viewing abnormal logs, modifying the number of retries and so on.\n First, make sure that your project is using Hmily and is running properly.\n Second, the JDK used by the user must be 1.8+. Git and Maven are installed locally, then execute the following command\n  Step 2：Modify index.html under the static folder of your project \u0026amp;lt;!--href use your ip and port--\u0026amp;gt; \u0026amp;lt;a id=\u0026amp;quot;serverIpAddress\u0026amp;quot; style=\u0026amp;quot;display: none\u0026amp;quot; href=\u0026amp;quot;http://192.168.1.132:8888/admin\u0026amp;quot;\u0026amp;gt;  Step 3: Run the main method in AdminApplication Step 4: Visit http://ip:port/tcc-admin/index.html in the browser, then enter the user name and password to login. If you have any questions, please join the QQ group: 162614487 for discussion ","date":-62135596800,"description":"Hmily-Admin","dir":"projects/hmily/admin/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"8936d55c5158db1fe822580a6e6b743dd0ecea27","permalink":"/projects/hmily/admin/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/hmily/admin/","summary":"Hmily-Admin startup tutorial (not completed）:  Admin is the background management system for viewing transaction logs in Hmily. It has many features, Such as viewing abnormal logs, modifying the number of retries and so on.\n First, make sure that your project is using Hmily and is running properly.\n Second, the JDK used by the user must be 1.8+. Git and Maven are installed locally, then execute the following command","tags":null,"title":"Hmily-Admin","type":"projects","url":"/projects/hmily/admin/","wordcount":126},{"author":null,"categories":null,"content":" Hmily-Admin 启动教程（未完成）:  admin 是Hmily中查看事务日志的后台管理系统。 可以查看异常的日志，修改重试次数等功能.\n 首先确保你的项目使用了Hmily并且正常运行.\n 首先用户使用的JDK必须是1.8+ 本地安装了git ,maven ，执行以下命令\n  步骤二：修改本项目static 文件夹下的 index.html \u0026amp;lt;!--href 修改成你的ip 端口--\u0026amp;gt; \u0026amp;lt;a id=\u0026amp;quot;serverIpAddress\u0026amp;quot; style=\u0026amp;quot;display: none\u0026amp;quot; href=\u0026amp;quot;http://192.168.1.132:8888/admin\u0026amp;quot;\u0026amp;gt;  步骤三: 运行 AdminApplication 中的main方法。 步骤四:在浏览器访问 http://ip:port/tcc-admin/index.html ,输入用户名，密码登录。 如有任何问题欢迎加入QQ群：162614487 进行讨论 ","date":-62135596800,"description":"Hmily-Admin","dir":"projects/hmily/admin/","fuzzywordcount":300,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"e5f34864c9cfe26307b520e9c74d5fefb6b1ea73","permalink":"/zh/projects/hmily/admin/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/zh/projects/hmily/admin/","summary":"Hmily-Admin 启动教程（未完成）: admin 是Hmily中查看事务日志的后台管理系统。 可以查看异常的日志，修改重试次数等功能. 首先确保你的项目使用了Hmily并","tags":null,"title":"Hmily-Admin","type":"projects","url":"/zh/projects/hmily/admin/","wordcount":217},{"author":null,"categories":null,"content":" Configuration Detail：  File Name: hmily.yml。\n Path： The default path is the resource directory of the project, which can be specified by -Dhmily.conf, and you can also put the configuration in user.dir directory. Priority: -Dhmily.conf \u0026amp;gt; user.dir \u0026amp;gt; resource\n  hmily: server: configMode: local appName: xiaoyu # The following configuration will be read when server.configMode equals local config: appName: xiaoyu serializer: kryo contextTransmittalMode: threadLocal scheduledThreadMax: 16 scheduledRecoveryDelay: 60 scheduledCleanDelay: 60 scheduledPhyDeletedDelay: 600 scheduledInitDelay: 30 recoverDelayTime: 60 cleanDelayTime: 180 limit: 200 retryMax: 10 bufferSize: 8192 consumerThreads: 16 asyncRepository: true autoSql: true phyDeleted: true storeDays: 3 repository: mysql repository: database: driverClassName: com.mysql.jdbc.Driver url : username: password: maxActive: 20 minIdle: 10 connectionTimeout: 30000 idleTimeout: 600000 maxLifetime: 1800000 file: path: prefix: /hmily mongo: databaseName: url: userName: password: zookeeper: host: localhost:2181 sessionTimeOut: 1000 rootPath: /hmily redis: cluster: false sentinel: false clusterUrl: sentinelUrl: masterName: hostName: port: password: maxTotal: 8 maxIdle: 8 minIdle: 2 maxWaitMillis: -1 minEvictableIdleTimeMillis: 1800000 softMinEvictableIdleTimeMillis: 1800000 numTestsPerEvictionRun: 3 testOnCreate: false testOnBorrow: false testOnReturn: false testWhileIdle: false timeBetweenEvictionRunsMillis: -1 blockWhenExhausted: true timeOut: 1000 metrics: metricsName: prometheus host: port: 9091 async: true threadCount : 16 jmxConfig:  Hmily.server Configuration    Name Type Default Required Description     configMode String local yes Configuration mode supports local,zookeeper,nacos, and apollo now. If configuration is local, it will read the configuration from yml file;If the configuration is other modes, it will get the configuration form configuration centre.   appName String null yes Application name. AppName will be overwritten if also configured in hmilyConfig.    Hmily.config Configuration  This is the core configuration of the whole framework     Name Type Default Required Description     appName String null yes It filled in your Microservices application\u0026amp;rsquo;s name generally, but don\u0026amp;rsquo;t repeat it   serializer String kryo no This is mode of serializing the specified transaction log，and currently supports filling in kryo, hessian, jdk, jdk, protostuff   contextTransmittalMode String threadLocal no This is the mode of transaction context transfer, and currently supports filling in threadLocal, transmittable (Cross-thread mode)   scheduledThreadMax int CPU * 2 no Maximum number of scheduled threads   scheduledRecoveryDelay int(unit:sec) 60 no Scheduling cycle of auto recovering transaction log   scheduledCleanDelay int(unit:sec) 60 no Scheduling cycle of cleaning transaction log   scheduledPhyDeletedDelay int(unit:sec) 60 no Scheduling cycle of deleting transaction log   scheduledInitDelay …","date":-62135596800,"description":"Hmily Configuration Detail","dir":"projects/hmily/config/","fuzzywordcount":1300,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"804b328f2572d7025e5b3f9de603971d5b754357","permalink":"/projects/hmily/config/","publishdate":"0001-01-01T00:00:00Z","readingtime":6,"relpermalink":"/projects/hmily/config/","summary":"Configuration Detail：  File Name: hmily.yml。\n Path： The default path is the resource directory of the project, which can be specified by -Dhmily.conf, and you can also put the configuration in user.dir directory. Priority: -Dhmily.conf \u0026gt; user.dir \u0026gt; resource\n  hmily: server: configMode: local appName: xiaoyu # The following configuration will be read when server.configMode equals local config: appName: xiaoyu serializer: kryo contextTransmittalMode: threadLocal scheduledThreadMax: 16 scheduledRecoveryDelay: 60 scheduledCleanDelay: 60 scheduledPhyDeletedDelay: 600 scheduledInitDelay: 30 recoverDelayTime: 60 cleanDelayTime: 180 limit: 200 retryMax: 10 bufferSize: 8192 consumerThreads: 16 asyncRepository: true autoSql: true phyDeleted: true storeDays: 3 repository: mysql repository: database: driverClassName: com.","tags":null,"title":"Hmily-Config","type":"projects","url":"/projects/hmily/config/","wordcount":1250},{"author":null,"categories":null,"content":" 配置详解：  文件名为 : hmily.yml。\n 路径： 默认路径为项目的 resource目录下，也可以使用 -Dhmily.conf 指定，也可以把配置放在 user.dir 目录下。 优先级别 -Dhmily.conf \u0026amp;gt; user.dir \u0026amp;gt; resource\n  hmily: server: configMode: local appName: xiaoyu # 如果server.configMode eq local 的时候才会读取到这里的配置信息. config: appName: xiaoyu serializer: kryo contextTransmittalMode: threadLocal scheduledThreadMax: 16 scheduledRecoveryDelay: 60 scheduledCleanDelay: 60 scheduledPhyDeletedDelay: 600 scheduledInitDelay: 30 recoverDelayTime: 60 cleanDelayTime: 180 limit: 200 retryMax: 10 bufferSize: 8192 consumerThreads: 16 asyncRepository: true autoSql: true phyDeleted: true storeDays: 3 repository: mysql repository: database: driverClassName: com.mysql.jdbc.Driver url : username: password: maxActive: 20 minIdle: 10 connectionTimeout: 30000 idleTimeout: 600000 maxLifetime: 1800000 file: path: prefix: /hmily mongo: databaseName: url: userName: password: zookeeper: host: localhost:2181 sessionTimeOut: 1000 rootPath: /hmily redis: cluster: false sentinel: false clusterUrl: sentinelUrl: masterName: hostName: port: password: maxTotal: 8 maxIdle: 8 minIdle: 2 maxWaitMillis: -1 minEvictableIdleTimeMillis: 1800000 softMinEvictableIdleTimeMillis: 1800000 numTestsPerEvictionRun: 3 testOnCreate: false testOnBorrow: false testOnReturn: false testWhileIdle: false timeBetweenEvictionRunsMillis: -1 blockWhenExhausted: true timeOut: 1000 metrics: metricsName: prometheus host: port: 9091 async: true threadCount : 16 jmxConfig:  hmily.server配置    名称 类型 默认值 是否必填 说明     configMode String local 必填 配置模式，现在支持local,zookeeper,nacos,apollo,配置为local，则会读取yml文件里的配置，其他模式，则会读取配置中心的   appName String 无 必填 应用的名称，如果hmilyConfig中也配置了appName则会覆盖此配置    hmily.config配置  这是整个框架的核心配置     名称 类型 默认值 是否必填 说明     appName String 无 必填 一般填你微服务的应用名称，请不要重复   serializer String kryo 非必填 这是指定事务日志的序列化方式，目前支持填写 kryo, hessian, jdk, protostuff   contextTransmittalMode String threadLocal 非必填 这是事务上下文传递的模式，目前支持填写 threadLocal, transmittable (跨线程模式)   scheduledThreadMax int CPU * 2 非必填 调度线程数最大线程数量   scheduledRecoveryDelay int(单位:秒) 60 非必填 事务日志自动恢复调度周期   scheduledCleanDelay int(单位:秒) 60 非必填 事务日志清理调度周期   scheduledPhyDeletedDelay int(单位:秒) 60 非必填 事务日志物理删除调度周期   scheduledInitDelay int(单位:秒) 30 非必填 调度任务启动延迟时间   recoverDelayTime int(单位:秒) 60 非必填 事务日志恢复迟延时间   cleanDelayTime int(单位:秒) 60 非必填 事务日志清理迟延时间   limit int 100 非必填 获取事务日志行数大小   retryMax int 10 非必填 最大重试次数   bufferSize int 4096 * 2 * 2 非必填 disruptor的bufferSize大小   consumerThreads int CPU * 2 非必填 disruptor消费者线程数量   asyncRepository boolean true 非必填 是否异步存储事务日志，设置为false则为同步   autoSql boolean true 非必填 是否自动执行框架自动建库建表SQL语句（如果已经创建可以设置为false）   phyDeleted boolean true 非必填 在运行过程中，是否物理删除日志。设置为false，则只会更改日志状态   storeDays int(单位:天) 3 非必填 如果 phyDeleted 设置为false的时候，日志存储天数   repository String mysql 必填 这是指定事务日志的存储方式，目前支持填写 mysql, oracle, postgresql, sqlserver, mongo, redis, file    repository配置 repository是Hmily用来存储事务日志的配置，目前支持:database(mysql, oracle, postgresql, sqlserver), file(本地模式，测试，开发环境用), mongodb, zookeeper, redis。\n database配置(默认使用hikari连接池):     名称 类型 默 …","date":-62135596800,"description":"Hmily配置详解","dir":"projects/hmily/config/","fuzzywordcount":2600,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"f93094e1975f84f81110b43c7fa410e104326e41","permalink":"/zh/projects/hmily/config/","publishdate":"0001-01-01T00:00:00Z","readingtime":6,"relpermalink":"/zh/projects/hmily/config/","summary":"配置详解： 文件名为 : hmily.yml。 路径： 默认路径为项目的 resource目录下，也可以使用 -Dhmily.conf 指定，也可以把配置放在 user.dir 目录下。 优先级别 -Dhmily.conf","tags":null,"title":"Hmily-Config","type":"projects","url":"/zh/projects/hmily/config/","wordcount":2581},{"author":null,"categories":null,"content":" Local Configuration  File Name : hmily.yml.\n Path： The default path is the resource directory of the project, which can be specified by -Dhmily.conf, and you can also put the configuration in user.dir directory. Priority: -Dhmily.conf \u0026amp;gt; user.dir \u0026amp;gt; resource\n The specific contents are as follows : Notice setting hmily.server.configMode = apollo\n The framework will pull the configuration according to your configured apollo.\n  hmily: server: configMode: apollo appName: # The following configuration will be read when server.configMode equals apollo. remote: apollo: configService: 127.0.0.1:8080 # apollo service address namespace: test # namespace appId: test # group secret: xxxx # the secret key env: dev # environment fileExtension: yml # format of configuration file of apollo (properties or yml）   You can add configurations in apollo, and the format is as follows(yml):  hmily: config: appName: xiaoyu serializer: kryo contextTransmittalMode: threadLocal scheduledThreadMax: 16 scheduledRecoveryDelay: 60 scheduledCleanDelay: 60 scheduledPhyDeletedDelay: 600 scheduledInitDelay: 30 recoverDelayTime: 60 cleanDelayTime: 180 limit: 200 retryMax: 10 bufferSize: 8192 consumerThreads: 16 asyncRepository: true autoSql: true phyDeleted: true storeDays: 3 repository: mysql repository: database: driverClassName: com.mysql.jdbc.Driver url : username: password: maxActive: 20 minIdle: 10 connectionTimeout: 30000 idleTimeout: 600000 maxLifetime: 1800000 file: path: prefix: /hmily mongo: databaseName: url: userName: password: zookeeper: host: localhost:2181 sessionTimeOut: 1000 rootPath: /hmily redis: cluster: false sentinel: false clusterUrl: sentinelUrl: masterName: hostName: port: password: maxTotal: 8 maxIdle: 8 minIdle: 2 maxWaitMillis: -1 minEvictableIdleTimeMillis: 1800000 softMinEvictableIdleTimeMillis: 1800000 numTestsPerEvictionRun: 3 testOnCreate: false testOnBorrow: false testOnReturn: false testWhileIdle: false timeBetweenEvictionRunsMillis: -1 blockWhenExhausted: true timeOut: 1000 metrics: metricsName: prometheus host: port: 9091 async: true threadCount : 16 jmxConfig:   Notice that the configurations of repository are extensions of SPI, you can select one from those modes, which don\u0026amp;rsquo;t have to be configured all.\n metrics is optional; If it is not configured，it means you don\u0026amp;rsquo;t enable metrics.\n  ","date":-62135596800,"description":"apollo configuration centre mode","dir":"projects/hmily/config-apollo/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"d91a7edb345962c1d8a6d96faf463f62f9fcf452","permalink":"/projects/hmily/config-apollo/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/hmily/config-apollo/","summary":"Local Configuration  File Name : hmily.yml.\n Path： The default path is the resource directory of the project, which can be specified by -Dhmily.conf, and you can also put the configuration in user.dir directory. Priority: -Dhmily.conf \u0026gt; user.dir \u0026gt; resource\n The specific contents are as follows : Notice setting hmily.server.configMode = apollo\n The framework will pull the configuration according to your configured apollo.\n  hmily: server: configMode: apollo appName: # The following configuration will be read when server.","tags":null,"title":"Hmily-Config-Apollo","type":"projects","url":"/projects/hmily/config-apollo/","wordcount":290},{"author":null,"categories":null,"content":" 本地配置  文件名为 : hmily.yml。\n 路径： 默认路径为项目的 resource目录下，也可以使用 -Dhmily.conf 指定，也可以把配置放在 user.dir 目录下。 优先级别 -Dhmily.conf \u0026amp;gt; user.dir \u0026amp;gt; resource\n 具体的全内容如下 : 注意设置 hmily.server.configMode = apollo\n 框架的或首先根据你的 apollo 配置，然后从 apollo 获取配置\n  hmily: server: configMode: apollo appName: # 如果server.configMode eq local 的时候才会读取到这里的配置信息. remote: apollo: configService: 127.0.0.1:8080 # apollo服务地址 namespace: test # namespace appId: test # group secret: xxxx #秘钥 env: dev #环境 fileExtension: yml #apollo上配置文件的格式（properties或者yml）二选一   然后，你可以在apollo上添加配置，配置格式如果下（yml）：  hmily: config: appName: xiaoyu serializer: kryo contextTransmittalMode: threadLocal scheduledThreadMax: 16 scheduledRecoveryDelay: 60 scheduledCleanDelay: 60 scheduledPhyDeletedDelay: 600 scheduledInitDelay: 30 recoverDelayTime: 60 cleanDelayTime: 180 limit: 200 retryMax: 10 bufferSize: 8192 consumerThreads: 16 asyncRepository: true autoSql: true phyDeleted: true storeDays: 3 repository: mysql repository: database: driverClassName: com.mysql.jdbc.Driver url : username: password: maxActive: 20 minIdle: 10 connectionTimeout: 30000 idleTimeout: 600000 maxLifetime: 1800000 file: path: prefix: /hmily mongo: databaseName: url: userName: password: zookeeper: host: localhost:2181 sessionTimeOut: 1000 rootPath: /hmily redis: cluster: false sentinel: false clusterUrl: sentinelUrl: masterName: hostName: port: password: maxTotal: 8 maxIdle: 8 minIdle: 2 maxWaitMillis: -1 minEvictableIdleTimeMillis: 1800000 softMinEvictableIdleTimeMillis: 1800000 numTestsPerEvictionRun: 3 testOnCreate: false testOnBorrow: false testOnReturn: false testWhileIdle: false timeBetweenEvictionRunsMillis: -1 blockWhenExhausted: true timeOut: 1000 metrics: metricsName: prometheus host: port: 9091 async: true threadCount : 16 jmxConfig:   注意 repository的配置是SPI的扩展方式，几种方式由你去选择一种，并不需要全部配置。\n metrics 配置可有可无，如果不配置，则代表不开启metrics\n  ","date":-62135596800,"description":"apollo配置中心模式","dir":"projects/hmily/config-apollo/","fuzzywordcount":500,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"91cb3b81a29cb5bdfd81452ba09f82784c93b473","permalink":"/zh/projects/hmily/config-apollo/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/zh/projects/hmily/config-apollo/","summary":"本地配置 文件名为 : hmily.yml。 路径： 默认路径为项目的 resource目录下，也可以使用 -Dhmily.conf 指定，也可以把配置放在 user.dir 目录下。 优先级别 -Dhmily.conf \u0026gt;","tags":null,"title":"Hmily-Config-Apollo","type":"projects","url":"/zh/projects/hmily/config-apollo/","wordcount":454},{"author":null,"categories":null,"content":" Local Configuration  File Name: hmily.yml。\n Path: The default path is the resource directory of the project, which can be specified by -Dhmily.conf, and you can also put the configuration in user.dir directory. Priority: -Dhmily.conf \u0026amp;gt; user.dir \u0026amp;gt; resource\n The specific contents are as follows : Notice setting hmily.server.configMode = consul\n The framework will pull the configuration according to your configured consul.\n  hmily: server: configMode: consul appName: xxxxx remote: consul: hostAndPort: 127.0.0.1:8500 # consul service address hostAndPorts: key: test # the key of consul blacklistTimeInMillis: 6000 fileExtension: yml # the format of the configuration of consul (properties or yml) passive: true # enable automatic update   Pay attention to consul service address configuration, if it is cluster, please configure hostAndPorts Nodes, configure hostAndPort to standalone mode. You have to set one of them, if the two is empty, it will adopt cluster configuration.\n And you need to add hmily configuration in the above configured key, the configuration is as follows:\n  hmily: config: appName: serializer: kryo contextTransmittalMode: threadLocal scheduledThreadMax: 16 scheduledRecoveryDelay: 60 scheduledCleanDelay: 60 scheduledPhyDeletedDelay: 600 scheduledInitDelay: 30 recoverDelayTime: 60 cleanDelayTime: 180 limit: 200 retryMax: 10 bufferSize: 8192 consumerThreads: 16 asyncRepository: true autoSql: true phyDeleted: true storeDays: 3 repository: mysql repository: database: driverClassName: com.mysql.jdbc.Driver url : username: password: maxActive: 20 minIdle: 10 connectionTimeout: 30000 idleTimeout: 600000 maxLifetime: 1800000 file: path: prefix: /hmily mongo: databaseName: url: userName: password: zookeeper: host: localhost:2181 sessionTimeOut: 1000 rootPath: /hmily redis: cluster: false sentinel: false clusterUrl: sentinelUrl: masterName: hostName: port: password: maxTotal: 8 maxIdle: 8 minIdle: 2 maxWaitMillis: -1 minEvictableIdleTimeMillis: 1800000 softMinEvictableIdleTimeMillis: 1800000 numTestsPerEvictionRun: 3 testOnCreate: false testOnBorrow: false testOnReturn: false testWhileIdle: false timeBetweenEvictionRunsMillis: -1 blockWhenExhausted: true timeOut: 1000 metrics: metricsName: prometheus host: port: 9091 async: true threadCount : 16 jmxConfig:   Notice that the configurations of repository are extensions of SPI, you can select one from those modes, which don\u0026amp;rsquo;t have to be configured all.\n metrics is optional; If it is not configured，it means you don\u0026amp;rsquo;t enable metrics.\n  ","date":-62135596800,"description":"Consul configuration centre mode","dir":"projects/hmily/config-consul/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"abc89c1124b74c3f71261de7a77f2bf69b2369e3","permalink":"/projects/hmily/config-consul/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/hmily/config-consul/","summary":"Local Configuration  File Name: hmily.yml。\n Path: The default path is the resource directory of the project, which can be specified by -Dhmily.conf, and you can also put the configuration in user.dir directory. Priority: -Dhmily.conf \u0026gt; user.dir \u0026gt; resource\n The specific contents are as follows : Notice setting hmily.server.configMode = consul\n The framework will pull the configuration according to your configured consul.\n  hmily: server: configMode: consul appName: xxxxx remote: consul: hostAndPort: 127.","tags":null,"title":"Hmily-Config-Consul","type":"projects","url":"/projects/hmily/config-consul/","wordcount":319},{"author":null,"categories":null,"content":" 本地配置  文件名为 : hmily.yml。\n 路径： 默认路径为项目的 resource目录下，也可以使用 -Dhmily.conf 指定，也可以把配置放在 user.dir 目录下。 优先级别 -Dhmily.conf \u0026amp;gt; user.dir \u0026amp;gt; resource\n 具体的全内容如下 : 注意设置 hmily.server.configMode = consul\n 框架的或首先根据你的 consul 配置，然后从 consul 获取配置\n  hmily: server: configMode: consul appName: xxxxx remote: consul: hostAndPort: 127.0.0.1:8500 # consul服务地址 hostAndPorts: key: test # consul 上的key blacklistTimeInMillis: 6000 fileExtension: yml # consul上配置文件的格式（properties或者yml）二选一 passive: true # 开启自动更新   注意consul服务地址配置，如果是集群，那么请配置hostAndPorts节点，单击配置hostAndPort，两者必须有一个不为空。两者都不为空，采用的是集群配置\n 然后，你需要在上述配置的key上写入hmily的配置，配置文件如下：\n  hmily: config: appName: serializer: kryo contextTransmittalMode: threadLocal scheduledThreadMax: 16 scheduledRecoveryDelay: 60 scheduledCleanDelay: 60 scheduledPhyDeletedDelay: 600 scheduledInitDelay: 30 recoverDelayTime: 60 cleanDelayTime: 180 limit: 200 retryMax: 10 bufferSize: 8192 consumerThreads: 16 asyncRepository: true autoSql: true phyDeleted: true storeDays: 3 repository: mysql repository: database: driverClassName: com.mysql.jdbc.Driver url : username: password: maxActive: 20 minIdle: 10 connectionTimeout: 30000 idleTimeout: 600000 maxLifetime: 1800000 file: path: prefix: /hmily mongo: databaseName: url: userName: password: zookeeper: host: localhost:2181 sessionTimeOut: 1000 rootPath: /hmily redis: cluster: false sentinel: false clusterUrl: sentinelUrl: masterName: hostName: port: password: maxTotal: 8 maxIdle: 8 minIdle: 2 maxWaitMillis: -1 minEvictableIdleTimeMillis: 1800000 softMinEvictableIdleTimeMillis: 1800000 numTestsPerEvictionRun: 3 testOnCreate: false testOnBorrow: false testOnReturn: false testWhileIdle: false timeBetweenEvictionRunsMillis: -1 blockWhenExhausted: true timeOut: 1000 metrics: metricsName: prometheus host: port: 9091 async: true threadCount : 16 jmxConfig:   注意 repository的配置是SPI的扩展方式，几种方式由你去选择一种，并不需要全部配置。\n metrics 配置可有可无，如果不配置，则代表不开启metrics\n  ","date":-62135596800,"description":"Consul配置中心模式","dir":"projects/hmily/config-consul/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"85741609640c91f8859af7db5a4cb7347f569c42","permalink":"/zh/projects/hmily/config-consul/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/zh/projects/hmily/config-consul/","summary":"本地配置 文件名为 : hmily.yml。 路径： 默认路径为项目的 resource目录下，也可以使用 -Dhmily.conf 指定，也可以把配置放在 user.dir 目录下。 优先级别 -Dhmily.conf \u0026gt;","tags":null,"title":"Hmily-Config-Consul","type":"projects","url":"/zh/projects/hmily/config-consul/","wordcount":504},{"author":null,"categories":null,"content":" Local Configuration  File Name: hmily.yml.\n Path: The default path is the resource directory of the project, which can be specified by -Dhmily.conf, and you can also put the configuration in user.dir directory. Priority: -Dhmily.conf \u0026amp;gt; user.dir \u0026amp;gt; resource\n The specific contents are as follows : Notice setting hmily.server.configMode = etcd\n The framework will pull the configuration according to your configured etcd.\n  hmily: server: configMode: etcd appName: xxxxx # The following configuration will be read when server.configMode equals etcd. remote: etcd: server: http://127.0.0.1:2379 # etcd service address key: test # key of etcd timeoutMs: 6000 fileExtension: yml # format of configuration of etcd (properties or yml) update : # Default is false，whether need to write local configuration file to zookeeper updateFileName: # when update is true, name of configuration file, which located in the yaml file of resource directory of the project位于项目的 resource文件夹下的yaml格式   And you need to add hmily configuration in the above configured key, the context is as follows:  hmily: config: appName: serializer: kryo contextTransmittalMode: threadLocal scheduledThreadMax: 16 scheduledRecoveryDelay: 60 scheduledCleanDelay: 60 scheduledPhyDeletedDelay: 600 scheduledInitDelay: 30 recoverDelayTime: 60 cleanDelayTime: 180 limit: 200 retryMax: 10 bufferSize: 8192 consumerThreads: 16 asyncRepository: true autoSql: true phyDeleted: true storeDays: 3 repository: mysql repository: database: driverClassName: com.mysql.jdbc.Driver url : username: password: maxActive: 20 minIdle: 10 connectionTimeout: 30000 idleTimeout: 600000 maxLifetime: 1800000 file: path: prefix: /hmily mongo: databaseName: url: userName: password: zookeeper: host: localhost:2181 sessionTimeOut: 1000 rootPath: /hmily redis: cluster: false sentinel: false clusterUrl: sentinelUrl: masterName: hostName: port: password: maxTotal: 8 maxIdle: 8 minIdle: 2 maxWaitMillis: -1 minEvictableIdleTimeMillis: 1800000 softMinEvictableIdleTimeMillis: 1800000 numTestsPerEvictionRun: 3 testOnCreate: false testOnBorrow: false testOnReturn: false testWhileIdle: false timeBetweenEvictionRunsMillis: -1 blockWhenExhausted: true timeOut: 1000 metrics: metricsName: prometheus host: port: 9091 async: true threadCount : 16 jmxConfig:   Notice that the configurations of repository are extensions of SPI, you can select one from those modes, which don\u0026amp;rsquo;t have to be configured all.\n metrics is optional; If it is not configured，it means you don\u0026amp;rsquo;t enable metrics.\n  ","date":-62135596800,"description":"etcd configuration centre mode","dir":"projects/hmily/config-etcd/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"57f4adcc91ac3307f201f834e55e206d761567e0","permalink":"/projects/hmily/config-etcd/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/hmily/config-etcd/","summary":"Local Configuration File Name: hmily.yml. Path: The default path is the resource directory of the project, which can be specified by -Dhmily.conf, and you can also put the configuration in user.dir directory. Priority: -Dhmily.conf \u0026gt; user.dir \u0026gt; resource The specific contents are as follows : Notice setting hmily.server.configMode = etcd The framework will pull the configuration according to your configured etcd. hmily: server: configMode: etcd appName: xxxxx # The following","tags":null,"title":"Hmily-Config-Etcd","type":"projects","url":"/projects/hmily/config-etcd/","wordcount":373},{"author":null,"categories":null,"content":" 本地配置  文件名为 : hmily.yml。\n 路径： 默认路径为项目的 resource目录下，也可以使用 -Dhmily.conf 指定，也可以把配置放在 user.dir 目录下。 优先级别 -Dhmily.conf \u0026amp;gt; user.dir \u0026amp;gt; resource\n 具体的全内容如下 : 注意设置 hmily.server.configMode = etcd\n 框架的或首先根据你的 etcd 配置，然后从 etcd 获取配置\n  hmily: server: configMode: etcd appName: xxxxx # 如果server.configMode eq local 的时候才会读取到这里的配置信息. remote: etcd: server: http://127.0.0.1:2379 # etcd服务地址 key: test # etcd 上的key， timeoutMs: 6000 fileExtension: yml #etcd上配置文件的格式（properties或者yml）二选一 update : #默认是false ，是否需要将本地的配置文件写到zookeeper updateFileName: #update属性为true时候 ，配置文件名称，位于项目的 resource文件夹下的yaml格式   然后，你需要在上述配置的key上写入hmily的配置，配置文件如下：  hmily: config: appName: serializer: kryo contextTransmittalMode: threadLocal scheduledThreadMax: 16 scheduledRecoveryDelay: 60 scheduledCleanDelay: 60 scheduledPhyDeletedDelay: 600 scheduledInitDelay: 30 recoverDelayTime: 60 cleanDelayTime: 180 limit: 200 retryMax: 10 bufferSize: 8192 consumerThreads: 16 asyncRepository: true autoSql: true phyDeleted: true storeDays: 3 repository: mysql repository: database: driverClassName: com.mysql.jdbc.Driver url : username: password: maxActive: 20 minIdle: 10 connectionTimeout: 30000 idleTimeout: 600000 maxLifetime: 1800000 file: path: prefix: /hmily mongo: databaseName: url: userName: password: zookeeper: host: localhost:2181 sessionTimeOut: 1000 rootPath: /hmily redis: cluster: false sentinel: false clusterUrl: sentinelUrl: masterName: hostName: port: password: maxTotal: 8 maxIdle: 8 minIdle: 2 maxWaitMillis: -1 minEvictableIdleTimeMillis: 1800000 softMinEvictableIdleTimeMillis: 1800000 numTestsPerEvictionRun: 3 testOnCreate: false testOnBorrow: false testOnReturn: false testWhileIdle: false timeBetweenEvictionRunsMillis: -1 blockWhenExhausted: true timeOut: 1000 metrics: metricsName: prometheus host: port: 9091 async: true threadCount : 16 jmxConfig:   注意 repository的配置是SPI的扩展方式，几种方式由你去选择一种，并不需要全部配置。\n metrics 配置可有可无，如果不配置，则代表不开启metrics\n  ","date":-62135596800,"description":"etcd配置中心模式","dir":"projects/hmily/config-etcd/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"8652aa886d5e2b29ed194226bad81dbf77109af3","permalink":"/zh/projects/hmily/config-etcd/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/zh/projects/hmily/config-etcd/","summary":"本地配置 文件名为 : hmily.yml。 路径： 默认路径为项目的 resource目录下，也可以使用 -Dhmily.conf 指定，也可以把配置放在 user.dir 目录下。 优先级别 -Dhmily.conf \u0026gt;","tags":null,"title":"Hmily-Config-Etcd","type":"projects","url":"/zh/projects/hmily/config-etcd/","wordcount":530},{"author":null,"categories":null,"content":" Local Configuration  File Name: hmily.yml。\n Path： The default path is the resource directory of the project, which can be specified by -Dhmily.conf, and you can also put the configuration in user.dir directory. Priority: -Dhmily.conf \u0026amp;gt; user.dir \u0026amp;gt; resource\n The specific contents are as follows : Notice setting hmily.server.configMode = local\n All configurations of the framework base on your local configuration files.\n Notice that the configurations of repository are extensions of SPI, you can select one from those modes, which don\u0026amp;rsquo;t have to be configured all.\n metrics is optional; If it is not configured，it means you don\u0026amp;rsquo;t enable metrics.\n  hmily: server: configMode: local appName: # The following configuration will be read when server.configMode equals local config: appName: xiaoyu serializer: kryo contextTransmittalMode: threadLocal scheduledThreadMax: 16 scheduledRecoveryDelay: 60 scheduledCleanDelay: 60 scheduledPhyDeletedDelay: 600 scheduledInitDelay: 30 recoverDelayTime: 60 cleanDelayTime: 180 limit: 200 retryMax: 10 bufferSize: 8192 consumerThreads: 16 asyncRepository: true autoSql: true phyDeleted: true storeDays: 3 repository: mysql repository: database: driverClassName: com.mysql.jdbc.Driver url : username: password: maxActive: 20 minIdle: 10 connectionTimeout: 30000 idleTimeout: 600000 maxLifetime: 1800000 file: path: prefix: /hmily mongo: databaseName: url: userName: password: zookeeper: host: localhost:2181 sessionTimeOut: 1000 rootPath: /hmily redis: cluster: false sentinel: false clusterUrl: sentinelUrl: masterName: hostName: port: password: maxTotal: 8 maxIdle: 8 minIdle: 2 maxWaitMillis: -1 minEvictableIdleTimeMillis: 1800000 softMinEvictableIdleTimeMillis: 1800000 numTestsPerEvictionRun: 3 testOnCreate: false testOnBorrow: false testOnReturn: false testWhileIdle: false timeBetweenEvictionRunsMillis: -1 blockWhenExhausted: true timeOut: 1000 metrics: metricsName: prometheus host: port: 9091 async: true threadCount : 16 jmxConfig:  ","date":-62135596800,"description":"Local configuration mode","dir":"projects/hmily/config-local/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"569c66056233e5c20a7f2453ce1eee69bcbab913","permalink":"/projects/hmily/config-local/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/hmily/config-local/","summary":"Local Configuration  File Name: hmily.yml。\n Path： The default path is the resource directory of the project, which can be specified by -Dhmily.conf, and you can also put the configuration in user.dir directory. Priority: -Dhmily.conf \u0026gt; user.dir \u0026gt; resource\n The specific contents are as follows : Notice setting hmily.server.configMode = local\n All configurations of the framework base on your local configuration files.\n Notice that the configurations of repository are extensions of SPI, you can select one from those modes, which don\u0026rsquo;t have to be configured all.","tags":null,"title":"Hmily-Config-Local","type":"projects","url":"/projects/hmily/config-local/","wordcount":238},{"author":null,"categories":null,"content":" 本地配置  文件名为 : hmily.yml。\n 路径： 默认路径为项目的 resource目录下，也可以使用 -Dhmily.conf 指定，也可以把配置放在 user.dir 目录下。 优先级别 -Dhmily.conf \u0026amp;gt; user.dir \u0026amp;gt; resource\n 具体的全内容如下 : 注意设置 hmily.server.configMode = local\n 框架的所有的配置就是基于你本地文件里面的配置\n 注意 repository的配置是SPI的扩展方式，几种方式由你去选择一种，并不需要全部配置。\n metrics 配置可有可无，如果不配置，则代表不开启metrics\n  hmily: server: configMode: local appName: # 如果server.configMode eq local 的时候才会读取到这里的配置信息. config: appName: xiaoyu serializer: kryo contextTransmittalMode: threadLocal scheduledThreadMax: 16 scheduledRecoveryDelay: 60 scheduledCleanDelay: 60 scheduledPhyDeletedDelay: 600 scheduledInitDelay: 30 recoverDelayTime: 60 cleanDelayTime: 180 limit: 200 retryMax: 10 bufferSize: 8192 consumerThreads: 16 asyncRepository: true autoSql: true phyDeleted: true storeDays: 3 repository: mysql repository: database: driverClassName: com.mysql.jdbc.Driver url : username: password: maxActive: 20 minIdle: 10 connectionTimeout: 30000 idleTimeout: 600000 maxLifetime: 1800000 file: path: prefix: /hmily mongo: databaseName: url: userName: password: zookeeper: host: localhost:2181 sessionTimeOut: 1000 rootPath: /hmily redis: cluster: false sentinel: false clusterUrl: sentinelUrl: masterName: hostName: port: password: maxTotal: 8 maxIdle: 8 minIdle: 2 maxWaitMillis: -1 minEvictableIdleTimeMillis: 1800000 softMinEvictableIdleTimeMillis: 1800000 numTestsPerEvictionRun: 3 testOnCreate: false testOnBorrow: false testOnReturn: false testWhileIdle: false timeBetweenEvictionRunsMillis: -1 blockWhenExhausted: true timeOut: 1000 metrics: metricsName: prometheus host: port: 9091 async: true threadCount : 16 jmxConfig:  ","date":-62135596800,"description":"本地配置模式","dir":"projects/hmily/config-local/","fuzzywordcount":400,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"8cf520a489831cb4d91418b9dbd9fedaf115cf2d","permalink":"/zh/projects/hmily/config-local/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/zh/projects/hmily/config-local/","summary":"本地配置 文件名为 : hmily.yml。 路径： 默认路径为项目的 resource目录下，也可以使用 -Dhmily.conf 指定，也可以把配置放在 user.dir 目录下。 优先级别 -Dhmily.conf \u0026gt;","tags":null,"title":"Hmily-Config-Local","type":"projects","url":"/zh/projects/hmily/config-local/","wordcount":351},{"author":null,"categories":null,"content":" Local Conguration  File Name: hmily.yml。\n Path： The default path is the resource directory of the project, which can be specified by -Dhmily.conf, and you can also put the configuration in user.dir directory. Priority: -Dhmily.conf \u0026amp;gt; user.dir \u0026amp;gt; resource\n The specific contents are as follows : Notice setting hmily.server.configMode = naocs\n The framework will pull the configuration from your configured nacos.\n  hmily: server: configMode: nacos appName: # The following configuration will be read when server.configMode equals nacos remote: nacos: server: 127.0.0.1:2181 # nacos service address dataId: test # dataId group: test # group timeoutMs: 6000 # Timeout(ms) fileExtension: yml # the format of the configuration of nacos (properties or yml)   And you can add configuration in nacos, the format is as follows(yml):  hmily: config: appName: xiaoyu serializer: kryo contextTransmittalMode: threadLocal scheduledThreadMax: 16 scheduledRecoveryDelay: 60 scheduledCleanDelay: 60 scheduledPhyDeletedDelay: 600 scheduledInitDelay: 30 recoverDelayTime: 60 cleanDelayTime: 180 limit: 200 retryMax: 10 bufferSize: 8192 consumerThreads: 16 asyncRepository: true autoSql: true phyDeleted: true storeDays: 3 repository: mysql repository: database: driverClassName: com.mysql.jdbc.Driver url : username: password: maxActive: 20 minIdle: 10 connectionTimeout: 30000 idleTimeout: 600000 maxLifetime: 1800000 file: path: prefix: /hmily mongo: databaseName: url: userName: password: zookeeper: host: localhost:2181 sessionTimeOut: 1000 rootPath: /hmily redis: cluster: false sentinel: false clusterUrl: sentinelUrl: masterName: hostName: port: password: maxTotal: 8 maxIdle: 8 minIdle: 2 maxWaitMillis: -1 minEvictableIdleTimeMillis: 1800000 softMinEvictableIdleTimeMillis: 1800000 numTestsPerEvictionRun: 3 testOnCreate: false testOnBorrow: false testOnReturn: false testWhileIdle: false timeBetweenEvictionRunsMillis: -1 blockWhenExhausted: true timeOut: 1000 metrics: metricsName: prometheus host: port: 9091 async: true threadCount : 16 jmxConfig:   Notice that the configurations of repository are extensions of SPI, you can select one from those modes, which don\u0026amp;rsquo;t have to be configured all.\n metrics is optional; If it is not configured，it means you don\u0026amp;rsquo;t enable metrics.\n  ","date":-62135596800,"description":"nacos configuration centre mode","dir":"projects/hmily/config-nacos/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"7be9f4182936790839e46fadaef6d3ba1619b3fe","permalink":"/projects/hmily/config-nacos/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/hmily/config-nacos/","summary":"Local Conguration  File Name: hmily.yml。\n Path： The default path is the resource directory of the project, which can be specified by -Dhmily.conf, and you can also put the configuration in user.dir directory. Priority: -Dhmily.conf \u0026gt; user.dir \u0026gt; resource\n The specific contents are as follows : Notice setting hmily.server.configMode = naocs\n The framework will pull the configuration from your configured nacos.\n  hmily: server: configMode: nacos appName: # The following configuration will be read when server.","tags":null,"title":"Hmily-Config-Nacos","type":"projects","url":"/projects/hmily/config-nacos/","wordcount":283},{"author":null,"categories":null,"content":" 本地配置  文件名为 : hmily.yml。\n 路径： 默认路径为项目的 resource目录下，也可以使用 -Dhmily.conf 指定，也可以把配置放在 user.dir 目录下。 优先级别 -Dhmily.conf \u0026amp;gt; user.dir \u0026amp;gt; resource\n 具体的全内容如下 : 注意设置 hmily.server.configMode = naocs\n 框架的或首先根据你的 nacos 配置，然后从 nacos 获取配置\n  hmily: server: configMode: nacos appName: # 如果server.configMode eq local 的时候才会读取到这里的配置信息. remote: nacos: server: 127.0.0.1:2181 # nacos服务地址 dataId: test # dataId group: test # group timeoutMs: 6000 #超时时间（ms） fileExtension: yml #nacos上配置文件的格式（properties或者yml）二选一   然后，你可以在nacos上添加配置，配置格式如果下（yml）：  hmily: config: appName: xiaoyu serializer: kryo contextTransmittalMode: threadLocal scheduledThreadMax: 16 scheduledRecoveryDelay: 60 scheduledCleanDelay: 60 scheduledPhyDeletedDelay: 600 scheduledInitDelay: 30 recoverDelayTime: 60 cleanDelayTime: 180 limit: 200 retryMax: 10 bufferSize: 8192 consumerThreads: 16 asyncRepository: true autoSql: true phyDeleted: true storeDays: 3 repository: mysql repository: database: driverClassName: com.mysql.jdbc.Driver url : username: password: maxActive: 20 minIdle: 10 connectionTimeout: 30000 idleTimeout: 600000 maxLifetime: 1800000 file: path: prefix: /hmily mongo: databaseName: url: userName: password: zookeeper: host: localhost:2181 sessionTimeOut: 1000 rootPath: /hmily redis: cluster: false sentinel: false clusterUrl: sentinelUrl: masterName: hostName: port: password: maxTotal: 8 maxIdle: 8 minIdle: 2 maxWaitMillis: -1 minEvictableIdleTimeMillis: 1800000 softMinEvictableIdleTimeMillis: 1800000 numTestsPerEvictionRun: 3 testOnCreate: false testOnBorrow: false testOnReturn: false testWhileIdle: false timeBetweenEvictionRunsMillis: -1 blockWhenExhausted: true timeOut: 1000 metrics: metricsName: prometheus host: port: 9091 async: true threadCount : 16 jmxConfig:   注意 repository的配置是SPI的扩展方式，几种方式由你去选择一种，并不需要全部配置。\n metrics 配置可有可无，如果不配置，则代表不开启metrics\n  ","date":-62135596800,"description":"nacos配置中心模式","dir":"projects/hmily/config-nacos/","fuzzywordcount":500,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"a4f631094be0037ba9b72f05e0ab5dcfc3f2a63b","permalink":"/zh/projects/hmily/config-nacos/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/zh/projects/hmily/config-nacos/","summary":"本地配置 文件名为 : hmily.yml。 路径： 默认路径为项目的 resource目录下，也可以使用 -Dhmily.conf 指定，也可以把配置放在 user.dir 目录下。 优先级别 -Dhmily.conf \u0026gt;","tags":null,"title":"Hmily-Config-Nacos","type":"projects","url":"/zh/projects/hmily/config-nacos/","wordcount":452},{"author":null,"categories":null,"content":" Local Configuration  File Name: hmily.yml。\n Path： The default path is the resource directory of the project, which can be specified by -Dhmily.conf, and you can also put the configuration in user.dir directory. Priority: -Dhmily.conf \u0026amp;gt; user.dir \u0026amp;gt; resource\n The specific contents are as follows : Notice setting hmily.server.configMode = zookeeper\n The framework will pull the configuration from your configured zookeeper.\n  hmily: server: configMode: zookeeper appName: # The following configuration will be read when server.configMode equals zookeeper remote: zookeeper: serverList: 127.0.0.1:2181 # your zookeeper service address, multiple addresses are separated by \u0026#39;,\u0026#39; fileExtension: yml # the format of the configuration of zookeeper(properties or yml) path: /hmily/xiaoyu # file path to zookeeper configuration update : # the deaflut is false, it means whether write the local configuration to zookeeper updateFileName: # it is the name of configuration when the property of \u0026#39;update\u0026#39; is true, and it is under the resource directory and the format is yaml   And you can add the needed configuration of hmily under the path, the configuration format is as follows(yml):  hmily: config: appName: serializer: kryo contextTransmittalMode: threadLocal scheduledThreadMax: 16 scheduledRecoveryDelay: 60 scheduledCleanDelay: 60 scheduledPhyDeletedDelay: 600 scheduledInitDelay: 30 recoverDelayTime: 60 cleanDelayTime: 180 limit: 200 retryMax: 10 bufferSize: 8192 consumerThreads: 16 asyncRepository: true autoSql: true phyDeleted: true storeDays: 3 repository: mysql repository: database: driverClassName: com.mysql.jdbc.Driver url : username: password: maxActive: 20 minIdle: 10 connectionTimeout: 30000 idleTimeout: 600000 maxLifetime: 1800000 file: path: prefix: /hmily mongo: databaseName: url: userName: password: zookeeper: host: localhost:2181 sessionTimeOut: 1000 rootPath: /hmily redis: cluster: false sentinel: false clusterUrl: sentinelUrl: masterName: hostName: port: password: maxTotal: 8 maxIdle: 8 minIdle: 2 maxWaitMillis: -1 minEvictableIdleTimeMillis: 1800000 softMinEvictableIdleTimeMillis: 1800000 numTestsPerEvictionRun: 3 testOnCreate: false testOnBorrow: false testOnReturn: false testWhileIdle: false timeBetweenEvictionRunsMillis: -1 blockWhenExhausted: true timeOut: 1000 metrics: metricsName: prometheus host: port: 9091 async: true threadCount : 16 jmxConfig:   Notice that the configurations of repository are extensions of SPI, you can select one from those modes, which don\u0026amp;rsquo;t have to be configured all.\n metrics is optional; If it is not configured，it means you don\u0026amp;rsquo;t enable metrics.\n  ","date":-62135596800,"description":"zookeeper configuration centre mode","dir":"projects/hmily/config-zookeeper/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"4e7f9a1ece30a1c69445af47dc74e0ab976bc13a","permalink":"/projects/hmily/config-zookeeper/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/hmily/config-zookeeper/","summary":"Local Configuration  File Name: hmily.yml。\n Path： The default path is the resource directory of the project, which can be specified by -Dhmily.conf, and you can also put the configuration in user.dir directory. Priority: -Dhmily.conf \u0026gt; user.dir \u0026gt; resource\n The specific contents are as follows : Notice setting hmily.server.configMode = zookeeper\n The framework will pull the configuration from your configured zookeeper.\n  hmily: server: configMode: zookeeper appName: # The following configuration will be read when server.","tags":null,"title":"Hmily-Config-Zookeeper","type":"projects","url":"/projects/hmily/config-zookeeper/","wordcount":333},{"author":null,"categories":null,"content":" 本地配置  文件名为 : hmily.yml。\n 路径： 默认路径为项目的 resource目录下，也可以使用 -Dhmily.conf 指定，也可以把配置放在 user.dir 目录下。 优先级别 -Dhmily.conf \u0026amp;gt; user.dir \u0026amp;gt; resource\n 具体的全内容如下 : 注意设置 hmily.server.configMode = zookeeper\n 框架的或首先根据你的 zookeeper 配置，然后从 zookeeper 获取配置\n  hmily: server: configMode: zookeeper appName: # 如果server.configMode eq local 的时候才会读取到这里的配置信息. remote: zookeeper: serverList: 127.0.0.1:2181 #你的zookeeper服务地址，多个使用逗号分隔 fileExtension: yml #zookeeper上配置文件的格式（properties或者yml）二选一 path: /hmily/xiaoyu #zookeeper上配置文件的路径 update : #默认是false ，是否需要将本地的配置文件写到zookeeper updateFileName: #update属性为true时候 ，配置文件名称，位于项目的 resource文件夹下的yaml格式   然后，你可以在上述的 path 配置路径下，去写入hmily框架所需要的配置，配置格式如果下（yml）：  hmily: config: appName: serializer: kryo contextTransmittalMode: threadLocal scheduledThreadMax: 16 scheduledRecoveryDelay: 60 scheduledCleanDelay: 60 scheduledPhyDeletedDelay: 600 scheduledInitDelay: 30 recoverDelayTime: 60 cleanDelayTime: 180 limit: 200 retryMax: 10 bufferSize: 8192 consumerThreads: 16 asyncRepository: true autoSql: true phyDeleted: true storeDays: 3 repository: mysql repository: database: driverClassName: com.mysql.jdbc.Driver url : username: password: maxActive: 20 minIdle: 10 connectionTimeout: 30000 idleTimeout: 600000 maxLifetime: 1800000 file: path: prefix: /hmily mongo: databaseName: url: userName: password: zookeeper: host: localhost:2181 sessionTimeOut: 1000 rootPath: /hmily redis: cluster: false sentinel: false clusterUrl: sentinelUrl: masterName: hostName: port: password: maxTotal: 8 maxIdle: 8 minIdle: 2 maxWaitMillis: -1 minEvictableIdleTimeMillis: 1800000 softMinEvictableIdleTimeMillis: 1800000 numTestsPerEvictionRun: 3 testOnCreate: false testOnBorrow: false testOnReturn: false testWhileIdle: false timeBetweenEvictionRunsMillis: -1 blockWhenExhausted: true timeOut: 1000 metrics: metricsName: prometheus host: port: 9091 async: true threadCount : 16 jmxConfig:   注意 repository的配置是SPI的扩展方式，几种方式由你去选择一种，并不需要全部配置。\n metrics 配置可有可无，如果不配置，则代表不开启metrics\n  ","date":-62135596800,"description":"zookeeper配置中心模式","dir":"projects/hmily/config-zookeeper/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"2eb557c4bcdb77c02a36358b07997299d28239ae","permalink":"/zh/projects/hmily/config-zookeeper/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/zh/projects/hmily/config-zookeeper/","summary":"本地配置 文件名为 : hmily.yml。 路径： 默认路径为项目的 resource目录下，也可以使用 -Dhmily.conf 指定，也可以把配置放在 user.dir 目录下。 优先级别 -Dhmily.conf \u0026gt;","tags":null,"title":"Hmily-Config-Zookeeper","type":"projects","url":"/zh/projects/hmily/config-zookeeper/","wordcount":571},{"author":null,"categories":null,"content":" HmilyTransactionContext事务上下文 @Data public class HmilyTransactionContext { /** * transId. */ private Long transId; /** * participant id. */ private Long participantId; /** * participant ref id. */ private Long participantRefId; /** * this hmily action. */ private int action; /** * 事务参与的角色. */ private int role; /** * transType. */ private String transType; }  HmilyTransactionContext 是Hmily分布式事务框架进行RPC调用时用于传递事务上下文的核心类, 默认会将其存储在ThreadLocal中，然后进行RPC的参数传递，也可以配置使用线程上下文切换的的场景， 这个时候需要在配置中指定 contextTransmittalMode = transmittable,将会使用alibaba开源类库。\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.alibaba\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;transmittable-thread-local\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.11.5\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  Dubbo框架传递事务上下文 具体实现类在org.dromara.hmily.dubbo.filter.DubboHmilyTransactionFilter中， 通过 RpcContext.getContext().setAttachment(String key, String value) 进行RPC传参数。\nMotan框架传递事务上下文 具体实现类在org.dromara.hmily.motan.filter.MotanHmilyTransactionFilter中， 通过 Request.setAttachment(String key, String value) 进行RPC传参数。\nSpringCloud框架传递事务上下文 具体实现类在org.dromara.hmily.springcloud.feign.HmilyFeignInterceptor中， 通过 RequestTemplate.header(String name, String... values) 进行RPC传参数。\n","date":-62135596800,"description":"Hmily-Context事务上下文","dir":"projects/hmily/context/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"27f12b2c83a727c1c59ae216f63a61b3f5ec5b16","permalink":"/zh/projects/hmily/context/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/zh/projects/hmily/context/","summary":"HmilyTransactionContext事务上下文 @Data public class HmilyTransactionContext { /** * transId. */ private Long transId; /** * participant id. */ private Long participantId; /** * participant ref id. */ private Long participantRefId; /** * this hmily action. */ private int action; /** * 事务","tags":null,"title":"Hmily-Context","type":"projects","url":"/zh/projects/hmily/context/","wordcount":516},{"author":null,"categories":null,"content":" Metrics 目前hmily的metrics模块，采用 prometheus来进行采集，使用pull模式对外暴露metrics信息接口。\n收集的metrics主要分为二个大类。\n 应用的JVM信息：内存，cpu，线程使用等等\n 事务信息：包括事务的总数，事务的迟延，事务的状态，事务的角色\n  指标详解 如何展示  用户可以使用 Grafana 从应用里面的metrics配置拉取的metrics信息  ","date":-62135596800,"description":"Metrics","dir":"projects/hmily/metrics/","fuzzywordcount":200,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"1209e148e81f6aeb5aa08fa3d6d0e63b709a97d9","permalink":"/zh/projects/hmily/metrics/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/zh/projects/hmily/metrics/","summary":"Metrics 目前hmily的metrics模块，采用 prometheus来进行采集，使用pull模式对外暴露metrics信息接口。 收集的metric","tags":null,"title":"Hmily-Metrics","type":"projects","url":"/zh/projects/hmily/metrics/","wordcount":174},{"author":null,"categories":null,"content":" TAC The TAC mode is actually a variant of the TCC mode. Just as the name implies, the TAC mode is called automatic rollback. As compared with the TCC mode, the user doesn\u0026amp;rsquo;t have to concern about how to write the rollback method at all. and then it can reduces user development volume and is entirely transparent to users.\n TAC Mode is only suitable for Relational Database.\n TAC Mode will intercept the user\u0026amp;rsquo;s SQL statement to generate reverse rollback SQL, and the compatibility of SQL will also be a ordeal.\n  ","date":-62135596800,"description":"Hmily-TAC","dir":"projects/hmily/tac/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"58609eebdc6bf207426e0c657e1535f7b6ec337d","permalink":"/projects/hmily/tac/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/hmily/tac/","summary":"TAC The TAC mode is actually a variant of the TCC mode. Just as the name implies, the TAC mode is called automatic rollback. As compared with the TCC mode, the user doesn\u0026rsquo;t have to concern about how to write the rollback method at all. and then it can reduces user development volume and is entirely transparent to users.\n TAC Mode is only suitable for Relational Database.\n TAC Mode will intercept the user\u0026rsquo;s SQL statement to generate reverse rollback SQL, and the compatibility of SQL will also be a ordeal.","tags":null,"title":"Hmily-TAC","type":"projects","url":"/projects/hmily/tac/","wordcount":90},{"author":null,"categories":null,"content":" TCC TCC模式是经典的柔性事务解决方案，需要使用者提供 try, confirm, cancel 三个方法， 真正的情况下会执行 try, confirm, 异常情况下会执行try, cancel。 confirm 方法并不是 必须的，完全依赖于用户的try 方法如何去写。 confirm, cancel 2个方法也需要用户去保证幂等性, 这会附加一定的工作量，由于在try方法完成之后，数据已经提交了，因此它并不保证数据的隔离性。但是这样，它的 性能相对较高，一个好的系统设计，是非常适用适用TCC模式。下面是Hmily 框架的 TCC 流程图  在极端异常情况下，比如服务突然宕机，超时异常等，依赖与自身的调用任务，来进行日志的事务恢复。\n 在confirm, cancel 阶段，如果有任何异常会继续执行相应的阶段，如果超过最大重试次数还未成功，将不再进行重试，需要人工介入。\n 在服务集群的情况下，confirm, cancel 2个方法用户去尽量保证其幂等性。\n  ","date":-62135596800,"description":"Hmily-TCC","dir":"projects/hmily/tcc/","fuzzywordcount":400,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"ab3fbd094b55130ba3997d7c129f22d0d45f7fbf","permalink":"/zh/projects/hmily/tcc/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/zh/projects/hmily/tcc/","summary":"TCC TCC模式是经典的柔性事务解决方案，需要使用者提供 try, confirm, cancel 三个方法， 真正的情况下会执行 try, confirm, 异常情况下会执行try, cancel。 confirm 方法并不是","tags":null,"title":"Hmily-TCC","type":"projects","url":"/zh/projects/hmily/tcc/","wordcount":349},{"author":null,"categories":null,"content":" @Hmily /** * The annotation Hmily. * * @author xiaoyu */ @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD) public @interface Hmily { }   该注解为hmily分布式事务接口标识，表示该接口参与hmily分布式事务  @HmilyTCC @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD) public @interface HmilyTCC { /** * Confirm method string. * * @return the string */ String confirmMethod() default \u0026amp;quot;\u0026amp;quot;; /** * Cancel method string. * * @return the string */ String cancelMethod() default \u0026amp;quot;\u0026amp;quot;; /** * Pattern pattern enum. * * @return the pattern enum */ TransTypeEnum pattern() default TransTypeEnum.TCC; }   该注解为Hmily分布式事务TCC模式的切面（AOP point），可以标识在你本地具体实现方法上。\n confirmMethod : 注解标识方法的，确认方法名称，该方法参数列表与返回类型应与标识方法一致。\n cancelMethod : 注解标识方法的，回滚方法名称，该方法参数列表与返回类型应与标识方法一致。\n  @HmilyTAC /** * The annotation HmilyTAC. * * @author xiaoyu */ @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD) public @interface HmilyTAC { }   该注解为Hmily分布式事务TAC模式的切面（AOP point），可以标识在你的本地方法具体实现上。  ","date":-62135596800,"description":"annotation","dir":"projects/hmily/annotation/","fuzzywordcount":400,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"665da8d1a0ec43b5feadab5532f39783b1ab5832","permalink":"/zh/projects/hmily/annotation/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/zh/projects/hmily/annotation/","summary":"@Hmily /** * The annotation Hmily. * * @author xiaoyu */ @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD) public @interface Hmily { } 该注解为hmily分布式事务接口标识，表示该接口参与hmily分布式事务 @HmilyTCC @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD) public @interface HmilyTCC { /** * Confirm method string. * * @return the","tags":null,"title":"Hmily-annotation","type":"projects","url":"/zh/projects/hmily/annotation/","wordcount":301},{"author":null,"categories":null,"content":" Development Guidelines  Intentions Write codes with heart. Pursue clean, simplified and extremely elegant codes. Readable The code is unambiguous, and the intention of the code is revealed through reading rather than debugging. Tidy Agree with concepts in and . Consistent Be familiar with codes already had, to keep consistent with the style and use. Simplified Express meaning with the least code. Highly reusable, no duplicated codes or configurations. Delete codes out of use in time. Abstract The levels are clearly divided and the concepts are reasonably refined. Keep methods, classes, packages and modules at the same abstract level.  Contributor Covenant Submitting of Conduct  Make sure all the test cases are passed, Make sure ./mvnw clean install can be compiled and tested successfully. Make sure the test coverage rate is not lower than the master branch. Make sure to check codes with Checkstyle. codes that violate check rules should have special reasons. Find checkstyle template from https://github.com/dromara/hmily/blob/master/script/hmily_checkstyle.xml, please use checkstyle 8.8 to run the rules. Careful consideration for each pull request; Small and frequent pull request with complete unit function is welcomed. Conform to Contributor Covenant Code of Conduct below.  Contributor Covenant Code of Conduct  Use linux line separators. Keep indents (including blank lines) consistent with the previous one. Keep one blank line after class definition. No meaningless blank lines. Please extract private methods to instead of blank lines if too long method body or different logic code fragments. Use meaningful class, method and variable names, avoid to use abbreviate. Return values are named with result; Variables in the loop structure are named with each; Replace each with entry in map. Name property files with Spinal Case(a variant of Snake Case which uses hyphens - to separate words). Split codes that need to add notes with it into small methods, which are explained with method names. Have constants on the left and variable on the right in == and equals conditional expressions; Have variable on the left and constants on the right in greater than and less than conditional expressions. Beside using same names as input parameters and global fields in assign statement, avoid using this modifier. Design class as final class except abstract class for extend. Make nested loop structures a new method. The order of definition of member variables and the order of parameter passing are kept consistent in each class and method. Order of members definition and parameters should be consistent during classes and methods. Use guard clauses in priority. Minimize the access permission for classes and methods. Private method should be just next to the method in which it is used; writing private methods should be in the same as the appearance order of private methods. No null parameters or return values. Replace if else return and assign statement with ternary …","date":-62135596800,"description":"hmily development guidelines","dir":"projects/hmily/code-conduct/","fuzzywordcount":600,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"db31031e4d576dab8beafe848a6c6c21a81302dd","permalink":"/projects/hmily/code-conduct/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/hmily/code-conduct/","summary":"Development Guidelines  Intentions Write codes with heart. Pursue clean, simplified and extremely elegant codes. Readable The code is unambiguous, and the intention of the code is revealed through reading rather than debugging. Tidy Agree with concepts in and . Consistent Be familiar with codes already had, to keep consistent with the style and use. Simplified Express meaning with the least code. Highly reusable, no duplicated codes or configurations. Delete codes out of use in time.","tags":null,"title":"Hmily-code-conduct","type":"projects","url":"/projects/hmily/code-conduct/","wordcount":530},{"author":null,"categories":null,"content":" 开发理念  用心 保持责任心和敬畏心，以工匠精神持续雕琢。 可读 代码无歧义，通过阅读而非调试手段浮现代码意图。 整洁 认同《重构》和《代码整洁之道》的理念，追求整洁优雅代码。 一致 代码风格、命名以及使用方式保持完全一致。 精简 极简代码，以最少的代码表达最正确的意思。高度复用，无重复代码和配置。及时删除无用代码。 抽象 层次划分清晰，概念提炼合理。保持方法、类、包以及模块处于同一抽象层级。  代码提交行为规范  确保通过全部测试用例，确保执行./mvnw clean install可以编译和测试通过。 确保覆盖率不低于master分支。 确保使用Checkstyle检查代码，违反验证规则的需要有特殊理由。模板位置在https://github.com/dromara/hmily/blob/master/script/hmily_checkstyle.xml，请使用checkstyle 8.8运行规则。 应尽量将设计精细化拆分；做到小幅度修改，多次数提交，但应保证提交的完整性。 确保遵守编码规范。  编码规范  使用linux换行符。 缩进（包含空行）和上一行保持一致。 类声明后与下面的变量或方法之间需要空一行。 不应有无意义的空行。请提炼私有方法，代替方法体过长或代码段逻辑闭环而采用的空行间隔。 类、方法和变量的命名要做到顾名思义，避免使用缩写。 返回值变量使用result命名；循环中使用each命名循环变量；map中使用entry代替each。 配置文件使用Spinal Case命名（一种使用-分割单词的特殊Snake Case）。 需要注释解释的代码尽量提成小方法，用方法名称解释。 equals和==条件表达式中，常量在左，变量在右；大于小于等条件表达式中，变量在左，常量在右。 除了构造器入参与全局变量名称相同的赋值语句外，避免使用this修饰符。 除了用于继承的抽象类之外，尽量将类设计为final。 嵌套循环尽量提成方法。 成员变量定义顺序以及参数传递顺序在各个类和方法中保持一致。 优先使用卫语句。 类和方法的访问权限控制为最小。 方法所用到的私有方法应紧跟该方法，如果有多个私有方法，书写私有方法应与私有方法在原方法的出现顺序相同。 方法入参和返回值不允许为null。 优先使用三目运算符代替if else的返回和赋值语句。 优先考虑使用LinkedList，只有在需要通过下标获取集合中元素值时再使用ArrayList。 ArrayList，HashMap等可能产生扩容的集合类型必须指定集合初始大小，避免扩容。 日志与注释一律使用英文。 注释只能包含javadoc，todo和fixme。 公开的类和方法必须有javadoc，其他类和方法以及覆盖自父类的方法无需javadoc。  ","date":-62135596800,"description":"hmily编码指南","dir":"projects/hmily/code-conduct/","fuzzywordcount":1200,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"6228fff3a43aab0d8106d96fbfd97de8b70d8c54","permalink":"/zh/projects/hmily/code-conduct/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/zh/projects/hmily/code-conduct/","summary":"开发理念 用心 保持责任心和敬畏心，以工匠精神持续雕琢。 可读 代码无歧义，通过阅读而非调试手段浮现代码意图。 整洁 认同《重构》和《代码整洁之道》的理","tags":null,"title":"Hmily-code-conduct","type":"projects","url":"/zh/projects/hmily/code-conduct/","wordcount":1105},{"author":null,"categories":null,"content":" Committer Promotion After you have made a lot of contributions, the community will invite you join Committers\nBecome a committer you will have\n Hmily repository write permissions\n Idea free license\n  Committer Responsibilities  Develop new features; Refactor codes; Review pull requests reliably and in time; Consider and accept feature requests; Answer questions; Update documentation and example; Improve processes and tools; Guide new contributors join community.  Committer Routine  Committer needs to check the list of pull requests and issues to be processed in the community on a daily basis and assign them to the appropriate committer, that is, assignee.\n After a committer is assigned with an issue, the following work is required:\n Estimate whether it is a long-term issue. If it is, please label it as pending. Add issue labels, such as bug, enhancement, discussion, etc. Add milestone.   Notice\nRegardless of whether it is a community issue, there must be an assignee until the issue is resolved.\n","date":-62135596800,"description":"Hmily committer guidelines","dir":"projects/hmily/committer/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"34d42512951463e632886242e281186237d59351","permalink":"/projects/hmily/committer/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/hmily/committer/","summary":"Committer Promotion After you have made a lot of contributions, the community will invite you join Committers\nBecome a committer you will have\n Hmily repository write permissions\n Idea free license\n  Committer Responsibilities  Develop new features; Refactor codes; Review pull requests reliably and in time; Consider and accept feature requests; Answer questions; Update documentation and example; Improve processes and tools; Guide new contributors join community.  Committer Routine  Committer needs to check the list of pull requests and issues to be processed in the community on a daily basis and assign them to the appropriate committer, that is, assignee.","tags":null,"title":"Hmily-committer","type":"projects","url":"/projects/hmily/committer/","wordcount":155},{"author":null,"categories":null,"content":" 提交者提名 当你做了很多贡献以后，社区会进行提名。 成为committer你会拥有\n hmily仓库写的权限\n idea 正版使用\n  提交者责任  开发新功能； 代码重构； 及时和可靠的评审Pull Request； 思考和接纳新特性请求； 解答问题； 维护文档和代码示例； 改进流程和工具； 引导新的参与者融入社区。  日常工作  committer需要每天查看社区待处理的Pull Request和issue列表，指定给合适的committer，即assignee。\n assignee在被分配issue后，需要进行如下判断：\n 判断是否是长期issue，如是，则标记为pending。 判断issue类型，如：bug，enhancement，discussion等。 判断Milestone，并标记。   注意\n无论是否是社区issue，都必须有assignee，直到issue完成。\n","date":-62135596800,"description":"Hmily-committer提交者指南","dir":"projects/hmily/committer/","fuzzywordcount":400,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"b7be93553744f09ed788cd696c351e709bb55abe","permalink":"/zh/projects/hmily/committer/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/zh/projects/hmily/committer/","summary":"提交者提名 当你做了很多贡献以后，社区会进行提名。 成为committer你会拥有 hmily仓库写的权限 idea 正版使用 提交者责任 开发新功能； 代码重构","tags":null,"title":"Hmily-committer","type":"projects","url":"/zh/projects/hmily/committer/","wordcount":358},{"author":null,"categories":null,"content":" You can report a bug, submit a new function enhancement suggestion, or submit a pull request directly.\nSubmit an Issue  Before submitting an issue, please go through a comprehensive search to make sure the problem cannot be solved just by searching. Check the Issue List to make sure the problem is not repeated. Create a new issue and choose the type of issue. Define the issue with a clear and descriptive title.. Fill in necessary information according to the template. Choose a label after issue created, for example: bug，enhancement，discussion. Please pay attention for your issue, you may need provide more information during discussion.  Developer Flow Fork Hmily repo  Fork a Hmily repo to your own repo to work, then setting upstream.  git remote add upstream https://github.com/dromara/hmily.git  Choose Issue  Please choose the issue to be edited. If it is a new issue discovered or a new function enhancement to offer, please create an issue and set the right label for it. After choosing the relevant issue, please reply with a deadline to indicate that you are working on it.  Create Branch  Switch to forked master branch, pull codes from upstream, then create a new branch.  git checkout master git pull upstream master git checkout -b issueNo  Notice ：We will merge PR using squash, commit log will be different form upstream if you use old branch\nCoding  Please obey the Code of Conduct during the process of development and finish the check before submitting the pull request. push code to your fork repo.  git add modified-file-names git commit -m \u0026#39;commit log\u0026#39; git push origin issueNo  Submit Pull Request  Send a pull request to the master branch. The mentor will do code review before discussing some details (including the design, the implementation and the performance) with you. The request will be merged into the branch of current development version after the edit is well enough. At last, congratulate to be an official contributor of Hmily  Delete Branch  You can delete the remote branch (origin/issueNo) and the local branch (issueNo) associated with the remote branch (origin/issueNo) after the mentor merged the pull request into the master branch of Hmily.  git checkout master git branch -d issueNo git push origin --delete issueNo  Notice Please note that in order to show your id in the contributor list, don’t forget the configurations below:\ngit config --global user.name \u0026amp;quot;username\u0026amp;quot; git config --global user.email \u0026amp;quot;username@mail.com\u0026amp;quot;  ","date":-62135596800,"description":"Hmily-contributor-guide","dir":"projects/hmily/contributor/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"c5c174a68978271968ec1b18ffcd3ee1bc709445","permalink":"/projects/hmily/contributor/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/hmily/contributor/","summary":"You can report a bug, submit a new function enhancement suggestion, or submit a pull request directly.\nSubmit an Issue  Before submitting an issue, please go through a comprehensive search to make sure the problem cannot be solved just by searching. Check the Issue List to make sure the problem is not repeated. Create a new issue and choose the type of issue. Define the issue with a clear and descriptive title.","tags":null,"title":"Hmily-contributor","type":"projects","url":"/projects/hmily/contributor/","wordcount":396},{"author":null,"categories":null,"content":" 您可以报告bug，提交一个新的功能增强建议或者直接对以上内容提交改进补丁。\n提交issue  在提交issue之前，请经过充分的搜索，确定该issue不是通过简单的检索即可以解决的问题。 查看issue列表，确定该issue不是一个重复的问题。 新建一个issue并选择您的issue类型。 使用一个清晰并有描述性的标题来定义issue。 根据模板填写必要信息。 在提交issue之后，对该issue分配合适的标签。如：bug，enhancement，discussion等。 请对自己提交的issue保持关注，在讨论中进一步提供必要信息。  开发流程 Fork分支到本地，设置upstream  从hmily的repo上fork一个分支到您自己的repo来开始工作，并设置upstream为hmily的repo。  git remote add upstream https://github.com/dromara/hmily.git  选择issue  请在选择您要修改的issue。如果是您新发现的问题或想提供issue中没有的功能增强，请先新建一个issue并设置正确的标签。 在选中相关的issue之后，请回复以表明您当前正在这个issue上工作。并在回复的时候为自己设置一个deadline，添加至回复内容中。  创建分支  切换到fork的master分支，拉取最新代码，创建本次的分支。  git checkout master git pull upstream master git checkout -b issueNo  注意 ：PR会按照squash的方式进行merge，如果不创建新分支，本地和远程的提交记录将不能保持同步。\n编码  请您在开发过程中遵循hmily的 开发规范。并在准备提交pull request之前完成相应的检查。 将修改的代码push到fork库的分支上。  git add 修改代码 git commit -m \u0026#39;commit log\u0026#39; git push origin issueNo  提交PR  发送一个pull request到hmily的master分支。 接着导师做CodeReview，然后他会与您讨论一些细节（包括设计，实现，性能等）。当导师对本次修改满意后，会将提交合并到当前开发版本的分支中。 最后，恭喜您已经成为了hmily的贡献者！  删除分支  在导师将pull request合并到hmily的master分支中之后，您就可以将远程的分支（origin/issueNo）及与远程分支（origin/issueNo）关联的本地分支（issueNo）删除。  git checkout master git branch -d issueNo git push origin --delete issueNo  注意 为了让您的id显示在contributor列表中，别忘了以下设置：\ngit config --global user.name \u0026amp;quot;username\u0026amp;quot; git config --global user.email \u0026amp;quot;username@mail.com\u0026amp;quot;  ","date":-62135596800,"description":"Hmily-contributor贡献者指南","dir":"projects/hmily/contributor/","fuzzywordcount":1000,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"897065d661e3482f0011b75e9d2ae8434831d5e3","permalink":"/zh/projects/hmily/contributor/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/zh/projects/hmily/contributor/","summary":"您可以报告bug，提交一个新的功能增强建议或者直接对以上内容提交改进补丁。 提交issue 在提交issue之前，请经过充分的搜索，确定该iss","tags":null,"title":"Hmily-contributor","type":"projects","url":"/zh/projects/hmily/contributor/","wordcount":963},{"author":null,"categories":null,"content":" TAC TAC模式其实是TCC模式的变种,顾名思义 TAC 模式被称为自动回滚,相比于 TCC模式，用户完全不用关心 回滚方法如何去写，减少了用户的开发量，对用户完全透明。\n TAC 模式只适合于关系型数据库。\n TAC 模式会拦截用户的SQL语句生成反向回滚SQL，SQL的兼容度也会是一大考验。\n  ","date":-62135596800,"description":"tac","dir":"projects/hmily/tac/","fuzzywordcount":200,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"b248c8ac0383696627e8f639f042dbad5b440774","permalink":"/zh/projects/hmily/tac/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/zh/projects/hmily/tac/","summary":"TAC TAC模式其实是TCC模式的变种,顾名思义 TAC 模式被称为自动回滚,相比于 TCC模式，用户完全不用关心 回滚方法如何去写，减少了用户的开发量，对","tags":null,"title":"Hmily-tac","type":"projects","url":"/zh/projects/hmily/tac/","wordcount":130},{"author":null,"categories":null,"content":" TCC The TCC Mode is a classic flexible transaction solution that needs the users to provided try, confirm, cancel methods. The try, confirm methods will be invoked under normal circumstances,and the try, cancel methods will be invoked as an exception occurs. the confirm method is not required,it entirely depends on the users how to implement the try method. the both confirm and cancel method also need the users to guarantee the idempotency, but it will bring addtional workload to the users. Because after the try method finished, the data had been committed. But with this,the performances will be even better. A good system design is very applicable to the TCC Mode. This is the flow diagram of TCC in Hmily framework as below:  In extreme cases, such as sudden service crash, timeout exceptions, and much more, the transaction recovery of the log depends on its own calling task.\n At the both confirm and cancel stage,if there are any exception occur, the corresponding stage will continue to be executed. If the maximum number of retries is exceeded, the transaction has not succeeded, It will not retry any more, then manual intervention is required at this time.\n In the case of a service cluster, the users need to do the best to ensure the idempotence of these two methods confirm, cancel.\n  ","date":-62135596800,"description":"tcc","dir":"projects/hmily/tcc/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"67d30126d857251634d592e0bafcf996f79c4685","permalink":"/projects/hmily/tcc/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/hmily/tcc/","summary":"TCC The TCC Mode is a classic flexible transaction solution that needs the users to provided try, confirm, cancel methods. The try, confirm methods will be invoked under normal circumstances,and the try, cancel methods will be invoked as an exception occurs. the confirm method is not required,it entirely depends on the users how to implement the try method. the both confirm and cancel method also need the users to guarantee the idempotency, but it will bring addtional workload to the users.","tags":null,"title":"Hmily-tcc","type":"projects","url":"/projects/hmily/tcc/","wordcount":219},{"author":null,"categories":null,"content":" The document is improving ","date":-62135596800,"description":"Distributed scheduling framework.","dir":"projects/hodor/overview/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"007599da79c513b8c058cf7b9d286758c4db24c2","permalink":"/projects/hodor/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/hodor/overview/","summary":" The document is improving ","tags":null,"title":"Hodor Introduction","type":"projects","url":"/projects/hodor/overview/","wordcount":4},{"author":null,"categories":null,"content":" 文档完善中，敬请期待 ","date":-62135596800,"description":"分布式调度框架.","dir":"projects/hodor/overview/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"50f7e92cbc247eb7f365720cea762cf265b41eab","permalink":"/zh/projects/hodor/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/zh/projects/hodor/overview/","summary":"文档完善中，敬请期待","tags":null,"title":"Hodor介绍","type":"projects","url":"/zh/projects/hodor/overview/","wordcount":10},{"author":null,"categories":null,"content":" Spring-boot framework which use netty as httpServer instead of tomcat.\nSpring-boot user  import jar\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.happylife.netty\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;happylife-netty\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;1.0-SNAPSHOT\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  Add the following code to the application class of spring boot:\n  @Bean public EmbeddedServletContainerFactory servletContainer(){ NettyContainerConfig nettyContainerConfig = new NettyContainerConfig(); NettyEmbeddedServletContainerFactory factory = new NettyEmbeddedServletContainerFactory(nettyContainerConfig); return factory; }  ","date":-62135596800,"description":"Spring-boot framework which use netty as httpServer instead of tomcat.","dir":"projects/jinx/overview/","fuzzywordcount":100,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"b284bde165a09c23c707084889ab6d6e9db9156e","permalink":"/projects/jinx/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/jinx/overview/","summary":" Spring-boot framework which use netty as httpServer instead of tomcat.\nSpring-boot user  import jar\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.happylife.netty\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;happylife-netty\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;  Add the following code to the application class of spring boot:\n  @Bean public EmbeddedServletContainerFactory servletContainer(){ NettyContainerConfig nettyContainerConfig = new NettyContainerConfig(); NettyEmbeddedServletContainerFactory factory = new NettyEmbeddedServletContainerFactory(nettyContainerConfig); return factory; }  ","tags":null,"title":"Jinx Introduction","type":"projects","url":"/projects/jinx/overview/","wordcount":47},{"author":null,"categories":null,"content":" Spring-boot框架采用netty取代tomcat来做http服务\nSpring-boot用户  首先引起jar包  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.happylife.netty\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;happylife-netty\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;1.0-SNAPSHOT\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   在spring-boot的Application类中加上如下代码：  @Bean public EmbeddedServletContainerFactory servletContainer(){ NettyContainerConfig nettyContainerConfig = new NettyContainerConfig(); NettyEmbeddedServletContainerFactory factory = new NettyEmbeddedServletContainerFactory(nettyContainerConfig); return factory; }  ","date":-62135596800,"description":"Spring-boot框架采用netty取代tomcat来做http服务","dir":"projects/jinx/overview/","fuzzywordcount":200,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"256a6b33ce06467dd183d245357d64288f0b4775","permalink":"/zh/projects/jinx/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/zh/projects/jinx/overview/","summary":"Spring-boot框架采用netty取代tomcat来做http服务 Spring-boot用户 首先引起jar包 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.happylife.netty\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;happylife-netty\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在spring-","tags":null,"title":"Jinx 介绍","type":"projects","url":"/zh/projects/jinx/overview/","wordcount":112},{"author":null,"categories":null,"content":" Prerequisites  JDK 1.8+ Maven 3.2.x Git Zookeeper  Cloning the GitHub Repository and Quick Installation  \u0026amp;gt; git clone https://github.com/dromara/hmily.git \u0026amp;gt; cd hmily \u0026amp;gt; mvn -DskipTests clean install -U  Executing SQL(s) in Demo Module sql\nOpen with Your Favourite Editor (IDEA), Locate on hmily-demo-dubbo Module and Run Build with Maven Configuring（hmily-demo-motan-account module for instance）  Configure with your business database in application.yml(account module for instance)  spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://\u0026amp;lt;db_host_ip\u0026amp;gt;:\u0026amp;lt;db_host_port\u0026amp;gt;/hmily_account?useUnicode=true\u0026amp;amp;characterEncoding=utf8 # replace with your db_host_ip and db_host_port username: root # replace with your db username password: your_password # replace with your db user password   Configure with motan registration address(es) in application.yml (can run with local zookeeper instance(s))  hmily: motan: # for registration address registry: address: 127.0.0.1:2181 # replace with registration address   Modify hmily.yml, with mysql persistence backend  repository: database: driverClassName: com.mysql.jdbc.Driver url: jdbc:mysql://\u0026amp;lt;db_host_ip\u0026amp;gt;:\u0026amp;lt;db_host_port\u0026amp;gt;/hmily?useUnicode=true\u0026amp;amp;characterEncoding=utf8 # replace with your db_host_ip and db_host_port username: root # replace with your db username password: your_password # replace with your db user password   run MotanHmilyAccountApplication.java  Run hmily-demo-motan-inventory(refer to simillar instructions above). Run hmily-demo-motan-order(refer to simillar instructions above). Access on http://127.0.0.1:8088/swagger-ui.html for more. ","date":-62135596800,"description":"motan Quick Start","dir":"projects/hmily/quick-start-motan/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"1f5e6ca8b2b4f80815a1c229bdc96e4c827d68b6","permalink":"/projects/hmily/quick-start-motan/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/hmily/quick-start-motan/","summary":"Prerequisites  JDK 1.8+ Maven 3.2.x Git Zookeeper  Cloning the GitHub Repository and Quick Installation  \u0026gt; git clone https://github.com/dromara/hmily.git \u0026gt; cd hmily \u0026gt; mvn -DskipTests clean install -U  Executing SQL(s) in Demo Module sql\nOpen with Your Favourite Editor (IDEA), Locate on hmily-demo-dubbo Module and Run Build with Maven Configuring（hmily-demo-motan-account module for instance）  Configure with your business database in application.yml(account module for instance)  spring: datasource: driver-class-name: com.","tags":null,"title":"Motan Quick Start","type":"projects","url":"/projects/hmily/quick-start-motan/","wordcount":174},{"author":null,"categories":null,"content":" Add myth-annotation dependency to motan api project.  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.github.myth\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;myth-annotation\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   Add the @Myth annotation to the motan Interface method and set the name of the message queue, which is the queue from which the messaging middleware sends messages.  @Myth(destination = \u0026amp;quot;account\u0026amp;quot;) boolean payment(AccountDTO accountDTO);   In the motan service provider (the participating method of the transaction, the callee).\n add myth-motan dependency\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.github.myth\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;myth-motan\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   Configure MythTransactionBootstrap to start the class, either as XML or as @Bean. Specific configuration can refer to here:configuration for details  \u0026amp;lt;context:component-scan base-package=\u0026amp;quot;com.github.myth.*\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;mythTransactionBootstrap\u0026amp;quot; class=\u0026amp;quot;com.github.myth.core.bootstrap.MythTransactionBootstrap\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;repositorySuffix\u0026amp;quot; value=\u0026amp;quot;account-service\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;serializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;coordinatorQueueMax\u0026amp;quot; value=\u0026amp;quot;5000\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;coordinatorThreadMax\u0026amp;quot; value=\u0026amp;quot;8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;rejectPolicy\u0026amp;quot; value=\u0026amp;quot;Abort\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;blockingQueueType\u0026amp;quot; value=\u0026amp;quot;Linked\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;repositorySupport\u0026amp;quot; value=\u0026amp;quot;db\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;mythDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;bean class=\u0026amp;quot;com.github.myth.common.config.MythDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;url\u0026amp;quot; value=\u0026amp;quot;jdbc:mysql://192.168.1.68:3306/myth?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;driverClassName\u0026amp;quot; value=\u0026amp;quot;com.mysql.jdbc.Driver\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;password\u0026amp;quot; value=\u0026amp;quot;Wgj@555888\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;username\u0026amp;quot; value=\u0026amp;quot;xiaoyu\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt; \u0026amp;lt;/property\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt;   Add @Myth to the implementation of your interface.\n Listen to the message queue (message queue name written in the annotations method), invoke the framework provides MythMqReceiveService.processMessage() method. If you use JMS, you can refer to the Demo project for details.\n@JmsListener(destination = \u0026amp;quot;account\u0026amp;quot;,containerFactory = \u0026amp;quot;queueListenerContainerFactory\u0026amp;quot;) public void receiveQueue(byte[] message) { LOGGER.info(\u0026amp;quot;=========Deducting the account information to receive Myth framework incoming information.==========\u0026amp;quot;); final Boolean success = mythMqReceiveService.processMessage(message); if(success){ //If the consumption is successful, the message is out of the queue, otherwise it is not consumed. } }   In the motan consumer (the invoker of the transaction, the caller)\n add …","date":-62135596800,"description":"Myth Motan User","dir":"projects/myth/motan-user/","fuzzywordcount":500,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"b96e0993b917ff08d902dcc3543096cde1d48086","permalink":"/projects/myth/motan-user/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/myth/motan-user/","summary":"Add myth-annotation dependency to motan api project.  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.myth\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;myth-annotation\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt;   Add the @Myth annotation to the motan Interface method and set the name of the message queue, which is the queue from which the messaging middleware sends messages.  @Myth(destination = \u0026quot;account\u0026quot;) boolean payment(AccountDTO accountDTO);   In the motan service provider (the participating method of the transaction, the callee).\n add myth-motan dependency\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.","tags":null,"title":"Motan User","type":"projects","url":"/projects/myth/motan-user/","wordcount":464},{"author":null,"categories":null,"content":" Motan Interface Sectioon  Introduce the jar packages into your interface project.  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-annotation\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   Add the @Hmily annotation on the interface method in which you need to perform Hmily distributed transactions.  public interface HelloService { @Hmily void say(String hello); }  The project with Motan implementation  Step 1 ： Introduce the jar package of the hmily dependency\n Step 2 ： Add Hmily configuration\n Step 3 ： Add the specific annotation to the implementation method. you need to complete the development of confirm and cancel method, if in TCC mode.\n  Introduce The Maven dependency Spring-Namespace  Introduce the hmily-motan dependency  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-motan\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   make the configuration in the XML configuration file as below:  \u0026amp;lt;!-- set up to enable the aspectj-autoproxy --\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id = \u0026amp;quot;hmilyTransactionAspect\u0026amp;quot; class=\u0026amp;quot;org.dromara.hmily.spring.aop.SpringHmilyTransactionAspect\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id = \u0026amp;quot;hmilyApplicationContextAware\u0026amp;quot; class=\u0026amp;quot;org.dromara.hmily.spring.HmilyApplicationContextAware\u0026amp;quot;/\u0026amp;gt;  Spring-Boot-starter  Introduce the hmily-spring-boot-starter-motan dependency  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-spring-boot-starter-motan\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  Introduce the Hmily configuration  new a configuration file named hmily.yml under the resource directory of the current project\n the specific parameter configuration can refer to configuration detail,Local configuration mode, Zookeeper configuration mode, nacos configuration mode,apollo configuration mode\n  Add annotations on the implementation interface We have completed the integration and configuration described above, and the next let\u0026amp;rsquo;s explain how to use it in detail.\nTCC Mode  Add @HmilyTCC (confirmMethod = \u0026amp;quot;confirm\u0026amp;quot;, cancelMethod = \u0026amp;quot;cancel\u0026amp;quot;) annotation to the concrete implementation of the interface method identified by \u0026amp;lsquo;@Hmily\u0026amp;rsquo;.\n confirmMethod : the method name for confirm，The method parameter list and return type should be consistent with the identification method.\n cancelMethod : the method for cancel，The method parameter list and return type should be consistent with the identification method.\n The TCC mode should ensure the idempotence of the confirm and cancel methods,Users need to develop these two methods by themselves,The confirmation and rollback behavior of all transactions are completely up tp users.The Hmily framework is just responsible for making calls.\n  public class HelloServiceImpl implements …","date":-62135596800,"description":"Hmily-Motan Distributed Transaction User Guide","dir":"projects/hmily/user-motan/","fuzzywordcount":700,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"f31a0351067a48e039bb17f0d2bfd50f0cc609a0","permalink":"/projects/hmily/user-motan/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/hmily/user-motan/","summary":"Motan Interface Sectioon  Introduce the jar packages into your interface project.  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.dromara\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;hmily-annotation\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;{last.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   Add the @Hmily annotation on the interface method in which you need to perform Hmily distributed transactions.  public interface HelloService { @Hmily void say(String hello); }  The project with Motan implementation  Step 1 ： Introduce the jar package of the hmily dependency\n Step 2 ： Add Hmily configuration","tags":null,"title":"Motan User Guide","type":"projects","url":"/projects/hmily/user-motan/","wordcount":620},{"author":null,"categories":null,"content":" Firstly, you should bootstrap raincat-manager, please refer to how to bootstrap Txmanager for details. Then, please add following dependency in maven at your service, and add @TxTransaction annotation in your distributed transaction method. \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;raincat-motan\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.0.0-RELEASE\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  Configure TxTransactionBootstrap by Spring XML \u0026amp;lt;context:component-scan base-package=\u0026amp;quot;org.dromara.*\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;txTransactionBootstrap\u0026amp;quot; class=\u0026amp;quot;org.dromara.raincat.core.bootstrap.TxTransactionBootstrap\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;txManagerUrl\u0026amp;quot; value=\u0026amp;quot;http://localhost:8761\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;serializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;nettySerializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;compensation\u0026amp;quot; value=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;compensationCacheType\u0026amp;quot; value=\u0026amp;quot;db\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;txDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;bean class=\u0026amp;quot;org.dromara.raincat.common.config.TxDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;url\u0026amp;quot; value=\u0026amp;quot;jdbc:mysql://192.168.1.98:3306/tx?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;driverClassName\u0026amp;quot; value=\u0026amp;quot;com.mysql.jdbc.Driver\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;username\u0026amp;quot; value=\u0026amp;quot;root\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;password\u0026amp;quot; value=\u0026amp;quot;123456\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt; \u0026amp;lt;/property\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt;  Configure TxTransactionBootstrap by Spring boot starter  Firstly, please add maven dependency raincat-spring-boot-starter-motan.\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;raincat-spring-boot-starter-motan\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.0.0-RELEASE\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   Secondly, please configure the application.yml like follows.  org: dromara: raincat: txManagerUrl: http://localhost:8761 serializer: kroy nettySerializer: kroy compensation: true compensationCacheType : db txDbConfig : driverClassName : com.mysql.jdbc.Driver url : jdbc:mysql://192.168.1.98:3306/tx?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8 username : root password : 123456  txManagerUrl is the ip and port that you bootstrap txManager . Please add http:// at head.\n serializer is the way of transaction log serialization.\n nettySerializer is the serialization way of how to communicate with txManager. Please be caution that It should be consistent with the configuration in txManager.\n compensation is the property whether compensation is required or not, the service will compensate itself in some cases.\n compensationCacheType is the storage types of log, support Redis, Mongodb, Zookeeper, etc. For details, please refer to the config.\n  NOTICE: You need to open AOP when you want to use XML to configure.\n","date":-62135596800,"description":"motan user  guide","dir":"projects/raincat/motan-user/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"1a49ce99f3d9f1015f1ad8b36b91d746b99b75a1","permalink":"/projects/raincat/motan-user/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/raincat/motan-user/","summary":"Firstly, you should bootstrap raincat-manager, please refer to how to bootstrap Txmanager for details. Then, please add following dependency in maven at your service, and add @TxTransaction annotation in your distributed transaction method. \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.dromara\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;raincat-motan\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.0.0-RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;  Configure TxTransactionBootstrap by Spring XML \u0026lt;context:component-scan base-package=\u0026quot;org.dromara.*\u0026quot;/\u0026gt; \u0026lt;aop:aspectj-autoproxy expose-proxy=\u0026quot;true\u0026quot;/\u0026gt; \u0026lt;bean id=\u0026quot;txTransactionBootstrap\u0026quot; class=\u0026quot;org.dromara.raincat.core.bootstrap.TxTransactionBootstrap\u0026quot;\u0026gt; \u0026lt;property name=\u0026quot;txManagerUrl\u0026quot; value=\u0026quot;http://localhost:8761\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;serializer\u0026quot; value=\u0026quot;kryo\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;nettySerializer\u0026quot; value=\u0026quot;kryo\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;compensation\u0026quot; value=\u0026quot;true\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;compensationCacheType\u0026quot; value=\u0026quot;db\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;txDbConfig\u0026quot;\u0026gt; \u0026lt;bean class=\u0026quot;org.","tags":null,"title":"Motan user guide","type":"projects","url":"/projects/raincat/motan-user/","wordcount":235},{"author":null,"categories":null,"content":" cd https://github.com/yu199195/myth/tree/master/myth-demo/myth-demo-motan\n Modifiy application.yml on Indicator Item And Modifiy you jdbc url And zookeeper url And choose you Message Oriented Middleware\nspring: motan: zookeeper: 192.168.1.148:2181 datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://192.168.1.68:3306/myth_account?useUnicode=true\u0026amp;amp;characterEncoding=utf8 username: xiaoyu password: Wgj@555888 #activemq: # broker-url: tcp://120.76.52.162:61616 # user: happylife # password: happylifeplat01 # trust-all: true #rabbitmq: # host: localhost # port: 5672 # username: guest # password: guest rocketmq: namesrvAddr: 192.168.1.148:9876 consumerGroupName: account instanceName: account #kafka: # consumer: # bootstrap-servers: localhost:9092 # group-id: test # auto-offset-reset: earliest # enable-auto-commit: true # auto-commit-interval: 100 # key-deserializer: org.apache.kafka.common.serialization.StringDeserializer # value-deserializer: org.apache.kafka.common.serialization.ByteArrayDeserializer   Modifiy applicationContext.xml on Indicator Item And choose repositorySupport and modifiy it  \u0026amp;lt;context:component-scan base-package=\u0026amp;quot;com.github.myth.*\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;mythTransactionBootstrap\u0026amp;quot; class=\u0026amp;quot;com.github.myth.core.bootstrap.MythTransactionBootstrap\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;repositorySuffix\u0026amp;quot; value=\u0026amp;quot;account-service\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;serializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;coordinatorQueueMax\u0026amp;quot; value=\u0026amp;quot;5000\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;coordinatorThreadMax\u0026amp;quot; value=\u0026amp;quot;8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;rejectPolicy\u0026amp;quot; value=\u0026amp;quot;Abort\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;blockingQueueType\u0026amp;quot; value=\u0026amp;quot;Linked\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;repositorySupport\u0026amp;quot; value=\u0026amp;quot;db\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;mythDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;bean class=\u0026amp;quot;com.github.myth.common.config.MythDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;url\u0026amp;quot; value=\u0026amp;quot;jdbc:mysql://192.168.1.68:3306/myth?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;driverClassName\u0026amp;quot; value=\u0026amp;quot;com.mysql.jdbc.Driver\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;password\u0026amp;quot; value=\u0026amp;quot;Wgj@555888\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;username\u0026amp;quot; value=\u0026amp;quot;xiaoyu\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt; \u0026amp;lt;/property\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt;  run MotanAccountApplication.java\n run MotanInventoryApplication.java\n run MotanOrderApplication.java\nthis mq sender so befer:\n in applicationContext.xml choose import you mq sender config\n  \u0026amp;lt;import resource=\u0026amp;quot;spring-rocketmq.xml\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;!--\u0026amp;lt;import resource=\u0026amp;quot;spring-rabbitmq.xml\u0026amp;quot;/\u0026amp;gt;--\u0026amp;gt; \u0026amp;lt;!--\u0026amp;lt;import resource=\u0026amp;quot;spring-kafka.xml\u0026amp;quot;/\u0026amp;gt;--\u0026amp;gt; \u0026amp;lt;!--\u0026amp;lt;import resource=\u0026amp;quot;spring-activemq.xml\u0026amp;quot;/\u0026amp;gt;--\u0026amp;gt;   modifiy you mq config for example  \u0026amp;lt;bean id=\u0026amp;quot;defaultMQProducer\u0026amp;quot; …","date":-62135596800,"description":"Motan 快速开始","dir":"projects/myth/quick-start-motan/","fuzzywordcount":300,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"6410e98e25bfaa06e53e9f5f0707984193e7e15b","permalink":"/zh/projects/myth/quick-start-motan/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/zh/projects/myth/quick-start-motan/","summary":"cd https://github.com/yu199195/myth/tree/master/myth-demo/myth-demo-motan Modifiy application.yml on Indicator Item And Modifiy you jdbc url And zookeeper url And choose you Message Oriented Middleware spring: motan: zookeeper: 192.168.1.148:2181 datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://192.168.1.68:3306/myth_account?useUnicode=true\u0026amp;characterEncoding=utf8 username: xiaoyu password: Wgj@555888 #activemq: # broker-url: tcp://120.76.52.162:61616 # user: happylife # password: happylifeplat01 # trust-all: true #rabbitmq: # host: localhost # port: 5672 # username: guest # password: guest rocketmq: namesrvAddr: 192.168.1.148:9876 consumerGroupName: account instanceName: account #kafka: # consumer:","tags":null,"title":"Motan 快速开始","type":"projects","url":"/zh/projects/myth/quick-start-motan/","wordcount":208},{"author":null,"categories":null,"content":" 在motan api 项目引入myth-annotation jar包  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.github.myth\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;myth-annotation\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   在motan interface 方法上加上@Myth注解 ,并设置消息队列名称,此队列就是消息中间件发消息的队列：  @Myth(destination = \u0026amp;quot;account\u0026amp;quot;) boolean payment(AccountDTO accountDTO);   在motan 服务提供方（事务的参与方法，被调用方）\n 引入myth-motan 包\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.github.myth\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;myth-motan\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   配置 MythTransactionBootstrap启动类,可以采用xml方式，或者@Bean的方式,具体配置可以参考:配置详解  \u0026amp;lt;context:component-scan base-package=\u0026amp;quot;com.github.myth.*\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;mythTransactionBootstrap\u0026amp;quot; class=\u0026amp;quot;com.github.myth.core.bootstrap.MythTransactionBootstrap\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;repositorySuffix\u0026amp;quot; value=\u0026amp;quot;account-service\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;serializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;coordinatorQueueMax\u0026amp;quot; value=\u0026amp;quot;5000\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;coordinatorThreadMax\u0026amp;quot; value=\u0026amp;quot;8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;rejectPolicy\u0026amp;quot; value=\u0026amp;quot;Abort\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;blockingQueueType\u0026amp;quot; value=\u0026amp;quot;Linked\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;repositorySupport\u0026amp;quot; value=\u0026amp;quot;db\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;mythDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;bean class=\u0026amp;quot;com.github.myth.common.config.MythDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;url\u0026amp;quot; value=\u0026amp;quot;jdbc:mysql://192.168.1.68:3306/myth?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;driverClassName\u0026amp;quot; value=\u0026amp;quot;com.mysql.jdbc.Driver\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;password\u0026amp;quot; value=\u0026amp;quot;Wgj@555888\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;username\u0026amp;quot; value=\u0026amp;quot;xiaoyu\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt; \u0026amp;lt;/property\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt;   在你接口的实现方法上加上@Myth\n 监听消息队列（注解方法上写的消息队列名称),调用框架提供 的MythMqReceiveService.processMessage方法。列如使用jms，具体可以参考demo工程。\n@JmsListener(destination = \u0026amp;quot;account\u0026amp;quot;,containerFactory = \u0026amp;quot;queueListenerContainerFactory\u0026amp;quot;) public void receiveQueue(byte[] message) { LOGGER.info(\u0026amp;quot;=========扣减账户信息接收到Myth框架传入的信息==========\u0026amp;quot;); final Boolean success = mythMqReceiveService.processMessage(message); if(success){ //消费成功，消息出队列，否则不消费 } }   在motan 消费方（事务的发起者，调用方）\n 引入myth-motan 包\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.github.myth\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;myth-motan\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;    配置 MythTransactionBootstrap启动类,可以采用xml方式，或者@Bean的方式,具体配置可以参考:配置详解\n\u0026amp;lt;context:component-scan base-package=\u0026amp;quot;com.github.myth.*\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;mythTransactionBootstrap\u0026amp;quot; class=\u0026amp;quot;com.github.myth.core.bootstrap.MythTransactionBootstrap\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;repositorySuffix\u0026amp;quot; value=\u0026amp;quot;account-service\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;serializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; …","date":-62135596800,"description":"Myth Motan User","dir":"projects/myth/motan-user/","fuzzywordcount":1000,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"28be0e1462461dc93a905a7ff214bd902076a23d","permalink":"/zh/projects/myth/motan-user/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/zh/projects/myth/motan-user/","summary":"在motan api 项目引入myth-annotation jar包 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.myth\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;myth-annotation\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 在motan interface 方法上加上@Myth注解 ,并设置消息队列名称,此队列就是消","tags":null,"title":"Motan 用户","type":"projects","url":"/zh/projects/myth/motan-user/","wordcount":978},{"author":null,"categories":null,"content":" 环境准备  JDK 1.8+ Maven 3.2.x Git Zookeeper  代码拉取  \u0026amp;gt; git clone https://github.com/dromara/hmily.git \u0026amp;gt; cd hmily \u0026amp;gt; mvn -DskipTests clean install -U  执行demo 模块的sql语句。 sql语句\n使用你的工具 idea 打开项目，找到hmily-demo-motan项目，进行maven构建 修改项目配置（hmily-demo-motan-account为列子）  application.yml 下修改业务数据库(account项目为列子)  spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://改成你的ip+端口/hmily_account?useUnicode=true\u0026amp;amp;characterEncoding=utf8 username: #改成你的用户名 password: #改成你的密码   application.yml 下修改motan的注册中心地址(可以在自己电脑本地启动一个zookeeper服务)  hmily : motan : #注册中心配置 registry : address : 127.0.0.1:2181 #注册中心地址   修改 hmily.yml,这里使用mysql来存储  repository: database: driverClassName: com.mysql.jdbc.Driver url : jdbc:mysql://改成你的ip+端口/hmily?useUnicode=true\u0026amp;amp;characterEncoding=utf8 username: root #改成你的用户名 password: #改成你的密码   run MotanHmilyAccountApplication.java  启动hmily-demo-motan-inventory 参考上述。 启动hmily-demo-motan-order 参考上述。 访问：http://127.0.0.1:8088/swagger-ui.html。 ","date":-62135596800,"description":"motan快速体验","dir":"projects/hmily/quick-start-motan/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"6874d46d471a1d72334dfd6c7d749642cc4e63aa","permalink":"/zh/projects/hmily/quick-start-motan/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/zh/projects/hmily/quick-start-motan/","summary":"环境准备 JDK 1.8+ Maven 3.2.x Git Zookeeper 代码拉取 \u0026gt; git clone https://github.com/dromara/hmily.git \u0026gt; cd hmily \u0026gt; mvn -DskipTests clean install -U 执行demo 模块的sql语句。 sql语句 使用你的工具 idea 打开项目，找到hmily-dem","tags":null,"title":"Motan快速体验","type":"projects","url":"/zh/projects/hmily/quick-start-motan/","wordcount":537},{"author":null,"categories":null,"content":" Motan接口部分  在你的接口项目中引入jar包。  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-annotation\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   在需要进行Hmily分布式事务的接口方法上加上 @Hmily 标识。  public interface HelloService { @Hmily void say(String hello); }  Motan实现项目  步骤一 ： 引入依赖hmily的jar包\n 步骤二 ： 新增Hmily配置\n 步骤三 ： 在实现方法上添加注解。TCC模式，则需要完成 confirm，cancel方法的开发\n  引入依赖 Spring-Namespace  引入依赖  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-motan\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   在xml中进行如下配置  \u0026amp;lt;!--设置开启aspectj-autoproxy--\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id = \u0026amp;quot;hmilyTransactionAspect\u0026amp;quot; class=\u0026amp;quot;org.dromara.hmily.spring.aop.SpringHmilyTransactionAspect\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id = \u0026amp;quot;hmilyApplicationContextAware\u0026amp;quot; class=\u0026amp;quot;org.dromara.hmily.spring.HmilyApplicationContextAware\u0026amp;quot;/\u0026amp;gt;  Spring-Boot-starter  用户引入  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-spring-boot-starter-motan\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  引入 hmily配置  在项目的 resource 添加文件名为:hmily.yml配置文件\n 具体的参数配置可以参考配置详解,本地配置模式, zookeeper配置模式, nacos配置模式,apollo配置模式\n  实现接口上添加注解 在上述中，我们已经完成了集成与配置，现在我们来详解说一下如何进行使用。\nTCC模式  在添加@Hmily 标识的接口方法的具体实现上 加上@HmilyTCC(confirmMethod = \u0026amp;quot;confirm\u0026amp;quot;, cancelMethod = \u0026amp;quot;cancel\u0026amp;quot;)\n confirmMethod : 确认方法名称，该方法参数列表与返回类型应与标识方法一致。\n cancelMethod : 回滚方法名称，该方法参数列表与返回类型应与标识方法一致。\n TCC模式应该保证 confirm 和 cancel 方法的幂等性，用户需要自行去开发这个2个方法，所有的事务的确认与回滚，完全由用户决定。Hmily框架只是负责来进行调用\n  public class HelloServiceImpl implements HelloService { @HmilyTCC(confirmMethod = \u0026amp;quot;sayConfrim\u0026amp;quot;, cancelMethod = \u0026amp;quot;sayCancel\u0026amp;quot;) public void say(String hello) { System.out.println(\u0026amp;quot;hello world\u0026amp;quot;); } public void sayConfrim(String hello) { System.out.println(\u0026amp;quot; confirm hello world\u0026amp;quot;); } public void sayCancel(String hello) { System.out.println(\u0026amp;quot; cancel hello world\u0026amp;quot;); } }  motan注解用户 对于使用 @MotanReferer 注解来注入motan服务的用户，请注意：你可以需要做如下配置:\nspring-namespace 用户 在你的xml配置中，需要将 org.dromara.hmily.spring.annotation.RefererAnnotationBeanPostProcessor 注入成spring的bean\n\u0026amp;lt;bean id = \u0026amp;quot;refererAnnotationBeanPostProcessor\u0026amp;quot; class=\u0026amp;quot;org.dromara.hmily.spring.annotation.RefererAnnotationBeanPostProcessor\u0026amp;quot;/\u0026amp;gt;  spring-boot用户 需要在yml文件里面开启注解支持：\nhmily.support.rpc.annotation = true  或者在项目中显示注入：\n@Bean public BeanPostProcessor refererAnnotationBeanPostProcessor() { return new RefererAnnotationBeanPostProcessor(); }  TAC模式 (在开发，未发布)  对@Hmily 标识的接口方法的具体实现加上@HmilyTAC   重要注意事项 在调用任何RPC调用之前，当你需要聚合rpc调用成为一次分布式事务的时候，需要在聚合RPC调用的方法上，先行添加 @HmilyTCC 或者 @HmilyTAC 注解,表示开启全局事务。\n负载均衡  如果服务部署了几个节点， 负载均衡算法最好使用 hmily, 这样 try, confirm, cancel 调用会落在同一个节点 充分利用了缓存，提搞了效率。\n 支持一下几种 hmilyActiveWeight, hmilyConfigurableWeight, hmilyConsistent, hmilyLocalFirst, hmilyRandom, hmilyRoundRobin 几种方式均是继承Motan …","date":-62135596800,"description":"Hmily-Motan分布式事务用户指南","dir":"projects/hmily/user-motan/","fuzzywordcount":1100,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"fd3b8d73ac60ac841f6a0c3e5ceb0ebb7b7effff","permalink":"/zh/projects/hmily/user-motan/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/zh/projects/hmily/user-motan/","summary":"Motan接口部分 在你的接口项目中引入jar包。 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.dromara\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;hmily-annotation\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;{last.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在需要进行Hmily分布式事务的接口方法上加上 @Hmily 标识。 public interface HelloService { @Hmily void say(String hello); } Motan","tags":null,"title":"Motan用户指南","type":"projects","url":"/zh/projects/hmily/user-motan/","wordcount":1045},{"author":null,"categories":null,"content":" source code parsing for annotation  /** * Myth is the annotation of distributed transaction framework. */ @Retention(RetentionPolicy.RUNTIME) @Target({ElementType.METHOD}) public @interface Myth { /** * The destination name for this listener, resolved through the container-wide */ String destination(); /** * Target interface class * If you are a SpringCloud user, you need to specify the target interface service. * (Since SpringCloud is an HTTP request that cannot be invoked through reflection serialization, this property is added.) * If you are a Dubbo user, you do not need to specify it. * If you are a Motan user, you do not need to specify it, too. * * @return Class */ Class target() default Object.class; /** * The method name of target interface * If you are a SpringCloud user, you need to specify the method name of the target. * （Since SpringCloud is an HTTP request that cannot be invoked through reflection serialization, this property is added.） * If you are a Dubbo user, you do not need to specify it. * If you are a Motan user, you do not need to specify it, too. * * @return String */ String targetMethod() default \u0026amp;quot;\u0026amp;quot;; /** * Whether there is a transaction, Here specifically refers to the invoker have a database operation.（Is there a transaction operation） * * @return PropagationEnum */ PropagationEnum propagation() default PropagationEnum.PROPAGATION_REQUIRED; /** * MQ message pattern * * @return MessageTypeEnum */ MessageTypeEnum pattern() default MessageTypeEnum.P2P;  The usage of Annotation: add the @Myth annotation to interface method and implementation class(Dubbo,motan added to the API interface. The SpringCloud needs to be added to FeignClient). Refer to the demo project for details.\n applicationContext.xml for details:  \u0026amp;lt;!-- aspect configuration, whether to open the AOP aspect--\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;!--The package of the scanning framework--\u0026amp;gt; \u0026amp;lt;context:component-scan base-package=\u0026amp;quot;com.github.myth.*\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;!--The property configuration of start class --\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;mythTransactionBootstrap\u0026amp;quot; class=\u0026amp;quot;com.github.myth.core.bootstrap.MythTransactionBootstrap\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;repositorySuffix\u0026amp;quot; value=\u0026amp;quot;account-service\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;serializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;coordinatorQueueMax\u0026amp;quot; value=\u0026amp;quot;5000\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;coordinatorThreadMax\u0026amp;quot; value=\u0026amp;quot;8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;rejectPolicy\u0026amp;quot; value=\u0026amp;quot;Abort\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;blockingQueueType\u0026amp;quot; value=\u0026amp;quot;Linked\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;repositorySupport\u0026amp;quot; value=\u0026amp;quot;db\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;mythDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;bean class=\u0026amp;quot;com.github.myth.common.config.MythDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;url\u0026amp;quot; …","date":-62135596800,"description":"Myth Configuration","dir":"projects/myth/config/","fuzzywordcount":800,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"6811269ec7690c2aa227a8366aa3718a84832857","permalink":"/projects/myth/config/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/myth/config/","summary":"source code parsing for annotation /** * Myth is the annotation of distributed transaction framework. */ @Retention(RetentionPolicy.RUNTIME) @Target({ElementType.METHOD}) public @interface Myth { /** * The destination name for this listener, resolved through the container-wide */ String destination(); /** * Target interface class * If you are a SpringCloud user, you need to specify the target interface service. * (Since SpringCloud is an HTTP request that cannot be invoked through reflection","tags":null,"title":"Myth Configuration","type":"projects","url":"/projects/myth/config/","wordcount":775},{"author":null,"categories":null,"content":" An open source framework that uses message queue to solve distributed transactions. Developed based on Java language (JDK1.8), it supports Dubbo, SpringCloud, Motan and other RPC frameworks for distributed transactions.\nFeatures  Integrate spring-boot-starter. RPC framework support: dubbo,motan,springcloud. Message middleware suooprt : jms(activimq), amqp(rabbitmq), kafka, roceketmq. Local transaction storage support: redis, mogondb, zookeeper, file, mysql. Transaction log serialization support ：java，hessian，kryo，protostuff. Aspect AOP facets are used to integrate with Spring and support clustering, high availability and high concurrency. Simple configuration, simple integration, simple source code, high stability, has been used in the production environment. Built-in classic distributed transaction scene Demo project, and Swagger-UI visual interface can be quickly experienced.  Parsing the source code  https://juejin.im/post/5a5c63986fb9a01cb64ec517  Video  Setup environment and running Explain principle(one) Explain principle(two)  Prerequisite  JDK 1.8+ Maven 3.2.x Git RPC framework dubbo or motan or springcloud。 Message Oriented Middleware  ","date":-62135596800,"description":"Myth Introduction","dir":"projects/myth/overview/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"6af1dc856f4f538087d18b8034ec6037c7d4ef5a","permalink":"/projects/myth/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/myth/overview/","summary":"An open source framework that uses message queue to solve distributed transactions. Developed based on Java language (JDK1.8), it supports Dubbo, SpringCloud, Motan and other RPC frameworks for distributed transactions.\nFeatures  Integrate spring-boot-starter. RPC framework support: dubbo,motan,springcloud. Message middleware suooprt : jms(activimq), amqp(rabbitmq), kafka, roceketmq. Local transaction storage support: redis, mogondb, zookeeper, file, mysql. Transaction log serialization support ：java，hessian，kryo，protostuff. Aspect AOP facets are used to integrate with Spring and support clustering, high availability and high concurrency.","tags":null,"title":"Myth Introduction","type":"projects","url":"/projects/myth/overview/","wordcount":137},{"author":null,"categories":null,"content":" 采用消息队列解决分布式事务的开源框架, 基于java语言来开发（JDK1.8），支持dubbo，springcloud,motan等rpc框架进行分布式事务。\nFeatures  天然无缝集成 spring-boot-starter 。\n RPC框架支持 : dubbo,motan,springcloud。\n 消息中间件支持 : jms(activimq),amqp(rabbitmq),kafka,roceketmq。\n 本地事务存储支持 : redis,mogondb,zookeeper,file,mysql。\n 事务日志序列化支持 ：java，hessian，kryo，protostuff。\n 采用Aspect AOP 切面思想与Spring无缝集成，天然支持集群,高可用,高并发。\n 配置简单，集成简单，源码简洁，稳定性高，已在生产环境使用。\n 内置经典的分布式事务场景demo工程，并有swagger-ui可视化界面可以快速体验。\n  源码解析  https://juejin.im/post/5a5c63986fb9a01cb64ec517   视频详解  环境搭建以及运行 : http://www.iqiyi.com/w_19rw5zuigl.html 原理讲解（1）：http://www.iqiyi.com/w_19rw5ztpkh.html 原理讲解（2）：http://www.iqiyi.com/w_19rw5zslm1.html   Prerequisite  JDK 1.8+ Maven 3.2.x Git RPC framework dubbo or motan or springcloud。 Message Oriented Middleware  ","date":-62135596800,"description":"Myth是基于可靠消息最终一致性分布式事务框架，无缝支持dubbo，springcloud,motan等rpc框架的微服务","dir":"projects/myth/overview/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"d76c2e39dd7f3763b1e6ee578e5855d4e23c0122","permalink":"/zh/projects/myth/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/zh/projects/myth/overview/","summary":"采用消息队列解决分布式事务的开源框架, 基于java语言来开发（JDK1.8），支持dubbo，springcloud,motan等rpc框架","tags":null,"title":"Myth 介绍","type":"projects","url":"/zh/projects/myth/overview/","wordcount":505},{"author":null,"categories":null,"content":" 注解源码解析  /** * myth分布式事务框架注解 */ @Retention(RetentionPolicy.RUNTIME) @Target({ElementType.METHOD}) public @interface Myth { /** * The destination name for this listener, resolved through the container-wide */ String destination(); /** * 目标接口类 * 如果是springcloud用户，需要指定目标的接口服务 * （因为springcloud是http的请求，通过反射序列化方式没办法调用，所有加了这个属性） * 如果是dubbo用户 则不需要指定 * 如果是motan用户 则不需要指定 * * @return Class */ Class target() default Object.class; /** * 目标接口方法名称 * 如果是springcloud用户，需要指定目标的方法名称 * （因为springcloud是http的请求，通过反射序列化方式没办法调用，所有加了这个属性） * 如果是dubbo用户 则不需要指定 * 如果是motan用户 则不需要指定 * * @return String */ String targetMethod() default \u0026amp;quot;\u0026amp;quot;; /** * 是否有事务 这里具体指的是发起方是否有进行数据库的操作（是否有事务操作） * * @return PropagationEnum */ PropagationEnum propagation() default PropagationEnum.PROPAGATION_REQUIRED; /** * mq 消息模式 * * @return MessageTypeEnum */ MessageTypeEnum pattern() default MessageTypeEnum.P2P;   注解使用： 在接口方法和实现类上添加@Myth注解（dubbo,motan 加在api接口上，springcloud则需要加在feignClient上），具体参考demo工程。\n applicationContext.xml 详解：\n  \u0026amp;lt;!-- Aspect 切面配置，是否开启AOP切面--\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;!--扫描框架的包--\u0026amp;gt; \u0026amp;lt;context:component-scan base-package=\u0026amp;quot;com.github.myth.*\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;!--启动类属性配置--\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;mythTransactionBootstrap\u0026amp;quot; class=\u0026amp;quot;com.github.myth.core.bootstrap.MythTransactionBootstrap\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;repositorySuffix\u0026amp;quot; value=\u0026amp;quot;account-service\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;serializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;coordinatorQueueMax\u0026amp;quot; value=\u0026amp;quot;5000\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;coordinatorThreadMax\u0026amp;quot; value=\u0026amp;quot;8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;rejectPolicy\u0026amp;quot; value=\u0026amp;quot;Abort\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;blockingQueueType\u0026amp;quot; value=\u0026amp;quot;Linked\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;repositorySupport\u0026amp;quot; value=\u0026amp;quot;db\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;mythDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;bean class=\u0026amp;quot;com.github.myth.common.config.MythDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;url\u0026amp;quot; value=\u0026amp;quot;jdbc:mysql://192.168.1.68:3306/myth?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;driverClassName\u0026amp;quot; value=\u0026amp;quot;com.mysql.jdbc.Driver\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;password\u0026amp;quot; value=\u0026amp;quot;Wgj@555888\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;username\u0026amp;quot; value=\u0026amp;quot;xiaoyu\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt; \u0026amp;lt;/property\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt;   MythTransactionBootstrap 详解（具体参见com.github.myth.common.config.MythConfig）  \u0026amp;lt;!--数据保存序列化方式 spi扩展支持 java kroy，hessian protostuff 推荐使用kroy--\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;serializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;!--协调资源线程池最大队列--\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;coordinatorQueueMax\u0026amp;quot; value=\u0026amp;quot;5000\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;!--协调资源线程池最大线程--\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;coordinatorThreadMax\u0026amp;quot; value=\u0026amp;quot;4\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;!-- 线程池中的队列类型 spi扩展支持 Linked Array SynchronousQueue--\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;blockingQueueType\u0026amp;quot; value=\u0026amp;quot;Linked\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;!--线程池中的拒绝策略 spi扩展支持 Abort …","date":-62135596800,"description":"Myth Configuration","dir":"projects/myth/config/","fuzzywordcount":1400,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"e6cc4187323a61f322c93e1ea3524998aaed6731","permalink":"/zh/projects/myth/config/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/zh/projects/myth/config/","summary":"注解源码解析 /** * myth分布式事务框架注解 */ @Retention(RetentionPolicy.RUNTIME) @Target({ElementType.METHOD}) public @interface Myth { /** * The destination name for this listener, resolved through the container-wide */ String destination(); /** * 目标接口类 * 如果是springcloud用户，需要","tags":null,"title":"Myth 配置","type":"projects","url":"/zh/projects/myth/config/","wordcount":1318},{"author":null,"categories":null,"content":" Startup premise: the distributed transaction project has been deployed and running, and users use it according to their own RPC framework.\n First, the JDK must be 1.8+, and Git and Maven are installed locally. Execute the following command.\ngit clone https://github.com/yu199195/myth.git maven clean install  Open the project with your development tool，for example Idea , Eclipse.\n  Step One:  Edit application.properties in myth-admin project.  server.port=8888 server.context-path=/myth-admin server.address=0.0.0.0 spring.application.name=myth-admin #Activation method: refers to the method used to store the transaction log, which is the same as the business module. spring.profiles.active=db # myth admin username myth.admin.userName=admin # myth admin password myth.admin.password=admin # The suffix of the transaction log storage path of each project must be specified here. myth.repository.suffix.list=account-service,inventory-service,order-service # Supported serialization methods, each item needs to be configured to be the same. myth.serializer.support=kryo myth.retry.max=10 #dbSuport myth.db.driver=com.mysql.jdbc.Driver myth.db.url=jdbc:mysql://192.168.1.68:3306/myth?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8 myth.db.username=xiaoyu myth.db.password=Wgj@555888 #redis myth.redis.cluster=false myth.redis.hostName=192.168.1.68 myth.redis.port=6379 myth.redis.password= #myth.redis.clusterUrl=127.0.0.1:70001;127.0.1:7002 #mongo myth.mongo.url=192.168.1.68:27017 myth.mongo.dbName=happylife #myth.mongo.userName=xiaoyu myth.mongo.password=123456 #zookeeper myth.zookeeper.host=192.168.1.116:2181 myth.zookeeper.sessionTimeOut=200000  Configuration explanation  myth.repository.suffix.list: it is necessary to configure the resource suffix of each system module participating in the distributed transaction of myth, and multiple modules are separated by \u0026amp;ldquo;,\u0026amp;rdquo;,which must be configured here.\n myth.serializer.support: it refers to the serialization mode of configuration transaction compensation information in Tcc distributed transaction system.\n spring.profiles.active: The type of admin project activation supports db, file, mongo and zookeeper. This refers to the storage mode of transaction compensation information in the distributed transaction system participating in Myth. If you use db for storage, it is configured as db, and information such as db is configured at the same time. Other ways are the same. Note that each module should use the same serialization method and storage type.\n myth.admin: Here is the user and password of the admin system, and the user can make custom changes.\n  Step Two: modify index.html under the static folder of this project. \u0026amp;lt;!--replace your ip and port in href property--\u0026amp;gt; \u0026amp;lt;a id=\u0026amp;quot;serverIpAddress\u0026amp;quot; style=\u0026amp;quot;display: none\u0026amp;quot; href=\u0026amp;quot;http://localhost:8888/admin\u0026amp;quot;\u0026amp;gt;  Step Three: run the main method in MythAdminApplication . Step Four: visit http://ip:port/myth-admin/index.html in the …","date":-62135596800,"description":"Myth-admin startup tutorial","dir":"projects/myth/start-myth-admin/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"96b852d1a686122e872b75c71c545a41b7cc0af9","permalink":"/projects/myth/start-myth-admin/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/myth/start-myth-admin/","summary":"Startup premise: the distributed transaction project has been deployed and running, and users use it according to their own RPC framework.\n First, the JDK must be 1.8+, and Git and Maven are installed locally. Execute the following command.\ngit clone https://github.com/yu199195/myth.git maven clean install  Open the project with your development tool，for example Idea , Eclipse.\n  Step One:  Edit application.properties in myth-admin project.  server.port=8888 server.","tags":null,"title":"Myth-admin startup tutorial","type":"projects","url":"/projects/myth/start-myth-admin/","wordcount":348},{"author":null,"categories":null,"content":" 启动前提：分布式事务项目已经部署并且运行起来，用户根据自己的RPC框架进行使用\n 首先用户使用的JDK必须是1.8+ 本地安装了git ,maven ，执行以下命令\ngit clone https://github.com/yu199195/myth.git maven clean install  使用你的开发工具打开项目，比如idea Eclipse\n  步骤一：  修改 myth-admin项目中的application.properties文件  server.port=8888 server.context-path=/myth-admin server.address=0.0.0.0 spring.application.name=myth-admin #激活方式 指的是存储事务日志采取的方式 同业务模块一样 spring.profiles.active=db # myth 管理后台用户名 myth.admin.userName=admin # myth 管理后台密码 myth.admin.password=admin # 各项目的事务日志存储路径的后缀，这里一定需要指定 myth.repository.suffix.list=account-service,inventory-service,order-service # 各项目支持的序列化方式 每个项目需要配置成一样的 myth.serializer.support=kryo myth.retry.max=10 #dbSuport myth.db.driver=com.mysql.jdbc.Driver myth.db.url=jdbc:mysql://192.168.1.68:3306/myth?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8 myth.db.username=xiaoyu myth.db.password=Wgj@555888 #redis myth.redis.cluster=false myth.redis.hostName=192.168.1.68 myth.redis.port=6379 myth.redis.password= #myth.redis.clusterUrl=127.0.0.1:70001;127.0.1:7002 #mongo myth.mongo.url=192.168.1.68:27017 myth.mongo.dbName=happylife #myth.mongo.userName=xiaoyu myth.mongo.password=123456 #zookeeper myth.zookeeper.host=192.168.1.116:2181 myth.zookeeper.sessionTimeOut=200000  配置解释  关于 myth.repository.suffix.list配置：这里需要配置每个参与myth分布式事务的系统模块的资源后缀，多个模块用 \u0026amp;ldquo;,\u0026amp;rdquo; 分隔，这里必须要配置。\n 关于 myth.serializer.support 配置，这里是指参与Tcc分布式事务系统中，配置事务补偿信息的序列化方式。\n 关于 spring.profiles.active 配置 admin项目激活的类型，支持db，file，mongo，zookeeper， 这里是指参与Myth分布式事务系统中，配置事务补偿信息存储方式，如果您用db存储，那这里就配置成db，同时配置好db等信息。 其他方式同理。 注意，每个模块请使用相同的序列化方式和存储类型\n 关于 myth.admin 等配置。 这里就是管理后台登录的用户与密码，用户可以进行自定义更改。\n  步骤二：修改本项目static 文件夹下的 index.html \u0026amp;lt;!--href 修改成你的ip 端口--\u0026amp;gt; \u0026amp;lt;a id=\u0026amp;quot;serverIpAddress\u0026amp;quot; style=\u0026amp;quot;display: none\u0026amp;quot; href=\u0026amp;quot;http://localhost:8888/admin\u0026amp;quot;\u0026amp;gt;  步骤三: 运行 MythAdminApplication 中的main方法。 步骤四:在浏览器访问 http://ip:port/myth-admin/index.html ,输入用户名，密码登录。 如有任何问题欢迎加入QQ群：162614487 进行讨论\n","date":-62135596800,"description":"Myth-admin startup tutorial","dir":"projects/myth/start-myth-admin/","fuzzywordcount":700,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"32e8bb4a5d2dc4e814ef4d7e598a5493145bc75a","permalink":"/zh/projects/myth/start-myth-admin/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/zh/projects/myth/start-myth-admin/","summary":"启动前提：分布式事务项目已经部署并且运行起来，用户根据自己的RPC框架进行使用 首先用户使用的JDK必须是1.8+ 本地安装了git ,maven ，执行以下","tags":null,"title":"Myth-admin 启动教程","type":"projects","url":"/zh/projects/myth/start-myth-admin/","wordcount":665},{"author":null,"categories":null,"content":" I have imported the jar package to my project, but found that my project cannot be started, what should I do if any error reported?  Answer : When you meet this kind of error, it requires you to locate the problem yourself, you can check the items as bellow:  check whether the framework configuration is carried out according to the document whether your project runtime environment is correct whether there is any dependency conflict problem   If your problem is still present after above check items, you can provide an issue on github of this project, our team will provide technique support as soon as possible.\nWhat if the microservice act as abnormal, but the transaction was not rolled back?  Answer : First of all, you can check the transaction log records. If the transaction log records exist, the rollback will be performed after the scheduled time you configured.  What should I do if I compile the source code and found that the get and set methods are missing?  Answer : The source code uses lombok, you may need to install the corresponding plug-in in your development tool. (No set get method does not affect the operation).  ","date":-62135596800,"description":"Frequently asked questions","dir":"projects/hmily/faq/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"84bf7acf770406520b2276e6a6d95395d5343c18","permalink":"/projects/hmily/faq/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/hmily/faq/","summary":"I have imported the jar package to my project, but found that my project cannot be started, what should I do if any error reported?  Answer : When you meet this kind of error, it requires you to locate the problem yourself, you can check the items as bellow:  check whether the framework configuration is carried out according to the document whether your project runtime environment is correct whether there is any dependency conflict problem   If your problem is still present after above check items, you can provide an issue on github of this project, our team will provide technique support as soon as possible.","tags":null,"title":"Questions","type":"projects","url":"/projects/hmily/faq/","wordcount":196},{"author":null,"categories":null,"content":" cd https://github.com/yu199195/myth/tree/master/myth-demo/myth-demo-dubbo\n Modifiy application.yml on Indicator Item And Modifiy you jdbc url And choose you Message Oriented Middleware\n  spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://192.168.1.68:3306/myth_account?useUnicode=true\u0026amp;amp;characterEncoding=utf8 username: xiaoyu password: Wgj@555888 #activemq: # broker-url: tcp://120.76.52.162:61616 # user: happylife # password: happylifeplat01 # trust-all: true #rabbitmq: # host: localhost # port: 5672 # username: guest # password: guest rocketmq: namesrvAddr: 192.168.1.148:9876 consumerGroupName: account instanceName: account #kafka: # consumer: # bootstrap-servers: localhost:9092 # group-id: test # auto-offset-reset: earliest # enable-auto-commit: true # auto-commit-interval: 100 # key-deserializer: org.apache.kafka.common.serialization.StringDeserializer # value-deserializer: org.apache.kafka.common.serialization.ByteArrayDeserializer   Modifiy applicationContext.xml on Indicator Item And choose repositorySupport and modifiy it\n If you use database compensation , You have to create a new database for example：myth\n\u0026amp;lt;context:component-scan base-package=\u0026amp;quot;com.github.myth.*\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;mythTransactionBootstrap\u0026amp;quot; class=\u0026amp;quot;com.github.myth.core.bootstrap.MythTransactionBootstrap\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;repositorySuffix\u0026amp;quot; value=\u0026amp;quot;account-service\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;serializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;coordinatorQueueMax\u0026amp;quot; value=\u0026amp;quot;5000\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;coordinatorThreadMax\u0026amp;quot; value=\u0026amp;quot;8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;rejectPolicy\u0026amp;quot; value=\u0026amp;quot;Abort\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;blockingQueueType\u0026amp;quot; value=\u0026amp;quot;Linked\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;repositorySupport\u0026amp;quot; value=\u0026amp;quot;db\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;mythDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;bean class=\u0026amp;quot;com.github.myth.common.config.MythDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;url\u0026amp;quot; value=\u0026amp;quot;jdbc:mysql://192.168.1.68:3306/myth?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;driverClassName\u0026amp;quot; value=\u0026amp;quot;com.mysql.jdbc.Driver\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;password\u0026amp;quot; value=\u0026amp;quot;Wgj@555888\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;username\u0026amp;quot; value=\u0026amp;quot;xiaoyu\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt; \u0026amp;lt;/property\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt;   Modifiy spring-dubbo.xml on Indicator Item And modifiy zookeeper url   \u0026amp;lt;dubbo:application name=\u0026amp;quot;account-service\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;dubbo:registry protocol=\u0026amp;quot;zookeeper\u0026amp;quot; address=\u0026amp;quot;192.168.1.148:2181\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;dubbo:protocol accesslog=\u0026amp;quot;true\u0026amp;quot; name=\u0026amp;quot;dubbo\u0026amp;quot; port=\u0026amp;quot;20888\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;dubbo:service interface=\u0026amp;quot;com.github.myth.demo.dubbo.account.api.service.AccountService\u0026amp;quot; ref=\u0026amp;quot;accountService\u0026amp;quot;/\u0026amp;gt;   run DubboAccountApplication.java\n run …","date":-62135596800,"description":"Myth Quick Start Dubbo","dir":"projects/myth/quick-start-dubbo/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"5095043006cd2e3b511ff20fef8040e7861f926a","permalink":"/projects/myth/quick-start-dubbo/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/myth/quick-start-dubbo/","summary":"cd https://github.com/yu199195/myth/tree/master/myth-demo/myth-demo-dubbo\n Modifiy application.yml on Indicator Item And Modifiy you jdbc url And choose you Message Oriented Middleware\n  spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://192.168.1.68:3306/myth_account?useUnicode=true\u0026amp;characterEncoding=utf8 username: xiaoyu password: Wgj@555888 #activemq: # broker-url: tcp://120.76.52.162:61616 # user: happylife # password: happylifeplat01 # trust-all: true #rabbitmq: # host: localhost # port: 5672 # username: guest # password: guest rocketmq: namesrvAddr: 192.168.1.148:9876 consumerGroupName: account instanceName: account #kafka: # consumer: # bootstrap-servers: localhost:9092 # group-id: test # auto-offset-reset: earliest # enable-auto-commit: true # auto-commit-interval: 100 # key-deserializer: org.","tags":null,"title":"Quick Start Dubbo","type":"projects","url":"/projects/myth/quick-start-dubbo/","wordcount":238},{"author":null,"categories":null,"content":" cd https://github.com/yu199195/myth/tree/master/myth-demo/myth-demo-motan\n Modifiy application.yml on Indicator Item And Modifiy you jdbc url And zookeeper url And choose you Message Oriented Middleware\n  spring: motan: zookeeper: 192.168.1.148:2181 datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://192.168.1.68:3306/myth_account?useUnicode=true\u0026amp;amp;characterEncoding=utf8 username: xiaoyu password: Wgj@555888 #activemq: # broker-url: tcp://120.76.52.162:61616 # user: happylife # password: happylifeplat01 # trust-all: true #rabbitmq: # host: localhost # port: 5672 # username: guest # password: guest rocketmq: namesrvAddr: 192.168.1.148:9876 consumerGroupName: account instanceName: account #kafka: # consumer: # bootstrap-servers: localhost:9092 # group-id: test # auto-offset-reset: earliest # enable-auto-commit: true # auto-commit-interval: 100 # key-deserializer: org.apache.kafka.common.serialization.StringDeserializer # value-deserializer: org.apache.kafka.common.serialization.ByteArrayDeserializer   Modifiy applicationContext.xml on Indicator Item And choose repositorySupport and modifiy it  \u0026amp;lt;context:component-scan base-package=\u0026amp;quot;com.github.myth.*\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;mythTransactionBootstrap\u0026amp;quot; class=\u0026amp;quot;com.github.myth.core.bootstrap.MythTransactionBootstrap\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;repositorySuffix\u0026amp;quot; value=\u0026amp;quot;account-service\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;serializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;coordinatorQueueMax\u0026amp;quot; value=\u0026amp;quot;5000\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;coordinatorThreadMax\u0026amp;quot; value=\u0026amp;quot;8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;rejectPolicy\u0026amp;quot; value=\u0026amp;quot;Abort\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;blockingQueueType\u0026amp;quot; value=\u0026amp;quot;Linked\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;repositorySupport\u0026amp;quot; value=\u0026amp;quot;db\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;mythDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;bean class=\u0026amp;quot;com.github.myth.common.config.MythDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;url\u0026amp;quot; value=\u0026amp;quot;jdbc:mysql://192.168.1.68:3306/myth?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;driverClassName\u0026amp;quot; value=\u0026amp;quot;com.mysql.jdbc.Driver\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;password\u0026amp;quot; value=\u0026amp;quot;Wgj@555888\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;username\u0026amp;quot; value=\u0026amp;quot;xiaoyu\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt; \u0026amp;lt;/property\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt;   run MotanAccountApplication.java\n run MotanInventoryApplication.java\n run MotanOrderApplication.java\nthis mq sender so befer:\n in applicationContext.xml choose import you mq sender config\n  \u0026amp;lt;import resource=\u0026amp;quot;spring-rocketmq.xml\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;!--\u0026amp;lt;import resource=\u0026amp;quot;spring-rabbitmq.xml\u0026amp;quot;/\u0026amp;gt;--\u0026amp;gt; \u0026amp;lt;!--\u0026amp;lt;import resource=\u0026amp;quot;spring-kafka.xml\u0026amp;quot;/\u0026amp;gt;--\u0026amp;gt; \u0026amp;lt;!--\u0026amp;lt;import resource=\u0026amp;quot;spring-activemq.xml\u0026amp;quot;/\u0026amp;gt;--\u0026amp;gt;   modifiy you mq config for example  \u0026amp;lt;bean …","date":-62135596800,"description":"Myth Quick Start Motan","dir":"projects/myth/quick-start-motan/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"e228a1e4ffec3165510d4db67472f959c4816ce1","permalink":"/projects/myth/quick-start-motan/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/myth/quick-start-motan/","summary":"cd https://github.com/yu199195/myth/tree/master/myth-demo/myth-demo-motan\n Modifiy application.yml on Indicator Item And Modifiy you jdbc url And zookeeper url And choose you Message Oriented Middleware\n  spring: motan: zookeeper: 192.168.1.148:2181 datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://192.168.1.68:3306/myth_account?useUnicode=true\u0026amp;characterEncoding=utf8 username: xiaoyu password: Wgj@555888 #activemq: # broker-url: tcp://120.76.52.162:61616 # user: happylife # password: happylifeplat01 # trust-all: true #rabbitmq: # host: localhost # port: 5672 # username: guest # password: guest rocketmq: namesrvAddr: 192.168.1.148:9876 consumerGroupName: account instanceName: account #kafka: # consumer: # bootstrap-servers: localhost:9092 # group-id: test # auto-offset-reset: earliest # enable-auto-commit: true # auto-commit-interval: 100 # key-deserializer: org.","tags":null,"title":"Quick Start Motan","type":"projects","url":"/projects/myth/quick-start-motan/","wordcount":208},{"author":null,"categories":null,"content":" cd https://github.com/yu199195/myth/tree/master/myth-demo/myth-demo-springcloud\n run EurekaServerApplication.java\n Modifiy application.yml on Indicator Item And Modifiy you jdbc url And choose you Message Oriented Middleware\n  spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://192.168.1.68:3306/myth_account?useUnicode=true\u0026amp;amp;characterEncoding=utf8 username: xiaoyu password: Wgj@555888 #activemq: # broker-url: tcp://120.76.52.162:61616 # user: happylife # password: happylifeplat01 # trust-all: true #rabbitmq: # host: localhost # port: 5672 # username: guest # password: guest rocketmq: namesrvAddr: 192.168.1.148:9876 consumerGroupName: account instanceName: account #kafka: # consumer: # bootstrap-servers: localhost:9092 # group-id: test # auto-offset-reset: earliest # enable-auto-commit: true # auto-commit-interval: 100 # key-deserializer: org.apache.kafka.common.serialization.StringDeserializer # value-deserializer: org.apache.kafka.common.serialization.ByteArrayDeserializer   Modifiy applicationContext.xml on Indicator Item And choose repositorySupport and modifiy it\n If you use database compensation , You have to create a new database for example：myth  \u0026amp;lt;context:component-scan base-package=\u0026amp;quot;com.github.myth.*\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;mythTransactionBootstrap\u0026amp;quot; class=\u0026amp;quot;com.github.myth.core.bootstrap.MythTransactionBootstrap\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;repositorySuffix\u0026amp;quot; value=\u0026amp;quot;account-service\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;serializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;coordinatorQueueMax\u0026amp;quot; value=\u0026amp;quot;5000\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;coordinatorThreadMax\u0026amp;quot; value=\u0026amp;quot;8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;rejectPolicy\u0026amp;quot; value=\u0026amp;quot;Abort\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;blockingQueueType\u0026amp;quot; value=\u0026amp;quot;Linked\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;repositorySupport\u0026amp;quot; value=\u0026amp;quot;db\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;mythDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;bean class=\u0026amp;quot;com.github.myth.common.config.MythDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;url\u0026amp;quot; value=\u0026amp;quot;jdbc:mysql://192.168.1.68:3306/myth?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;driverClassName\u0026amp;quot; value=\u0026amp;quot;com.mysql.jdbc.Driver\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;password\u0026amp;quot; value=\u0026amp;quot;Wgj@555888\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;username\u0026amp;quot; value=\u0026amp;quot;xiaoyu\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt; \u0026amp;lt;/property\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt;   run SpringCloudAccountApplication.java\n run SpringCloudInventoryApplication.java\n run SpringcloudOrderApplication.java this mq sender so befer:\n in applicationContext.xml choose import you mq sender config\n  \u0026amp;lt;import resource=\u0026amp;quot;spring-rocketmq.xml\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;!--\u0026amp;lt;import resource=\u0026amp;quot;spring-rabbitmq.xml\u0026amp;quot;/\u0026amp;gt;--\u0026amp;gt; \u0026amp;lt;!--\u0026amp;lt;import resource=\u0026amp;quot;spring-kafka.xml\u0026amp;quot;/\u0026amp;gt;--\u0026amp;gt; \u0026amp;lt;!--\u0026amp;lt;import …","date":-62135596800,"description":"Myth Quick Start SpringCloud","dir":"projects/myth/quick-start-springcloud/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"ae3987a138101bf32cad1c2e7f0b425b5633eb5b","permalink":"/projects/myth/quick-start-springcloud/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/myth/quick-start-springcloud/","summary":"cd https://github.com/yu199195/myth/tree/master/myth-demo/myth-demo-springcloud\n run EurekaServerApplication.java\n Modifiy application.yml on Indicator Item And Modifiy you jdbc url And choose you Message Oriented Middleware\n  spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://192.168.1.68:3306/myth_account?useUnicode=true\u0026amp;characterEncoding=utf8 username: xiaoyu password: Wgj@555888 #activemq: # broker-url: tcp://120.76.52.162:61616 # user: happylife # password: happylifeplat01 # trust-all: true #rabbitmq: # host: localhost # port: 5672 # username: guest # password: guest rocketmq: namesrvAddr: 192.168.1.148:9876 consumerGroupName: account instanceName: account #kafka: # consumer: # bootstrap-servers: localhost:9092 # group-id: test # auto-offset-reset: earliest # enable-auto-commit: true # auto-commit-interval: 100 # key-deserializer: org.","tags":null,"title":"Quick Start SpringCloud","type":"projects","url":"/projects/myth/quick-start-springcloud/","wordcount":219},{"author":null,"categories":null,"content":" Raincat Strongly consistent distributed transactions are implemented based on two-phase commit + local transaction compensation mechanism. Principle\nIt is based on Java language (JDK1.8), supports Dubbo, Motan, Springcloud for distributed transactions.\nDue to the file name is too long, you can executes git config --global core.longpaths true when pulling the code.\nFeatures  Frame features\n Seamlessly integrate spring or spring boot.\n Support Dubbo, Motan, Springcloud, and other RPC frameworks for distributed transactions.\n Transaction initiator, participant and coordinator are based on Netty long connection which is stable and efficient.\n The coordinator uses Eureka as the registry center and supports cluster mode.\n It would be seamless to integrate with Spring by AOP.\n The configuration, integration and source code are concise. It has been used in the production environment with high stability.\n It has been provided built-in distributed transaction scenario demo, and you can use swagger-ui visual interface for quick experience.\n  The role in transaction\n The transaction initiator which can be understood as a consumer, such as: Dubbo consumer, Springcloud caller, used for initiating a distributed transaction.\n Transaction participants which can be understood as providers such as: Dubbo provider, Springcloud rest service provider, participating in the transaction of the transaction initiator.\n Transaction coordinator (tx-manager), which coordinates the submission and rollback of distributed transactions.\n  Technical solutions\n The coordinator (tx-manager) uses Eureka as the registry center to do cluster configuration for high availability, and use Redis cluster to storage distributed transaction data. Rest services is provided by Springboot, and Netty is used to communicate with participants and initiators for long connections.\n The initiator and the coordinator use AOP, SPI, multi-threading, asynchronous callback, thread pool, Netty communication, etc.\n  SPI expansion\n Local transaction recovery support Redis, Mogondb, Zookeeper, File, Mysql and other relational databases. Local transaction serialization support Java, Hessian, Kryo, Protostuff. Netty communication serialization support Hessian, Kryo, Protostuff.   Prerequisite  JDK 1.8+ Maven 3.2.x Git RPC framework dubbo or motan or springcloud。  Architecture  Architecture diagram：  Flow diagram：\n  Video Environment Bootstrap Commitment Rollback Administration  Support  If you have any questions, please join the QQ group for discussion.  WeChat public account   ","date":-62135596800,"description":"Raincat is a strongly consistent distributed transaction framework based on a two-phase commit + local transaction compensation mechanism. support RPC framework, like Dubbo, Motan and Springcloud","dir":"projects/raincat/overview/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"31fdd0e59b740a72677437f75116e9bf43eb1e6f","permalink":"/projects/raincat/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/raincat/overview/","summary":"Raincat Strongly consistent distributed transactions are implemented based on two-phase commit + local transaction compensation mechanism. Principle\nIt is based on Java language (JDK1.8), supports Dubbo, Motan, Springcloud for distributed transactions.\nDue to the file name is too long, you can executes git config --global core.longpaths true when pulling the code.\nFeatures  Frame features\n Seamlessly integrate spring or spring boot.\n Support Dubbo, Motan, Springcloud, and other RPC frameworks for distributed transactions.","tags":null,"title":"Raincat Introduction","type":"projects","url":"/projects/raincat/overview/","wordcount":341},{"author":null,"categories":null,"content":" Raincat 强一致性分布式事务，是基于二阶段提交+本地事务补偿机制来实现。原理介绍\n基于java语言来开发（JDK1.8），支持dubbo,motan,springcloud进行分布式事务。\n因为文件名太长，大家在拉取代码的时候执git命令：git config \u0026amp;ndash;global core.longpaths true Features  框架特性\n 无缝集成spring 或 spring boot。\n 支持dubbo,motan,springcloud,等rpc框架进行分布式事务。\n 事务发起者，参与者与协调者底层基于netty长连接通信,稳定高效。\n 协调者采用eureka做注册中心，支持集群模式。\n 采用Aspect AOP 切面思想与Spring无缝集成。\n 配置简单，集成简单，源码简洁，稳定性高，已在生产环境使用。\n 内置经典的分布式事务场景demo工程，并有swagger-ui可视化界面可以快速体验。\n  事务角色\n 事务发起者（可理解为消费者 如：dubbo的消费者,springcloud的调用方）,发起分布式事务\n 事务参与者（可理解为提供者 如：dubbo的提供者,springcloud的rest服务提供者),参与事务发起者的事务\n 事务协调者（tx-manager），协调分布式事务的提交，回滚等。\n  技术方案\n 协调者（tx-manager）采用eureka作为注册中心，集群配置，达到服务的高可用，采用redis集群来分布式存储事务数据, springboot 提供rest服务，采用netty与参与者，发起者进行长连接通信。\n 发起者与协调者，采用Aspect AOP 切面思想，SPI，多线程，异步回调，线程池，netty通信等技术。\n  SPI扩展\n 本地事务恢复，支持redis，mogondb，zookeeper，file，mysql等关系型数据库 本地事务序列化保存，支持java，hessian，kryo，protostuff netty通信序列化方式，支持 hessian，kryo，protostuff   Prerequisite  JDK 1.8+ Maven 3.2.x Git RPC framework dubbo or motan or springcloud。  架构设计  架构设计图 ：  流程图 ：\n  视频源码分析 环境搭建 启动过程 事务提交 回滚恢复 管理后台 Support  如有任何问题欢迎加入QQ群进行讨论  微信公众号   # Contribution\n","date":-62135596800,"description":"Raincat是基于二阶段提交+本地事务补偿机制来实现的强一致性分布式事务框架。无缝支持dubbo,motan,springcloud等Rpc框架的微服务。","dir":"projects/raincat/overview/","fuzzywordcount":900,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"bedfdea663c27d8d473d9e350a6a76b621d42988","permalink":"/zh/projects/raincat/overview/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/zh/projects/raincat/overview/","summary":"Raincat 强一致性分布式事务，是基于二阶段提交+本地事务补偿机制来实现。原理介绍 基于java语言来开发（JDK1.8），支持dubbo,motan,","tags":null,"title":"Raincat 介绍","type":"projects","url":"/zh/projects/raincat/overview/","wordcount":854},{"author":null,"categories":null,"content":" SOFA-RPC Interface Sectioon  Introduce the jar packages into your interface project.  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-annotation\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   Add the @Hmily annotation on the interface method in which you need to perform Hmily distributed transactions.\npublic interface HelloService { @Hmily void say(String hello); }  The project with SOFA-RPC implementation  Step 1 ： Introduce the jar package of the hmily dependency\n Step 2 ： Add Hmily configuration\n Step 3 ： Add the specific annotation to the implementation method. you need to complete the development of confirm and cancel method, if in TCC mode.\n  Introduce The Maven dependency Spring-Namespace  Introduce the hmily-sofa-rpc dependency  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-sofa-rpc\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  make the configuration in the XML configuration file as below:\n  \u0026amp;lt;!-- set up to enable the aspectj-autoproxy --\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id = \u0026amp;quot;hmilyTransactionAspect\u0026amp;quot; class=\u0026amp;quot;org.dromara.hmily.spring.aop.SpringHmilyTransactionAspect\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id = \u0026amp;quot;hmilyApplicationContextAware\u0026amp;quot; class=\u0026amp;quot;org.dromara.hmily.spring.HmilyApplicationContextAware\u0026amp;quot;/\u0026amp;gt;  Spring-Boot  Introduce the hmily-spring-boot-starter-sofa-rpc dependency  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-spring-boot-starter-sofa-rpc\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  Introduce the Hmily configuration  new a configuration file named hmily.yml under the resource directory of the current project\n the specific parameter configuration can refer to configuration detail,Local configuration mode, Zookeeper configuration mode, nacos configuration mode,apollo configuration mode\n  Add annotations on the implementation interface We have completed the integration described above,and the next we will talk about the specific implementation.\nTCC Mode  Add @HmilyTCC (confirmMethod = \u0026amp;quot;confirm\u0026amp;quot;, cancelMethod = \u0026amp;quot;cancel\u0026amp;quot;) annotation to the concrete implementation of the interface method identified by \u0026amp;lsquo;@Hmily\u0026amp;rsquo;.\n confirmMethod : the method name for confirm，The method parameter list and return type should be consistent with the identification method.\n cancelMethod : the method for cancel，The method parameter list and return type should be consistent with the identification method.\n The TCC mode should ensure the idempotence of the confirm and cancel methods,Users need to develop these two methods by themselves,The confirmation and rollback behavior of all transactions are completely up tp users.The Hmily framework is just responsible for making calls.\n  public class HelloServiceImpl implements HelloService { …","date":-62135596800,"description":"SOFA-RPC User Guide","dir":"projects/hmily/user-rpc/","fuzzywordcount":600,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"0c2555a83f4e51ee037f201aa956dd0f29e6fcbb","permalink":"/projects/hmily/user-rpc/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/hmily/user-rpc/","summary":"SOFA-RPC Interface Sectioon  Introduce the jar packages into your interface project.  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.dromara\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;hmily-annotation\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;{last.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   Add the @Hmily annotation on the interface method in which you need to perform Hmily distributed transactions.\npublic interface HelloService { @Hmily void say(String hello); }  The project with SOFA-RPC implementation  Step 1 ： Introduce the jar package of the hmily dependency\n Step 2 ： Add Hmily configuration","tags":null,"title":"SOFA-RPC User Guide","type":"projects","url":"/projects/hmily/user-rpc/","wordcount":515},{"author":null,"categories":null,"content":" Spring-Cloud User Guide  Step 1: Introduce the jar packages\n Step 2: Introduce the Hmily configuration\n Step 3: Add @HmilyTCC or @HmilyTAC annotation on the concrete implementation method(Service provider).\n Step 4: Add @Hmily annotation on the feignClient call method(Consumer side).\n  1.Introduce The Maven dependency Spring-Namespace  Introduce the hmily-springcloud dependency  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-springcloud\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   make the configuration in the XML configuration file as below:  \u0026amp;lt;!--Configure the base packages that the Hmily framework need to scan --\u0026amp;gt; \u0026amp;lt;context:component-scan base-package=\u0026amp;quot;org.dromara.hmily.*\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;!-- set up to enable the aspectj-autoproxy --\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;!-- Configure the bean parameters for Hmily startup --\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;hmilyApplicationContextAware\u0026amp;quot; class=\u0026amp;quot;org.dromara.hmily.spring.HmilyApplicationContextAware\u0026amp;quot;/\u0026amp;gt;  Spring-Boot-Starter  Introduce the hmily-spring-boot-starter-springcloud dependency  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-spring-boot-starter-springcloud\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  2.Introduce the Hmily configuration  new a configuration file named hmily.yml under the resource directory of the current project\n the specific parameter configuration can refer to configuration detail,Local configuration mode, Zookeeper configuration mode, nacos configuration mode,apollo configuration mode\n  3. Add annotations on the service implementation method TCC Mode  Add @HmilyTCC (confirmMethod = \u0026amp;quot;confirm\u0026amp;quot;, cancelMethod = \u0026amp;quot;cancel\u0026amp;quot;) annotation to the concrete implementation of the interface method identified by \u0026amp;lsquo;@Hmily\u0026amp;rsquo;.\n confirmMethod : the method name for confirm，The method parameter list and return type should be consistent with the identification method.\n cancelMethod : the method for cancel，The method parameter list and return type should be consistent with the identification method.\n The TCC mode should ensure the idempotence of the confirm and cancel methods,Users need to develop these two methods by themselves,The confirmation and rollback behavior of all transactions are completely up tp users.The Hmily framework is just responsible for making calls.\n  public class HelloServiceImpl implements HelloService { @HmilyTCC(confirmMethod = \u0026amp;quot;sayConfrim\u0026amp;quot;, cancelMethod = \u0026amp;quot;sayCancel\u0026amp;quot;) public void say(String hello) { System.out.println(\u0026amp;quot;hello world\u0026amp;quot;); } public void sayConfrim(String hello) { System.out.println(\u0026amp;quot; confirm hello world\u0026amp;quot;); } public void sayCancel(String hello) { System.out.println(\u0026amp;quot; cancel hello world\u0026amp;quot;); } }  TAC Mode(Under development, not released)  Add @HmilyTAC annotation to the …","date":-62135596800,"description":"Hmily-Spring Cloud Distributed Transaction User Guide","dir":"projects/hmily/user-springcloud/","fuzzywordcount":600,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"c41d6ae6fb5b255ac153fc6936085582c5367fef","permalink":"/projects/hmily/user-springcloud/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/hmily/user-springcloud/","summary":"Spring-Cloud User Guide  Step 1: Introduce the jar packages\n Step 2: Introduce the Hmily configuration\n Step 3: Add @HmilyTCC or @HmilyTAC annotation on the concrete implementation method(Service provider).\n Step 4: Add @Hmily annotation on the feignClient call method(Consumer side).\n  1.Introduce The Maven dependency Spring-Namespace  Introduce the hmily-springcloud dependency  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.dromara\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;hmily-springcloud\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;{last.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   make the configuration in the XML configuration file as below:  \u0026lt;!","tags":null,"title":"Spring Cloud User Guide","type":"projects","url":"/projects/hmily/user-springcloud/","wordcount":541},{"author":null,"categories":null,"content":" Prerequisites  JDK 1.8+ Maven 3.2.x Git  Cloning the GitHub Repository and Quick Installation  \u0026amp;gt; git clone https://github.com/dromara/hmily.git \u0026amp;gt; cd hmily \u0026amp;gt; mvn -DskipTests clean install -U  Executing SQL(s) in Demo Module sql\nOpen with Your Favourite Editor (IDEA), Locate on hmily-demo-dubbo Module and Run Build with Maven Run with EurekaServerApplication.java in hmily-demo-springcloud-eureka project. Configuring（hmily-demo-springcloud-account module for instance）  Configure with your business database (account module for instance)  spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://\u0026amp;lt;db_host_ip\u0026amp;gt;:\u0026amp;lt;db_host_port\u0026amp;gt;/hmily_account?useUnicode=true\u0026amp;amp;characterEncoding=utf8 # replace with your db_host_ip and db_host_port username: root # replace with your db username password: your_password # replace with your db user password   Modify hmily.yml, with mysql persistence backend  repository: database: driverClassName: com.mysql.jdbc.Driver url: jdbc:mysql://\u0026amp;lt;db_host_ip\u0026amp;gt;:\u0026amp;lt;db_host_port\u0026amp;gt;/hmily?useUnicode=true\u0026amp;amp;characterEncoding=utf8 # replace with your db_host_ip and db_host_port username: root # replace with your db username password: your_password # replace with your db user password   run SpringCloudHmilyAccountApplication.java  Run hmily-demo-springcloud-inventory(refer to simillar instructions above). Run hmily-demo-springcloud-order(refer to simillar instructions above). Access on http://127.0.0.1:8884/swagger-ui.html for more. ","date":-62135596800,"description":"Hmily-SpringCloud Quick Start for Distributed Transactions","dir":"projects/hmily/quick-start-springcloud/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"3c087cfc0d507bb5f090a57e5422542efcbcb97d","permalink":"/projects/hmily/quick-start-springcloud/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/hmily/quick-start-springcloud/","summary":"Prerequisites  JDK 1.8+ Maven 3.2.x Git  Cloning the GitHub Repository and Quick Installation  \u0026gt; git clone https://github.com/dromara/hmily.git \u0026gt; cd hmily \u0026gt; mvn -DskipTests clean install -U  Executing SQL(s) in Demo Module sql\nOpen with Your Favourite Editor (IDEA), Locate on hmily-demo-dubbo Module and Run Build with Maven Run with EurekaServerApplication.java in hmily-demo-springcloud-eureka project. Configuring（hmily-demo-springcloud-account module for instance）  Configure with your business database (account module for instance)  spring: datasource: driver-class-name: com.","tags":null,"title":"SpringCloud Quick Start","type":"projects","url":"/projects/hmily/quick-start-springcloud/","wordcount":151},{"author":null,"categories":null,"content":" In the springcloud service provider (the participating method of the transaction, the called party).\n add myth-springcloud dependency\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.github.myth\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;myth-springcloud\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   Configure MythTransactionBootstrap to start the class, either as XML or as @Bean. Specific configuration can refer to here:configuration for details.  \u0026amp;lt;context:component-scan base-package=\u0026amp;quot;com.github.myth.*\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;mythTransactionBootstrap\u0026amp;quot; class=\u0026amp;quot;com.github.myth.core.bootstrap.MythTransactionBootstrap\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;repositorySuffix\u0026amp;quot; value=\u0026amp;quot;account-service\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;serializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;coordinatorQueueMax\u0026amp;quot; value=\u0026amp;quot;5000\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;coordinatorThreadMax\u0026amp;quot; value=\u0026amp;quot;8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;rejectPolicy\u0026amp;quot; value=\u0026amp;quot;Abort\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;blockingQueueType\u0026amp;quot; value=\u0026amp;quot;Linked\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;repositorySupport\u0026amp;quot; value=\u0026amp;quot;db\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;mythDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;bean class=\u0026amp;quot;com.github.myth.common.config.MythDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;url\u0026amp;quot; value=\u0026amp;quot;jdbc:mysql://192.168.1.68:3306/myth?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;driverClassName\u0026amp;quot; value=\u0026amp;quot;com.mysql.jdbc.Driver\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;password\u0026amp;quot; value=\u0026amp;quot;Wgj@555888\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;username\u0026amp;quot; value=\u0026amp;quot;xiaoyu\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt; \u0026amp;lt;/property\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt;  Add @Myth to the implementation method of springcloud service.\n Listen to the message queue (message queue name written in the annotations method), invoke the framework provides MythMqReceiveService.processMessage() method. If you use JMS, you can refer to the Demo project for details.\n@JmsListener(destination = \u0026amp;quot;account\u0026amp;quot;,containerFactory = \u0026amp;quot;queueListenerContainerFactory\u0026amp;quot;) public void receiveQueue(byte[] message) { LOGGER.info(\u0026amp;quot;=========扣减账户信息接收到Myth框架传入的信息==========\u0026amp;quot;); final Boolean success = mythMqReceiveService.processMessage(message); if(success){ //消费成功，消息出队列，否则不消费 } }   In the springcloud consumer (the invoker of the transaction, the caller)\n add myth-springcloud dependency\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.github.myth\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;myth-springcloud\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;    Set feignClient to add @Myth annotation to the interface, the target must be set to the service interface you actually call, and it must be set correctly.\n@FeignClient(value = \u0026amp;quot;account-service\u0026amp;quot;, configuration = MyConfiguration.class) public interface AccountClient { @Myth(destination = \u0026amp;quot;account\u0026amp;quot;, target = AccountService.class) Boolean …","date":-62135596800,"description":"Myth SpringCloud User","dir":"projects/myth/springcloud-user/","fuzzywordcount":600,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"505b8df6cae812d2e4356d1be583b6c020f193aa","permalink":"/projects/myth/springcloud-user/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/myth/springcloud-user/","summary":"In the springcloud service provider (the participating method of the transaction, the called party). add myth-springcloud dependency \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.myth\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;myth-springcloud\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; Configure MythTransactionBootstrap to start the class, either as XML or as @Bean. Specific configuration can refer to here:configuration for details. \u0026lt;context:component-scan base-package=\u0026quot;com.github.myth.*\u0026quot;/\u0026gt; \u0026lt;aop:aspectj-autoproxy expose-proxy=\u0026quot;true\u0026quot;/\u0026gt; \u0026lt;bean id=\u0026quot;mythTransactionBootstrap\u0026quot; class=\u0026quot;com.github.myth.core.bootstrap.MythTransactionBootstrap\u0026quot;\u0026gt; \u0026lt;property name=\u0026quot;repositorySuffix\u0026quot; value=\u0026quot;account-service\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;serializer\u0026quot; value=\u0026quot;kryo\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;coordinatorQueueMax\u0026quot; value=\u0026quot;5000\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;coordinatorThreadMax\u0026quot; value=\u0026quot;8\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;rejectPolicy\u0026quot; value=\u0026quot;Abort\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;blockingQueueType\u0026quot; value=\u0026quot;Linked\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;repositorySupport\u0026quot; value=\u0026quot;db\u0026quot;/\u0026gt; \u0026lt;property","tags":null,"title":"SpringCloud User","type":"projects","url":"/projects/myth/springcloud-user/","wordcount":571},{"author":null,"categories":null,"content":" 在springcloud 服务提供方（事务的参与方法，被调用方）\n 引入myth-springcloud 包\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.github.myth\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;myth-springcloud\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   配置 MythTransactionBootstrap启动类,可以采用xml方式，或者@Bean的方式,具体配置可以参考:配置详解  \u0026amp;lt;context:component-scan base-package=\u0026amp;quot;com.github.myth.*\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;mythTransactionBootstrap\u0026amp;quot; class=\u0026amp;quot;com.github.myth.core.bootstrap.MythTransactionBootstrap\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;repositorySuffix\u0026amp;quot; value=\u0026amp;quot;account-service\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;serializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;coordinatorQueueMax\u0026amp;quot; value=\u0026amp;quot;5000\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;coordinatorThreadMax\u0026amp;quot; value=\u0026amp;quot;8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;rejectPolicy\u0026amp;quot; value=\u0026amp;quot;Abort\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;blockingQueueType\u0026amp;quot; value=\u0026amp;quot;Linked\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;repositorySupport\u0026amp;quot; value=\u0026amp;quot;db\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;mythDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;bean class=\u0026amp;quot;com.github.myth.common.config.MythDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;url\u0026amp;quot; value=\u0026amp;quot;jdbc:mysql://192.168.1.68:3306/myth?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;driverClassName\u0026amp;quot; value=\u0026amp;quot;com.mysql.jdbc.Driver\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;password\u0026amp;quot; value=\u0026amp;quot;Wgj@555888\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;username\u0026amp;quot; value=\u0026amp;quot;xiaoyu\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt; \u0026amp;lt;/property\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt;  springcloud服务的实现方法上加上 @Myth\n 监听消息队列（注解方法上写的消息队列名称),调用框架提供 的MythMqReceiveService.processMessage方法。列如使用jms，具体可以参考demo工程。\n@JmsListener(destination = \u0026amp;quot;account\u0026amp;quot;,containerFactory = \u0026amp;quot;queueListenerContainerFactory\u0026amp;quot;) public void receiveQueue(byte[] message) { LOGGER.info(\u0026amp;quot;=========扣减账户信息接收到Myth框架传入的信息==========\u0026amp;quot;); final Boolean success = mythMqReceiveService.processMessage(message); if(success){ //消费成功，消息出队列，否则不消费 } }   在springcloud 消费方（事务的发起者，调用方）\n 引入myth-springcloud 包\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.github.myth\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;myth-springcloud\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;    设置feignClient在接口上加上@Myth注解，target必须设置成你真实调用的服务接口,千万要设置正确\n@FeignClient(value = \u0026amp;quot;account-service\u0026amp;quot;, configuration = MyConfiguration.class) public interface AccountClient { @Myth(destination = \u0026amp;quot;account\u0026amp;quot;, target = AccountService.class) Boolean payment(@RequestBody AccountDTO accountDO); }   FeignClient 配置 configuration = MyConfiguration.class ```java @Configuration public class MyConfiguration {  @Bean @Scope(\u0026amp;ldquo;prototype\u0026amp;rdquo;) public Feign.Builder feignBuilder() { return Feign.builder() .requestInterceptor(new MythRestTemplateInterceptor()) .invocationHandlerFactory(invocationHandlerFactory()); }\n@Bean public InvocationHandlerFactory invocationHandlerFactory() { return (target, dispatch) -\u0026amp;gt; { MythFeignHandler handler = new …","date":-62135596800,"description":"SpringCloud 用户","dir":"projects/myth/springcloud-user/","fuzzywordcount":1100,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"241c635bdcad609905c15173fa54450210e77dde","permalink":"/zh/projects/myth/springcloud-user/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/zh/projects/myth/springcloud-user/","summary":"在springcloud 服务提供方（事务的参与方法，被调用方） 引入myth-springcloud 包 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.myth\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;myth-springcloud\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 配置 MythTransactio","tags":null,"title":"SpringCloud 用户","type":"projects","url":"/zh/projects/myth/springcloud-user/","wordcount":1044},{"author":null,"categories":null,"content":" 环境准备  JDK 1.8+ Maven 3.2.x Git  代码拉取  \u0026amp;gt; git clone https://github.com/dromara/hmily.git \u0026amp;gt; cd hmily \u0026amp;gt; mvn -DskipTests clean install -U  执行demo 模块的sql语句。 sql语句\n使用你的工具 idea 打开项目，找到hmily-demo-springcloud项目, 进行maven构建。 启动 hmily-demo-springcloud-eureka项目中的 EurekaServerApplication.java。 修改项目配置（hmily-demo-springcloud-account为列子）  修改业务数据库(account项目为列子)  spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://改成你的ip+端口/hmily_account?useUnicode=true\u0026amp;amp;characterEncoding=utf8 username: 你的用户名 password: 你的密码   修改 hmily.yml,这里使用mysql来存储  repository: database: driverClassName: com.mysql.jdbc.Driver url : jdbc:mysql://改成你的ip+端口/hmily?useUnicode=true\u0026amp;amp;characterEncoding=utf8 username: root #改成你的用户名 password: #改成你的密码   run SpringCloudHmilyAccountApplication.java  启动hmily-demo-springcloud-inventory 参考上述。 启动hmily-demo-springcloud-order 参考上述。 访问：http://127.0.0.1:8884/swagger-ui.html。 ","date":-62135596800,"description":"Hmily-SpringCloud分布式事务体验","dir":"projects/hmily/quick-start-springcloud/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"02b37cdf98dcf9b3ac3a82721cd7575bc5d06dcc","permalink":"/zh/projects/hmily/quick-start-springcloud/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/zh/projects/hmily/quick-start-springcloud/","summary":"环境准备 JDK 1.8+ Maven 3.2.x Git 代码拉取 \u0026gt; git clone https://github.com/dromara/hmily.git \u0026gt; cd hmily \u0026gt; mvn -DskipTests clean install -U 执行demo 模块的sql语句。 sql语句 使用你的工具 idea 打开项目，找到hmily-demo","tags":null,"title":"SpringCloud快速体验","type":"projects","url":"/zh/projects/hmily/quick-start-springcloud/","wordcount":552},{"author":null,"categories":null,"content":" cd https://github.com/yu199195/myth/tree/master/myth-demo/myth-demo-springcloud\n run EurekaServerApplication.java\n Modifiy application.yml on Indicator Item And Modifiy you jdbc url And choose you Message Oriented Middleware\nspring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://192.168.1.68:3306/myth_account?useUnicode=true\u0026amp;amp;characterEncoding=utf8 username: xiaoyu password: Wgj@555888 #activemq: # broker-url: tcp://120.76.52.162:61616 # user: happylife # password: happylifeplat01 # trust-all: true #rabbitmq: # host: localhost # port: 5672 # username: guest # password: guest rocketmq: namesrvAddr: 192.168.1.148:9876 consumerGroupName: account instanceName: account #kafka: # consumer: # bootstrap-servers: localhost:9092 # group-id: test # auto-offset-reset: earliest # enable-auto-commit: true # auto-commit-interval: 100 # key-deserializer: org.apache.kafka.common.serialization.StringDeserializer # value-deserializer: org.apache.kafka.common.serialization.ByteArrayDeserializer   Modifiy applicationContext.xml on Indicator Item And choose repositorySupport and modifiy it\n If you use database compensation , You have to create a new database for example：myth\n  \u0026amp;lt;context:component-scan base-package=\u0026amp;quot;com.github.myth.*\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;mythTransactionBootstrap\u0026amp;quot; class=\u0026amp;quot;com.github.myth.core.bootstrap.MythTransactionBootstrap\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;repositorySuffix\u0026amp;quot; value=\u0026amp;quot;account-service\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;serializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;coordinatorQueueMax\u0026amp;quot; value=\u0026amp;quot;5000\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;coordinatorThreadMax\u0026amp;quot; value=\u0026amp;quot;8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;rejectPolicy\u0026amp;quot; value=\u0026amp;quot;Abort\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;blockingQueueType\u0026amp;quot; value=\u0026amp;quot;Linked\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;repositorySupport\u0026amp;quot; value=\u0026amp;quot;db\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;mythDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;bean class=\u0026amp;quot;com.github.myth.common.config.MythDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;url\u0026amp;quot; value=\u0026amp;quot;jdbc:mysql://192.168.1.68:3306/myth?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;driverClassName\u0026amp;quot; value=\u0026amp;quot;com.mysql.jdbc.Driver\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;password\u0026amp;quot; value=\u0026amp;quot;Wgj@555888\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;username\u0026amp;quot; value=\u0026amp;quot;xiaoyu\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt; \u0026amp;lt;/property\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt;  run SpringCloudAccountApplication.java\n run SpringCloudInventoryApplication.java\n run SpringcloudOrderApplication.java this mq sender so befer:\n in applicationContext.xml choose import you mq sender config\n  \u0026amp;lt;import resource=\u0026amp;quot;spring-rocketmq.xml\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;!--\u0026amp;lt;import resource=\u0026amp;quot;spring-rabbitmq.xml\u0026amp;quot;/\u0026amp;gt;--\u0026amp;gt; \u0026amp;lt;!--\u0026amp;lt;import resource=\u0026amp;quot;spring-kafka.xml\u0026amp;quot;/\u0026amp;gt;--\u0026amp;gt; \u0026amp;lt;!--\u0026amp;lt;import …","date":-62135596800,"description":"SpringCloud快速开始","dir":"projects/myth/quick-start-springcloud/","fuzzywordcount":300,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"898cb015d2d8a77c4acb4a466673805d0fa20cab","permalink":"/zh/projects/myth/quick-start-springcloud/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/zh/projects/myth/quick-start-springcloud/","summary":"cd https://github.com/yu199195/myth/tree/master/myth-demo/myth-demo-springcloud run EurekaServerApplication.java Modifiy application.yml on Indicator Item And Modifiy you jdbc url And choose you Message Oriented Middleware spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://192.168.1.68:3306/myth_account?useUnicode=true\u0026amp;characterEncoding=utf8 username: xiaoyu password: Wgj@555888 #activemq: # broker-url: tcp://120.76.52.162:61616 # user: happylife # password: happylifeplat01 # trust-all: true #rabbitmq: # host: localhost # port: 5672 # username: guest # password: guest rocketmq: namesrvAddr: 192.168.1.148:9876 consumerGroupName: account instanceName: account #kafka: # consumer: # bootstrap-servers: localhost:9092 #","tags":null,"title":"SpringCloud快速开始","type":"projects","url":"/zh/projects/myth/quick-start-springcloud/","wordcount":230},{"author":null,"categories":null,"content":" Spring-Cloud 用户指南  步骤一: 引入依赖jar包\n 步骤二：引入hmily配置\n 步骤三：在具体的实现方法上（服务提供端），加上HmilyTCC or HmilyTAC 注解\n 步骤四：在feignClient调用方法上（消费方），加上Hmily\n  1.引入依赖 Spring-Namespace  引入依赖  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-springcloud\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   在xml中进行如下配置  \u0026amp;lt;!--配置扫码hmily框架的包--\u0026amp;gt; \u0026amp;lt;context:component-scan base-package=\u0026amp;quot;org.dromara.hmily.*\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;!--设置开启aspectj-autoproxy--\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;!--配置Hmily启动的bean参数--\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;hmilyApplicationContextAware\u0026amp;quot; class=\u0026amp;quot;org.dromara.hmily.spring.HmilyApplicationContextAware\u0026amp;quot;/\u0026amp;gt;  Spring-Boot-Starter  引入依赖  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-spring-boot-starter-springcloud\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  2.新增hmily配置  在项目的 resource 添加文件名为:hmily.yml 的配置文件\n 具体的参数配置可以参考配置详解,本地配置模式, zookeeper配置模式, nacos配置模式,apollo配置模式\n  3. 服务实现方添加注解 TCC模式  只需要在参与hmily分布式事务调用的具体实现方法上加@HmilyTCC(confirmMethod = \u0026amp;quot;confirm\u0026amp;quot;, cancelMethod = \u0026amp;quot;cancel\u0026amp;quot;)\n confirmMethod : 确认方法名称，该方法参数列表与返回类型应与标识方法一致。\n cancelMethod : 回滚方法名称，该方法参数列表与返回类型应与标识方法一致。\n TCC模式应该保证 confirm 和 cancel 方法的幂等性，用户需要自行去开发这个2个方法，所有的事务的确认与回滚，完全由用户决定。Hmily框架只是负责来进行调用\n  public class HelloServiceImpl implements HelloService { @HmilyTCC(confirmMethod = \u0026amp;quot;sayConfrim\u0026amp;quot;, cancelMethod = \u0026amp;quot;sayCancel\u0026amp;quot;) public void say(String hello) { System.out.println(\u0026amp;quot;hello world\u0026amp;quot;); } public void sayConfrim(String hello) { System.out.println(\u0026amp;quot; confirm hello world\u0026amp;quot;); } public void sayCancel(String hello) { System.out.println(\u0026amp;quot; cancel hello world\u0026amp;quot;); } }  TAC模式（在开发，未发布）  只需要在参与分布式事务调用的具体实现方法上加@HmilyTAC  服务消费端（FeignClient）  在服务被调用方的@FeignClient 接口方法上加上 @Hmily注解。  @FeignClient(value = \u0026amp;quot;helle-service\u0026amp;quot;) public interface HelloService { @Hmily @RequestMapping(\u0026amp;quot;/helle-service/sayHello\u0026amp;quot;) void say(String hello); }  重要注意事项 在调用任何RPC调用之前，当你需要聚合rpc调用成为一次分布式事务的时候，需要在聚合RPC调用的方法上，先行添加 @HmilyTCC 或者 @HmilyTAC 注解,表示开启全局事务。\n负载均衡  如果服务部署了几个节点， 负载均衡算法最好使用 hmily自带, 这样 try, confirm, cancel 调用会落在同一个节点 充分利用了缓存，提搞了效率。在你的yaml配置如下：   hmily.ribbon.rule.enabled = true  开启hystrix  如果用户配置了feign.hystrix.enabled = true, 默认使用线程池模式， 将会开启 HmilyHystrixConcurrencyStrategy 它在hystrix使用线程池模式的时候，能够照样通过threadLoacl 进行RPC传参数。   设置永不重试  需要进行分布式事务的SpringCloud微服务的调用方需要设置不重试，如下是参考：  ribbon: MaxAutoRetriesNextServer : 0 MaxAutoRetries: 0  异常  try, confirm, cancel 方法的所有异常不要自行catch 任何异常都应该抛出给 Hmily框架处理。   ","date":-62135596800,"description":"Hmily-SpringCloud分布式事务用户指南","dir":"projects/hmily/user-springcloud/","fuzzywordcount":1100,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"3a41cae46f09d52506e336b94a32db802937aff9","permalink":"/zh/projects/hmily/user-springcloud/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/zh/projects/hmily/user-springcloud/","summary":"Spring-Cloud 用户指南 步骤一: 引入依赖jar包 步骤二：引入hmily配置 步骤三：在具体的实现方法上（服务提供端），加上HmilyTCC or HmilyTAC 注解 步骤四：在","tags":null,"title":"SpringCloud用户指南","type":"projects","url":"/zh/projects/hmily/user-springcloud/","wordcount":1031},{"author":null,"categories":null,"content":" Firstly, you should bootstrap raincat-manager, please refer to how to bootstrap Txmanager for details. Then, please add following dependency in maven at your service, and add @TxTransaction annotation in your distributed transaction method. \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;raincat-springcloud\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.0.0-RELEASE\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  Configure TxTransactionBootstrap by Spring XML \u0026amp;lt;context:component-scan base-package=\u0026amp;quot;org.dromara.*\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;txTransactionBootstrap\u0026amp;quot; class=\u0026amp;quot;org.dromara.raincat.core.bootstrap.TxTransactionBootstrap\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;txManagerUrl\u0026amp;quot; value=\u0026amp;quot;http://localhost:8761\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;serializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;nettySerializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;compensation\u0026amp;quot; value=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;compensationCacheType\u0026amp;quot; value=\u0026amp;quot;db\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;txDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;bean class=\u0026amp;quot;org.dromara.raincat.common.config.TxDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;url\u0026amp;quot; value=\u0026amp;quot;jdbc:mysql://192.168.1.98:3306/tx?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;driverClassName\u0026amp;quot; value=\u0026amp;quot;com.mysql.jdbc.Driver\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;username\u0026amp;quot; value=\u0026amp;quot;root\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;password\u0026amp;quot; value=\u0026amp;quot;123456\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt; \u0026amp;lt;/property\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt;  Configure TxTransactionBootstrap by spring boot starter  Firstly, please add maven dependency spring-boot-starter-springcloud.\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;raincat-spring-boot-starter-springcloud\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.0.0-RELEASE\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   Secondly, please configure the application.yml like follows.  org: dromara: raincat: txManagerUrl: http://localhost:8761 serializer: kroy nettySerializer: kroy compensation: true compensationCacheType : db txDbConfig : driverClassName : com.mysql.jdbc.Driver url : jdbc:mysql://192.168.1.98:3306/tx?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8 username : root password : 123456  txManagerUrl is the ip and port that you bootstrap txManager . Please add http:// at head.\n serializer is the way of transaction log serialization.\n nettySerializer is the serialization way of how to communicate with txManager. Please be caution that It should be consistent with the configuration in txManager.\n compensation is the property whether compensation is required or not, the service will compensate itself in some cases.\n compensationCacheType is the types of storage log, and support Redis, Mongodb, Zookeeper, etc. For details, please refer to the config.\n  NOTICE：You need to open AOP when you want to use XML to configure. …","date":-62135596800,"description":"springcloud user guide","dir":"projects/raincat/springcloud-user/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"969843af59ba4a760abfd75c90d05e2d1d0be12c","permalink":"/projects/raincat/springcloud-user/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/raincat/springcloud-user/","summary":"Firstly, you should bootstrap raincat-manager, please refer to how to bootstrap Txmanager for details. Then, please add following dependency in maven at your service, and add @TxTransaction annotation in your distributed transaction method. \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.dromara\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;raincat-springcloud\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.0.0-RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;  Configure TxTransactionBootstrap by Spring XML \u0026lt;context:component-scan base-package=\u0026quot;org.dromara.*\u0026quot;/\u0026gt; \u0026lt;aop:aspectj-autoproxy expose-proxy=\u0026quot;true\u0026quot;/\u0026gt; \u0026lt;bean id=\u0026quot;txTransactionBootstrap\u0026quot; class=\u0026quot;org.dromara.raincat.core.bootstrap.TxTransactionBootstrap\u0026quot;\u0026gt; \u0026lt;property name=\u0026quot;txManagerUrl\u0026quot; value=\u0026quot;http://localhost:8761\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;serializer\u0026quot; value=\u0026quot;kryo\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;nettySerializer\u0026quot; value=\u0026quot;kryo\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;compensation\u0026quot; value=\u0026quot;true\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;compensationCacheType\u0026quot; value=\u0026quot;db\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;txDbConfig\u0026quot;\u0026gt; \u0026lt;bean class=\u0026quot;org.","tags":null,"title":"Springcloud user guide","type":"projects","url":"/projects/raincat/springcloud-user/","wordcount":243},{"author":null,"categories":null,"content":" Prerequisites  JDK 1.8+ Maven 3.2.x Git Zookeeper  Cloning the GitHub Repository and Quick Installation  \u0026amp;gt; git clone https://github.com/dromara/hmily.git \u0026amp;gt; cd hmily \u0026amp;gt; mvn -DskipTests clean install -U  Executing SQL(s) in Demo Module sql\nSetting tars nodes Build tars nodes with following information refering to here:\n APP: TestInventory, Server Name: InventoryApp, OBJ: InventoryObj, Port: 29740 APP: HmilyAccount, Server Name: AccountApp, OBJ: AccountObj, Port: 10386  With nodes built, run mvn clean package packaging command respectively under hmily-demo-tars-springboot-account and hmily-demo-tars-springboot-inventory directories, and publish with outputs on previous nodes set. Refer to here for details.\nOpen with Your Favourite Editor (IDEA) and Locate on hmily-demo-tars Module Configuring（hmily-demo-tars-account module for instance）  Configure with your business database(account module for instance)  spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://\u0026amp;lt;db_host_ip\u0026amp;gt;:\u0026amp;lt;db_host_port\u0026amp;gt;/hmily_account?useUnicode=true\u0026amp;amp;characterEncoding=utf8 # replace with your db_host_ip and db_host_port username: root # replace with your db username password: your_password # replace with your db user password   Modify hmily.yml, with mysql persistence backend  repository: database: driverClassName: com.mysql.jdbc.Driver url: jdbc:mysql://\u0026amp;lt;db_host_ip\u0026amp;gt;:\u0026amp;lt;db_host_port\u0026amp;gt;/hmily?useUnicode=true\u0026amp;amp;characterEncoding=utf8 # replace with your db_host_ip and db_host_port username: root # replace with your db username password: your_password # replace with your db user password   Replace 192.168.41.102 globally with tars platform IP address within file(s) suffixed with config.conf under rescouces directory, and append an -Dconfig=\u0026amp;lt;file\u0026amp;gt; parameter to bootstrap parameters with previous file location(s)\n run TarsHmilyAccountApplication.java\n  Run hmily-demo-tars-springboot-inventory(refer to simillar instructions above). Run hmily-demo-tars-springboot-order(refer to simillar instructions above). Access on http://127.0.0.1:18087/swagger-ui.html for more. ","date":-62135596800,"description":"Tars Quick Start","dir":"projects/hmily/quick-start-tars/","fuzzywordcount":300,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"b43fe73bcf2842441752b747792c355d65121d0e","permalink":"/projects/hmily/quick-start-tars/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/hmily/quick-start-tars/","summary":"Prerequisites  JDK 1.8+ Maven 3.2.x Git Zookeeper  Cloning the GitHub Repository and Quick Installation  \u0026gt; git clone https://github.com/dromara/hmily.git \u0026gt; cd hmily \u0026gt; mvn -DskipTests clean install -U  Executing SQL(s) in Demo Module sql\nSetting tars nodes Build tars nodes with following information refering to here:\n APP: TestInventory, Server Name: InventoryApp, OBJ: InventoryObj, Port: 29740 APP: HmilyAccount, Server Name: AccountApp, OBJ: AccountObj, Port: 10386  With nodes built, run mvn clean package packaging command respectively under hmily-demo-tars-springboot-account and hmily-demo-tars-springboot-inventory directories, and publish with outputs on previous nodes set.","tags":null,"title":"Tars Quick Start","type":"projects","url":"/projects/hmily/quick-start-tars/","wordcount":227},{"author":null,"categories":null,"content":" Tars User Guide  Step 1: Introduce the jar packages\n Step 2: Introduce the Hmily configuration\n Step 3: Add @Hmily annotation on the auto-generated Servant interface method which required the Hmily Distributed Transaction.\n Step 4: Add @HmilyTCC or @HmilyTAC annotation on the concrete implementation method(Service provider).\n  Introduce The Maven dependency Spring-Namespace\n Introduce the hmily-tars dependency   \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-tars\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   make the configuration in the XML configuration file as below:\n\u0026amp;lt;!--Configure the base packages that the Hmily framework need to scan --\u0026amp;gt; \u0026amp;lt;context:component-scan base-package=\u0026amp;quot;org.dromara.hmily.*\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;!-- set up to enable the aspectj-autoproxy --\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;!-- Configure the bean parameters for Hmily startup --\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;hmilyApplicationContextAware\u0026amp;quot; class=\u0026amp;quot;org.dromara.hmily.spring.HmilyApplicationContextAware\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;hmilyCommunicatorBeanPostProcessor\u0026amp;quot; class=\u0026amp;quot;org.dromara.hmily.tars.spring.TarsHmilyCommunicatorBeanPostProcessor\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;tarsHmilyStartupBean\u0026amp;quot; class=\u0026amp;quot;org.dromara.hmily.tars.spring.TarsHmilyFilterStartupBean\u0026amp;quot;/\u0026amp;gt;  Spring-Boot\n Introduce the hmily-spring-boot-starter-tars dependency\nxml \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-spring-boot-starter-tars\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;    Introduce the Hmily configuration  new a configuration file named hmily.yml under the resource directory of the current project\n the specific parameter configuration can refer to configuration detail,Local configuration mode, Zookeeper configuration mode, nacos configuration mode,apollo configuration mode\n  Add annotations on the service implementation interface We have completed the integration described above,and the next we will talk about the specific implementation.\nTCC Mode  Add @HmilyTCC (confirmMethod = \u0026amp;quot;confirm\u0026amp;quot;, cancelMethod = \u0026amp;quot;cancel\u0026amp;quot;) annotation to the concrete implementation of the interface method identified by \u0026amp;lsquo;@Hmily\u0026amp;rsquo;.\n confirmMethod : the method name for confirm，The method parameter list and return type should be consistent with the identification method.\n cancelMethod : the method for cancel，The method parameter list and return type should be consistent with the identification method.\n The TCC mode should ensure the idempotence of the confirm and cancel methods,Users need to develop these two methods by themselves,The confirmation and rollback behavior of all transactions are completely up tp users.The Hmily framework is just responsible for making calls.\n  public class HelloServiceImpl implements HelloService { @HmilyTCC(confirmMethod = …","date":-62135596800,"description":"Tars User Guide","dir":"projects/hmily/user-tars/","fuzzywordcount":400,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"dcf533434776ebf73b83017cec406dc4d29649c3","permalink":"/projects/hmily/user-tars/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/projects/hmily/user-tars/","summary":"Tars User Guide  Step 1: Introduce the jar packages\n Step 2: Introduce the Hmily configuration\n Step 3: Add @Hmily annotation on the auto-generated Servant interface method which required the Hmily Distributed Transaction.\n Step 4: Add @HmilyTCC or @HmilyTAC annotation on the concrete implementation method(Service provider).\n  Introduce The Maven dependency Spring-Namespace\n Introduce the hmily-tars dependency   \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.dromara\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;hmily-tars\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;{last.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   make the configuration in the XML configuration file as below:","tags":null,"title":"Tars User Guide","type":"projects","url":"/projects/hmily/user-tars/","wordcount":352},{"author":null,"categories":null,"content":" @TxTransaction annotation  This annotation is the aspect of distributed transaction, it need to be added when the business side need distributed transaction.  TxTransactionBootstrap Configuration： \u0026amp;lt;context:component-scan base-package=\u0026amp;quot;org.dromara.raincat.*\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;txTransactionBootstrap\u0026amp;quot; class=\u0026amp;quot;org.dromara.raincat.core.bootstrap.TxTransactionBootstrap\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;txManagerUrl\u0026amp;quot; value=\u0026amp;quot;http://localhost:8761\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;serializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;nettySerializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;bufferSize\u0026amp;quot; value=\u0026amp;quot;4096\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;nettyThreadMax\u0026amp;quot; value=\u0026amp;quot;16\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;refreshInterval\u0026amp;quot; value=\u0026amp;quot;30\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;delayTime\u0026amp;quot; value=\u0026amp;quot;30\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;heartTime\u0026amp;quot; value=\u0026amp;quot;10\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;compensation\u0026amp;quot; value=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;recoverDelayTime\u0026amp;quot; value=\u0026amp;quot;60\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;retryMax\u0026amp;quot; value=\u0026amp;quot;3\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;compensationRecoverTime\u0026amp;quot; value=\u0026amp;quot;60\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;compensationCacheType\u0026amp;quot; value=\u0026amp;quot;db\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;txDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;bean class=\u0026amp;quot;org.dromara.raincat.common.config.TxDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;url\u0026amp;quot; value=\u0026amp;quot;jdbc:mysql://192.168.1.98:3306/tx?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;driverClassName\u0026amp;quot; value=\u0026amp;quot;com.mysql.jdbc.Driver\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;username\u0026amp;quot; value=\u0026amp;quot;root\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;password\u0026amp;quot; value=\u0026amp;quot;123456\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt; \u0026amp;lt;/property\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt;   txManagerUrl is the ip and port of thetxManager, and please add the http:// prefix at head.\n serializer is the way of transaction log serialization, which Kroy is recommended, and Hessian, Protostuff, Jdk are also supported. In our performance test, it is shown as: Kroy\u0026amp;gt;Hessian\u0026amp;gt;Protostuff\u0026amp;gt;Jdk.\n nettySerializer is the serialization way of communicating with txManager, and it need to be the same as the serialization way configured in txManager.\n bufferSize is the bufferSize of disruptor and can be adjusted larger when the concurrency at a high level. Note that it should be 2n power.\n nettyThreadMax is the number of Netty client work thread.\n refreshInterval is the interval of pulling txmanager configuration, and the unit is seconds.\n delayTime is the maximum communication delay time between the client and txmanager.\n heartTime is the heartbeat interval with txmanager, and the unit is seconds.\n compensation is a boolean value to configure whether the compensation is required, most of time it is not required, you can set true in some …","date":-62135596800,"description":"TxTransactionBootstrap Configuration","dir":"projects/raincat/config/","fuzzywordcount":500,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"0231f6398134c2b0fdb30d824f130b69f81ea67e","permalink":"/projects/raincat/config/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/projects/raincat/config/","summary":"@TxTransaction annotation  This annotation is the aspect of distributed transaction, it need to be added when the business side need distributed transaction.  TxTransactionBootstrap Configuration： \u0026lt;context:component-scan base-package=\u0026quot;org.dromara.raincat.*\u0026quot;/\u0026gt; \u0026lt;aop:aspectj-autoproxy expose-proxy=\u0026quot;true\u0026quot;/\u0026gt; \u0026lt;bean id=\u0026quot;txTransactionBootstrap\u0026quot; class=\u0026quot;org.dromara.raincat.core.bootstrap.TxTransactionBootstrap\u0026quot;\u0026gt; \u0026lt;property name=\u0026quot;txManagerUrl\u0026quot; value=\u0026quot;http://localhost:8761\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;serializer\u0026quot; value=\u0026quot;kryo\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;nettySerializer\u0026quot; value=\u0026quot;kryo\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;bufferSize\u0026quot; value=\u0026quot;4096\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;nettyThreadMax\u0026quot; value=\u0026quot;16\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;refreshInterval\u0026quot; value=\u0026quot;30\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;delayTime\u0026quot; value=\u0026quot;30\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;heartTime\u0026quot; value=\u0026quot;10\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;compensation\u0026quot; value=\u0026quot;true\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;recoverDelayTime\u0026quot; value=\u0026quot;60\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;retryMax\u0026quot; value=\u0026quot;3\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;compensationRecoverTime\u0026quot; value=\u0026quot;60\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;compensationCacheType\u0026quot; value=\u0026quot;db\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;txDbConfig\u0026quot;\u0026gt; \u0026lt;bean class=\u0026quot;org.","tags":null,"title":"TxTransactionBootstrap Configuration","type":"projects","url":"/projects/raincat/config/","wordcount":474},{"author":null,"categories":null,"content":" @TxTransaction annotation详解  该注解为分布式事务的切面（AOP point） ，如果业务方的service服务需要参与分布式事务，则需要加上此注解。  TxTransactionBootstrap 详解： \u0026amp;lt;context:component-scan base-package=\u0026amp;quot;org.dromara.raincat.*\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;txTransactionBootstrap\u0026amp;quot; class=\u0026amp;quot;org.dromara.raincat.core.bootstrap.TxTransactionBootstrap\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;txManagerUrl\u0026amp;quot; value=\u0026amp;quot;http://localhost:8761\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;serializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;nettySerializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;bufferSize\u0026amp;quot; value=\u0026amp;quot;4096\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;nettyThreadMax\u0026amp;quot; value=\u0026amp;quot;16\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;refreshInterval\u0026amp;quot; value=\u0026amp;quot;30\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;delayTime\u0026amp;quot; value=\u0026amp;quot;30\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;heartTime\u0026amp;quot; value=\u0026amp;quot;10\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;compensation\u0026amp;quot; value=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;recoverDelayTime\u0026amp;quot; value=\u0026amp;quot;60\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;retryMax\u0026amp;quot; value=\u0026amp;quot;3\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;compensationRecoverTime\u0026amp;quot; value=\u0026amp;quot;60\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;compensationCacheType\u0026amp;quot; value=\u0026amp;quot;db\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;txDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;bean class=\u0026amp;quot;org.dromara.raincat.common.config.TxDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;url\u0026amp;quot; value=\u0026amp;quot;jdbc:mysql://192.168.1.98:3306/tx?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;driverClassName\u0026amp;quot; value=\u0026amp;quot;com.mysql.jdbc.Driver\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;username\u0026amp;quot; value=\u0026amp;quot;root\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;password\u0026amp;quot; value=\u0026amp;quot;123456\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt; \u0026amp;lt;/property\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt;   txManagerUrl：填写你启动的txManager的ip端口，注意添加http://前缀。\n serializer :事务日志序列化方式，这里我推荐使用是kroy。当然也支持hessian,protostuff,jdk。在我们测试中表现为: kroy\u0026amp;gt;hessian\u0026amp;gt;protostuff\u0026amp;gt;jdk。\n nettySerializer： 与txManager通信对象的序列化方法，注意与txManager中的序列化方式配置一样。\n bufferSize: disruptor的bufferSize,当高并发的时候，可以调大。注意是 2n次方。\n nettyThreadMax ： netty客户端工作线程数量。\n refreshInterval: 拉取txmanager配置信息间隔时间，单位秒。\n delayTime ： 客户端与txmanager通信最大延迟时间。\n heartTime ： 与txmanager保持心跳时间间隔，单位秒。\n compensation： 是否需要补偿，一般情况下不需要，极端情况下设置为true。\n recoverDelayTime：事务恢复延迟时间，只有当 compensation：为ture才有用。\n compensationRecoverTime： 补偿间隔时间 只有当 compensation：为ture才有用。\n retryMax ： 事务补偿最大重试次数。\n  compensationCacheType：使用何种方式存储日志，支持的有db，redis，mongo，zookeeper等。\n 接下来是最重要的事务日志的存储 在我们的压测中，推荐使用mongo。表现为 mongodb\u0026amp;gt;redis集群\u0026amp;gt;mysql\u0026amp;gt;zookeeper\n 如果你采用mongodb存储日志,配置如下(url可以配置成mongdb集群的url)\n  \u0026amp;lt;property name=\u0026amp;quot;compensationCacheType\u0026amp;quot; value=\u0026amp;quot;mongodb\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;txMongoConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;bean class=\u0026amp;quot;org.dromara.raincat.common.config.TxMongoConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;mongoDbUrl\u0026amp;quot; value=\u0026amp;quot;192.168.1.68:27017\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property …","date":-62135596800,"description":"TxTransactionBootstrap配置详解","dir":"projects/raincat/config/","fuzzywordcount":1000,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"cb6b24b6fcd53a713fbd9012b752ea93d261f586","permalink":"/zh/projects/raincat/config/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/zh/projects/raincat/config/","summary":"@TxTransaction annotation详解 该注解为分布式事务的切面（AOP point） ，如果业务方的service服务需要参与分布式事务，则需要加上此注解。","tags":null,"title":"TxTransactionBootstrap配置详解","type":"projects","url":"/zh/projects/raincat/config/","wordcount":994},{"author":null,"categories":null,"content":" Environment  JDK 1.8+ Maven 3.2.x Git Redis Mysql  Pull the code \u0026amp;gt; git clone https://github.com/yu199195/Raincat.git \u0026amp;gt; cd Raincat \u0026amp;gt; mvn -DskipTests clean install -U  Prepare the database Execute the SQL statement in demo. SQL statement\nConfiguration  Please open the project in IDEA or Eclipse, and modify the Redis configuration in application.yml.  tx: manager: netty : port: 9998 serialize: kryo maxConnection: 100 maxThreads : 16 delayTime : 5 heartTime : 20 redis : cluster : false hostName : 192.168.1.91 port: 6379 password : foobaredbbexONE123  Then, bootstrap the raincat-manager by executing the main() in TxManagerApplication.\n Modify the database configuration in application.yml.  spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://192.168.1.98:3306/order?useUnicode=true\u0026amp;amp;characterEncoding=utf8 username: root password: 123456 application: name: order-service org: dromara: raincat: txManagerUrl: http://localhost:8761 serializer: kroy nettySerializer: kroy compensation: true compensationCacheType : db txDbConfig : driverClassName : com.mysql.jdbc.Driver url : jdbc:mysql://192.168.1.98:3306/tx?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8 username : root password : 123456   Modify the Zookeeper configuration in spring-dubbo.xml.  \u0026amp;lt;dubbo:registry protocol=\u0026amp;quot;zookeeper\u0026amp;quot; address=\u0026amp;quot;localhost:2181\u0026amp;quot;/\u0026amp;gt;   Modify the Zookeeper configuration in spring-dubbo.xml.  \u0026amp;lt;dubbo:registry protocol=\u0026amp;quot;zookeeper\u0026amp;quot; address=\u0026amp;quot;192.168.1.148:2181\u0026amp;quot;/\u0026amp;gt;   Start the order project. (Execute the main() method in OrderApplication)  Bootstrap the project Bootstrap the stock project and consume project like others. Please access the following address.http://127.0.0.1:8087/swagger-ui.html.\n","date":-62135596800,"description":"dubbo quick start","dir":"projects/raincat/quick-start-dubbo/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"b4f09828ceb88bd4e9eaeb79f0c550851b4ba975","permalink":"/projects/raincat/quick-start-dubbo/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/raincat/quick-start-dubbo/","summary":"Environment  JDK 1.8+ Maven 3.2.x Git Redis Mysql  Pull the code \u0026gt; git clone https://github.com/yu199195/Raincat.git \u0026gt; cd Raincat \u0026gt; mvn -DskipTests clean install -U  Prepare the database Execute the SQL statement in demo. SQL statement\nConfiguration  Please open the project in IDEA or Eclipse, and modify the Redis configuration in application.yml.  tx: manager: netty : port: 9998 serialize: kryo maxConnection: 100 maxThreads : 16 delayTime : 5 heartTime : 20 redis : cluster : false hostName : 192.","tags":null,"title":"dubbo quick start","type":"projects","url":"/projects/raincat/quick-start-dubbo/","wordcount":185},{"author":null,"categories":null,"content":" 环境准备  JDK 1.8+ Maven 3.2.x Git Redis Mysql  代码拉取  \u0026amp;gt; git clone https://github.com/yu199195/Raincat.git \u0026amp;gt; cd Raincat \u0026amp;gt; mvn -DskipTests clean install -U  执行demo 模块的sql语句。 sql语句\n使用你的工具 idea 或者eclipse 打开项目。 修改raincat-manager项目下，application.yml中的redis配置 tx: manager: netty : port: 9998 serialize: kryo maxConnection: 100 maxThreads : 16 delayTime : 5 heartTime : 20 redis : cluster : false hostName : 192.168.1.91 port: 6379 password : foobaredbbexONE123  启动raincat-manager （执行TxManagerApplication中的main方法） 修改order项目的application.yml中的数据库配置 spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://192.168.1.98:3306/order?useUnicode=true\u0026amp;amp;characterEncoding=utf8 username: root password: 123456 application: name: order-service org: dromara: raincat: txManagerUrl: http://localhost:8761 serializer: kroy nettySerializer: kroy compensation: true compensationCacheType : db txDbConfig : driverClassName : com.mysql.jdbc.Driver url : jdbc:mysql://192.168.1.98:3306/tx?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8 username : root password : 123456   修改 spring-dubbo.xml中的zookeeper配置  \u0026amp;lt;dubbo:registry protocol=\u0026amp;quot;zookeeper\u0026amp;quot; address=\u0026amp;quot;localhost:2181\u0026amp;quot;/\u0026amp;gt;   在spring-dubbo中修改你的zookeeper地址  \u0026amp;lt;dubbo:registry protocol=\u0026amp;quot;zookeeper\u0026amp;quot; address=\u0026amp;quot;192.168.1.148:2181\u0026amp;quot;/\u0026amp;gt;   启动order项目。（执行OrderApplication中的main方法）  其他项目类似，启动stock项目，启动consume项目。 访问 http://127.0.0.1:8087/swagger-ui.html ","date":-62135596800,"description":"dubbo快速体验","dir":"projects/raincat/quick-start-dubbo/","fuzzywordcount":500,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"fd01e0b5466a2d592c505c37520fba9e68499a18","permalink":"/zh/projects/raincat/quick-start-dubbo/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/zh/projects/raincat/quick-start-dubbo/","summary":"环境准备 JDK 1.8+ Maven 3.2.x Git Redis Mysql 代码拉取 \u0026gt; git clone https://github.com/yu199195/Raincat.git \u0026gt; cd Raincat \u0026gt; mvn -DskipTests clean install -U 执行demo 模块的sql语句。 sql语句 使用你的工具 idea 或者eclipse 打开项目。 修","tags":null,"title":"dubbo 快速体验","type":"projects","url":"/zh/projects/raincat/quick-start-dubbo/","wordcount":404},{"author":null,"categories":null,"content":" Dubbo接口部分  在你的接口项目中引入jar包。  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-annotation\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   在需要进行Hmily分布式事务的接口方法上加上 @Hmily 标识。\npublic interface HelloService { @Hmily void say(String hello); }  Dubbo实现项目  步骤一 ： 引入依赖hmily的jar包\n 步骤二 ： 新增Hmily配置\n 步骤三 ： 在实现方法上添加注解。TCC模式，则需要完成 confirm，cancel方法的开发\n  引入依赖 Spring-Namespace  Alibaba-Dubbo 用户引入  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-dubbo\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  Aapche-Dubbo 用户引入\n  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-apache-dubbo\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   在xml中进行如下配置  \u0026amp;lt;!--设置开启aspectj-autoproxy--\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id = \u0026amp;quot;hmilyTransactionAspect\u0026amp;quot; class=\u0026amp;quot;org.dromara.hmily.spring.aop.SpringHmilyTransactionAspect\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id = \u0026amp;quot;hmilyApplicationContextAware\u0026amp;quot; class=\u0026amp;quot;org.dromara.hmily.spring.HmilyApplicationContextAware\u0026amp;quot;/\u0026amp;gt;  Spring-Boot  Alibaba-Dubbo 用户引入  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-spring-boot-starter-dubbo\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   Aapche-Dubbo 用户引入  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-spring-boot-starter-apache-dubbo\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  引入 hmily配置  在项目的 resource 新建文件名为:hmily.yml配置文件\n 具体的参数配置可以参考配置详解,本地配置模式, zookeeper配置模式, nacos配置模式,apollo配置模式\n  实现接口上添加注解 上述我们已经完成了集成，下面将讲述具体的实现。\nTCC模式  对@Hmily 标识的接口方法的具体实现上，加上@HmilyTCC(confirmMethod = \u0026amp;quot;confirm\u0026amp;quot;, cancelMethod = \u0026amp;quot;cancel\u0026amp;quot;)\n confirmMethod : 确认方法名称，该方法参数列表与返回类型应与标识方法一致。\n cancelMethod : 回滚方法名称，该方法参数列表与返回类型应与标识方法一致。\n TCC模式应该保证 confirm 和 cancel 方法的幂等性，用户需要自行去开发这个2个方法，所有的事务的确认与回滚，完全由用户决定。Hmily框架只是负责来进行调用\n  public class HelloServiceImpl implements HelloService { @HmilyTCC(confirmMethod = \u0026amp;quot;sayConfrim\u0026amp;quot;, cancelMethod = \u0026amp;quot;sayCancel\u0026amp;quot;) public void say(String hello) { System.out.println(\u0026amp;quot;hello world\u0026amp;quot;); } public void sayConfrim(String hello) { System.out.println(\u0026amp;quot; confirm hello world\u0026amp;quot;); } public void sayCancel(String hello) { System.out.println(\u0026amp;quot; cancel hello world\u0026amp;quot;); } }  dubbo注解用户 对于使用 @Reference 注解来注入dubbo服务的用户，请注意：你可以需要做如下配置:\nspring-namespace 用户 在你的xml配置中，需要将 org.dromara.hmily.spring.annotation.RefererAnnotationBeanPostProcessor 注入成spring的bean\n\u0026amp;lt;bean id = \u0026amp;quot;refererAnnotationBeanPostProcessor\u0026amp;quot; class=\u0026amp;quot;org.dromara.hmily.spring.annotation.RefererAnnotationBeanPostProcessor\u0026amp;quot;/\u0026amp;gt;  spring-boot用户 需要在yml文件里面开启注解支持：\nhmily.support.rpc.annotation = true  或者在项目中显式注入：\n@Bean public BeanPostProcessor …","date":-62135596800,"description":"dubbo用户指南","dir":"projects/hmily/user-dubbo/","fuzzywordcount":1100,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"a6ce57470599ea9c55b7c746a367292788678104","permalink":"/zh/projects/hmily/user-dubbo/","publishdate":"0001-01-01T00:00:00Z","readingtime":3,"relpermalink":"/zh/projects/hmily/user-dubbo/","summary":"Dubbo接口部分 在你的接口项目中引入jar包。 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.dromara\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;hmily-annotation\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;{last.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在需要进行Hmily分布式事务的接口方法上加上 @Hmily 标识。 public interface HelloService { @Hmily void say(String hello); } Dubbo","tags":null,"title":"dubbo用户指南","type":"projects","url":"/zh/projects/hmily/user-dubbo/","wordcount":1053},{"author":null,"categories":null,"content":" 首先启动raincat-manager，具体怎么启动参考 启动manager jar包依赖，在你的dubbo服务端添加jar包，并在需要参与分布式事务的方法上添加 @TxTransaction注解 \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;raincat-dubbo\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.0.0-RELEASE\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  Spring XML方式配置 TxTransactionBootstrap \u0026amp;lt;context:component-scan base-package=\u0026amp;quot;org.dromara.*\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;txTransactionBootstrap\u0026amp;quot; class=\u0026amp;quot;org.dromara.raincat.core.bootstrap.TxTransactionBootstrap\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;txManagerUrl\u0026amp;quot; value=\u0026amp;quot;http://localhost:8761\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;serializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;nettySerializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;compensation\u0026amp;quot; value=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;compensationCacheType\u0026amp;quot; value=\u0026amp;quot;db\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;txDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;bean class=\u0026amp;quot;org.dromara.raincat.common.config.TxDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;url\u0026amp;quot; value=\u0026amp;quot;jdbc:mysql://192.168.1.98:3306/tx?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;driverClassName\u0026amp;quot; value=\u0026amp;quot;com.mysql.jdbc.Driver\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;username\u0026amp;quot; value=\u0026amp;quot;root\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;password\u0026amp;quot; value=\u0026amp;quot;123456\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt; \u0026amp;lt;/property\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt;  Spring boot start方式配置 TxTransactionBootstrap  首先依赖raincat 提供的spring-boot-starter-dubbo\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;raincat-spring-boot-starter-dubbo\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.0.0-RELEASE\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   配置 application.yml  org: dromara: raincat: txManagerUrl: http://localhost:8761 serializer: kroy nettySerializer: kroy compensation: true compensationCacheType : db txDbConfig : driverClassName : com.mysql.jdbc.Driver url : jdbc:mysql://192.168.1.98:3306/tx?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8 username : root password : 123456  txManagerUrl：填写你启动的txManager的ip端口，注意添加http://\n serializer： 是指事务日志的序列化方式\n nettySerializer： 与txManager通信对象的序列化方法，注意与txManager中的序列化方式配置一样。\n compensation ：是否需要补偿，极端情况下，服务自身会进行补偿。\n compensationCacheType： 存储日志类型，当然还有支持redis，mongo，zookeeper等等，具体可以参考 配置详解。\n  配置扫描raincat包，与开启AOP代理（XML方式配置的时候必须加上，starter方式不需要）。 如果有任何问题可以参考dubbo-sample ","date":-62135596800,"description":"dubbo用户指南","dir":"projects/raincat/dubbo-user/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"b700c1a827b370a62429e3497fd0510a77393f4c","permalink":"/zh/projects/raincat/dubbo-user/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/zh/projects/raincat/dubbo-user/","summary":"首先启动raincat-manager，具体怎么启动参考 启动manager jar包依赖，在你的dubbo服务端添加jar包，并在需要参与分布","tags":null,"title":"dubbo用户指南","type":"projects","url":"/zh/projects/raincat/dubbo-user/","wordcount":535},{"author":null,"categories":null,"content":" 首先启动raincat-manager，具体怎么启动参考 启动manager jar包依赖，在你的服务端添加jar包，并在需要参与分布式事务的方法上添加 @TxTransaction注解 \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;raincat-motan\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.0.0-RELEASE\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  Spring XML方式配置 TxTransactionBootstrap \u0026amp;lt;context:component-scan base-package=\u0026amp;quot;org.dromara.*\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;txTransactionBootstrap\u0026amp;quot; class=\u0026amp;quot;org.dromara.raincat.core.bootstrap.TxTransactionBootstrap\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;txManagerUrl\u0026amp;quot; value=\u0026amp;quot;http://localhost:8761\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;serializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;nettySerializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;compensation\u0026amp;quot; value=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;compensationCacheType\u0026amp;quot; value=\u0026amp;quot;db\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;txDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;bean class=\u0026amp;quot;org.dromara.raincat.common.config.TxDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;url\u0026amp;quot; value=\u0026amp;quot;jdbc:mysql://192.168.1.98:3306/tx?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;driverClassName\u0026amp;quot; value=\u0026amp;quot;com.mysql.jdbc.Driver\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;username\u0026amp;quot; value=\u0026amp;quot;root\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;password\u0026amp;quot; value=\u0026amp;quot;123456\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt; \u0026amp;lt;/property\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt;  Spring boot start方式配置 TxTransactionBootstrap  首先依赖raincat 提供的spring-boot-starter-springcloud\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;raincat-spring-boot-starter-motan\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.0.0-RELEASE\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   配置 application.yml  org: dromara: raincat: txManagerUrl: http://localhost:8761 serializer: kroy nettySerializer: kroy compensation: true compensationCacheType : db txDbConfig : driverClassName : com.mysql.jdbc.Driver url : jdbc:mysql://192.168.1.98:3306/tx?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8 username : root password : 123456  txManagerUrl：填写你启动的txManager的ip端口，注意添加http://\n serializer： 是指事务日志的序列化方式\n nettySerializer： 与txManager通信对象的序列化方法，注意与txManager中的序列化方式配置一样。\n compensation ：是否需要补偿，极端情况下，服务自身会进行补偿。\n compensationCacheType： 存储日志类型，当然还有支持redis，mongo，zookeeper等等，具体可以参考 配置详解。\n  配置扫描raincat包，与开启AOP代理（XML方式配置的时候必须加上，starter方式不需要）。 ","date":-62135596800,"description":"motan用户指南","dir":"projects/raincat/motan-user/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"c46d91b05bb51922ce897c55d8926a0644023224","permalink":"/zh/projects/raincat/motan-user/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/zh/projects/raincat/motan-user/","summary":"首先启动raincat-manager，具体怎么启动参考 启动manager jar包依赖，在你的服务端添加jar包，并在需要参与分布式事务的方","tags":null,"title":"motan用户指南","type":"projects","url":"/zh/projects/raincat/motan-user/","wordcount":513},{"author":null,"categories":null,"content":" Prerequisites  JDK 1.8+ Maven 3.2.x Git Zookeeper  Cloning the GitHub Repository and Quick Installation  \u0026amp;gt; git clone https://github.com/dromara/hmily.git \u0026amp;gt; cd hmily \u0026amp;gt; mvn -DskipTests clean install -U  Executing SQL(s) in Demo Module sql\nOpen with Your Favourite Editor (IDEA), Locate on hmily-demo-sofa Module and Run Build with Maven Configuring（hmily-demo-sofa-account module for instance）  Configure with your business database in application.yml  spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://\u0026amp;lt;db_host_ip\u0026amp;gt;:\u0026amp;lt;db_host_port\u0026amp;gt;/hmily_account?useUnicode=true\u0026amp;amp;characterEncoding=utf8 # replace with your db_host_ip and db_host_port username: root # replace with your db username password: your_password # replace with your db user password   Configure with sofa-rpc registration address(es) in application.yml (can run with local zookeeper instance(s))  com: alipay: sofa: rpc: registry-address: zookeeper://127.0.0.1:2181 bolt-port: 8888   Modify hmily.yml, with mysql persistence backend  repository: database: driverClassName: com.mysql.jdbc.Driver url: jdbc:mysql://\u0026amp;lt;db_host_ip\u0026amp;gt;:\u0026amp;lt;db_host_port\u0026amp;gt;/hmily?useUnicode=true\u0026amp;amp;characterEncoding=utf8 # replace with your db_host_ip and db_host_port username: root # replace with your db username password: your_password # replace with your db user password   run SofaHmilyAccountApplication.java  Run hmily-demo-sofa-inventory(refer to simillar instructions above). Run hmily-demo-sofa-order(refer to simillar instructions above). Access on http://127.0.0.1:8089/swagger-ui.html for more. ","date":-62135596800,"description":"sofa-rpc Quick Start","dir":"projects/hmily/quick-start-rpc/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"ba7d9a66090ce5eddb7e76528546f5465e96484b","permalink":"/projects/hmily/quick-start-rpc/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/hmily/quick-start-rpc/","summary":"Prerequisites  JDK 1.8+ Maven 3.2.x Git Zookeeper  Cloning the GitHub Repository and Quick Installation  \u0026gt; git clone https://github.com/dromara/hmily.git \u0026gt; cd hmily \u0026gt; mvn -DskipTests clean install -U  Executing SQL(s) in Demo Module sql\nOpen with Your Favourite Editor (IDEA), Locate on hmily-demo-sofa Module and Run Build with Maven Configuring（hmily-demo-sofa-account module for instance）  Configure with your business database in application.yml  spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://\u0026lt;db_host_ip\u0026gt;:\u0026lt;db_host_port\u0026gt;/hmily_account?","tags":null,"title":"sofa-rpc Quick Start","type":"projects","url":"/projects/hmily/quick-start-rpc/","wordcount":165},{"author":null,"categories":null,"content":" 环境准备  JDK 1.8+ Maven 3.2.x Git Zookeeper  代码拉取  \u0026amp;gt; git clone https://github.com/dromara/hmily.git \u0026amp;gt; cd hmily \u0026amp;gt; mvn -DskipTests clean install -U  执行demo 模块的sql语句。 sql语句\n使用你的工具 idea 打开项目，找到hmily-demo-sofa项目，进行maven构建。 修改项目配置（hmily-demo-sofa-account为列子）  application.yml 下修改业务数据库  spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://改成你的ip+端口/hmily_account?useUnicode=true\u0026amp;amp;characterEncoding=utf8 username: #改成你的用户名 password: #改成你的密码   application.yml 下修改sofa-rpc的注册中心地址(可以在自己电脑本地启动一个zookeeper服务)  com: alipay: sofa: rpc: registry-address: zookeeper://127.0.0.1:2181 bolt-port: 8888   修改 hmily.yml,这里使用mysql来存储  repository: database: driverClassName: com.mysql.jdbc.Driver url : jdbc:mysql://改成你的ip+端口/hmily?useUnicode=true\u0026amp;amp;characterEncoding=utf8 username: root #改成你的用户名 password: #改成你的密码   run SofaHmilyAccountApplication.java  启动hmily-demo-sofa-inventory 参考上述。 启动hmily-demo-sofa-order 参考上述。 访问：http://127.0.0.1:8089/swagger-ui.html。 ","date":-62135596800,"description":"sofa-rpc快速体验","dir":"projects/hmily/quick-start-rpc/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"40326f544594be25ef63cfc5f8f6546467d57274","permalink":"/zh/projects/hmily/quick-start-rpc/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/zh/projects/hmily/quick-start-rpc/","summary":"环境准备 JDK 1.8+ Maven 3.2.x Git Zookeeper 代码拉取 \u0026gt; git clone https://github.com/dromara/hmily.git \u0026gt; cd hmily \u0026gt; mvn -DskipTests clean install -U 执行demo 模块的sql语句。 sql语句 使用你的工具 idea 打开项目，找到hmily-dem","tags":null,"title":"sofa-rpc快速体验","type":"projects","url":"/zh/projects/hmily/quick-start-rpc/","wordcount":508},{"author":null,"categories":null,"content":" sofa-rpc接口项目  在你的接口项目中引入jar包。  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-annotation\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   在需要进行Hmily分布式事务的接口方法上加上 @Hmily 标识。\npublic interface HelloService { @Hmily void say(String hello); }  sofa-rpc实现项目  步骤一 ： 引入依赖hmily的jar包\n 步骤二 ： 新增Hmily配置\n 步骤三 ： 在实现方法上添加注解。TCC模式，则需要完成 confirm，cancel方法的开发\n  引入依赖 Spring-Namespace  引入依赖  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-sofa-rpc\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  在xml中进行如下配置\n  \u0026amp;lt;!--设置开启aspectj-autoproxy--\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id = \u0026amp;quot;hmilyTransactionAspect\u0026amp;quot; class=\u0026amp;quot;org.dromara.hmily.spring.aop.SpringHmilyTransactionAspect\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id = \u0026amp;quot;hmilyApplicationContextAware\u0026amp;quot; class=\u0026amp;quot;org.dromara.hmily.spring.HmilyApplicationContextAware\u0026amp;quot;/\u0026amp;gt;  Spring-Boot  引入依赖  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-spring-boot-starter-sofa-rpc\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  引入 hmily配置  在项目的 resource 新建文件名为:hmily.yml配置文件\n 具体的参数配置可以参考配置详解,本地配置模式, zookeeper配置模式, nacos配置模式,apollo配置模式\n  实现接口上添加注解 上述我们已经完成了集成，下面将讲述具体的实现。\nTCC模式  对@Hmily 标识的接口方法的具体实现上，加上@HmilyTCC(confirmMethod = \u0026amp;quot;confirm\u0026amp;quot;, cancelMethod = \u0026amp;quot;cancel\u0026amp;quot;)\n confirmMethod : 确认方法名称，该方法参数列表与返回类型应与标识方法一致。\n cancelMethod : 回滚方法名称，该方法参数列表与返回类型应与标识方法一致。\n TCC模式应该保证 confirm 和 cancel 方法的幂等性，用户需要自行去开发这个2个方法，所有的事务的确认与回滚，完全由用户决定。Hmily框架只是负责来进行调用\n  public class HelloServiceImpl implements HelloService { @HmilyTCC(confirmMethod = \u0026amp;quot;sayConfrim\u0026amp;quot;, cancelMethod = \u0026amp;quot;sayCancel\u0026amp;quot;) public void say(String hello) { System.out.println(\u0026amp;quot;hello world\u0026amp;quot;); } public void sayConfrim(String hello) { System.out.println(\u0026amp;quot; confirm hello world\u0026amp;quot;); } public void sayCancel(String hello) { System.out.println(\u0026amp;quot; cancel hello world\u0026amp;quot;); } }  TAC模式(在开发，未发布)  对@Hmily 标识的接口方法的具体实现上加上@HmilyTAC   重要注意事项 在调用任何RPC调用之前，当你需要聚合rpc调用成为一次分布式事务的时候，需要在聚合RPC调用的方法上，先行添加 @HmilyTCC 或者 @HmilyTAC 注解,表示开启全局事务。\n负载均衡 \u0026amp;amp;\u0026amp;amp; 设置永不重试  如果服务部署了几个节点， 负载均衡算法最好使用 hmily, 这样 try, confirm, cancel 调用会落在同一个节点 充分利用了缓存，提搞了效率。\n 支持一下几种 hmilyConsistentHash, hmilyRandom, hmilyLocalPref, hmilyRoundRobin, hmilyWeightRoundRobin, hmilyWeightConsistentHash 几种方式均是继承sofa-rpc原生的\n  \u0026amp;lt;sofa:reference jvm-first=\u0026amp;quot;false\u0026amp;quot; id=\u0026amp;quot;accountService\u0026amp;quot; interface=\u0026amp;quot;org.dromara.hmily.demo.common.account.api.AccountService\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;sofa:global-attrs retries=\u0026amp;quot;0\u0026amp;quot; timeout=\u0026amp;quot;5000\u0026amp;quot; loadBalancer =\u0026amp;quot;hmilyRandom\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;/sofa:binding.bolt\u0026amp;gt; \u0026amp;lt;/sofa:reference\u0026amp;gt;  异常  try, confirm, cancel 方法的所有异常不要自行catch 任何异常都应该抛出给 Hmily框架处理。  ","date":-62135596800,"description":"sofa-rpc用户指南","dir":"projects/hmily/user-rpc/","fuzzywordcount":900,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"85b3b8c9ac417d66f6fce3e02146b49fc56b142f","permalink":"/zh/projects/hmily/user-rpc/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/zh/projects/hmily/user-rpc/","summary":"sofa-rpc接口项目 在你的接口项目中引入jar包。 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.dromara\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;hmily-annotation\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;{last.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在需要进行Hmily分布式事务的接口方法上加上 @Hmily 标识。 public interface HelloService { @Hmily void say(String hello); } so","tags":null,"title":"sofa-rpc用户指南","type":"projects","url":"/zh/projects/hmily/user-rpc/","wordcount":858},{"author":null,"categories":null,"content":" Environment  JDK 1.8+ Maven 3.2.x Git Redis Mysql  Pull the code \u0026amp;gt; git clone https://github.com/yu199195/Raincat.git \u0026amp;gt; cd Raincat \u0026amp;gt; mvn -DskipTests clean install -U  Prepare the database Execute the SQL statement in demo. SQL statement\nConfiguration  Please open the project in IDEA or Eclipse, and modify the Redis configuration in application.yml.  tx: manager: netty : port: 9998 serialize: kryo maxConnection: 100 maxThreads : 16 delayTime : 5 heartTime : 20 redis : cluster : false hostName : 192.168.1.91 port: 6379 password : foobaredbbexONE123  Then, bootstrap the raincat-manager by executing the main() in TxManagerApplication.\n Modify the alipay database configuration in application.yml.  spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://192.168.1.98:3306/alipay?useUnicode=true\u0026amp;amp;characterEncoding=utf8 username: root password: 123456 application: name: alipay-service   Modify the database configuration in applicationContext.xml.  \u0026amp;lt;bean id=\u0026amp;quot;txTransactionBootstrap\u0026amp;quot; class=\u0026amp;quot;org.dromara.raincat.core.bootstrap.TxTransactionBootstrap\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;txManagerUrl\u0026amp;quot; value=\u0026amp;quot;http://127.0.0.1:8761\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;serializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;nettySerializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;compensation\u0026amp;quot; value=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;compensationCacheType\u0026amp;quot; value=\u0026amp;quot;db\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;txDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;bean class=\u0026amp;quot;org.dromara.raincat.common.config.TxDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;url\u0026amp;quot; value=\u0026amp;quot;jdbc:mysql://192.168.1.98:3306/tx?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;driverClassName\u0026amp;quot; value=\u0026amp;quot;com.mysql.jdbc.Driver\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;username\u0026amp;quot; value=\u0026amp;quot;root\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;password\u0026amp;quot; value=\u0026amp;quot;123456\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt; \u0026amp;lt;/property\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt;  Bootstrap the project  Bootstrap the Alipay project by executing the main() method in AliPayApplication.\n Bootstrap the wechat project and pay project like others. Please access the following address. http://127.0.0.1:8087/swagger-ui.html.\n  ","date":-62135596800,"description":"springcloud quick start","dir":"projects/raincat/quick-start-springcloud/","fuzzywordcount":200,"kind":"page","lang":"en","lastmod":1624504597,"objectID":"8b2580e2ebad8a93585bf39c6af3f65f4eb7343b","permalink":"/projects/raincat/quick-start-springcloud/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/projects/raincat/quick-start-springcloud/","summary":"Environment  JDK 1.8+ Maven 3.2.x Git Redis Mysql  Pull the code \u0026gt; git clone https://github.com/yu199195/Raincat.git \u0026gt; cd Raincat \u0026gt; mvn -DskipTests clean install -U  Prepare the database Execute the SQL statement in demo. SQL statement\nConfiguration  Please open the project in IDEA or Eclipse, and modify the Redis configuration in application.yml.  tx: manager: netty : port: 9998 serialize: kryo maxConnection: 100 maxThreads : 16 delayTime : 5 heartTime : 20 redis : cluster : false hostName : 192.","tags":null,"title":"springcloud quick start","type":"projects","url":"/projects/raincat/quick-start-springcloud/","wordcount":185},{"author":null,"categories":null,"content":" 环境准备  JDK 1.8+ Maven 3.2.x Git Redis Mysql  代码拉取  \u0026amp;gt; git clone https://github.com/yu199195/Raincat.git \u0026amp;gt; cd Raincat \u0026amp;gt; mvn -DskipTests clean install -U  执行demo 模块的sql语句。 sql语句\n使用你的工具 idea 或者eclipse 打开项目。 修改raincat-manager项目下，application.yml中的redis配置 tx: manager: netty : port: 9998 serialize: kryo maxConnection: 100 maxThreads : 16 delayTime : 5 heartTime : 20 redis : cluster : false hostName : 192.168.1.91 port: 6379 password : foobaredbbexONE123  启动raincat-manager （执行TxManagerApplication中的main方法） 修改alipay项目的application.yml中的数据库配置 spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://192.168.1.98:3306/alipay?useUnicode=true\u0026amp;amp;characterEncoding=utf8 username: root password: 123456 application: name: alipay-service   修改 applicationContext.xml中的数据库配置  \u0026amp;lt;bean id=\u0026amp;quot;txTransactionBootstrap\u0026amp;quot; class=\u0026amp;quot;org.dromara.raincat.core.bootstrap.TxTransactionBootstrap\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;txManagerUrl\u0026amp;quot; value=\u0026amp;quot;http://127.0.0.1:8761\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;serializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;nettySerializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;compensation\u0026amp;quot; value=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;compensationCacheType\u0026amp;quot; value=\u0026amp;quot;db\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;txDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;bean class=\u0026amp;quot;org.dromara.raincat.common.config.TxDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;url\u0026amp;quot; value=\u0026amp;quot;jdbc:mysql://192.168.1.98:3306/tx?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;driverClassName\u0026amp;quot; value=\u0026amp;quot;com.mysql.jdbc.Driver\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;username\u0026amp;quot; value=\u0026amp;quot;root\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;password\u0026amp;quot; value=\u0026amp;quot;123456\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt; \u0026amp;lt;/property\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt;   启动Alipay项目。（执行AliPayApplication中的main方法）  其他项目类似，启动wechat项目，启动pay项目。 访问 http://127.0.0.1:8881/swagger-ui.html ","date":-62135596800,"description":"springcloud快速体验","dir":"projects/raincat/quick-start-springcloud/","fuzzywordcount":400,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"daa1b8477a26df3fa68f7b3607dc4394ab8cbf84","permalink":"/zh/projects/raincat/quick-start-springcloud/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/zh/projects/raincat/quick-start-springcloud/","summary":"环境准备 JDK 1.8+ Maven 3.2.x Git Redis Mysql 代码拉取 \u0026gt; git clone https://github.com/yu199195/Raincat.git \u0026gt; cd Raincat \u0026gt; mvn -DskipTests clean install -U 执行demo 模块的sql语句。 sql语句 使用你的工具 idea 或者eclipse 打开项目。 修","tags":null,"title":"springcloud快速体验","type":"projects","url":"/zh/projects/raincat/quick-start-springcloud/","wordcount":378},{"author":null,"categories":null,"content":" 首先启动raincat-manager，具体怎么启动参考 启动manager jar包依赖，在你的服务端添加jar包，并在需要参与分布式事务的方法上添加 @TxTransaction注解 \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;raincat-springcloud\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.0.0-RELEASE\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;  Spring XML方式配置 TxTransactionBootstrap \u0026amp;lt;context:component-scan base-package=\u0026amp;quot;org.dromara.*\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;txTransactionBootstrap\u0026amp;quot; class=\u0026amp;quot;org.dromara.raincat.core.bootstrap.TxTransactionBootstrap\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;txManagerUrl\u0026amp;quot; value=\u0026amp;quot;http://localhost:8761\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;serializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;nettySerializer\u0026amp;quot; value=\u0026amp;quot;kryo\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;compensation\u0026amp;quot; value=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;compensationCacheType\u0026amp;quot; value=\u0026amp;quot;db\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;txDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;bean class=\u0026amp;quot;org.dromara.raincat.common.config.TxDbConfig\u0026amp;quot;\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;url\u0026amp;quot; value=\u0026amp;quot;jdbc:mysql://192.168.1.98:3306/tx?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;driverClassName\u0026amp;quot; value=\u0026amp;quot;com.mysql.jdbc.Driver\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;username\u0026amp;quot; value=\u0026amp;quot;root\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;quot;password\u0026amp;quot; value=\u0026amp;quot;123456\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt; \u0026amp;lt;/property\u0026amp;gt; \u0026amp;lt;/bean\u0026amp;gt;  Spring boot start方式配置 TxTransactionBootstrap  首先依赖raincat 提供的spring-boot-starter-springcloud\n\u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;raincat-spring-boot-starter-springcloud\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.0.0-RELEASE\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   配置 application.yml  org: dromara: raincat: txManagerUrl: http://localhost:8761 serializer: kroy nettySerializer: kroy compensation: true compensationCacheType : db txDbConfig : driverClassName : com.mysql.jdbc.Driver url : jdbc:mysql://192.168.1.98:3306/tx?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8 username : root password : 123456  txManagerUrl：填写你启动的txManager的ip端口，注意添加http://\n serializer： 是指事务日志的序列化方式\n nettySerializer： 与txManager通信对象的序列化方法，注意与txManager中的序列化方式配置一样。\n compensation ：是否需要补偿，极端情况下，服务自身会进行补偿。\n compensationCacheType： 存储日志类型，当然还有支持redis，mongo，zookeeper等等，具体可以参考 配置详解。\n  配置扫描raincat包，与开启AOP代理（XML方式配置的时候必须加上，starter方式不需要）。 如果有任何问题可以参考springcloud-sample ","date":-62135596800,"description":"springcloud用户指南","dir":"projects/raincat/springcloud-user/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"4d9ec3a8755681a2c2a0d1e87e21d5ab24b74408","permalink":"/zh/projects/raincat/springcloud-user/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/zh/projects/raincat/springcloud-user/","summary":"首先启动raincat-manager，具体怎么启动参考 启动manager jar包依赖，在你的服务端添加jar包，并在需要参与分布式事务的方","tags":null,"title":"springcloud用户指南","type":"projects","url":"/zh/projects/raincat/springcloud-user/","wordcount":542},{"author":null,"categories":null,"content":" 环境准备  JDK 1.8+ Maven 3.2.x Git Zookeeper  代码拉取  \u0026amp;gt; git clone https://github.com/dromara/hmily.git \u0026amp;gt; cd hmily \u0026amp;gt; mvn -DskipTests clean install -U  执行demo 模块的sql语句。 sql语句\n建立tars节点 根据此文在当前tars平台建立\n- 应用名:TestInventory,服务名称:InventoryApp,Obj名:InventoryObj,端口29740的节点。\n- 应用名:HmilyAccount,服务名称:AccountApp,Obj名:AccountObj,端口10386的节点。\n在完成节点的建立后，分别到hmily-demo-tars-springboot-account和hmily-demo-tars-springboot-inventory目录下执行mvn clean package命令打包并按照此文在两个前面建立的节点上使用打包的成果物进行节点发布。\n使用你的工具 idea 打开项目，找到hmily-demo-tars项目。 修改项目配置（hmily-demo-tars-account为列子）  修改业务数据库(account项目为列子)  spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://改成你的ip+端口/hmily_account?useUnicode=true\u0026amp;amp;characterEncoding=utf8 username: #改成你的用户名 password: #改成你的密码   修改 hmily.yml,这里使用mysql来存储  repository: database: driverClassName: com.mysql.jdbc.Driver url : jdbc:mysql://改成你的ip+端口/hmily?useUnicode=true\u0026amp;amp;characterEncoding=utf8 username: root #改成你的用户名 password: #改成你的密码   将rescouces目录下的config.conf后缀文件里的192.168.41.102全局替换成tars平台ip,并在启动参数中添加-Dconfig=该文件的路径\n run TarsHmilyAccountApplication.java\n  启动hmily-demo-tars-springboot-inventory 参考上述。 启动hmily-demo-tars-springboot-order 参考上述。 访问：http://127.0.0.1:18087/swagger-ui.html。 ","date":-62135596800,"description":"tars快速体验","dir":"projects/hmily/quick-start-tars/","fuzzywordcount":900,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"7c0bdd9ecb5f9441af37ad4e00a626fabb078ed9","permalink":"/zh/projects/hmily/quick-start-tars/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/zh/projects/hmily/quick-start-tars/","summary":"环境准备 JDK 1.8+ Maven 3.2.x Git Zookeeper 代码拉取 \u0026gt; git clone https://github.com/dromara/hmily.git \u0026gt; cd hmily \u0026gt; mvn -DskipTests clean install -U 执行demo 模块的sql语句。 sql语句 建立tars节点 根据此文在当前tars平台建立","tags":null,"title":"tars快速体验","type":"projects","url":"/zh/projects/hmily/quick-start-tars/","wordcount":848},{"author":null,"categories":null,"content":" Tars用户指南  引入jar包\n 引入hmily配置\n 在需要进行Hmily分布式事务的自动生成的Servant接口方法上加上 @Hmily 标识。\n 在具体的实现方法上（服务提供端），加上@HmilyTCC or HmilyTAC 注解\n  引入依赖 Spring-Namespace\n 引入依赖\n  \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-tars\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   在xml中进行如下配置\n\u0026amp;lt;!--配置扫码hmily框架的包--\u0026amp;gt; \u0026amp;lt;context:component-scan base-package=\u0026amp;quot;org.dromara.hmily.*\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;!--设置开启aspectj-autoproxy--\u0026amp;gt; \u0026amp;lt;aop:aspectj-autoproxy expose-proxy=\u0026amp;quot;true\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;!--配置Hmily启动的bean参数--\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;hmilyApplicationContextAware\u0026amp;quot; class=\u0026amp;quot;org.dromara.hmily.spring.HmilyApplicationContextAware\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;hmilyCommunicatorBeanPostProcessor\u0026amp;quot; class=\u0026amp;quot;org.dromara.hmily.tars.spring.TarsHmilyCommunicatorBeanPostProcessor\u0026amp;quot;/\u0026amp;gt; \u0026amp;lt;bean id=\u0026amp;quot;tarsHmilyStartupBean\u0026amp;quot; class=\u0026amp;quot;org.dromara.hmily.tars.spring.TarsHmilyFilterStartupBean\u0026amp;quot;/\u0026amp;gt;  Spring-Boot\n 引入依赖\nxml \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hmily-spring-boot-starter-tars\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;{last.version}\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;    引入Hmily配置  在项目的 resource 新建文件名为: hmily.ym 配置文件。\n 具体的参数配置可以参考配置详解,本地配置模式, zookeeper配置模式, nacos配置模式,apollo配置模式\n  实现接口上添加注解 上述我们已经完成了集成，下面将讲述具体的实现。\nTCC模式  对@Hmily 标识的接口方法的具体实现上，加上@HmilyTCC(confirmMethod = \u0026amp;quot;confirm\u0026amp;quot;, cancelMethod = \u0026amp;quot;cancel\u0026amp;quot;)\n confirmMethod : 确认方法名称，该方法参数列表与返回类型应与标识方法一致。\n cancelMethod : 回滚方法名称，该方法参数列表与返回类型应与标识方法一致。\n TCC模式应该保证 confirm 和 cancel 方法的幂等性，用户需要自行去开发这个2个方法，所有的事务的确认与回滚，完全由用户决定。Hmily框架只是负责来进行调用\n  public class HelloServiceImpl implements HelloService { @HmilyTCC(confirmMethod = \u0026amp;quot;sayConfrim\u0026amp;quot;, cancelMethod = \u0026amp;quot;sayCancel\u0026amp;quot;) public void say(String hello) { System.out.println(\u0026amp;quot;hello world\u0026amp;quot;); } public void sayConfrim(String hello) { System.out.println(\u0026amp;quot; confirm hello world\u0026amp;quot;); } public void sayCancel(String hello) { System.out.println(\u0026amp;quot; cancel hello world\u0026amp;quot;); } }  重要注意事项 异常  try, confirm, cancel 方法的所有异常不要自行catch 任何异常都应该抛出给 Hmily框架处理。  ","date":-62135596800,"description":"tars用户指南","dir":"projects/hmily/user-tars/","fuzzywordcount":700,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"c62d46e0482b5422faa5352fb63f45e326c49a99","permalink":"/zh/projects/hmily/user-tars/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/zh/projects/hmily/user-tars/","summary":"Tars用户指南 引入jar包 引入hmily配置 在需要进行Hmily分布式事务的自动生成的Servant接口方法上加上 @Hmily 标识。 在具体的实现方法","tags":null,"title":"tars用户指南","type":"projects","url":"/zh/projects/hmily/user-tars/","wordcount":623},{"author":null,"categories":null,"content":" raincat-admin 启动教程  启动前提：分布式事务项目已经部署并且运行起来，用户根据自己的RPC框架进行使用 dubbo 用户 springcloud 用户  启动方式一：自己打包进行部署。  首先用户使用的JDK必须是1.8+ 本地安装了git ,maven ，执行以下命令\ngit clone https://github.com/yu199195/Raincat.git maven clean install  使用你的开发工具打开项目，比如idea Eclipse\n  修改application.yml server: port: 8888 context-path: /admin spring: application: name: raincat-admin profiles: active: db tx: admin : userName : admin password : admin redis: hostName: localhost port : 6379 #password: cluster : false # nodes: 127.0.0.1:70001;127.0.1:7002 # redirects: 20   userName，password 是你登录的用户名与密码。\n reids配置为你的txManager的redis配置。\n spring.profiles.active 是你激活的方式，意思就是你采用什么方式来存储日志的，就激活什么方式，然后修改对应的yml。比如这里使用的db那么我们找到application-db.yml\n  recover: application: list : alipay-service,wechat-service,pay-service serializer : support: kryo retry : max: 10 db: driver : com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/tx?useUnicode=true\u0026amp;amp;amp;characterEncoding=utf8 username: root password: 123456   application.list是指你微服务的applicationName，用逗号分隔。\n serializer : 事务日志的序列化方式\n retry.max ： 最大重试次数。\n  修改index.html \u0026amp;lt;!--href 修改成你的ip 端口--\u0026amp;gt; \u0026amp;lt;a id=\u0026amp;quot;serverIpAddress\u0026amp;quot; style=\u0026amp;quot;display: none\u0026amp;quot; href=\u0026amp;quot;http://192.168.1.132:8888/admin\u0026amp;quot;\u0026amp;gt;  运行 AdminApplication 中的main方法。 在浏览器访问 http://ip:port/admin ,输入用户名，密码登录。 启动方式二：从maven中心仓库获取adminjar包 . \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.dromara\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;raincat-admin\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;2.0.0-RELEASE\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt;   创建config文件夹，创建application.yml等，然后修改启动。  ","date":-62135596800,"description":"启动raincat-admin","dir":"projects/raincat/admin-starter/","fuzzywordcount":600,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"08bd2f1f6c41be6f4cee3a2ada121fb962734c70","permalink":"/zh/projects/raincat/admin-starter/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/zh/projects/raincat/admin-starter/","summary":"raincat-admin 启动教程 启动前提：分布式事务项目已经部署并且运行起来，用户根据自己的RPC框架进行使用 dubbo 用户 springcloud 用户 启动方式一：自己打包进行部署。 首先用户使","tags":null,"title":"启动raincat-admin","type":"projects","url":"/zh/projects/raincat/admin-starter/","wordcount":538},{"author":null,"categories":null,"content":" 启动raincat-manager 方式一：自己拉取代码编译：https://github.com/yu199195/Raincat  修改application.yml 中的redis配置  transactionWaitMaxTime: 500 redisSaveMaxTime: 3000 tx: manager: netty : port: 9998 serialize: kryo maxConnection: 100 maxThreads : 16 delayTime : 5 heartTime : 20 redis : cluster : false hostName : 192.168.1.91 port: 6379 password : foobaredbbexONE123   transactionWaitMaxTime 事务最大等待时间\n redisSaveMaxTime redis存储最大等待时间\n tx:manager:netty 解释\n port 是只netty长连接的netty端口（可以自行修改）\n serialize netty自定义序列化协议（推荐使用kroy这个要与客户端的序列化协议对应）\n maxConnection 最大长连接数量\n maxThreads netty work线程数量\n heartTime 心跳时间（单位秒）\n   启动方式二：直接从maven中央仓库获取raincat-manager jar包。  建立config目录，新增applicationyml配置文件并修改。覆盖jar包里面的applicationyml。具体的请参考springboot配置文件读取顺序。  ","date":-62135596800,"description":"启动raincat-manager","dir":"projects/raincat/raincat-manager-starter/","fuzzywordcount":400,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"bbdcdac27d74dd98b5f039c32e1939852bf324c4","permalink":"/zh/projects/raincat/raincat-manager-starter/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/zh/projects/raincat/raincat-manager-starter/","summary":"启动raincat-manager 方式一：自己拉取代码编译：https://github.com/yu199195/Raincat 修改app","tags":null,"title":"启动raincat-manager","type":"projects","url":"/zh/projects/raincat/raincat-manager-starter/","wordcount":371},{"author":null,"categories":null,"content":" 团队成员（排名不分先后）    名字 github 角色 所在公司     肖宇 yu199195 VP 京东   张永伦 tuohai666 committer 京东   赵俊 cherrylzhao committer 联通   陈斌 prFor committer 某创业公司   李浪 cysy-lli committer 携程   汤煜冬 tydhot committer perfma    ","date":-62135596800,"description":"团队介绍","dir":"projects/hmily/team/","fuzzywordcount":100,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"8d3d94758b890d2b1ca2b21f24ba04af40cf4fa8","permalink":"/zh/projects/hmily/team/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/zh/projects/hmily/team/","summary":"团队成员（排名不分先后） 名字 github 角色 所在公司 肖宇 yu199195 VP 京东 张永伦 tuohai666 committer 京东 赵俊 cherrylzhao committer 联通 陈斌 prFor committer 某创业公司 李浪 cysy-lli committer 携程 汤煜冬 tydhot committer perfma","tags":null,"title":"团队介绍","type":"projects","url":"/zh/projects/hmily/team/","wordcount":61},{"author":null,"categories":null,"content":" 术语  发起者：全局事务的发起者，在一个请求链路资源方法里面，最先需要对分布式资源进行事务处理的地方，在Hmily框架里面 可以表示为：一个请求最先遇到 @HmilyTCC or @HmilyTAC 注解的方法，该所属方法应用被称为发起者。\n 参与者：分布式服务或者资源，需要与其他服务一起参与到一次分布式事务场景下。在Hmily框架里面，表现为一个RPC框架的接口被加上@Hmily注解。\n 协调者：用来协调分布式事务到底是commit，还是 rollback的角色，他可以是远程的，也可以是本地的，可以是中心化的，也可以是去中心化的。在Hmily框架里面的协调者是本地去中心化的角色。\n TCC ：Try, Confirm, Cancel 3个阶段的简称。\n TAC ：Try Auto Cancel的简称。Try阶段预留资源后，会由框架自动生成反向的操作资源的行为。\n  ","date":-62135596800,"description":"术语","dir":"projects/hmily/term/","fuzzywordcount":400,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"c8cce5e1bdfb921bdfee3259c940cb096da7bc74","permalink":"/zh/projects/hmily/term/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/zh/projects/hmily/term/","summary":"术语 发起者：全局事务的发起者，在一个请求链路资源方法里面，最先需要对分布式资源进行事务处理的地方，在Hmily框架里面 可以表示为：一个请求最","tags":null,"title":"术语","type":"projects","url":"/zh/projects/hmily/term/","wordcount":327},{"author":null,"categories":null,"content":" 我引用了jar包，发现启动不了，报错怎么办？  答：这种需要你自己去定位问题，查看是否按照文档来进行配置，环境是否正确，是否有依赖冲突问题，实在解决不了，可以在github上提供issue， 我们团队会进行技术支持。  微服务异常，事务没回滚怎么办？  答：首先，你可以去查看日志记录，如果日志记录存在，那在你配置的调度时间之后，会执行回滚。  编译源码，发现缺少get，set方法怎么办？  答：源码使用了lombok，你可能需要在你的开发工具，安装对应的插件。（没有set get方法并不影响运行的）。  ","date":-62135596800,"description":"问题描述","dir":"projects/hmily/faq/","fuzzywordcount":300,"kind":"page","lang":"zh","lastmod":1624504597,"objectID":"d22162d388a3fc2e1d5a17891f00319edb02e0f1","permalink":"/zh/projects/hmily/faq/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/zh/projects/hmily/faq/","summary":"我引用了jar包，发现启动不了，报错怎么办？ 答：这种需要你自己去定位问题，查看是否按照文档来进行配置，环境是否正确，是否有依赖冲突问题，实在","tags":null,"title":"问题","type":"projects","url":"/zh/projects/hmily/faq/","wordcount":241}]