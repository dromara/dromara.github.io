<!doctype html><html><head><title>深度剖析一站式分布式事务方案 Seata-Server · SOFAStack</title><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><meta name=viewport content="width=device-width,minimum-scale=1"><meta name=description content="SOFAStack is a Scalable Open Financial Architecture for building cloud native applications"><meta name=generator content="Hugo 0.55.5"><link rel="shortcut icon" href=https://gw.alipayobjects.com/os/q/cms/images/jqu9346l/4ba95631-2489-4885-881f-bc7f8d787d5e_w64_h61.png type=image/png><link href=https://unpkg.com/purecss@1.0.0/build/base-min.css rel=stylesheet><link href=/css/main.css rel=stylesheet><link href=/css/zoom-image.css rel=stylesheet><script src=/js/iconfont.js></script><script src=/js/highlight.pack.js></script><script>hljs.initHighlightingOnLoad();</script><script>window.SITE_LANGUAGE="zh"</script><script src=/js/app.js></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');ga('create','UA-142131411-1','auto');ga('send','pageview');}</script></head><body><header class=ss-header><nav class=navbar role=navigation aria-label="main navigation"><div class=navbar-brand><a class=logo-link href=/><img class=logo src=/img/logo.png></a><div class=-show-mobile><a id=mobile-menu-icon><svg class="icon" aria-hidden="true"><use xlink:href="#icon-menu"/></svg></a><nav id=mobile-menu><div id=js-menu-search-mobile class=navbar-search-mobile><input class=input placeholder=请输入要搜索的关键词><svg class="icon" aria-hidden="true"><use xlink:href="#icon-search"/></svg></div><a href=/projects/><span>项目</span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-ARROW"/></svg></a>
<a href=/guides/><span>指南</span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-ARROW"/></svg></a>
<a href=/blog/><span>博客</span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-ARROW"/></svg></a>
<a href=/activities/><span>活动</span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-ARROW"/></svg></a>
<a href=/community/><span>社区</span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-ARROW"/></svg></a>
<a href=/awesome/><span>Awesome SOFA</span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-ARROW"/></svg></a></nav></div></div><div class="navbar-menu -hidden-mobile"><div class=navbar-start><a class=navbar-item href=/projects/>项目</a>
<a class=navbar-item href=/guides/>指南</a>
<a class=navbar-item href=/blog/>博客</a>
<a class=navbar-item href=/activities/>活动</a>
<a class=navbar-item href=/community/>社区</a>
<a class=navbar-item href=/awesome/>Awesome SOFA</a></div><div class=navbar-end><div class=navbar-item><div id=js-menu-search class=navbar-search><input class=input placeholder=请输入要搜索的关键词><svg class="icon" aria-hidden="true"><use xlink:href="#icon-search"/></svg></div></div><div class=navbar-item></div></div></div></nav></header><div class=ss-layout-container><main class="ss-layout-main -card"><div class=ss-meta><h1 class=title>深度剖析一站式分布式事务方案 Seata-Server</h1><div class=meta>2019-04-09 ·
李钊 ·
<span class=tags><a class=tag href=/tags/seata/ rel=tag>#Seata</a></span></div></div><article class=typo><p><img src=https://cdn.nlark.com/yuque/0/2019/png/226702/1554783030924-cf469fe5-f8ca-4b27-b250-4ef0a26e7c50.png alt=Seata></p><p>本文作者李钊，公众号「咖啡拿铁」作者，分布式事务 Seata 社区 Contributor。</p><h2 id=1-关于-seata>1.关于 Seata</h2><p>在前不久，我写了一篇关于分布式事务中间件 Fescar 的解析，没过几天 Fescar 团队对其进行了品牌升级，取名为 Seata(Simpe Extensible Autonomous Transcaction Architecture)，而以前的 Fescar 的英文全称为 Fast &amp; EaSy Commit And Rollback。可以看见 Fescar 从名字上来看更加局限于 Commit 和 Rollback，而新的品牌名字 Seata 旨在打造一套一站式分布式事务解决方案。更换名字之后，我对其未来的发展更有信心。</p><p>这里先大概回忆一下 Seata 的整个过程模型：</p><p><img src=https://cdn.nlark.com/yuque/0/2019/png/226702/1554712795916-70b699d0-3817-4483-8767-6ece98e1b9fe.png alt="Seata 过程模型"></p><ul><li>TM：事务的发起者。用来告诉 TC，全局事务的开始，提交，回滚。</li><li>RM：具体的事务资源，每一个 RM 都会作为一个分支事务注册在 TC。</li><li>TC 事务的协调者。也可以看做是 Fescar-server，用于接收我们的事务的注册，提交和回滚。</li></ul><p>在之前的文章中对整个角色有个大体的介绍，在这篇文章中我将重点介绍其中的核心角色 TC，也就是事务协调器。</p><h2 id=2-transaction-coordinator>2.Transaction Coordinator</h2><p>为什么之前一直强调 TC 是核心呢？那因为 TC 这个角色就好像上帝一样，管控着芸芸众生的 RM 和 TM。如果 TC 一旦不好使，那么 RM 和 TM 一旦出现小问题，那必定会乱的一塌糊涂。所以要想了解 Seata，那么必须要了解他的 TC。</p><p>那么一个优秀的事务协调者应该具备哪些能力呢？我觉得应该有以下几个：</p><ul><li>正确的协调：能正确的协调 RM 和 TM 接下来应该做什么，做错了应该怎么办，做对了应该怎么办。</li><li>高可用：事务协调器在分布式事务中很重要，如果不能保证高可用，那么他也没有存在的必要了。</li><li>高性能：事务协调器的性能一定要高，如果事务协调器性能有瓶颈，那么他所管理的 RM 和 TM 会经常遇到超时，从而引起回滚频繁。</li><li>高扩展性：这个特点是属于代码层面的，如果是一个优秀的框架，那么需要给使用方很多自定义扩展，比如服务注册/发现，读取配置等等。</li></ul><p>下面我也将逐步阐述 Seata 是如何做到上面四点。</p><h3 id=2-1-seata-server-的设计>2.1 Seata-Server 的设计</h3><p><img src=https://cdn.nlark.com/yuque/0/2019/png/226702/1554712795921-d0f878a4-1f47-4b3d-b060-daa15fbb9da4.png alt="Seata-Server 整体模块图"></p><p>Seata-Server 整体的模块图如上所示：</p><ul><li>Coordinator Core：最下面的模块是事务协调器核心代码，主要用来处理事务协调的逻辑，如是否 Commit、Rollback 等协调活动。</li><li>Store：存储模块，用来将我们的数据持久化，防止重启或者宕机数据丢失。</li><li>Discover：服务注册/发现模块，用于将 Server 地址暴露给 Client。</li><li>Config：用来存储和查找服务端的配置。</li><li>Lock：锁模块，用于给 Seata 提供全局锁的功能。</li><li>Rpc：用于和其他端通信。</li><li>HA-Cluster：高可用集群，目前还没开源。为 Seata 提供可靠的高可用功能。</li></ul><h3 id=2-2-discover>2.2 Discover</h3><p>首先来讲讲比较基础的 Discover 模块，又称服务注册/发现模块。我们将 Seata-Server 启动之后，需要将自己的地址暴露给其他使用者，那么就需要这个模块帮忙。</p><p><img src=https://cdn.nlark.com/yuque/0/2019/png/226702/1554712795942-1f83e0b4-110d-41eb-bd57-c4cfcaf6d783.png alt="核心接口 RegistryService"></p><p>这个模块有个核心接口 RegistryService，如上图所示：</p><ul><li>register：服务端使用，进行服务注册。</li><li>unregister：服务端使用，一般在 JVM 关闭钩子，ShutdownHook 中调用。</li><li>subscribe：客户端使用，注册监听事件，用来监听地址的变化。</li><li>unsubscribe：客户端使用，取消注册监听事件。</li><li>lookup：客户端使用，根据 Key 查找服务地址列表。</li><li>close：都可以使用，用于关闭 Register 资源。</li></ul><p>如果需要添加自己定义的服务注册/发现，那么实现这个接口即可。截止目前在社区的不断开发推动下，已经有四种服务注册/发现，分别是 redis、zk、nacos、eruka。下面简单介绍下 Nacos 的实现：</p><h4 id=2-2-1-register-接口>2.2.1 register 接口</h4><p><img src=https://cdn.nlark.com/yuque/0/2019/png/226702/1554712795942-8c36fa4f-61ac-4ca9-80a1-dd35c09c7cee.png alt="register 接口"></p><p>step1：校验地址是否合法；</p><p>step2：获取 Nacos 的 Name 实例，然后将地址注册到当前 Cluster 名称上面。</p><p>unregister 接口类似，这里不做详解。</p><h4 id=2-2-2-lookup-接口>2.2.2 lookup 接口</h4><p><img src=https://cdn.nlark.com/yuque/0/2019/png/226702/1554712795966-5ce5a7f3-9f86-4c64-9458-8a152a7fd442.png alt="lookup 接口"></p><p>step1：获取当前 clusterName 名字；</p><p>step2：判断当前 Cluster 是否已经获取过了，如果获取过就从 Map 中取；</p><p>step3：从 Nacos 拿到地址数据，将其转换成我们所需要的；</p><p>step4：将我们事件变动的 Listener 注册到 Nacos。</p><h4 id=2-2-3-subscribe-接口>2.2.3 subscribe 接口</h4><p><img src=https://cdn.nlark.com/yuque/0/2019/png/226702/1554712795900-b870f451-d671-4a17-a6cd-60ad824acc22.png alt="subscribe 接口"></p><p>这个接口比较简单，具体分两步：</p><p>step1：将 Clstuer 和 Listener 添加进 Map 中；</p><p>step2：向 Nacos 注册。</p><h3 id=2-3-config>2.3 Config</h3><p>配置模块也是一个比较基础，比较简单的模块。我们需要配置一些常用的参数比如：Netty 的 Select 线程数量，Work 线程数量，Session 允许最大为多少等等，当然这些参数在 Seata 中都有自己的默认设置。</p><p>同样的在 Seata 中也提供了一个接口 Configuration，用来自定义我们需要的获取配置的地方：</p><p><img src=https://cdn.nlark.com/yuque/0/2019/png/226702/1554712795936-03cb0753-2e0c-473c-b363-911d79f4e692.png alt=Config></p><ul><li>getInt/Long/Boolean/Config()：通过 DataId 来获取对应的值。</li><li>putConfig：用于添加配置。</li><li>removeConfig：删除一个配置。</li><li>add/remove/get ConfigListener：添加/删除/获取 配置监听器，一般用来监听配置的变更。</li></ul><p>目前为止有四种方式获取 Config：File（文件获取）、Nacos、Apollo、ZK。在 Seata 中首先需要配置 registry.conf，来配置 conf 的类型。实现 conf 比较简单这里就不深入分析。</p><h3 id=2-4-store>2.4 Store</h3><p>存储层的实现对于 Seata 是否高性能，是否可靠非常关键。</p><p>如果存储层没有实现好，那么如果发生宕机，在 TC 中正在进行分布式事务处理的数据将会被丢失。既然使用了分布式事务，那么其肯定不能容忍丢失。如果存储层实现好了，但是其性能有很大问题，RM 可能会发生频繁回滚那么其完全无法应对高并发的场景。</p><p>在 Seata 中默认提供了文件方式的存储，下面定义存储的数据为 Session，而 TM 创造的全局事务数据叫 GloabSession，RM 创造的分支事务叫 BranchSession，一个 GloabSession 可以拥有多个 BranchSession。我们的目的就是要将这么多 Session 存储下来。</p><p>在 FileTransactionStoreManager#writeSession 代码中：</p><p><img src=https://cdn.nlark.com/yuque/0/2019/png/226702/1554712795941-0f1088d1-5c37-4f99-a21a-446bcd329bb6.png alt=Store></p><p>上面的代码主要分为下面几步：</p><p>step1：生成一个 TransactionWriteFuture。</p><p>step2：将这个 futureRequest 丢进一个 LinkedBlockingQueue 中。为什么需要将所有数据都丢进队列中呢？当然这里其实也可以用锁来实现，在另外一个阿里开源的 RocketMQ 中使用的锁。不论是队列还是锁，他们的目的是为了保证单线程写，这又是为什么呢？有人会解释说，需要保证顺序写，这样速度就很快，这个理解是错误的，我们的 FileChannel 其实是线程安全的，已经能保证顺序写了。保证单线程写其实是为了让这个写逻辑都是单线程的，因为可能有些文件写满或者记录写数据位置等等逻辑，当然这些逻辑都可以主动加锁去做，但是为了实现简单方便，直接再整个写逻辑加锁是最为合适的。</p><p>step3：调用 future.get，等待该条数据写逻辑完成通知。</p><p>我们将数据提交到队列之后，接下来需要对其进行消费，代码如下：</p><p><img src=https://cdn.nlark.com/yuque/0/2019/png/226702/1554712795923-50ad4e8a-41f3-4b03-8df6-fcc4173dcf46.png alt="调用 future.get"></p><p>这里将一个 WriteDataFileRunnable() 提交进线程池，这个 Runnable 的 run() 方法如下：</p><p><img src=https://cdn.nlark.com/yuque/0/2019/png/226702/1554712795932-a480fa94-ed74-48a9-a2d5-a8e3d31e4025.png alt="Runnable 的 run() 方法"></p><p>分为下面几步：</p><p>step1：判断是否停止，如果 stopping 为 true 则返回 null。</p><p>step2：从队列中获取数据。</p><p>step3：判断 future 是否已经超时了，如果超时，则设置结果为 false，此时我们生产者 get() 方法会接触阻塞。</p><p>step4：将数据写进文件，此时数据还在 pageCache 层并没有刷新到磁盘，如果写成功然后根据条件判断是否进行刷盘操作。</p><p>step5：当写入数量到达一定的时候，或者写入时间到达一定的时候，需要将当前的文件保存为历史文件，删除以前的历史文件，然后创建新的文件。这一步是为了防止文件无限增长，大量无效数据浪费磁盘资源。</p><p>在 writeDataFile 中有如下代码：</p><p><img src=https://cdn.nlark.com/yuque/0/2019/png/226702/1554712795910-748af023-d2c6-44b4-b349-2a6b78c81588.png alt=writeDataFile></p><p>step1：首先获取 ByteBuffer，如果超出最大循环 BufferSize 就直接创建一个新的，否则就使用缓存的 Buffer。这一步可以很大的减少 GC。</p><p>step2：然后将数据添加进入 ByteBuffer。</p><p>step3：最后将 ByteBuffer 写入 fileChannel，这里会重试三次。此时的数据还在 pageCache 层，受两方面的影响，OS 有自己的刷新策略，但是这个业务程序不能控制，为了防止宕机等事件出现造成大量数据丢失，所以就需要业务自己控制 flush。下面是 flush 的代码：</p><p><img src=https://cdn.nlark.com/yuque/0/2019/png/226702/1554712795934-6c9d38e1-e21e-4ba7-b58b-d2d6a3e31238.png alt="flush 的代码"></p><p>这里 flush 的条件写入一定数量或者写的时间超过一定时间，这样也会有个小问题如果是停电，那么 pageCache 中有可能还有数据并没有被刷盘，会导致少量的数据丢失。目前还不支持同步模式，也就是每条数据都需要做刷盘操作，这样可以保证每条消息都落盘，但是性能也会受到极大的影响，当然后续会不断的演进支持。</p><p>Store 核心流程主要是上面几个方法，当然还有一些比如 Session 重建等，这些比较简单，读者可以自行阅读。</p><h3 id=2-5-lock>2.5 Lock</h3><p>大家知道数据库实现隔离级别主要是通过锁来实现的，同样的再分布式事务框架 Seata 中要实现隔离级别也需要通过锁。一般在数据库中数据库的隔离级别一共有四种：读未提交、读已提交、可重复读、串行化。在 Seata 中可以保证写的互斥，而读的隔离级别一般是未提交，但是提供了达到读已提交隔离的手段。</p><p>Lock 模块也就是 Seata 实现隔离级别的核心模块。在 Lock 模块中提供了一个接口用于管理锁：</p><p><img src=https://cdn.nlark.com/yuque/0/2019/png/226702/1554712796093-777fef80-b8b2-42b7-8cc3-2848b6d09a78.png alt="Lock 模块"></p><p>其中有三个方法：</p><ul><li>acquireLock：用于对 BranchSession 加锁，这里虽然是传的分支事务 Session，实际上是对分支事务的资源加锁，成功返回 true。</li><li>isLockable：根据事务 ID，资源 ID，锁住的 Key 来查询是否已经加锁。</li><li>cleanAllLocks：清除所有的锁。</li></ul><p>对于锁我们可以在本地实现，也可以通过 redis 或者 mysql 来帮助我们实现。官方默认提供了本地全局锁的实现：</p><p><img src=https://cdn.nlark.com/yuque/0/2019/png/226702/1554712795923-3d584904-2eb1-469d-a42e-a13fcb252f36.png alt=本地全局锁的实现></p><p>在本地锁的实现中有两个常量需要关注：</p><ul><li>BUCKET_PER_TABLE：用来定义每个 table 有多少个 bucket，目的是为了后续对同一个表加锁的时候减少竞争。</li><li>LOCK_MAP：这个 Map 从定义上来看非常复杂，里里外外套了很多层 Map，这里用个表格具体说明一下：
| 层数 | key | value |
| &mdash; | &mdash; | &mdash; |
| 1-LOCK_MAP | resourceId（jdbcUrl） | dbLockMap |
| 2- dbLockMap | tableName （表名） | tableLockMap |
| 3- tableLockMap | PK.hashcode%Bucket （主键值的 hashcode%bucket） | bucketLockMap |
| 4- bucketLockMap | PK | trascationId |</li></ul><p>可以看见实际上的加锁在 bucketLockMap 这个 Map 中，这里具体的加锁方法比较简单就不作详细阐述，主要是逐步的找到 bucketLockMap ，然后将当前 trascationId 塞进去，如果这个主键当前有 TranscationId，那么比较是否是自己，如果不是则加锁失败。</p><h3 id=2-6-rpc>2.6 RPC</h3><p>保证 Seata 高性能的关键之一也是使用了 Netty 作为 RPC 框架，采用默认配置的线程模型如下图所示：</p><p><img src=https://cdn.nlark.com/yuque/0/2019/png/226702/1554712795955-0bbdffe0-f9ab-4a97-bea4-56c2caf86675.png alt=线程模型></p><p>如果采用默认的基本配置那么会有一个 Acceptor 线程用于处理客户端的链接，会有 cpu x 2 数量的 NIO-Thread，再这个线程中不会做业务太重的事情，只会做一些速度比较快的事情，比如编解码，心跳事件和TM注册。一些比较费时间的业务操作将会交给业务线程池，默认情况下业务线程池配置为最小线程为 100，最大为 500。</p><p>这里需要提一下的是 Seata 的心跳机制，这里是使用 Netty 的 IdleStateHandler 完成的，如下：</p><p><img src=https://cdn.nlark.com/yuque/0/2019/png/226702/1554712795931-dcbb5789-2e24-467a-90fb-ee4edb2eed4a.png alt="Seata 的心跳机制"></p><p>在 Sever 端对于写没有设置最大空闲时间，对于读设置了最大空闲时间，默认为 15s，如果超过 15s 则会将链接断开，关闭资源。</p><p><img src=https://cdn.nlark.com/yuque/0/2019/png/226702/1554712795936-5b62671d-8c75-4bf9-84d6-d68673aa590d.png alt="Seata 的心跳机制"></p><p>step1：判断是否是读空闲的检测事件；</p><p>step2：如果是则断开链接，关闭资源。</p><h3 id=2-7-ha-cluster>2.7 HA-Cluster</h3><p>目前官方没有公布 HA-Cluster，但是通过一些其他中间件和官方的一些透露，可以将 HA-Cluster 用如下方式设计：</p><p><img src=https://cdn.nlark.com/yuque/0/2019/png/226702/1554712795934-98520eb5-afb3-45f1-8153-2adedf45124a.png alt=HA-Cluster></p><p>具体的流程如下：</p><p>step1：客户端发布信息的时候根据 TranscationId 保证同一个 Transcation 是在同一个 Master 上，通过多个 Master 水平扩展，提供并发处理性能。</p><p>step2：在 Server 端中一个 Master 有多个 Slave，Master 中的数据近实时同步到 Slave上，保证当 Master 宕机的时候，还能有其他 Slave 顶上来可以用。</p><p>当然上述一切都是猜测，具体的设计实现还得等 0.5 版本之后。目前有一个 Go 版本的 Seata-Server 也捐赠给了 Seata (还在流程中)，其通过 Raft 实现副本一致性，其他细节不是太清楚。</p><h3 id=2-8-metrics-tracing>2.8 Metrics &amp; Tracing</h3><p>这个模块也是一个没有具体公布实现的模块，当然有可能会提供插件口，让其他第三方 metric 接入进来。另外最近 Apache SkyWalking 正在和 Seata 小组商讨如何接入进来。</p><h2 id=3-coordinator-core>3.Coordinator Core</h2><p>上面我们讲了很多 Server 基础模块，想必大家对 Seata 的实现已经有个大概，接下来我会讲解事务协调器具体逻辑是如何实现的，让大家更加了解 Seata 的实现内幕。</p><h2 id=3-1-启动流程>3.1 启动流程</h2><p>启动方法在 Server 类有个 main 方法，定义了我们启动流程：</p><p><img src=https://cdn.nlark.com/yuque/0/2019/png/226702/1554712795941-44550135-acd8-492c-9240-e88eeb7bce63.png alt=启动流程></p><p>step1：创建一个 RpcServer，再这个里面包含了我们网络的操作，用 Netty 实现了服务端。</p><p>step2：解析端口号和文件地址。</p><p>step3：初始化 SessionHoler，其中最重要的重要就是重我们 dataDir 这个文件夹中恢复我们的数据，重建我们的Session。</p><p>step4：创建一个CoorDinator,这个也是我们事务协调器的逻辑核心代码，然后将其初始化，其内部初始化的逻辑会创建四个定时任务：</p><ul><li>retryRollbacking：重试 rollback 定时任务，用于将那些失败的 rollback 进行重试的，每隔 5ms 执行一次。</li><li>retryCommitting：重试 commit 定时任务，用于将那些失败的commit 进行重试的，每隔 5ms 执行一次。</li><li>asyncCommitting：异步 commit 定时任务，用于执行异步的commit，每隔 10ms 一次。</li><li>timeoutCheck：超时定时任务检测，用于检测超时的任务，然后执行超时的逻辑，每隔 2ms 执行一次。</li></ul><p>step5： 初始化 UUIDGenerator 这个也是我们生成各种 ID(transcationId,branchId) 的基本类。</p><p>step6：将本地 IP 和监听端口设置到 XID 中，初始化 rpcServer 等待客户端的连接。</p><p>启动流程比较简单，下面我会介绍分布式事务框架中的常见的一些业务逻辑 Seata 是如何处理的。</p><h3 id=3-2-begin-开启全局事务>3.2 Begin - 开启全局事务</h3><p>一次分布式事务的起始点一定是开启全局事务，首先我们看看全局事务 Seata 是如何实现的：</p><p><img src=https://cdn.nlark.com/yuque/0/2019/png/226702/1554712795957-945d679c-d333-409e-a0e9-ec65d6c31c38.png alt=开启全局事务></p><p>step1： 根据应用 ID，事务分组，名字，超时时间创建一个 GloabSession，这个再前面也提到过他和 branchSession 分别是什么。</p><p>step2：对其添加一个 RootSessionManager 用于监听一些事件，这里要说一下目前在 Seata 里面有四种类型的 Listener (这里要说明的是所有的 sessionManager 都实现了 SessionLifecycleListener)：</p><ul><li>ROOT_SESSION_MANAGER：最全，最大的，拥有所有的 Session。</li><li>ASYNC_COMMITTING_SESSION_MANAGER：用于管理需要做异步 commit 的 Session。</li><li>RETRY_COMMITTING_SESSION_MANAGER：用于管理重试 commit 的 Session。</li><li>RETRY_ROLLBACKING_SESSION_MANAGER：用于管理重试回滚的 Session。
由于这里是开启事务，其他 SessionManager 不需要关注，我们只添加 RootSessionManager 即可。</li></ul><p>step3：开启 Globalsession：</p><p><img src=https://cdn.nlark.com/yuque/0/2019/png/226702/1554712795950-4ffc9045-28ee-489a-8a70-2774d9c514a7.png alt="开启 Globalsession"></p><p>这一步会把状态变为 Begin，记录开始时间,并且调用 RootSessionManager的onBegin 监听方法，将 Session 保存到 Map 并写入到我们的文件。</p><p>step4：最后返回 XID，这个 XID 是由 ip+port+transactionId 组成的，非常重要，当 TM 申请到之后需要将这个 ID 传到 RM 中，RM 通过 XID 来决定到底应该访问哪一台 Server。</p><h3 id=3-3-branchregister-分支事务注册>3.3 BranchRegister - 分支事务注册</h3><p>当全局事务在 TM 开启之后，RM 的分支事务也需要注册到全局事务之上，这里看看是如何处理的：</p><p><img src=https://cdn.nlark.com/yuque/0/2019/png/226702/1554712795959-81b1f164-be0c-4439-91e5-c78bda839b3a.png alt=分支事务注册></p><p>step1：通过 transactionId 获取并校验全局事务是否是开启状态。</p><p>step2：创建一个新的分支事务，也就是 BranchSession。</p><p>step3：对分支事务进行加全局锁，这里的逻辑就是使用锁模块的逻辑。</p><p>step4：添加 branchSession，主要是将其添加到 globalSession 对象中，并写入到我们的文件中。</p><p>step5：返回 branchId，这个 ID 也很重要，我们后续需要用它来回滚我们的事务，或者对我们分支事务状态更新。</p><p>分支事务注册之后，还需要汇报分支事务的后续状态到底是成功还是失败，在 Server 目前只是简单的做一下保存记录，汇报的目的是，就算这个分支事务失败，如果 TM 还是执意要提交全局事务，那么再遍历提交分支事务的时候，这个失败的分支事务就不需要提交。</p><h3 id=3-4-globalcommit-全局提交>3.4 GlobalCommit - 全局提交</h3><p>当分支事务执行完成之后，就轮到 TM-事务管理器来决定是提交还是回滚，如果是提交，那么就会走到下面的逻辑：</p><p><img src=https://cdn.nlark.com/yuque/0/2019/png/226702/1554712795948-66403baf-5745-4c47-afb8-d3fb4c5e925f.png alt=全局提交></p><p>step1：首先找到 globalSession。如果他为 Null 证明已经被 commit 过了，那么直接幂等操作，返回成功。</p><p>step2：关闭  GloabSession 防止再次有新的 branch 进来。</p><p>step3：如果 status 是等于 Begin，那么久证明还没有提交过，改变其状态为 Committing 也就是正在提交。</p><p>step4：判断是否是可以异步提交，目前只有AT模式可以异步提交，因为是通过 Undolog 的方式去做的。MT 和 TCC 都需要走同步提交的代码。</p><p>step5：如果是异步提交，直接将其放进 ASYNC_COMMITTING_SESSION_MANAGER，让其再后台线程异步去做  step6，如果是同步的那么直接执行 step6。</p><p>step6：遍历 BranchSession 进行提交，如果某个分支事务失败，根据不同的条件来判断是否进行重试，异步不需要重试，因为其本身都在 manager 中，只要没有成功就不会被删除会一直重试，如果是同步提交的会放进异步重试队列进行重试。</p><h3 id=3-5-globalrollback-全局回滚>3.5 GlobalRollback - 全局回滚</h3><p>如果我们的 TM 决定全局回滚，那么会走到下面的逻辑：</p><p><img src=https://cdn.nlark.com/yuque/0/2019/png/226702/1554712796004-71279d70-0422-4c44-b4c9-74a841d115a6.png alt=全局回滚></p><p>这个逻辑和提交流程基本一致，可以看作是他的反向，这里就不展开讲了。</p><h2 id=4-总结>4.总结</h2><p>最后在总结一下开始我们提出了分布式事务的关键四点，Seata 到底是怎么解决的：</p><ul><li>正确的协调：通过后台定时任务各种正确的重试，并且未来会推出监控平台有可能可以手动回滚。</li><li>高可用: 通过 HA-Cluster 保证高可用。</li><li>高性能：文件顺序写，RPC 通过 netty 实现，Seata 未来可以水平扩展，提高处理性能。</li><li>高扩展性：提供给用户可以自由实现的地方，比如配置，服务发现和注册，全局锁等等。</li></ul><p>最后希望大家能从这篇文章能了解 Seata-Server 的核心设计原理，当然你也可以想象如果你自己去实现一个分布式事务的 Server 应该怎样去设计？</p><h2 id=文中涉及的相关链接>文中涉及的相关链接</h2><ul><li>Seata github 地址：<a href=https://github.com/seata/seata>https://github.com/seata/seata</a></li><li>延伸阅读：<a href=https://www.sofastack.tech/blog/sofa-meetup-1-seata/>蚂蚁金服分布式事务开源以及实践 | SOFA 开源一周年献礼</a></li></ul></article><div class=-show-mobile><nav class=ss-pagination-next><a class=link-prev href=/blog/sofa-meetup-1-seata/><span class=text>上一篇:</span>
<span class=text>蚂蚁金服分布式事务开源以及实践 | SOFA 开源一周年献礼</span></a>
<a class=link-next href=/blog/sofastack-anniversary-1/><span class=text>下一篇:</span>
<span class=text>Hey, SOFAer！有些话想对你说：</span></a></nav></div></main><aside class=ss-layout-aside><div class=ss-card><h2 class=card-title>相关推荐</h2><ul class=ss-aside-related><li><a href=/activities/sofa-channel-4/>SOFAChannel#4：分布式事务 Seata TCC 模式深度解析</a></li><li><a href=/blog/sofa-meetup-1-seata/>蚂蚁金服分布式事务开源以及实践 | SOFA 开源一周年献礼</a></li><li><a href=/blog/seata-distributed-transaction-open-source/>蚂蚁金服分布式事务开源以及实践 | SOFA 开源一周年献礼</a></li></ul></div><div class="ss-aside-tags ss-card"><h2 class=card-title>标签
<span class=card-extra></span></h2><ul class=tag-list><li class=tag><a href=/tags/1024/>1024</a></li><li class=tag><a href=/tags/api-gateway/>API Gateway</a></li><li class=tag><a href=/tags/cafedeployment/>CAFEDeployment</a></li><li class=tag><a href=/tags/cloud-native/>Cloud Native</a></li><li class=tag><a href=/tags/cncf/>CNCF</a></li><li class=tag><a href=/tags/db-mesh/>DB Mesh</a></li><li class=tag><a href=/tags/elasticdl/>ElasticDL</a></li><li class=tag><a href=/tags/kata-container/>Kata Container</a></li><li class=tag><a href=/tags/kata-containers/>Kata Containers</a></li><li class=tag><a href=/tags/knative/>Knative</a></li><li class=tag><a href=/tags/kubecon/>KubeCon</a></li><li class=tag><a href=/tags/kubernetes/>Kubernetes</a></li><li class=tag><a href=/tags/meetup/>Meetup</a></li><li class=tag><a href=/tags/mosn/>MOSN</a></li><li class=tag><a href=/tags/occlum/>Occlum</a></li><li class=tag><a href=/tags/seata/>Seata</a></li><li class=tag><a href=/tags/serverless/>Serverless</a></li><li class=tag><a href=/tags/service-mesh/>Service Mesh</a></li><li class=tag><a href=/tags/service-mesh-meetup/>Service Mesh Meetup</a></li><li class=tag><a href=/tags/service-mesh-virtual-meetup/>Service Mesh Virtual Meetup</a></li><li class=tag><a href=/tags/service-mesh-webinar/>Service Mesh Webinar</a></li><li class=tag><a href=/tags/service-mesh-%E8%90%BD%E5%9C%B0%E5%AE%9E%E8%B7%B5/>Service Mesh 落地实践</a></li><li class=tag><a href=/tags/sidecar-%E5%AE%B9%E5%99%A8/>Sidecar 容器</a></li><li class=tag><a href=/tags/sofa-weekly/>SOFA Weekly</a></li><li class=tag><a href=/tags/sofaacts/>SOFAActs</a></li><li class=tag><a href=/tags/sofaark/>SOFAArk</a></li><li class=tag><a href=/tags/sofaarklab/>SOFAArkLab</a></li><li class=tag><a href=/tags/sofabolt/>SOFABolt</a></li><li class=tag><a href=/tags/sofaboot/>SOFABoot</a></li><li class=tag><a href=/tags/sofachannel/>SOFAChannel</a></li><li class=tag><a href=/tags/sofadashboard/>SOFADashboard</a></li><li class=tag><a href=/tags/sofaenclave/>SOFAEnclave</a></li><li class=tag><a href=/tags/sofajraft/>SOFAJRaft</a></li><li class=tag><a href=/tags/sofajraft-%E7%89%B9%E6%80%A7%E8%A7%A3%E6%9E%90/>SOFAJRaft 特性解析</a></li><li class=tag><a href=/tags/sofalab/>SOFALab</a></li><li class=tag><a href=/tags/sofalookout/>SOFALookout</a></li><li class=tag><a href=/tags/sofameetup/>SOFAMeetup</a></li><li class=tag><a href=/tags/sofamesh/>SOFAMesh</a></li><li class=tag><a href=/tags/sofaregistry/>SOFARegistry</a></li><li class=tag><a href=/tags/sofarpc/>SOFARPC</a></li><li class=tag><a href=/tags/sofastack/>SOFAStack</a></li><li class=tag><a href=/tags/sofatracer/>SOFATracer</a></li><li class=tag><a href=/tags/springboot/>SpringBoot</a></li><li class=tag><a href=/tags/sqlflow/>SQLFlow</a></li><li class=tag><a href=/tags/workshop/>Workshop</a></li><li class=tag><a href=/tags/zsearch/>ZSearch</a></li><li class=tag><a href=/tags/%E4%BA%91%E5%8E%9F%E7%94%9F/>云原生</a></li><li class=tag><a href=/tags/%E5%88%86%E5%B8%83%E5%BC%8F/>分布式</a></li><li class=tag><a href=/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/>分布式事务</a></li><li class=tag><a href=/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84/>分布式架构</a></li><li class=tag><a href=/tags/%E5%89%96%E6%9E%90-sofaark-%E6%BA%90%E7%A0%81/>剖析 | SOFAArk 源码</a></li><li class=tag><a href=/tags/%E5%89%96%E6%9E%90-sofabolt-%E6%A1%86%E6%9E%B6/>剖析 | SOFABolt 框架</a></li><li class=tag><a href=/tags/%E5%89%96%E6%9E%90-sofaboot-%E6%A1%86%E6%9E%B6/>剖析 | SOFABoot 框架</a></li><li class=tag><a href=/tags/%E5%89%96%E6%9E%90-sofajraft-%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/>剖析 | SOFAJRaft 实现原理</a></li><li class=tag><a href=/tags/%E5%89%96%E6%9E%90-sofaregistry-%E6%A1%86%E6%9E%B6/>剖析 | SOFARegistry 框架</a></li><li class=tag><a href=/tags/%E5%89%96%E6%9E%90-sofarpc-%E6%A1%86%E6%9E%B6/>剖析 | SOFARPC 框架</a></li><li class=tag><a href=/tags/%E5%89%96%E6%9E%90-sofatracer-%E6%A1%86%E6%9E%B6/>剖析 | SOFATracer 框架</a></li><li class=tag><a href=/tags/%E5%AE%9E%E8%B7%B5/>实践</a></li><li class=tag><a href=/tags/%E5%BC%80%E6%BA%90/>开源</a></li><li class=tag><a href=/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/>微服务</a></li><li class=tag><a href=/tags/%E6%99%BA%E8%83%BD%E7%9B%91%E6%8E%A7/>智能监控</a></li><li class=tag><a href=/tags/%E6%99%BA%E8%83%BD%E8%BF%90%E7%BB%B4/>智能运维</a></li><li class=tag><a href=/tags/%E6%BA%90%E5%88%9B%E4%BC%9A/>源创会</a></li><li class=tag><a href=/tags/%E9%95%9C%E5%83%8F/>镜像</a></li></ul></div></aside></div><footer class=ss-footer><div class=container><div class=links><div class=cate><h2 class=cate-title>资源</h2><a class=link href=https://github.com/sofastack>Github</a>
<a class=link href=https://gitee.com/sofastack/>Gitee</a>
<a class=link href=https://github.com/sofastack-guides>示例</a></div><div class=cate><h2 class=cate-title>社交媒体</h2><a class=link href=https://zhuanlan.zhihu.com/sofastack>知乎专栏</a>
<a class=link href=https://weibo.com/sofastack>新浪微博</a>
<a class=link href=https://twitter.com/sofastack_io>Twitter</a></div><div class=cate><h2 class=cate-title>参与进来</h2><a class=link href=https://github.com/sofastack/sofastack.tech/issues/new>反馈</a>
<a class=link href=https://github.com/sofastack/community>社区</a>
<a class=link href=https://github.com/sofastack/sofastack.tech/wiki>Wiki</a>
<a class=link href=mailto:sofa@alipay.cloud.com>Email</a>
<a class=link href=/hr/>加入我们</a></div><div class=cate><h2 class=cate-title>蚂蚁金服开源项目</h2><a class=link href=https://ant.design/>Ant Design</a>
<a class=link href=https://eggjs.org/>Egg</a>
<a class=link href=https://sqlflow.org>SQLFlow</a>
<a class=link href=https://tech.antfin.com/open-source>更多</a></div></div><div class=qrcode><div><img class=qrcode-img src=/img/qrcode/qrcode_1.png><p class=qrcode-desc>微信公众号</p></div><div><img class=qrcode-img src=/img/qrcode/qrcode_2.png><p class=qrcode-desc>钉钉群</p></div></div></div><div class=copyright><p>© 2019 - 2020 The SOFAStack Authors
<a href=http://beian.miit.gov.cn/>浙 ICP 备 16045294 号-3</a></p></div></footer></body></html>